<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>技术心得</title>
    <url>/readme/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>有人认为编程是一门技术活，要有一定的天赋，非天资聪慧者不能及也。</p>
<p>其实不然，笔者计算机专业出身，对于技术这碗饭有一些心得体会，大多数人成为某领域顶级专家可能会有些难度，但应对日常工作，<strong>成长为资深研发工程师、技术专家、甚至成为小团队的Team Leader，并不难。</strong></p>
<a id="more"></a>
<p><strong>多读书、多看报，多研究开源框架源码，比如：github.com，这里汇集了全球工程师的智慧！</strong></p>
<p>言归正传，本文会列举工作中常用的一些技术，以及如何锻炼提升自己的架构能力。</p>
<p>由于每块技术市场上基本都有对应的网络资料或书籍，所以本文只是少篇幅列举工作中用到的核心知识点，抛砖引玉，属于进阶型，不适用初学者。</p>
<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><ul>
<li><a href="/java/summary">java</a></li>
<li><a href="/spring/sprint-summary">spring</a></li>
<li><a href="/springboot/summary">spring boot</a></li>
<li><a href="/springcloud/springcloud-netflix">spring cloud</a></li>
<li><a href="/java/mybatis">ibatis</a></li>
<li><a href="/java/common-design-patterns">设计模式</a></li>
<li><a href="/java/log">Log日志</a></li>
</ul>
<p>HashMap的原理<br><a href="https://www.jianshu.com/p/d2c14a10266e" target="_blank" rel="noopener">https://www.jianshu.com/p/d2c14a10266e</a></p>
<p>kafka之partition消费者并行度测试心得<br><a href="https://blog.csdn.net/willwill101/article/details/50393416" target="_blank" rel="noopener">https://blog.csdn.net/willwill101/article/details/50393416</a></p>
<p>k8s与各网络插件集成<br><a href="https://www.jianshu.com/p/9e02e755bf54" target="_blank" rel="noopener">https://www.jianshu.com/p/9e02e755bf54</a></p>
<p>软件架构设计-五视图方法论<br><a href="https://blog.csdn.net/nnsword/article/details/78109126" target="_blank" rel="noopener">https://blog.csdn.net/nnsword/article/details/78109126</a></p>
<p>Flink面试题<br><a href="https://blog.csdn.net/huzechen/article/details/102827576" target="_blank" rel="noopener">https://blog.csdn.net/huzechen/article/details/102827576</a></p>
<h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><p>目前使用最多还是mysql，虽然单机性能比不上oracle，但免费开源，单机成本低且借助于分布式集群，可以有强大的输出能力。</p>
<ul>
<li><a href="/java/database-connection-pool">连接池</a></li>
<li><a href="/db/transaction">事务</a></li>
<li><a href="/db/sub-db-sub-table">分库分表</a></li>
<li><a href="/java/id-generate">全局表 ID生成器</a></li>
<li><a href="http://blog.csdn.net/itomge/article/details/6909240" target="_blank" rel="noopener">读写分离</a></li>
<li><a href="/db/sql-optimize1">SQL调优1</a></li>
<li><a href="/db/sql-optimize2">SQL调优1</a></li>
</ul>
<h2 id="web容器-协议-网络"><a href="#web容器-协议-网络" class="headerlink" title="web容器/协议/网络"></a>web容器/协议/网络</h2><ul>
<li><a href="/web/load-balance">负载均衡</a></li>
<li>服务器<ul>
<li><a href="/web/nginx">Nginx</a></li>
<li><a href="/web/tomcat">Tomcat</a></li>
</ul>
</li>
<li>协议<ul>
<li><a href="/web/http">HTTP 协议</a></li>
<li><a href="/web/tcp">TCP 协议</a></li>
</ul>
</li>
<li><a href="/web/cdn">CDN</a></li>
</ul>
<h2 id="常用三方工具包"><a href="#常用三方工具包" class="headerlink" title="常用三方工具包"></a>常用三方工具包</h2><ul>
<li><a href="/third-tools/Goole-Guava">Google Guava</a></li>
<li><a href="/third-tools/fastJson">fastJson</a></li>
<li><a href="http://blog.csdn.net/itomge/article/details/17913607" target="_blank" rel="noopener">log4J</a></li>
<li><a href="/third-tools/commons-codec">commons-codec</a></li>
<li><a href="/third-tools/commons-lang3">commons-lang3</a></li>
<li><a href="/third-tools/commons-io">commons-io</a></li>
<li><a href="/third-tools/Quartz">Quartz</a></li>
<li><a href="/third-tools/HttpClient">HttpClient</a></li>
<li><a href="/third-tools/okhttp">okhttp</a></li>
<li><a href="/third-tools/Javassist">Javassist</a></li>
<li><a href="/third-tools/lombok">lombok</a></li>
</ul>
<h2 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h2><ul>
<li><p>RPC框架</p>
<ul>
<li><a href="/middle-software/dubbo">dubbo</a></li>
<li><a href="https://www.oschina.net/p/dubbox" target="_blank" rel="noopener">dubbox</a></li>
<li><a href="https://github.com/weibocom/motan" target="_blank" rel="noopener">motan</a></li>
<li><a href="https://github.com/apache/thrift" target="_blank" rel="noopener">Thrift</a></li>
<li><a href="/middle-software/rpc-compare">RPC框架性能比较</a></li>
</ul>
</li>
<li><p>MQ消息</p>
<ul>
<li><a href="https://github.com/apache/activemq" target="_blank" rel="noopener">ActiveMQ</a></li>
<li><a href="/middle-software/RabbitMQ">RabbitMQ</a></li>
<li><a href="/middle-software/kafka">Kafka</a></li>
<li><a href="/middle-software/RocketMQ">RocketMQ</a>    </li>
<li><a href="/middle-software/mq-compare">MQ框架性能比较</a></li>
</ul>
</li>
<li><p>分布式缓存</p>
<ul>
<li><a href="/third-tools/redis">redis</a></li>
<li><a href="http://blog.csdn.net/itomge/article/details/8035197" target="_blank" rel="noopener">memcache</a></li>
</ul>
</li>
<li><p>本地缓存</p>
<ul>
<li><a href="/middle-software/guava">Guava</a></li>
<li><a href="/middle-software/ehcache">Ehcache</a></li>
</ul>
</li>
<li><p>搜索</p>
<ul>
<li><a href="/middle-software/elasticsearch">Elasticsearch</a></li>
</ul>
</li>
<li><p>分布式数据框架</p>
<ul>
<li><a href="/middle-software/cobar">cobar</a></li>
<li><a href="/middle-software/mycat">Mycat</a></li>
<li><a href="/middle-software/tsharding">tsharding</a></li>
<li><a href="https://github.com/alibaba/tb_tddl" target="_blank" rel="noopener">tddl</a></li>
<li><a href="/middle-software/sharding-jdbc">sharding-jdbc</a></li>
<li><a href="https://gitee.com/robertleepeak/dbsplit" target="_blank" rel="noopener">dbsplit</a></li>
</ul>
</li>
<li><p>分布式协调服务</p>
<ul>
<li><a href="/middle-software/zookeeper">zookeeper</a></li>
</ul>
</li>
<li><p>配置管理</p>
<ul>
<li><a href="/java-other/super-diamond源码分析">super-diamond</a></li>
<li><a href="https://www.oschina.net/p/disconf" target="_blank" rel="noopener">disconf</a></li>
<li><a href="/middle-software/apollo">apollo</a></li>
</ul>
</li>
<li><p>分布式文件系统</p>
<ul>
<li><a href="/middle-software/FastDFS">FastDFS</a></li>
</ul>
</li>
<li><p>分布式任务调度框架</p>
<ul>
<li><a href="https://github.com/elasticjob/elastic-job" target="_blank" rel="noopener">Elastic-Job</a></li>
<li><a href="http://www.infoq.com/cn/articles/dangdang-distributed-work-framework-elastic-job" target="_blank" rel="noopener">详解当当网的分布式作业框架elastic-job</a></li>
<li><a href="http://blog.csdn.net/taosir_zhang/article/details/50728362" target="_blank" rel="noopener">TBSchedule</a></li>
<li><a href="https://github.com/xuxueli/xxl-job" target="_blank" rel="noopener">xxl-job</a></li>
</ul>
</li>
<li><p>大数据</p>
<ul>
<li><a href="/middle-software/Hbase">Hbase</a></li>
<li><a href="/middle-software/Spark">Spark</a></li>
<li><a href="/middle-software/Hadoop">Hadoop</a></li>
<li><a href="/middle-software/Hive">Hive</a></li>
<li><a href="/middle-software/big-data">other框架</a>    </li>
</ul>
</li>
<li><p>其它</p>
<ul>
<li><a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">数据库binlog的增量订阅&amp;消费组件</a></li>
<li><a href="https://github.com/alibaba/otter" target="_blank" rel="noopener">数据库同步系统</a></li>
<li><a href="/middle-software/TCC-Transaction">TCC-Transaction</a></li>
<li><a href="/middle-software/Netty">Netty</a></li>
<li><a href="/middle-software/openresty">OpenResty</a></li>
</ul>
</li>
</ul>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><ul>
<li><a href="/system-architecture/architecture-experience">架构经验</a></li>
<li><a href="/system-architecture/architecture-good-case">经典案例</a></li>
<li><a href="/system-architecture/technology-selection">通用技术方案选型</a></li>
<li><a href="/system-architecture/编码前3000问">编码前3000问</a></li>
<li><a href="/system-architecture/software-performance">软硬件性能</a></li>
<li><a href="/system-architecture/knowledge-outline">技术大纲</a></li>
</ul>
<h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><ul>
<li><a href="/project-management/论需求调研的重要性">论需求调研的重要性</a></li>
<li><a href="/project-management/project-management">项目管理</a></li>
<li><a href="/project-management/code">代码管理</a></li>
<li><a href="/project-management/test">测试相关</a></li>
</ul>
<h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><ul>
<li><a href="/java/online-question">快速排查线上问题</a></li>
<li><a href="/linux/linux-commands">linux常用命令</a></li>
<li><a href="/docker/docker-summary">Docker</a></li>
</ul>
<h2 id="个人成长"><a href="#个人成长" class="headerlink" title="个人成长"></a>个人成长</h2><ul>
<li><a href="/java-other/study">学习网站</a></li>
<li><a href="/java-other/book">Tom哥的读书单</a></li>
<li><a href="/java-other/person">个人成长与职业规划</a></li>
<li><a href="/java-other/programer">程序员素养</a></li>
</ul>
<h2 id="优秀开源项目"><a href="#优秀开源项目" class="headerlink" title="优秀开源项目"></a>优秀开源项目</h2><h3 id="1-SpringBlade"><a href="#1-SpringBlade" class="headerlink" title="1. SpringBlade"></a>1. SpringBlade</h3><p>SpringBlade 是一个由商业级项目升级优化而来的SpringCloud分布式微服务架构、SpringBoot单体式微服务架构并存的综合型项目，采用Java8 API重构了业务代码，完全遵循阿里巴巴编码规范。采用Spring Boot 2 、Spring Cloud Hoxton 、Mybatis 等核心技术，同时提供基于React和Vue的两个前端框架用于快速搭建企业级的SaaS多租户微服务平台。 官网：<a href="https://bladex.vip" target="_blank" rel="noopener">https://bladex.vip</a></p>
<p>项目地址: <a href="https://gitee.com/kisee/SpringBlade" target="_blank" rel="noopener">https://gitee.com/kisee/SpringBlade</a></p>
<h3 id="1-wisdom-education"><a href="#1-wisdom-education" class="headerlink" title="1. wisdom-education"></a>1. wisdom-education</h3><p>基于 SpringBoot + Mybatis + Shiro + mysql + redis构建的智慧云智能教育平台。</p>
<p>项目地址：<a href="https://gitee.com/zhuimengshaonian/wisdom-education" target="_blank" rel="noopener">https://gitee.com/zhuimengshaonian/wisdom-education</a></p>
<p>项目演示地址<br>管理后台 <a href="http://180.76.146.67:8002" target="_blank" rel="noopener">http://180.76.146.67:8002</a> （admin 123456）<br>学生端 <a href="http://180.76.146.67" target="_blank" rel="noopener">http://180.76.146.67</a> （student 123456）</p>
<p>智慧云智能教育系统管理平台<br>项目源码地址： <a href="https://gitee.com/zhuimengshaonian/wisdom-education-admin-front" target="_blank" rel="noopener">https://gitee.com/zhuimengshaonian/wisdom-education-admin-front</a></p>
<ul>
<li>功能模块：系统首页、教育教学模块、考试管理模块、统计分析模块、系统设置模块</li>
<li>试题管理：支持excel模板导入试题、支持使用富文本编辑试题及插入数学公式，同时还支持上传试题教学视频</li>
<li>试卷管理：支持将试卷导出成word文档、html页面进行打印、支持富文本图片导出到word</li>
<li>试卷批改功能：支持教师后台批改试卷，主观题系统自动评分、非主观题由教师评分、错题可设置添加到学员错题本</li>
<li>RBCA权限管理：主要包括用户、角色、权限<br>智慧云智能教育平台学生端<br>项目源码地址： <a href="https://gitee.com/zhuimengshaonian/wisdom-education-front" target="_blank" rel="noopener">https://gitee.com/zhuimengshaonian/wisdom-education-front</a></li>
<li>功能模块：学员在线做课程试题、在线考试、错题本功能记录、考试记录、个人中心</li>
</ul>
<h3 id="2-dts-shop"><a href="#2-dts-shop" class="headerlink" title="2. dts-shop"></a>2. dts-shop</h3><p>聚惠星商城 DTS-SHOP，基于 微信小程序 + springboot + vue 技术构建 ，支持单店铺，多店铺入驻的商城平台。项目包含 微信小程序，管理后台。基于java后台语言，已功能闭环，且达到商用标准的一套项目体系。</p>
<p>项目地址：<a href="https://gitee.com/qiguliuxing/dts-shop" target="_blank" rel="noopener">https://gitee.com/qiguliuxing/dts-shop</a></p>
<h3 id="3-x-RdbmsSyncTool"><a href="#3-x-RdbmsSyncTool" class="headerlink" title="3.x-RdbmsSyncTool"></a>3.x-RdbmsSyncTool</h3><p>RdbmsSyncTool是使用javaFx开发的关系型数据库同步工具xJavaFxTool的插件集合，可实现打包后让框架自动加载，可在线下载和更新工具，后续小工具将在这个项目中添加，实现动态jar包加载。</p>
<p>项目地址：<a href="https://gitee.com/xwintop/x-RdbmsSyncTool" target="_blank" rel="noopener">https://gitee.com/xwintop/x-RdbmsSyncTool</a></p>
<h3 id="4-QuickD"><a href="#4-QuickD" class="headerlink" title="4. QuickD"></a>4. QuickD</h3><p>QuickD是一个前后端分离快速开发平台，是基于 Spring Boot 和 Vue 开发，整合Flowable工作流、Shiro、Redis等，来帮助中小型企业及个人实现敏捷化的应用交付和运营管理，并提供代码生成器、通用前端等业务组件，来帮助开发者聚焦于业务，加速中小型企业数字化转型。<a href="http://website.jhyj56.com/" target="_blank" rel="noopener">http://website.jhyj56.com/</a></p>
<p>项目地址：<a href="https://gitee.com/quickd/quickd" target="_blank" rel="noopener">https://gitee.com/quickd/quickd</a></p>
<h3 id="5-JeecgBoot"><a href="#5-JeecgBoot" class="headerlink" title="5. JeecgBoot"></a>5. JeecgBoot</h3><p>基于代码生成器的低代码开发平台，开源界“小普元”超越传统商业开发平台！前后端分离架构：SpringBoot 2.x，Ant Design&amp;Vue，Mybatis-plus，Shiro，JWT。强大的代码生成器让前后端代码一键生成，无需写任何代码! 引领新开发模式(OnlineCoding-&gt; 代码生成-&gt; 手工MERGE)，帮助Java项目解决70%重复工作，让开发更关注业务逻辑，既能快速提高开发效率，帮助公司节省成本，同时又不失灵活性。 <a href="http://www.jeecg.com" target="_blank" rel="noopener">http://www.jeecg.com</a></p>
<p>项目地址：<a href="https://github.com/zhangdaiscott/jeecg-boot" target="_blank" rel="noopener">https://github.com/zhangdaiscott/jeecg-boot</a></p>
<h3 id="6-ExeBuilder"><a href="#6-ExeBuilder" class="headerlink" title="6. ExeBuilder"></a>6. ExeBuilder</h3><p>ExeBuilder 是一款利用 JDK 模块化的特性把jar打包成独立exe的工具，它支持GUI和控制台应用程序的创建。</p>
<p>项目地址：<a href="https://gitee.com/qsyan/ExeBuilder" target="_blank" rel="noopener">https://gitee.com/qsyan/ExeBuilder</a></p>
<h3 id="7-keycloak"><a href="#7-keycloak" class="headerlink" title="7. keycloak"></a>7. keycloak</h3><p>Open Source Identity and Access Management For Modern Applications and Services <a href="https://www.keycloak.org" target="_blank" rel="noopener">https://www.keycloak.org</a></p>
<p>项目地址：<a href="https://github.com/keycloak/keycloak" target="_blank" rel="noopener">https://github.com/keycloak/keycloak</a></p>
<h3 id="8-MaxKey"><a href="#8-MaxKey" class="headerlink" title="8. MaxKey"></a>8. MaxKey</h3><p>MaxKey(马克思的钥匙)，寓意是最大钥匙， 是用户单点登录认证系统（Sigle Sign On System）,支持OAuth 2.0/OpenID Connect、SAML 2.0、JWT、CAS等标准化的开放协议，提供简单、标准、安全和开放的用户身份认证和单点登录，包含用户认证、单点登录、资源管理、权限管理等。</p>
<p>项目地址：<a href="https://gitee.com/shimingxy/MaxKey" target="_blank" rel="noopener">https://gitee.com/shimingxy/MaxKey</a></p>
<h3 id="9-microservices-platform"><a href="#9-microservices-platform" class="headerlink" title="9. microservices-platform"></a>9. microservices-platform</h3><p>SpringCloud, 基于SpringBoot2.x、SpringCloud和SpringCloudAlibaba并采用前后端分离的企业级微服务多租户系统架构。并引入组件化的思想实现高内聚低耦合并且高度可配置化，适合学习和企业中使用。真正实现了基于RBAC、jwt和oauth2的无状态统一权限认证的解决方案，面向互联网设计同时适合B端和C端用户，支持CI/CD多环境部署，并提供应用管理方便第三方系统接入；同时还集合各种微服务治理功能和监控功能。模块包括:企业级的认证系统、开发平台、应用监控、慢sql监控、统一日志、单点登录、Redis分布式高速缓存、配置中心、分布式任务调度、接口文档、代码生成等等。</p>
<p>项目地址： <a href="https://gitee.com/zlt2000/microservices-platform.git" target="_blank" rel="noopener">https://gitee.com/zlt2000/microservices-platform.git</a></p>
<h3 id="10-middle-ware-parent"><a href="#10-middle-ware-parent" class="headerlink" title="10. middle-ware-parent"></a>10. middle-ware-parent</h3><p>SpringBoot集成各类常用开发中间件，分库分表，缓存，消息队列，定时器，权限管理等组件</p>
<p>项目地址：<a href="https://gitee.com/cicadasmile/middle-ware-parent" target="_blank" rel="noopener">https://gitee.com/cicadasmile/middle-ware-parent</a></p>
<h3 id="11-chjm872-mall"><a href="#11-chjm872-mall" class="headerlink" title="11. chjm872/mall"></a>11. chjm872/mall</h3><p>mall项目是一套电商系统，包括前台商城系统及后台管理系统，基于SpringBoot+MyBatis实现，采用Docker容器化部署。 前台商城系统包含首页门户、商品推荐、商品搜索、商品展示、购物车、订单流程、会员中心、客户服务、帮助中心等模块。 后台管理系统包含商品管理、订单管理、会员管理、促销管理、运营管理、内容管理、统计报表、财务管理、权限管理、设置等模块。</p>
<p>项目地址：<a href="https://github.com/chjm872/mall" target="_blank" rel="noopener">https://github.com/chjm872/mall</a></p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><ul>
<li><a href="/java-other/tool">常用软件工具</a></li>
<li><a href="/java-other/一致性hash">一致性hash算法</a></li>
<li>面试<ul>
<li><a href="/java-other/java-interview">java面试题</a></li>
<li><a href="/java-other/bigdata-interview">大数据面试题</a></li>
</ul>
</li>
<li><a href="/java-other/回车与换行的区别">回车与换行的区别</a></li>
<li><a href="http://blog.csdn.net/qq1332479771/article/details/56087333" target="_blank" rel="noopener">github上fork项目后，如何同步更新后面提交</a></li>
<li><a href="/java-other/other">其它</a></li>
</ul>
<h2 id="今日头条"><a href="#今日头条" class="headerlink" title="今日头条"></a>今日头条</h2><p><strong>新开了个今日头条号：微观技术，分享各个行业优秀的架构设计方案、技术心得、心路历程等，欢迎各位技术达人关注、经验交流</strong></p>
<img data-src="http://f.ngall-in.com/alan87/static/images/toutiao.jpeg/200">


<h2 id="商务合作，请发邮件到-547708024-QQ邮箱"><a href="#商务合作，请发邮件到-547708024-QQ邮箱" class="headerlink" title="商务合作，请发邮件到 547708024 QQ邮箱"></a>商务合作，请发邮件到 547708024 QQ邮箱</h2>]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>Dockerfile创建自定义Docker镜像Dockerfile创建自定义Docker镜像</title>
    <url>/docker/Dockerfile%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89Docker%E9%95%9C%E5%83%8F/</url>
    <content><![CDATA[<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h1><p>创建Docker镜像的方式有三种</p>
<ul>
<li>docker commit命令：由容器生成镜像；</li>
<li>Dockerfile文件+docker build命令；</li>
<li>从本地文件系统导入：OpenVZ的模板。</li>
</ul>
<p>最近学习了Dockerfile文件的相关配置，这里做一下简单的总结，并对之前一直感到有些迷惑的CMD和ENTRYPOINT指令做个差异对比。</p>
<h1 id="2-Dockerfile文件总结"><a href="#2-Dockerfile文件总结" class="headerlink" title="2.Dockerfile文件总结"></a>2.Dockerfile文件总结</h1><p>Dockerfile 由一行行命令语句组成，并且支持以 # 开头的注释行。</p>
<p>一般地，Dockerfile 分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。<br>| 四部分 | 指令 |<br>| :—–| :—- |<br>| 基础镜像信息 | FROM |<br>| 维护者信息 | MAINTAINER |<br>| 镜像操作指令 | RUN、COPY、ADD、EXPOSE等 |<br>| 容器启动时执行指令 | CMD、ENTRYPOINT | </p>
<p>Dockerfile文件的第一条指令必须是FROM，其后可以是各种镜像的操作指令，最后是CMD或ENTRYPOINT指定容器启动时执行的命令。</p>
<h2 id="2-1-各个指令的介绍，"><a href="#2-1-各个指令的介绍，" class="headerlink" title="2.1 各个指令的介绍，"></a>2.1 各个指令的介绍，</h2><ul>
<li>指令</li>
</ul>
<p>指令的一般格式为 INSTRUCTION arguments，指令包括 FROM、MAINTAINER、RUN 等。</p>
<ul>
<li>FROM</li>
</ul>
<p>格式为 FROM <image>或FROM <image>:<tag>。</p>
<p>第一条指令必须为 FROM 指令。并且，如果在同一个Dockerfile中创建多个镜像时，可以使用多个 FROM 指令（每个镜像一次）。</p>
<ul>
<li>MAINTAINER</li>
</ul>
<p>格式为 MAINTAINER <name>，指定维护者信息。</p>
<ul>
<li>RUN</li>
</ul>
<p>格式为 RUN <command> 或 RUN [“executable”, “param1”, “param2”]。</p>
<p>前者将在 shell 终端中运行命令，即 /bin/sh -c；后者则使用 exec 执行。指定使用其它终端可以通过第二种方式实现，例如 RUN [“/bin/bash”, “-c”, “echo hello”]。</p>
<p>每条 RUN 指令将在当前镜像基础上执行指定命令，并提交为新的镜像。当命令较长时可以使用 \ 来换行。</p>
<ul>
<li>CMD<br>  支持三种格式<ul>
<li>CMD [“executable”,”param1”,”param2”] 使用 exec 执行，推荐方式；</li>
<li>CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用；</li>
<li>CMD [“param1”,”param2”] 提供给 ENTRYPOINT 的默认参数；</li>
</ul>
</li>
</ul>
<p>指定启动容器时执行的命令，每个 Dockerfile 只能有一条 CMD 命令。如果指定了多条命令，只有最后一条会被执行。</p>
<p>如果用户启动容器时候指定了运行的命令，则会覆盖掉 CMD 指定的命令。</p>
<ul>
<li>EXPOSE</li>
</ul>
<p>格式为 EXPOSE <port> [<port>…]。</p>
<p>告诉 Docker 服务端容器暴露的端口号，供互联系统使用。在启动容器时需要通过 -P，Docker 主机会自动分配一个端口转发到指定的端口。</p>
<ul>
<li>ENV</li>
</ul>
<p>格式为 ENV <key> <value>。 指定一个环境变量，会被后续 RUN 指令使用，并在容器运行时保持。</p>
<p>例如:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ENV PG_MAJOR 9.3</span><br><span class="line"></span><br><span class="line">ENV PG_VERSION 9.3.4</span><br><span class="line"></span><br><span class="line">RUN curl -SL http://example.com/postgres-<span class="variable">$PG_VERSION</span>.tar.xz | tar -xJC /usr/src/postgress &amp;&amp; …</span><br><span class="line"></span><br><span class="line">ENV PATH /usr/<span class="built_in">local</span>/postgres-<span class="variable">$PG_MAJOR</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<ul>
<li>ADD</li>
</ul>
<p>格式为 ADD <src> <dest>。</p>
<p>该命令将复制指定的 <src> 到容器中的 <dest>。 其中 <src> 可以是Dockerfile所在目录的一个相对路径；也可以是一个 URL；还可以是一个 tar 文件（自动解压为目录）。</p>
<ul>
<li>COPY</li>
</ul>
<p>格式为 COPY <src> <dest>。</p>
<p>复制本地主机的 <src>（为 Dockerfile 所在目录的相对路径）到容器中的 <dest>。</p>
<p>当使用本地目录为源目录时，推荐使用 COPY。</p>
<ul>
<li><p>ENTRYPOINT<br>  两种格式：</p>
<ul>
<li><p>ENTRYPOINT [“executable”, “param1”, “param2”]</p>
</li>
<li><p>ENTRYPOINT command param1 param2（shell中执行）。</p>
</li>
</ul>
</li>
</ul>
<p>配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。</p>
<p>每个 Dockerfile 中只能有一个 ENTRYPOINT，当指定多个时，只有最后一个起效。</p>
<ul>
<li>VOLUME</li>
</ul>
<p>格式为 VOLUME [“/data”]。</p>
<p>创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等。</p>
<ul>
<li>USER</li>
</ul>
<p>格式为 USER daemon。</p>
<p>指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。</p>
<p>当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户，例如：RUN groupadd -r postgres &amp;&amp; useradd -r -g postgres postgres。要临时获取管理员权限可以使用 gosu，而不推荐 sudo。</p>
<ul>
<li>WORKDIR</li>
</ul>
<p>格式为 WORKDIR /path/to/workdir。</p>
<p>为后续的 RUN、CMD、ENTRYPOINT 指令配置工作目录。</p>
<p>可以使用多个 WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如</p>
<p>WORKDIR /a</p>
<p>WORKDIR b</p>
<p>WORKDIR c</p>
<p>RUN pwd</p>
<p>则最终路径为 /a/b/c。</p>
<ul>
<li>ONBUILD</li>
</ul>
<p>格式为 ONBUILD [INSTRUCTION]。</p>
<p>配置当所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令。</p>
<p>例如，Dockerfile 使用如下的内容创建了镜像 image-A。</p>
<p>[…]</p>
<p>ONBUILD ADD . /app/src</p>
<p>ONBUILD RUN /usr/local/bin/python-build –dir /app/src</p>
<p>[…]</p>
<p>如果基于 image-A 创建新的镜像时，新的Dockerfile中使用 FROM image-A指定基础镜像时，会自动执行 ONBUILD 指令内容，等价于在后面添加了两条指令。</p>
<p>FROM image-A #Automatically run the followingADD . /app/srcRUN /usr/local/bin/python-build –dir /app/src</p>
<p>使用 ONBUILD 指令的镜像，推荐在标签中注明，例如 ruby:1.9-onbuild。</p>
<h1 id="3-创建镜像"><a href="#3-创建镜像" class="headerlink" title="3.创建镜像"></a>3.创建镜像</h1><p>编写完Dockerfile文件后，通过运行docker build命令来创建自定义的镜像。Docker build命令格式如下：</p>
<p>docker build [options] <path></p>
<p>该命令将读取指定路径下（包括子目录）的 Dockerfile，并将该路径下所有内容发送给 Docker 服务端，由服务端来创建镜像。因此一般建议放置 Dockerfile 的目录为空目录。也可以通过 .dockerignore 文件（每一行添加一条匹配模式）来让 Docker 忽略路径下的目录和文件。</p>
<p>例如下面使用Dockerfile样例来创建了镜像test:0.0.1，其中-t选项用来指定镜像的tag。Dockerfile文件内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER lienhua34@xxx.com</span><br><span class="line"> </span><br><span class="line">RUN mkdir /opt/leh</span><br><span class="line">RUN touch /opt/leh/<span class="built_in">test</span></span><br><span class="line"> </span><br><span class="line">CMD <span class="built_in">echo</span> <span class="string">"Hello lienhua34"</span></span><br></pre></td></tr></table></figure>


<p>下面运行docker build命令生成镜像test:0.0.1，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker build -t <span class="built_in">test</span>:0.0.1 .</span><br><span class="line">Sending build context to Docker daemon 3.072 kB</span><br><span class="line">Step 1 : FROM ubuntu:14.04</span><br><span class="line"> ---&gt; a5a467fddcb8</span><br><span class="line">Step 2 : MAINTAINER lienhua34@163.com</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> ce9e7b02f075</span><br><span class="line"> ---&gt; 332259a92e74</span><br><span class="line">Removing intermediate container ce9e7b02f075</span><br><span class="line">Step 3 : RUN mkdir /opt/leh</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> e93f0a98040f</span><br><span class="line"> ---&gt; 097e177cf37f</span><br><span class="line">Removing intermediate container e93f0a98040f</span><br><span class="line">Step 4 : RUN touch /opt/leh/<span class="built_in">test</span></span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> f1531d3dea1a</span><br><span class="line"> ---&gt; 0f68852f8356</span><br><span class="line">Removing intermediate container f1531d3dea1a</span><br><span class="line">Step 5 : CMD <span class="built_in">echo</span> <span class="string">"Hello lienhua34"</span></span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> cf3c5ce2af46</span><br><span class="line"> ---&gt; 811ce27ce692</span><br><span class="line">Removing intermediate container cf3c5ce2af46</span><br><span class="line">Successfully built 811ce27ce692</span><br></pre></td></tr></table></figure>

<p>然后启动该镜像的容器来查看结果，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker images</span><br><span class="line">REPOSITORY                   TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span><br><span class="line"><span class="built_in">test</span>                         0.0.1               811ce27ce692        32 seconds ago      187.9 MB</span><br><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti <span class="built_in">test</span>:0.0.1</span><br><span class="line">Hello lienhua34</span><br></pre></td></tr></table></figure>

<p>Dockerfile文件的每条指令生成镜像的一层（注：一个镜像不能超过127层）。Dockerfile中的指令被一条条地执行。每一步都创建一个新的容器，在容器中执行指令并提交修改。当所有指令执行完毕后，返回最终的镜像id。</p>
<h1 id="4-Dockerfile文件中的CMD和ENTRYPOINT指令差异对比"><a href="#4-Dockerfile文件中的CMD和ENTRYPOINT指令差异对比" class="headerlink" title="4.Dockerfile文件中的CMD和ENTRYPOINT指令差异对比"></a>4.Dockerfile文件中的CMD和ENTRYPOINT指令差异对比</h1><p>CMD指令和ENTRYPOINT指令的作用都是为镜像指定容器启动后的命令，那么它们两者之间有什么各自的优点呢？</p>
<p>为了更好地对比CMD指令和ENTRYPOINT指令的差异，我们这里再列一下这两个指令的说明，</p>
<ul>
<li><p>CMD</p>
<p>  支持三种格式</p>
<ul>
<li><p>CMD [“executable”,”param1”,”param2”] 使用 exec 执行，推荐方式；</p>
</li>
<li><p>CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用；</p>
</li>
<li><p>CMD [“param1”,”param2”] 提供给 ENTRYPOINT 的默认参数；</p>
</li>
</ul>
</li>
</ul>
<p>指定启动容器时执行的命令，每个 Dockerfile 只能有一条 CMD 命令。如果指定了多条命令，只有最后一条会被执行。</p>
<p>如果用户启动容器时候指定了运行的命令，则会覆盖掉 CMD 指定的命令。</p>
<ul>
<li><p>ENTRYPOINT</p>
<p>  两种格式：</p>
<ul>
<li><p>ENTRYPOINT [“executable”, “param1”, “param2”]</p>
</li>
<li><p>ENTRYPOINT command param1 param2（shell中执行）。</p>
</li>
</ul>
</li>
</ul>
<p>配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。</p>
<p>每个 Dockerfile 中只能有一个 ENTRYPOINT，当指定多个时，只有最后一个起效。</p>
<p>从上面的说明，我们可以看到有两个共同点：</p>
<p>都可以指定shell或exec函数调用的方式执行命令；<br>当存在多个CMD指令或ENTRYPOINT指令时，只有最后一个生效；<br>而它们有如下差异：</p>
<ul>
<li><p>差异1：CMD指令指定的容器启动时命令可以被docker run指定的命令覆盖，而ENTRYPOINT指令指定的命令不能被覆盖，而是将docker run指定的参数当做ENTRYPOINT指定命令的参数。</p>
</li>
<li><p>差异2：CMD指令可以为ENTRYPOINT指令设置默认参数，而且可以被docker run指定的参数覆盖；</p>
</li>
</ul>
<p>下面分别对上面两个差异点进行详细说明，</p>
<h2 id="4-1-差异1"><a href="#4-1-差异1" class="headerlink" title="4.1 差异1"></a>4.1 差异1</h2><p>CMD指令指定的容器启动时命令可以被docker run指定的命令覆盖；而ENTRYPOINT指令指定的命令不能被覆盖，而是将docker run指定的参数当做ENTRYPOINT指定命令的参数。</p>
<p>下面有个命名为startup的可执行shell脚本，其功能就是输出命令行参数而已。内容如下所示，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">"in startup, args: <span class="variable">$@</span>"</span></span><br></pre></td></tr></table></figure>
<p>通过CMD指定容器启动时命令：<br>现在我们新建一个Dockerfile文件，其将startup脚本拷贝到容器的/opt目录下，并通过CMD指令指定容器启动时运行该startup脚本。其内容如下，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER lienhua34@xxx.com</span><br><span class="line"> </span><br><span class="line">ADD startup /opt</span><br><span class="line">RUN chmod a+x /opt/startup</span><br><span class="line"> </span><br><span class="line">CMD [<span class="string">"/opt/startup"</span>]</span><br></pre></td></tr></table></figure>
<p>然后我们通过运行docker build命令生成test:latest镜像，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker build -t <span class="built_in">test</span> .</span><br><span class="line">Sending build context to Docker daemon 4.096 kB</span><br><span class="line">Step 1 : FROM ubuntu:14.04</span><br><span class="line"> ---&gt; a5a467fddcb8</span><br><span class="line">Step 2 : MAINTAINER lienhua34@163.com</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 332259a92e74</span><br><span class="line">Step 3 : ADD startup /opt</span><br><span class="line"> ---&gt; 3c26b6a8ef1b</span><br><span class="line">Removing intermediate container 87022b0f30c5</span><br><span class="line">Step 4 : RUN chmod a+x /opt/startup</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 4518ba223345</span><br><span class="line"> ---&gt; 04d9b53d6148</span><br><span class="line">Removing intermediate container 4518ba223345</span><br><span class="line">Step 5 : CMD /opt/startup</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 64a07c2f5e64</span><br><span class="line"> ---&gt; 18a2d5066346</span><br><span class="line">Removing intermediate container 64a07c2f5e64</span><br><span class="line">Successfully built 18a2d5066346</span><br></pre></td></tr></table></figure>

<p>然后使用docker run启动两个test:latest镜像的容器，第一个docker run命令没有指定容器启动时命令，第二个docker run命令指定了容器启动时的命令为“/bin/bash -c ‘echo Hello’”，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti --rm=<span class="literal">true</span> <span class="built_in">test</span></span><br><span class="line"><span class="keyword">in</span> startup, args: </span><br><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti --rm=<span class="literal">true</span> <span class="built_in">test</span> /bin/bash -c <span class="string">'echo Hello'</span></span><br><span class="line">Hello</span><br></pre></td></tr></table></figure>
<p>从上面运行结果可以看到，docker run命令启动容器时指定的运行命令覆盖了Dockerfile文件中CMD指令指定的命令。</p>
<p>通过ENTRYPOINT指定容器启动时命令：<br>将上面的Dockerfile中的CMD替换成ENTRYPOINT，内容如下所示，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER lienhua34@xxx.com</span><br><span class="line"> </span><br><span class="line">ADD startup /opt</span><br><span class="line">RUN chmod a+x /opt/startup</span><br><span class="line"> </span><br><span class="line">ENTRYPOINT [“/opt/startup”]</span><br></pre></td></tr></table></figure>

<p>同样，通过运行docker build生成test:latest镜像，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker build -t <span class="built_in">test</span> .</span><br><span class="line">Sending build context to Docker daemon 4.096 kB</span><br><span class="line">Step 1 : FROM ubuntu:14.04</span><br><span class="line"> ---&gt; a5a467fddcb8</span><br><span class="line">Step 2 : MAINTAINER lienhua34@163.com</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 332259a92e74</span><br><span class="line">Step 3 : ADD startup /opt</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 3c26b6a8ef1b</span><br><span class="line">Step 4 : RUN chmod a+x /opt/startup</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 04d9b53d6148</span><br><span class="line">Step 5 : ENTRYPOINT /opt/startup</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> cdec60940ad7</span><br><span class="line"> ---&gt; 78f8aca2edc2</span><br><span class="line">Removing intermediate container cdec60940ad7</span><br><span class="line">Successfully built 78f8aca2edc2</span><br></pre></td></tr></table></figure>
<p>然后使用docker run启动两个test:latest镜像的容器，第一个docker run命令没有指定容器启动时命令，第二个docker run命令指定了容器启动时的命令为“/bin/bash -c ‘echo Hello’”，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti --rm=<span class="literal">true</span> <span class="built_in">test</span></span><br><span class="line"><span class="keyword">in</span> startup, args: </span><br><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti --rm=<span class="literal">true</span> <span class="built_in">test</span> /bin/bash -c <span class="string">'echo Hello'</span></span><br><span class="line"><span class="keyword">in</span> startup, args: /bin/bash -c <span class="built_in">echo</span> Hello</span><br></pre></td></tr></table></figure>

<p>通过上面的运行结果可以看出，docker run命令指定的容器运行命令不能覆盖Dockerfile文件中ENTRYPOINT指令指定的命令，反而被当做参数传递给ENTRYPOINT指令指定的命令。</p>
<h2 id="4-2-差异2"><a href="#4-2-差异2" class="headerlink" title="4.2 差异2"></a>4.2 差异2</h2><p>CMD指令可以为ENTRYPOINT指令设置默认参数，而且可以被docker run指定的参数覆盖；</p>
<p>同样使用上面的startup脚本。编写Dockerfile，内容如下所示，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER lienhua34@xxx.com</span><br><span class="line"> </span><br><span class="line">ADD startup /opt</span><br><span class="line">RUN chmod a+x /opt/startup</span><br><span class="line"> </span><br><span class="line">ENTRYPOINT [<span class="string">"/opt/startup"</span>, <span class="string">"arg1"</span>]</span><br><span class="line">CMD [<span class="string">"arg2"</span>]</span><br></pre></td></tr></table></figure>

<p>运行docker build命令生成test:latest镜像，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker build -t <span class="built_in">test</span> .</span><br><span class="line">Sending build context to Docker daemon 4.096 kB</span><br><span class="line">Step 1 : FROM ubuntu:14.04</span><br><span class="line"> ---&gt; a5a467fddcb8</span><br><span class="line">Step 2 : MAINTAINER lienhua34@163.com</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 332259a92e74</span><br><span class="line">Step 3 : ADD startup /opt</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 3c26b6a8ef1b</span><br><span class="line">Step 4 : RUN chmod a+x /opt/startup</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 04d9b53d6148</span><br><span class="line">Step 5 : ENTRYPOINT /opt/startup arg1</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 54947233dc3d</span><br><span class="line"> ---&gt; 15a485253b4e</span><br><span class="line">Removing intermediate container 54947233dc3d</span><br><span class="line">Step 6 : CMD arg2</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 18c43d2d90fd</span><br><span class="line"> ---&gt; 4684ba457cc2</span><br><span class="line">Removing intermediate container 18c43d2d90fd</span><br><span class="line">Successfully built 4684ba457cc2</span><br></pre></td></tr></table></figure>

<p>下面运行docker run启动两个test:latest镜像的容器，第一条docker run命令没有指定参数，第二条docker run命令指定了参数arg3，其运行结果如下，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti --rm=<span class="literal">true</span> <span class="built_in">test</span></span><br><span class="line"><span class="keyword">in</span> startup, args: arg1 arg2</span><br><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti --rm=<span class="literal">true</span> <span class="built_in">test</span> arg3</span><br><span class="line"><span class="keyword">in</span> startup, args: arg1 arg3</span><br></pre></td></tr></table></figure>
<p>从上面第一个容器的运行结果可以看出CMD指令为ENTRYPOINT指令设置了默认参数；从第二个容器的运行结果看出，docker run命令指定的参数覆盖了CMD指令指定的参数。</p>
<h2 id="4-3注意点"><a href="#4-3注意点" class="headerlink" title="4.3注意点"></a>4.3注意点</h2><p>CMD指令为ENTRYPOINT指令提供默认参数是基于镜像层次结构生效的，而不是基于是否在同个Dockerfile文件中。意思就是说，如果Dockerfile指定基础镜像中是ENTRYPOINT指定的启动命令，则该Dockerfile中的CMD依然是为基础镜像中的ENTRYPOINT设置默认参数。</p>
<p>例如，我们有如下一个Dockerfile文件，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM ubuntu:14.04</span><br><span class="line">MAINTAINER lienhua34@xxx.com</span><br><span class="line"> </span><br><span class="line">ADD startup /opt</span><br><span class="line">RUN chmod a+x /opt/startup</span><br><span class="line"> </span><br><span class="line">ENTRYPOINT [<span class="string">"/opt/startup"</span>, <span class="string">"arg1"</span>]</span><br></pre></td></tr></table></figure>

<p>通过运行docker build命令生成test:0.0.1镜像，然后创建该镜像的一个容器，查看运行结果，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker build -t <span class="built_in">test</span>:0.0.1 .</span><br><span class="line">Sending build context to Docker daemon 6.144 kB</span><br><span class="line">Step 1 : FROM ubuntu:14.04</span><br><span class="line"> ---&gt; a5a467fddcb8</span><br><span class="line">Step 2 : MAINTAINER lienhua34@163.com</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 57a96522061a</span><br><span class="line"> ---&gt; c3bbf1bd8068</span><br><span class="line">Removing intermediate container 57a96522061a</span><br><span class="line">Step 3 : ADD startup /opt</span><br><span class="line"> ---&gt; f9884fbc7607</span><br><span class="line">Removing intermediate container 591a82b2f382</span><br><span class="line">Step 4 : RUN chmod a+x /opt/startup</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 7a19f10b5513</span><br><span class="line"> ---&gt; 16c03869a764</span><br><span class="line">Removing intermediate container 7a19f10b5513</span><br><span class="line">Step 5 : ENTRYPOINT /opt/startup arg1</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> b581c32b25c3</span><br><span class="line"> ---&gt; c6b1365afe03</span><br><span class="line">Removing intermediate container b581c32b25c3</span><br><span class="line">Successfully built c6b1365afe03</span><br><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti --rm=<span class="literal">true</span> <span class="built_in">test</span>:0.0.1</span><br><span class="line"><span class="keyword">in</span> startup, args: arg1</span><br></pre></td></tr></table></figure>

<p>下面新建一个Dockerfile文件，基础镜像是刚生成的test:0.0.1，通过CMD指定要通过echo打印字符串“in test:0.0.2”。文件内容如下所示，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM <span class="built_in">test</span>:0.0.1</span><br><span class="line">MAINTAINER lienhua34@xxx.com</span><br><span class="line"> </span><br><span class="line">CMD [<span class="string">"/bin/bash"</span>, <span class="string">"-c"</span>, <span class="string">"echo in test:0.0.2"</span>]</span><br></pre></td></tr></table></figure>

<p>运行docker build命令生成test:0.0.2镜像，然后通过运行docker run启动一个test:0.0.2镜像的容器来查看结果，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker build -t <span class="built_in">test</span>:0.0.2 .</span><br><span class="line">Sending build context to Docker daemon 6.144 kB</span><br><span class="line">Step 1 : FROM <span class="built_in">test</span>:0.0.1</span><br><span class="line"> ---&gt; c6b1365afe03</span><br><span class="line">Step 2 : MAINTAINER lienhua34@163.com</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> deca95cf4c15</span><br><span class="line"> ---&gt; 971b5a819b48</span><br><span class="line">Removing intermediate container deca95cf4c15</span><br><span class="line">Step 3 : CMD /bin/bash -c <span class="built_in">echo</span> <span class="keyword">in</span> <span class="built_in">test</span>:0.0.2</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 4a31c4652e1e</span><br><span class="line"> ---&gt; 0ca06ba31405</span><br><span class="line">Removing intermediate container 4a31c4652e1e</span><br><span class="line">Successfully built 0ca06ba31405</span><br><span class="line">lienhua34@<span class="built_in">test</span>$ sudo docker run -ti --rm=<span class="literal">true</span> <span class="built_in">test</span>:0.0.2</span><br><span class="line"><span class="keyword">in</span> startup, args: arg1 /bin/bash -c <span class="built_in">echo</span> <span class="keyword">in</span> <span class="built_in">test</span>:0.0.2</span><br></pre></td></tr></table></figure>
<p>从上面结果可以看到，镜像test:0.0.2启动的容器运行时并不是打印字符串”in test:0.0.2”，而是将CMD指令指定的命令当做基础镜像test:0.0.1中ENTRYPOINT指定的运行脚本startup的参数。</p>
]]></content>
      <categories>
        <category>云原生</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>docker-maven-plugin配置</title>
    <url>/docker/docker-maven-plugin%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="pom-xml-配置"><a href="#pom-xml-配置" class="headerlink" title="pom.xml 配置"></a>pom.xml 配置</h1><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">docker.maven.plugin.version</span>&gt;</span>1.2.0<span class="tag">&lt;/<span class="name">docker.maven.plugin.version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">docker.serverId</span>&gt;</span>nex-alan-release<span class="tag">&lt;/<span class="name">docker.serverId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">docker.baseImage</span>&gt;</span>openjdk:8-jre-alpine<span class="tag">&lt;/<span class="name">docker.baseImage</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">docker.volumes</span>&gt;</span>/tmp<span class="tag">&lt;/<span class="name">docker.volumes</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">docker.image.prefix</span>&gt;</span>dev.alan/kisee-clouds<span class="tag">&lt;/<span class="name">docker.image.prefix</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">docker.java.security.egd</span>&gt;</span>-Djava.security.egd=file:/dev/./urandom<span class="tag">&lt;/<span class="name">docker.java.security.egd</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">docker.java.opts</span>&gt;</span>-Xms256m -Xmx256m<span class="tag">&lt;/<span class="name">docker.java.opts</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">directory</span>&gt;</span>$&#123;basedir&#125;/target<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">finalName</span>&gt;</span>$&#123;project.artifactId&#125;-$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">finalName</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">resources</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">directory</span>&gt;</span>src/main/resources<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">filtering</span>&gt;</span>true<span class="tag">&lt;/<span class="name">filtering</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">exclude</span>&gt;</span>*.yml<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">directory</span>&gt;</span>src/main/resources<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">filtering</span>&gt;</span>true<span class="tag">&lt;/<span class="name">filtering</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">includes</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">include</span>&gt;</span>bootstrap.yml<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">include</span>&gt;</span>application-$&#123;profileActive&#125;.yml<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">includes</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">resources</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">pluginManagement</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;maven.compiler.plugin.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">source</span>&gt;</span>$&#123;maven.compiler.source&#125;<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">target</span>&gt;</span>$&#123;maven.compiler.target&#125;<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">annotationProcessorPaths</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">path</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mapstruct<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mapstruct-processor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;mapstruct.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">path</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;lombok.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">annotationProcessorPaths</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;maven-surefire-plugin.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">skipTests</span>&gt;</span>true<span class="tag">&lt;/<span class="name">skipTests</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">testFailureIgnore</span>&gt;</span>true<span class="tag">&lt;/<span class="name">testFailureIgnore</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.spotify<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>docker-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;docker.maven.plugin.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">serverId</span>&gt;</span>$&#123;docker.serverId&#125;<span class="tag">&lt;/<span class="name">serverId</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">pushImage</span>&gt;</span>true<span class="tag">&lt;/<span class="name">pushImage</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">imageName</span>&gt;</span>$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;:$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">imageName</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">imageTags</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">imageTag</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">imageTag</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">imageTag</span>&gt;</span>latest<span class="tag">&lt;/<span class="name">imageTag</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">imageTags</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">forceTags</span>&gt;</span>true<span class="tag">&lt;/<span class="name">forceTags</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">baseImage</span>&gt;</span>$&#123;docker.baseImage&#125;<span class="tag">&lt;/<span class="name">baseImage</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">volumes</span>&gt;</span>$&#123;docker.volumes&#125;<span class="tag">&lt;/<span class="name">volumes</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">env</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">JAVA_OPTS</span>&gt;</span>$&#123;docker.java.opts&#125;<span class="tag">&lt;/<span class="name">JAVA_OPTS</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">env</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">entryPoint</span>&gt;</span>["sh","-c","java $JAVA_OPTS -XX:+UseG1GC $&#123;docker.java.security.egd&#125; -jar /$&#123;project.build.finalName&#125;.jar"]<span class="tag">&lt;/<span class="name">entryPoint</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">resources</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">targetPath</span>&gt;</span>/<span class="tag">&lt;/<span class="name">targetPath</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">directory</span>&gt;</span>$&#123;project.build.directory&#125;<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">include</span>&gt;</span>$&#123;project.build.finalName&#125;.jar<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">resources</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">pluginManagement</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><div class="note primary">
            <ul><li><p>serverId : nex-alan-release<br>在maven的配置文件settings.xml中配置用户名和密码：</p><server>  <!--这是server的id（注意不是用户登陆的id），该id与distributionManagement中repository元素的id相匹配。 -->  <id>nex-alan-release</id>  <username>admin</username>  <password>admin</password></server></li><li><p>imageName</p></li></ul><p><imageName>${docker.image.prefix}/${project.artifactId}:${project.version}</imageName><br>需要加 标签, 不然-DpushImage 会报错,找不到镜像</p>
          </div>
]]></content>
      <categories>
        <category>云原生</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Overlay详解</title>
    <url>/docker/docker-overlay%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="Overlay-Network"><a href="#Overlay-Network" class="headerlink" title="Overlay Network"></a><strong>Overlay Network</strong></h2><ul>
<li><strong>Overlay Network：属于Docker网络驱动，基于VXLAN封装实现Docker原生Overlay网络。</strong></li>
<li><strong>Overlay Network：覆盖网络，在基础网络上叠加的一种虚拟网络技术模式，该网络中的主机通过虚拟链路连接起来。</strong></li>
<li><strong>Overlay Network：Overlay网络有三种协议实现方式分别为，VXLAN、NVGRE、STT。</strong></li>
</ul>
<h2 id="VXLAN：VXLAN（Virtual-Extensible-Local-Area-Network，虚拟可扩展局域网），通过将物理服务器或虚拟机发出的数据包封装到UDP中，并使用物理网络的IP-MAC作为外层报文头进行封装，然后在IP网络上传输，到达目的地后由隧道端点解封装并将数据发送给目标物理服务器或虚拟机，扩展了大规模虚拟机网络通信。由于VLAN-Header头部限制长度是12bit，导致只能分配4095个VLAN，也就是4095个网段，在大规模虚拟网络。VXLAN标准定义Header限制长度24bit，可以支持1600万个VLAN，满足大规模虚拟机网络需求。"><a href="#VXLAN：VXLAN（Virtual-Extensible-Local-Area-Network，虚拟可扩展局域网），通过将物理服务器或虚拟机发出的数据包封装到UDP中，并使用物理网络的IP-MAC作为外层报文头进行封装，然后在IP网络上传输，到达目的地后由隧道端点解封装并将数据发送给目标物理服务器或虚拟机，扩展了大规模虚拟机网络通信。由于VLAN-Header头部限制长度是12bit，导致只能分配4095个VLAN，也就是4095个网段，在大规模虚拟网络。VXLAN标准定义Header限制长度24bit，可以支持1600万个VLAN，满足大规模虚拟机网络需求。" class="headerlink" title="VXLAN：VXLAN（Virtual Extensible Local Area Network，虚拟可扩展局域网），通过将物理服务器或虚拟机发出的数据包封装到UDP中，并使用物理网络的IP/MAC作为外层报文头进行封装，然后在IP网络上传输，到达目的地后由隧道端点解封装并将数据发送给目标物理服务器或虚拟机，扩展了大规模虚拟机网络通信。由于VLAN Header头部限制长度是12bit，导致只能分配4095个VLAN，也就是4095个网段，在大规模虚拟网络。VXLAN标准定义Header限制长度24bit，可以支持1600万个VLAN，满足大规模虚拟机网络需求。"></a><strong>VXLAN：</strong>VXLAN（Virtual Extensible Local Area Network，虚拟可扩展局域网），通过将物理服务器或虚拟机发出的数据包封装到UDP中，并使用物理网络的IP/MAC作为外层报文头进行封装，然后在IP网络上传输，到达目的地后由隧道端点解封装并将数据发送给目标物理服务器或虚拟机，扩展了大规模虚拟机网络通信。由于VLAN Header头部限制长度是12bit，导致只能分配4095个VLAN，也就是4095个网段，在大规模虚拟网络。VXLAN标准定义Header限制长度24bit，可以支持1600万个VLAN，满足大规模虚拟机网络需求。</h2><h3 id="VXLAN有以下核心技术组成："><a href="#VXLAN有以下核心技术组成：" class="headerlink" title="VXLAN有以下核心技术组成："></a><strong>VXLAN有以下核心技术组成：</strong></h3><ul>
<li><p><strong>NVE</strong>（Network Vritual Endpoint，网络虚拟端点）：实现网络虚拟化功能。报文经过NVE封装转换后，NVE间就可基于三层基础网络建立二层虚拟化网络。</p>
</li>
<li><p><strong>VTEP</strong>（VXLAN Tunnel Endpoints，VXLAN隧道端点）：封装在NVE中，用于VXLAN报文的封装和解封装。</p>
</li>
<li><p><strong>VNI</strong>（VXLAN Network Identifier，VXLAN网络标识ID）：类似于VLAN ID，用于区分VXLAN段，不同的VXLAN段不能直接二层网络通信。</p>
<img data-src="https://img2018.cnblogs.com/blog/1183448/201811/1183448-20181102193351308-897002545.png" alt="" />

</li>
</ul>
<p><strong>讲解：</strong></p>
<ul>
<li><strong>1、左右两边分别为容器节点1与容器节点2。</strong></li>
<li><strong>2、当容器节点1发出一个报文时会通过VTEP将这个数据包进行封装，封装完成之后再由ech0转发到对应的主机中。</strong></li>
<li><strong>3、通过UDP协议在VXLAN Tunnel隧道中传输。</strong></li>
<li><strong>4、对应的主机也通过eth0收到数据包，通过VTEP将收到的数据包进行解封装，从里面取出对应的mac地址等信息发送到对应的容器中。</strong></li>
</ul>
<h2 id="NVGRE-（Network-Virtual-using-Generic-Routing-Encapsulation，使用GRE虚拟网络）：与VXLAN不同的是，NVGRE没有采用标准传输协议（TCP-UDP），而是借助通用路由封装协议（GRE）。采用24bit标识二层网络分段，与VXLAN一样可以支持1600万个虚拟网络。"><a href="#NVGRE-（Network-Virtual-using-Generic-Routing-Encapsulation，使用GRE虚拟网络）：与VXLAN不同的是，NVGRE没有采用标准传输协议（TCP-UDP），而是借助通用路由封装协议（GRE）。采用24bit标识二层网络分段，与VXLAN一样可以支持1600万个虚拟网络。" class="headerlink" title="NVGRE**（Network Virtual using Generic Routing Encapsulation，使用GRE虚拟网络）：与VXLAN不同的是，NVGRE没有采用标准传输协议（TCP/UDP），而是借助通用路由封装协议（GRE）。采用24bit标识二层网络分段，与VXLAN一样可以支持1600万个虚拟网络。**"></a><strong>NVGRE**</strong>（Network Virtual using Generic Routing Encapsulation，使用GRE虚拟网络）：与VXLAN不同的是，NVGRE没有采用标准传输协议（TCP/UDP），而是借助通用路由封装协议（GRE）。采用24bit标识二层网络分段，与VXLAN一样可以支持1600万个虚拟网络。**</h2><h2 id="STT-（Stateless-Transport-Tunneling，无状态传输隧道）：模拟TCP数据格式进行封装，改造了TCP传输机制，不维护TCP状态信息。"><a href="#STT-（Stateless-Transport-Tunneling，无状态传输隧道）：模拟TCP数据格式进行封装，改造了TCP传输机制，不维护TCP状态信息。" class="headerlink" title="STT**（Stateless Transport Tunneling，无状态传输隧道）：模拟TCP数据格式进行封装，改造了TCP传输机制，不维护TCP状态信息。**"></a><strong>STT**</strong>（Stateless Transport Tunneling，无状态传输隧道）：模拟TCP数据格式进行封装，改造了TCP传输机制，不维护TCP状态信息。**</h2>]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker汇总</title>
    <url>/docker/docker-summary/</url>
    <content><![CDATA[<ul>
<li><a href="https://mp.weixin.qq.com/s/bNmpqDsX1RTaiBHi0FIk0Q" target="_blank" rel="noopener">简述 Docker</a></li>
<li><a href="https://mp.weixin.qq.com/s/mNge9HfAjeiP12Z8IikP2g" target="_blank" rel="noopener">Docker入门教程</a></li>
</ul>
<a id="more"></a>
<p>/etc/docker/daemon.json</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="attr">"log-driver"</span>:<span class="string">"json-file"</span>,</span><br><span class="line">  <span class="attr">"log-opts"</span>: &#123;<span class="attr">"max-size"</span>:<span class="string">"100m"</span>, <span class="attr">"max-file"</span>:<span class="string">"3"</span>&#125;,</span><br><span class="line">  <span class="attr">"registry-mirrors"</span>: [</span><br><span class="line">        <span class="string">"https://zckzdbvq.mirror.aliyuncs.com"</span>, </span><br><span class="line">        <span class="string">"https://116.62.81.173"</span>, </span><br><span class="line">        <span class="string">"http://hub-mirror.c.163.com"</span>,</span><br><span class="line">        <span class="string">"https://docker.mirrors.ustc.edu.cn"</span>,</span><br><span class="line">        <span class="string">"http://192.168.1.200:2000"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"insecure-registries"</span>: [<span class="string">"139.159.220.178:8088"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="添加静态路由联通不同主机docker"><a href="#添加静态路由联通不同主机docker" class="headerlink" title="添加静态路由联通不同主机docker"></a>添加静态路由联通不同主机docker</h1><p>在/etc/rc.local 加</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">route add -net 172.18.1.0/24 dev eth0</span><br><span class="line"></span><br><span class="line">route -n <span class="comment"># 查看路由</span></span><br><span class="line"><span class="comment"># 开启内核ipv4转发功能</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"net.ipv4.ip_forward = 1"</span> &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure>
<h1 id="清理docker空间"><a href="#清理docker空间" class="headerlink" title="清理docker空间"></a>清理docker空间</h1><p>docker system prune -a</p>
<h1 id="删除所有没有用的镜像，而不仅仅是临时文件；"><a href="#删除所有没有用的镜像，而不仅仅是临时文件；" class="headerlink" title="删除所有没有用的镜像，而不仅仅是临时文件；"></a>删除所有没有用的镜像，而不仅仅是临时文件；</h1><p>docker image prune -a </p>
<h1 id="限制docker-日志大小"><a href="#限制docker-日志大小" class="headerlink" title="限制docker 日志大小"></a>限制docker 日志大小</h1><p>{<br>  “log-driver”:”json-file”,<br>  “log-opts”: {“max-size”:”100m”, “max-file”:”1”}<br>}</p>
<h1 id="无法用docker-rmi-删除的镜像，可以直接删除文件"><a href="#无法用docker-rmi-删除的镜像，可以直接删除文件" class="headerlink" title="无法用docker rmi 删除的镜像，可以直接删除文件"></a>无法用docker rmi 删除的镜像，可以直接删除文件</h1><p>cd /var/lib/docker/image/overlay2/imagedb/content/sha256<br>for i in <code>docker images|grep /test/|awk &#39;{print $3}&#39;</code>;do rm -rf $i* ;done</p>
<h1 id="docker-build-报错"><a href="#docker-build-报错" class="headerlink" title="docker build 报错"></a>docker build 报错</h1><p>unable to find image “sha256:823e1ed7982d5426dcc257ef43ba7e10b7758d6275d85ce645899f4f55b073b7”<br>加 –no-cache 参数<br>docker build -t docker.io/share/test/insurance-center:latest . –no-cache</p>
<h1 id="Docker-Swarm"><a href="#Docker-Swarm" class="headerlink" title="Docker Swarm"></a>Docker Swarm</h1><h2 id="创建Swarm集群"><a href="#创建Swarm集群" class="headerlink" title="创建Swarm集群"></a>创建Swarm集群</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 在manager1机器上创建docker swarm集群</span></span><br><span class="line">docker swarm init ‐‐advertise‐addr 192.168.1.200</span><br><span class="line"><span class="comment"># docker swarm join-token manager 查看token</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 向docker swarm中添加工作节点：在两个工作节点中分别执行如下命令，ip地址是manager节点的</span></span><br><span class="line">docker swarm join ‐‐token xxx 192.168.1.200:2377  （worker1）</span><br><span class="line">docker swarm join ‐‐token xxx 192.168.1.200:2377  （worker2）</span><br><span class="line"><span class="comment"># 3. 查看管理节点集群信息：</span></span><br><span class="line">docker node ls</span><br><span class="line"><span class="comment"># 4. 删除node,退出集群 </span></span><br><span class="line">docker swarm leave --force(节点上)</span><br><span class="line">docker node rm id --force（manager上）</span><br><span class="line"><span class="comment"># 5. 节点加标签</span></span><br><span class="line"><span class="comment"># docker node update --label-add role=标签名称  主机名</span></span><br><span class="line">docker node update --label-add role=db  docker1</span><br><span class="line"><span class="comment">#删除标签</span></span><br><span class="line">docker node update --label-rm role manager-node </span><br><span class="line"><span class="comment"># 6. 查看节点详情</span></span><br><span class="line">docker node inspect hostname</span><br></pre></td></tr></table></figure>

<h2 id="在docker-swarm中部署服务（管理节点运行）"><a href="#在docker-swarm中部署服务（管理节点运行）" class="headerlink" title="在docker swarm中部署服务（管理节点运行）"></a>在docker swarm中部署服务（管理节点运行）</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. service命令创建服务</span></span><br><span class="line">$ docker service create --replicas 1 --name nginx1 nginx(imagename) --network=goldeye</span><br><span class="line"></span><br><span class="line"><span class="comment"># docker service create指令：用于在Swarm集群中创建一个基于alpine镜像的服务</span></span><br><span class="line"><span class="comment"># 	‐‐replicas参数：指定了该服务只有一个副本实例</span></span><br><span class="line"><span class="comment"># 	‐‐name参数：指定创建成功后的服务名称为helloworld</span></span><br><span class="line"><span class="comment"># 	ping docker.com指令：表示服务启动后执行的命令</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 查看docker swarm集群中的服务</span></span><br><span class="line">查看服务列表：docker service ls</span><br><span class="line">查看部署具体服务的详细信息：docker service inspect 服务名称</span><br><span class="line">查看服务在集群节点上的分配以及运行情况：docker service ps --no-trunc 服务名称</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 修改副本数量</span></span><br><span class="line">在manager1上，更改服务副本的数量（创建的副本会随机分配到不同的节点）</span><br><span class="line">docker service scale helloworld=5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 删除服务（在管理节点）</span></span><br><span class="line">docker service rm 服务名称</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 在集群管理节点manager1上部署一个nginx服务</span></span><br><span class="line">docker service create \</span><br><span class="line">  ‐‐network my‐multi‐host‐network \</span><br><span class="line">  ‐‐name my‐web \</span><br><span class="line">  ‐p 8080:80 \</span><br><span class="line">  ‐‐replicas 2 \</span><br><span class="line">  nginx</span><br></pre></td></tr></table></figure>
<h2 id="使用compose部署docker-swarm-服务"><a href="#使用compose部署docker-swarm-服务" class="headerlink" title="使用compose部署docker swarm 服务"></a>使用compose部署docker swarm 服务</h2><ol>
<li><p>部署服务<br><code># docker stack deploy -c docker-compose.yml stackname</code></p>
</li>
<li><p>查看服务<br><code># docker stack ls</code></p>
</li>
<li><p>移除服务<br><code># docker stack down stackname</code></p>
</li>
<li><p>docker-compose.yml 文件示例</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3.3"</span></span><br><span class="line"> </span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">visualizer:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">dockersamples/visualizer:stable</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"8080:8080"</span></span><br><span class="line">    <span class="attr">stop_grace_period:</span> <span class="string">1m30s</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"/var/run/docker.sock:/var/run/docker.sock"</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">alan</span></span><br><span class="line">    <span class="attr">deploy:</span> <span class="comment"># deploy参数是Docker Compose针对Swarm集群部署提供的，子参数专门用于指定与服务部署和运行相关的配置</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">replicated</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">restart_policy:</span></span><br><span class="line">        <span class="attr">condition:</span> <span class="string">on-failure</span></span><br><span class="line">        <span class="attr">max_attempts:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">placement:</span></span><br><span class="line">        <span class="attr">constraints:</span>  </span><br><span class="line">          <span class="bullet">-</span> <span class="string">node.role</span> <span class="string">==</span> <span class="string">manager</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">node.hostname</span> <span class="string">==</span> <span class="string">docker1</span> </span><br><span class="line">          <span class="bullet">-</span> <span class="string">node.labels.role</span> <span class="string">==</span> <span class="string">db</span></span><br><span class="line">      <span class="attr">update_config:</span></span><br><span class="line">        <span class="attr">delay:</span> <span class="string">5s</span></span><br><span class="line">        <span class="attr">order:</span> <span class="string">start-first</span> <span class="comment"># 默认为 stop-first，推荐设置先启动新服务再终止旧的</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">limits:</span></span><br><span class="line">          <span class="attr">cpus:</span> <span class="string">"0.50"</span></span><br><span class="line">          <span class="attr">memory:</span> <span class="string">1g</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">alan:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
]]></content>
      <categories>
        <category>云原生</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker三剑客之Docker Swarm</title>
    <url>/docker/docker%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bswarm/</url>
    <content><![CDATA[<h1 id="一、什么是Docker-Swarm"><a href="#一、什么是Docker-Swarm" class="headerlink" title="一、什么是Docker Swarm"></a>一、什么是Docker Swarm</h1><p>　　Swarm是Docker公司推出的用来管理docker集群的平台，几乎全部用GO语言来完成的开发的，代码开源在<a href="https://github.com/docker/swarm，" target="_blank" rel="noopener">https://github.com/docker/swarm，</a> 它是将一群Docker宿主机变成一个单一的虚拟主机，Swarm使用标准的Docker API接口作为其前端的访问入口，换言之，各种形式的Docker</p>
<p>  Client(compose,docker-py等)均可以直接与Swarm通信，甚至Docker本身都可以很容易的与Swarm集成，这大大方便了用户将原本基于单节点的系统移植到Swarm上，同时Swarm内置了对Docker网络插件的支持，用户也很容易的部署跨主机的容器集群服务。</p>
<p>　　Docker Swarm 和 Docker Compose 一样，都是 Docker 官方容器编排项目，但不同的是，Docker Compose 是一个在单个服务器或主机上创建多个容器的工具，而 Docker Swarm 则可以在多个服务器或主机上创建容器集群服务，对于微服务的部署，显然 Docker Swarm 会更加适合。</p>
<p>从 Docker 1.12.0 版本开始，Docker Swarm 已经包含在 Docker 引擎中（docker swarm），并且已经内置了服务发现工具，我们就不需要像之前一样，再配置 Etcd 或者 Consul 来进行服务发现配置了。</p>
<p>　　Swarm deamon只是一个调度器(Scheduler)加路由器(router),Swarm自己不运行容器，它只是接受Docker客户端发来的请求，调度适合的节点来运行容器，这就意味着，即使Swarm由于某些原因挂掉了，集群中的节点也会照常运行，放Swarm重新恢复运行之后，他会收集重建集群信息。</p>
<h1 id="二、Docker-Swarm-基本结构图"><a href="#二、Docker-Swarm-基本结构图" class="headerlink" title="二、Docker Swarm 基本结构图"></a>二、Docker Swarm 基本结构图</h1><p>在结构图可以看出 Docker Client使用Swarm对 集群(Cluster)进行调度使用。</p>
<p>上图可以看出，Swarm是典型的master-slave结构，通过发现服务来选举manager。manager是中心管理节点，各个node上运行agent接受manager的统一管理，集群会自动通过Raft协议分布式选举出manager节点，无需额外的发现服务支持，避免了单点的瓶颈问题，同时也内置了DNS的负载均衡和对外部负载均衡机制的集成支持</p>
<h1 id="三-Swarm的几个关键概念"><a href="#三-Swarm的几个关键概念" class="headerlink" title="三.Swarm的几个关键概念"></a>三.Swarm的几个关键概念</h1><ol>
<li><p>Swarm<br>集群的管理和编排是使用嵌入docker引擎的SwarmKit，可以在docker初始化时启动swarm模式或者加入已存在的swarm</p>
</li>
<li><p>Node<br>一个节点是docker引擎集群的一个实例。您还可以将其视为Docker节点。您可以在单个物理计算机或云服务器上运行一个或多个节点，但生产群集部署通常包括分布在多个物理和云计算机上的Docker节点。</p>
</li>
</ol>
<p>要将应用程序部署到swarm，请将服务定义提交给 管理器节点。管理器节点将称为任务的工作单元分派 给工作节点。</p>
<p>Manager节点还执行维护所需群集状态所需的编排和集群管理功能。Manager节点选择单个领导者来执行编排任务。</p>
<p>工作节点接收并执行从管理器节点分派的任务。默认情况下，管理器节点还将服务作为工作节点运行，但您可以将它们配置为仅运行管理器任务并且是仅管理器节点。代理程序在每个工作程序节点上运行，并报告分配给它的任务。工作节点向管理器节点通知其分配的任务的当前状态，以便管理器可以维持每个工作者的期望状态。</p>
<ol start="3">
<li><p>Service<br>一个服务是任务的定义，管理机或工作节点上执行。它是群体系统的中心结构，是用户与群体交互的主要根源。创建服务时，你需要指定要使用的容器镜像。</p>
</li>
<li><p>Task<br>任务是在docekr容器中执行的命令，Manager节点根据指定数量的任务副本分配任务给worker节点</p>
</li>
</ol>
<p>——————————————使用方法————————————-<br>docker swarm：集群管理，子命令有init, join, leave, update。（docker swarm –help查看帮助）<br>docker service：服务创建，子命令有create, inspect, update, remove, tasks。（docker service–help查看帮助）<br>docker node：节点管理，子命令有accept, promote, demote, inspect, update, tasks, ls, rm。（docker node –help查看帮助）</p>
<p>node是加入到swarm集群中的一个docker引擎实体，可以在一台物理机上运行多个node，node分为：<br>manager nodes，也就是管理节点<br>worker nodes，也就是工作节点</p>
<ul>
<li>1）manager node管理节点：执行集群的管理功能，维护集群的状态，选举一个leader节点去执行调度任务。</li>
<li>2）worker node工作节点：接收和执行任务。参与容器集群负载调度，仅用于承载task。</li>
<li>3）service服务：一个服务是工作节点上执行任务的定义。创建一个服务，指定了容器所使用的镜像和容器运行的命令。<br> service是运行在worker nodes上的task的描述，service的描述包括使用哪个docker 镜像，以及在使用该镜像的容器中执行什么命令。</li>
<li>4）task任务：一个任务包含了一个容器及其运行的命令。task是service的执行实体，task启动docker容器并在容器中执行任务。</li>
</ul>
<h1 id="四、Swarm的工作模式"><a href="#四、Swarm的工作模式" class="headerlink" title="四、Swarm的工作模式"></a>四、Swarm的工作模式</h1><ol>
<li>Node</li>
<li>Service</li>
<li>任务与调度</li>
<li>服务副本与全局服务</li>
</ol>
<h1 id="五、Swarm的调度策略"><a href="#五、Swarm的调度策略" class="headerlink" title="五、Swarm的调度策略"></a>五、Swarm的调度策略</h1><p>Swarm在调度(scheduler)节点（leader节点）运行容器的时候，会根据指定的策略来计算最适合运行容器的节点，目前支持的策略有：spread, binpack, random.</p>
<ul>
<li><p>1）Random<br>顾名思义，就是随机选择一个Node来运行容器，一般用作调试用，spread和binpack策略会根据各个节点的可用的CPU, RAM以及正在运<br>行的容器的数量来计算应该运行容器的节点。</p>
</li>
<li><p>2）Spread<br>在同等条件下，Spread策略会选择运行容器最少的那台节点来运行新的容器，binpack策略会选择运行容器最集中的那台机器来运行新的节点。<br>使用Spread策略会使得容器会均衡的分布在集群中的各个节点上运行，一旦一个节点挂掉了只会损失少部分的容器。</p>
</li>
<li><p>3）Binpack<br>Binpack策略最大化的避免容器碎片化，就是说binpack策略尽可能的把还未使用的节点留给需要更大空间的容器运行，尽可能的把容器运行在<br>一个节点上面。</p>
</li>
</ul>
<h1 id="六、Swarm-Cluster模式特性"><a href="#六、Swarm-Cluster模式特性" class="headerlink" title="六、Swarm Cluster模式特性"></a>六、Swarm Cluster模式特性</h1><ul>
<li><p>1）批量创建服务<br>建立容器之前先创建一个overlay的网络，用来保证在不同主机上的容器网络互通的网络模式</p>
</li>
<li><p>2）强大的集群的容错性<br>当容器副本中的其中某一个或某几个节点宕机后，cluster会根据自己的服务注册发现机制，以及之前设定的值–replicas n，<br>在集群中剩余的空闲节点上，重新拉起容器副本。整个副本迁移的过程无需人工干预，迁移后原本的集群的load balance依旧好使！<br>不难看出，docker service其实不仅仅是批量启动服务这么简单，而是在集群中定义了一种状态。Cluster会持续检测服务的健康状态<br>并维护集群的高可用性。</p>
</li>
<li><p>3）服务节点的可扩展性<br>Swarm Cluster不光只是提供了优秀的高可用性，同时也提供了节点弹性扩展或缩减的功能。当容器组想动态扩展时，只需通过scale<br>参数即可复制出新的副本出来。</p>
</li>
</ul>
<p>仔细观察的话，可以发现所有扩展出来的容器副本都run在原先的节点下面，如果有需求想在每台节点上都run一个相同的副本，方法<br>其实很简单，只需要在命令中将”–replicas n”更换成”–mode=global”即可！</p>
<p>复制服务（–replicas n）<br>将一系列复制任务分发至各节点当中，具体取决于您所需要的设置状态，例如“–replicas 3”。</p>
<p>全局服务（–mode=global）<br>适用于集群内全部可用节点上的服务任务，例如“–mode global”。如果大家在 Swarm 集群中设有 7 台 Docker 节点，则全部节点之上都将存在对应容器。</p>
<ol start="4">
<li>调度机制<br>所谓的调度其主要功能是cluster的server端去选择在哪个服务器节点上创建并启动一个容器实例的动作。它是由一个装箱算法和过滤器<br>组合而成。每次通过过滤器（constraint）启动容器的时候，swarm cluster 都会调用调度机制筛选出匹配约束条件的服务器，并在这上面运行容器。</li>
</ol>
<p>——————Swarm cluster的创建过程包含以下三个步骤———————-</p>
<ul>
<li>1）发现Docker集群中的各个节点，收集节点状态、角色信息，并监视节点状态的变化</li>
<li>2）初始化内部调度（scheduler）模块</li>
<li>3）创建并启动API监听服务模块</li>
</ul>
<p>一旦创建好这个cluster，就可以用命令docker service批量对集群内的容器进行操作，非常方便！</p>
<p>在启动容器后，docker 会根据当前每个swarm节点的负载判断，在负载最优的节点运行这个task任务，用”docker service ls” 和”docker service ps + taskID”<br>可以看到任务运行在哪个节点上。容器启动后，有时需要等待一段时间才能完成容器创建。</p>
<h1 id="七、Dcoker-Swarm-集群部署"><a href="#七、Dcoker-Swarm-集群部署" class="headerlink" title="七、Dcoker Swarm 集群部署"></a>七、Dcoker Swarm 集群部署</h1><p>温馨提示：</p>
<p>机器环境(三台机器，centos系统)</p>
<p>IP：192.168.31.43 主机名：manager43 担任角色：swarm manager</p>
<p>IP：192.168.31.188 主机名：node188 担任角色：swarm node</p>
<p>IP：192.168.31.139 主机名：node139 担任角色：swarm node</p>
<h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul>
<li>1) 修改主机名<h1 id="192-168-31-43-主机上执行"><a href="#192-168-31-43-主机上执行" class="headerlink" title="192.168.31.43  主机上执行"></a>192.168.31.43  主机上执行</h1>[root@manager43 ~]# hostnamectl set-hostname manager43</li>
</ul>
<h1 id="192-168-31-188-主机上执行"><a href="#192-168-31-188-主机上执行" class="headerlink" title="192.168.31.188 主机上执行"></a>192.168.31.188 主机上执行</h1><p>[root@node188 ~]# hostnamectl set-hostname node188</p>
<h1 id="192-168-31-139-主机上执行"><a href="#192-168-31-139-主机上执行" class="headerlink" title="192.168.31.139 主机上执行"></a>192.168.31.139 主机上执行</h1><p>[root@node139 ~]# hostnamectl set-hostname node139</p>
<ul>
<li>2)配置hosts文件(可配置可不配置)<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># cat /etc/hosts</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"> </span><br><span class="line">192.168.31.43 manager43</span><br><span class="line">192.168.31.188 node188</span><br><span class="line">192.168.31.139 node139</span><br></pre></td></tr></table></figure>
<h1 id="使用scp复制到node主机"><a href="#使用scp复制到node主机" class="headerlink" title="使用scp复制到node主机"></a>使用scp复制到node主机</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># scp /etc/hosts root@192.168.31.188:/etc/hosts</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># scp /etc/hosts root@192.168.31.139:/etc/hosts</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>3) 设置防火墙<br>关闭三台机器上的防火墙。如果开启防火墙，则需要在所有节点的防火墙上依次放行2377/tcp（管理端口）、7946/udp（节点间通信端口）、4789/udp（overlay 网络端口）端口。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># systemctl disable firewalld.service</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># systemctl stop firewalld.service</span></span><br></pre></td></tr></table></figure>

<p>4) 安装docker并配置加速器(在三台主机都要安装哟…)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># yum -y install docker</span></span><br><span class="line">[root@node188 ~]<span class="comment"># yum -y install docker</span></span><br><span class="line">[root@node139 ~]<span class="comment"># yum -y install docker</span></span><br></pre></td></tr></table></figure>
<p>也可以安装最新版docker，可查考：docker安装教程</p>
<p>加速器配置，可查考:docker加速器配置教程</p>
<h2 id="2、创建Swarm并添加节点"><a href="#2、创建Swarm并添加节点" class="headerlink" title="2、创建Swarm并添加节点"></a>2、创建Swarm并添加节点</h2><p>1) 创建Swarm集群</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker swarm init --advertise-addr 192.168.31.43</span></span><br><span class="line">Swarm initialized: current node (z2n633mty5py7u9wyl423qnq0) is now a manager.</span><br><span class="line"> </span><br><span class="line">To add a worker to this swarm, run the following <span class="built_in">command</span>:</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 这就是添加节点的方式(要保存初始化后token，因为在节点加入时要使用token作为通讯的密钥)</span></span><br><span class="line">    docker swarm join --token SWMTKN-1-2lefzq18zohy9yr1vskutf1sfb2a590xz9d0mjj2m15zu9eprw-2938j5f50t35ycut0vbj2sx0s 192.168.31.43:2377  </span><br><span class="line"> </span><br><span class="line">To add a manager to this swarm, run <span class="string">'docker swarm join-token manager'</span> and follow the instructions.</span><br></pre></td></tr></table></figure>

<p>上面命令执行后，该机器自动加入到swarm集群。这个会创建一个集群token，获取全球唯一的 token，作为集群唯一标识。后续将其他节点加入集群都会用到这个token值。<br>其中，–advertise-addr参数表示其它swarm中的worker节点使用此ip地址与manager联系。命令的输出包含了其它节点如何加入集群的命令。</p>
<p>这里无意中遇到了一个小小的问题：</p>
<h1 id="在次执行上面的命令，回报下面的错误"><a href="#在次执行上面的命令，回报下面的错误" class="headerlink" title="在次执行上面的命令，回报下面的错误"></a>在次执行上面的命令，回报下面的错误</h1><p>[root@manager43 ~]# docker swarm init –advertise-addr 192.168.31.43<br>Error response from daemon: This node is already part of a swarm. Use “docker swarm leave” to leave this swarm and join another one.</p>
<h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p><code>[root@manager43 ~]# docker swarm leave -f</code><br>这里的leave就是在集群中删除节点，-f参数强制删除，执行完在重新执行OK</p>
<p>2) 查看集群的相关信息<br><code>[root@manager43 ~]# docker info</code><br>上面的命令执行后 找到Swarm的关键字，就可以看到相关信息了</p>
<p>[root@manager43 ~]# docker node ls<br>ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION<br>3jcmnzjh0e99ipgshk1ykuovd *   manager43           Ready               Active              Leader              18.06.0-ce<br>上面的命令是查看集群中的机器(注意上面node ID旁边那个*号表示现在连接到这个节点上)</p>
<p>3) 添加节点主机到Swarm集群<br>上面我们在创建Swarm集群的时候就已经给出了添加节点的方法</p>
<h1 id="192-168-31-188-主机上执行-1"><a href="#192-168-31-188-主机上执行-1" class="headerlink" title="192.168.31.188 主机上执行"></a>192.168.31.188 主机上执行</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node188 ~]<span class="comment"># docker swarm join --token SWMTKN-1-2lefzq18zohy9yr1vskutf1sfb2a590xz9d0mjj2m15zu9eprw-2938j5f50t35ycut0vbj2sx0s 192.168.31.43:2377</span></span><br><span class="line">This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure>

<h1 id="192-168-31-139-主机上执行-1"><a href="#192-168-31-139-主机上执行-1" class="headerlink" title="192.168.31.139 主机上执行"></a>192.168.31.139 主机上执行</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node139 ~]<span class="comment"># docker swarm join --token SWMTKN-1-2lefzq18zohy9yr1vskutf1sfb2a590xz9d0mjj2m15zu9eprw-2938j5f50t35ycut0vbj2sx0s 192.168.31.43:2377</span></span><br><span class="line">This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure>

<p>如果想要将其他更多的节点添加到这个swarm集群中，添加方法如上一致</p>
<p>在manager43主机上我们可以看一下集群中的机器及状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker node ls</span></span><br><span class="line">ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class="line">3jcmnzjh0e99ipgshk1ykuovd *   manager43           Ready               Active              Leader              18.06.0-ce</span><br><span class="line">vww7ue2xprzg46bjx7afo4h04     node139             Ready               Active                                  18.06.1-ce</span><br><span class="line">c5klw5ns4adcvumzgiv66xpyj     node188             Ready               Active                                  18.06.1-ce</span><br></pre></td></tr></table></figure>
<hr>
<p>温馨提示：更改节点的availablity状态</p>
<ul>
<li>swarm集群中node的availability状态可以为 active或者drain，其中：</li>
<li>active状态下，node可以接受来自manager节点的任务分派；</li>
<li>drain状态下，node节点会结束task，且不再接受来自manager节点的任务分派（也就是下线节点）<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker node update --availability drain node139               # 将node139节点下线。如果要删除node139节点，命令是"docker node rm --force node139"</span></span><br><span class="line">node139</span><br><span class="line">[root@manager43 ~]<span class="comment"># docker node ls</span></span><br><span class="line">ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class="line">3jcmnzjh0e99ipgshk1ykuovd *   manager43           Ready               Active              Leader              18.06.0-ce</span><br><span class="line">vww7ue2xprzg46bjx7afo4h04     node139             Ready               Drain                                   18.06.1-ce</span><br><span class="line">c5klw5ns4adcvumzgiv66xpyj     node188             Ready               Active                                  18.06.1-ce</span><br></pre></td></tr></table></figure>
如上，当node1的状态改为drain后，那么该节点就不会接受task任务分发，就算之前已经接受的任务也会转移到别的节点上。<br>再次修改为active状态（及将下线的节点再次上线）<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker node update --availability active node139</span></span><br><span class="line">node139</span><br><span class="line">[root@manager43 ~]<span class="comment"># docker node ls</span></span><br><span class="line">ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class="line">3jcmnzjh0e99ipgshk1ykuovd *   manager43           Ready               Active              Leader              18.06.0-ce</span><br><span class="line">vww7ue2xprzg46bjx7afo4h04     node139             Ready               Active                                  18.06.1-ce</span><br><span class="line">c5klw5ns4adcvumzgiv66xpyj     node188             Ready               Active                                  18.06.1-ce</span><br></pre></td></tr></table></figure>
<h2 id="3、在Swarm中部署服务-nginx为例"><a href="#3、在Swarm中部署服务-nginx为例" class="headerlink" title="3、在Swarm中部署服务(nginx为例)"></a>3、在Swarm中部署服务(nginx为例)</h2></li>
</ul>
<p>Docker 1.12版本提供服务的Scaling、health check、滚动升级等功能，并提供了内置的dns、vip机制，实现service的服务发现和负载均衡能力</p>
<p>1) 创建网络在部署服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建网络</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># docker network create -d overlay nginx_net</span></span><br><span class="line">a52jy33asc5o0ts0rq823bf0m</span><br><span class="line">[root@manager43 ~]<span class="comment"># docker network ls | grep nginx_net</span></span><br><span class="line">a52jy33asc5o        nginx_net           overlay             swarm</span><br><span class="line"><span class="comment"># 部署服务</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># docker service create --replicas 1 --network nginx_net --name my_nginx -p 80:80 nginx    # 就创建了一个具有一个副本（--replicas 1 ）的nginx服务，使用镜像nginx</span></span><br><span class="line">olexfmtdf94sxyeetkchwhehg</span><br><span class="line">overall progress: 1 out of 1 tasks</span><br><span class="line">1/1: running   [==================================================&gt;]</span><br><span class="line">verify: Service converged</span><br></pre></td></tr></table></figure>
<p>在manager-node节点上使用上面这个覆盖网络创建nginx服务：<br>其中，–replicas 参数指定服务由几个实例组成。<br>注意：不需要提前在节点上下载nginx镜像，这个命令执行后会自动下载这个容器镜像（比如此处创建tomcat容器，就将下面命令中的镜像改为tomcat镜像）。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 docker service ls 查看正在运行服务的列表</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># docker service ls</span></span><br><span class="line">ID                  NAME                MODE                REPLICAS            IMAGE               PORTS</span><br><span class="line">olexfmtdf94s        my_nginx            replicated          1/1                 nginx:latest        *:80-&gt;80/tcp</span><br></pre></td></tr></table></figure>
<p>2) 查询Swarm中服务的信息<br>-pretty 使命令输出格式化为可读的格式，不加 –pretty 可以输出更详细的信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker service inspect --pretty my_nginx</span></span><br><span class="line">ID:             zs7fw4ereo5w7ohd4n9ii06nt</span><br><span class="line">Name:           my_nginx</span><br><span class="line">Service Mode:   Replicated</span><br><span class="line"> Replicas:      1</span><br><span class="line">Placement:</span><br><span class="line">UpdateConfig:</span><br><span class="line"> Parallelism:   1</span><br><span class="line"> On failure:    pause</span><br><span class="line"> Monitoring Period: 5s</span><br><span class="line"> Max failure ratio: 0</span><br><span class="line"> Update order:      stop-first</span><br><span class="line">RollbackConfig:</span><br><span class="line"> Parallelism:   1</span><br><span class="line"> On failure:    pause</span><br><span class="line"> Monitoring Period: 5s</span><br><span class="line"> Max failure ratio: 0</span><br><span class="line"> Rollback order:    stop-first</span><br><span class="line">ContainerSpec:</span><br><span class="line"> Image:         nginx:latest@sha256:b73f527d86e3461fd652f62cf47e7b375196063bbbd503e853af5be16597cb2e</span><br><span class="line"> Init:          <span class="literal">false</span></span><br><span class="line">Resources:</span><br><span class="line">Networks: nginx_net</span><br><span class="line">Endpoint Mode:  vip</span><br><span class="line">Ports:</span><br><span class="line"> PublishedPort = 80</span><br><span class="line">  Protocol = tcp</span><br><span class="line">  TargetPort = 80</span><br><span class="line">  PublishMode = ingress</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询到哪个节点正在运行该服务。如下该容器被调度到manager-node节点上启动了，然后访问http://192.168.31.43即可访问这个容器应用（如果调度到其他节点，访问也是如此）</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># docker service ps my_nginx</span></span><br><span class="line">ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE               ERROR               PORTS</span><br><span class="line">yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running about an hour ago</span><br><span class="line">```                       </span><br><span class="line">温馨提示：如果上面命令执行后，上面的 STATE 字段中刚开始的服务状态为 Preparing，需要等一会才能变为 Running 状态，其中最费时间的应该是下载镜像的过程</span><br><span class="line"> </span><br><span class="line">有上面命令可知，该服务在manager-node节点上运行。登陆该节点，可以查看到nginx容器在运行中</span><br><span class="line">```bash</span><br><span class="line">[root@manager43 ~]<span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">0dc7103f8030        nginx:latest        <span class="string">"nginx -g 'daemon of…"</span>   About an hour ago   Up About an hour    80/tcp              my_nginx.1.yzonph0zu7km0211uj0ro5brj</span><br></pre></td></tr></table></figure>
<p>3) 在Swarm中动态扩展服务(scale)<br>当然，如果只是通过service启动容器，swarm也算不上什么新鲜东西了。Service还提供了复制（类似kubernetes里的副本）功能。可以通过 docker service scale 命令来设置服务中容器的副本数<br>比如将上面的my_nginx容器动态扩展到4个</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker service scale my_nginx=4</span></span><br><span class="line">my_nginx scaled to 4</span><br><span class="line">overall progress: 4 out of 4 tasks</span><br><span class="line">1/4: running   [==================================================&gt;]</span><br><span class="line">2/4: running   [==================================================&gt;]</span><br><span class="line">3/4: running   [==================================================&gt;]</span><br><span class="line">4/4: running   [==================================================&gt;]</span><br><span class="line">verify: Service converged</span><br></pre></td></tr></table></figure>
<p>和创建服务一样，增加scale数之后，将会创建新的容器，这些新启动的容器也会经历从准备到运行的过程，过一分钟左右，服务应该就会启动完成，这时候可以再来看一下 nginx 服务中的容器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker service ps my_nginx</span></span><br><span class="line">ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE               ERROR               PORTS</span><br><span class="line">yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running about an hour ago                      </span><br><span class="line">mlprstt9ds5x        my_nginx.2          nginx:latest        node139             Running             Running 52 seconds ago                         </span><br><span class="line">y09lk90tdzdp        my_nginx.3          nginx:latest        node139             Running             Running 52 seconds ago                         </span><br><span class="line">clolfl3zlvj0        my_nginx.4          nginx:latest        node188             Running             Running 2 minutes ago</span><br></pre></td></tr></table></figure>

<p>可以看到，之前my_nginx容器只在manager-node节点上有一个实例，而现在又增加了3个实例。<br>这4个副本的my_nginx容器分别运行在这三个节点上，登陆这三个节点，就会发现已经存在运行着的my_nginx容器</p>
<p>4) 模拟宕机node节点<br>特别需要清楚的一点：<br>如果一个节点宕机了（即该节点就会从swarm集群中被踢出），则Docker应该会将在该节点运行的容器，调度到其他节点，以满足指定数量的副本保持运行状态。</p>
<p>比如：<br>将node139宕机后或将node139的docker服务关闭，那么它上面的task实例就会转移到别的节点上。当node139节点恢复后，它转移出去的task实例不会主动转移回来，<br>只能等别的节点出现故障后转移task实例到它的上面。使用命令”docker node ls”，发现node139节点已不在swarm集群中了(状态为：Down)。<br>[root@node139 ~]# systemctl stop docker<br>[root@manager43 ~]# docker node ls<br>ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION<br>ppk7q0bjond8a58xja7in1qid *   manager43           Ready               Active              Leader              18.06.0-ce<br>mums8azgbrffnecp3q8fz70pl     node139             Down                Active                                  18.06.1-ce<br>z3n36maf03yjg7odghikuv574     node188             Ready               Active                                  18.06.1-ce</p>
<p>然后过一会查询服务的状态列表<br>[root@manager43 ~]# docker service ps my_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTS<br>yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running about an hour ago<br>wb1cpk9k22rl        my_nginx.2          nginx:latest        node188             Running             Running about a minute ago<br>mlprstt9ds5x         _ my_nginx.2      nginx:latest        node139             Shutdown            Running 4 minutes ago<br>rhbj4bcr4t2c        my_nginx.3          nginx:latest        manager43           Running             Running about a minute ago<br>y09lk90tdzdp         _ my_nginx.3      nginx:latest        node139             Shutdown            Running 4 minutes ago<br>clolfl3zlvj0        my_nginx.4          nginx:latest        node188             Running             Running 6 minutes ago</p>
<p>上面我们可以发现node139故障后，它上面之前的两个task任务已经转移到node188和manager43节点上了</p>
<p>登陆到node188和manager43节点上，可以看到这两个运行的task任务。当访问192.168.31.188和192.168.31.43节点的80端口，swarm的负载均衡会把请求路由到一个任意节点的可用的容器上<br>[root@manager43 ~]# docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES<br>ae4c5c2e6f3f        nginx:latest        “nginx -g ‘daemon of…”   4 minutes ago       Up 4 minutes        80/tcp              my_nginx.3.rhbj4bcr4t2c3y2f8vyfmbi21<br>0dc7103f8030        nginx:latest        “nginx -g ‘daemon of…”   About an hour ago   Up About an hour    80/tcp              my_nginx.1.yzonph0zu7km0211uj0ro5brj</p>
<p>[root@node188 ~]# docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES<br>a63ef253f7dd        nginx:latest        “nginx -g ‘daemon of…”   3 minutes ago       Up 3 minutes        80/tcp              my_nginx.2.wb1cpk9k22rl1ydab7aozl2b5<br>74a1a1db81d4        nginx:latest        “nginx -g ‘daemon of…”   8 minutes ago       Up 8 minutes        80/tcp              my_nginx.4.clolfl3zlvj0ewmh85c2ljnza</p>
<p>再次在node188和manager43节点上将从node139上转移过来的两个task关闭<br>[root@manager43 ~]# docker stop my_nginx.3.rhbj4bcr4t2c3y2f8vyfmbi21<br>my_nginx.3.rhbj4bcr4t2c3y2f8vyfmbi21</p>
<p>[root@node188 ~]# docker stop my_nginx.2.wb1cpk9k22rl1ydab7aozl2b5<br>my_nginx.2.wb1cpk9k22rl1ydab7aozl2b5</p>
<p>再次查询服务的状态列表，发现这两个task又转移到node139上了<br>[root@manager43 ~]# docker service ps my_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR               PORTS<br>yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running 2 hours ago<br>j2q61f8jtzba        my_nginx.2          nginx:latest        node188             Running             Running 24 seconds ago<br>wb1cpk9k22rl         _ my_nginx.2      nginx:latest        node188             Shutdown            Complete 29 seconds ago<br>mlprstt9ds5x         _ my_nginx.2      nginx:latest        node139             Shutdown            Running 11 minutes ago<br>oz9wyjuldw1t        my_nginx.3          nginx:latest        manager43           Running             Running 40 seconds ago<br>rhbj4bcr4t2c         _ my_nginx.3      nginx:latest        manager43           Shutdown            Complete 45 seconds ago<br>y09lk90tdzdp         _ my_nginx.3      nginx:latest        node139             Shutdown            Running 11 minutes ago<br>clolfl3zlvj0        my_nginx.4          nginx:latest        node188             Running             Running 12 minutes ago<br>结论：即在swarm cluster集群中启动的容器，在worker node节点上删除或停用后，该容器会自动转移到其他的worker node节点上</p>
<p>5) Swarm 动态缩容服务(scale)<br>同理，swarm还可以缩容，同样是使用scale命令<br>如下，将my_nginx容器变为1个<br>[root@manager43 ~]# docker service scale my_nginx=1<br>my_nginx scaled to 1<br>overall progress: 1 out of 1 tasks<br>1/1:<br>verify: Service converged</p>
<p>[root@manager43 ~]# docker service ls<br>ID                  NAME                MODE                REPLICAS            IMAGE               PORTS<br>zs7fw4ereo5w        my_nginx            replicated          1/1                 nginx:latest        *:80-&gt;80/tcp</p>
<p>[root@manager43 ~]# docker service ps my_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR               PORTS<br>yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running 11 hours ago<br>wb1cpk9k22rl        my_nginx.2          nginx:latest        node188             Shutdown            Complete 9 hours ago<br>mlprstt9ds5x         _ my_nginx.2      nginx:latest        node139             Shutdown            Shutdown 29 seconds ago<br>rhbj4bcr4t2c        my_nginx.3          nginx:latest        manager43           Shutdown            Complete 9 hours ago<br>y09lk90tdzdp         _ my_nginx.3      nginx:latest        node139             Shutdown            Shutdown 29 seconds ago      </p>
<p>通过docker service ps my_nginx 可以看到node节点上已经为Shutdown状态了</p>
<p>在登录到node节点主机上查看<br>[root@node188 ~]# docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS               NAMES<br>f93c0a27374a        nginx:latest        “nginx -g ‘daemon of…”   9 hours ago         Exited (0) 44 seconds ago                       my_nginx.2.j2q61f8jtzba9kb3unupkhl25<br>a63ef253f7dd        nginx:latest        “nginx -g ‘daemon of…”   9 hours ago         Exited (0) 9 hours ago                          my_nginx.2.wb1cpk9k22rl1ydab7aozl2b5<br>[root@node139 ~]# docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                   PORTS               NAMES<br>e8ac2e44f5c4        nginx:latest        “nginx -g ‘daemon of…”   9 hours ago         Exited (0) 9 hours ago                       my_nginx.2.mlprstt9ds5xi48u1rzscgfdk<br>5b031aa5a2cc        nginx:latest        “nginx -g ‘daemon of…”   9 hours ago         Exited (0) 9 hours ago                       my_nginx.3.y09lk90tdzdp8cwj6mm5oyr3f<br>登录node节点，使用docker ps -a 查看，会发现容器被stop而非rm</p>
<p>6) 除了上面使用scale进行容器的扩容或缩容之外，还可以使用docker service update 命令。 可对 服务的启动 参数 进行 更新/修改。<br>[root@manager43 ~]# docker service update –replicas 3 my_nginx<br>my_nginx<br>overall progress: 3 out of 3 tasks<br>1/3: running   [==================================================&gt;]<br>2/3: running   [==================================================&gt;]<br>3/3: running   [==================================================&gt;]<br>verify: Service converged</p>
<p>[root@manager43 ~]# docker service ls<br>ID                  NAME                MODE                REPLICAS            IMAGE               PORTS<br>zs7fw4ereo5w        my_nginx            replicated          3/3                 nginx:latest        *:80-&gt;80/tcp</p>
<p>[root@manager43 ~]# docker service ps my_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS<br>yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running 11 hours ago<br>j3hduzd9pret        my_nginx.2          nginx:latest        node188             Running             Running 18 seconds ago<br>wb1cpk9k22rl         _ my_nginx.2      nginx:latest        node188             Shutdown            Complete 9 hours ago<br>mlprstt9ds5x         _ my_nginx.2      nginx:latest        node139             Shutdown            Shutdown 4 minutes ago<br>gng96vc5vqpv        my_nginx.3          nginx:latest        node139             Running             Running 18 seconds ago<br>rhbj4bcr4t2c         _ my_nginx.3      nginx:latest        manager43           Shutdown            Complete 9 hours ago<br>y09lk90tdzdp         _ my_nginx.3      nginx:latest        node139             Shutdown            Shutdown 4 minutes ago    </p>
<p>docker service update 命令，也可用于直接 升级 镜像等<br>[root@manager43 ~]# docker service update –image nginx:new my_nginx</p>
<p>[root@manager43 ~]# docker service ls<br>ID                  NAME                MODE                REPLICAS            IMAGE               PORTS<br>zs7fw4ereo5w        my_nginx            replicated          3/3                 nginx:new           *:80-&gt;80/tcp<br>注意IMAGE列 变成了nginx:new</p>
<p>7) 为了下面的直观显示，我这里把my_nginx服务直接删除了<br>[root@manager43 ~]# docker service rm my_nginx</p>
<p>这样就会把所有节点上的所有容器（task任务实例）全部删除了<br>4、Swarm中使用Volume(挂在目录，mount命令)</p>
<p>1) 查看volume的帮助信息<br>[root@manager43 ~]# docker volume –help</p>
<p>Usage:  docker volume COMMAND</p>
<p>Manage volumes</p>
<p>Commands:<br>  create      Create a volume<br>  inspect     Display detailed information on one or more volumes<br>  ls          List volumes<br>  prune       Remove all unused local volumes<br>  rm          Remove one or more volumes</p>
<p>Run ‘docker volume COMMAND –help’ for more information on a command.</p>
<p>2) 创建一个volume<br>[root@manager43 ~]# docker volume create –name testvolume<br>testvolume</p>
<h1 id="查看创建的volume"><a href="#查看创建的volume" class="headerlink" title="查看创建的volume"></a>查看创建的volume</h1><p>[root@manager43 ~]# docker volume ls<br>DRIVER              VOLUME NAME<br>local               testvolume</p>
<h1 id="查看volume详情"><a href="#查看volume详情" class="headerlink" title="查看volume详情"></a>查看volume详情</h1><p>[root@manager43 ~]# docker volume inspect testvolume<br>[<br>    {<br>        “CreatedAt”: “2018-10-21T10:50:02+08:00”,<br>        “Driver”: “local”,<br>        “Labels”: {},<br>        “Mountpoint”: “/var/lib/docker/volumes/testvolume/_data”,<br>        “Name”: “testvolume”,<br>        “Options”: {},<br>        “Scope”: “local”<br>    }<br>]</p>
<p>3) 创建新的服务并挂载testvolume(nginx为例)<br>[root@manager43 ~]# docker service create –replicas 3 –mount type=volume,src=testvolume,dst=/zjz –name test_nginx nginx<br>sh7wc8yzcvr0xaedo4tnraj7l<br>overall progress: 3 out of 3 tasks<br>1/3: running   [==================================================&gt;]<br>2/3: running   [==================================================&gt;]<br>3/3: running   [==================================================&gt;]<br>verify: Service converged</p>
<p>温馨提示：<br>参数src写成source也可以；dst表示容器内的路径，也可以写成target</p>
<h1 id="查看创建服务"><a href="#查看创建服务" class="headerlink" title="查看创建服务"></a>查看创建服务</h1><p>[root@manager43 ~]# docker service ls<br>ID                  NAME                MODE                REPLICAS            IMAGE               PORTS<br>sh7wc8yzcvr0        test_nginx          replicated          3/3                 nginx:latest<br>[root@manager43 ~]# docker service ps test_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS<br>m7m41kwt4q6w        test_nginx.1        nginx:latest        node188             Running             Running 56 seconds ago<br>kayh81q1o1kx        test_nginx.2        nginx:latest        node139             Running             Running 56 seconds ago<br>eq11v0rcwy38        test_nginx.3        nginx:latest        manager43           Running             Running 56 seconds ago           </p>
<h1 id="查看有没有挂载成功-登录各个节点的容器看看有没有指定的目录并创建文件测试"><a href="#查看有没有挂载成功-登录各个节点的容器看看有没有指定的目录并创建文件测试" class="headerlink" title="查看有没有挂载成功(登录各个节点的容器看看有没有指定的目录并创建文件测试)"></a>查看有没有挂载成功(登录各个节点的容器看看有没有指定的目录并创建文件测试)</h1><h1 id="容器中操作"><a href="#容器中操作" class="headerlink" title="容器中操作"></a>容器中操作</h1><p>[root@manager43 ~]# docker exec -it 63451219cb4e /bin/bash<br>root@63451219cb4e:/# cd /zjz/<br>root@63451219cb4e:/zjz# ls<br>root@63451219cb4e:/zjz# echo “gen wo xue docker” &gt; docker.txt<br>root@63451219cb4e:/zjz# ls<br>docker.txt</p>
<p>执行docker volume inspect testvolume 可以看到本地的路径(上面已经执行过了)<br>本地路径：/var/lib/docker/volumes/testvolume/_data<br>[root@manager43 ~]# cd /var/lib/docker/volumes/testvolume/_data<br>[root@manager43 _data]# ls<br>docker.txt<br>[root@manager43 _data]# cat docker.txt<br>gen wo xue docker</p>
<p>还可以将node节点机上的volume数据目录做成软链接<br>[root@manager43 _data]# ln -s /var/lib/docker/volumes/testvolume/_data /zjz<br>[root@manager43 _data]# cd /zjz/<br>[root@manager43 zjz]# ls<br>docker.txt<br>[root@manager43 zjz]# echo “123” &gt; 1.txt<br>[root@manager43 zjz]# ll<br>总用量 8<br>-rw-r–r– 1 root root  4 10月 21 11:04 1.txt<br>-rw-r–r– 1 root root 18 10月 21 11:00 docker.txt</p>
<h1 id="容器中查看"><a href="#容器中查看" class="headerlink" title="容器中查看"></a>容器中查看</h1><p>[root@manager43 zjz]# docker exec -it 63451219cb4e /bin/bash<br>root@63451219cb4e:/# cd /zjz/<br>root@63451219cb4e:/zjz# ls<br>1.txt  docker.txt<br>root@63451219cb4e:/zjz# cat 1.txt<br>123<br>root@63451219cb4e:/zjz# cat docker.txt<br>gen wo xue docker</p>
<h1 id="还有一种挂载方式简单说一下吧，上面的会了下面的肯定简单"><a href="#还有一种挂载方式简单说一下吧，上面的会了下面的肯定简单" class="headerlink" title="还有一种挂载方式简单说一下吧，上面的会了下面的肯定简单"></a>还有一种挂载方式简单说一下吧，上面的会了下面的肯定简单</h1><p>命令格式：<br>docker service create –mount type=bind,target=/container_data/,source=/host_data/<br>其中，参数target表示容器里面的路径，source表示本地硬盘路径</p>
<h1 id="示例创建并挂载并使用网络"><a href="#示例创建并挂载并使用网络" class="headerlink" title="示例创建并挂载并使用网络"></a>示例创建并挂载并使用网络</h1><p>[root@manager43 ~]# docker service create –replicas 1 –mount type=bind,target=/usr/share/nginx/html/,source=/opt/web/ –network nginx_net –name zjz_nginx -p 8880:80 nginx<br>5、多服务Swarm集群部署</p>
<p>问：上面我们只是对单独的一个nginx服务进行的集群部署，那如果要统一编排多个服务呢？<br>答：docker 三剑客中有个compose 这个就是对单机进行统一编排的，它的实现是通过docker-compose.yml的文件，这里我们就可以结合compose和swarm进行多服务的编排(docker compose教程)</p>
<p>温馨提示：<br>我们这里要部署的服务有三个(nginx服务，visualizer服务，portainer服务) 都是集群 GUI 管理服务<br>docker service部署的是单个服务，我们可以使用docker stack进行多服务编排部署</p>
<p>1) 编写docker-compose.yml文件<br>[root@manager43 ~]# mkdir testswarm<br>[root@manager43 ~]# cd testswarm/<br>[root@manager43 testswarm]# cat docker-compose.yml<br>version: “3”<br>services:<br>  nginx:<br>    image: nginx<br>    ports:<br>      - 8888:80<br>    deploy:<br>      mode: replicated<br>      replocas: 3</p>
<p>  visualizer:<br>    image: dockersamples/visualizer<br>    ports:<br>      - “8080:8080”<br>    volumes:<br>      - “/var/run/docker.sock:/var/run/docker.sock”<br>    deploy:<br>      replicas: 1<br>      placement:<br>        constraints: [node.role == manager]</p>
<p>  portainer:<br>    image: portainer/portainer<br>    ports:<br>      - “9000:9000”<br>    volumes:<br>      - “/var/run/docker.sock:/var/run/docker.sock”<br>    deploy:<br>      replicas: 1<br>      placement:<br>        constraints: [node.role == manager]</p>
<p>2) 通过这个yml文件部署服务<br>[root@manager43 testswarm]# docker stack deploy -c docker-compose.yml deploy_deamon<br>Creating network deploy_deamon_default<br>Creating service deploy_deamon_portainer<br>Creating service deploy_deamon_nginx<br>Creating service deploy_deamon_visualizer</p>
<p>通过上面的执行过程可以看出这样创建会默认创建一个网络并使用它，名字都是我们给的名字的前缀加上服务名</p>
<h1 id="查看创建服务-1"><a href="#查看创建服务-1" class="headerlink" title="查看创建服务"></a>查看创建服务</h1><p>[root@manager43 testswarm]# docker service ls<br>ID                  NAME                       MODE                REPLICAS            IMAGE                             PORTS<br>xj2f1t5ax3nm        deploy_deamon_nginx        replicated          3/3                 nginx:latest                      *:8888-&gt;80/tcp<br>ky9qpldr5abb        deploy_deamon_portainer    replicated          1/1                 portainer/portainer:latest        *:9000-&gt;9000/tcp<br>r47ff177x1ir        deploy_deamon_visualizer   replicated          1/1                 dockersamples/visualizer:latest   *:8080-&gt;8080/tcp</p>
<p>[root@manager43 testswarm]# docker service ps deploy_deamon_nginx<br>ID                  NAME                    IMAGE               NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTS<br>z3v4uc1ujsnq        deploy_deamon_nginx.1   nginx:latest        node139             Running             Running about a minute ago<br>jhg3ups0cko5        deploy_deamon_nginx.2   nginx:latest        manager43           Running             Running about a minute ago<br>3e6guv791x21        deploy_deamon_nginx.3   nginx:latest        node188             Running             Running about a minute ago        </p>
<p>[root@manager43 testswarm]# docker service ps deploy_deamon_portainer<br>ID                  NAME                        IMAGE                        NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTS<br>whyuvy82cvvw        deploy_deamon_portainer.1   portainer/portainer:latest   manager43           Running             Running about a minute ago                      </p>
<p>[root@manager43 testswarm]# docker service ps deploy_deamon_visualizer<br>ID                  NAME                         IMAGE                             NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS<br>wge5w1eqykg3        deploy_deamon_visualizer.1   dockersamples/visualizer:latest   manager43           Running             Starting 7 seconds ago<br>测试</p>
<h1 id="八、Docker-Swarm-容器网络"><a href="#八、Docker-Swarm-容器网络" class="headerlink" title="八、Docker Swarm 容器网络"></a>八、Docker Swarm 容器网络</h1><p>在Docker版本1.12之后swarm模式原生支持覆盖网络(overlay networks)，可以先创建一个覆盖网络，然后启动容器的时候启用这个覆盖网络，<br>这样只要是这个覆盖网络内的容器，不管在不在同一个宿主机上都能相互通信，即跨主机通信！不同覆盖网络内的容器组之间是相互隔离的（相互ping不通）。</p>
<p>swarm模式的覆盖网络包括以下功能：<br>1）可以附加多个服务到同一个网络。<br>2）默认情况下，service discovery为每个swarm服务分配一个虚拟IP地址(vip)和DNS名称，使得在同一个网络中容器之间可以使用服务名称为互相连接。<br>3）可以配置使用DNS轮循而不使用VIP<br>4）为了可以使用swarm的覆盖网络，在启用swarm模式之间你需要在swarm节点之间开放以下端口：<br>5）TCP/UDP端口7946 – 用于容器网络发现<br>6）UDP端口4789 – 用于容器覆盖网络</p>
<p>实例如下：<br>———–在Swarm集群中创建overlay网络————<br>[root@manager-node ~]# docker network create –driver overlay –opt encrypted –subnet 10.10.19.0/24 ngx_net</p>
<p>参数解释：<br>–opt encrypted  默认情况下swarm中的节点通信是加密的。在不同节点的容器之间，可选的–opt encrypted参数能在它们的vxlan流量启用附加的加密层。<br>–subnet 命令行参数指定overlay网络使用的子网网段。当不指定一个子网时，swarm管理器自动选择一个子网并分配给网络。</p>
<p>[root@manager-node ~]# docker network ls<br>NETWORK ID          NAME                DRIVER              SCOPE<br>d7aa48d3e485        bridge              bridge              local<br>9e637a97a3b9        docker_gwbridge     bridge              local<br>b5a41c8c71e7        host                host                local<br>7f4fx3jf4dbr        ingress             overlay             swarm<br>3x2wgugr6zmn        ngx_net             overlay             swarm<br>0808a5c72a0a        none                null                local</p>
<p>由上可知，Swarm当中拥有2套覆盖网络。其中”ngx_net”网络正是我们在部署容器时所创建的成果。而”ingress”覆盖网络则为默认提供。<br>Swarm 管理节点会利用 ingress 负载均衡以将服务公布至集群之外。<br>在将服务连接到这个创建的网络之前，网络覆盖到manager节点。上面输出的SCOPE为 swarm 表示将服务部署到Swarm时可以使用此网络。<br>在将服务连接到这个网络后，Swarm只将该网络扩展到特定的worker节点，这个worker节点被swarm调度器分配了运行服务的任务。<br>在那些没有运行该服务任务的worker节点上，网络并不扩展到该节点。</p>
<p>——————将服务连接到overlay网络——————-<br>[root@manager-node ~]# docker service create –replicas 5 –network ngx_net –name my-test -p 80:80 nginx</p>
<p>上面名为”my-test”的服务启动了3个task，用于运行每个任务的容器都可以彼此通过overlay网络进行通信。Swarm集群将网络扩展到所有任务处于Running状态的节点上。<br>[root@manager-node ~]# docker service ls<br>ID            NAME     REPLICAS  IMAGE  COMMAND<br>dsaxs6v463g9  my-test  5/5       nginx</p>
<p>在manager-node节点上，通过下面的命令查看哪些节点有处于running状态的任务：<br>[root@manager-node ~]# docker service ps my-test<br>ID                         NAME       IMAGE  NODE          DESIRED STATE  CURRENT STATE          ERROR<br>8433fuiy7vpu0p80arl7vggfe  my-test.1  nginx  node2         Running        Running 2 minutes ago<br>f1h7a0vtojv18zrsiw8j0rzaw  my-test.2  nginx  node1         Running        Running 2 minutes ago<br>ex73ifk3jvzw8ukurl8yu7fyq  my-test.3  nginx  node1         Running        Running 2 minutes ago<br>cyu73jd8psupfhken23vvmpud  my-test.4  nginx  manager-node  Running        Running 2 minutes ago<br>btorxekfix4hcqh4v83dr0tzw  my-test.5  nginx  manager-node  Running        Running 2 minutes ago</p>
<p>可见三个节点都有处于running状态的任务，所以my-network网络扩展到三个节点上。</p>
<p>可以查询某个节点上关于my-network的详细信息：<br>[root@manager-node ~]# docker network inspect ngx_net<br>[<br>    {<br>        “Name”: “ngx_net”,<br>        “Id”: “3x2wgugr6zmn1mcyf9k1du27p”,<br>        “Scope”: “swarm”,<br>        “Driver”: “overlay”,<br>        “EnableIPv6”: false,<br>        “IPAM”: {<br>            “Driver”: “default”,<br>            “Options”: null,<br>            “Config”: [<br>                {<br>                    “Subnet”: “10.10.19.0/24”,<br>                    “Gateway”: “10.10.19.1”<br>                }<br>            ]<br>        },<br>        “Internal”: false,<br>        “Containers”: {<br>            “00f47e38deea76269eb03ba13695ec0b0c740601c85019546d6a9a17fd434663”: {<br>                “Name”: “my-test.5.btorxekfix4hcqh4v83dr0tzw”,<br>                “EndpointID”: “ea962d07eee150b263ae631b8a7f8c1950337c11ef2c3d488a7c3717defd8601”,<br>                “MacAddress”: “02:42:0a:0a:13:03”,<br>                “IPv4Address”: “10.10.19.3/24”,<br>                “IPv6Address”: “”<br>            },<br>            “957620c6f7abb44ad8dd2d842d333f5e5c1655034dc43e49abbbd680de3a5341”: {<br>                “Name”: “my-test.4.cyu73jd8psupfhken23vvmpud”,<br>                “EndpointID”: “f33a6e9ddf1dd01bcfc43ffefd19e19514658f001cdf9b2fbe23bc3fdf56a42a”,<br>                “MacAddress”: “02:42:0a:0a:13:07”,<br>                “IPv4Address”: “10.10.19.7/24”,<br>                “IPv6Address”: “”<br>            }<br>        },<br>        “Options”: {<br>            “com.docker.network.driver.overlay.vxlanid_list”: “257”<br>        },<br>        “Labels”: {}<br>    }<br>]</p>
<p>从上面的信息可以看出在manager-node节点上，名为my-test的服务有一个名为my-test.5.btorxekfix4hcqh4v83dr0tzw和<br>my-test.4.cyu73jd8psupfhken23vvmpud的task连接到名为ngx_net的网络上（另外两个节点node1和node2同样可以用上面命令查看）<br>[root@node1 ~]# docker network inspect ngx_net<br>…….<br>        “Containers”: {<br>            “7d9986fad5a7d834676ba76ae75aff2258f840953f1dc633c3ef3c0efd2b2501”: {<br>                “Name”: “my-test.3.ex73ifk3jvzw8ukurl8yu7fyq”,<br>                “EndpointID”: “957ca19f3d5480762dbd14fd9a6a1cd01a8deac3e8e35b23d1350f480a7b2f37”,<br>                “MacAddress”: “02:42:0a:0a:13:06”,<br>                “IPv4Address”: “10.10.19.6/24”,<br>                “IPv6Address”: “”<br>            },<br>            “9e50fceada1d7c653a886ca29d2bf2606debafe8c8a97f2d79104faf3ecf8a46”: {<br>                “Name”: “my-test.2.f1h7a0vtojv18zrsiw8j0rzaw”,<br>                “EndpointID”: “b1c209c7b68634e88e0bf5e100fe03435b3096054da6555c61e6c207ac651ac2”,<br>                “MacAddress”: “02:42:0a:0a:13:05”,<br>                “IPv4Address”: “10.10.19.5/24”,<br>                “IPv6Address”: “”<br>            }<br>        },<br>………</p>
<p>[root@node2 web]# docker network inspect ngx_net<br>……..<br>        “Containers”: {<br>            “4bdcce0ee63edc08d943cf4a049eac027719ff2dc14b7c3aa85fdddc5d1da968”: {<br>                “Name”: “my-test.1.8433fuiy7vpu0p80arl7vggfe”,<br>                “EndpointID”: “df58de85b0a0e4d128bf332fc783f6528d1f179b0f9f3b7aa70ebc832640d3bc”,<br>                “MacAddress”: “02:42:0a:0a:13:04”,<br>                “IPv4Address”: “10.10.19.4/24”,<br>                “IPv6Address”: “”<br>            }<br>        },</p>
<p>可以通过查询服务来获得服务的虚拟IP地址，如下：<br>[root@manager-node ~]# docker service inspect –format=’‘ my-test<br>[{“NetworkID”:”7f4fx3jf4dbrp97aioc05pul4”,”Addr”:”10.255.0.6/16”},{“NetworkID”:”3x2wgugr6zmn1mcyf9k1du27p”,”Addr”:”10.10.19.2/24”}]</p>
<p>由上结果可知，10.10.19.2其实就是swarm集群内部的vip，整个网络结构如下图所示：
　</p>
<p>加入ngx_net网络的容器彼此之间可以通过IP地址通信，也可以通过名称通信。</p>
<p>[root@node2 ~]# docker ps<br>CONTAINER ID    IMAGE           COMMAND                  CREATED         STATUS             PORTS    NAMES<br>4bdcce0ee63e    nginx:latest    “nginx -g ‘daemon off”   22 minutes ago  Up 22 minutes      80/tcp   my-test.1.8433fuiy7vpu0p80arl7vggfe</p>
<p>[root@node2 ~]# docker exec -ti 4bdcce0ee63e /bin/bash<br>root@4bdcce0ee63e:/# ip addr<br>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default<br>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00<br>    inet 127.0.0.1/8 scope host lo<br>       valid_lft forever preferred_lft forever<br>    inet6 ::1/128 scope host<br>       valid_lft forever preferred_lft forever<br>1786: eth0@if1787: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default<br>    link/ether 02:42:0a:ff:00:08 brd ff:ff:ff:ff:ff:ff link-netnsid 0<br>    inet 10.255.0.8/16 scope global eth0<br>       valid_lft forever preferred_lft forever<br>    inet 10.255.0.6/32 scope global eth0<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::42:aff:feff:8/64 scope link<br>       valid_lft forever preferred_lft forever<br>1788: eth1@if1789: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default<br>    link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 1<br>    inet 172.18.0.3/16 scope global eth1<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::42:acff:fe12:3/64 scope link<br>       valid_lft forever preferred_lft forever<br>1791: eth2@if1792: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default<br>    link/ether 02:42:0a:0a:13:04 brd ff:ff:ff:ff:ff:ff link-netnsid 2<br>    inet 10.10.19.4/24 scope global eth2<br>       valid_lft forever preferred_lft forever<br>    inet 10.10.19.2/32 scope global eth2<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::42:aff:fe0a:1304/64 scope link<br>       valid_lft forever preferred_lft forever</p>
<p>root@4bdcce0ee63e:/# ping 10.10.19.3<br>PING 10.10.19.3 (10.10.19.3): 56 data bytes<br>64 bytes from 10.10.19.3: icmp_seq=0 ttl=64 time=0.890 ms<br>64 bytes from 10.10.19.3: icmp_seq=1 ttl=64 time=0.622 ms<br>…..-<br>2 packets transmitted, 2 packets received, 0% packet loss<br>round-trip min/avg/max/stddev = 0.622/0.756/0.890/0.134 ms</p>
<p>root@4bdcce0ee63e:/# ping 10.10.19.6<br>PING 10.10.19.6 (10.10.19.6): 56 data bytes<br>64 bytes from 10.10.19.6: icmp_seq=0 ttl=64 time=0.939 ms<br>64 bytes from 10.10.19.6: icmp_seq=1 ttl=64 time=0.590 ms</p>
<p>—————————-使用swarm模式的服务发现————————–<br>默认情况下，当创建了一个服务并连接到某个网络后，swarm会为该服务分配一个VIP。此VIP根据服务名映射到DNS。在网络上的容器共享该服务的DNS映射，<br>所以网络上的任意容器可以通过服务名访问服务。</p>
<p>在同一overlay网络中，不用通过端口映射来使某个服务可以被其它服务访问。Swarm内部的负载均衡器自动将请求发送到服务的VIP上，然后分发到所有的<br>active的task上。</p>
<p>如下示例：<br>在同一个网络中添加了一个centos服务，此服务可以通过名称my-test访问前面创建的nginx服务：<br>[root@manager-node ~]# docker service create –name my-centos –network ngx_net centos       </p>
<p>查询centos运行在哪个节点上（上面创建命令执行后，需要一段时间才能完成这个centos服务的创建）<br>[root@manager-node ~]# docker service ps my-centos<br>ID                         NAME             IMAGE   NODE   DESIRED STATE  CURRENT STATE            ERROR<br>e03pqgkjs3l1qizc6v4aqaune  my-centos.1      centos  node2  Running        Preparing 4 seconds ago</p>
<p>登录centos运行的节点（由上可知是node2节点），打开centos的交互shell：<br>[root@node2 ~]# docker ps<br>CONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS            NAMES<br>e4554490d891        centos:latest            “/bin/bash”             About an hour ago   Up About an hour   my-centos.1.9yk5ie28gwk9mw1h1jovb68ki</p>
<p>[root@node2 ~]# docker exec -ti my-centos.1.9yk5ie28gwk9mw1h1jovb68ki /bin/bash<br>root@4bdcce0ee63e:/# nslookup my-test<br>Server: 127.0.0.11<br>Address 1: 127.0.0.11</p>
<p>Name: my-test<br>Address 1: 10.10.19.2 10.10.19.2</p>
<p>从centos容器内部，使用特殊查询 查询DNS，来找到my-test服务的所有容器的IP地址：<br>root@4bdcce0ee63e:/# nslookup tasks.my-test<br>Server: 127.0.0.11<br>Address 1: 127.0.0.11</p>
<p>Name: tasks.my-test<br>Address 1: 10.10.19.4 my-test.1.8433fuiy7vpu0p80arl7vggfe<br>Address 2: 10.10.19.5 my-test.2.f1h7a0vtojv18zrsiw8j0rzaw<br>Address 3: 10.10.19.6 my-test.3.ex73ifk3jvzw8ukurl8yu7fyq<br>Address 2: 10.10.19.7 my-test.4.cyu73jd8psupfhken23vvmpud<br>Address 3: 10.10.19.3 my-test.5.btorxekfix4hcqh4v83dr0tzw</p>
<p>从centos容器内部，通过wget来访问my-test服务中运行的nginx网页服务器<br>root@4bdcce0ee63e:/# wget -O- my-test<br>Connecting to my-test (10.10.19.2:80)<br><!DOCTYPE html></p>
<html>
<head>
<title>Welcome to nginx!</title>
...

<p>Swarm的负载均衡器自动将HTTP请求路由到VIP上，然后到一个active的task容器上。它根据round-robin选择算法将后续的请求分发到另一个active的task上。</p>
<p>———————————–为服务使用DNS round-robin—————————–<br>在创建服务时，可以配置服务直接使用DNS round-robin而无需使用VIP。这是通过在创建服务时指定 –endpoint-mode dnsrr 命令行参数实现的。<br>当你想要使用自己的负载均衡器时可以使用这种方式。</p>
<p>如下示例（注意：使用DNS round-robin方式创建服务，不能直接在命令里使用-p指定端口）<br>[root@manager-node ~]# docker service create –replicas 3 –name my-dnsrr-nginx –network ngx_net –endpoint-mode dnsrr nginx</p>
<p>[root@manager-node ~]# docker service ps my-dnsrr-nginx<br>ID                         NAME              IMAGE  NODE          DESIRED STATE  CURRENT STATE          ERROR<br>65li2zbhxvvoaesndmwjokouj  my-dnsrr-nginx.1  nginx  node1         Running        Running 2 minutes ago<br>5hjw7wm4xr877879m0ewjciuj  my-dnsrr-nginx.2  nginx  manager-node  Running        Running 2 minutes ago<br>afo7acduge2qfy60e87liz557  my-dnsrr-nginx.3  nginx  manager-node  Running        Running 2 minutes ago</p>
<p>当通过服务名称查询DNS时，DNS服务返回所有任务容器的IP地址：<br>root@4bdcce0ee63e:/# nslookup my-dnsrr-nginx<br>Server:    127.0.0.11<br>Address 1: 127.0.0.11</p>
<p>Name:      my-dnsrr-nginx<br>Address 1: 10.10.19.10 my-dnsrr-nginx.3.0sm1n9o8hygzarv5t5eq46okn.my-network<br>Address 2: 10.10.19.9  my-dnsrr-nginx.2.b3o1uoa8m003b2kk0ytl9lawh.my-network<br>Address 3: 10.10.19.8  my-dnsrr-nginx.1.55za4c83jq9846rle6eigiq15.my-network</p>
<p>需要注意的是：一定要确认VIP的连通性<br>通常Docker官方推荐使用dig，nslookup或其它DNS查询工具来查询通过DNS对服务名的访问。因为VIP是逻辑IP，ping并不是确认VIP连通性的正确的工具。</p>
]]></content>
      <categories>
        <category>云原生</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>elasticsearch实战--java实现修改数据立即可见</title>
    <url>/es/elasticsearch%E5%AE%9E%E6%88%98-java%E5%AE%9E%E7%8E%B0%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E7%AB%8B%E5%8D%B3%E5%8F%AF%E8%A7%81/</url>
    <content><![CDATA[<h1 id="0-背景"><a href="#0-背景" class="headerlink" title="0.背景"></a>0.背景</h1><p>后台管理系统中，当进行部分修改操作后，会立即跳转列表页面，此时列表展示的仍为es的旧数据。修改的es的数据没有立即展示，但是当再次刷新页面后，数据才为最新的数据。</p>
<p>众所周知，es不是一个实时的搜索引擎，<strong>当数据从写入到可见之间有1秒的间隔时间</strong>。因此，在此时间间隔内的查询操作，都是不是最新的数据。</p>
<h1 id="1-解决"><a href="#1-解决" class="headerlink" title="1.解决"></a>1.解决</h1><p>在<strong>java high level client</strong>中，为<code>index</code>、<code>insert</code>、<code>update</code>、<code>bulk</code> 提供了<code>setRefreshPolicy</code>方法，用于设置数据更改后的刷新策略。</p>
<p>主要是三个参数<code>IMMEDIATE</code>、<code>NONE</code>、<code>WAIT_UNTIL</code>：</p>
<h2 id="NONE"><a href="#NONE" class="headerlink" title="NONE:"></a><strong>NONE</strong>:</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Don’t refresh after this request. The default.</span><br><span class="line">这是默认的一种方式，调用request修改以后，并不进行强制刷新，刷新的时间间隔为refresh_interval设置的参数。</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1.</span></span><br><span class="line">request.setRefreshPolicy(WriteRequest.RefreshPolicy.NONE);</span><br><span class="line"><span class="comment">// 2.</span></span><br><span class="line">request.setRefreshPolicy(<span class="string">"false"</span>);</span><br></pre></td></tr></table></figure>

<h2 id="IMMEDIATE："><a href="#IMMEDIATE：" class="headerlink" title="IMMEDIATE："></a><strong>IMMEDIATE</strong>：</h2><ul>
<li>强制刷新相关的主分片和副分片（而不是整个索引），使更新的分片状态变为可搜索。</li>
<li>在使用之前，一定要仔细考虑使用该参数会不会导致性能不佳。</li>
<li>强制刷新作为请求的一部分,这种方式并不适用于索引和查询高吞吐量的场景，</li>
<li>但是作为流量小时提供一致性的视图的确是很使用的。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1.</span></span><br><span class="line">request.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE);</span><br><span class="line"><span class="comment">// 2.</span></span><br><span class="line">request.setRefreshPolicy(<span class="string">"true"</span>);</span><br></pre></td></tr></table></figure>

<h2 id="WAIT-UNTIL"><a href="#WAIT-UNTIL" class="headerlink" title="WAIT_UNTIL:"></a><strong>WAIT_UNTIL</strong>:</h2><ul>
<li>在返回请求结果之前，会等待刷新请求所做的更改。并不是强制立即刷新，而是等待刷新发生。Elasticsearch会自动刷新已更改每个index.refresh_interval的分片，默认为一秒。该设置是动态的。</li>
<li>请求持续为打开状态，直到修改的内容变为可搜索为止。此刷新策略与高索引和搜索吞吐量兼容，但它会导致请求等待回复，直到刷新发生</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1.</span></span><br><span class="line">request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL);</span><br><span class="line"><span class="comment">// 2.</span></span><br><span class="line">request.setRefreshPolicy(<span class="string">"wait_for"</span>);</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>B+树,B树,红黑树对比</title>
    <url>/java/B+%E6%A0%91,B%E6%A0%91,%E7%BA%A2%E9%BB%91%E6%A0%91%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<h1 id="B-树，B树"><a href="#B-树，B树" class="headerlink" title="B+树，B树"></a>B+树，B树</h1><img data-src="https://img2018.cnblogs.com/blog/885859/201904/885859-20190406195954385-2039999739.png" alt="" width="547" height="184" />

<h2 id="区别有以下两点："><a href="#区别有以下两点：" class="headerlink" title="区别有以下两点："></a><strong>区别有以下两点：</strong></h2><ol>
<li>B+树中只有叶子节点会带有指向记录的指针，而B树则所有节点都带有，在内部节点出现的索引项不会再出现在叶子节点中。</li>
<li>B+树中所有叶子节点都是通过指针连接在一起，而B树不会。</li>
</ol>
<h2 id="B-树的优点："><a href="#B-树的优点：" class="headerlink" title="B+树的优点："></a><strong>B+树的优点：</strong></h2><ol>
<li><strong>非叶子节点不会带上指向记录的指针，这样，一个块中可以容纳更多的索引项，</strong>一是可以降低树的高度。二是一个内部节点可以定位更多的叶子节点。</li>
<li>叶子节点之间通过指针来连接，范围扫描将十分简单，而对于B树来说，则需要在叶子节点和内部节点不停的往返移动。<strong>具体的来讲，如何想扫描一次所有数据，对于b+树来说，可以从因为他们的叶子结点是连在一起的，所以可以横向的遍历过去。而对于b-树来说，就这能中序遍历了。</strong></li>
</ol>
<h2 id="B树的优点："><a href="#B树的优点：" class="headerlink" title="B树的优点："></a><strong>B树的优点：</strong></h2><p>对于在内部节点的数据，可直接得到，不必根据叶子节点来定位。</p>
<h2 id="B树长什么样子？"><a href="#B树长什么样子？" class="headerlink" title="B树长什么样子？"></a><strong>B树长什么样子？</strong></h2><p><img data-src="https://img2018.cnblogs.com/blog/885859/201904/885859-20190406200022185-1775475900.png" alt=""></p>
<h1 id="红黑树和B树应用场景有何不同？"><a href="#红黑树和B树应用场景有何不同？" class="headerlink" title="红黑树和B树应用场景有何不同？"></a>红黑树和B树应用场景有何不同？</h1><h2 id="为什么要设计红黑树？"><a href="#为什么要设计红黑树？" class="headerlink" title="为什么要设计红黑树？"></a>为什么要设计红黑树？</h2><p>先说一下红黑树，红黑树有一个比较复杂的规则，平衡树和红黑树的区别是什么？为什么有了平衡树还要设计出来红黑树？</p>
<p>红黑树的规则：</p>
<ul>
<li>1）每个结点要么是红的，要么是黑的。</li>
<li>2）根结点是黑的。</li>
<li>3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。</li>
<li>4）如果一个结点是红的，那么它的俩个儿子都是黑的。</li>
<li>5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。</li>
</ul>
<p>现在想想，我的理解是<strong>平衡树（AVL）</strong>更平衡，结构上更加直观，时间效能针对读取而言更高，<strong>但是维护起来比较麻烦！！！</strong>（插入和删除之后，都需要rebalance）。但是，红黑树通过它规则的设定，确保了插入和删除的最坏的时间复杂度是O(log N) 。</p>
<p>设计红黑树的目的，<strong>就是解决平衡树的维护起来比较麻烦的问题，红黑树，读取略逊于AVL，维护强于AVL，每次插入和删除的平均旋转次数应该是远小于平衡树。</strong></p>
<p>小结一下：</p>
<p>能用平衡树的地方，就可以用红黑树。用红黑树之后，读取略逊于AVL，维护强于AVL。</p>
<h2 id="红黑树-和-b-树的用途有什么区别？"><a href="#红黑树-和-b-树的用途有什么区别？" class="headerlink" title="红黑树 和 b+树的用途有什么区别？"></a>红黑树 和 b+树的用途有什么区别？</h2><ol>
<li><p>红黑树多用在内部排序，即全放在内存中的，STL的map和set的内部实现就是红黑树。</p>
</li>
<li><p>B+树多用于外存上时，B+也被成为一个磁盘友好的数据结构。</p>
</li>
</ol>
<h2 id="为什么b-磁盘友好？"><a href="#为什么b-磁盘友好？" class="headerlink" title="为什么b+磁盘友好？"></a><strong>为什么b+磁盘友好？</strong></h2><ol>
<li><p>磁盘读写代价更低<br> 树的非叶子结点里面没有数据，这样索引比较小，可以放在一个blcok（或者尽可能少的blcok）里面。避免了树形结构不断的向下查找，然后磁盘不停的寻道，读数据。这样的设计，可以降低io的次数。</p>
</li>
<li><p>查询效率更加稳定<br> 非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</p>
</li>
<li><p>遍历所有的数据更方便<br> B+树只要遍历叶子节点就可以实现整棵树的遍历，而其他的树形结构 要中序遍历才可以访问所有的数据。</p>
</li>
</ol>
<h2 id="为什么mysql索引使用B-树而不使用红黑树"><a href="#为什么mysql索引使用B-树而不使用红黑树" class="headerlink" title="为什么mysql索引使用B+树而不使用红黑树?"></a><strong>为什么mysql索引使用B+树而不使用红黑树?</strong></h2><p>B+树就是为文件存储而生的。如果数据库文件存储在主存中我认为两种结构的查询速度差距不是很大，因为主存的查找速度非常快。</p>
<p>而数据库文件实际存储在磁盘中，定位一行信息需要查找该行文件所在柱面号，磁盘号，扇区号，页号这个阶段是很耗费时间的。</p>
<p>每一次的定位请求意味着要做一次IO操作，也意味着成倍的时间消耗。因此减少IO查询的次数是提高查询性能的关键。而IO的查询次数就是索引树的高度，高度越低查询的次数越少。</p>
<p>同样的结点次数红黑树的高度最多为2log(n+1)，而B+树的高度最多为(logt (n+1)/2)+1,随着t增大高度会更小，IO次数也会减少。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 并发包ConcurrentHashMap图解上</title>
    <url>/java/ConcurrentHashMap1/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h1><p>以前写过介绍HashMap的文章，文中提到过HashMap在put的时候，插入的元素超过了容量（由负载因子决定）的范围就会触发扩容操作，就是rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。</p>
<a id="more"></a>

<p>我们来了解另一个键值存储集合HashTable，它是线程安全的，它在所有涉及到多线程操作的都加上了synchronized关键字来锁住整个table，这就意味着所有的线程都在竞争一把锁，在多线程的环境下，它是安全的，但是无疑是效率低下的。</p>
<p>其实HashTable有很多的优化空间，锁住整个table这么粗暴的方法可以变相的柔和点，比如在多线程的环境下，对不同的数据集进行操作时其实根本就不需要去竞争一个锁，因为他们不同hash值，不会因为rehash造成线程不安全，所以互不影响，这就是锁分离技术，将锁的粒度降低，利用多个锁来控制多个小的table，这就是这篇文章的主角ConcurrentHashMap JDK1.7版本的核心思想。</p>
<h1 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a><strong>ConcurrentHashMap</strong></h1><h2 id="JDK1-7的实现"><a href="#JDK1-7的实现" class="headerlink" title="JDK1.7的实现"></a><strong>JDK1.7的实现</strong></h2><p>在JDK1.7版本中，ConcurrentHashMap的数据结构是由一个Segment数组和多个HashEntry组成，如下图所示：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/ConcurrentHashMap1/1.png/w600">

<p>Segment数组的意义就是将一个大的table分割成多个小的table来进行加锁，也就是上面的提到的锁分离技术，而每一个Segment元素存储的是HashEntry数组+链表，这个和HashMap的数据存储结构一样</p>
<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a><strong>初始化</strong></h2><p>ConcurrentHashMap的初始化是会通过位与运算来初始化Segment的大小，用ssize来表示，如下所示</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> sshift = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> ssize = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (ssize &gt; concurrencyLevel) &#123;</span><br><span class="line">  ++sshift;</span><br><span class="line">  ssize &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如上所示，因为ssize用位于运算来计算（ssize &lt;&lt;=1），所以Segment的大小取值都是以2的N次方，无关concurrencyLevel的取值，当然concurrencyLevel最大只能用16位的二进制来表示，即65536，换句话说，Segment的大小最多65536个，没有指定concurrencyLevel元素初始化，Segment的大小ssize默认为16</p>
<p>每一个Segment元素下的HashEntry的初始化也是按照位于运算来计算，用cap来表示，如下所示</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> cap = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (cap &lt; c)</span><br><span class="line">  cap &lt;&lt;= <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>如上所示，HashEntry大小的计算也是2的N次方（cap &lt;&lt;=1）， cap的初始值为1，所以HashEntry最小的容量为2</p>
<h2 id="put操作"><a href="#put操作" class="headerlink" title="put操作"></a><strong>put操作</strong></h2><p>对于ConcurrentHashMap的数据插入，这里要进行两次Hash去定位数据的存储位置</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Segment</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">ReentrantLock</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br></pre></td></tr></table></figure>

<p>从上Segment的继承体系可以看出，Segment实现了ReentrantLock,也就带有锁的功能，当执行put操作时，会进行第一次key的hash来定位Segment的位置，如果该Segment还没有初始化，即通过CAS操作进行赋值，然后进行第二次hash操作，找到相应的HashEntry的位置，这里会利用继承过来的锁的特性，在将数据插入指定的HashEntry位置时（链表的尾端），会通过继承ReentrantLock的tryLock（）方法尝试去获取锁，如果获取成功就直接插入相应的位置，如果已经有线程获取该Segment的锁，那当前线程会以自旋的方式去继续的调用tryLock（）方法去获取锁，超过指定次数就挂起，等待唤醒。</p>
<h2 id="get操作"><a href="#get操作" class="headerlink" title="get操作"></a><strong>get操作</strong></h2><p>ConcurrentHashMap的get操作跟HashMap类似，只是ConcurrentHashMap第一次需要经过一次hash定位到Segment的位置，然后再hash定位到指定的HashEntry，遍历该HashEntry下的链表进行对比，成功就返回，不成功就返回null。</p>
<h2 id="size操作"><a href="#size操作" class="headerlink" title="size操作"></a><strong>size操作</strong></h2><p>计算ConcurrentHashMap的元素大小是一个有趣的问题，因为他是并发操作的，就是在你计算size的时候，他还在并发的插入数据，可能会导致你计算出来的size和你实际的size有相差（在你return size的时候，插入了多个数据），要解决这个问题，JDK1.7版本用两种方案。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    <span class="keyword">if</span> (retries++ == RETRIES_BEFORE_LOCK) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j) </span><br><span class="line">        ensureSegment(j).lock(); <span class="comment">// force creation</span></span><br><span class="line">    &#125;</span><br><span class="line">    sum = <span class="number">0L</span>;</span><br><span class="line">    size = <span class="number">0</span>;</span><br><span class="line">    overflow = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j) &#123;</span><br><span class="line">      Segment&lt;K,V&gt; seg = segmentAt(segments, j);</span><br><span class="line">      <span class="keyword">if</span> (seg != <span class="keyword">null</span>) &#123; </span><br><span class="line">        sum += seg.modCount; <span class="keyword">int</span> c = seg.count; </span><br><span class="line">        <span class="keyword">if</span> (c &lt; <span class="number">0</span> || (size += c) &lt; <span class="number">0</span>)</span><br><span class="line">          &amp;nbsp; &amp;nbsp;overflow = <span class="keyword">true</span>;</span><br><span class="line">      &#125; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (sum == last) <span class="keyword">break</span>;</span><br><span class="line">    last = sum; </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">finally</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (retries &gt; RETRIES_BEFORE_LOCK) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j)</span><br><span class="line">      segmentAt(segments, j).unlock();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>第一种方案他会使用不加锁的模式去尝试多次计算ConcurrentHashMap的size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的；1. 第二种方案是如果第一种方案不符合，他就会给每个Segment加上锁，然后计算ConcurrentHashMap的size返回。</li>
<li>第二种方案是如果第一种方案不符合，他就会给每个Segment加上锁，然后计算ConcurrentHashMap的size返回。</li>
</ol>
<h2 id="JDK1-8的实现"><a href="#JDK1-8的实现" class="headerlink" title="JDK1.8的实现"></a><strong>JDK1.8的实现</strong></h2><p>JDK1.8的实现已经摒弃了Segment的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作，整个看起来就像是优化过且线程安全的HashMap，虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/ConcurrentHashMap1/2.png/w600">

<p>在深入JDK1.8的put和get实现之前要知道一些常量设计和数据结构，这些是构成ConcurrentHashMap实现结构的基础，下面看一下基本属性：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// node数组最大容量：2^30=1073741824</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br><span class="line"><span class="comment">// 默认初始值，必须是2的幕数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CAPACITY = <span class="number">16</span>;</span><br><span class="line"><span class="comment">//数组可能最大值，需要与toArray（）相关方法关联</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_ARRAY_SIZE = Integer.MAX_VALUE - <span class="number">8</span>;</span><br><span class="line"><span class="comment">//并发级别，遗留下来的，为兼容以前的版本</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CONCURRENCY_LEVEL = <span class="number">16</span>;</span><br><span class="line"><span class="comment">// 负载因子</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> LOAD_FACTOR = <span class="number">0.75f</span>;</span><br><span class="line"><span class="comment">// 链表转红黑树阀值,&gt; 8 链表转换为红黑树</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"><span class="comment">//树转链表阀值，小于等于6（tranfer时，lc、hc=0两个计数器分别++记录原bin、新binTreeNode数量，&lt;=UNTREEIFY_THRESHOLD 则untreeify(lo)）</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TRANSFER_STRIDE = <span class="number">16</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> RESIZE_STAMP_BITS = <span class="number">16</span>;</span><br><span class="line"><span class="comment">// 2^15-1，help resize的最大线程数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_RESIZERS = (<span class="number">1</span> &lt;&lt; (<span class="number">32</span> - RESIZE_STAMP_BITS)) - <span class="number">1</span>;</span><br><span class="line"><span class="comment">// 32-16=16，sizeCtl中记录size大小的偏移量</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESIZE_STAMP_SHIFT = <span class="number">32</span> - RESIZE_STAMP_BITS;</span><br><span class="line"><span class="comment">// forwarding nodes的hash值</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MOVED     = -<span class="number">1</span>; </span><br><span class="line"><span class="comment">// 树根节点的hash值</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEBIN   = -<span class="number">2</span>; </span><br><span class="line"><span class="comment">// ReservationNode的hash值</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RESERVED  = -<span class="number">3</span>; </span><br><span class="line"><span class="comment">// 可用处理器数量</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> NCPU = Runtime.getRuntime().availableProcessors();</span><br><span class="line"><span class="comment">//存放node的数组</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">volatile</span> Node&lt;K,V&gt;[] table;</span><br><span class="line"><span class="comment">/*控制标识符，用来控制table的初始化和扩容的操作，不同的值有不同的含义</span></span><br><span class="line"><span class="comment"> *当为负数时：-1代表正在初始化，-N代表有N-1个线程正在 进行扩容</span></span><br><span class="line"><span class="comment"> *当为0时：代表当时的table还没有被初始化</span></span><br><span class="line"><span class="comment"> *当为正数时：表示初始化或者下一次进行扩容的大小*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> <span class="keyword">int</span> sizeCtl;</span><br></pre></td></tr></table></figure>
<p>基本属性定义了ConcurrentHashMap的一些边界以及操作时的一些控制，下面看一些内部的一些结构组成，这些是整个ConcurrentHashMap整个数据结构的核心。</p>
<h2 id="Node"><a href="#Node" class="headerlink" title="Node"></a><strong>Node</strong></h2><p>Node是ConcurrentHashMap存储结构的基本单元，继承于HashMap中的Entry，用于存储数据，源代码如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">//链表的数据结构</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="comment">//val和next都会在扩容时发生变化，所以加上volatile来保持可见性和禁止重排序</span></span><br><span class="line">    <span class="keyword">volatile</span> V val;</span><br><span class="line">    <span class="keyword">volatile</span> Node&lt;K,V&gt; next;</span><br><span class="line">    Node(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        <span class="keyword">this</span>.hash = hash;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.val = val;</span><br><span class="line">        <span class="keyword">this</span>.next = next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span>       </span>&#123; <span class="keyword">return</span> key; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span>     </span>&#123; <span class="keyword">return</span> val; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span>   </span>&#123; <span class="keyword">return</span> key.hashCode() ^ val.hashCode(); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">toString</span><span class="params">()</span></span>&#123; <span class="keyword">return</span> key + <span class="string">"="</span> + val; &#125;</span><br><span class="line">    <span class="comment">//不允许更新value  </span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">setValue</span><span class="params">(V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">        Object k, v, u; Map.Entry&lt;?,?&gt; e;</span><br><span class="line">        <span class="keyword">return</span> ((o <span class="keyword">instanceof</span> Map.Entry) &amp;&amp;</span><br><span class="line">                (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">                (v = e.getValue()) != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">                (k == key || k.equals(key)) &amp;&amp;</span><br><span class="line">                (v == (u = val) || v.equals(u)));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//用于map中的get（）方法，子类重写</span></span><br><span class="line">    <span class="function">Node&lt;K,V&gt; <span class="title">find</span><span class="params">(<span class="keyword">int</span> h, Object k)</span> </span>&#123;</span><br><span class="line">        Node&lt;K,V&gt; e = <span class="keyword">this</span>;</span><br><span class="line">        <span class="keyword">if</span> (k != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                K ek;</span><br><span class="line">                <span class="keyword">if</span> (e.hash == h &amp;&amp;</span><br><span class="line">                    ((ek = e.key) == k || (ek != <span class="keyword">null</span> &amp;&amp; k.equals(ek))))</span><br><span class="line">                    <span class="keyword">return</span> e;</span><br><span class="line">            &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Node数据结构很简单，从上可知，就是一个链表，但是只允许对数据进行查找，不允许进行修改。</p>
<h2 id="TreeNode"><a href="#TreeNode" class="headerlink" title="TreeNode"></a><strong>TreeNode</strong></h2><p>TreeNode继承与Node，但是数据结构换成了二叉树结构，它是红黑树的数据的存储结构，用于红黑树中存储数据，当链表的节点数大于8时会转换成红黑树的结构，他就是通过TreeNode作为存储结构代替Node来转换成黑红树源代码如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">//树形结构的属性定义</span></span><br><span class="line">    TreeNode&lt;K,V&gt; parent;  <span class="comment">// red-black tree links</span></span><br><span class="line">    TreeNode&lt;K,V&gt; left;</span><br><span class="line">    TreeNode&lt;K,V&gt; right;</span><br><span class="line">    TreeNode&lt;K,V&gt; prev;    <span class="comment">// needed to unlink next upon deletion</span></span><br><span class="line">    <span class="keyword">boolean</span> red; <span class="comment">//标志红黑树的红节点</span></span><br><span class="line">    TreeNode(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next,</span><br><span class="line">    TreeNode&lt;K,V&gt; parent) &#123;</span><br><span class="line">        <span class="keyword">super</span>(hash, key, val, next);</span><br><span class="line">        <span class="keyword">this</span>.parent = parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">Node&lt;K,V&gt; <span class="title">find</span><span class="params">(<span class="keyword">int</span> h, Object k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> findTreeNode(h, k, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//根据key查找 从根节点开始找出相应的TreeNode，</span></span><br><span class="line">    <span class="function"><span class="keyword">final</span> TreeNode&lt;K,V&gt; <span class="title">findTreeNode</span><span class="params">(<span class="keyword">int</span> h, Object k, Class&lt;?&gt; kc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (k != <span class="keyword">null</span>) &#123;</span><br><span class="line">            TreeNode&lt;K,V&gt; p = <span class="keyword">this</span>;</span><br><span class="line">            <span class="keyword">do</span>  &#123;</span><br><span class="line">                <span class="keyword">int</span> ph, dir; K pk; TreeNode&lt;K,V&gt; q;</span><br><span class="line">                TreeNode&lt;K,V&gt; pl = p.left, pr = p.right;</span><br><span class="line">                <span class="keyword">if</span> ((ph = p.hash) &gt; h)</span><br><span class="line">                    p = pl;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (ph &lt; h)</span><br><span class="line">                    p = pr;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> ((pk = p.key) == k || (pk != <span class="keyword">null</span> &amp;&amp; k.equals(pk)))</span><br><span class="line">                    <span class="keyword">return</span> p;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (pl == <span class="keyword">null</span>)</span><br><span class="line">                    p = pr;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (pr == <span class="keyword">null</span>)</span><br><span class="line">                    p = pl;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> ((kc != <span class="keyword">null</span> ||</span><br><span class="line">                    (kc = comparableClassFor(k)) != <span class="keyword">null</span>) &amp;&amp;</span><br><span class="line">                         (dir = compareComparables(kc, k, pk)) != <span class="number">0</span>)</span><br><span class="line">                    p = (dir &lt; <span class="number">0</span>) ? pl : pr;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> ((q = pr.findTreeNode(h, k, kc)) != <span class="keyword">null</span>)</span><br><span class="line">                    <span class="keyword">return</span> q;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    p = pl;</span><br><span class="line">            &#125; <span class="keyword">while</span> (p != <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="TreeBin"><a href="#TreeBin" class="headerlink" title="TreeBin"></a><strong>TreeBin</strong></h2><p>TreeBin从字面含义中可以理解为存储树形结构的容器，而树形结构就是指TreeNode，所以TreeBin就是封装TreeNode的容器，它提供转换黑红树的一些条件和锁的控制，部分源码结构如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeBin</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">//指向TreeNode列表和根节点</span></span><br><span class="line">    TreeNode&lt;K,V&gt; root;</span><br><span class="line">    <span class="keyword">volatile</span> TreeNode&lt;K,V&gt; first;</span><br><span class="line">    <span class="keyword">volatile</span> Thread waiter;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">int</span> lockState;</span><br><span class="line">    <span class="comment">// 读写锁状态</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> WRITER = <span class="number">1</span>; <span class="comment">// 获取写锁的状态</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> WAITER = <span class="number">2</span>; <span class="comment">// 等待写锁的状态</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> READER = <span class="number">4</span>; <span class="comment">// 增加数据时读锁的状态</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">     * 初始化红黑树</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    TreeBin(TreeNode&lt;K,V&gt; b) &#123;</span><br><span class="line">        <span class="keyword">super</span>(TREEBIN, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">this</span>.first = b;</span><br><span class="line">        TreeNode&lt;K,V&gt; r = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">for</span> (TreeNode&lt;K,V&gt; x = b, next; x != <span class="keyword">null</span>; x = next) &#123;</span><br><span class="line">            next = (TreeNode&lt;K,V&gt;)x.next;</span><br><span class="line">            x.left = x.right = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">if</span> (r == <span class="keyword">null</span>) &#123;</span><br><span class="line">                x.parent = <span class="keyword">null</span>;</span><br><span class="line">                x.red = <span class="keyword">false</span>;</span><br><span class="line">                r = x;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                K k = x.key;</span><br><span class="line">                <span class="keyword">int</span> h = x.hash;</span><br><span class="line">                Class&lt;?&gt; kc = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">for</span> (TreeNode&lt;K,V&gt; p = r;;) &#123;</span><br><span class="line">                    <span class="keyword">int</span> dir, ph;</span><br><span class="line">                    K pk = p.key;</span><br><span class="line">                    <span class="keyword">if</span> ((ph = p.hash) &gt; h)</span><br><span class="line">                        dir = -<span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (ph &lt; h)</span><br><span class="line">                        dir = <span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> ((kc == <span class="keyword">null</span> &amp;&amp; (kc = comparableClassFor(k)) == <span class="keyword">null</span>) || (dir = compareComparables(kc, k, pk)) == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                        dir = tieBreakOrder(k, pk);</span><br><span class="line">                        TreeNode&lt;K,V&gt; xp = p;</span><br><span class="line">                    <span class="keyword">if</span> ((p = (dir &lt;= <span class="number">0</span>) ? p.left : p.right) == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        x.parent = xp;</span><br><span class="line">                        <span class="keyword">if</span> (dir &lt;= <span class="number">0</span>)</span><br><span class="line">                            xp.left = x;</span><br><span class="line">                        <span class="keyword">else</span></span><br><span class="line">                            xp.right = x;</span><br><span class="line">                        r = balanceInsertion(r, x);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.root = r;</span><br><span class="line">        <span class="function"><span class="keyword">assert</span> <span class="title">checkInvariants</span><span class="params">(root)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>介绍了ConcurrentHashMap主要的属性与内部的数据结构，现在通过一个简单的例子以debug的视角看看ConcurrentHashMap的具体操作细节。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestConcurrentHashMap</span></span>&#123;    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        ConcurrentHashMap&lt;String,String&gt; map = <span class="keyword">new</span> ConcurrentHashMap(); <span class="comment">//初始化ConcurrentHashMap</span></span><br><span class="line">        <span class="comment">//新增个人信息</span></span><br><span class="line">        map.put(<span class="string">"id"</span>,<span class="string">"1"</span>);</span><br><span class="line">        map.put(<span class="string">"name"</span>,<span class="string">"andy"</span>);</span><br><span class="line">        map.put(<span class="string">"sex"</span>,<span class="string">"男"</span>);</span><br><span class="line">        <span class="comment">//获取姓名</span></span><br><span class="line">        String name = map.get(<span class="string">"name"</span>);</span><br><span class="line">        Assert.assertEquals(name,<span class="string">"andy"</span>);</span><br><span class="line">        <span class="comment">//计算大小</span></span><br><span class="line">        <span class="keyword">int</span> size = map.size();</span><br><span class="line">        Assert.assertEquals(size,<span class="number">3</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们先通过new ConcurrentHashMap()来进行初始化</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMap</span><span class="params">()</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure>

<p>由上你会发现ConcurrentHashMap的初始化其实是一个空实现，并没有做任何事，这里后面会讲到，这也是和其他的集合类有区别的地方，初始化操作并不是在构造函数实现的，而是在put操作中实现，当然ConcurrentHashMap还提供了其他的构造函数，有指定容量大小或者指定负载因子，跟HashMap一样，这里就不做介绍了。</p>
<h2 id="put操作-1"><a href="#put操作-1" class="headerlink" title="put操作"></a><strong>put操作</strong></h2><p>在上面的例子中我们新增个人信息会调用put方法，我们来看下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> putVal(key, value, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** Implementation for put and putIfAbsent */</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(K key, V value, <span class="keyword">boolean</span> onlyIfAbsent)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span> || value == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> hash = spread(key.hashCode()); <span class="comment">//两次hash，减少hash冲突，可以均匀分布</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> binCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Node&lt;K,V&gt;[] tab = table;;) &#123; <span class="comment">//对这个table进行迭代</span></span><br><span class="line"></span><br><span class="line">        Node&lt;K,V&gt; f; <span class="keyword">int</span> n, i, fh;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//这里就是上面构造方法没有进行初始化，在这里进行判断，为null就调用initTable进行初始化，属于懒汉模式初始化</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (tab == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            tab = initTable();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((f = tabAt(tab, i = (n - <span class="number">1</span>) &amp; hash)) == <span class="keyword">null</span>) &#123;<span class="comment">//如果i位置没有数据，就直接无锁插入</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (casTabAt(tab, i, <span class="keyword">null</span>,</span><br><span class="line"></span><br><span class="line">                         <span class="keyword">new</span> Node&lt;K,V&gt;(hash, key, value, <span class="keyword">null</span>)))</span><br><span class="line"></span><br><span class="line">                <span class="keyword">break</span>;                   <span class="comment">// no lock when adding to empty bin</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((fh = f.hash) == MOVED)<span class="comment">//如果在进行扩容，则先进行扩容操作</span></span><br><span class="line"></span><br><span class="line">            tab = helpTransfer(tab, f);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">            V oldVal = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//如果以上条件都不满足，那就要进行加锁操作，也就是存在hash冲突，锁住链表或者红黑树的头结点</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">synchronized</span> (f) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (tabAt(tab, i) == f) &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (fh &gt;= <span class="number">0</span>) &#123; <span class="comment">//表示该节点是链表结构</span></span><br><span class="line"></span><br><span class="line">                        binCount = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">for</span> (Node&lt;K,V&gt; e = f;; ++binCount) &#123;</span><br><span class="line"></span><br><span class="line">                            K ek;</span><br><span class="line"></span><br><span class="line">                            <span class="comment">//这里涉及到相同的key进行put就会覆盖原先的value</span></span><br><span class="line"></span><br><span class="line">                            <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line"></span><br><span class="line">                                ((ek = e.key) == key ||</span><br><span class="line"></span><br><span class="line">                                 (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek)))) &#123;</span><br><span class="line"></span><br><span class="line">                                oldVal = e.val;</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">if</span> (!onlyIfAbsent)</span><br><span class="line"></span><br><span class="line">                                    e.val = value;</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            Node&lt;K,V&gt; pred = e;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">if</span> ((e = e.next) == <span class="keyword">null</span>) &#123;  <span class="comment">//插入链表尾部</span></span><br><span class="line"></span><br><span class="line">                                pred.next = <span class="keyword">new</span> Node&lt;K,V&gt;(hash, key,</span><br><span class="line"></span><br><span class="line">                                                          value, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (f <span class="keyword">instanceof</span> TreeBin) &#123;<span class="comment">//红黑树结构</span></span><br><span class="line"></span><br><span class="line">                        Node&lt;K,V&gt; p;</span><br><span class="line"></span><br><span class="line">                        binCount = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">//红黑树结构旋转插入</span></span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,</span><br><span class="line"></span><br><span class="line">                                                       value)) != <span class="keyword">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">                            oldVal = p.val;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">if</span> (!onlyIfAbsent)</span><br><span class="line"></span><br><span class="line">                                p.val = value;</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (binCount != <span class="number">0</span>) &#123; <span class="comment">//如果链表的长度大于8时就会进行红黑树的转换</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD)</span><br><span class="line"></span><br><span class="line">                    treeifyBin(tab, i);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (oldVal != <span class="keyword">null</span>)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> oldVal;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    addCount(<span class="number">1L</span>, binCount);<span class="comment">//统计size，并且检查是否需要扩容</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个put的过程很清晰，对当前的table进行无条件自循环直到put成功，可以分成以下六步流程来概述。</p>
<ol>
<li>如果没有初始化就先调用initTable（）方法来进行初始化过程</li>
<li>如果没有hash冲突就直接CAS插入</li>
<li>如果还在进行扩容操作就先进行扩容</li>
<li>如果存在hash冲突，就加锁来保证线程安全，这里有两种情况，一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入，</li>
<li>最后一个如果该链表的数量大于阈值8，就要先转换成黑红树的结构，break再一次进入循环</li>
<li>如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java CopyOnWriteArrayList图解</title>
    <url>/java/CopyOnWriteArrayList/</url>
    <content><![CDATA[<h1 id="初识CopyOnWriteArrayList"><a href="#初识CopyOnWriteArrayList" class="headerlink" title="初识CopyOnWriteArrayList"></a><strong>初识CopyOnWriteArrayList</strong></h1><p>第一次见到CopyOnWriteArrayList，是在研究JDBC的时候，每一个数据库的Driver都是维护在一个CopyOnWriteArrayList中的，为了证明这一点，贴两段代码，第一段在com.mysql.jdbc.Driver下，也就是我们写Class.forName(“…”)中的内容：</p>
<a id="more"></a>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Driver</span> <span class="keyword">extends</span> <span class="title">NonRegisteringDriver</span>&amp;<span class="title">nbsp</span></span>; implements java.sql.Driver&#123;&amp;nbsp; <span class="function"><span class="keyword">public</span> <span class="title">Driver</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> SQLException&amp;nbsp</span>; &#123;&amp;nbsp; &#125;&amp;nbsp;&amp;nbsp; <span class="keyword">static</span>&amp;nbsp; &#123;</span><br><span class="line"><span class="keyword">try</span></span><br><span class="line">&#123;</span><br><span class="line">&amp;nbsp; DriverManager.registerDriver(<span class="keyword">new</span> Driver());</span><br><span class="line">&#125; <span class="keyword">catch</span> (SQLException E) &#123;</span><br><span class="line">&amp;nbsp; <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Can't register driver!"</span>);</span><br><span class="line">&#125;&amp;nbsp; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看到com.mysql.jdbc.Driver调用了DriverManager的registerDriver方法，这个类在java.sql.DriverManager下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DriverManager</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> CopyOnWriteArrayList&lt;DriverInfo&gt;&amp;nbsp;</span><br><span class="line">registeredDrivers = <span class="keyword">new</span> CopyOnWriteArrayList();</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> loginTimeout = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> PrintWriter logWriter = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> PrintStream logStream = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object logSync = <span class="keyword">new</span> Object();</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> SQLPermission SET_LOG_PERMISSION = <span class="keyword">new</span></span><br><span class="line">SQLPermission(<span class="string">"setLog"</span>);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看到所有的DriverInfo都在CopyOnWriteArrayList中。既然看到了CopyOnWriteArrayList，我自然免不了要研究一番为什么JDK使用的是这个List。</p>
<p>首先提两点：</p>
<p>1、CopyOnWriteArrayList位于java.util.concurrent包下，可想而知，这个类是为并发而设计的</p>
<p>2、CopyOnWriteArrayList，顾名思义，Write的时候总是要Copy，也就是说对于CopyOnWriteArrayList，任何可变的操作（add、set、remove等等）都是伴随复制这个动作的，后面会解读CopyOnWriteArrayList的底层实现机制</p>
<h1 id="四个关注点在CopyOnWriteArrayList上的答案"><a href="#四个关注点在CopyOnWriteArrayList上的答案" class="headerlink" title="四个关注点在CopyOnWriteArrayList上的答案"></a><strong>四个关注点在CopyOnWriteArrayList上的答案</strong></h1><img data-src="http://f.ngall-in.com/alan87/static/images/java/CopyOnWriteArrayList/1.png/w600">

<h1 id="如何向CopyOnWriteArrayList中添加元素"><a href="#如何向CopyOnWriteArrayList中添加元素" class="headerlink" title="如何向CopyOnWriteArrayList中添加元素"></a><strong>如何向CopyOnWriteArrayList中添加元素</strong></h1><p>对于CopyOnWriteArrayList来说，增加、删除、修改、插入的原理都是一样的，所以用增加元素来分析一下CopyOnWriteArrayList的底层实现机制就可以了。先看一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">&amp;nbsp;List&lt;Integer&gt; list = <span class="keyword">new</span> CopyOnWriteArrayList&lt;Integer&gt;();</span><br><span class="line">&amp;nbsp;list.add(<span class="number">1</span>);</span><br><span class="line">&amp;nbsp;list.add(<span class="number">2</span>);&#125;</span><br></pre></td></tr></table></figure>

<p>看一下这段代码做了什么，先是第3行的实例化一个新的CopyOnWriteArrayList：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CopyOnWriteArrayList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">RandomAccess</span>, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">8673264195747942595L</span>;&amp;nbsp;</span><br><span class="line"><span class="comment">/** The lock protecting all mutators */</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">new</span> ReentrantLock();&amp;nbsp;</span><br><span class="line"><span class="comment">/** The array, accessed only via getArray/setArray. */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">transient</span> Object[] array;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">CopyOnWriteArrayList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  setArray(<span class="keyword">new</span> Object[<span class="number">0</span>]);&#125;</span><br><span class="line">  <span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">setArray</span><span class="params">(Object[] a)</span> </span>&#123;</span><br><span class="line">  array = a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看到，对于CopyOnWriteArrayList来说，底层就是一个Object[] array，然后实例化一个CopyOnWriteArrayList，用图来表示非常简单：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/CopyOnWriteArrayList/2.png/w600">


<p>就是这样，Object array指向一个数组大小为0的数组。接着看一下，第4行的add一个整数1做了什么，add的源代码是：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;<span class="keyword">final</span> ReentrantLock lock = <span class="keyword">this</span>.lock;lock.lock();<span class="keyword">try</span> &#123;</span><br><span class="line">Object[] elements = getArray();</span><br><span class="line"><span class="keyword">int</span> len = elements.length;</span><br><span class="line">Object[] newElements = Arrays.copyOf(elements, len + <span class="number">1</span>);</span><br><span class="line">newElements[len] = e;</span><br><span class="line">setArray(newElements);</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">true</span>;&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">lock.unlock();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>画一张图表示一下：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/CopyOnWriteArrayList/3.png/w600">

<p>每一步都清楚地表示在图上了，一次add大致经历了几个步骤：</p>
<ol>
<li><p>加锁</p>
</li>
<li><p>拿到原数组，得到新数组的大小（原数组大小+1），实例化出一个新的数组来</p>
</li>
<li><p>把原数组的元素复制到新数组中去</p>
</li>
<li><p>新数组最后一个位置设置为待添加的元素（因为新数组的大小是按照原数组大小+1来的）</p>
</li>
<li><p>把Object array引用指向新数组</p>
</li>
<li><p>解锁</p>
</li>
</ol>
<p>整个过程看起来比较像ArrayList的扩容。有了这个基础，我们再来看一下第5行的add了一个整数2做了什么，这应该非常简单了，还是画一张图来表示：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/CopyOnWriteArrayList/4.png/w600">

<p>和前面差不多，就不解释了。</p>
<p>另外，插入、删除、修改操作也都是一样，每一次的操作都是以对Object[] array进行一次复制为基础的，如果上面的流程看懂了，那么研究插入、删除、修改的源代码应该不难。</p>
<h1 id="普通List的缺陷"><a href="#普通List的缺陷" class="headerlink" title="普通List的缺陷"></a><strong>普通List的缺陷</strong></h1><p>常用的List有ArrayList、LinkedList、Vector，其中前两个是线程非安全的，最后一个是线程安全的。我有一种场景，两个线程操作了同一个List，分别对同一个List进行迭代和删除，就如同下面的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">T1</span> <span class="keyword">extends</span> <span class="title">Thread</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> List&lt;Integer&gt; list;&amp;nbsp;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">T1</span><span class="params">(List&lt;Integer&gt; list)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">this</span>.list = list;</span><br><span class="line">&#125;&amp;nbsp;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (Integer i : list)&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">T2</span> <span class="keyword">extends</span> <span class="title">Thread</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> List&lt;Integer&gt; list;&amp;nbsp;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">T2</span><span class="params">(List&lt;Integer&gt; list)</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">this</span>.list = list;</span><br><span class="line">&#125;&amp;nbsp;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; list.size(); i++)&#123;</span><br><span class="line">  list.remove(i);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先我在这两个线程中放入ArrayList并启动这两个线程：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">List&lt;Integer&gt; list = <span class="keyword">new</span> ArrayList&lt;Integer&gt;();&amp;nbsp;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++)&#123;</span><br><span class="line">list.add(i);</span><br><span class="line">&#125;&amp;nbsp;</span><br><span class="line">T1 t1 = <span class="keyword">new</span> T1(list);</span><br><span class="line">T2 t2 = <span class="keyword">new</span> T2(list);</span><br><span class="line">t1.start();</span><br><span class="line">t2.start();&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;Thread-0&quot; java.util.ConcurrentModificationException</span><br><span class="line">at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)</span><br><span class="line">at java.util.AbstractList$Itr.next(AbstractList.java:343)</span><br><span class="line">at com.xrq.test60.TestMain$T1.run(TestMain.java:19)</span><br></pre></td></tr></table></figure>


<p>把ArrayList换成LinkedList，main函数的代码就不贴了，运行结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;Thread-0&quot; java.util.ConcurrentModificationException</span><br><span class="line">at java.util.LinkedList$ListItr.checkForComodification(LinkedList.java:761)</span><br><span class="line">at java.util.LinkedList$ListItr.next(LinkedList.java:696)</span><br><span class="line">at com.xrq.test60.TestMain$T1.run(TestMain.java:19)</span><br></pre></td></tr></table></figure>


<p>可能有人觉得，这两个线程都是线程非安全的类，所以不行。其实这个问题和线程安不安全没有关系，换成Vector看一下运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;Thread-0&quot; java.util.ConcurrentModificationException</span><br><span class="line">at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)</span><br><span class="line">at java.util.AbstractList$Itr.next(AbstractList.java:343)</span><br><span class="line">at com.xrq.test60.TestMain$T1.run(TestMain.java:19)</span><br></pre></td></tr></table></figure>
<p>Vector虽然是线程安全的，但是只是一种相对的线程安全而不是绝对的线程安全，它只能够保证增、删、改、查的单个操作一定是原子的，不会被打断，但是如果组合起来用，并不能保证线程安全性。比如就像上面的线程1在遍历一个Vector中的元素、线程2在删除一个Vector中的元素一样，势必产生并发修改异常，也就是fail-fast。</p>
<h1 id="CopyOnWriteArrayList的作用"><a href="#CopyOnWriteArrayList的作用" class="headerlink" title="CopyOnWriteArrayList的作用"></a><strong>CopyOnWriteArrayList的作用</strong></h1><p>把上面的代码修改一下，用CopyOnWriteArrayList：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">List&lt;Integer&gt; list = <span class="keyword">new</span> CopyOnWriteArrayList&lt;Integer&gt;();&amp;nbsp;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)&#123;</span><br><span class="line">list.add(i);</span><br><span class="line">&#125;&amp;nbsp;</span><br><span class="line">T1 t1 = <span class="keyword">new</span> T1(list);</span><br><span class="line">T2 t2 = <span class="keyword">new</span> T2(list);</span><br><span class="line">t1.start();</span><br><span class="line">t2.start();&#125;</span><br></pre></td></tr></table></figure>
<p>可以运行一下这段代码，是没有任何问题的。</p>
<p>看到我把元素数量改小了一点，因为我们从上面的分析中应该可以看出，CopyOnWriteArrayList的缺点，就是修改代价十分昂贵，每次修改都伴随着一次的数组复制；但同时优点也十分明显，就是在并发下不会产生任何的线程安全问题，也就是绝对的线程安全，这也是为什么我们要使用CopyOnWriteArrayList的原因。</p>
<p>另外，有两点必须讲一下。我认为CopyOnWriteArrayList这个并发组件，其实反映的是两个十分重要的分布式理念：</p>
<h2 id="（1）读写分离"><a href="#（1）读写分离" class="headerlink" title="（1）读写分离"></a><strong>（1）读写分离</strong></h2><p>我们读取CopyOnWriteArrayList的时候读取的是CopyOnWriteArrayList中的Object[] array，但是修改的时候，操作的是一个新的Object[] array，读和写操作的不是同一个对象，这就是读写分离。这种技术数据库用的非常多，在高并发下为了缓解数据库的压力，即使做了缓存也要对数据库做读写分离，读的时候使用读库，写的时候使用写库，然后读库、写库之间进行一定的同步，这样就避免同一个库上读、写的IO操作太多</p>
<h2 id="（2）最终一致"><a href="#（2）最终一致" class="headerlink" title="（2）最终一致"></a><strong>（2）最终一致</strong></h2><p>对CopyOnWriteArrayList来说，线程1读取集合里面的数据，未必是最新的数据。因为线程2、线程3、线程4四个线程都修改了CopyOnWriteArrayList里面的数据，但是线程1拿到的还是最老的那个Object[] array，新添加进去的数据并没有，所以线程1读取的内容未必准确。不过这些数据虽然对于线程1是不一致的，但是对于之后的线程一定是一致的，它们拿到的Object[] array一定是三个线程都操作完毕之后的Object array[]，这就是最终一致。最终一致对于分布式系统也非常重要，它通过容忍一定时间的数据不一致，提升整个分布式系统的可用性与分区容错性。当然，最终一致并不是任何场景都适用的，像火车站售票这种系统用户对于数据的实时性要求非常非常高，就必须做成强一致性的。</p>
<p>最后总结一点，随着CopyOnWriteArrayList中元素的增加，CopyOnWriteArrayList的修改代价将越来越昂贵，因此，CopyOnWriteArrayList适用于读操作远多于修改操作的并发场景中。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 并发包ConcurrentHashMap图解下</title>
    <url>/java/ConcurrentHashMap2/</url>
    <content><![CDATA[<p>现在我们来对每一步的细节进行源码分析，在第一步中，符合条件会进行初始化操作，我们来看看initTable（）方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Initializes table, using the size recorded in sizeCtl.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Node&lt;K,V&gt;[] initTable() &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; <span class="keyword">int</span> sc;</span><br><span class="line">    <span class="keyword">while</span> ((tab = table) == <span class="keyword">null</span> || tab.length == <span class="number">0</span>) &#123;<span class="comment">//空的table才能进入初始化操作</span></span><br><span class="line">        <span class="keyword">if</span> ((sc = sizeCtl) &lt; <span class="number">0</span>) <span class="comment">//sizeCtl&lt;0表示其他线程已经在初始化了或者扩容了，挂起当前线程 </span></span><br><span class="line">            Thread.yield(); <span class="comment">// lost initialization race; just spin</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, -<span class="number">1</span>)) &#123;<span class="comment">//CAS操作SIZECTL为-1，表示初始化状态</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || tab.length == <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">int</span> n = (sc &gt; <span class="number">0</span>) ? sc : DEFAULT_CAPACITY;</span><br><span class="line"></span><br><span class="line">                    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"></span><br><span class="line">                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node&lt;?,?&gt;[n];<span class="comment">//初始化</span></span><br><span class="line"></span><br><span class="line">                    table = tab = nt;</span><br><span class="line"></span><br><span class="line">                    sc = n - (n &gt;&gt;&gt; <span class="number">2</span>);<span class="comment">//记录下次扩容的大小</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                sizeCtl = sc;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> tab;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在第二步中没有hash冲突就直接调用Unsafe的方法CAS插入该元素，进入第三步如果容器正在扩容，则会调用helpTransfer（）方法帮助扩容，现在我们跟进helpTransfer（）方法看看</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *帮助从旧的table的元素复制到新的table中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">final</span> Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] nextTab; <span class="keyword">int</span> sc;</span><br><span class="line">    <span class="keyword">if</span> (tab != <span class="keyword">null</span> &amp;&amp; (f <span class="keyword">instanceof</span> ForwardingNode) &amp;&amp;</span><br><span class="line">        (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != <span class="keyword">null</span>) &#123; <span class="comment">//新的table nextTba已经存在前提下才能帮助扩容</span></span><br><span class="line">        <span class="keyword">int</span> rs = resizeStamp(tab.length);</span><br><span class="line">        <span class="keyword">while</span> (nextTab == nextTable &amp;&amp; table == tab &amp;&amp;</span><br><span class="line">               (sc = sizeCtl) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + <span class="number">1</span> ||</span><br><span class="line">                sc == rs + MAX_RESIZERS || transferIndex &lt;= <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, sc + <span class="number">1</span>)) &#123;</span><br><span class="line">                transfer(tab, nextTab);<span class="comment">//调用扩容方法</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nextTab;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> table;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其实helpTransfer（）方法的目的就是调用多个工作线程一起帮助进行扩容，这样的效率就会更高，而不是只有检查到要扩容的那个线程进行扩容操作，其他线程就要等待扩容操作完成才能工作。</p>
<p>既然这里涉及到扩容的操作，我们也一起来看看扩容方法transfer（）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = tab.length, stride;</span><br><span class="line">    <span class="comment">// 每核处理的量小于16，则强制赋值16</span></span><br><span class="line">    <span class="keyword">if</span> ((stride = (NCPU &gt; <span class="number">1</span>) ? (n &gt;&gt;&gt; <span class="number">3</span>) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)</span><br><span class="line">        stride = MIN_TRANSFER_STRIDE; <span class="comment">// subdivide range</span></span><br><span class="line">    <span class="keyword">if</span> (nextTab == <span class="keyword">null</span>) &#123;            <span class="comment">// initiating</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node&lt;?,?&gt;[n &lt;&lt; <span class="number">1</span>];        <span class="comment">//构建一个nextTable对象，其容量为原来容量的两倍</span></span><br><span class="line">            nextTab = nt;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable ex) &#123;      <span class="comment">// try to cope with OOME</span></span><br><span class="line">            sizeCtl = Integer.MAX_VALUE;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        nextTable = nextTab;</span><br><span class="line">        transferIndex = n;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> nextn = nextTab.length;</span><br><span class="line">    <span class="comment">// 连接点指针，用于标志位（fwd的hash值为-1，fwd.nextTable=nextTab）</span></span><br><span class="line">    ForwardingNode&lt;K,V&gt; fwd = <span class="keyword">new</span> ForwardingNode&lt;K,V&gt;(nextTab);</span><br><span class="line">    <span class="comment">// 当advance == true时，表明该节点已经处理过了</span></span><br><span class="line">    <span class="keyword">boolean</span> advance = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">boolean</span> finishing = <span class="keyword">false</span>; <span class="comment">// to ensure sweep before committing nextTab</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, bound = <span class="number">0</span>;;) &#123;</span><br><span class="line">        Node&lt;K,V&gt; f; <span class="keyword">int</span> fh;</span><br><span class="line">        <span class="comment">// 控制 --i ,遍历原hash表中的节点</span></span><br><span class="line">        <span class="keyword">while</span> (advance) &#123;</span><br><span class="line">            <span class="keyword">int</span> nextIndex, nextBound;</span><br><span class="line">            <span class="keyword">if</span> (--i &gt;= bound || finishing)</span><br><span class="line">                advance = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((nextIndex = transferIndex) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">                i = -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">                advance = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 用CAS计算得到的transferIndex</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt</span><br><span class="line">                    (<span class="keyword">this</span>, TRANSFERINDEX, nextIndex,</span><br><span class="line">                            nextBound = (nextIndex &gt; stride ?</span><br><span class="line">                                    nextIndex - stride : <span class="number">0</span>))) &#123;</span><br><span class="line">                bound = nextBound;</span><br><span class="line">                i = nextIndex - <span class="number">1</span>;</span><br><span class="line">                advance = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i &lt; <span class="number">0</span> || i &gt;= n || i + n &gt;= nextn) &#123;</span><br><span class="line">            <span class="keyword">int</span> sc;</span><br><span class="line">            <span class="comment">// 已经完成所有节点复制了</span></span><br><span class="line">            <span class="keyword">if</span> (finishing) &#123;</span><br><span class="line">                nextTable = <span class="keyword">null</span>;</span><br><span class="line">                table = nextTab;        <span class="comment">// table 指向nextTable</span></span><br><span class="line">                sizeCtl = (n &lt;&lt; <span class="number">1</span>) - (n &gt;&gt;&gt; <span class="number">1</span>);     <span class="comment">// sizeCtl阈值为原来的1.5倍</span></span><br><span class="line">                <span class="keyword">return</span>;     <span class="comment">// 跳出死循环，</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// CAS 更扩容阈值，在这里面sizectl值减一，说明新加入一个线程参与到扩容操作</span></span><br><span class="line">            <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc = sizeCtl, sc - <span class="number">1</span>)) &#123;</span><br><span class="line">                <span class="keyword">if</span> ((sc - <span class="number">2</span>) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                finishing = advance = <span class="keyword">true</span>;</span><br><span class="line">                i = n; <span class="comment">// recheck before commit</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 遍历的节点为null，则放入到ForwardingNode 指针节点</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((f = tabAt(tab, i)) == <span class="keyword">null</span>)</span><br><span class="line">            advance = casTabAt(tab, i, <span class="keyword">null</span>, fwd);</span><br><span class="line">        <span class="comment">// f.hash == -1 表示遍历到了ForwardingNode节点，意味着该节点已经处理过了</span></span><br><span class="line">        <span class="comment">// 这里是控制并发扩容的核心</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((fh = f.hash) == MOVED)</span><br><span class="line">            advance = <span class="keyword">true</span>; <span class="comment">// already processed</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 节点加锁</span></span><br><span class="line">            <span class="keyword">synchronized</span> (f) &#123;</span><br><span class="line">                <span class="comment">// 节点复制工作</span></span><br><span class="line">                <span class="keyword">if</span> (tabAt(tab, i) == f) &#123;</span><br><span class="line">                    Node&lt;K,V&gt; ln, hn;</span><br><span class="line">                    <span class="comment">// fh &gt;= 0 ,表示为链表节点</span></span><br><span class="line">                    <span class="keyword">if</span> (fh &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                        <span class="comment">// 构造两个链表  一个是原链表  另一个是原链表的反序排列</span></span><br><span class="line">                        <span class="keyword">int</span> runBit = fh &amp; n;</span><br><span class="line">                        Node&lt;K,V&gt; lastRun = f;</span><br><span class="line">                        <span class="keyword">for</span> (Node&lt;K,V&gt; p = f.next; p != <span class="keyword">null</span>; p = p.next) &#123;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">int</span> b = p.hash &amp; n;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">if</span> (b != runBit) &#123;</span><br><span class="line"></span><br><span class="line">                                runBit = b;</span><br><span class="line"></span><br><span class="line">                                lastRun = p;</span><br><span class="line"></span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> (runBit == <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">                            ln = lastRun;</span><br><span class="line"></span><br><span class="line">                            hn = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">                            hn = lastRun;</span><br><span class="line"></span><br><span class="line">                            ln = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">for</span> (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">int</span> ph = p.hash; K pk = p.key; V pv = p.val;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">if</span> ((ph &amp; n) == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                                ln = <span class="keyword">new</span> Node&lt;K,V&gt;(ph, pk, pv, ln);</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">                                hn = <span class="keyword">new</span> Node&lt;K,V&gt;(ph, pk, pv, hn);</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// 在nextTable i 位置处插上链表</span></span><br><span class="line">                        setTabAt(nextTab, i, ln);</span><br><span class="line">                        <span class="comment">// 在nextTable i + n 位置处插上链表</span></span><br><span class="line">                        setTabAt(nextTab, i + n, hn);</span><br><span class="line">                        <span class="comment">// 在table i 位置处插上ForwardingNode 表示该节点已经处理过了</span></span><br><span class="line">                        setTabAt(tab, i, fwd);</span><br><span class="line">                        <span class="comment">// advance = true 可以执行--i动作，遍历节点</span></span><br><span class="line">                        advance = <span class="keyword">true</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">// 如果是TreeBin，则按照红黑树进行处理，处理逻辑与上面一致</span></span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (f <span class="keyword">instanceof</span> TreeBin) &#123;</span><br><span class="line">                        TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;</span><br><span class="line"></span><br><span class="line">                        TreeNode&lt;K,V&gt; lo = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">                        TreeNode&lt;K,V&gt; hi = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">int</span> lc = <span class="number">0</span>, hc = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">for</span> (Node&lt;K,V&gt; e = t.first; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">int</span> h = e.hash;</span><br><span class="line"></span><br><span class="line">                            TreeNode&lt;K,V&gt; p = <span class="keyword">new</span> TreeNode&lt;K,V&gt;</span><br><span class="line"></span><br><span class="line">                                    (h, e.key, e.val, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">if</span> ((h &amp; n) == <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">if</span> ((p.prev = loTail) == <span class="keyword">null</span>)</span><br><span class="line"></span><br><span class="line">                                    lo = p;</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">                                    loTail.next = p;</span><br><span class="line"></span><br><span class="line">                                loTail = p;</span><br><span class="line"></span><br><span class="line">                                ++lc;</span><br><span class="line"></span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">if</span> ((p.prev = hiTail) == <span class="keyword">null</span>)</span><br><span class="line"></span><br><span class="line">                                    hi = p;</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">                                    hiTail.next = p;</span><br><span class="line"></span><br><span class="line">                                hiTail = p;</span><br><span class="line"></span><br><span class="line">                                ++hc;</span><br><span class="line"></span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// 扩容后树节点个数若&lt;=6，将树转链表</span></span><br><span class="line"></span><br><span class="line">                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :</span><br><span class="line"></span><br><span class="line">                                (hc != <span class="number">0</span>) ? <span class="keyword">new</span> TreeBin&lt;K,V&gt;(lo) : t;</span><br><span class="line"></span><br><span class="line">                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :</span><br><span class="line"></span><br><span class="line">                                (lc != <span class="number">0</span>) ? <span class="keyword">new</span> TreeBin&lt;K,V&gt;(hi) : t;</span><br><span class="line">                        setTabAt(nextTab, i, ln);</span><br><span class="line">                        setTabAt(nextTab, i + n, hn);</span><br><span class="line">                        setTabAt(tab, i, fwd);</span><br><span class="line">                        advance = <span class="keyword">true</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>扩容过程有点复杂，这里主要涉及到多线程并发扩容,ForwardingNode的作用就是支持扩容操作，将已处理的节点和空节点置为ForwardingNode，并发处理时多个线程经过ForwardingNode就表示已经遍历了，就往后遍历，下图是多线程合作扩容的过程：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/ConcurrentHashMap2/1.png/w600">

<p>介绍完扩容过程，我们再次回到put流程，在第四步中是向链表或者红黑树里加节点，到第五步，会调用treeifyBin（）方法进行链表转红黑树的过程。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">treeifyBin</span><span class="params">(Node&lt;K,V&gt;[] tab, <span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Node&lt;K,V&gt; b; <span class="keyword">int</span> n, sc;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tab != <span class="keyword">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果整个table的数量小于64，就扩容至原来的一倍，不转红黑树了</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//因为这个阈值扩容可以减少hash冲突，不必要去转红黑树</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) </span><br><span class="line"></span><br><span class="line">            tryPresize(n &lt;&lt; <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((b = tabAt(tab, index)) != <span class="keyword">null</span> &amp;&amp; b.hash &gt;= <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">synchronized</span> (b) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (tabAt(tab, index) == b) &#123;</span><br><span class="line"></span><br><span class="line">                    TreeNode&lt;K,V&gt; hd = <span class="keyword">null</span>, tl = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">for</span> (Node&lt;K,V&gt; e = b; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">//封装成TreeNode</span></span><br><span class="line"></span><br><span class="line">                        TreeNode&lt;K,V&gt; p =</span><br><span class="line"></span><br><span class="line">                            <span class="keyword">new</span> TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,</span><br><span class="line"></span><br><span class="line">                                              <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> ((p.prev = tl) == <span class="keyword">null</span>)</span><br><span class="line"></span><br><span class="line">                            hd = p;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">                            tl.next = p;</span><br><span class="line"></span><br><span class="line">                        tl = p;</span><br><span class="line"></span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">//通过TreeBin对象对TreeNode转换成红黑树</span></span><br><span class="line">                    setTabAt(tab, index, <span class="keyword">new</span> TreeBin&lt;K,V&gt;(hd));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>到第六步表示已经数据加入成功了，现在调用addCount()方法计算ConcurrentHashMap的size，在原来的基础上加一，现在来看看addCount()方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">addCount</span><span class="params">(<span class="keyword">long</span> x, <span class="keyword">int</span> check)</span> </span>&#123;</span><br><span class="line">    CounterCell[] as; <span class="keyword">long</span> b, s;</span><br><span class="line">    <span class="comment">//更新baseCount，table的数量，counterCells表示元素个数的变化</span></span><br><span class="line">    <span class="keyword">if</span> ((as = counterCells) != <span class="keyword">null</span> ||</span><br><span class="line">        !U.compareAndSwapLong(<span class="keyword">this</span>, BASECOUNT, b = baseCount, s = b + x)) &#123;</span><br><span class="line">        CounterCell a; <span class="keyword">long</span> v; <span class="keyword">int</span> m;</span><br><span class="line">        <span class="keyword">boolean</span> uncontended = <span class="keyword">true</span>;</span><br><span class="line">        <span class="comment">//如果多个线程都在执行，则CAS失败，执行fullAddCount，全部加入count</span></span><br><span class="line">        <span class="keyword">if</span> (as == <span class="keyword">null</span> || (m = as.length - <span class="number">1</span>) &lt; <span class="number">0</span> || </span><br><span class="line">            (a = as[ThreadLocalRandom.getProbe() &amp; m]) == <span class="keyword">null</span> ||</span><br><span class="line">            !(uncontended =</span><br><span class="line">              U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123;</span><br><span class="line">            fullAddCount(x, uncontended);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (check &lt;= <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        s = sumCount();</span><br><span class="line">    &#125;</span><br><span class="line">     <span class="comment">//check&gt;=0表示需要进行扩容操作</span></span><br><span class="line">    <span class="keyword">if</span> (check &gt;= <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">        Node&lt;K,V&gt;[] tab, nt; <span class="keyword">int</span> n, sc;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (s &gt;= (<span class="keyword">long</span>)(sc = sizeCtl) &amp;&amp; (tab = table) != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">               (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123;</span><br><span class="line">            <span class="keyword">int</span> rs = resizeStamp(n);</span><br><span class="line">            <span class="keyword">if</span> (sc &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + <span class="number">1</span> ||</span><br><span class="line"></span><br><span class="line">                    sc == rs + MAX_RESIZERS || (nt = nextTable) == <span class="keyword">null</span> ||</span><br><span class="line"></span><br><span class="line">                    transferIndex &lt;= <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc, sc + <span class="number">1</span>))</span><br><span class="line">                    transfer(tab, nt);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//当前线程发起库哦哦让操作，nextTable=null</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (U.compareAndSwapInt(<span class="keyword">this</span>, SIZECTL, sc,</span><br><span class="line"></span><br><span class="line">                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + <span class="number">2</span>))</span><br><span class="line">                transfer(tab, <span class="keyword">null</span>);</span><br><span class="line">            s = sumCount();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>put的流程现在已经分析完了，你可以从中发现，他在并发处理中使用的是乐观锁，当有冲突的时候才进行并发处理，而且流程步骤很清晰，但是细节设计的很复杂，毕竟多线程的场景也复杂。</p>
<h2 id="get操作"><a href="#get操作" class="headerlink" title="get操作"></a><strong>get操作</strong></h2><p>我们现在要回到开始的例子中，我们对个人信息进行了新增之后，我们要获取所新增的信息，使用String name = map.get(“name”)获取新增的name信息，现在我们依旧用debug的方式来分析下ConcurrentHashMap的获取方法get()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; <span class="keyword">int</span> n, eh; K ek;</span><br><span class="line">    <span class="keyword">int</span> h = spread(key.hashCode()); <span class="comment">//计算两次hash</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">        (e = tabAt(tab, (n - <span class="number">1</span>) &amp; h)) != <span class="keyword">null</span>) &#123;<span class="comment">//读取首节点的Node元素</span></span><br><span class="line">        <span class="keyword">if</span> ((eh = e.hash) == h) &#123; <span class="comment">//如果该节点就是首节点就返回</span></span><br><span class="line">            <span class="keyword">if</span> ((ek = e.key) == key || (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek)))</span><br><span class="line">                <span class="keyword">return</span> e.val;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//hash值为负值表示正在扩容，这个时候查的是ForwardingNode的find方法来定位到nextTable来</span></span><br><span class="line">        <span class="comment">//查找，查找到就返回</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (eh &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> (p = e.find(h, key)) != <span class="keyword">null</span> ? p.val : <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>) &#123;<span class="comment">//既不是首节点也不是ForwardingNode，那就往下遍历</span></span><br><span class="line">            <span class="keyword">if</span> (e.hash == h &amp;&amp;</span><br><span class="line">                ((ek = e.key) == key || (ek != <span class="keyword">null</span> &amp;&amp; key.equals(ek))))</span><br><span class="line">                <span class="keyword">return</span> e.val;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ConcurrentHashMap的get操作的流程很简单，也很清晰，可以分为三个步骤来描述：</p>
<ol>
<li>计算hash值，定位到该table索引位置，如果是首节点符合就返回1. 如果遇到扩容的时候，会调用标志正在扩容节点ForwardingNode的find方法，查找该节点，匹配就返回1. 以上都不符合的话，就往下遍历节点，匹配就返回，否则最后就返回null<br>如果遇到扩容的时候，会调用标志正在扩容节点ForwardingNode的find方法，查找该节点，匹配就返回</li>
</ol>
<h2 id="size操作"><a href="#size操作" class="headerlink" title="size操作"></a><strong>size操作</strong></h2><p>最后我们来看下例子中最后获取size的方式int size = map.size();，现在让我们看下size()方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> n = sumCount();</span><br><span class="line">    <span class="keyword">return</span> ((n &lt; <span class="number">0L</span>) ? <span class="number">0</span> :</span><br><span class="line">            (n &gt; (<span class="keyword">long</span>)Integer.MAX_VALUE) ? Integer.MAX_VALUE :</span><br><span class="line">            (<span class="keyword">int</span>)n);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">long</span> <span class="title">sumCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    CounterCell[] as = counterCells; CounterCell a; <span class="comment">//变化的数量</span></span><br><span class="line">    <span class="keyword">long</span> sum = baseCount;</span><br><span class="line">    <span class="keyword">if</span> (as != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; as.length; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((a = as[i]) != <span class="keyword">null</span>)</span><br><span class="line">                sum += a.value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在JDK1.8版本中，对于size的计算，在扩容和addCount()方法就已经有处理了，JDK1.7是在调用size()方法才去计算，其实在并发集合中去计算size是没有多大的意义的，因为size是实时在变的，只能计算某一刻的大小，但是某一刻太快了，人的感知是一个时间段，所以并不是很精确。</p>
<h2 id="总结与思考"><a href="#总结与思考" class="headerlink" title="总结与思考"></a><strong>总结与思考</strong></h2><p>其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树,相对而言，总结如下思考：</p>
<ol>
<li><p>JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）</p>
</li>
<li><p>JDK1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了</p>
</li>
<li><p>JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档</p>
</li>
<li><p>JDK1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点：</p>
<ul>
<li><p>因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了</p>
</li>
<li><p>JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然</p>
</li>
<li><p>在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存，虽然不是瓶颈，但是也是一个选择依据</p>
</li>
</ul>
</li>
</ol>
<p><strong>参考</strong><br><a href="https://bentang.me/tech/2016/12/01/jdk8-concurrenthashmap-1/" target="_blank" rel="noopener">https://bentang.me/tech/2016/12/01/jdk8-concurrenthashmap-1/</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM内存模型、指令重排、内存屏障概念解析</title>
    <url>/java/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B,%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92,%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/</url>
    <content><![CDATA[<p>在高并发模型中，无是面对物理机SMP系统模型，还是面对像JVM的虚拟机多线程并发内存模型，指令重排(编译器、运行时)和内存屏障都是非常重要的概念，因此，搞清楚这些概念和原理很重要。否则，你很难搞清楚:</p>
<ul>
<li>哪些操作是在并发先绝对安全的？</li>
<li>哪些是相对安全的？</li>
<li>哪些并发同步手段性能最低？</li>
<li>valotile的二层语义分别是什么？<br>…</li>
</ul>
<h1 id="一、什么是重排序"><a href="#一、什么是重排序" class="headerlink" title="一、什么是重排序"></a>一、什么是重排序</h1><p>请先看这样一段代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PossibleReordering</span> </span>&#123;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> x = <span class="number">0</span>, y = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">0</span>, b = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    Thread one = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            a = <span class="number">1</span>;</span><br><span class="line">            x = b;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    Thread other = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            b = <span class="number">1</span>;</span><br><span class="line">            y = a;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    one.start();</span><br><span class="line">    other.start();</span><br><span class="line">    one.join();</span><br><span class="line">    other.join();</span><br><span class="line">    System.out.println(“(” + x + “,” + y + “)”);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>很容易想到这段代码的运行结果可能为(1,0)、(0,1)或(1,1)，因为线程one可以在线程two开始之前就执行完了，也有可能反之，甚至有可能二者的指令是同时或交替执行的。</p>
<p>然而，这段代码的执行结果也可能是(0,0). 因为，在实际运行时，代码指令可能并不是严格按照代码语句顺序执行的。得到(0,0)结果的语句执行过程，如下图所示。值得注意的是，a=1和x=b这两个语句的赋值操作的顺序被颠倒了，或者说，发生了指令&ldquo;重排序&rdquo;(reordering)。（事实上，输出了这一结果，并不代表一定发生了指令重排序，内存可见性问题也会导致这样的输出，详见后文）</p>
<p>对重排序现象不太了解的开发者可能会对这种现象感到吃惊，但是，笔者开发环境下做的一个小实验证实了这一结果。</p>
<p>实验代码是构造一个循环，反复执行上面的实例代码，直到出现a=0且b=0的输出为止。实验结果说明，循环执行到第13830次时输出了(0,0)。</p>
<p>大多数现代微处理器都会采用将指令乱序执行（out-of-order execution，简称OoOE或OOE）的方法，在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避开获取下一条指令所需数据时造成的等待3。通过乱序执行的技术，处理器可以大大提高执行效率。<br>除了处理器，常见的Java运行时环境的JIT编译器也会做指令重排序操作，即生成的机器指令与字节码指令顺序不一致。</p>
<h1 id="二、as-if-serial语义"><a href="#二、as-if-serial语义" class="headerlink" title="二、as-if-serial语义"></a>二、as-if-serial语义</h1><p>As-if-serial语义的意思是，所有的动作(Action)都可以为了优化而被重排序，但是必须保证它们重排序后的结果和程序代码本身的应有结果是一致的。Java编译器、运行时和处理器都会保证单线程下的as-if-serial语义。<br>比如，为了保证这一语义，重排序不会发生在有数据依赖的操作之中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> b = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> c = a + b;</span><br></pre></td></tr></table></figure>
<p>将上面的代码编译成Java字节码或生成机器指令，可视为展开成了以下几步动作（实际可能会省略或添加某些步骤）。</p>
<ol>
<li>对a赋值1</li>
<li>对b赋值2</li>
<li>取a的值</li>
<li>取b的值</li>
<li>将取到两个值相加后存入c</li>
</ol>
<p>在上面5个动作中，</p>
<ul>
<li>动作1可能会和动作2、4重排序，</li>
<li>动作2可能会和动作1、3重排序，</li>
<li>动作3可能会和动作2、4重排序，</li>
<li>动作4可能会和1、3重排序。</li>
<li>但动作1和动作3、5不能重排序。</li>
<li>动作2和动作4、5不能重排序。</li>
</ul>
<p>因为它们之间存在数据依赖关系，一旦重排，as-if-serial语义便无法保证。</p>
<p>为保证as-if-serial语义，Java异常处理机制也会为重排序做一些特殊处理。例如在下面的代码中，y = 0 / 0可能会被重排序在x = 2之前执行，为了保证最终不致于输出x = 1的错误结果，JIT在重排序时会在catch语句中插入错误代偿代码，将x赋值为2，将程序恢复到发生异常时应有的状态。这种做法的确将异常捕捉的逻辑变得复杂了，但是JIT的优化的原则是，尽力优化正常运行下的代码逻辑，哪怕以catch块逻辑变得复杂为代价，毕竟，进入catch块内是一种&ldquo;异常&rdquo;情况的表现。</p>
<h1 id="三、内存访问重排序与内存可见性"><a href="#三、内存访问重排序与内存可见性" class="headerlink" title="三、内存访问重排序与内存可见性"></a>三、内存访问重排序与内存可见性</h1><p>计算机系统中，为了尽可能地避免处理器访问主内存的时间开销，处理器大多会利用缓存(cache)以提高性能。其模型如下图所示。</p>
<p>在这种模型下会存在一个现象，即缓存中的数据与主内存的数据并不是实时同步的，各CPU（或CPU核心）间缓存的数据也不是实时同步的。这导致在同一个时间点，各CPU所看到同一内存地址的数据的值可能是不一致的。从程序的视角来看，就是在同一个时间点，各个线程所看到的共享变量的值可能是不一致的。</p>
<p>有的观点会将这种现象也视为重排序的一种，命名为&ldquo;内存系统重排序&rdquo;。因为这种内存可见性问题造成的结果就好像是内存访问指令发生了重排序一样。</p>
<p>这种内存可见性问题也会导致章节一中示例代码即便在没有发生指令重排序的情况下的执行结果也还是(0, 0)。</p>
<h1 id="四、内存访问重排序与Java内存模型"><a href="#四、内存访问重排序与Java内存模型" class="headerlink" title="四、内存访问重排序与Java内存模型"></a>四、内存访问重排序与Java内存模型</h1><p>Java的目标是成为一门平台无关性的语言，即Write once, run anywhere. 但是不同硬件环境下指令重排序的规则不尽相同。例如，x86下运行正常的Java程序在IA64下就可能得到非预期的运行结果。为此，JSR-1337制定了Java内存模型(Java Memory Model, JMM)，旨在提供一个统一的可参考的规范，屏蔽平台差异性。从Java 5开始，Java内存模型成为Java语言规范的一部分。</p>
<p>根据Java内存模型中的规定，可以总结出以下几条happens-before规则。Happens-before的前后两个操作不会被重排序且后者对前者的内存可见。</p>
<ul>
<li><strong>程序次序法则：</strong>线程中的每个动作A都happens-before于该线程中的每一个动作B，其中，在程序中，所有的动作B都能出现在A之后。</li>
<li><strong>监视器锁法则：</strong>对一个监视器锁的解锁 happens-before于每一个后续对同一监视器锁的加锁。</li>
<li><strong>volatile变量法则：</strong>对volatile域的写入操作happens-before于每一个后续对同一个域的读写操作。</li>
<li><strong>线程启动法则：</strong>在一个线程里，对Thread.start的调用会happens-before于每个启动线程的动作。</li>
<li><strong>线程终结法则：</strong>线程中的任何动作都happens-before于其他线程检测到这个线程已经终结、或者从Thread.join调用中成功返回，或Thread.isAlive返回false。</li>
<li><strong>中断法则：</strong>一个线程调用另一个线程的interrupt happens-before于被中断的线程发现中断。</li>
<li><strong>终结法则：</strong>一个对象的构造函数的结束happens-before于这个对象finalizer的开始。</li>
<li><strong>传递性：</strong>如果A happens-before于B，且B happens-before于C，则A happens-before于C</li>
</ul>
<p>Happens-before关系只是对Java内存模型的一种近似性的描述，它并不够严谨，但便于日常程序开发参考使用，关于更严谨的Java内存模型的定义和描述，请阅读JSR-133原文或Java语言规范章节17.4。</p>
<p>除此之外，Java内存模型对volatile和final的语义做了扩展。对volatile语义的扩展保证了volatile变量在一些情况下不会重排序，volatile的64位变量double和long的读取和赋值操作都是原子的。对final语义的扩展保证一个对象的构建方法结束前，所有final成员变量都必须完成初始化（的前提是没有this引用溢出）。</p>
<p>Java内存模型关于重排序的规定，总结后如下表所示。</p>
<p>表中&ldquo;第二项操作&rdquo;的含义是指，第一项操作之后的所有指定操作。如，普通读不能与其之后的所有volatile写重排序。另外，JMM也规定了上述volatile和同步块的规则尽适用于存在多线程访问的情景。例如，若编译器（这里的编译器也包括JIT，下同）证明了一个volatile变量只能被单线程访问，那么就可能会把它做为普通变量来处理。<br />留白的单元格代表允许在不违反Java基本语义的情况下重排序。例如，编译器不会对对同一内存地址的读和写操作重排序，但是允许对不同地址的读和写操作重排序。</p>
<p>除此之外，为了保证final的新增语义。JSR-133对于final变量的重排序也做了限制。</p>
<ul>
<li><p>构建方法内部的final成员变量的存储，并且，假如final成员变量本身是一个引用的话，这个final成员变量可以引用到的一切存储操作，都不能与构建方法外的将当期构建对象赋值于多线程共享变量的存储操作重排序。例如对于如下语句</p>
<p>x.finalField = v; … ;构建方法边界sharedRef = x;<br>v.afield = 1; x.finalField = v; … ; 构建方法边界sharedRef = x;<br>这两条语句中，构建方法边界前后的指令都不能重排序。</p>
</li>
<li><p>初始读取共享对象与初始读取该共享对象的final成员变量之间不能重排序。例如对于如下语句<br>x = sharedRef; … ; i = x.finalField;<br>前后两句语句之间不会发生重排序。由于这两句语句有数据依赖关系，编译器本身就不会对它们重排序，但确实有一些处理器会对这种情况重排序，因此特别制定了这一规则。</p>
</li>
</ul>
<h1 id="五、内存屏障"><a href="#五、内存屏障" class="headerlink" title="五、内存屏障"></a>五、内存屏障</h1><p>内存屏障（Memory Barrier，或有时叫做内存栅栏，Memory Fence）是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。</p>
<p>内存屏障可以被分为以下几种类型</p>
<ul>
<li><strong>LoadLoad屏障：</strong>对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li>
<li><strong>StoreStore屏障：</strong>对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li>
<li><strong>LoadStore屏障：</strong>对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li>
<li><strong>StoreLoad屏障：</strong>对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。 在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。</li>
</ul>
<p>&nbsp;有的处理器的重排序规则较严，无需内存屏障也能很好的工作，Java编译器会在这种情况下不放置内存屏障。<br>&nbsp;为了实现上一章中讨论的JSR-133的规定，Java编译器会这样使用内存屏障。</p>
<p>为了保证final字段的特殊语义，也会在下面的语句加入内存屏障。<br>x.finalField = v; StoreStore; sharedRef = x;</p>
<h1 id="六、Intel-64-IA-32架构下的内存访问重排序"><a href="#六、Intel-64-IA-32架构下的内存访问重排序" class="headerlink" title="六、Intel 64/IA-32架构下的内存访问重排序"></a>六、Intel 64/IA-32架构下的内存访问重排序</h1><p>Intel 64和IA-32是我们较常用的硬件环境，相对于其它处理器而言，它们拥有一种较严格的重排序规则。Pentium 4以后的Intel 64或IA-32处理的重排序规则如下。9</p>
<p>在单CPU系统中</p>
<ul>
<li>读操作不与其它读操作重排序。</li>
<li>写操作不与其之前的写操作重排序。</li>
<li>写内存操作不与其它写操作重排序，但有以下几种例外</li>
<li>CLFLUSH的写操作</li>
<li>带有non-temporal move指令(MOVNTI, MOVNTQ, MOVNTDQ, MOVNTPS, and MOVNTPD)的streaming写入。</li>
<li>字符串操作</li>
<li>读操作可能会与其之前的写不同位置的写操作重排序，但不与其之前的写相同位置的写操作重排序。</li>
<li>读和写操作不与I/O指令，带锁的指令或序列化指令重排序。</li>
<li>读操作不能重排序到LFENCE和MFENCE之前。</li>
<li>写操作不能重排序到LFENCE、SFENCE和MFENCE之前。</li>
<li>LFENCE不能重排序到读操作之前。</li>
<li>SFENCE不能重排序到写之前。</li>
<li>MFENCE不能重排序到读或写操作之前。</li>
</ul>
<p>在多处理器系统中</p>
<ul>
<li>各自处理器内部遵循单处理器的重排序规则。</li>
<li>单处理器的写操作对所有处理器可见是同时的。</li>
<li>各自处理器的写操作不会重排序。</li>
<li>内存重排序遵守因果性(causality)（内存重排序遵守传递可见性）。</li>
<li>任何写操作对于执行这些写操作的处理器之外的处理器来看都是一致的。</li>
<li>带锁指令是顺序执行的。</li>
</ul>
<p>值得注意的是，对于Java编译器而言，Intel 64/IA-32架构下处理器不需要LoadLoad、LoadStore、StoreStore屏障，因为不会发生需要这三种屏障的重排序。</p>
<h1 id="七、一例Intel-64-IA-32架构下的代码性能优化"><a href="#七、一例Intel-64-IA-32架构下的代码性能优化" class="headerlink" title="七、一例Intel 64/IA-32架构下的代码性能优化"></a>七、一例Intel 64/IA-32架构下的代码性能优化</h1><p>现在有这样一个场景，一个容器可以放一个东西，容器支持create方法来创建一个新的东西并放到容器里，支持get方法取到这个容器里的东西。我们可以较容易地写出下面的代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Container</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SomeThing</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> status;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">SomeThing</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            status = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getStatus</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> status;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> SomeThing object;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        object = <span class="keyword">new</span> SomeThing();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SomeThing <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (object == <span class="keyword">null</span>) &#123;</span><br><span class="line">            Thread.yield(); <span class="comment">//不加这句话可能会在此出现无限循环</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> object;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在单线程场景下，这段代码执行起来是没有问题的。但是在多线程并发场景下，由不同的线程create和get东西，这段代码是有问题的。问题的原因与普通的双重检查锁定单例模式(Double Checked Locking, DCL)10类似，即SomeThing的构建与将指向构建中的SomeThing引用赋值到object变量这两者可能会发生重排序。导致get中返回一个正被构建中的不完整的SomeThing对象实例。为了解决这一问题，通常的办法是使用volatile修饰object字段。这种方法避免了重排序，保证了内存可见性，摒弃比使用同步块导致的性能损失更小。但是，假如使用场景对object的内存可见性并不敏感的话（不要求一个线程写入了object，object的新值立即对下一个读取的线程可见），在Intel 64/IA-32环境下，有更好的解决方案。</p>
<p>根据上一章的内容，我们知道Intel 64/IA-32下写操作之间不会发生重排序，即在处理器中，构建SomeThing对象与赋值到object这两个操作之间的顺序性是可以保证的。这样看起来，仅仅使用volatile来避免重排序是多此一举的。但是，Java编译器却可能生成重排序后的指令。但令人高兴的是，Oracle的JDK中提供了Unsafe. putOrderedObject，Unsafe. putOrderedInt，Unsafe. putOrderedLong这三个方法，JDK会在执行这三个方法时插入StoreStore内存屏障，避免发生写操作重排序。而在Intel 64/IA-32架构下，StoreStore屏障并不需要，Java编译器会将StoreStore屏障去除。比起写入volatile变量之后执行StoreLoad屏障的巨大开销，采用这种方法除了避免重排序而带来的性能损失以外，不会带来其它的性能开销。<br />我们将做一个小实验来比较二者的性能差异。一种是使用volatile修饰object成员变量。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Container</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SomeThing</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> status;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">SomeThing</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            status = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getStatus</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> status;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span>  SomeThing object;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        object = <span class="keyword">new</span> SomeThing();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SomeThing <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (object == <span class="keyword">null</span>) &#123;</span><br><span class="line">            Thread.yield(); <span class="comment">//不加这句话可能会在此出现无限循环</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> object;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一种是利用Unsafe. putOrderedObject在避免在适当的位置发生重排序。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Container</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SomeThing</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> status;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">SomeThing</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            status = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getStatus</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> status;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> SomeThing object;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Object value;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Unsafe unsafe = getUnsafe();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> valueOffset;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            valueOffset = unsafe.objectFieldOffset(Container.class.getDeclaredField("value"));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123; <span class="keyword">throw</span> <span class="keyword">new</span> Error(ex); &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        SomeThing temp = <span class="keyword">new</span> SomeThing();</span><br><span class="line">        unsafe.putOrderedObject(<span class="keyword">this</span>, valueOffset, <span class="keyword">null</span>);    <span class="comment">//将value赋null值只是一项无用操作，实际利用的是这条语句的内存屏障</span></span><br><span class="line">        object = temp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SomeThing <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (object == <span class="keyword">null</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> object;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Unsafe <span class="title">getUnsafe</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Field f = Unsafe.class.getDeclaredField("theUnsafe");</span><br><span class="line">            f.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">return</span> (Unsafe)f.get(<span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于直接调用Unsafe.getUnsafe()需要配置JRE获取较高权限，我们利用反射获取Unsafe中的theUnsafe来取得Unsafe的可用实例。<br />unsafe.putOrderedObject(this, valueOffset, null)<br />这句仅仅是为了借用这句话功能的防止写重排序，除此之外无其它作用。</p>
<p>利用下面的代码分别测试两种方案的实际运行时间。在运行时开启-server和 -XX:CompileThreshold=1以模拟生产环境下长时间运行后的JIT优化效果。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> THREADS_COUNT = <span class="number">20</span>;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> LOOP_COUNT = <span class="number">100000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">long</span> min = Integer.MAX_VALUE;</span><br><span class="line">    <span class="keyword">long</span> max = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> n = <span class="number">0</span>;n &lt;= <span class="number">100</span>;n++) &#123;</span><br><span class="line">        <span class="keyword">final</span> Container basket = <span class="keyword">new</span> Container();</span><br><span class="line">        List&lt;Thread&gt; putThreads = <span class="keyword">new</span> ArrayList&lt;Thread&gt;();</span><br><span class="line">        List&lt;Thread&gt; takeThreads = <span class="keyword">new</span> ArrayList&lt;Thread&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREADS_COUNT; i++) &#123;</span><br><span class="line">            putThreads.add(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; LOOP_COUNT; j++) &#123;</span><br><span class="line">                        basket.create();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            takeThreads.add(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; LOOP_COUNT; j++) &#123;</span><br><span class="line">                        basket.get().getStatus();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREADS_COUNT; i++) &#123;</span><br><span class="line">            takeThreads.get(i).start();</span><br><span class="line">            putThreads.get(i).start();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREADS_COUNT; i++) &#123;</span><br><span class="line">            takeThreads.get(i).join();</span><br><span class="line">            putThreads.get(i).join();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> end = System.nanoTime();</span><br><span class="line">        <span class="keyword">long</span> period = end - start;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;    <span class="comment">//由于JIT的编译，第一次执行需要更多时间，将此时间不计入统计</span></span><br><span class="line">        &#125;</span><br><span class="line">        sum += (period);</span><br><span class="line">        System.out.println(period);</span><br><span class="line">        <span class="keyword">if</span>(period &lt; min) &#123;</span><br><span class="line">            min = period;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(period &gt; max) &#123;</span><br><span class="line">            max = period;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(<span class="string">"Average : "</span> + sum / <span class="number">100</span>);</span><br><span class="line">    System.out.println(<span class="string">"Max : "</span> + max);</span><br><span class="line">    System.out.println(<span class="string">"Min : "</span> + min);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在笔者的计算机上运行测试，采用volatile方案的运行结果如下<br>Average : 62535770<br>Max : 82515000<br>Min : 45161000</p>
<p>采用unsafe.putOrderedObject方案的运行结果如下<br>Average : 50746230<br>Max : 68999000<br>Min : 38038000</p>
<p>从结果看出，unsafe.putOrderedObject方案比volatile方案平均耗时减少18.9%，最大耗时减少16.4%，最小耗时减少15.8%.另外，即使在其它会发生写写重排序的处理器中，由于StoreStore屏障的性能损耗小于StoreLoad屏障，采用这一方法也是一种可行的方案。但值得再次注意的是，这一方案不是对volatile语义的等价替换，而是在特定场景下做的特殊优化，它仅避免了写写重排序，但不保证内存可见性。</p>
<p>&nbsp;</p>
<h2 id="附1-复现重排序现象实验代码"><a href="#附1-复现重排序现象实验代码" class="headerlink" title="附1 复现重排序现象实验代码**"></a>附1 复现重排序现象实验代码**</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> x = <span class="number">0</span>, y = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">0</span>, b =<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(;;) &#123;</span><br><span class="line">            i++;</span><br><span class="line">            x = <span class="number">0</span>; y = <span class="number">0</span>;</span><br><span class="line">            a = <span class="number">0</span>; b = <span class="number">0</span>;</span><br><span class="line">            Thread one = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="comment">//由于线程one先启动，下面这句话让它等一等线程two. 读着可根据自己电脑的实际性能适当调整等待时间.</span></span><br><span class="line">                    shortWait(<span class="number">100000</span>);</span><br><span class="line">                    a = <span class="number">1</span>;</span><br><span class="line">                    x = b;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">            Thread other = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    b = <span class="number">1</span>;</span><br><span class="line">                    y = a;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            one.start();other.start();</span><br><span class="line">            one.join();other.join();</span><br><span class="line">            String result = <span class="string">"第"</span> + i + <span class="string">"次 ("</span> + x + <span class="string">","</span> + y + <span class="string">"）"</span>;</span><br><span class="line">            <span class="keyword">if</span>(x == <span class="number">0</span> &amp;&amp; y == <span class="number">0</span>) &#123;</span><br><span class="line">                System.err.println(result);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(result);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">shortWait</span><span class="params">(<span class="keyword">long</span> interval)</span></span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line">        <span class="keyword">long</span> end;</span><br><span class="line">        <span class="keyword">do</span>&#123;</span><br><span class="line">            end = System.nanoTime();</span><br><span class="line">        &#125;<span class="keyword">while</span>(start + interval &gt;= end);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK各个版本发布时间和版本名称</title>
    <url>/java/JDK%E5%90%84%E4%B8%AA%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83%E6%97%B6%E9%97%B4%E5%92%8C%E7%89%88%E6%9C%AC%E5%90%8D%E7%A7%B0/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>版本</th>
<th>名称</th>
<th>发行日期</th>
</tr>
</thead>
<tbody><tr>
<td>JDK 1.0</td>
<td>Oak(橡树)</td>
<td>1996-01-23</td>
</tr>
<tr>
<td>JDK 1.1</td>
<td></td>
<td>1997-02-19</td>
</tr>
<tr>
<td>JDK 1.1.4</td>
<td>Sparkler（宝石）</td>
<td>1997-09-12</td>
</tr>
<tr>
<td>JDK 1.1.5</td>
<td>Pumpkin（南瓜）</td>
<td>1997-12-13</td>
</tr>
<tr>
<td>JDK 1.1.6</td>
<td>Abigail（阿比盖尔–女子名）</td>
<td>1998-04-24</td>
</tr>
<tr>
<td>JDK 1.1.7</td>
<td>Brutus（布鲁图–古罗马政治家和将军）</td>
<td>1998-09-28</td>
</tr>
<tr>
<td>JDK 1.1.8</td>
<td>Chelsea（切尔西–城市名）</td>
<td>1999-04-08</td>
</tr>
<tr>
<td>J2SE 1.2</td>
<td>Playground（运动场）</td>
<td>1998-12-04</td>
</tr>
<tr>
<td>J2SE 1.2.1</td>
<td>none（无）</td>
<td>1999-03-30</td>
</tr>
<tr>
<td>J2SE 1.2.2</td>
<td>Cricket（蟋蟀）</td>
<td>1999-07-08</td>
</tr>
<tr>
<td>J2SE 1.3</td>
<td>Kestrel（美洲红隼）</td>
<td>2000-05-08</td>
</tr>
<tr>
<td>J2SE 1.3.1</td>
<td>Ladybird（瓢虫）</td>
<td>2001-05-17</td>
</tr>
<tr>
<td>J2SE 1.4.0</td>
<td>Merlin（灰背隼）</td>
<td>2002-02-13</td>
</tr>
<tr>
<td>J2SE 1.4.1</td>
<td>grasshopper（蚱蜢）</td>
<td>2002-09-16</td>
</tr>
<tr>
<td>J2SE 1.4.2</td>
<td>Mantis（螳螂）</td>
<td>2003-06-26</td>
</tr>
<tr>
<td>Java SE 5.0 (1.5.0)</td>
<td>Tiger（老虎）</td>
<td>2004-09-30</td>
</tr>
<tr>
<td>Java SE 6.0 (1.6.0)</td>
<td>Mustang（野马）</td>
<td>2006-04</td>
</tr>
<tr>
<td>Java SE 7.0 (1.7.0)</td>
<td>Dolphin（海豚）</td>
<td>2011-07-28</td>
</tr>
<tr>
<td>Java SE 8.0 (1.8.0)</td>
<td>Spider（蜘蛛）</td>
<td>2014-03-18</td>
</tr>
<tr>
<td>Java SE 9.0</td>
<td></td>
<td>2017-09-21</td>
</tr>
<tr>
<td>Java SE 10.0</td>
<td></td>
<td>2018-03-21</td>
</tr>
<tr>
<td>Java SE 11.0</td>
<td></td>
<td>2018-09-25</td>
</tr>
<tr>
<td>Java SE 12.0</td>
<td></td>
<td>2019-03-19</td>
</tr>
<tr>
<td>Java SE 13.0</td>
<td></td>
<td>2019-09-08</td>
</tr>
<tr>
<td>Java SE 14.0</td>
<td></td>
<td>2020-03-17</td>
</tr>
</tbody></table>
<p>从这个表中我们可以看出一个非常有意思的现象，就是JDK的每一个版本号都使用一个开发代号表示（就是表中的中文名）。而且从JDK1.2.2 开始,主要版本(如1.3,1.4,5.0)都是以鸟类或哺乳动物来命名的. 而它们的bug修正版本(如1.2.2,1.3.1,1.4.2)都是以昆虫命名的。</p>
<p><strong>时间-事件轴</strong></p>
<p>1995年5月23日，Java语言诞生<br>1996年1月，第一个JDK-JDK1.0诞生<br>1996年4月，10个最主要的操作系统供应商申明将在其产品中嵌入JAVA技术<br>1996年9月，约8.3万个网页应用了JAVA技术来制作<br>1997年2月18日，JDK1.1发布<br>1997年4月2日，JavaOne会议召开，参与者逾一万人，创当时全球同类会议规模之纪录<br>1997年9月，JavaDeveloperConnection社区成员超过十万<br>1998年2月，JDK1.1被下载超过2,000,000次<br>1998年12月8日，JAVA2企业平台J2EE发布<br>1999年6月，SUN公司发布Java的三个版本：标准版、企业版和微型版（J2SE、J2EE、J2ME）<br>2000年5月8日，JDK1.3发布<br>2000年5月29日，JDK1.4发布<br>2001年6月5日，NOKIA宣布，到2003年将出售1亿部支持Java的手机<br>2001年9月24日，J2EE1.3发布<br>2002年2月13日，J2SE1.4发布，自此Java的计算能力有了大幅提升。<br>2004年9月30日18:00PM，J2SE1.5发布，是Java语言的发展史上的又一里程碑事件。为了表示这个版本的重要性，J2SE1.5更名为J2SE5.0<br>2005年6月，JavaOne大会召开，SUN公司公开Java SE 6。此时，Java的各种版本已经更名以取消其中的数字“2”：J2EE更名为Java EE, J2SE更名为Java SE，J2ME更名为Java ME。<br>2006年11月13日，SUN公司宣布Java全线采纳GNU General Public License Version 2，从而公开了Java的源代码。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>简述Java中满足线程安全的数据结构</title>
    <url>/java/Java%E4%B8%AD%E6%BB%A1%E8%B6%B3%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h2 id="简述Java中满足线程安全的数据结构"><a href="#简述Java中满足线程安全的数据结构" class="headerlink" title="简述Java中满足线程安全的数据结构"></a>简述Java中满足线程安全的数据结构</h2><p>所谓 <strong>线程安全</strong> 就是：一段操纵共享数据的代码能够保证在同一时间内被多个线程执行而仍然保持其正确性的，就被称为是线程安全的。</p>
<a id="more"></a>
<p>线程安全是保证执行业务逻辑正确的基本前提，为此在多线程开发中，我们尽量采用能保证线程安全的数据结构。</p>
<p>JDK已经为大家准备好了一批好用的线程安全容器类，可以大大减少开发工作量，例如<strong>HashTable，ConcurrentHashMap，CopyOnWriteArrayList，CopyOnWriteArraySet，ConcurrentLinkedQueue，Vector，StringBuffer</strong>等。本文主要对这些数据结构的功能及其常见使用场景进行说明与比较。<br><br><img data-src="https://img-blog.csdnimg.cn/20190220155444620.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MjI5NTY3,size_16,color_FFFFFF,t_70" ></p>
<h2 id="1、HashTable"><a href="#1、HashTable" class="headerlink" title="1、HashTable"></a>1、HashTable</h2><p>HashTable实现了Map接口，为此其本身也是一个散列表，它存储的内容是基于key-value的键值对映射。</p>
<p>HashTable中的key、value都不可以为null；具有无序特性；由于其方法函数都是同步的（采用synchronized修饰），不会出现两个线程同时对数据进行操作的情况，因此保证了线程安全性。</p>
<p>HashTable使用synchronized来修饰方法函数来保证线程安全，但是在多线程运行环境下效率表现非常低下。因为当一个线程访问HashTable的同步方法时，其他线程也访问同步方法就会粗线阻塞状态。比如当一个线程在添加数据时候，另外一个线程即使执行获取其他数据的操作也必须被阻塞，大大降低了程序的运行效率。</p>
<h2 id="2、ConcurrentHashMap"><a href="#2、ConcurrentHashMap" class="headerlink" title="2、ConcurrentHashMap"></a>2、ConcurrentHashMap</h2><p>我们知道HashMap是线程不安全的，ConcurrentHashMap是HashMap的线程安全版。</p>
<p>但是与HashTable相比，ConcurrentHashMap不仅保证了多线程运行环境下的数据访问安全性，而且性能上有长足的提升。</p>
<p>ConcurrentHashMap允许多个修改操作并发运行，其原因在于使用了锁分段技术：首先讲Map存放的数据分成一段一段的存储方式，然后给每一段数据分配一把锁，当一个线程占用锁访问其中一个段的数据时，其他段的数据也能被其他线程访问。这样就保证了每一把锁只是用于锁住一部分数据，那么当多线程访问Map里的不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效提高并发访问效率。</p>
<p>上述的处理机制明显区别于HashTable是给整体数据分配了一把锁的处理方法。为此，在多线程环境下，常用ConcurrentHashMap在需要保证数据安全的场景中去替换HashMap，而不会去使用HashTable，同时在最新版的JDK中已经推荐废弃使用HashTable。</p>
<h2 id="3、CopyOnWriteArrayList"><a href="#3、CopyOnWriteArrayList" class="headerlink" title="3、CopyOnWriteArrayList"></a>3、CopyOnWriteArrayList</h2><p>CopyOnWriteArrayList实现了List接口，提供的数据更新操作都使用了ReentrantLock的lock()方法来加锁，unlock()方法来解锁。</p>
<p>当增加元素的时候，首先使用Arrays.copyOf()来拷贝形成新的副本，在副本上增加元素，然后改变原引用指向副本。读操作不需要加锁，而写操作类实现中对其进行了加锁。因此，CopyOnWriteArrayList类是一个线程安全的List接口的实现，在高并发的情况下，可以提供高性能的并发读取，并且保证读取的内容一定是正确的，这对于读操作远远多于写操作的应用非常适合（<strong>注意：</strong> 如上述更新操作会带来较大的空间与性能开销，如果更新操太过频繁，反而不太合适使用）。</p>
<h2 id="4、CopyOnWriteArraySet"><a href="#4、CopyOnWriteArraySet" class="headerlink" title="4、CopyOnWriteArraySet"></a>4、CopyOnWriteArraySet</h2><p>CopyOnWriteArraySet是对CopyOnWriteArrayList使用了装饰模式后的具体实现。所以CopyOnWriteArrayList的实现机理适用于CopyOnWriteArraySet，此处不再赘述。</p>
<p>Java里的List和Set的之间的特性比较结论同样适用于CopyOnWriteArrayList与CopyOnWriteArraySet之间的比较；此外，CopyOnWriteArrayList与CopyOnWriteArraySet都是线程安全的。</p>
<h2 id="5、ConcurrentLinkedQueue"><a href="#5、ConcurrentLinkedQueue" class="headerlink" title="5、ConcurrentLinkedQueue"></a>5、ConcurrentLinkedQueue</h2><p>ConcurrentLinkedQueue可以被看作是一个线程安全的LinkedList，使用了非阻塞算法实现的一个高效、线程安全的并发队列；其本质是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当添加一个元素时会添加到队列的尾部；当获取一个元素时，会返回队列头部的元素。</p>
<p>ConcurrentLinkedQueue应该算是在高并发环境中性能最好的队列，没有之一。</p>
<h2 id="6、Vector"><a href="#6、Vector" class="headerlink" title="6、Vector"></a>6、Vector</h2><p>Vector通过数组保存数据，继承了Abstract，实现了List；所以，其本质上是一个队列。</p>
<p>但是和ArrayList不同，Vector中的操作是线程安全的，它是利用synchronized同步锁机制进行实现，其实现方式与HashTable类似。</p>
<h2 id="7、StringBuffer与StringBuilder"><a href="#7、StringBuffer与StringBuilder" class="headerlink" title="7、StringBuffer与StringBuilder"></a>7、StringBuffer与StringBuilder</h2><p>在Java里面，字符串操作应该是最频繁的操作了，为此有必要把StringBuffer与StringBuilder两个方法类比较一下。</p>
<p>首先，对于频繁的字符串拼接操作，是不推荐采用效率低下的“+”操作的。一般是采用StringBuffer与StringBuilder来实现上述功能。但是，这两者也是有区别的：前者线程安全，后者不是线程安全的。</p>
<p>StringBuffer是通过对方法函数进行synchronized修饰实现其线程安全特性，实现方式与HashTable、Vector类似。</p>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><ol>
<li>HashTable是线程安全类；通过对其方法函数进行synchronized修饰实现其特性，效率低下，目前已被jdk废弃，不再推荐使用。</li>
<li>在多线程环境下，我们常用ConcurrentHashMap在需要保证数据安全的场景中去替换HashMap；此外ConcurrentHashMap也有不错的性能表现</li>
<li>CopyOnWriteArrayList类是一个线程安全的List接口的实现，在高并发的情况下，可以提供高性能的并发读取，并且保证读取的内容一定是正确的，这对于读操作远远多于写操作的应用非常适合。</li>
<li>CopyOnWriteArraySet是对CopyOnWriteArrayList使用了装饰模式后的具体实现，可理解为线程安全的Set。</li>
<li>ConcurrentLinkedQueue应该算是在高并发环境中性能最好的队列；在多线程的队列应用场景中，强烈推荐使用。</li>
<li>Vector中的操作是线程安全的，它是利用synchronized同步锁机制进行实现，其实现方式与HashTable类似。</li>
<li>StringBuffer与StringBuilder常用于字符串拼接；前者线程安全，后者不是线程安全的；在多线程环境中下，考虑数据安全使用前者，否则使用后者。</li>
</ol>
<p>支付成功即可阅读</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java开发中常用的数据结构</title>
    <url>/java/Java%E5%BC%80%E5%8F%91%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h1 id="Java开发中常用的数据结构对比"><a href="#Java开发中常用的数据结构对比" class="headerlink" title="Java开发中常用的数据结构对比"></a>Java开发中常用的数据结构对比</h1><img data-src="https://img-blog.csdn.net/20180602102328655?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMxNjE1MDQ5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" />

<img data-src="https://img-blog.csdn.net/20180602113323887?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMxNjE1MDQ5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" />

<h1 id="JAVA中常用的数据结构（java-util-中）"><a href="#JAVA中常用的数据结构（java-util-中）" class="headerlink" title="JAVA中常用的数据结构（java.util. 中）"></a>JAVA中常用的数据结构（java.util. 中）</h1><p>java中有几种常用的数据结构，主要分为Collection和map两个主要接口（接口只提供方法，并不提供实现），而程序中最终使用的数据结构是继承自这些接口的数据结构类。其主要的关系（继承关系）有： &nbsp;（—-详细参见java api文档！）</p>
<p>Collection—-&gt;Collections &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Map—–&gt;SortedMap——&gt;TreeMap</p>
<p>Collection—-&gt;List—–&gt;(Vector \ ArryList \ LinkedList) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Map——&gt;HashMap</p>
<p>Collection—-&gt;Set——&gt;(HashSet \ LinkedHashSet \ SortedSet)</p>
<img data-src="https://img-blog.csdn.net/20160725191058505?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="" />


<h1 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h1><h2 id="1、Collections"><a href="#1、Collections" class="headerlink" title="1、Collections"></a>1、Collections</h2><p>API—-This class consists exclusively of static methods that operate on or return collections. It contains polymorphic algorithms that operate on collections, “wrappers”, which return a new collection backed by a specified collection, and a few other odds and ends.</p>
<p>The methods of this class all throw a&nbsp;<tt>NullPointerException</tt>&nbsp;if the collections or class objects provided to them are null.&nbsp;</p>
<h2 id="2、List"><a href="#2、List" class="headerlink" title="2、List"></a>2、List</h2><p>The methods of this class all throw a&nbsp;<tt>NullPointerException</tt>&nbsp;if the collections or class objects provided to them are null.&nbsp;</p>
<p>List是有序的Collection，使用此接口能够精确的控制每个元素插入的位置。用户能够使用索引（元素在List中的位置，类似于数组下 &gt;标）来访问List中的元素，这类似于Java的数组。</p>
<h2 id="3、Vector"><a href="#3、Vector" class="headerlink" title="3、Vector"></a>3、Vector</h2><p>API—-The&nbsp;<code>Vector</code>&nbsp;class implements a growable array of objects. Like an array, it contains components that can be accessed using an integer index. However, the size of a<code>Vector</code>&nbsp;can grow or shrink as needed to accommodate adding and removing items after the<code>Vector</code>&nbsp;has been created.&nbsp;</p>
<p>基于数组（Array）的List，其实就是封装了数组所不具备的一些功能方便我们使用，所以它难易避免数组的限制，同时性能也不可能超越数组。所以，在可能的情况下，我们要多运用数组。另外很重要的一点就是Vector是线程同步的(sychronized)的，这也是Vector和ArrayList 的一个的重要区别。&nbsp;</p>
<h2 id="4、ArrayList"><a href="#4、ArrayList" class="headerlink" title="4、ArrayList"></a>4、ArrayList</h2><p>API—-Resizable-array implementation of the List interface. Implements all optional list operations, and permits all elements, includingnull. In addition to implementing theList interface, this class provides methods to manipulate the size of the array that is used internally to store the list. (This class is roughly equivalent toVector, except that it is unsynchronized.)</p>
<p>同Vector一样是一个基于数组上的链表，但是不同的是ArrayList不是同步的。所以在性能上要比Vector好一些，但是当运行到多线程环境中时，可需要自己在管理线程的同步问题。</p>
<h2 id="5、LinkedList"><a href="#5、LinkedList" class="headerlink" title="5、LinkedList"></a>5、LinkedList</h2><p>LinkedList不同于前面两种List，它不是基于数组的，所以不受数组性能的限制。&nbsp;<br />它每一个节点（Node）都包含两方面的内容：&nbsp;<br />1.节点本身的数据（data）；&nbsp;<br />2.下一个节点的信息（nextNode）。&nbsp;<br />所以当对LinkedList做添加，删除动作的时候就不用像基于数组的ArrayList一样，必须进行大量的数据移动。只要更改nextNode的相关信息就可以实现了，这是LinkedList的优势。</p>
<h2 id="List总结："><a href="#List总结：" class="headerlink" title="List总结："></a>List总结：</h2><ul>
<li><p>所有的List中只能容纳单个不同类型的对象组成的表，而不是Key－Value键值对。例如：[ tom,1,c ]</p>
</li>
<li><p>所有的List中可以有相同的元素，例如Vector中可以有 [ tom,koo,too,koo ]</p>
</li>
<li><p>所有的List中可以有null元素，例如[ tom,null,1 ]</p>
</li>
</ul>
<p>&nbsp;</p>
<h2 id="6、Set-接口"><a href="#6、Set-接口" class="headerlink" title="6、Set(接口)"></a>6、Set(接口)</h2><p>API—–A collection that contains no duplicate elements. More formally, sets contain no pair of elementse1 ande2 such that e1.equals(e2), and at most one null element. As implied by its name, this interface models the mathematicalset abstraction. </p>
<p>Set是不包含重复元素的Collection</p>
<h2 id="7、HashSet"><a href="#7、HashSet" class="headerlink" title="7、HashSet"></a>7、HashSet</h2><p>API—–This class implements theSet interface, backed by a hash table (actually aHashMap instance). It makes no guarantees as to the iteration order of the set; in particular, it does not guarantee that the order will remain constant over time. This class permits thenull element. </p>
<p>虽然Set同List都实现了Collection接口，但是他们的实现方式却大不一样。List基本上都是以Array为基础。但是Set则是在 HashMap的基础上来实现的，这个就是Set和List的根本区别。HashSet的存储方式是把HashMap中的Key作为Set的对应存储项。看看 HashSet的add（Object obj）方法的实现就可以一目了然了。</p>
<h2 id="8、LinkedHashSet"><a href="#8、LinkedHashSet" class="headerlink" title="8、LinkedHashSet"></a>8、LinkedHashSet</h2><p>API—-Linked list implementation of the List interface. Implements all optional list operations, and permits all elements (includingnull). In addition to implementing theList interface, the LinkedList class provides uniformly named methods toget, remove andinsert an element at the beginning and end of the list. These operations allow linked lists to be used as a stack,queue, ordouble-ended queue.<br>HashSet的一个子类，一个链表。</p>
<h2 id="9、SortedSet"><a href="#9、SortedSet" class="headerlink" title="9、SortedSet"></a>9、SortedSet</h2><p> API—ASet that further provides atotal ordering on its elements. The elements are ordered using theirnatural ordering, or by aComparator typically provided at sorted set creation time. The set’s iterator will traverse the set in ascending element order. Several additional operations are provided to take advantage of the ordering. (This interface is the set analogue ofSortedMap.)  </p>
<p>有序的Set，通过SortedMap来实现的。</p>
<h2 id="Set总结："><a href="#Set总结：" class="headerlink" title="Set总结："></a>Set总结：</h2><ul>
<li>（1）Set实现的基础是Map（HashMap）</li>
<li>（2）Set中的元素是不能重复的，如果使用add(Object obj)方法添加已经存在的对象，则会覆盖前面的对象</li>
</ul>
<h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><h2 id="1、HashMap"><a href="#1、HashMap" class="headerlink" title="1、HashMap"></a>1、HashMap</h2><p>API—-Hash table based implementation of theMap interface. This implementation provides all of the optional map operations, and permitsnull values and the null key. (The HashMap class is roughly equivalent toHashtable, except that it is unsynchronized and permits nulls.) This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain constant over time.  </p>
<h2 id="2、TreeMap"><a href="#2、TreeMap" class="headerlink" title="2、TreeMap"></a>2、TreeMap</h2><p>API—-A Red-Black tree basedNavigableMap implementation. The map is sorted according to thenatural ordering of its keys, or by aComparator provided at map creation time, depending on which constructor is used. </p>
<p>TreeMap则是对键按序存放，因此它便有一些扩展的方法，比如firstKey(),lastKey()等，你还可以从TreeMap中指定一个范围以取得其子Map。 </p>
<p>键和值的关联很简单，用put(Object key,Object value)方法即可将一个键与一个值对象相关联。用get(Object key)可得到与此key对象所对应的值对象。 </p>
<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><h2 id="一、几个常用类的区别"><a href="#一、几个常用类的区别" class="headerlink" title="一、几个常用类的区别"></a>一、几个常用类的区别</h2><ol>
<li>ArrayList: 元素单个，效率高，多用于查询 </li>
<li>Vector: 元素单个，线程安全，多用于查询 </li>
<li>LinkedList:元素单个，多用于插入和删除 </li>
<li>HashMap: 元素成对，元素可为空 </li>
<li>HashTable: 元素成对，线程安全，元素不可为空 </li>
</ol>
<h2 id="二、Vector、ArrayList和LinkedList"><a href="#二、Vector、ArrayList和LinkedList" class="headerlink" title="二、Vector、ArrayList和LinkedList"></a>二、Vector、ArrayList和LinkedList</h2><ul>
<li>大多数情况下，从性能上来说ArrayList最好，但是当集合内的元素需要频繁插入、删除时LinkedList会有比较好的表现，但是它们三个性能都比不上数组，另外Vector是线程同步的。所以： </li>
<li>如果能用数组的时候(元素类型固定，数组长度固定)，请尽量使用数组来代替List； </li>
<li>如果没有频繁的删除插入操作，又不用考虑多线程问题，优先选择ArrayList； </li>
<li>如果在多线程条件下使用，可以考虑Vector； </li>
<li>如果需要频繁地删除插入，LinkedList就有了用武之地； </li>
<li>如果你什么都不知道，用ArrayList没错。 </li>
</ul>
<p>三、Collections和Arrays<br>在 Java集合类框架里有两个类叫做Collections（注意，不是Collection！）和Arrays，这是JCF里面功能强大的工具，但初学者往往会忽视。按JCF文档的说法，这两个类提供了封装器实现（Wrapper Implementations）、数据结构算法和数组相关的应用。<br>想必大家不会忘记上面谈到的“折半查找”、“排序”等经典算法吧，Collections类提供了丰富的静态方法帮助我们轻松完成这些在数据结构课上烦人的工作：<br>binarySearch：折半查找。<br>sort：排序，这里是一种类似于快速排序的方法，效率仍然是O(n * log n)，但却是一种稳定的排序方法。<br>reverse：将线性表进行逆序操作，这个可是从前数据结构的经典考题哦！<br>rotate：以某个元素为轴心将线性表“旋转”。<br>swap：交换一个线性表中两个元素的位置。<br>……<br>Collections还有一个重要功能就是“封装器”（Wrapper），它提供了一些方法可以把一个集合转换成一个特殊的集合，如下：<br>unmodifiableXXX：转换成只读集合，这里XXX代表六种基本集合接口：Collection、List、Map、Set、SortedMap和SortedSet。如果你对只读集合进行插入删除操作，将会抛出UnsupportedOperationException异常。<br>synchronizedXXX：转换成同步集合。<br>singleton：创建一个仅有一个元素的集合，这里singleton生成的是单元素Set，<br>singletonList和singletonMap分别生成单元素的List和Map。<br>空集：由Collections的静态属性EMPTY_SET、EMPTY_LIST和EMPTY_MAP表示。 </p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java线程的6种状态及切换(透彻讲解)</title>
    <url>/java/Java%E7%BA%BF%E7%A8%8B%E7%9A%846%E7%A7%8D%E7%8A%B6%E6%80%81%E5%8F%8A%E5%88%87%E6%8D%A2/</url>
    <content><![CDATA[<h2 id="Java中线程的状态分为6种。"><a href="#Java中线程的状态分为6种。" class="headerlink" title="Java中线程的状态分为6种。"></a>Java中线程的状态分为6种。</h2><ul>
<li><ol>
<li><strong>初始(NEW)</strong>：新创建了一个线程对象，但还没有调用start()方法。</li>
</ol>
</li>
<li><ol start="2">
<li><strong>运行(RUNNABLE)</strong>：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。<br>线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权，此时处于就绪状态（ready）。就绪状态的线程在获得CPU时间片后变为运行中状态（running）。</li>
</ol>
</li>
<li>3.<strong>阻塞(BLOCKED)</strong>：表示线程阻塞于锁。</li>
<li>4.<strong>等待(WAITING)</strong>：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）。</li>
<li>5.<strong>超时等待(TIMED_WAITING)</strong>：该状态不同于WAITING，它可以在指定的时间后自行返回。</li>
<li><ol start="6">
<li><strong>终止(TERMINATED)</strong>：表示该线程已经执行完毕。</li>
</ol>
</li>
</ul>
<h2 id="线程的状态图"><a href="#线程的状态图" class="headerlink" title="线程的状态图"></a><strong>线程的状态图</strong></h2><img data-src="https://img-blog.csdn.net/2018070117435683?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">

<h2 id="1-初始状态"><a href="#1-初始状态" class="headerlink" title="1. 初始状态"></a><strong>1. 初始状态</strong></h2><p>实现Runnable接口和继承Thread可以得到一个线程类，new一个实例出来，线程就进入了初始状态。</p>
<h2 id="2-1-就绪状态"><a href="#2-1-就绪状态" class="headerlink" title="2.1. 就绪状态"></a><strong>2.1. 就绪状态</strong></h2><ol>
<li>就绪状态只是说你资格运行，调度程序没有挑选到你，你就永远是就绪状态。</li>
<li>调用线程的start()方法，此线程进入就绪状态。</li>
<li>当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些线程也将进入就绪状态。</li>
<li>当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入就绪状态。</li>
<li>锁池里的线程拿到对象锁后，进入就绪状态。</li>
</ol>
<h2 id="2-2-运行中状态"><a href="#2-2-运行中状态" class="headerlink" title="2.2. 运行中状态"></a><strong>2.2. 运行中状态</strong></h2><p>线程调度程序从可运行池中选择一个线程作为当前线程时线程所处的状态。这也是线程进入运行状态的唯一一种方式。</p>
<h2 id="3-阻塞状态"><a href="#3-阻塞状态" class="headerlink" title="3. 阻塞状态"></a><strong>3. 阻塞状态</strong></h2><p>阻塞状态是线程阻塞在进入synchronized关键字修饰的方法或代码块(获取锁)时的状态。</p>
<h2 id="4-等待"><a href="#4-等待" class="headerlink" title="4. 等待"></a>4. 等待</h2><p>处于这种状态的线程不会被分配CPU执行时间，它们要等待被显式地唤醒，否则会处于无限期等待的状态。</p>
<h2 id="5-超时等待"><a href="#5-超时等待" class="headerlink" title="5. 超时等待"></a>5. 超时等待</h2><p>处于这种状态的线程不会被分配CPU执行时间，不过无须无限期等待被其他线程显示地唤醒，在达到一定时间后它们会自动唤醒。</p>
<h2 id="6-终止状态"><a href="#6-终止状态" class="headerlink" title="6. 终止状态"></a><strong>6. 终止状态</strong></h2><ol>
<li>当线程的run()方法完成时，或者主线程的main()方法完成时，我们就认为它终止了。这个线程对象也许是活的，但是，它已经不是一个单独执行的线程。线程一旦终止了，就不能复生。</li>
<li>在一个终止的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。</li>
</ol>
<h2 id="等待队列"><a href="#等待队列" class="headerlink" title="等待队列"></a><strong>等待队列</strong></h2><ul>
<li>调用obj的wait(), notify()方法前，必须获得obj锁，也就是必须写在synchronized(obj) 代码段内。</li>
<li>与等待队列相关的步骤和图</li>
</ul>
<img data-src="https://img-blog.csdn.net/20180701221233161?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">

<p>&nbsp;</p>
<ul>
<li>1.线程1获取对象A的锁，正在使用对象A。</li>
<li>2.线程1调用对象A的wait()方法。</li>
<li>3.线程1释放对象A的锁，并马上进入等待队列。</li>
<li>4.锁池里面的对象争抢对象A的锁。</li>
<li>5.线程5获得对象A的锁，进入synchronized块，使用对象A。</li>
<li>6.线程5调用对象A的notifyAll()方法，唤醒所有线程，所有线程进入同步队列。若线程5调用对象A的notify()方法，则唤醒一个线程，不知道会唤醒谁，被唤醒的那个线程进入同步队列。</li>
<li>7.notifyAll()方法所在synchronized结束，线程5释放对象A的锁。</li>
<li>8.同步队列的线程争抢对象锁，但线程1什么时候能抢到就不知道了。</li>
</ul>
<h2 id="同步队列状态"><a href="#同步队列状态" class="headerlink" title="同步队列状态"></a><strong>同步队列状态</strong></h2><ul>
<li>当前线程想调用对象A的同步方法时，发现对象A的锁被别的线程占有，此时当前线程进入同步队列。简言之，同步队列里面放的都是想争夺对象锁的线程。</li>
<li>当一个线程1被另外一个线程2唤醒时，1线程进入同步队列，去争夺对象锁。</li>
<li>同步队列是在同步的环境下才有的概念，一个对象对应一个同步队列。</li>
</ul>
<h2 id="几个方法的比较"><a href="#几个方法的比较" class="headerlink" title="几个方法的比较"></a><strong>几个方法的比较</strong></h2><ol>
<li>Thread.sleep(long millis)，一定是当前线程调用此方法，当前线程进入TIMED_WAITING状态，但不释放对象锁，millis后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。</li>
<li>Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的CPU时间片，但不释放锁资源，由运行状态变为就绪状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。该方法与sleep()类似，只是不能由用户指定暂停多长时间。</li>
<li>t.join()/t.join(long millis)，当前线程里调用其它线程t的join方法，当前线程进入WAITING/TIMED_WAITING状态，当前线程不会释放已经持有的对象锁。线程t执行完毕或者millis时间到，当前线程进入就绪状态。</li>
<li>obj.wait()，当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者wait(long timeout) timeout时间到自动唤醒。</li>
<li>obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程。</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java内存模型详解</title>
    <url>/java/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>网上有很多关于Java内存模型的文章，在《深入理解Java虚拟机》和《Java并发编程的艺术》等书中也都有关于这个知识点的介绍。<a id="more"></a>但是，很多人读完之后还是搞不清楚，甚至有的人说自己更懵了。本文，就来整体的介绍一下Java内存模型，目的很简单，让你读完本文以后，就知道到底Java内存模型是什么，为什么要有Java内存模型，Java内存模型解决了什么问题等。</p>
<p>本文中，有很多定义和说法，都是笔者自己理解后定义出来的。希望能够让读者可以对Java内存模型有更加清晰的认识。当然，如有偏颇，欢迎指正。</p>
<h2 id="1、为什么要有内存模型"><a href="#1、为什么要有内存模型" class="headerlink" title="1、为什么要有内存模型"></a>1、为什么要有内存模型</h2><p>在介绍Java内存模型之前，先来看一下到底什么是计算机内存模型，然后再来看Java内存模型在计算机内存模型的基础上做了哪些事情。要说计算机的内存模型，就要说一下一段古老的历史，看一下为什么要有内存模型。</p>
<p><strong>内存模型，英文名Memory Model，他是一个很老的老古董了。他是与计算机硬件有关的一个概念。那么我先给你介绍下他和硬件到底有啥关系。</strong></p>
<h3 id="CPU和缓存一致性"><a href="#CPU和缓存一致性" class="headerlink" title="CPU和缓存一致性"></a>CPU和缓存一致性</h3><p>我们应该都知道，计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存啦。</p>
<p>刚开始，还相安无事的，但是随着CPU技术的发展，CPU的执行速度越来越快。而由于内存的技术并没有太大的变化，所以从内存中读取和写入数据的过程和CPU的执行速度比起来差距就会越来越大,这就导致CPU每次操作内存都要耗费很多等待时间。</p>
<div class="note warning">
            <p>这就像一家创业公司，刚开始，创始人和员工之间工作关系其乐融融，但是随着创始人的能力和野心越来越大，逐渐和员工之间出现了差距，普通员工原来越跟不上CEO的脚步。老板的每一个命令，传到到基层员工之后，由于基层员工的理解能力、执行能力的欠缺，就会耗费很多时间。这也就无形中拖慢了整家公司的工作效率。</p>
          </div>

<p>可是，不能因为内存的读写速度慢，就不发展CPU技术了吧，总不能让内存成为计算机处理的瓶颈吧。</p>
<p>所以，人们想出来了一个好的办法，就是在CPU和内存之间增加高速缓存。缓存的概念大家都知道，就是保存一份数据拷贝。他的特点是速度快，内存小，并且昂贵。</p>
<p>那么，程序的执行过程就变成了：</p>
<p><strong>当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。</strong></p>
<div class="note warning">
            <p>之后，这家公司开始设立中层管理人员，管理人员直接归CEO领导，领导有什么指示，直接告诉管理人员，然后就可以去做自己的事情了。管理人员负责去协调底层员工的工作。因为管理人员是了解手下的人员以及自己负责的事情的。所以，大多数时候，公司的各种决策，通知等，CEO只要和管理人员之间沟通就够了。</p>
          </div>

<p>而随着CPU能力的不断提升，一层缓存就慢慢的无法满足要求了，就逐渐的衍生出多级缓存。</p>
<p>按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存（L1），二级缓存（L3），部分高端CPU还具有三级缓存（L3），每一级缓存中所储存的全部数据都是下一级缓存的一部分。</p>
<p>这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。</p>
<p>那么，在有了多级缓存之后，程序的执行就变成了：</p>
<p><strong>当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。</strong></p>
<div class="note warning">
            <ul><li><p>随着公司越来越大，老板要管的事情越来越多，公司的管理部门开始改革，开始出现高层，中层，底层等管理者。一级一级之间逐层管理。</p><p>单核CPU只含有一套L1，L2，L3缓存；</p><p>如果CPU含有多个核心，即多核CPU，则每个核心都含有一套L1（甚至和L2）缓存，而共享L3（或者和L2）缓存。</p></li><li><p>公司也分很多种，有些公司只有一个大Boss，他一个人说了算。但是有些公司有比如联席总经理、合伙人等机制。</p></li><li><p>单核CPU就像一家公司只有一个老板，所有命令都来自于他，那么就只需要一套管理班底就够了。</p></li><li><p>多核CPU就像一家公司是由多个合伙人共同创办的，那么，就需要给每个合伙人都设立一套供自己直接领导的高层管理人员，多个合伙人共享使用的是公司的底层员工。</p></li><li><p>还有的公司，不断壮大，开始差分出各个子公司。各个子公司就是多个CPU了，互相之前没有共用的资源。互不影响。</p></li></ul>
          </div>
<p>下图为一个单CPU双核的缓存结构。</p>
<img data-src="https://img2018.cnblogs.com/blog/1330846/201906/1330846-20190613212539898-321568989.png" alt="" />

<p>随着计算机能力不断提升，开始支持多线程。那么问题就来了。我们分别来分析下单线程、多线程在单核CPU、多核CPU中的影响。</p>
<ul>
<li><p><strong>单线程。</strong>cpu核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。</p>
</li>
<li><p><strong>单核CPU，多线程。</strong>进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。</p>
</li>
<li><p><strong>多核CPU，多线程。</strong>每个核都至少有一个L1 缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的caehe中保留一份共享内存的缓冲。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。</p>
</li>
</ul>
<p>在CPU和主存之间增加缓存，在多线程场景下就可能存在<strong>缓存一致性问题</strong>，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。</p>
<div class="note warning">
            <ul><li>如果这家公司的命令都是串行下发的话，那么就没有任何问题。</li><li>如果这家公司的命令都是并行下发的话，并且这些命令都是由同一个CEO下发的，这种机制是也没有什么问题。因为他的命令执行者只有一套管理体系。</li><li>如果这家公司的命令都是并行下发的话，并且这些命令是由多个合伙人下发的，这就有问题了。因为每个合伙人只会把命令下达给自己直属的管理人员，而多个管理人员管理的底层员工可能是公用的。</li><li>比如，合伙人1要辞退员工a，合伙人2要给员工a升职，升职后的话他再被辞退需要多个合伙人开会决议。两个合伙人分别把命令下发给了自己的管理人员。合伙人1命令下达后，管理人员a在辞退了员工后，他就知道这个员工被开除了。而合伙人2的管理人员2这时候在没得到消息之前，还认为员工a是在职的，他就欣然的接收了合伙人给他的升职a的命令。</li></ul>
          </div>

<img data-src="https://img2018.cnblogs.com/blog/1330846/201906/1330846-20190613212611041-299834852.png" alt="" />

<h3 id="处理器优化和指令重排"><a href="#处理器优化和指令重排" class="headerlink" title="处理器优化和指令重排"></a>处理器优化和指令重排</h3><p>上面提到在在CPU和主存之间增加缓存，在多线程场景下会存在<strong>缓存一致性问题</strong>。除了这种情况，还有一种硬件问题也比较重要。那就是为了使处理器内部的运算单元能够尽量的被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是<strong>处理器优化</strong>。</p>
<p>除了现在很多流行的处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的即时编译器（JIT）也会做<strong>指令重排</strong>。</p>
<p>可想而知，如果任由处理器优化和编译器对指令重排的话，就可能导致各种各样的问题。</p>
<div class="note warning">
            <p>关于员工组织调整的情况，如果允许人事部在接到多个命令后进行随意拆分乱序执行或者重排的话，那么对于这个员工以及这家公司的影响是非常大的。</p>
          </div>

<h2 id="2、并发编程的问题"><a href="#2、并发编程的问题" class="headerlink" title="2、并发编程的问题"></a>2、并发编程的问题</h2><p>前面说的和硬件有关的概念你可能听得有点蒙，还不知道他到底和软件有啥关系。但是关于并发编程的问题你应该有所了解，比如原子性问题，可见性问题和有序性问题。</p>
<p>其实，原子性问题，可见性问题和有序性问题。是人们抽象定义出来的。而这个抽象的底层问题就是前面提到的缓存一致性问题、处理器优化问题和指令重排问题等。</p>
<p>这里简单回顾下这三个问题，并不准备深入展开，感兴趣的读者可以自行学习。我们说，并发编程，为了保证数据的安全，需要满足以下三个特性：</p>
<ul>
<li><p><strong>原子性</strong>是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。</p>
</li>
<li><p><strong>可见性</strong>是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。</p>
</li>
<li><p><strong>有序性</strong>即程序执行的顺序按照代码的先后顺序执行。</p>
</li>
</ul>
<p>有没有发现，<strong>缓存一致性问题</strong>其实就是<strong>可见性问题</strong>。而<strong>处理器优化</strong>是可以导致<strong>原子性问题</strong>的。<strong>指令重排</strong>即会导致<strong>有序性问题</strong>。所以，后文将不再提起硬件层面的那些概念，而是直接使用大家熟悉的原子性、可见性和有序性。</p>
<h2 id="3、什么是内存模型"><a href="#3、什么是内存模型" class="headerlink" title="3、什么是内存模型"></a>3、什么是内存模型</h2><p>前面提到的，缓存一致性问题、处理器器优化的指令重排问题是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？</p>
<p>最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。</p>
<p>所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是&mdash;&mdash;<strong>内存模型</strong>。</p>
<p><strong>为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。</strong>通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。</p>
<p>内存模型解决并发问题主要采用两种方式：<strong>限制处理器优化</strong>和<strong>使用内存屏障</strong>。本文就不深入底层原理来展开介绍了，感兴趣的朋友可以自行学习。</p>
<h2 id="4、什么是Java内存模型"><a href="#4、什么是Java内存模型" class="headerlink" title="4、什么是Java内存模型"></a>4、什么是Java内存模型</h2><p>前面介绍过了计算机内存模型，这是解决多线程场景下并发问题的一个重要规范。那么具体的实现是如何的呢，不同的编程语言，在实现上可能有所不同。</p>
<p>我们知道，Java程序是需要运行在Java虚拟机上面的，<strong>Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。</strong></p>
<p>提到Java内存模型，一般指的是JDK 5 开始使用的新的内存模型，主要由JSR-133: JavaTM Memory Model and Thread Specification 描述。感兴趣的可以参看下这份PDF文档（<a href="http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf）" target="_blank" rel="noopener">http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf）</a></p>
<p>Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。</p>
<p>而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。</p>
<img data-src="https://img2018.cnblogs.com/blog/1330846/201906/1330846-20190613213024870-648973066.png" alt="" />

<p>这里面提到的主内存和工作内存，读者可以简单的类比成计算机内存模型中的主存和缓存的概念。特别需要注意的是，主内存和工作内存与JVM内存结构中的Java堆、栈、方法区等并不是同一个层次的内存划分，无法直接类比。《深入理解Java虚拟机》中认为，如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。</p>
<p><strong>所以，再来总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。</strong></p>
<h2 id="5、Java内存模型的实现"><a href="#5、Java内存模型的实现" class="headerlink" title="5、Java内存模型的实现"></a>5、Java内存模型的实现</h2><p>了解Java多线程的朋友都知道，在Java中提供了一系列和并发处理相关的关键字，比如<code>volatile</code>、<code>synchronized</code>、<code>final</code>、<code>concurren</code>包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字。</p>
<p>在开发多线程的代码的时候，我们可以直接使用<code>synchronized</code>等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，<strong>Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。</strong></p>
<p>本文并不准备把所有的关键字逐一介绍其用法，因为关于各个关键字的用法，网上有很多资料。读者可以自行学习。本文还有一个重点要介绍的就是，我们前面提到，并发编程要解决原子性、有序性和一致性的问题，我们就再来看下，在Java中，分别使用什么方式来保证。</p>
<h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>在Java中，为了保证原子性，提供了两个高级的字节码指令<code>monitorenter</code>和<code>monitorexit</code>。在synchronized的实现原理文章中，介绍过，这两个字节码，在Java中对应的关键字就是<code>synchronized</code>。</p>
<p>因此，在Java中可以使用<code>synchronized</code>来保证方法和代码块内的操作是原子性的。</p>
<h3 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h3><p>Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。</p>
<p>Java中的<code>volatile</code>关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用<code>volatile</code>来保证多线程操作时变量的可见性。</p>
<p>除了<code>volatile</code>，Java中的<code>synchronized</code>和<code>final</code>两个关键字也可以实现可见性。只不过实现方式不同，这里不再展开了。</p>
<h3 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h3><p>在Java中，可以使用<code>synchronized</code>和<code>volatile</code>来保证多线程之间操作的有序性。实现方式有所区别：</p>
<p><code>volatile</code>关键字会禁止指令重排。<code>synchronized</code>关键字保证同一时刻只允许一条线程操作。</p>
<p>好了，这里简单的介绍完了Java并发编程中解决原子性、可见性以及有序性可以使用的关键字。读者可能发现了，好像<code>synchronized</code>关键字是万能的，他可以同时满足以上三种特性，这其实也是很多人滥用<code>synchronized</code>的原因。</p>
<p>但是<code>synchronized</code>是比较影响性能的，虽然编译器提供了很多锁优化技术，但是也不建议过度使用。</p>
<h2 id="6、总结"><a href="#6、总结" class="headerlink" title="6、总结"></a>6、总结</h2><p>在读完本文之后，相信你应该了解了什么是Java内存模型、Java内存模型的作用以及Java中内存模型做了什么事情等。</p>
<p>关于Java中这些和内存模型有关的关键字，希望读者还可以继续深入学习，并且自己写几个例子亲自体会一下。可以参考《深入理解Java虚拟机》和《Java并发编程的艺术》两本书。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java线程池-ThreadPoolExecutor构造方法参数的使用规则</title>
    <url>/java/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0-ThreadPoolExecutor%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0/</url>
    <content><![CDATA[<h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>为了更好的使用多线程，JDK提供了线程池供开发人员使用，目的在于减少线程的创建和销毁次数，以此达到线程的重复利用。</p>
<a id="more"></a>
<p>其中ThreadPoolExecutor是线程池中最核心的一个类，我们先简单看一下这个类的继承关系。<br><img data-src="https://images2018.cnblogs.com/blog/1014108/201804/1014108-20180410005628299-888807412.jpg" alt="" width="154" height="298" /></p>
<p>其中Executor是线程池的顶级接口，接口中只定义了一个方法 void execute(Runnable command)；线程池的操作方法都是定义子在ExecutorService子接口中的，所以说ExecutorService是线程池真正的接口。</p>
<p>ThreadPoolExecutor提供了四个构造方法，我们看一下参数最全的一个构造函数；</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">      　　　　　　　　　　　<span class="keyword">int</span> maximumPoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">long</span> keepAliveTime,</span></span></span><br><span class="line"><span class="function"><span class="params">                        TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">                        BlockingQueue&lt;Runnable&gt;    workQueue,　　　　　　　　　　　　　　　　　　ThreadFactory threadFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">                        RejectedExecutionHandler handler)</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>函数的参数含义如下：</p>
<ul>
<li><strong>corePoolSize</strong>： 线程池核心线程数</li>
<li><strong>maximumPoolSize</strong>：线程池最大数</li>
<li><strong>keepAliveTime</strong>： 空闲线程存活时间</li>
<li><strong>unit</strong>： 时间单位</li>
<li><strong>workQueue</strong>： 线程池所使用的缓冲队列</li>
<li><strong>threadFactory</strong>：线程池创建线程使用的工厂</li>
<li><strong>handler</strong>： 线程池对拒绝任务的处理策略</li>
</ul>
<p>本节我们主要对前五个参数中的corePoolSize，maximumPoolSize及workQueue是如何配合使用做出说明（keepAliveTime，unit主要对空闲线程的存活时间做的定义，见名知意，不再做出说明），以此来引出线程池的一些特性。</p>
<p>threadFactory和handler这两个参数都有默认值，对于它们的用法将放到其它章节去做说明。</p>
<h2 id="特性一："><a href="#特性一：" class="headerlink" title="**特性一："></a>**特性一：</h2><p>当池中正在运行的线程数（包括空闲线程）小于corePoolSize时，新建线程执行任务。</p>
<p>下面用实验来说明，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestThreadPoolExecutor</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ThreadPoolExecutor pool = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>, <span class="number">3</span>, <span class="number">60L</span>, TimeUnit.SECONDS,<span class="keyword">new</span> LinkedBlockingQueue&lt;&gt;(<span class="number">1</span>));</span><br><span class="line">        <span class="comment">//任务1</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"-------------helloworld_001---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//主线程睡2秒</span></span><br><span class="line">            Thread.sleep(<span class="number">2</span>*<span class="number">1000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//任务2</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"-------------helloworld_002---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);   </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实验结果如下：</p>
<img data-src="https://images2018.cnblogs.com/blog/1014108/201804/1014108-20180410014101204-561462983.jpg" alt="" />

<p>实验结果分析：</p>
<p>从实验结果上可以看出，当执行任务1的线程（thread-1）执行完成之后，任务2并没有去复用thread-1而是新建线程（thread-2）去执行任务。</p>
<h2 id="特性二："><a href="#特性二：" class="headerlink" title="特性二："></a>特性二：</h2><p>当池中正在运行的线程数大于等于corePoolSize时，新插入的任务进入workQueue排队（如果workQueue长度允许），等待空闲线程来执行。</p>
<p>下面用实验来说明，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestThreadPoolExecutor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ThreadPoolExecutor pool = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>, <span class="number">3</span>, <span class="number">60L</span>, TimeUnit.SECONDS, <span class="keyword">new</span> LinkedBlockingQueue&lt;&gt;(<span class="number">1</span>));</span><br><span class="line">        <span class="comment">// 任务1</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">3</span> * <span class="number">1000</span>);</span><br><span class="line">                    System.out.println(<span class="string">"-------------helloworld_001---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 任务2</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">5</span> * <span class="number">1000</span>);</span><br><span class="line">                    System.out.println(<span class="string">"-------------helloworld_002---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 任务3</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"-------------helloworld_003---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实验结果如下：<br><img data-src="https://images2018.cnblogs.com/blog/1014108/201804/1014108-20180410112935712-60748220.png" alt="" /></p>
<p>实验结果分析：</p>
<p>从实验结果上看，任务3会等待任务1执行完之后，有了空闲线程，才会执行。并没有新建线程执行任务3，这时<strong>maximumPoolSize=3</strong>这个参数不起作用<strong>。</strong></p>
<h2 id="特性三："><a href="#特性三：" class="headerlink" title="特性三："></a>特性三：</h2><p>当队列里的任务数达到上限，并且池中正在运行的线程数小于maximumPoolSize**，对于新加入的任务，新建线程。</p>
<p>下面用实验来说明，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestThreadPoolExecutor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ThreadPoolExecutor pool = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>, <span class="number">3</span>, <span class="number">60L</span>, TimeUnit.SECONDS, <span class="keyword">new</span> LinkedBlockingQueue&lt;&gt;(<span class="number">1</span>));</span><br><span class="line">        <span class="comment">// 任务1</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">3</span> * <span class="number">1000</span>);</span><br><span class="line">                    System.out.println(<span class="string">"-------------helloworld_001---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 任务2</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">5</span> * <span class="number">1000</span>);</span><br><span class="line">                    System.out.println(<span class="string">"-------------helloworld_002---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 任务3</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"-------------helloworld_003---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 任务4</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"-------------helloworld_004---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实验结果如下：</p>
<img data-src="https://images2018.cnblogs.com/blog/1014108/201804/1014108-20180410142716085-891833621.png" alt="" />

<p>实验结果分析：</p>
<p>当任务4进入队列时发现队列的长度已经到了上限，所以无法进入队列排队，而此时正在运行的线程数（2）小于maximumPoolSize所以新建线程执行该任务。</p>
<h2 id="特性四："><a href="#特性四：" class="headerlink" title="特性四："></a>特性四：</h2><p>当队列里的任务数达到上限，并且池中正在运行的线程数等于maximumPoolSize**，对于新加入的任务，执行拒绝策略（线程池默认的拒绝策略是抛异常）。</p>
<p>下面用实验来说明，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestThreadPoolExecutor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ThreadPoolExecutor pool = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>, <span class="number">3</span>, <span class="number">60L</span>, TimeUnit.SECONDS, <span class="keyword">new</span> LinkedBlockingQueue&lt;&gt;(<span class="number">1</span>));</span><br><span class="line">        <span class="comment">// 任务1</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">3</span> * <span class="number">1000</span>);</span><br><span class="line">                    System.out.println(<span class="string">"-------------helloworld_001---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 任务2</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">5</span> * <span class="number">1000</span>);</span><br><span class="line">                    System.out.println(<span class="string">"-------------helloworld_002---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 任务3</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"-------------helloworld_003---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 任务4</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">2</span> * <span class="number">1000</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(<span class="string">"-------------helloworld_004---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 任务5</span></span><br><span class="line">        pool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"-------------helloworld_005---------------"</span> + Thread.currentThread().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实验结果如下：</p>
<img data-src="https://images2018.cnblogs.com/blog/1014108/201804/1014108-20180410144055461-1427791979.png" alt="" />

<p>实验结果分析：</p>
<p>当任务5加入时，队列达到上限，池内运行的线程数达到最大，故执行默认的拒绝策略，抛异常。</p>
<p>本文中使用到的队列类型虽然仅限于LinkedBlockingQueue这一种队列类型，但总结出来的特性，对与常用ArrayBlockingQueue 和SynchronousQueue同样适用，些许不同及三种队列的区别，将在下个章节中说明。</p>
<p><strong>最后说一点，我们作为程序员，研究问题还是要仔细深入一点的。当你对原理了解的有够透彻，开发起来也就得心应手了，很多开发中的问题和疑惑也就迎刃而解了，而且在面对其他问题的时候也可做到触类旁通。当然在开发中没有太多的时间让你去研究原理，开发中要以实现功能为前提，可等项目上线的后，你有大把的时间或者空余的时间，你大可去刨根问底，深入的去研究一项技术，为觉得这对一名程序员的成长是很重要的事情。</strong></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java LinkedHashMap图解</title>
    <url>/java/LinkedHashMap/</url>
    <content><![CDATA[<h1 id="初识LinkedHashMap"><a href="#初识LinkedHashMap" class="headerlink" title="初识LinkedHashMap"></a><strong>初识LinkedHashMap</strong></h1><p>上两篇文章讲了HashMap和HashMap在多线程下引发的问题，说明了，HashMap是一种非常常见、非常有用的集合，并且在多线程情况下使用不当会有线程安全问题。</p>
<a id="more"></a>

<p>大多数情况下，只要不涉及线程安全问题，Map基本都可以使用HashMap，不过HashMap有一个问题，就是迭代HashMap的顺序并不是HashMap放置的顺序，也就是无序。HashMap的这一缺点往往会带来困扰，因为有些场景，我们期待一个有序的Map。</p>
<p>这个时候，LinkedHashMap就闪亮登场了，它虽然增加了时间和空间上的开销，但是通过维护一个运行于所有条目的双向链表，LinkedHashMap保证了元素迭代的顺序。</p>
<h1 id="四个关注点在LinkedHashMap上的答案"><a href="#四个关注点在LinkedHashMap上的答案" class="headerlink" title="四个关注点在LinkedHashMap上的答案"></a><strong>四个关注点在LinkedHashMap上的答案</strong></h1><img data-src="http://f.ngall-in.com/alan87/static/images/java/LinkedHashMap/1.png/w600">

<h1 id="LinkedHashMap基本数据结构"><a href="#LinkedHashMap基本数据结构" class="headerlink" title="LinkedHashMap基本数据结构"></a><strong>LinkedHashMap基本数据结构</strong></h1><p>关于LinkedHashMap，先提两点：</p>
<ol>
<li><p>LinkedHashMap可以认为是HashMap+LinkedList，即它既使用HashMap操作数据结构，又使用LinkedList维护插入元素的先后顺序</p>
</li>
<li><p>LinkedHashMap的基本实现思想就是—-多态。可以说，理解多态，再去理解LinkedHashMap原理会事半功倍；反之也是，对于LinkedHashMap原理的学习，也可以促进和加深对于多态的理解。</p>
</li>
</ol>
<p>为什么可以这么说，首先看一下，LinkedHashMap的定义：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;<span class="keyword">extends</span> <span class="title">HashMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;<span class="keyword">implements</span> <span class="title">Map</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;</span>&#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看到，LinkedHashMap是HashMap的子类，自然LinkedHashMap也就继承了HashMap中所有非private的方法。再看一下LinkedHashMap中本身的方法：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/LinkedHashMap/2.png/w600">

<p>看到LinkedHashMap中并没有什么操作数据结构的方法，也就是说LinkedHashMap操作数据结构（比如put一个数据），和HashMap操作数据的方法完全一样，无非就是细节上有一些的不同罢了。</p>
<p>LinkedHashMap和HashMap的区别在于它们的基本数据结构上，看一下LinkedHashMap的基本数据结构，也就是Entry：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">HashMap</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="comment">// These fields comprise the doubly linked list used for iteration.</span></span><br><span class="line">  Entry&lt;K,V&gt; before, after;&amp;nbsp;Entry(<span class="keyword">int</span> hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">super</span>(hash, key, value, next);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>列一下Entry里面有的一些属性吧：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">- K key- V value- Entry&lt;K, V&gt; next- <span class="keyword">int</span> hash- Entry&lt;K, V&gt; before- Entry&lt;K, V&gt; after</span><br><span class="line">V value</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> hash</span><br><span class="line"></span><br><span class="line">Entry&lt;K, V&gt; after</span><br></pre></td></tr></table></figure>
<p>其中前面四个，也就是红色部分是从HashMap.Entry中继承过来的；后面两个，也就是蓝色部分是LinkedHashMap独有的。不要搞错了next和before、After，next是用于维护HashMap指定table位置上连接的Entry的顺序的，before、After是用于维护Entry插入的先后顺序的。</p>
<p>还是用图表示一下，列一下属性而已：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/LinkedHashMap/3.png/w600">

<h1 id="初始化LinkedHashMap"><a href="#初始化LinkedHashMap" class="headerlink" title="初始化LinkedHashMap"></a><strong>初始化LinkedHashMap</strong></h1><p>假如有这么一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">LinkedHashMap&lt;String, String&gt; linkedHashMap =</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">new</span> LinkedHashMap&lt;String, String&gt;();</span><br><span class="line">linkedHashMap.put(<span class="string">"111"</span>, <span class="string">"111"</span>);</span><br><span class="line">linkedHashMap.put(<span class="string">"222"</span>, <span class="string">"222"</span>);&#125;</span><br></pre></td></tr></table></figure>

<p>首先是第3行~第4行，new一个LinkedHashMap出来，看一下做了什么：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedHashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&amp;nbsp; <span class="keyword">super</span>();</span><br><span class="line">&amp;nbsp; accessOrder = <span class="keyword">false</span>;&amp;nbsp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  &amp;nbsp;<span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR;</span><br><span class="line">  &amp;nbsp;threshold = (<span class="keyword">int</span>)(DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR);</span><br><span class="line">  &amp;nbsp;table = <span class="keyword">new</span> Entry[DEFAULT_INITIAL_CAPACITY];</span><br><span class="line">  &amp;nbsp;init();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&amp;nbsp; header = <span class="keyword">new</span> Entry&lt;K,V&gt;(-<span class="number">1</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">&amp;nbsp; header.before = header.after = header;&amp;nbsp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**&amp;nbsp;* The head of the doubly linked list.&amp;nbsp;*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> Entry&lt;K,V&gt; header;</span><br></pre></td></tr></table></figure>

<p>这里出现了第一个多态：init()方法。尽管init()方法定义在HashMap中，但是由于：</p>
<ol>
<li><p>LinkedHashMap重写了init方法</p>
</li>
<li><p>实例化出来的是LinkedHashMap</p>
</li>
</ol>
<p>因此实际调用的init方法是LinkedHashMap重写的init方法。假设header的地址是0×00000000，那么初始化完毕，实际上是这样的：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/LinkedHashMap/4.png/w600">

<h1 id="LinkedHashMap添加元素"><a href="#LinkedHashMap添加元素" class="headerlink" title="LinkedHashMap添加元素"></a><strong>LinkedHashMap添加元素</strong></h1><p>继续看LinkedHashMap添加元素，也就是put(“111″,”111″)做了什么，首先当然是调用HashMap的put方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">    <span class="keyword">return</span> putForNullKey(value);</span><br><span class="line">  <span class="keyword">int</span> hash = hash(key.hashCode());</span><br><span class="line">  <span class="keyword">int</span> i = indexFor(hash, table.length);</span><br><span class="line">  <span class="keyword">for</span> (Entry&lt;K,V&gt; e = table[i]; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">    Object k;</span><br><span class="line">    <span class="keyword">if</span> (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))) &#123;</span><br><span class="line">      V oldValue = e.value;</span><br><span class="line">      e.value = value;</span><br><span class="line">      e.recordAccess(<span class="keyword">this</span>);</span><br><span class="line">      <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  modCount++;</span><br><span class="line">  addEntry(hash, key, value, i);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第17行又是一个多态，因为LinkedHashMap重写了addEntry方法，因此addEntry调用的是LinkedHashMap重写了的方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">int</span> bucketIndex)</span> </span>&#123;</span><br><span class="line">  createEntry(hash, key, value, bucketIndex);&amp;nbsp;</span><br><span class="line">  <span class="comment">// Remove eldest entry if instructed, else grow capacity if appropriate</span></span><br><span class="line">  Entry&lt;K,V&gt; eldest = header.after;</span><br><span class="line">  <span class="keyword">if</span> (removeEldestEntry(eldest)) &#123;</span><br><span class="line">    removeEntryForKey(eldest.key);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">  <span class="keyword">if</span> (size &gt;= threshold)</span><br><span class="line">    resize(<span class="number">2</span> * table.length);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为LinkedHashMap由于其本身维护了插入的先后顺序，因此LinkedHashMap可以用来做缓存，第5行~第7行是用来支持FIFO算法的，这里暂时不用去关心它。看一下createEntry方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createEntry</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">int</span> bucketIndex)</span> </span>&#123;</span><br><span class="line">  HashMap.Entry&lt;K,V&gt; old = table[bucketIndex];</span><br><span class="line">  Entry&lt;K,V&gt; e = <span class="keyword">new</span> Entry&lt;K,V&gt;(hash, key, value, old);</span><br><span class="line">  table[bucketIndex] = e;</span><br><span class="line">  e.addBefore(header);</span><br><span class="line">  size++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addBefore</span><span class="params">(Entry&lt;K,V&gt;istingEntry)</span> </span>&#123;</span><br><span class="line">  after &amp;nbsp;= existingEntry;</span><br><span class="line">  before = existingEntry.before;</span><br><span class="line">  before.after = <span class="keyword">this</span>;</span><br><span class="line">  after.before = <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第2行~第4行的代码和HashMap没有什么不同，新添加的元素放在table[i]上，差别在于LinkedHashMap还做了addBefore操作，这四行代码的意思就是让新的Entry和原链表生成一个双向链表。假设字符串111放在位置table[1]上，生成的Entry地址为0×00000001，那么用图表示是这样的：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/LinkedHashMap/5.png/w600">

<p>如果熟悉LinkedList的源码应该不难理解，还是解释一下，注意下existingEntry表示的是header：</p>
<ol>
<li><p>after=existingEntry，即新增的Entry的after=header地址，即after=0×00000000</p>
</li>
<li><p>before=existingEntry.before，即新增的Entry的before是header的before的地址，header的before此时是0×00000000，因此新增的Entry的before=0×00000000</p>
</li>
<li><p>before.after=this，新增的Entry的before此时为0×00000000即header，header的after=this，即header的after=0×00000001</p>
</li>
<li><p>after.before=this，新增的Entry的after此时为0×00000000即header，header的before=this，即header的before=0×00000001</p>
</li>
</ol>
<p>这样，header与新增的Entry的一个双向链表就形成了。再看，新增了字符串222之后是什么样的，假设新增的Entry的地址为0×00000002，生成到table[2]上，用图表示是这样的：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/LinkedHashMap/6.png/w600">

<p>就不细解释了，只要before、after清除地知道代表的是哪个Entry的就不会有什么问题。</p>
<p>总得来看，再说明一遍，LinkedHashMap的实现就是HashMap+LinkedList的实现方式，以HashMap维护数据结构，以LinkList的方式维护数据插入顺序。</p>
<h1 id="利用LinkedHashMap实现LRU算法缓存"><a href="#利用LinkedHashMap实现LRU算法缓存" class="headerlink" title="利用LinkedHashMap实现LRU算法缓存"></a><strong>利用LinkedHashMap实现LRU算法缓存</strong></h1><p>前面讲了LinkedHashMap添加元素，删除、修改元素就不说了，比较简单，和HashMap+LinkedList的删除、修改元素大同小异，下面讲一个新的内容。</p>
<p>LinkedHashMap可以用来作缓存，比方说LRUCache，看一下这个类的代码，很简单，就十几行而已：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> <span class="keyword">extends</span> <span class="title">LinkedHashMap</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> maxSize)</span></span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(maxSize, <span class="number">0.75F</span>, <span class="keyword">true</span>);</span><br><span class="line">    maxElements = maxSize;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(java.util.Map.Entry eldest)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> size() &gt;xElements;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">int</span> maxElements;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>顾名思义，LRUCache就是基于LRU算法的Cache（缓存），这个类继承自LinkedHashMap，而类中看到没有什么特别的方法，这说明LRUCache实现缓存LRU功能都是源自LinkedHashMap的。LinkedHashMap可以实现LRU算法的缓存基于两点：</p>
<ol>
<li><p>LinkedList首先它是一个Map，Map是基于K-V的，和缓存一致</p>
</li>
<li><p>LinkedList提供了一个boolean值可以让用户指定是否实现LRU</p>
</li>
</ol>
<p>那么，首先我们了解一下什么是LRU：LRU即Least Recently Used，最近最少使用，也就是说，当缓存满了，会优先淘汰那些最近最不常访问的数据。比方说数据a，1天前访问了；数据b，2天前访问了，缓存满了，优先会淘汰数据b。</p>
<p>我们看一下LinkedList带boolean型参数的构造方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedHashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, &amp;nbsp;<span class="keyword">float</span> loadFactor, &amp;nbsp;<span class="keyword">boolean</span> accessOrder)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">super</span>(initialCapacity, loadFactor);</span><br><span class="line">  <span class="keyword">this</span>.accessOrder = accessOrder;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>就是这个accessOrder，它表示：</p>
<p>（1）false，所有的Entry按照插入的顺序排列</p>
<p>（2）true，所有的Entry按照访问的顺序排列</p>
<p>第二点的意思就是，如果有1 2 3这3个Entry，那么访问了1，就把1移到尾部去，即2 3 1。每次访问都把访问的那个数据移到双向队列的尾部去，那么每次要淘汰数据的时候，双向队列最头的那个数据不就是最不常访问的那个数据了吗？换句话说，双向链表最头的那个数据就是要淘汰的数据。</p>
<p>“访问”，这个词有两层意思：</p>
<ol>
<li><p>根据Key拿到Value，也就是get方法</p>
</li>
<li><p>修改Key对应的Value，也就是put方法</p>
</li>
</ol>
<p>首先看一下get方法，它在LinkedHashMap中被重写：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">  Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key);</span><br><span class="line">  <span class="keyword">if</span> (e == <span class="keyword">null</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  e.recordAccess(<span class="keyword">this</span>);</span><br><span class="line">  <span class="keyword">return</span> e.value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后是put方法，沿用父类HashMap的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">    <span class="keyword">return</span> putForNullKey(value);</span><br><span class="line">  <span class="keyword">int</span> hash = hash(key.hashCode());</span><br><span class="line">  <span class="keyword">int</span> i = indexFor(hash, table.length);</span><br><span class="line">  <span class="keyword">for</span> (Entry&lt;K,V&gt; e = table[i]; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">    Object k;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))) &#123;</span><br><span class="line"></span><br><span class="line">      V oldValue = e.value;</span><br><span class="line"></span><br><span class="line">      e.value = value;</span><br><span class="line"></span><br><span class="line">      e.recordAccess(<span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  modCount++;</span><br><span class="line">  addEntry(hash, key, value, i);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">修改数据也就是第<span class="number">6</span>行~第<span class="number">14</span>行的代码。看到两端代码都有一个共同点：都调用了recordAccess方法，且这个方法是Entry中的方法，也就是说每次的recordAccess操作的都是某一个固定的Entry。</span><br><span class="line"></span><br><span class="line">recordAccess，顾名思义，记录访问，也就是说你这次访问了双向链表，我就把你记录下来，怎么记录？把你访问的Entry移到尾部去。这个方法在HashMap中是一个空方法，就是用来给子类记录访问用的，看一下LinkedHashMap中的实现：</span><br><span class="line"></span><br><span class="line">```java </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">recordAccess</span><span class="params">(HashMap&lt;K,V&gt; m)</span> </span>&#123;</span><br><span class="line">  LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m;</span><br><span class="line">  <span class="keyword">if</span> (lm.accessOrder) &#123;</span><br><span class="line">    lm.modCount++;</span><br><span class="line"></span><br><span class="line">    remove();</span><br><span class="line"></span><br><span class="line">    addBefore(lm.header);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  before.after = after;</span><br><span class="line">  after.before = before;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addBefore</span><span class="params">(Entry&lt;K,V&gt; existingEntry)</span> </span>&#123;</span><br><span class="line">  after &amp;nbsp;= existingEntry;</span><br><span class="line">  before = existingEntry.before;</span><br><span class="line">  before.after = <span class="keyword">this</span>;</span><br><span class="line">  after.before = <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>看到每次recordAccess的时候做了两件事情：</p>
<ol>
<li><p>把待移动的Entry的前后Entry相连</p>
</li>
<li><p>把待移动的Entry移动到尾部</p>
</li>
</ol>
<p>当然，这一切都是基于accessOrder=true的情况下。最后用一张图表示一下整个recordAccess的过程吧：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/LinkedHashMap/7.png/w600">

<h1 id="代码演示LinkedHashMap按照访问顺序排序的效果"><a href="#代码演示LinkedHashMap按照访问顺序排序的效果" class="headerlink" title="代码演示LinkedHashMap按照访问顺序排序的效果"></a><strong>代码演示LinkedHashMap按照访问顺序排序的效果</strong></h1><p>最后代码演示一下LinkedList按照访问顺序排序的效果，验证一下上一部分LinkedHashMap的LRU功能：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">  LinkedHashMap&lt;String, String&gt; linkedHashMap = <span class="keyword">new</span> LinkedHashMap&lt;String, String&gt;(<span class="number">16</span>, <span class="number">0.75f</span>, <span class="keyword">true</span>);</span><br><span class="line">  </span><br><span class="line">  linkedHashMap.put(<span class="string">"111"</span>, <span class="string">"111"</span>);</span><br><span class="line">  linkedHashMap.put(<span class="string">"222"</span>, <span class="string">"222"</span>);</span><br><span class="line">  linkedHashMap.put(<span class="string">"333"</span>, <span class="string">"333"</span>);</span><br><span class="line">  linkedHashMap.put(<span class="string">"444"</span>, <span class="string">"444"</span>);</span><br><span class="line">  loopLinkedHashMap(linkedHashMap);</span><br><span class="line">  linkedHashMap.get(<span class="string">"111"</span>);</span><br><span class="line">  loopLinkedHashMap(linkedHashMap);</span><br><span class="line">  linkedHashMap.put(<span class="string">"222"</span>, <span class="string">"2222"</span>);</span><br><span class="line">  loopLinkedHashMap(linkedHashMap);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">loopLinkedHashMap</span><span class="params">(LinkedHashMap&lt;String, String&gt; linkedHashMap)</span></span>&#123;</span><br><span class="line">  Set&lt;Map.Entry&lt;String, String&gt;&gt; set = inkedHashMap.entrySet();</span><br><span class="line">  Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = set.iterator();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">while</span> (iterator.hasNext())&#123;</span><br><span class="line">    System.out.print(iterator.next() + <span class="string">"\t"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  System.out.println();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">注意这里的构造方法要用三个参数那个且最后的要传入<span class="keyword">true</span>，这样才表示按照访问顺序排序。看一下代码运行结果：</span><br><span class="line">```java </span><br><span class="line"><span class="number">111</span>=<span class="number">111</span>   <span class="number">222</span>=<span class="number">222</span>   <span class="number">333</span>=<span class="number">333</span>   <span class="number">444</span>=<span class="number">444</span>    <span class="number">222</span>=<span class="number">222</span>   <span class="number">333</span>=<span class="number">333</span>   <span class="number">444</span>=<span class="number">444</span>   <span class="number">111</span>=<span class="number">111</span>  <span class="number">333</span>=<span class="number">333</span>   <span class="number">444</span>=<span class="number">444</span>   <span class="number">111</span>=<span class="number">111</span>   <span class="number">222</span>=<span class="number">2222</span></span><br></pre></td></tr></table></figure>


<p>代码运行结果证明了两点：</p>
<ol>
<li><p>LinkedList是有序的；</p>
</li>
<li><p>每次访问一个元素（get或put），被访问的元素都被提到最后面去了。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java ArrayList图解</title>
    <url>/java/arraylist/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h1><p>集合是Java中非常重要而且基础的内容，因为任何数据必不可少的就是该数据是如何存储的，集合的作用就是以一定的方式组织、存储数据。这里写的集合，一部分是比较常见的、一部分是不常用但是我个人平时见到过的，一些比较相似的集合（比如HashMap和Hashtable）就只讲一个，突出它们之间的区别即可。</p>
<a id="more"></a>

<p>最后，要指出一点，对于集合，我认为关注的点主要有四点：</p>
<div class="note primary">
            <ol><li><p>是否允许空</p></li><li><p>是否允许重复数据</p></li><li><p>是否有序，有序的意思是读取数据的顺序和存放数据的顺序是否一致</p></li><li><p>是否线程安全&nbsp;</p></li></ol>
          </div>

<h1 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a><strong>ArrayList</strong></h1><p>ArrayList是最常见以及每个Java开发者最熟悉的集合类了，顾名思义，ArrayList就是一个以数组形式实现的集合，以一张表格来看一下ArrayList里面有哪些基本的元素：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/arraylist/1.png/w600">


<h1 id="四个关注点在ArrayList上的答案"><a href="#四个关注点在ArrayList上的答案" class="headerlink" title="四个关注点在ArrayList上的答案"></a><strong>四个关注点在ArrayList上的答案</strong></h1><p>以后每篇文章在讲解代码前，都会先对于一个集合关注的四个点以表格形式做一个解答：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/arraylist/2.png/w600">


<h1 id="添加元素"><a href="#添加元素" class="headerlink" title="添加元素"></a><strong>添加元素</strong></h1><p>有这么一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">    List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">    list.add(<span class="string">"000"</span>);</span><br><span class="line">    list.add(<span class="string">"111"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看下底层会做什么，进入add方法的源码来看一下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    ensureCapacity(size + <span class="number">1</span>); <span class="comment">// Increments modCount!!</span></span><br><span class="line">    elementData[size++] = e;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先不去管第2行的ensureCapacity方法，这个方法是扩容用的，底层实际上在调用add方法的时候只是给elementData的某个位置添加了一个数据而已，用一张图表示的话是这样的：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/arraylist/3.png/w600">

<p>多说一句，我这么画图有一定的误导性。elementData中存储的应该是堆内存中元素的引用，而不是实际的元素，这么画给人一种感觉就是说elementData数组里面存放的就是实际的元素，这是不太严谨的。不过这么画主要是为了方便起见，只要知道这个问题就好了。</p>
<h1 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a><strong>扩容</strong></h1><p>我们看一下，构造ArrayList的时候，默认的底层数组大小是10：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>(<span class="number">10</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>那么有一个问题来了，底层数组的大小不够了怎么办？答案就是扩容，这也就是为什么一直说ArrayList的底层是基于动态数组实现的原因，动态数组的意思就是指底层的数组大小并不是固定的，而是根据添加的元素大小进行一个判断，不够的话就动态扩容，扩容的代码就在ensureCapacity里面：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ensureCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">int</span> oldCapacity = elementData.length;</span><br><span class="line">    <span class="keyword">if</span> (minCapacity &gt; oldCapacity) &#123;</span><br><span class="line">        Object oldData[] = elementData;</span><br><span class="line">        <span class="keyword">int</span> newCapacity = (oldCapacity * <span class="number">3</span>)/<span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (newCapacity &lt; minCapacity)</span><br><span class="line">            newCapacity = minCapacity;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// minCapacity is usually close to size, so this is a win:</span></span><br><span class="line">        elementData = Arrays.copyOf(elementData, newCapacity);</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">看到扩容的时候把元素组大小先乘以<span class="number">3</span>，再除以<span class="number">2</span>，最后加<span class="number">1</span>。可能有些人要问为什么？我们可以想：</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>. 如果一次性扩容扩得太大，必然造成内存空间的浪费</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 如果一次性扩容扩得不够，那么下一次扩容的操作必然比较快地会到来，这会降低程序运行效率，要知道扩容还是比价耗费性能的一个操作</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">所以扩容扩多少，是JDK开发人员在时间、空间上做的一个权衡，提供出来的一个比较合理的数值。最后调用到的是Arrays的copyOf方法，将元素组里面的内容复制到新的数组里面去：</span><br><span class="line">```java</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T,U&gt; T[] copyOf(U[] original, <span class="keyword">int</span> newLength, Class&lt;? extends T[]&gt; newType) &#123;</span><br><span class="line">    T[] copy = ((Object)newType == (Object)Object[]<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line">    ? (T[]) new Object[newLength]</span><br><span class="line"></span><br><span class="line">    : (T[]) Array.newInstance(newType.getComponentType(), newLength);</span><br><span class="line">    System.arraycopy(original, <span class="number">0</span>, copy, <span class="number">0</span>,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Math.min(original.length, newLength));</span><br><span class="line">    <span class="keyword">return</span> copy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>用一张图来表示就是这样的：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/arraylist/4.png/w600">

<h1 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a><strong>删除元素</strong></h1><p>接着我们看一下删除的操作。ArrayList支持两种删除方式：</p>
<ol>
<li><p>按照下标删除</p>
</li>
<li><p>按照元素删除，这会删除ArrayList中与指定要删除的元素匹配的第一个元素</p>
</li>
</ol>
<p>对于ArrayList来说，这两种删除的方法差不多，都是调用的下面一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> numMoved = size - index - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</span><br><span class="line">    System.arraycopy(elementData, index+<span class="number">1</span>, elementData, index,numMoved);</span><br><span class="line">elementData[--size] = <span class="keyword">null</span>; <span class="comment">// Let gc do its work</span></span><br></pre></td></tr></table></figure>

<p>其实做的事情就是两件:</p>
<ol>
<li><p>把指定元素后面位置的所有元素，利用System.arraycopy方法整体向前移动一个位置</p>
</li>
<li><p>最后一个位置的元素指定为null，这样让gc可以去回收它</p>
</li>
</ol>
<p>比方说有这么一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">list.add(<span class="string">"111"</span>);</span><br><span class="line">list.add(<span class="string">"222"</span>);</span><br><span class="line">list.add(<span class="string">"333"</span>);</span><br><span class="line">list.add(<span class="string">"444"</span>);</span><br><span class="line">list.add(<span class="string">"555"</span>);</span><br><span class="line">list.add(<span class="string">"666"</span>);</span><br><span class="line">list.add(<span class="string">"777"</span>);</span><br><span class="line">list.add(<span class="string">"888"</span>);</span><br><span class="line">list.remove(<span class="string">"333"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>用图表示是这样的：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/arraylist/5.png/w600">

<h1 id="插入元素"><a href="#插入元素" class="headerlink" title="插入元素"></a><strong>插入元素</strong></h1><p>看一下ArrayList的插入操作，插入操作调用的也是add方法，比如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">    List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">    list.add(<span class="string">"111"</span>);</span><br><span class="line">    list.add(<span class="string">"222"</span>);</span><br><span class="line">    list.add(<span class="string">"333"</span>);</span><br><span class="line">    list.add(<span class="string">"444"</span>);</span><br><span class="line">    list.add(<span class="string">"555"</span>);</span><br><span class="line">    list.add(<span class="string">"666"</span>);</span><br><span class="line">    list.add(<span class="string">"777"</span>);</span><br><span class="line">    list.add(<span class="string">"888"</span>);</span><br><span class="line">    list.add(<span class="number">2</span>, <span class="string">"000"</span>);</span><br><span class="line">    System.out.println(list);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">有一个地方不要搞错了，第<span class="number">12</span>行的add方法的意思是，往第几个元素后面插入一个元素，像第<span class="number">12</span>行就是往第二个元素后面插入一个<span class="number">000</span>。看一下运行结果也证明了这一点：</span><br><span class="line"></span><br><span class="line">&gt; [<span class="number">111</span>, <span class="number">222</span>, <span class="number">000</span>, <span class="number">333</span>, <span class="number">444</span>, <span class="number">555</span>, <span class="number">666</span>, <span class="number">777</span>, <span class="number">888</span>]</span><br><span class="line"></span><br><span class="line">还是看一下插入的时候做了什么：</span><br><span class="line">```java</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (index &gt; size || index &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(<span class="string">"Index: "</span>+index+<span class="string">", Size: "</span>+size);</span><br><span class="line">    ensureCapacity(size+<span class="number">1</span>); <span class="comment">// Increments modCount!!System.arraycopy(elementData, index, elementData, index + 1,</span></span><br><span class="line"></span><br><span class="line">    &amp;nbsp;size - index);elementData[index] = element;size++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看到插入的时候，按照指定位置，把从指定位置开始的所有元素利用System,arraycopy方法做一个整体的复制，向后移动一个位置（当然先要用ensureCapacity方法进行判断，加了一个元素之后数组会不会不够大），然后指定位置的元素设置为需要插入的元素，完成了一次插入的操作。用图表示这个过程是这样的：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/arraylist/6.png/w600">

<h1 id="ArrayList的优缺点"><a href="#ArrayList的优缺点" class="headerlink" title="ArrayList的优缺点"></a><strong>ArrayList的优缺点</strong></h1><p>从上面的几个过程总结一下ArrayList的优缺点。ArrayList的优点如下：</p>
<ol>
<li><p>ArrayList底层以数组实现，是一种随机访问模式，再加上它实现了RandomAccess接口，因此查找也就是get的时候非常快</p>
</li>
<li><p>ArrayList在顺序添加一个元素的时候非常方便，只是往数组里面添加了一个元素而已</p>
</li>
</ol>
<p>不过ArrayList的缺点也十分明显：</p>
<ol>
<li><p>删除元素的时候，涉及到一次元素复制，如果要复制的元素很多，那么就会比较耗费性能</p>
</li>
<li><p>插入元素的时候，涉及到一次元素复制，如果要复制的元素很多，那么就会比较耗费性能</p>
</li>
</ol>
<p>因此，ArrayList比较适合顺序添加、随机访问的场景。</p>
<h1 id="ArrayList和Vector的区别"><a href="#ArrayList和Vector的区别" class="headerlink" title="ArrayList和Vector的区别"></a><strong>ArrayList和Vector的区别</strong></h1><p>ArrayList是线程非安全的，这很明显，因为ArrayList中所有的方法都不是同步的，在并发下一定会出现线程安全问题。那么我们想要使用ArrayList并且让它线程安全怎么办？一个方法是用Collections.synchronizedList方法把你的ArrayList变成一个线程安全的List，比如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; synchronizedList = Collections.synchronizedList(list);synchronizedList.add(<span class="string">"aaa"</span>);</span><br><span class="line">synchronizedList.add(<span class="string">"bbb"</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; synchronizedList.size(); i++)&#123;</span><br><span class="line">    System.out.println(synchronizedList.get(i));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另一个方法就是Vector，它是ArrayList的线程安全版本，其实现90%和ArrayList都完全一样，区别在于：</p>
<ol>
<li><p>Vector是线程安全的，ArrayList是线程非安全的</p>
</li>
<li><p>Vector可以指定增长因子，如果该增长因子指定了，那么扩容的时候会每次新的数组大小会在原数组的大小基础上加上增长因子；如果不指定增长因子，那么就给原数组大小*2，源代码是这样的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> newCapacity = oldCapacity + ((capacityIncrement &gt; <span class="number">0</span>) ? capacityIncrement : oldCapacity);</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h1 id="为什么ArrayList的elementData是用transient修饰的？"><a href="#为什么ArrayList的elementData是用transient修饰的？" class="headerlink" title="为什么ArrayList的elementData是用transient修饰的？"></a><strong>为什么ArrayList的elementData是用transient修饰的？</strong></h1><p>最后一个问题，我们看一下ArrayList中的数组，是这么定义的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> Object[] elementData;</span><br></pre></td></tr></table></figure>

<p>不知道大家有没有想过，为什么elementData是使用transient修饰的呢？关于这个问题，说说我的看法。我们看一下ArrayList的定义：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArrayList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">RandomAccess</span>, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span></span><br></pre></td></tr></table></figure>
<p>看到ArrayList实现了Serializable接口，这意味着ArrayList是可以被序列化的，用transient修饰elementData意味着我不希望elementData数组被序列化。这是为什么？因为序列化ArrayList的时候，ArrayList里面的elementData未必是满的，比方说elementData有10的大小，但是我只用了其中的3个，那么是否有必要序列化整个elementData呢？显然没有这个必要，因此ArrayList中重写了writeObject方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeObject</span><span class="params">(java.io.ObjectOutputStream s)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> java.io.IOException</span>&#123;<span class="comment">// Write out element count, and any hidden stuffint expectedModCount = modCount;s.defaultWriteObject();</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Write out array length</span></span><br><span class="line">&amp;nbsp; &amp;nbsp;s.writeInt(elementData.length);</span><br><span class="line"><span class="comment">// Write out all elements in the proper order.for (int i=0; i&lt;size; i++)</span></span><br><span class="line"></span><br><span class="line">&amp;nbsp; &amp;nbsp;s.writeObject(elementData[i]);</span><br><span class="line"><span class="keyword">if</span> (modCount != expectedModCount) &#123;</span><br><span class="line">    &amp;nbsp; &amp;nbsp;<span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每次序列化的时候调用这个方法，先调用defaultWriteObject()方法序列化ArrayList中的非transient元素，elementData不去序列化它，然后遍历elementData，只序列化那些有的元素，这样：</p>
<ol>
<li>加快了序列化的速度</li>
<li>减小了序列化之后的文件大小</li>
</ol>
<p>不失为一种聪明的做法，如果以后开发过程中有遇到这种情况，也是值得学习、借鉴的一种思路。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>anatomy</title>
    <url>/java/anatomy/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>anatomy 是阿里同学开发的一款用于JVM进程执行过程中的异常诊断工具，可以在不中断程序执行的情况下轻松完成问题排查工作。</p>
<a id="more"></a>

<ul>
<li>纯Java实现的开源项目</li>
<li>安装使用便捷</li>
<li>方法级问题诊断</li>
<li>Groovy表达式展开变对象，方便你观察入参、出参、异常、当前对象的各种属性细节</li>
</ul>
<h1 id="接下来结合线上应用，列举常用的几个排查问题命令如何使用"><a href="#接下来结合线上应用，列举常用的几个排查问题命令如何使用" class="headerlink" title="接下来结合线上应用，列举常用的几个排查问题命令如何使用"></a>接下来结合线上应用，列举常用的几个排查问题命令如何使用</h1><h2 id="1、安装："><a href="#1、安装：" class="headerlink" title="1、安装："></a>1、安装：</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -sLk http://ompc.oss.aliyuncs.com/greys/install.sh|sh</span><br></pre></td></tr></table></figure>

<h2 id="2、启动"><a href="#2、启动" class="headerlink" title="2、启动"></a>2、启动</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">greys.sh  &lt;PID&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注：PID：目标Java进程ID</span></span><br></pre></td></tr></table></figure>

<h2 id="3、help"><a href="#3、help" class="headerlink" title="3、help"></a>3、help</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">help</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 注：所有命令</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">help</span> watch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注：help命令同时也支持对其他命令的一个解释说明，比如我们键入help watch，包含（用途说明、参数列表、实际例子）</span></span><br></pre></td></tr></table></figure>

<h2 id="4、sc-搜索所有已经加载到JVM中的Class信息。"><a href="#4、sc-搜索所有已经加载到JVM中的Class信息。" class="headerlink" title="4、sc 搜索所有已经加载到JVM中的Class信息。"></a>4、sc 搜索所有已经加载到JVM中的Class信息。</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sc -d *RecommendManagerImpl</span><br></pre></td></tr></table></figure>
<p><strong>使用场景：</strong></p>
<p>主要是用于排查一个应用可能存在同一个jar包的多个版本，而不同版本的类的方法可能会有实现上的差异，可以通过这种方式确认JVM中加载的是哪一个jar下的类。</p>
<h2 id="5、monitor-方法层面的性能监控，非实时返回的命令，则是不断的等待目标Java进程返回信息，直到用户输入Ctrl-D为止"><a href="#5、monitor-方法层面的性能监控，非实时返回的命令，则是不断的等待目标Java进程返回信息，直到用户输入Ctrl-D为止" class="headerlink" title="5、monitor 方法层面的性能监控，非实时返回的命令，则是不断的等待目标Java进程返回信息，直到用户输入Ctrl+D为止"></a>5、monitor 方法层面的性能监控，非实时返回的命令，则是不断的等待目标Java进程返回信息，直到用户输入Ctrl+D为止</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">monitor -c 5  *TimelineReadServiceImpl getEditorRecPost</span><br><span class="line"></span><br><span class="line">注：-c : 统计周期，默认值为120秒</span><br></pre></td></tr></table></figure>

<p><strong>使用场景：</strong></p>
<p>线上反馈某个接口突然响应较慢，但又缺乏全链路维度节点的监控，可以通过该命令能定位到具体哪个方法耗时较长，有效缩小排查范围。</p>
<h2 id="6、trace-统计整个调用链路上的所有性能开销和追踪调用链路。"><a href="#6、trace-统计整个调用链路上的所有性能开销和追踪调用链路。" class="headerlink" title="6、trace 统计整个调用链路上的所有性能开销和追踪调用链路。"></a>6、trace 统计整个调用链路上的所有性能开销和追踪调用链路。</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">trace -n 2 *TimelineReadServiceImpl queryRecPageTimeLine</span><br></pre></td></tr></table></figure>

<p><strong>使用场景：</strong></p>
<p>定位查找某一接口响应较慢，主要是损耗在哪一个环节。</p>
<p>另外也可以做为性能优化的参考标准，了解一个接口下面每个环节的消耗时间，从而判断是否合理，有没有优化的空间</p>
<h2 id="7、watch-观察到指定方法的调用情况"><a href="#7、watch-观察到指定方法的调用情况" class="headerlink" title="7、watch 观察到指定方法的调用情况"></a>7、watch 观察到指定方法的调用情况</h2><p>能观察到的范围：入参、返回值、抛出异常，通过编写groovy表达式进行对应变量的查看。详细使用手册可以通过命令help watch</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">watch -b  *TimelineReadServiceImpl queryRecPageTimeLine  params[0]</span><br><span class="line"></span><br><span class="line">注：打印完整的入参信息</span><br><span class="line"></span><br><span class="line">watch -b  *TimelineReadServiceImpl queryRecPageTimeLine  params[0] &#39;params[0].uid&gt;2894731&#39; </span><br><span class="line"></span><br><span class="line">注：带上groovy表达式，uid&gt;2894731</span><br><span class="line"></span><br><span class="line">watch -s  *TimelineReadServiceImpl queryRecPageTimeLine  params[0]+returnObj &#39;params[0].uid&#x3D;&#x3D;3680667&#39;</span><br><span class="line"></span><br><span class="line">注：当请求的uid为3680667时，打印入参和返回结果</span><br></pre></td></tr></table></figure>

<h2 id="8、-jvm"><a href="#8、-jvm" class="headerlink" title="8、 jvm"></a>8、 jvm</h2><p>查看当前JVM的信息，无参数</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://github.com/oldmanpushcart/greys-anatomy/wiki/Commands#help" target="_blank" rel="noopener">https://github.com/oldmanpushcart/greys-anatomy/wiki/Commands#help</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java类加载器</title>
    <url>/java/class-loader/</url>
    <content><![CDATA[<h1 id="什么是类的加载"><a href="#什么是类的加载" class="headerlink" title="什么是类的加载"></a>什么是类的加载</h1><p>类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放入方法区，并在堆区创建一个 java.lang.Class对象，用来描述类在方法区内的数据结构（比如，类的name、全局变量、构造器和方法等）。类加载的最终产物是位于堆区中的 Class对象， Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。允许用户根据这些元信息对象间接调用Class对象的功能，即“反射”机制。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-class-loader/java-class-loader-1.png/w600">

<p>类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误</p>
<h1 id="类的生命周期"><a href="#类的生命周期" class="headerlink" title="类的生命周期"></a>类的生命周期</h1><img data-src="http://f.ngall-in.com/alan87/static/images/java/java-class-loader/java-class-loader-2.jpg/w600">

<p>其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。</p>
<h2 id="1、加载"><a href="#1、加载" class="headerlink" title="1、加载"></a>1、加载</h2><p>在加载阶段，虚拟机需要完成以下三件事情：</p>
<ul>
<li>通过一个类的全限定名来获取其定义的二进制字节流。</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</li>
<li>在Java堆中生成一个代表这个类的 java.lang.Class对象，作为对方法区中这些数据的访问入口。</li>
</ul>
<p>相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。</p>
<p>加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个 java.lang.Class类的对象，这样便可以通过该对象访问方法区中的数据。</p>
<h2 id="2、连接"><a href="#2、连接" class="headerlink" title="2、连接"></a>2、连接</h2><h2 id="2-1-验证"><a href="#2-1-验证" class="headerlink" title="2.1 验证"></a>2.1 验证</h2><p><strong>确保被加载的类的正确性。</strong></p>
<p>验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作：</p>
<ul>
<li>文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以 0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。</li>
<li>元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了 java.lang.Object之外。</li>
<li>字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。</li>
<li>符号引用验证：确保解析动作能正确执行。</li>
</ul>
<p>验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用 -Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。</p>
<h2 id="2-2-准备"><a href="#2-2-准备" class="headerlink" title="2.2 准备"></a>2.2 准备</h2><p><strong>为类的 静态变量分配内存，并将其初始化为默认值。</strong></p>
<p>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：</p>
<ul>
<li>这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。</li>
<li>这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。</li>
</ul>
<p>假设一个类变量的定义为：<code>public static int value=3；</code></p>
<p>那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的 public static 指令是在程序编译后，存放于类构造器 &lt;clinit&gt;（）方法中，所以把value赋值为3的动作将在<code>初始化阶段</code>才会执行。</p>
<ul>
<li>如果类字段的字段属性表中存在 ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。</li>
</ul>
<p>假设上面的类变量value被定义为： <code>public static final int value=3；</code></p>
<p>编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据 ConstantValue的设置将value赋值为3。我们可以理解为static final常量在编译期就将其结果放入了调用它的类的常量池中</p>
<h2 id="2-3-解析"><a href="#2-3-解析" class="headerlink" title="2.3 解析"></a>2.3 解析</h2><p><strong>把类中的符号引用转换为直接引用</strong></p>
<p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。</p>
<p>直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。</p>
<h2 id="3、初始化"><a href="#3、初始化" class="headerlink" title="3、初始化"></a>3、初始化</h2><p>初始化，为类的静态变量赋予正确的初始值，有两种方式：</p>
<ul>
<li>声明类变量是指定初始值</li>
<li>使用静态代码块为类变量指定初始值</li>
</ul>
<p>JVM初始化步骤</p>
<ul>
<li>假如这个类还没有被加载和连接，则程序先加载并连接该类</li>
<li>假如该类的直接父类还没有被初始化，则先初始化其直接父类</li>
<li>假如类中有初始化语句，则系统依次执行这些初始化语句</li>
</ul>
<p>类初始化时机：只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种：</p>
<ul>
<li>创建类的实例，也就是new的方式</li>
<li>访问某个类或接口的静态变量，或者对该静态变量赋值</li>
<li>调用类的静态方法</li>
<li>反射（如 Class.forName(“com.shengsiyuan.Test”)）</li>
<li>初始化某个类的子类，则其父类也会被初始化</li>
<li>Java虚拟机启动时被标明为启动类的类（ Java Test），直接使用 java.exe命令来运行某个主类</li>
</ul>
<h2 id="4、使用阶段"><a href="#4、使用阶段" class="headerlink" title="4、使用阶段"></a>4、使用阶段</h2><h2 id="5、结束生命周期"><a href="#5、结束生命周期" class="headerlink" title="5、结束生命周期"></a>5、结束生命周期</h2><p>在如下几种情况下，Java虚拟机将结束生命周期</p>
<ul>
<li>执行了 System.exit()方法</li>
<li>程序正常执行结束</li>
<li>程序在执行过程中遇到了异常或错误而异常终止</li>
<li>由于操作系统出现错误而导致Java虚拟机进程终止</li>
</ul>
<h1 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h1><p>类的装载器有三个：根装载器（用C++编写），负责装载JRE的核心类库。ExtClassLoader扩展类加载器，负责加载ext目录下的jar包。AppClassLoader系统类装载器，负责装载Classpath路径下的类包。这三个类装载器存在父子层级关系，根装载器是ExtClassLoader的父装载器，ExtClassLoader是AppClassLoader的父装载器。一般来说，Java 应用的类都是由AppClassLoader来完成加载的。可以通过 ClassLoader.getSystemClassLoader() 来获取它。一般来说，开发人员编写的类加载器的父类加载器是 应用类加载器  Application ClassLoader  </p>
<p>除了系统提供的类加载器以外，开发人员可以通过继承 java.lang.ClassLoader 类的方式实现自己的类加载器，以满足一些特殊的需求。</p>
<p>除了根类加载器之外，所有的类加载器都有一个父类加载器。可以通过 getParent()方法得到。<strong>不同的类加载器为相同名字的类创建了额外的名称空间，所以相同名称的类才可以并存在 Java 虚拟机中，只需要用不同的类加载器来加载它们即可。</strong>不同类加载器加载的类之间是不兼容的（相当于两个不同的类型），这就相当于在 Java 虚拟机内部创建了一个个相互隔离的 Java 类空间。这种技术在许多框架中都被用到，如OSGI等。</p>
<p>jvm启动时，会启动jre/rt.jar里的类加载器：bootstrap classloader，用来加载java核心api；然后启动扩展类加载器ExtClassLoader加载扩展类，并加载用户程序加载器AppClassLoader，并指定ExtClassLoader为他的父类；</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-class-loader/java-class-loader-3.jpeg/w600">

<p>CommonClassLoader、CatalinaClassLoader和SharedClassLoader与具体部署的Web应用无关，而WebappClassLoader则对应Web应用，每个Web应用都会有独立的类加载器，从而实现类的隔离。当类被加载时，会先检查在内存中是否已经被加载，如果是，则不再加载，如果没有，再由AppClassLoader来加载，先从jar包里找，没有再从classpath里找；如果自定义loader类，就会存在命名空间的情况，不同的加载器加载同一个类时，产生的实例其实是不同的。</p>
<h1 id="JVM类加载机制"><a href="#JVM类加载机制" class="headerlink" title="JVM类加载机制"></a>JVM类加载机制</h1><ul>
<li><strong>全盘负责</strong>，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入</li>
<li><strong>父类委托</strong>，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类</li>
<li><strong>缓存机制</strong>，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效</li>
</ul>
<h1 id="双亲委派模式"><a href="#双亲委派模式" class="headerlink" title="双亲委派模式"></a>双亲委派模式</h1><p>双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。这也就可以解释为什么无法加载一个自定义的java.lang.String类！！！</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-class-loader/java-class-loader-4.jpeg/w600">

<p>双亲委派机制:</p>
<div class="note primary">
            <p>1、当 AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。<br>2、当 ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。<br>3、如果 BootStrapClassLoader加载失败（例如在 $JAVA_HOME/jre/lib里未查找到该class），会使用 ExtClassLoader来尝试加载；<br>4、若ExtClassLoader也加载失败，则会使用 AppClassLoader来加载，如果 AppClassLoader也加载失败，则会报出异常 ClassNotFoundException。</p>
          </div>

<p>ClassLoader源码分析：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">synchronized</span> Class&lt;?&gt; loadClass(String name, <span class="keyword">boolean</span> resolve)</span><br><span class="line"> <span class="keyword">throws</span> ClassNotFoundException&#123;</span><br><span class="line"> <span class="comment">// 首先判断该类型是否已经被加载</span></span><br><span class="line"> Class c = findLoadedClass(name);</span><br><span class="line"> <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;</span><br><span class="line"> 	<span class="comment">//如果没有被加载，就委托给父类加载或者委派给启动类加载器加载</span></span><br><span class="line">     <span class="keyword">try</span> &#123;</span><br><span class="line">  		<span class="keyword">if</span> (parent != <span class="keyword">null</span>) &#123;</span><br><span class="line">     	 	 <span class="comment">//如果存在父类加载器，就委派给父类加载器加载，false表示加载的类不会初始化</span></span><br><span class="line">     		 c = parent.loadClass(name, <span class="keyword">false</span>);</span><br><span class="line">  		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     		<span class="comment">//如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native 			// Class findBootstrapClass(String name)</span></span><br><span class="line">      		c = findBootstrapClass0(name);</span><br><span class="line">  		&#125;</span><br><span class="line">     &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</span><br><span class="line">         <span class="comment">// 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能</span></span><br><span class="line">         c = findClass(name);</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">if</span> (resolve) &#123;</span><br><span class="line">     resolveClass(c);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>双亲委派模型意义：</p>
<ul>
<li>系统类防止内存中出现多份同样的字节码</li>
<li>保证Java程序安全稳定运行</li>
</ul>
<h1 id="类的完整标识是（classLoader，package，className）"><a href="#类的完整标识是（classLoader，package，className）" class="headerlink" title="类的完整标识是（classLoader，package，className）"></a>类的完整标识是（classLoader，package，className）</h1><h1 id="Class-forName-和ClassLoader-loadClass-区别"><a href="#Class-forName-和ClassLoader-loadClass-区别" class="headerlink" title="Class.forName()和ClassLoader.loadClass()区别"></a>Class.forName()和ClassLoader.loadClass()区别</h1><p>类加载有三种方式：</p>
<ul>
<li>java命令行启动应用时候由JVM初始化加载</li>
<li>通过Class.forName()方法动态加载</li>
<li>通过ClassLoader.loadClass()方法动态加载</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Class&lt;?&gt; loadClass(String name) </span><br><span class="line"></span><br><span class="line">Class&lt;?&gt; loadClass(String name, <span class="keyword">boolean</span> resolve)</span><br></pre></td></tr></table></figure>

<p>我们看到上面两个方法声明，第二个方法的第二个参数用于设置加载类的时候是否链接该类（上文中装载类文件的第二步），true链接，否则就不链接。Class类的forName方法则相反，使用forName加载时会将Class进行解析和初始化。</p>
<p>例如：JDBC DRIVER的加载，我们在加载JDBC驱动的时候都是使用的forName而非是ClassLoader的loadClass方法呢？我们知道，JDBC驱动是通过DriverManager，必须在DriverManager中注册，如果驱动类没有被初始化，则不能注册到DriverManager中，因此必须使用forName而不是用LoadClass。 </p>
<h1 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a>自定义类加载器</h1><p>通常情况下，我们都是直接使用系统类加载器。但是，有的时候，我们也需要自定义类加载器。比如应用是通过网络来传输 Java类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承 ClassLoader类，并重写 findClass 方法</p>
<h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h1><p><a href="https://mp.weixin.qq.com/s/rLooaTOU_NQTJdn28KAUFw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/rLooaTOU_NQTJdn28KAUFw</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>强引用、软引用、弱引用、幻象引用</title>
    <url>/java/class-reference/</url>
    <content><![CDATA[<ul>
<li><p>强引用<br>常见的普通对象引用，只要还有强引用指向一个对象，就表示这个对象还“活着”，垃圾回收不会回收这种对象。对于一个普通对象，如果没有其他引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就可以被垃圾收集了。</p>
<a id="more"></a>
</li>
<li><p>软引用<br>SoftReference，相对强引用弱一些，可以让对象豁免一些垃圾收集，只有当JVM 认为内存不足时，才会去试图回收软引用指向的对象。</p>
</li>
</ul>
<p>JVM会确保在抛出OutofMemoryError之前，清理软引用指向的对象。这样保证了使用缓存的同时，不会耗尽内存。</p>
<ul>
<li>弱引用<br>并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途经。</li>
</ul>
<p>如果试图获取时对象还在，就使用它，否则重新实例化，它同样是很多缓存实现的选择。</p>
<ul>
<li>幻象引用<br>也叫虚引用，你不能通过它访问对象。仅仅提供了对象被finalize以后，做某些事情的机制，比如 Post-Mortem清理机制</li>
</ul>
<p>对象可达性状态流转图：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-class-reference/java-class-reference.jpeg/w600">

<p>所有引用类型，都是抽象类 java.lang.ref.Reference的子类，提供了get（）方法。</p>
<p><strong>除了幻象引用（get返回null），如果对象没有被销毁，都可以通过get（）方法获取原有对象，我们可以将访问到的对象，重新指向强引用，也就是人为的改变对象的可达性状态。</strong></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>常用Java类库</title>
    <url>/java/common-class-lib/</url>
    <content><![CDATA[<h1 id="1-Runtime类"><a href="#1-Runtime类" class="headerlink" title="1.Runtime类"></a>1.Runtime类</h1><ul>
<li>jvm虚拟机注册一个勾子，当虚拟机要关闭时，会执行预先注册的线程任务。</li>
</ul>
<a id="more"></a>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            logger.info(<span class="string">"## stop the canal client"</span>);</span><br><span class="line">            clientTest.stop();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">            logger.warn(<span class="string">"##something goes wrong when stopping canal:\n&#123;&#125;"</span>, ExceptionUtils.getFullStackTrace(e));</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            logger.info(<span class="string">"## canal client is down."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p> <a href="https://mp.weixin.qq.com/s/z5bfW8OJOYMK-fzSzDOkdg" target="_blank" rel="noopener">ShutdownHook - java中优雅地停止服务</a></p>
<ul>
<li>获取JVM的内存空间信息</li>
</ul>
<h1 id="2-字符串操作"><a href="#2-字符串操作" class="headerlink" title="2. 字符串操作"></a>2. 字符串操作</h1><ul>
<li><p>StringBuffer 线程安全</p>
</li>
<li><p>StringBuilder 非线程安全，适用于单线程，速度快</p>
</li>
</ul>
<h1 id="3-日期操作"><a href="#3-日期操作" class="headerlink" title="3. 日期操作"></a>3. 日期操作</h1><ul>
<li>Date</li>
<li>Calendar</li>
<li>DateFormat</li>
<li>SimpleDateFormat</li>
</ul>
<h1 id="4-Math类"><a href="#4-Math类" class="headerlink" title="4.Math类"></a>4.Math类</h1><p>数学操作相关，提供一系列的数学操作方法。比如：求平方根，两数的最大值，两数的最小值，四舍五入，2的3次方，绝对值，三角函数等等</p>
<h1 id="5-Random类"><a href="#5-Random类" class="headerlink" title="5. Random类"></a>5. Random类</h1><p>可以指定一个随机数的范围，然后任意产生此范围的数字。</p>
<h1 id="6-DecimalFormat"><a href="#6-DecimalFormat" class="headerlink" title="6. DecimalFormat"></a>6. DecimalFormat</h1><p>Format的一个子类，可以根据用户自定义格式来格式化数字</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DecimalFormat df=<span class="keyword">new</span> DecimalFormat(<span class="string">"###,###.###"</span>);</span><br><span class="line">df.format(<span class="number">1234232.1456</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 结果</span></span><br><span class="line"><span class="number">1</span>,<span class="number">234</span>,<span class="number">232.146</span></span><br></pre></td></tr></table></figure>

<h1 id="7-BigInteger"><a href="#7-BigInteger" class="headerlink" title="7. BigInteger"></a>7. BigInteger</h1><p>大整数类。如果在操作时一个整型数据超过了整数的最大长度Long，可以使用此类。</p>
<p>提供了一系列方法，用于基本运算。</p>
<h1 id="8-BigDecimal"><a href="#8-BigDecimal" class="headerlink" title="8. BigDecimal"></a>8. BigDecimal</h1><p>float和double无法做到准确的精度计数，如果需要精确的计算结果，可以使用此类。</p>
<p>注：通常涉及到钱的计算，比如交易订单各种折扣、优惠混合运算，最好使用此类。</p>
<h1 id="9-Arrays"><a href="#9-Arrays" class="headerlink" title="9. Arrays"></a>9. Arrays</h1><p>数组元素的查找、数组内容的填充、排序等</p>
<h1 id="10-Comparable接口"><a href="#10-Comparable接口" class="headerlink" title="10. Comparable接口"></a>10. Comparable接口</h1><p>比较器，排序时使用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(T o)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>与Arrays.sort(Object[] a)方法或者Collections.sort(List<T> list)方法组合使用。</p>
<p>另一种用法：</p>
<p><code>java.util.Collections.sort(List&lt;T&gt;, Comparator&lt;? super T&gt;)</code></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>常用的设计模式</title>
    <url>/java/common-design-patterns/</url>
    <content><![CDATA[<h1 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h1><p>保证一个类仅有一个实例，并提供一个访问它的全局访问点</p>
<a id="more"></a>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonClass</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> SingletonClass instance=<span class="keyword">null</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonClass <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(instance==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">synchronized</span>(SingletonClass<span class="class">.<span class="keyword">class</span>)</span>&#123;</span><br><span class="line">                <span class="keyword">if</span>(instance==<span class="keyword">null</span>)&#123;</span><br><span class="line">                    instance=<span class="keyword">new</span> SingletonClass();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><a href="https://mp.weixin.qq.com/s/2ARZEkUZWKN0fxHfkayYHA" target="_blank" rel="noopener">如何实现一个正确的单例模式</a></p>
<p><a href="https://mp.weixin.qq.com/s/1fQkkdtzYh_OikbYJnmZWg" target="_blank" rel="noopener">漫画：什么是单例模式？（整合版）</a></p>
<h1 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h1><p><strong>类图：</strong></p>
<pre class="mermaid" style="text-align: center;">
            classDiagram
            class IProduct{
  <<所有产品的接口>>
  +function() int
}
IProduct <|.. Product_A
IProduct <|.. Product_B

class Creator
Creator: <<具体工厂类>>
Creator: +factory() IProduct

Creator "0..1"-->"0..*" Product_A
Creator "0..1"-->"0..*" Product_B

class Product_A{
  <<具体产品A>>
  +function() int
}
class Product_B{
  <<具体产品B>>
  +function() int
}
          </pre>


<h1 id="装饰模式"><a href="#装饰模式" class="headerlink" title="装饰模式"></a>装饰模式</h1><p>装饰者模式，在保持原有功能不变的情况下将一个类重新装饰，使其具有更强大的功能，用一句成语形容“锦上添花”。</p>
<p><strong>类结构：</strong></p>
<pre class="mermaid" style="text-align: center;">
            classDiagram
            class IComponent{
  <<interface>>
  +methodA()
}

class ComponentImpl{
    +methodA()
} 

class Decoractor{
    -Component: IComponent
    +methodA()
}

IComponent <|.. ComponentImpl
IComponent <|.. Decoractor

Decoractor *..IComponent
          </pre>


<p>Component：抽象组件，定义了一组抽象的接口，指定了被装饰的组件都有哪些功能。</p>
<p>ComponentImpl：抽象组件实现类，完成了基本的功能实现。</p>
<p>Decorator：装饰器角色，持有Component的实例引用，有点递归的感觉。</p>
<p>伪代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Component c=<span class="keyword">new</span> ComponentImpl();</span><br><span class="line">Decorator d1=<span class="keyword">new</span> Decorator();</span><br><span class="line">d1.setComponent(c);</span><br><span class="line">Decorator d2=<span class="keyword">new</span> Decorator();</span><br><span class="line">d2.setComponent(d1);</span><br><span class="line">Decorator d3=<span class="keyword">new</span> Decorator();</span><br><span class="line">d3.setComponent(d2);</span><br><span class="line">Decorator d4=<span class="keyword">new</span> Decorator();</span><br><span class="line">d4.setComponent(d3);</span><br><span class="line">d4.methodA();</span><br></pre></td></tr></table></figure>
<p>装饰者模式和适配器模式有点类似，都是包装（wrapper）了一个类，但目地却不相同。适配器模式是将一个接口转换成另一个接口，从而达成匹配。而装饰者模式并没有改变原来的接口，而是改变原有对象的处理方法，借助递归提升性能。</p>
<h1 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h1><p>适配器模式就是一个类的接口不能被客户端接受，需要转换为另一种接口，从而使两个不匹配的接口能在一起工作。</p>
<p><strong>类结构</strong></p>
<pre class="mermaid" style="text-align: center;">
            classDiagram
            class Adaptee

class ITarget
ITarget: <<Interface>>
ITarget: +methodA()

class Adapter
Adapter: +methodA()

Adaptee <|-- Adapter
ITarget <|.. Adapter
          </pre>

<ul>
<li><p>Adaptee：源接口，需要适配的接口</p>
</li>
<li><p>Target：目标接口，暴露出去的接口</p>
</li>
<li><p>Adapter：适配器，将源接口适配成目标接口</p>
</li>
</ul>
<p>举个现实例子：</p>
<p>Adaptee就是相机中的内存卡片，Target就是电脑，而Adapter则是USB读卡器。</p>
<p><strong>适用场景：</strong></p>
<p>比如查物流信息，由于物流公司的系统都是各自独立，在编程语言和交互方式上有很大差异，需要针对不同的物流公司做单独适配，同时结合不同公司的系统性能，配置不同的响应超时时间</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-common-design-patterns/java-common-design-patterns-1.jpg/w600">

<h1 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h1><p>观察者模式通常也叫发布—订阅模式，或者事件监听模式，定义一对多的依赖关系，让多个观察者对象同时监听一个主题对象，如果这个主题对象的状态发生变化时，会通知所有的观察者对象。<br>异步消息（MQ、activeMQ）都是基于这种模式</p>
<p><strong>类结构图：</strong></p>
<pre class="mermaid" style="text-align: center;">
            classDiagram
            class Subject{
  - list<Observer>
  + add(Observer)
  + delete(Observer)
  + nofify()
}

class ConcreteSubject

class Observer
Observer: +action()
Subject ..>Observer

class ConcreteObserver
ConcreteObserver: +action()

Subject <|-- ConcreteSubject
Observer <|-- ConcreteObserver
          </pre>

<ul>
<li>Subject：主题类，将所有的观察者对象保存在一个List集合中，并提供增、删的方法，以及状态变化后的通知方法。</li>
<li>Observer：观察者的抽象接口，提供了一个抽象的动作方法，具体的业务由子类来实现</li>
<li>ConcreteObserver：具体的观察者，负责实现自己的业务动作</li>
<li>ConcreteSubject：具体的主题类，在内部状态发生变化时，给所有登记过的观察者发出通知。</li>
</ul>
<p><strong>优点：</strong></p>
<ul>
<li>解耦，将耦合的双方都依赖于抽象类，而不是依赖于具体。从而使得各自的变化不会影响另一边的变化。</li>
<li>Observer采用的是抽象类，这样的好处是可以将多个子类相同的代码逻辑抽取出来，放到抽象类中</li>
</ul>
<h1 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h1><p>责任链模式就是很多对象由每个对象对其下家的引用串连起来形成一条链，请求在这条链上传递，直到最终处理完。就象一根水管一样，水从一端流入，会经过一系列的阀门，最终从另一端流出。如果有一个阀门关着，水都流不出来。</p>
<p><strong>链上的节点可以控制，根据是否执行分为两种情况：</strong></p>
<ul>
<li>找到对应的点，执行，跳出。如：for循环的break</li>
<li>所有的节点都执行一遍，上个节点的返回结果作为下个节点的入参</li>
</ul>
<p><a href="http://blog.csdn.net/itomge/article/details/20792567" target="_blank" rel="noopener">http://blog.csdn.net/itomge/article/details/20792567</a></p>
<h1 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h1><p>策略模式通常是指完成某个操作可能会有多种方法，适用于多种场合。我们需要把每个操作方法当做一个实现策略，调用者可根据需要（特定的规则）选择合适的策略</p>
<p><strong>结构类图：</strong></p>
<pre class="mermaid" style="text-align: center;">
            classDiagram
            class Context{
  - Strategy strategy
}

class Strategy
Strategy: <<interface>>

class Realize1
class Realize2

Strategy --* Context
Strategy <|-- Realize1
Strategy <|-- Realize2
          </pre>

<ul>
<li>Context：使用不同的策略环境，根据自身的条件选择不同的策略实现类来完成所需要的操作。他持有一个策略实例的引用</li>
<li>Strategy:抽象策略，定义每个策略都要实现的方法</li>
<li>Realize1，Realize2：负责实现抽象策略中定义的策略方法。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 例子：</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="meta">@Enhancement</span>(&#123; <span class="meta">@Capability</span>(type = CapabilityTypeEnum.INVOCATION_STATS) &#125;)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendGoods</span><span class="params">(SendGoodsParam param)</span> <span class="keyword">throws</span> ServiceException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == param || <span class="keyword">null</span> == param.getId()) &#123;</span><br><span class="line">        <span class="keyword">this</span>.throwInvalidError(ErrorCodeEnum.NULL_PARAM, <span class="keyword">null</span>, param);</span><br><span class="line">    &#125;</span><br><span class="line">    TradeFlowService t = createTradeFlowServiceByOrderId(param.getId());</span><br><span class="line">    t.sendGoods(param);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>createTradeFlowServiceByOrderId方法会根据”订单号的长短“选择具体的子策略</p>
<ul>
<li>长订单号：tpTradeFlowService</li>
<li>短订单号：unifyTradeFlowService</li>
</ul>
<p>彼此子策略实现互不干扰，有效达到隔离效果。</p>
<h1 id="合成模式"><a href="#合成模式" class="headerlink" title="合成模式"></a>合成模式</h1><p>可以控制某资源同时被访问的个数。例如连接池中通常要控制创建连接的个数。</p>
<p>tryAcquire方法，获得锁</p>
<p>release方法，释放锁</p>
<h1 id="模板模式"><a href="#模板模式" class="headerlink" title="模板模式"></a>模板模式</h1><p>应用场景很多，尤其是在框架设计中，提供了一个方便的开发程序的模板，你只要实现模板中的一些接口或方法就能完成一个复杂的任务。</p>
<p><strong>结构类图：</strong></p>
<pre class="mermaid" style="text-align: center;">
            classDiagram
            AbstractTemplate <|-- SubTemplate
          </pre>

<ul>
<li>AbstractTemplate：定义一个完整的框架，方法的调用顺序已经确定，但会定义一些抽象的方法留给子类去实现</li>
<li>SubTemplate：实现抽象模板中定义的抽象方法，从而形成一个完整的流程逻辑</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> TradeFlowActionResult <span class="title">execute</span><span class="params">(TradeFlowActionParam param, Map context)</span> <span class="keyword">throws</span> ServiceException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;    <span class="comment">// 业务逻辑校验</span></span><br><span class="line">        <span class="keyword">this</span>.validateBusinessLogic(param, context);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ServiceException ex) &#123;</span><br><span class="line">        sendGoodsLog.info(<span class="string">"SendGoodsAction-&gt;validateBusinessLogic got exception. param is "</span> + param, ex);</span><br><span class="line">        <span class="keyword">throw</span> ex;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RuntimeException ex) &#123;</span><br><span class="line">        sendGoodsLog.info(<span class="string">"SendGoodsAction-&gt;validateBusinessLogic got runtime exception. param is "</span> + param, ex);</span><br><span class="line">        <span class="keyword">throw</span> ex;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 卖家发货业务逻辑</span></span><br><span class="line">        <span class="keyword">this</span>.sendGoods(param, context);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ServiceException ex) &#123;</span><br><span class="line">        sendGoodsLog.info(<span class="string">"SendGoodsAction-&gt;sendGoods got exception. param is "</span> + param, ex);</span><br><span class="line">        <span class="keyword">throw</span> ex;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RuntimeException ex) &#123;</span><br><span class="line">        sendGoodsLog.info(<span class="string">"SendGoodsAction-&gt;sendGoods got runtime exception. param is "</span> + param, ex);</span><br><span class="line">        <span class="keyword">throw</span> ex;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 补充业务（结果不影响核心业务）</span></span><br><span class="line">        <span class="keyword">this</span>.addition(param, context);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ServiceException ex) &#123;</span><br><span class="line">        sendGoodsLog.info(<span class="string">"SendGoodsAction-&gt;addition got exception. param is "</span> + param, ex);</span><br><span class="line">        <span class="keyword">throw</span> ex;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RuntimeException ex) &#123;</span><br><span class="line">        sendGoodsLog.info(<span class="string">"SendGoodsAction-&gt;addition got runtime exception. param is "</span> + param, ex);</span><br><span class="line">        <span class="keyword">throw</span> ex;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 处理结果</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面提到的三个抽象方法（业务逻辑校验、卖家发货业务逻辑、补充业务）都是在子类中实现的</p>
<p>即控制了主流程结构，又不失灵活性，可以让使用者在其基础上定制开发。</p>
<h2 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h2><p>代理模式，为其它对象提供一种代理以控制对这个对象的访问。</p>
<p><strong>类结构图：</strong></p>
<pre class="mermaid" style="text-align: center;">
            classDiagram
            class Subject
Subject:<<interface>>
Subject:+methodA()

class RealSubject
RealSubject:+methodA()

class ProxySubject
ProxySubject:-Subject subject
ProxySubject:+methodA()

Subject <|.. RealSubject
Subject <|.. ProxySubject
RealSubject <.. ProxySubject
          </pre>

<ul>
<li>Subject：接口类，定义了一些需要代理的接口方法</li>
<li>RealSubject：具体的实现类</li>
<li>ProxySubject：代理类，保存一个Subject引用，可以注入一个具体的子类比如RealSubject。</li>
</ul>
<p>代理模式其实就是在操作对象时引入一定程度的间接性。这种间接性，可以增加很多附加操作。比如权限控制，参数校验等等</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProxyPersonManager</span> <span class="keyword">implements</span> <span class="title">PersonManager</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 接口引用</span></span><br><span class="line">    PersonManager realPersonManager = <span class="keyword">new</span> RealPersonManager();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getSalary</span><span class="params">(String name, String operateName)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 1. 增加一些的权限判断。比如操作人是否有查询某人工资的权限</span></span><br><span class="line">        <span class="comment">// 2. 具体类的调用</span></span><br><span class="line">        <span class="keyword">return</span> realPersonManager.getSalary(name, operateName);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="RBAC"><a href="#RBAC" class="headerlink" title="RBAC"></a>RBAC</h2><p>基于角色的权限访问控制。</p>
<p>用户—》用户的身份（店铺、达人）–》对应的权限集合</p>
<p>每个权限都拆分原子的，采用并集的形式。另外增加个性化权限表，专属用户有专门的权限。</p>
<h2 id="事件溯源Event-Sourcing"><a href="#事件溯源Event-Sourcing" class="headerlink" title="事件溯源Event Sourcing"></a>事件溯源Event Sourcing</h2><p>几乎所有数据库都支持高可用性集群，大多数数据库对系统一致性模型提供一个易于理解的方式，保证强一致性模型的安全方式是维持数据库事务操作的有序日志，理论上理由非常简单，一个事务日志是一系列数据更新操作的动作有序记录集合，当其他节点从主节点获得这个事务日志时，能够按照这种有序动作集合重新播放这些操作，从而更新自己所在节点的数据库状态，当这个事务日志完成后，次节点的状态最终会和主节点状态一致，</p>
<p>Event sourcing事件溯源是借鉴数据库事务日志的一种数据持久方式，在事务日志中记录导致状态变化的一系列领域事件。通过持久化记录改变状态的事件，通过重新播放获得状态改变的历史。 事件回放可以返回系统到任何状态。</p>
<p><a href="https://www.jdon.com/event.html" target="_blank" rel="noopener">https://www.jdon.com/event.html</a></p>
<h2 id="Sidecar模式"><a href="#Sidecar模式" class="headerlink" title="Sidecar模式"></a>Sidecar模式</h2><p>Sidecar主张以额外的容器来扩展或增强主容器，而这个额外的容器被称为Sidecar容器。也可以理解为插件。</p>
<p>主要是用来改造已有服务。我们知道，要在一个架构中实施一些架构变更时，需要业务方一起过来进行一些改造。然而业务方的事情比较多，像架构上的变更会低优先级处理，这就导致架构变更的 “ 政治复杂度 “ 太大。而通过 Sidecar 的方式，我们可以适配应用服务，成为应用服务进出请求的代理。这样，我们就可以干很多对于业务方完全透明的事情了。</p>
<p><a href="https://blog.csdn.net/ZYQDuron/article/details/80757232" target="_blank" rel="noopener">https://blog.csdn.net/ZYQDuron/article/details/80757232</a></p>
<p><a href="https://www.cnblogs.com/waterlufei/p/7145746.html" target="_blank" rel="noopener">https://www.cnblogs.com/waterlufei/p/7145746.html</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Jdk并发包里常用类</title>
    <url>/java/concurrent-class/</url>
    <content><![CDATA[<h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><p>是线程安全的。</p>
<p>Put方法，首先是对key.hashCode进行hash操作，得到hash值。然后获取对应的segment对象，接着调用Segment对象的put方法完成当前操作。当调用put方法时，首先lock操作，完成操作后再释放锁。</p>
<a id="more"></a>

<p><img data-src="https://static001.infoq.cn/resource/image/1e/18/1efc05472707ac5b47da82a4f4c35418.jpg" alt=""></p>
<h2 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h2><p>可以控制某资源同时被访问的个数。例如连接池中通常要控制创建连接的个数。</p>
<p>tryAcquire方法，获得锁<br>release方法，释放锁</p>
<h2 id="CountdownLatch"><a href="#CountdownLatch" class="headerlink" title="CountdownLatch"></a>CountdownLatch</h2><p>闭锁，确保一个服务不会开始，直到它依赖的其他服务都已近开始，它允许一个或多个线程，等待一个事件集的发生。<br>通过减计数的方式，控制多个线程同时开始某个动作。当计数为0时，await后的代码才会被执行。<br>提供await（）和countDown（）两个方法。</p>
<h2 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h2><p>CyclicBarrier中的await方法会对count值减1，并阻塞当前线程（java.util.concurrent.locks.Condition.await()），如果count==0时先执行CyclicBarrier内部的Runnable任务（java.lang.Runnable.run()），然后唤醒所有阻塞的线程（java.util.concurrent.locks.Condition.signalAll()），count恢复初始值（可以进入下一轮循环）。</p>
<p>与CountdownLatch不同的是，它可以循环重用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.CyclicBarrier;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestCyclicBarrier</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> THREAD_NUM = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WorkerThread</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        CyclicBarrier barrier;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">WorkerThread</span><span class="params">(CyclicBarrier b)</span></span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.barrier = b;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">"Worker's waiting"</span>);</span><br><span class="line">                <span class="comment">// 线程在这里等待，直到所有线程都到达barrier。</span></span><br><span class="line">                barrier.await();</span><br><span class="line">                System.out.println(<span class="string">"ID:"</span> + Thread.currentThread().getId() + <span class="string">" Working"</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        CyclicBarrier cb = <span class="keyword">new</span> CyclicBarrier(THREAD_NUM, <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 当所有线程到达barrier时执行</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"Inside Barrier"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(<span class="keyword">new</span> WorkerThread(cb)).start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Worker<span class="string">'s waiting</span></span><br><span class="line"><span class="string">Worker'</span>s waiting</span><br><span class="line">Worker<span class="string">'s waiting</span></span><br><span class="line"><span class="string">Worker'</span>s waiting</span><br><span class="line">Worker<span class="string">'s waiting</span></span><br><span class="line"><span class="string">Inside Barrier</span></span><br><span class="line"><span class="string">ID:13 Working</span></span><br><span class="line"><span class="string">ID:9 Working</span></span><br><span class="line"><span class="string">ID:12 Working</span></span><br><span class="line"><span class="string">ID:11 Working</span></span><br><span class="line"><span class="string">ID:10 Working</span></span><br><span class="line"><span class="string">Worker'</span>s waiting</span><br><span class="line">Worker<span class="string">'s waiting</span></span><br><span class="line"><span class="string">Worker'</span>s waiting</span><br><span class="line">Worker<span class="string">'s waiting</span></span><br><span class="line"><span class="string">Worker'</span>s waiting</span><br><span class="line">Inside Barrier</span><br><span class="line">ID:<span class="number">18</span> Working</span><br><span class="line">ID:<span class="number">14</span> Working</span><br><span class="line">ID:<span class="number">16</span> Working</span><br><span class="line">ID:<span class="number">15</span> Working</span><br><span class="line">ID:<span class="number">17</span> Working</span><br></pre></td></tr></table></figure>

<h2 id="AtomicInteger"><a href="#AtomicInteger" class="headerlink" title="AtomicInteger"></a>AtomicInteger</h2><p>原子操作，线程安全。之前如果多线程累计计数，需要通过锁控制。</p>
<p>IncrementAndGet方法，关键是调用了compareAndSwap方法，是native方法，基于cpu的CAS原语来实现的。简单原理是由cpu比较内存位置上的值是否为当前值，如果是换成新值，否则返回false</p>
<h2 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h2><p>提供线程池服务，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ThreadPoolExecutor（<span class="keyword">int</span> corePoolSize, </span><br><span class="line">                    <span class="keyword">int</span> maximumPoolSize,</span><br><span class="line">                    <span class="keyword">long</span> keepAliveTime, </span><br><span class="line">                    TimeUnit unit,</span><br><span class="line">                    BlockingQueue&lt;Runnable&gt; workQueue,</span><br><span class="line">                    RejectedExecutionHandler handler）</span><br></pre></td></tr></table></figure>

<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">corePoolSize：</span> <span class="string">线程池维护线程的最少数量</span></span><br><span class="line"><span class="string">maximumPoolSize：线程池维护线程的最大数量</span></span><br><span class="line"><span class="string">keepAliveTime：</span> <span class="string">线程池维护线程所允许的空闲时间</span></span><br><span class="line"><span class="string">unit：</span> <span class="string">线程池维护线程所允许的空闲时间的单位</span></span><br><span class="line"><span class="string">workQueue：</span> <span class="string">线程池所使用的缓冲队列</span></span><br><span class="line"><span class="string">handler：</span> <span class="string">线程池对拒绝任务的处理策略</span></span><br></pre></td></tr></table></figure>

<p>block queue有以下几种实现：</p>
<ol>
<li>ArrayBlockingQueue：有界的数组队列</li>
<li>LinkedBlockingQueue：可支持有界、无界的队列，使用链表实现</li>
<li>PriorityBlockingQueue：优先队列，可对任务排序</li>
<li>SynchronousQueue：队列长度为1的队列，和Array有点区别就是：client 线程提交到 block queue会是一个阻塞过程，直到有一个消费线程连接上来poll task</li>
</ol>
<p>RejectExecutionHandler是针对任务无法处理时的一些自我保护处理：</p>
<ol>
<li>Reject 直接抛出Reject exception</li>
<li>Discard 直接忽略该runnable，不建议使用</li>
<li>DiscardOldest 丢弃最早入队列的任务</li>
<li>CallerRuns 直接让原先的client thread做为消费线程，象同步调用方式一样，自己来执行。</li>
</ol>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-concurrent-class/java-concurrent-class-quere.png/w600">

<p><strong>如何确定最大线程数？</strong><br>确定线程数首先需要考虑到系统可用的处理器核心数：</p>
<p>Runtime.getRuntime().availableProcessors();<br>应用程序最小线程数应该等于可用的处理器核数。</p>
<p>如果所有的任务都是计算密集型的，则创建处理器可用核心数这么多个线程就可以了，这样已经充分利用了处理器，也就是让它以最大火力不停进行计算。创建更多的线程对于程序性能反而是不利的，因为多个线程间频繁进行上下文切换对于程序性能损耗较大。</p>
<p>如果任务都是IO密集型的，那我们就需要创建比处理器核心数大几倍数量的线程。为何？当一个任务执行IO操作时，线程将被阻塞，于是处理器可以立即进行上下文切换以便处理其他就绪线程。如果我们只有处理器核心数那么多个线程的话，即使有待执行的任务也无法调度处理了。</p>
<p>因此，线程数与我们每个任务处于阻塞状态的时间比例相关。加入任务有50%时间处于阻塞状态，那程序所需线程数是处理器核心数的两倍。我们可以计算出程序所需的线程数，公式如下：</p>
<p>线程数=CPU可用核心数/（1 - 阻塞系数），其中阻塞系数在在0到1范围内。</p>
<p>计算密集型程序的阻塞系数为0，IO密集型程序的阻塞系数接近1。<br>确定阻塞系数，我们可以先试着猜测，或者采用一些性能分析工具或java.lang.management API 来确定线程花在系统IO上的时间与CPU密集任务所耗的时间比值。</p>
<h2 id="Executors"><a href="#Executors" class="headerlink" title="Executors"></a>Executors</h2><p>工具类，提供大量管理线程执行器的工厂方法。</p>
<ol>
<li>newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newCachedThreadPool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">0</span>, Integer.MAX_VALUE,</span><br><span class="line">                                    <span class="number">60L</span>, TimeUnit.SECONDS,</span><br><span class="line">                                    <span class="keyword">new</span> SynchronousQueue&lt;Runnable&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>newFixedThreadPool(int) ,创建固定大小的线程池<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newFixedThreadPool</span><span class="params">(<span class="keyword">int</span> nThreads)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(nThreads, nThreads,</span><br><span class="line">                                    <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                    <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>newSingleThreadPool(),创建大小为1的线程池,同一时刻执行的task只有一个，其它的都放在阻塞队列中。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newSingleThreadExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> FinalizableDelegatedExecutorService</span><br><span class="line">        (<span class="keyword">new</span> ThreadPoolExecutor(<span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">                                <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>newScheduledThreadPool(int),适用于一些需要定时或延迟的任务。与Timer的区别：</li>
</ol>
<ul>
<li>Timer是单线程，一旦一个task执行慢，将会影响其它任务。另外如果抛出异常，其它任务也不再执行。</li>
<li>ScheduledThreadPoolExecutor可执行callable的task，执行完毕后得到执行结果。任务队列是基于DelayedWorkQueue实现，将有新task加入时，会按执行时间排序。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ScheduledExecutorService <span class="title">newScheduledThreadPool</span><span class="params">(<span class="keyword">int</span> corePoolSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ScheduledThreadPoolExecutor(corePoolSize);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ScheduledThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(corePoolSize, Integer.MAX_VALUE, <span class="number">0</span>, NANOSECONDS,</span><br><span class="line">            <span class="keyword">new</span> DelayedWorkQueue());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="5">
<li><p>newWorkStealingPool：<strong>jdk1.8新增</strong>,创建持有足够线程的线程池来支持给定的并行级别，并通过使用多个队列，减少竞争，它需要穿一个并行级别的参数，如果不传，则被设定为默认的CPU数量。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newWorkStealingPool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ForkJoinPool (Runtime.getRuntime().availableProcessors(),</span><br><span class="line">            ForkJoinPool.defaultForkJoinWorkerThreadFactory,</span><br><span class="line">            <span class="keyword">null</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>自定义线程池<br>以下是自定义线程池，使用了有界队列，自定义ThreadFactory和拒绝策略的demo：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, IOException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> corePoolSize = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">int</span> maximumPoolSize = <span class="number">4</span>;</span><br><span class="line">        <span class="keyword">long</span> keepAliveTime = <span class="number">10</span>;</span><br><span class="line">        TimeUnit unit = TimeUnit.SECONDS;</span><br><span class="line">        BlockingQueue&lt;Runnable&gt; workQueue = <span class="keyword">new</span> ArrayBlockingQueue&lt;&gt;(<span class="number">2</span>);</span><br><span class="line">        ThreadFactory threadFactory = <span class="keyword">new</span> NameTreadFactory();</span><br><span class="line">        RejectedExecutionHandler handler = <span class="keyword">new</span> MyIgnorePolicy();</span><br><span class="line">        ThreadPoolExecutor executor = <span class="keyword">new</span> ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit,</span><br><span class="line">                workQueue, threadFactory, handler);</span><br><span class="line">        executor.prestartAllCoreThreads(); <span class="comment">// 预启动所有核心线程</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++) &#123;</span><br><span class="line">            MyTask task = <span class="keyword">new</span> MyTask(String.valueOf(i));</span><br><span class="line">            executor.execute(task);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.in.read(); <span class="comment">//阻塞主线程</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NameTreadFactory</span> <span class="keyword">implements</span> <span class="title">ThreadFactory</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger mThreadNum = <span class="keyword">new</span> AtomicInteger(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Thread <span class="title">newThread</span><span class="params">(Runnable r)</span> </span>&#123;</span><br><span class="line">            Thread t = <span class="keyword">new</span> Thread(r, <span class="string">"my-thread-"</span> + mThreadNum.getAndIncrement());</span><br><span class="line">            System.out.println(t.getName() + <span class="string">" has been created"</span>);</span><br><span class="line">            <span class="keyword">return</span> t;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyIgnorePolicy</span> <span class="keyword">implements</span> <span class="title">RejectedExecutionHandler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">            doLog(r, e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doLog</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 可做日志记录等</span></span><br><span class="line">            System.err.println( r.toString() + <span class="string">" rejected"</span>);</span><br><span class="line"><span class="comment">//          System.out.println("completedTaskCount: " + e.getCompletedTaskCount());</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyTask</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">MyTask</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.name = name;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(<span class="keyword">this</span>.toString() + <span class="string">" is running!"</span>);</span><br><span class="line">                Thread.sleep(<span class="number">3000</span>); <span class="comment">//让任务执行慢点</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> name;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"MyTask [name="</span> + name + <span class="string">"]"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<div class="note danger">
            <p>线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这<br>样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。</p><p>说明：Executors 返回的线程池对象的弊端如下：</p><ul><li>1） FixedThreadPool 和 SingleThreadPool：<br>允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。</li><li>2） CachedThreadPool：<br>允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。</li></ul>
          </div>

<h2 id="FutureTask"><a href="#FutureTask" class="headerlink" title="FutureTask"></a>FutureTask</h2><p>用于异步获取执行结果或取消执行任务。通过传入Callable给FutureTask，直接调用run方法执行，之后可以通过FutureTask的get异步方法获得执行结果。FutureTask即使多次调用了run方法，它只会执行一次Callable任务，当然也可以通过cancel来取消执行。<br>《分布式java应用》P158</p>
<h2 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a>ArrayBlockingQueue</h2><p>基于数组、先进先出、线程安全的集合</p>
<h2 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a>CopyOnWriteArrayList</h2><p>线程安全，读操作时无锁的ArrayList。每次新增一个对象时，会将创建一个新的数组（长度+1），将之前的数组中的内容复制到新的数组中，并将新增的对象放入数组末尾。最后做引用切换。</p>
<h2 id="CopyOnWriteArraySet"><a href="#CopyOnWriteArraySet" class="headerlink" title="CopyOnWriteArraySet"></a>CopyOnWriteArraySet</h2><p>与上面的类似，无非在add时，会调用addIfAbsent，由于每次add时都要进行数组遍历，因此性能会略低于CopyOnWriteArrayList</p>
<h2 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h2><p>单锁。控制并发的，和synchronized达到的效果是一致的。<br>Lock方法，借助于CAS机制来控制锁。<br>Unlock方法，释放锁</p>
<h2 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h2><p>与ReentrantLock没有任何继承关系，提供了读锁和写锁，在读多写少的场景中大幅度提升性能。</p>
<p>持有读锁时，不能直接调用写锁的lock方法<br><br>持有写锁时，其他线程的读或写都会被阻塞。</p>
<p>ReentrantReadWriteLock  lock=new ReentrantReadWriteLock();<br>WriteLock  writeLock=lock.writeLock();<br>ReadLock   readLock=lock.readLock();<br>《分布式java应用》P165</p>
<h2 id="如何避免死锁"><a href="#如何避免死锁" class="headerlink" title="如何避免死锁"></a>如何避免死锁</h2><ol>
<li><p>制定锁的顺序，来避免死锁（先A后B，避免A-&gt;B和B-&gt;A同时存在）；</p>
</li>
<li><p>尝试使用定时锁（lock.tryLock(timeout)）</p>
</li>
<li><p>在持有锁的方法中进行其他方法的调用，尽量使用开放调用（当调用方法不需要持有锁时，叫做开放调用）</p>
</li>
<li><p>减少锁的持有时间、减小锁代码块的粒度。</p>
</li>
</ol>
<h2 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h2><img data-src="http://f.ngall-in.com/alan87/static/images/java/java-concurrent-class/java-concurrent-class-sum.png/w600">
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>DAO层接口性能监控</title>
    <url>/java/dao-monition/</url>
    <content><![CDATA[<p>笼统来讲讲，任何系统都可以抽象为数据+算法。而数据库作为数据的存储系统，其响应快慢直接影响着系统的整体性能。</p>
<a id="more"></a>

<p>目前很多大公司内部都有一些定制的监控系统，可以多维度采集数据，生成各种报表。</p>
<p>不过这样的系统维护成本比较高，甚至要专门的技术人员维护。如果是创业公司，可能不具备这种条件，不过我们可以通过一些简单方法，也能达到同样的效果。</p>
<ul>
<li>记录日志<br>比如通过Spring AOP机制，统计dao方法的调用时间，超过一定阈值，会打印到日志中。后面可以接入邮件系统，每天统计慢<span class="label warning">sql</span>，了解系统的健康状况，<strong>及时优化各种潜在的风险。</strong></li>
</ul>
<p><strong>代码示例：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DaoRTLogAspect</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(<span class="string">"daoRTLog"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Pointcut</span>(<span class="string">"execution(public * com.onlyone.bbs.dal.dao..*.*(..))"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">daoLog</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Around</span>(<span class="string">"daoLog()"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">profile</span><span class="params">(ProceedingJoinPoint pjp)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">        String method = pjp.getSignature().toString();</span><br><span class="line">        Long _startTime = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> pjp.proceed();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            Long _wasteTime = System.currentTimeMillis() - _startTime;</span><br><span class="line">            <span class="keyword">if</span> (_wasteTime &gt; <span class="number">50</span>) &#123;</span><br><span class="line">                StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">                sb.append(<span class="string">"method="</span>).append(method).append(<span class="string">",wasteTime="</span>).append(_wasteTime);</span><br><span class="line">                logger.info(sb.toString());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>利用自带监控的数据库连接池<br>如 alibaba/druid<br><img data-src="https://images2018.cnblogs.com/blog/648026/201809/648026-20180903200426746-2116743008.png" alt=""></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>数据库</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库连接池</title>
    <url>/java/database-connection-pool/</url>
    <content><![CDATA[<h2 id="SQL生命周期："><a href="#SQL生命周期：" class="headerlink" title="SQL生命周期："></a>SQL生命周期：</h2><div class="note primary">
            <ol><li>应用服务器与数据库服务器建立一个连接</li><li>数据库进程拿到请求sql</li><li>解析并生成执行计划，执行</li><li>读取数据到内存并进行逻辑处理</li><li>通过步骤一的连接，发送结果到客户端</li><li>关掉连接，释放资源</li></ol>
          </div>
<a id="more"></a>

<p>其中的连接在里面发挥着重大作用，但频繁的创建和销毁，非常浪费系统资源。由于数据库更适合长连接，也就有个连接池，能对连接复用，维护连接对象、分配、管理、释放，也可以避免创建大量的连接对DB引发的各种问题；另外通过请求排队，也缓解对DB的冲击。</p>
<p>连接池在初始化时创建MIN个连接。如果有业务请求，而此时没有空闲的管道，如果没有达到MAX连接数，无需等待，会申请创建一个新的连接。如果已经达到MAX，只能排队等待，等待的时间取决于block-timeout，如果超过等待时间没有拿到连接，抛拿不到连接的异常。</p>
<h2 id="推荐开源框架"><a href="#推荐开源框架" class="headerlink" title="推荐开源框架"></a>推荐开源框架</h2><p>Druid首先是一个数据库连接池，但它不仅仅是一个数据库连接池。Druid是一个JDBC组件，它包括三部分： </p>
<div class="note primary">
            <ul><li><p>DruidDriver ProxyDriver，能够提供基于Filter－Chain模式的插件体系。 </p></li><li><p>DruidDataSource 高效可管理的数据库连接池。 </p></li><li><p>SQLParser </p></li></ul>
          </div>
<p>Druid可以做什么？ </p>
<ul>
<li><p>可以监控数据库访问性能，Druid内置提供了一个功能强大的StatFilter插件，能够详细统计SQL的执行性能，这对于线上分析数据库访问性能有帮助，统计慢sql。</p>
</li>
<li><p>替换DBCP和C3P0。Druid提供了一个高效、功能强大、可扩展性好的数据库连接池。 </p>
</li>
<li><p>数据库密码加密。直接把数据库密码写在配置文件中，这是不好的行为，容易导致安全问题。DruidDruiver和DruidDataSource都支持PasswordCallback。 </p>
</li>
<li><p>SQL执行日志，Druid提供了不同的LogFilter，能够支持Common-Logging、Log4j和JdkLog，你可以按需要选择相应的LogFilter，监控你应用的数据库访问情况。 </p>
</li>
<li><p>扩展JDBC，如果你要对JDBC层有编程的需求，可以通过Druid提供的Filter-Chain机制，很方便编写JDBC层的扩展插件。 </p>
</li>
<li><p>防御SQL注入攻击</p>
</li>
<li><p>支持spring boot</p>
</li>
</ul>
<p>如下是一个基于Druid内置扩展StatFilter的监控实现：<br><img data-src="https://images2018.cnblogs.com/blog/648026/201809/648026-20180903200426746-2116743008.png" alt=""></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">`</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"shardingDataSource"</span> <span class="attr">class</span>=<span class="string">"com.alibaba.druid.pool.DruidDataSource"</span> <span class="attr">init-method</span>=<span class="string">"init"</span> <span class="attr">destroy-method</span>=<span class="string">"close"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:url</span>=<span class="string">"$&#123;jdbc.bbs.sharding.url&#125;"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:username</span>=<span class="string">"$&#123;jdbc.bbs.sharding.username&#125;"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:password</span>=<span class="string">"$&#123;jdbc.bbs.sharding.password&#125;"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:initialSize</span>=<span class="string">"1"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:minIdle</span>=<span class="string">"1"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:maxActive</span>=<span class="string">"20"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:maxWait</span>=<span class="string">"60000"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:timeBetweenEvictionRunsMillis</span>=<span class="string">"60000"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:minEvictableIdleTimeMillis</span>=<span class="string">"300000"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:validationQuery</span>=<span class="string">"SELECT 'x'"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:testWhileIdle</span>=<span class="string">"true"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:testOnBorrow</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:testOnReturn</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:poolPreparedStatements</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:maxPoolPreparedStatementPerConnectionSize</span>=<span class="string">"20"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:connectionProperties</span>=<span class="string">"config.decrypt=true"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">p:filters</span>=<span class="string">"stat,config"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><a href="https://github.com/alibaba/druid/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98" target="_blank" rel="noopener">常见问题</a></p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><ul>
<li><a href="http://www.iteye.com/magazines/90" target="_blank" rel="noopener">阿里巴巴开源项目 Druid 负责人温少访谈</a></li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Exception</title>
    <url>/java/exception/</url>
    <content><![CDATA[<p>图中红色部分为受检查异常。它们必须被捕获，或者在函数中声明为抛出该异常。</p>
<a id="more"></a>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-exception/java-exception-1.png/w600">
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java垃圾回收</title>
    <url>/java/gc/</url>
    <content><![CDATA[<ul>
<li><p><a href="https://mp.weixin.qq.com/s/olNXcRAT3PTK-hV_ehtmtw" target="_blank" rel="noopener">GC算法 垃圾收集器</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/S3PcA2KIzCVB2hJmsbVzyQ" target="_blank" rel="noopener">Java GC 分析</a></p>
<a id="more"></a></li>
<li><p><a href="https://yq.aliyun.com/articles/94557?spm=5176.100239.blogcont217385.73.SaQb9l" target="_blank" rel="noopener">Java应用频繁FullGC分析</a></p>
</li>
<li><p>GC日志</p>
<ul>
<li><a href="https://blog.csdn.net/renfufei/article/details/49230943" target="_blank" rel="noopener">快速解读GC日志</a></li>
<li><a href="https://blog.csdn.net/zqz_zqz/article/details/70568819" target="_blank" rel="noopener">CMS垃圾回收器详解</a></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>HashMap的扩容机制</title>
    <url>/java/hashmap-expand/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>单纯的kv键值对结构，可以接受null键和null值，速度比较快，非线程安全。</p>
<a id="more"></a>

<h1 id="HashMap的数据结构"><a href="#HashMap的数据结构" class="headerlink" title="HashMap的数据结构"></a>HashMap的数据结构</h1><p>HashMap实际上是一个“链表的数组”的数据结构，每个元素存放链表头结点的数组，即数组和链表的结合体。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-hashmap-expand/java-hashmap-expand-1.png/w600">

<p>Entry就是数组中的元素，每个 Map.Entry 其实就是一个key-value对，它持有指向下一个元素的引用，这就构成了链表。</p>
<h1 id="工作原理："><a href="#工作原理：" class="headerlink" title="工作原理："></a>工作原理：</h1><h2 id="put"><a href="#put" class="headerlink" title="put"></a>put</h2><p>当我们往HashMap中put元素的时候，先根据key的hashCode重新计算hash值，根据hash值得到这个元素在数组中的位置（即下标），如果数组该位置上已经存放有其他元素了，那么在这个位置上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。如果数组该位置上没有元素，就直接将该元素放到此数组中的该位置上。</p>
<p>HashMap基于hashing原理，我们通过put()方法储存，当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到bucket位置来储存值对象。</p>
<p>当获取对象时，同上找到对应的bucket，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java服务器load飚高排查思路</title>
    <url>/java/highload-troubleshoot/</url>
    <content><![CDATA[<h1 id="Load"><a href="#Load" class="headerlink" title="Load"></a>Load</h1><p>Load 是指对计算机干活多少的度量（WikiPedia：the system load is a measure of the amount of work that a computer system is doing），简单的说是进程队列的长度。</p>
<a id="more"></a>
<p>Load Average 就是一段时间 (1 分钟、5分钟、15分钟) 内平均 Load </p>
<p><strong>通过uptime命令可以查看当前的load，如果值很高。一般情况是java某些线程长期占用资源、死锁、死循环等导致某个进程占用的CPU资源过高。大致可以从以下几个角度来排查：</strong></p>
<h1 id="排查步骤"><a href="#排查步骤" class="headerlink" title="排查步骤"></a>排查步骤</h1><h2 id="1-首先通过jps命令，查看当前进程id，如id为-28118"><a href="#1-首先通过jps命令，查看当前进程id，如id为-28118" class="headerlink" title="1. 首先通过jps命令，查看当前进程id，如id为 28118"></a>1. 首先通过jps命令，查看当前进程id，如id为 28118</h2><h2 id="2-查看该进程下的线程资源使用情况"><a href="#2-查看该进程下的线程资源使用情况" class="headerlink" title="2. 查看该进程下的线程资源使用情况"></a>2. 查看该进程下的线程资源使用情况</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">top -Hp 28118 </span><br><span class="line"></span><br><span class="line">32694 root      20   0 3249m 2.0g  11m S    2  6.4   3:31.12 java                      </span><br><span class="line">28175 root      20   0 3249m 2.0g  11m S    0  6.4   0:00.06 java                   </span><br><span class="line">28176 root      20   0 3249m 2.0g  11m S    0  6.4   1:40.79 java                   </span><br><span class="line">28177 root      20   0 3249m 2.0g  11m S    0  6.4   1:41.12 java                   </span><br><span class="line">28178 root      20   0 3249m 2.0g  11m S    0  6.4   1:41.11 java                   </span><br><span class="line">28179 root      20   0 3249m 2.0g  11m S    0  6.4   1:41.33 java                   </span><br><span class="line">28180 root      20   0 3249m 2.0g  11m S    0  6.4   1:41.58 java                   </span><br><span class="line">28181 root      20   0 3249m 2.0g  11m S    0  6.4   1:40.36 java                   </span><br><span class="line">28182 root      20   0 3249m 2.0g  11m S    0  6.4   1:41.02 java                   </span><br><span class="line">28183 root      20   0 3249m 2.0g  11m S    0  6.4   1:40.96 java                   </span><br><span class="line">28184 root      20   0 3249m 2.0g  11m S    0  6.4   4:38.30 java</span><br></pre></td></tr></table></figure>

<h2 id="3-打印JAVA进程28118的堆栈信息"><a href="#3-打印JAVA进程28118的堆栈信息" class="headerlink" title="3. 打印JAVA进程28118的堆栈信息"></a>3. 打印JAVA进程28118的堆栈信息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jstack 28118 &gt;&gt; stack.log</span><br></pre></td></tr></table></figure>

<h2 id="4-将cpu消耗高的线程的pid换算为16进制"><a href="#4-将cpu消耗高的线程的pid换算为16进制" class="headerlink" title="4. 将cpu消耗高的线程的pid换算为16进制"></a>4. 将cpu消耗高的线程的pid换算为16进制</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">printf</span> 0x%x 32694</span><br></pre></td></tr></table></figure>

<p>转换后的16进制为 0x7fb6</p>
<h2 id="5-从刚才的栈日志中查找该线程正在运行的方法"><a href="#5-从刚才的栈日志中查找该线程正在运行的方法" class="headerlink" title="5. 从刚才的栈日志中查找该线程正在运行的方法"></a>5. 从刚才的栈日志中查找该线程正在运行的方法</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep 0x7fb6  stack.log -a10</span><br><span class="line"></span><br><span class="line"><span class="string">"MSXMLProcessorThread"</span> prio=10 tid=0x00002b469923a800 [color=darkred]nid=0x7fb6[/color] sleeping[0x00002b46b0200000]    </span><br><span class="line">   java.lang.Thread.State: TIMED_WAITING (sleeping)    </span><br><span class="line">        at java.lang.Thread.sleep(Native Method)    </span><br><span class="line">        at com.adventnet.management.xml.MSXmlProcessor.listen(MSXmlProcessor.java:279)    </span><br><span class="line">        at com.adventnet.management.xml.MSXmlProcessor.run(MSXmlProcessor.java:264)    </span><br><span class="line">        at java.lang.Thread.run(Thread.java:619)</span><br></pre></td></tr></table></figure>

<h2 id="6-另外也可以查找正在运行的线程，及线程处于运行状态的位置，从这些线程中来查找资源消耗过高的代码。"><a href="#6-另外也可以查找正在运行的线程，及线程处于运行状态的位置，从这些线程中来查找资源消耗过高的代码。" class="headerlink" title="6.另外也可以查找正在运行的线程，及线程处于运行状态的位置，从这些线程中来查找资源消耗过高的代码。"></a>6.另外也可以查找正在运行的线程，及线程处于运行状态的位置，从这些线程中来查找资源消耗过高的代码。</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep RUNNABLE stack.log  -a3</span><br></pre></td></tr></table></figure>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/highload-troubleshoot/highload-troubleshoot-2.png/w600">

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">less a.log |awk <span class="string">'&#123;FS="java.lang.Thread.State:";print $2&#125;'</span>|sort |uniq -c |sort -nr</span><br></pre></td></tr></table></figure>
<img data-src="http://f.ngall-in.com/alan87/static/images/source/static/images/java/highload-troubleshoot/highload-troubleshoot-1.png/w600">


<h2 id="7、查看当前jvm内存各堆区的占比"><a href="#7、查看当前jvm内存各堆区的占比" class="headerlink" title="7、查看当前jvm内存各堆区的占比"></a>7、查看当前jvm内存各堆区的占比</h2><p>jmap -heap 8002</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio         = 40</span><br><span class="line">   MaxHeapFreeRatio         = 70</span><br><span class="line">   MaxHeapSize              = 2147483648 (2048.0MB)</span><br><span class="line">   NewSize                  = 786432000 (750.0MB)</span><br><span class="line">   MaxNewSize               = 786432000 (750.0MB)</span><br><span class="line">   OldSize                  = 1361051648 (1298.0MB)</span><br><span class="line">   NewRatio                 = 2</span><br><span class="line">   SurvivorRatio            = 8</span><br><span class="line">   MetaspaceSize            = 39845888 (38.0MB)</span><br><span class="line">   CompressedClassSpaceSize = 1073741824 (1024.0MB)</span><br><span class="line">   MaxMetaspaceSize         = 398458880 (380.0MB)</span><br><span class="line">   G1HeapRegionSize         = 0 (0.0MB)</span><br><span class="line"></span><br><span class="line">Heap Usage:</span><br><span class="line">New Generation (Eden + 1 Survivor Space):</span><br><span class="line">   capacity = 707788800 (675.0MB)</span><br><span class="line">   used     = 383204272 (365.4520721435547MB)</span><br><span class="line">   free     = 324584528 (309.5479278564453MB)</span><br><span class="line">   54.14104772497107% used</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity = 629145600 (600.0MB)</span><br><span class="line">   used     = 334989624 (319.4710006713867MB)</span><br><span class="line">   free     = 294155976 (280.5289993286133MB)</span><br><span class="line">   53.24516677856445% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity = 78643200 (75.0MB)</span><br><span class="line">   used     = 48214648 (45.98107147216797MB)</span><br><span class="line">   free     = 30428552 (29.01892852783203MB)</span><br><span class="line">   61.30809529622396% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity = 78643200 (75.0MB)</span><br><span class="line">   used     = 0 (0.0MB)</span><br><span class="line">   free     = 78643200 (75.0MB)</span><br><span class="line">   0.0% used</span><br><span class="line">concurrent mark-sweep generation:</span><br><span class="line">   capacity = 1361051648 (1298.0MB)</span><br><span class="line">   used     = 985748664 (940.0831832885742MB)</span><br><span class="line">   free     = 375302984 (357.9168167114258MB)</span><br><span class="line">   72.4255148912615% used</span><br><span class="line"></span><br><span class="line">49647 interned Strings occupying 5512480 bytes.</span><br></pre></td></tr></table></figure>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="排查线上问题常用命令脚本"><a href="#排查线上问题常用命令脚本" class="headerlink" title="排查线上问题常用命令脚本"></a>排查线上问题常用命令脚本</h2><h1 id="1-查看进程pid"><a href="#1-查看进程pid" class="headerlink" title="1. 查看进程pid"></a>1. 查看进程pid</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps -ef |grep <span class="string">'bbs-service'</span> | grep -v grep |grep -v <span class="string">'python'</span> | awk <span class="string">'&#123;print $2&#125;'</span></span><br></pre></td></tr></table></figure>

<h1 id="2-查看线程信息"><a href="#2-查看线程信息" class="headerlink" title="2. 查看线程信息"></a>2. 查看线程信息</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jstack 27676| grep Druid-ConnectionPool- | wc -l</span><br><span class="line"></span><br><span class="line">jstack 27676| grep Xmemcached-Reactor- </span><br><span class="line"></span><br><span class="line">jstack 27676| grep java.lang.Thread.State </span><br><span class="line"></span><br><span class="line">jstack 27676| grep DubboServerHandler-</span><br><span class="line"></span><br><span class="line">jstack 27676| grep DubboClientHandler-</span><br><span class="line"></span><br><span class="line">top -H -b -n 1  -p 27676 | sed <span class="string">'1,/^$/d'</span> | sed <span class="string">'1d;/^$/d'</span> | grep -v 27676 | sort -nrk9 | head -3</span><br></pre></td></tr></table></figure>
<p>注：27676 为进程pid</p>
<h1 id="3-系统"><a href="#3-系统" class="headerlink" title="3. 系统"></a>3. 系统</h1><p>已建立的连接数：</p>
<p><code>netstat -ant |grep ESTABLISHED |wc -l</code></p>
<p>处于等待状态的连接数：</p>
<p><code>netstat -ant |grep TIME_WAIT |wc -l</code></p>
<p>各个cpu的资源使用情况：</p>
<h2 id="mpstat-P-ALL"><a href="#mpstat-P-ALL" class="headerlink" title="mpstat -P ALL"></a><code>mpstat -P ALL</code></h2><h1 id="服务器异常案例"><a href="#服务器异常案例" class="headerlink" title="服务器异常案例"></a>服务器异常案例</h1><h2 id="1-某应用load-gt-7-ssh感到输入命令后-要等待1、2秒-才开始执行"><a href="#1-某应用load-gt-7-ssh感到输入命令后-要等待1、2秒-才开始执行" class="headerlink" title="1.某应用load&gt;7,ssh感到输入命令后,要等待1、2秒 才开始执行"></a>1.某应用load&gt;7,ssh感到输入命令后,要等待1、2秒 才开始执行</h2><ul>
<li>top命令查看cpu占用率,约70%,不至于导致ssh中命令响应变慢</li>
<li>tsar查看最近的网络流量，正常</li>
<li>iostat 1，发现(虚拟机)磁盘tps达到500+非常高</li>
<li>jstack观察java中一个线程频繁操作磁盘</li>
<li>lsof命令观察打开文件，并排查代码发现配置项有误导致磁盘上出现很多小的零碎文件，引发频繁的随机访问，修改配置项后问题解决<br>￼￼</li>
</ul>
<h2 id="2-应用Load-gt-10，GC正常，活跃线程数很多，CPU-100"><a href="#2-应用Load-gt-10，GC正常，活跃线程数很多，CPU-100" class="headerlink" title="2.应用Load&gt;10，GC正常，活跃线程数很多，CPU 100%"></a>2.应用Load&gt;10，GC正常，活跃线程数很多，CPU 100%</h2><ul>
<li>ps -efL， 显示所有活跃线程ID和对应时间</li>
<li>根据对应线程SPID找出jstack中的执行栈</li>
<li>定位到问题代码，发现一个没同步保护的HashMap频繁并发put/get导致死循环</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">注意：</span><br><span class="line">通常cpu使用率达到了100%，一般是某些线程在某种条件下进入死循环，退不出来</span><br></pre></td></tr></table></figure>

<h2 id="3-容灾演习之后服务无法启动"><a href="#3-容灾演习之后服务无法启动" class="headerlink" title="3.容灾演习之后服务无法启动"></a>3.容灾演习之后服务无法启动</h2><ul>
<li>df –h 命令 /home 100%占用，日志文件巨大</li>
<li>删掉由于断网引起的大量重连日志，重启</li>
</ul>
<h2 id="4-￼某应用机器load狂飙100-，报警不断"><a href="#4-￼某应用机器load狂飙100-，报警不断" class="headerlink" title="4.￼某应用机器load狂飙100+，报警不断"></a>4.￼某应用机器load狂飙100+，报警不断</h2><ul>
<li>收集各个系统指标，发现除了load之外没有异常，load&gt;进程数，应用响应正常</li>
<li>jstack中Runnable状态线程很多“at<br>java.io.UnixFileSystem.getBooleanAttributes0(Native Method)”</li>
<li>ps –Tel 打印所有线程状态，发现大量怨妇进程（状态D，既无法中断又无法继续）</li>
<li>根据僵尸进程ID再次查找jstack中对应代码，为blocked的文件访问栈</li>
<li>df命令hang住</li>
<li>联系PE同学得知NAS故障,修复后重启OK</li>
</ul>
<h2 id="5-Java进程健在，应用运行一段时间失去响应"><a href="#5-Java进程健在，应用运行一段时间失去响应" class="headerlink" title="5.Java进程健在，应用运行一段时间失去响应"></a>5.Java进程健在，应用运行一段时间失去响应</h2><ul>
<li>jstat各个区域内存正常，应用服务器系统资源正常</li>
<li>查看应用默认日志文件发现一行“WARN [common] 服务器 已停止运行:12201”</li>
<li>jstack发现有线程“JBoss Shutdown Hook”健在，查找代码发现居然有二方包代码在抛出异常后调用system.exit(0)</li>
</ul>
<p>￼￼￼</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java HashMap图解</title>
    <url>/java/hashmap/</url>
    <content><![CDATA[<h1 id="初识HashMap"><a href="#初识HashMap" class="headerlink" title="初识HashMap"></a><strong>初识HashMap</strong></h1><p>之前的List，讲了ArrayList、LinkedList，最后讲到了CopyOnWriteArrayList，就前两者而言，反映的是两种思想：</p>
<a id="more"></a>

<ul>
<li><p>（1）ArrayList以数组形式实现，顺序插入、查找快，插入、删除较慢</p>
</li>
<li><p>（2）LinkedList以链表形式实现，顺序插入、查找较慢，插入、删除方便</p>
</li>
</ul>
<p>那么是否有一种数据结构能够结合上面两种的优点呢？有，答案就是HashMap。</p>
<p>HashMap是一种非常常见、方便和有用的集合，是一种键值对（K-V）形式的存储结构，下面将还是用图示的方式解读HashMap的实现原理。</p>
<h1 id="四个关注点在HashMap上的答案"><a href="#四个关注点在HashMap上的答案" class="headerlink" title="四个关注点在HashMap上的答案"></a><strong>四个关注点在HashMap上的答案</strong></h1><img data-src="http://f.ngall-in.com/alan87/static/images/java/hashmap/1.png/w600">

<h1 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a><strong>添加数据</strong></h1><p>首先看一下HashMap的一个存储单元Entry：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line"><span class="keyword">final</span> K key;</span><br><span class="line">V value;</span><br><span class="line">Entry&lt;K,V&gt; next;</span><br><span class="line"><span class="keyword">int</span> hash;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>之前一篇写LinkedList的文章，里面写到LinkedList是一个双向链表，从HashMap的Entry看得出，Entry组成的是一个单向链表，因为里面只有Entry的后继Entry，而没有Entry的前驱Entry。用图表示应该是这么一个数据结构：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/hashmap/2.png/w600">

<p>接下来，假设我有这么一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">&amp;nbsp;Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">&amp;nbsp;map.put(<span class="string">"111"</span>, <span class="string">"111"</span>);</span><br><span class="line">&amp;nbsp;map.put(<span class="string">"222"</span>, <span class="string">"222"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看一下做了什么。首先从第3行开始，new了一个HashMap出来：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&amp;nbsp;<span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR;</span><br><span class="line">&amp;nbsp;threshold = (<span class="keyword">int</span>)(DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR);</span><br><span class="line">&amp;nbsp;table = <span class="keyword">new</span> Entry[DEFAULT_INITIAL_CAPACITY];</span><br><span class="line">&amp;nbsp;init();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意一下第5行的init()是个空方法，它是HashMap的子类比如LinkedHashMap构造的时候使用的。DEFAULT_INITIAL_CAPACITY为16，也就是说，HashMap在new的时候构造出了一个大小为16的Entry数组，Entry内所有数据都取默认值，如图示为：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/hashmap/3.png/w600">

<p>看到new出了一个大小为16的Entry数组来。接着第4行，put了一个Key和Value同为111的字符串，看一下put的时候底层做了什么：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">    <span class="keyword">return</span> putForNullKey(value);</span><br><span class="line">  <span class="keyword">int</span> hash = hash(key.hashCode());</span><br><span class="line">  <span class="keyword">int</span> i = indexFor(hash, table.length);</span><br><span class="line">  <span class="keyword">for</span> (Entry&lt;&gt; e = table[i]; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">    Object k;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))) &#123;</span><br><span class="line">      V oldValue = e.value;</span><br><span class="line">      e.value = value;</span><br><span class="line">      e.recordAccess(<span class="keyword">this</span>);</span><br><span class="line">      <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  modCount++;</span><br><span class="line">  addEntry(hash, key, value, i);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(<span class="keyword">int</span> h)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// This function ensures that hashCodes that differ only by</span></span><br><span class="line">  <span class="comment">// constant multiples at each bit position have a bounded</span></span><br><span class="line">  <span class="comment">// number of collisions (approximately 8 at default load factor).</span></span><br><span class="line">  h ^= (h &gt;&gt;&gt; <span class="number">20</span>) ^ (h &gt;&gt;&gt; <span class="number">12</span>);</span><br><span class="line">  <span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">7</span>) ^ (h &gt;&gt;&gt; <span class="number">4</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">indexFor</span><span class="params">(<span class="keyword">int</span> h, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">  &amp;nbsp;<span class="keyword">return</span> h &amp;amp; (length-<span class="number">1</span>);&amp;nbsp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看一下put方法的几个步骤：</p>
<ol>
<li><p>第2行~第3行就是HashMap允许Key值为空的原因，空的Key会默认放在第0位的数组位置上</p>
</li>
<li><p>第4行拿到Key值的HashCode，由于HashCode是Object的方法，因此每个对象都有一个HashCode，对这个HashCode做一次hash计算。按照JDK源码注释的说法，这次hash的作用是根据给定的HashCode对它做一次打乱的操作，防止一些糟糕的Hash算法产生的糟糕的Hash值，至于为什么要防止糟糕的Hash值，HashMap添加元素的最后会讲到</p>
</li>
<li><p>第5行根据重新计算的HashCode，对Entry数组的大小取模得到一个Entry数组的位置。看到这里使用了&amp;，移位加快一点代码运行效率。另外，这个取模操作的正确性依赖于length必须是2的N次幂，这个熟悉二进制的朋友一定理解，因此注意HashMap构造函数中，如果你指定HashMap初始数组的大小initialCapacity，如果initialCapacity不是2的N次幂，HashMap会算出大于initialCapacity的最小2的N次幂的值，作为Entry数组的初始化大小。这里为了讲解方便，我们假定字符串111和字符串222算出来的i都是1</p>
</li>
<li><p>第6行~第14行会先判断一下原数据结构中是否存在相同的Key值，存在则覆盖并返回，不执行后面的代码。注意一下recordAccess这个方法，它也是HashMap的子类比如LinkedHashMap用的，HashMap中这个方法为空。另外，注意一点，对比Key是否相同，是先比HashCode是否相同，HashCode相同再判断equals是否为true，这样大大增加了HashMap的效率，对HashCode不熟悉的朋友可以看一下我的这篇文章讲讲HashCode的作用</p>
</li>
<li><p>第16行的modeCount++是用于fail-fast机制的，每次修改HashMap数据结构的时候都会自增一次这个值</p>
</li>
</ol>
<p>然后就到了关键的addEntry方法了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">int</span> bucketIndex)</span> </span>&#123;</span><br><span class="line">  Entry&lt;&gt; e = table[bucketIndex];</span><br><span class="line">  table[bucketIndex] = <span class="keyword">new</span> Entry&lt;K,V&gt;(hash, key, value, e);</span><br><span class="line">  <span class="keyword">if</span> (size++ &gt;= threshold)</span><br><span class="line"></span><br><span class="line">  resize(<span class="number">2</span> * table.length);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Entry(<span class="keyword">int</span> h, K k, V v, Entry&lt;K,V&gt; n) &#123;</span><br><span class="line">  value = v;</span><br><span class="line">  next = n;</span><br><span class="line">  key = k;</span><br><span class="line">  hash = h;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>假设new出来的Entry地址为0×00000001，那么，put(“111″, “111″)用图表示应该是这样的：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/hashmap/4.png/w600">

<p>每一个新增的Entry都位于table[1]上，另外，里面的hash是rehash之后的hash而不是Key最原始的hash。看到table[1]上存放了111—-&gt;111这个键值对，它持有原table[1]的引用地址，因此可以寻址到原table[1]，这就是单向链表。 再看一下put(“222″, “222″)做了什么，一张图就可以理解了：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/hashmap/5.png/w600">

<p>新的Entry再次占据table[1]的位置，并且持有原table[1]，也就是111—-&gt;111这个键值对。</p>
<p>至此，HashMap进行put数据的过程就呈现清楚了。不过还有一个问题，就是HashMap如何进行扩容，再看一下addEntry方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">int</span> bucketIndex)</span> </span>&#123;</span><br><span class="line">  &amp;nbsp; Entry&lt;K,V&gt; e = table[bucketIndex];</span><br><span class="line">  &amp;nbsp; table[bucketIndex] = <span class="keyword">new</span> Entry&lt;K,V&gt;(hash, key, value, e);</span><br><span class="line">  &amp;nbsp; <span class="keyword">if</span> (size++ &gt;= threshold)</span><br><span class="line"></span><br><span class="line">  &amp;nbsp; resize(<span class="number">2</span> * table.length);&amp;nbsp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看到第4行~第5行，也就是说在每次放置完Entry之后都会判断是否需要扩容。这里不讲扩容是因为HashMap扩容在不正确的使用场景下将会导致死循环，这是一个值得探讨的话题，也是我工作中实际遇到过的一个问题，因此下一篇文章将会详细说明为什么不正确地使用HashMap会导致死循环。</p>
<h1 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a><strong>删除数据</strong></h1><p>有一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">map.put(<span class="string">"111"</span>, <span class="string">"111"</span>);</span><br><span class="line">map.put(<span class="string">"222"</span>, <span class="string">"222"</span>);</span><br><span class="line">map.remove(<span class="string">"111"</span>);&#125;</span><br></pre></td></tr></table></figure>

<p>第6行删除元素，看一下删除元素的时候做了什么，第4行~第5行添加了两个键值对就沿用上面的图，HashMap删除指定键值对的源代码是：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">  &amp;nbsp; Entry&lt;K,V&gt; e = removeEntryForKey(key);</span><br><span class="line">  &amp;nbsp; <span class="keyword">return</span> (e == <span class="keyword">null</span> ? <span class="keyword">null</span> : e.value);&amp;nbsp;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">final</span> Entry&lt;K,V&gt; <span class="title">removeEntryForKey</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> hash = (key == <span class="keyword">null</span>) ? <span class="number">0</span> : hash(key.hashCode());</span><br><span class="line">  <span class="keyword">int</span> i = indexFor(hash, table.length);</span><br><span class="line">  Entry&lt;K,V&gt; prev = table[i];</span><br><span class="line">  Entry&lt;K,V&gt; e = prev;&amp;nbsp;</span><br><span class="line">  <span class="keyword">while</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">    Entry&lt;K,V&gt; next = e.next;</span><br><span class="line">    Object k;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;amp;&amp;amp; key.equals(k)))) &#123;</span><br><span class="line"></span><br><span class="line">      modCount++;</span><br><span class="line">      size--;</span><br><span class="line">      <span class="keyword">if</span> (prev == e)</span><br><span class="line">        table[i] = next;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        prev.next = next;</span><br><span class="line">      e.recordRemoval(<span class="keyword">this</span>);</span><br><span class="line">      <span class="keyword">return</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    prev = e;</span><br><span class="line">    e = next;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> e;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>分析一下remove元素的时候做了几步：</p>
<ol>
<li><p>根据key的hash找到待删除的键值对位于table的哪个位置上</p>
</li>
<li><p>记录一个prev表示待删除的Entry的前一个位置Entry，e可以认为是当前位置</p>
</li>
<li><p>从table[i]开始遍历链表，假如找到了匹配的Entry，要做一个判断，这个Entry是不是table[i]：</p>
<ul>
<li><p>（1）是的话，也就是第14行~第15行，table[i]就直接是table[i]的下一个节点，后面的都不需要动</p>
</li>
<li><p>（2）不是的话，也就是第16行~第17行，e的前一个Entry也就是prev，prev的next指向e的后一个节点，也就是next，这样，e所代表的Entry就被踢出了，e的前后Entry就连起来了</p>
</li>
</ul>
</li>
</ol>
<p>remove(“111″)用图表示就是：</p>
<img class="aligncenter size-full wp-image-25055" title="801753-20151212160519559-1676241073" data-src="http://mmbiz.qpic.cn/mmbiz_png/eZzl4LXykQwibZwgqHG6eMbLa2ibSsPYwNSNetViczaN3Nsz78UfxcCYfGpAPIPhria29FDicy8Z6Vu3o6UW8nyPE4A/0?wx_fmt=png" style=" border-width: 0px; border-style: initial; border-color: initial; font-size: 0px; color: transparent; vertical-align: middle; text-align: center ; ; ; ; ; ; ; ; ; " data-type="png"  />



<p>整个过程只需要修改一个节点的next的值即可，非常方便。</p>
<p><strong>修改数据</strong></p>
<p>修改元素也是put，看一下源代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> putForNullKey(value);</span><br><span class="line"><span class="keyword">int</span> hash = hash(key.hashCode());</span><br><span class="line"><span class="keyword">int</span> i = indexFor(hash, table.length);</span><br><span class="line"><span class="keyword">for</span> (Entry&lt;K,V&gt; e = table[i]; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line"></span><br><span class="line">Object k;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))) &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">V oldValue = e.value;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">e.value = value;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">e.recordAccess(<span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> oldValue;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">modCount++;</span><br><span class="line">addEntry(hash, key, value, i);</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">这个其实前面已经提到过了，第<span class="number">6</span>行~第<span class="number">14</span>行就是修改元素的逻辑，如果某个Key已经在数据结构中存在的话，那么就会覆盖原value，也就是第<span class="number">10</span>行的代码。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**插入数据**</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">所谓”插入元素”，在我的理解里，一定是基于数据结构是有序的前提下的。像ArrayList、LinkedList，再远点说就是数据库，一条一条都是有序的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">而HashMap，它的顺序是基于HashCode，HashCode是一个随机性很强的数字，所以HashMap中的Entry完全是随机存放的。HashMap又不像LinkedHashMap这样维护了插入元素的顺序，所以对HashMap这个数据结构谈插入元素是没有意义的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">所以，HashMap并没有插入的概念。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**再谈HashCode的重要性**</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">前面讲到了，HashMap中对Key的HashCode要做一次rehash，防止一些糟糕的Hash算法生成的糟糕的HashCode，那么为什么要防止糟糕的HashCode？</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">糟糕的HashCode意味着的是Hash冲突，即多个不同的Key可能得到的是同一个HashCode，糟糕的Hash算法意味着的就是Hash冲突的概率增大，这意味着HashMap的性能将下降，表现在两方面：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>. 有<span class="number">10</span>个Key，可能<span class="number">6</span>个Key的HashCode都相同，另外四个Key所在的Entry均匀分布在table的位置上，而某一个位置上却连接了<span class="number">6</span>个Entry。这就失去了HashMap的意义，HashMap这种数据结构性高性能的前提是，Entry均匀地分布在table位置上，但现在确是<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">6</span>的分布。所以，我们要求HashCode有很强的随机性，这样就尽可能地可以保证了Entry分布的随机性，提升了HashMap的效率。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. HashMap在一个某个table位置上遍历链表的时候的代码：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line"><span class="keyword">if</span> (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k)))</span><br></pre></td></tr></table></figure>


<p>看到，由于采用了”&amp;&amp;”运算符，因此先比较HashCode，HashCode都不相同就直接pass了，不会再进行equals比较了。HashCode因为是int值，比较速度非常快，而equals方法往往会对比一系列的内容，速度会慢一些。Hash冲突的概率大，意味着equals比较的次数势必增多，必然降低了HashMap的效率了。&nbsp;</p>
<p><strong>HashMap的table为什么是transient的</strong></p>
<p>一个非常细节的地方：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">transient</span> Entry[] table;</span><br></pre></td></tr></table></figure>


<p>看到table用了transient修饰，也就是说table里面的内容全都不会被序列化，不知道大家有没有想过这么写的原因？</p>
<p>在我看来，这么写是非常必要的。因为HashMap是基于HashCode的，HashCode作为Object的方法，是native的：</p>
<pre><code class="java">


这意味着的是：HashCode和底层实现相关，不同的虚拟机可能有不同的HashCode算法。再进一步说得明白些就是，可能同一个Key在虚拟机A上的HashCode=<span class="number">1</span>，在虚拟机B上的HashCode=<span class="number">2</span>，在虚拟机C上的HashCode=<span class="number">3</span>。



这就有问题了，Java自诞生以来，就以跨平台性作为最大卖点，好了，如果table不被<span class="keyword">transient</span>修饰，在虚拟机A上可以用的程序到虚拟机B上可以用的程序就不能用了，失去了跨平台性，因为：



<span class="number">1</span>. Key在虚拟机A上的HashCode=<span class="number">100</span>，连在table[<span class="number">4</span>]上



<span class="number">2</span>. Key在虚拟机B上的HashCode=<span class="number">101</span>，这样，就去table[<span class="number">5</span>]上找Key，明显找不到



整个代码就出问题了。因此，为了避免这一点，Java采取了重写自己序列化table的方法，在writeObject选择将key和value追加到序列化的文件最后面：



```<span class="function">java <span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeObject</span><span class="params">(java.io.ObjectOutputStream s)</span></span>
<span class="function"></span>
<span class="function"><span class="keyword">throws</span> IOException</span>{Iterator&lt;Map.Entry&lt;K,V&gt;&gt; i =
(size &gt; <span class="number">0</span>) ? entrySet0().iterator() : <span class="keyword">null</span>;&amp;nbsp;<span class="comment">// Write out the threshold, loadfactor, and any hidden stuffs.defaultWriteObject();&amp;nbsp;// Write out number of bucketss.writeInt(table.length);&amp;nbsp;// Write out size (number of Mappings)s.writeInt(size);&amp;nbsp;</span>
<span class="comment">// Write out keys and values (alternating)if (i != null) {&amp;nbsp;while (i.hasNext()) {</span>
Map.Entry&lt;K,V&gt; e = i.next();
s.writeObject(e.getKey());
s.writeObject(e.getValue());
}
}}



而在readObject的时候重构HashMap数据结构：



```<span class="function">java <span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readObject</span><span class="params">(java.io.ObjectInputStream s)</span></span>
<span class="function"></span>
<span class="function">&amp;nbsp</span>;<span class="keyword">throws</span> IOException, ClassNotFoundException{<span class="comment">// Read in the threshold, loadfactor, and any hidden stuffs.defaultReadObject();&amp;nbsp;// Read in number of buckets and allocate the bucket array;int numBuckets = s.readInt();table = new Entry[numBuckets];&amp;nbsp;</span>
init(); &amp;nbsp;<span class="comment">// Give subclass a chance to do its thing.&amp;nbsp;// Read in size (number of Mappings)int size = s.readInt();&amp;nbsp;// Read the keys and values, and put the mappings in the HashMapfor (int i=0; i&lt;size; i++) {</span>
K key = (K) s.readObject();
V value = (V) s.readObject();
putForCreate(key, value);}}



一种麻烦的方式，但却保证了跨平台性。



这个例子也告诉了我们：尽管使用的虚拟机大多数情况下都是HotSpot，但是也不能对其它虚拟机不管不顾，有跨平台的思想是一件好事。



**HashMap和Hashtable的区别**



HashMap和Hashtable是一组相似的键值对集合，它们的区别也是面试常被问的问题之一，我这里简单总结一下HashMap和Hashtable的区别：



<span class="number">1</span>. Hashtable是线程安全的，Hashtable所有对外提供的方法都使用了<span class="keyword">synchronized</span>，也就是同步，而HashMap则是线程非安全的



<span class="number">2</span>. Hashtable不允许空的value，空的value将导致空指针异常，而HashMap则无所谓，没有这方面的限制



<span class="number">3</span>. 上面两个缺点是最主要的区别，另外一个区别无关紧要，我只是提一下，就是两个的rehash算法不同，Hashtable的是：



```<span class="function">java <span class="keyword">private</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object k)</span> </span>{
<span class="comment">// hashSeed will be zero if alternative hashing is disabled.</span>
<span class="keyword">return</span> hashSeed ^ k.hashCode();}



这个hashSeed是使用sun.misc.Hashing类的randomHashSeed方法产生的。HashMap的rehash算法上面看过了，也就是：



```<span class="function">java <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(<span class="keyword">int</span> h)</span> </span>{
<span class="comment">// This function ensures that hashCodes that differ only by</span>
<span class="comment">// constant multiples at each bit position have a bounded</span>
<span class="comment">// number of collisions (approximately 8 at default load factor).</span>
h ^= (h &gt;&gt;&gt; <span class="number">20</span>) ^ (h &gt;&gt;&gt; <span class="number">12</span>);
<span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">7</span>) ^ (h &gt;&gt;&gt; <span class="number">4</span>);
}
</code></pre>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Id生成器</title>
    <url>/java/id-generate/</url>
    <content><![CDATA[<p><strong>资料</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/qO84jWhQ5O2mPafsHrh2bA" target="_blank" rel="noopener">分布式ID生成器</a></li>
<li><a href="https://gitee.com/robertleepeak/vesta-id-generator" target="_blank" rel="noopener">通用的ID产生器–Vesta</a></li>
<li><a href="https://github.com/twitter/snowflake" target="_blank" rel="noopener">twitter的全局唯一ID生成器—snowflake</a></li>
</ul>
<hr>
<h2 id="单表"><a href="#单表" class="headerlink" title="单表"></a>单表</h2><p>可以借助于mysql自带的id生成器每次自增+1的方式来生成主键id。</p>
<h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><p>需要提前在外部生成id，然后将记录插入到对应的分表中。</p>
<a id="more"></a>
<div class="note primary">
            <p><strong>其实原理很简单，只需实现一个id批量生成查询器即可，大概步骤：</strong></p>
          </div>
<div class="text-center">
<pre class="mermaid" style="text-align: center;">
            graph TD
            A[消费端] -->|Get ID| B(缓存)
B --> C{判断是否超出范围}
C -->|没有超出| A[消费端]
C -->|超出范围| E[生产服务]
E -->F[数据库]
          </pre>
</div>

<ol>
<li>本地引入一个client二方包，当有记录要插入数据库表时，调用nextId方法生成一个id，由于是提前分配的，大多数情况下从本地cache取，如果分配完了，需要从服务器再次申请。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ConcurrentHashMap&lt;CacheKey, CachedRange&gt; cache = <span class="keyword">new</span> ConcurrentHashMap&lt;CacheKey, CachedRange&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// CacheKey：业务场景</span></span><br><span class="line"><span class="comment">// CachedRange：当前批次可用的id区间范围</span></span><br></pre></td></tr></table></figure>

 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">nextId</span><span class="params">(String app, String key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>)&#123;</span><br><span class="line">        CacheKey cacheKey = <span class="keyword">new</span> CacheKey(app, key);</span><br><span class="line">        CachedRange cachedRange = <span class="keyword">this</span>.cache.get(cacheKey);</span><br><span class="line">        <span class="keyword">if</span> (cachedRange == <span class="keyword">null</span> || cachedRange.range.getEnd() &lt; cachedRange.pos) &#123;</span><br><span class="line">            IDRange range = <span class="keyword">this</span>.service.getNextRange(app, key, <span class="keyword">this</span>.size);</span><br><span class="line">            cachedRange = <span class="keyword">new</span> CachedRange(range, range.getStart()) ;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> pos = cachedRange.pos;</span><br><span class="line">        cachedRange.pos += <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">this</span>.cache.put(cacheKey, cachedRange);</span><br><span class="line">        <span class="keyword">return</span> pos;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>初始化时或者分配的区间段用完，此时需要从远程服务器申请</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取一个可用的IDRange, 结果为闭区间[a, b]</span></span><br><span class="line"><span class="comment">// size：表示一次获取id的区间长度</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> IDRange <span class="title">getNextRange</span><span class="params">(String app, String key, <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">        IDRange result = <span class="keyword">new</span> IDRange();</span><br><span class="line">        IDRange range = <span class="keyword">this</span>.getAndUpdate(app, key, size * <span class="keyword">this</span>.PRE_ALOCATE_BATCH_NUM);</span><br><span class="line">        result.setApp(app);</span><br><span class="line">        result.setKey(key);</span><br><span class="line">        result.setStart(range.getStart());</span><br><span class="line">        result.setEnd(range.getEnd());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.logger.info(<span class="string">"return range: &#123;&#125;"</span>, result);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数据库查询</span></span><br><span class="line"> <span class="meta">@Transactional</span>(value=<span class="string">"crtTransactionManager"</span>, propagation = Propagation.REQUIRED, rollbackFor = Exception<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">IDRange</span> <span class="title">getAndUpdate</span>(<span class="title">String</span> <span class="title">app</span>, <span class="title">String</span> <span class="title">key</span>, <span class="title">int</span> <span class="title">size</span>) </span>&#123;</span><br><span class="line">    Map&lt;String, String&gt; params = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">    params.put(<span class="string">"app"</span>, app);</span><br><span class="line">    params.put(<span class="string">"key"</span>, key);</span><br><span class="line">    SqlSession sqlSession = <span class="keyword">this</span>.commonSqlSessionTemplate.getSqlSessionFactory()</span><br><span class="line">            .openSession();</span><br><span class="line">    UniversalId universalId = sqlSession.selectOne(<span class="string">"select Update;"</span>, params);</span><br><span class="line">    <span class="keyword">if</span> (universalId == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    IDRange range = <span class="keyword">new</span> IDRange();</span><br><span class="line">    range.setApp(app);</span><br><span class="line">    range.setKey(key);</span><br><span class="line">    range.setStart(universalId.getValue() + <span class="number">1</span>);</span><br><span class="line">    range.setEnd(universalId.getValue() + size - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    universalId.setValue(universalId.getValue() + size);</span><br><span class="line">    sqlSession.update(<span class="string">"updateValue"</span>, universalId);</span><br><span class="line">    <span class="keyword">return</span> range;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>常用jdk命令</title>
    <url>/java/common-jdk-cmd/</url>
    <content><![CDATA[<h2 id="1-查看正在运行的JVM的参数"><a href="#1-查看正在运行的JVM的参数" class="headerlink" title="1.查看正在运行的JVM的参数"></a>1.查看正在运行的JVM的参数</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jcmd 24684 VM.flags</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<p>返回结果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">-XX:CICompilerCount=<span class="number">3</span> -XX:ErrorFile=/data/program/java_error.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/program/java.hprof -XX:InitialHeapSize=<span class="number">130023424</span> -XX:+ManagementServer -XX:MaxHeapSize=<span class="number">2063597568</span> -XX:MaxNewSize=<span class="number">687865856</span> -XX:MinHeapDeltaBytes=<span class="number">524288</span> -XX:NewSize=<span class="number">42991616</span> -XX:OldSize=<span class="number">87031808</span> -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java IO</title>
    <url>/java/io/</url>
    <content><![CDATA[<h1 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h1><h1 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h1><h1 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h1><a id="more"></a>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Jvm参数---性能调优</title>
    <url>/java/jvm-param/</url>
    <content><![CDATA[<h1 id="一、jvm参数"><a href="#一、jvm参数" class="headerlink" title="一、jvm参数"></a>一、jvm参数</h1><ul>
<li>-Xms </li>
</ul>
<p>堆最小值</p>
<a id="more"></a>

<ul>
<li>-Xmx</li>
</ul>
<p>堆最大堆值。-Xms与-Xmx 的单位默认字节都是以k、m做单位的。</p>
<p>通常这两个配置参数相等，避免每次空间不足，动态扩容带来的影响。</p>
<ul>
<li>-Xmn </li>
</ul>
<p>新生代大小</p>
<ul>
<li>-Xss </li>
</ul>
<p>每个线程池的堆栈大小。在jdk5以上的版本，每个线程堆栈大小为1m，jdk5以前的版本是每个线程池大小为256k。一般在相同物理内存下，如果减少－xss值会产生更大的线程数，但不同的操作系统对进程内线程数是有限制的，是不能无限生成。</p>
<ul>
<li>-XX:NewRatio </li>
</ul>
<p>设置新生代与老年代比值，-XX:NewRatio=4 表示新生代与老年代所占比例为1:4 ，新生代占比整个堆的五分之一。如果设置了-Xmn的情况下，该参数是不需要在设置的。</p>
<ul>
<li>-XX:PermSize</li>
</ul>
<p>设置持久代初始值，默认是物理内存的六十四分之一</p>
<ul>
<li>-XX:MaxPermSize </li>
</ul>
<p>设置持久代最大值，默认是物理内存的四分之一</p>
<ul>
<li>-XX:MaxTenuringThreshold</li>
</ul>
<p>新生代中对象存活次数，默认15。（若对象在eden区，经历一次MinorGC后还活着，则被移动到Survior区，年龄加1。以后，对象每次经历MinorGC，年龄都加1。达到阀值，则移入老年代）</p>
<ul>
<li>-XX:SurvivorRatio </li>
</ul>
<p>Eden区与Subrvivor区大小的比值，如果设置为8，两个Subrvivor区与一个Eden区的比值为2:8，一个Survivor区占整个新生代的十分之一</p>
<ul>
<li>-XX:+UseFastAccessorMethods </li>
</ul>
<p>原始类型快速优化</p>
<ul>
<li>-XX:+AggressiveOpts</li>
</ul>
<p>编译速度加快</p>
<ul>
<li>-XX:PretenureSizeThreshold</li>
</ul>
<p>对象超过多大值时直接在老年代中分配</p>
<p>说明：</p>
<div class="note primary">
            <p>整个堆大小的计算公式：JVM 堆大小 ＝ 年轻代大小＋年老代大小＋持久代大小。<br>增大新生代大小就会减少对应的年老代大小，设置-Xmn值对系统性能影响较大，所以如果设置新生代大小的调整，则需要严格的测试调整。而新生代是用来存放新创建的对象，大小是随着堆大小增大和减少而有相应的变化，默认值是保持堆大小的十五分之一，-Xmn参数就是设置新生代的大小，也可以通过-XX:NewRatio来设置新生代与年老代的比例，java 官方推荐配置为3:8。</p><p>新生代的特点就是内存中的对象更新速度快，在短时间内容易产生大量的无用对象，如果在这个参数时就需要考虑垃圾回收器设置参数也需要调整。推荐使用：复制清除算法和并行收集器进行垃圾回收，而新生代的垃圾回收叫做初级回收。</p>
          </div>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StackOverflowError和OutOfMemoryException。当线程中的请求的栈的深度大于最大可用深度，就会抛出前者；若内存空间不够，无法创建新的线程，则会抛出后者。栈的大小直接决定了函数的调用最大深度，栈越大，函数嵌套可调用次数就越多。</span><br></pre></td></tr></table></figure>
<p><strong>经验：</strong></p>
<ol>
<li><p>Xmn用于设置新生代的大小。过小会增加Minor GC频率，过大会减小老年代的大小。一般设为整个堆空间的1/4或1/3.</p>
</li>
<li><p>XX:SurvivorRatio用于设置新生代中survivor空间（from/to）和eden空间的大小比例；<br>XX:TargetSurvivorRatio表示，当经历Minor GC后，survivor空间占有量（百分比）超过它的时候，就会压缩进入老年代（当然，如果survivor空间不够，则直接进入老年代）。默认值为50%。</p>
</li>
<li><p>为了性能考虑，一开始尽量将新生代对象留在新生代，避免新生的大对象直接进入老年代。因为新生对象大部分都是短期的，这就造成了老年代的内存浪费，并且回收代价也高（Full GC发生在老年代和方法区Perm）.</p>
</li>
<li><p>当Xms=Xmx，可以使得堆相对稳定，避免不停震荡</p>
</li>
<li><p>一般来说，MaxPermSize设为64MB可以满足绝大多数的应用了。若依然出现方法区溢出，则可以设为128MB。若128MB还不能满足需求，那么就应该考虑程序优化了，减少<strong>动态类</strong>的产生。</p>
</li>
</ol>
<h1 id="二、垃圾回收"><a href="#二、垃圾回收" class="headerlink" title="二、垃圾回收"></a>二、垃圾回收</h1><h2 id="垃圾回收算法："><a href="#垃圾回收算法：" class="headerlink" title="垃圾回收算法："></a><strong>垃圾回收算法：</strong></h2><ul>
<li>引用计数法：会有循环引用的问题，古老的方法；</li>
<li>Mark-Sweep：标记清除。根可达判断，最大的问题是空间碎片（清除垃圾之后剩下不连续的内存空间）；</li>
<li>Copying：复制算法。对于短命对象来说有用，否则需要复制大量的对象，效率低。<strong>如Java的新生代堆空间中就是使用了它（survivor空间的from和to区）；</strong></li>
<li>Mark-Compact：标记整理。对于老年对象来说有用，无需复制，不会产生内存碎片</li>
</ul>
<h2 id="GC考虑的指标"><a href="#GC考虑的指标" class="headerlink" title="GC考虑的指标"></a><strong>GC考虑的指标</strong></h2><ul>
<li>吞吐量：应用耗时和实际耗时的比值；</li>
<li>停顿时间：垃圾回收的时候，由于Stop the World，应用程序的所有线程会挂起，造成应用停顿。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">吞吐量和停顿时间是互斥的。</span><br><span class="line">对于后端服务(比如后台计算任务)，吞吐量优先考虑（并行垃圾回收）；</span><br><span class="line">对于前端应用，RT响应时间优先考虑，减少垃圾收集时的停顿时间，适用场景是Web系统（并发垃圾回收）</span><br></pre></td></tr></table></figure>

<h2 id="回收器的JVM参数"><a href="#回收器的JVM参数" class="headerlink" title="回收器的JVM参数"></a><strong>回收器的JVM参数</strong></h2><ul>
<li>-XX:+UseSerialGC</li>
</ul>
<p>串行垃圾回收，现在基本很少使用。</p>
<ul>
<li>-XX:+UseParNewGC</li>
</ul>
<p>新生代使用并行，老年代使用串行；</p>
<ul>
<li>-XX:+UseConcMarkSweepGC</li>
</ul>
<p>新生代使用并行，老年代使用CMS（一般都是使用这种方式），CMS是Concurrent Mark Sweep的缩写，并发标记清除，一看就是老年代的算法，所以，它可以作为老年代的垃圾回收器。CMS不是独占式的，它关注停顿时间</p>
<ul>
<li>-XX:ParallelGCThreads</li>
</ul>
<p>指定并行的垃圾回收线程的数量，最好等于CPU数量</p>
<ul>
<li>-XX:+DisableExplicitGC</li>
</ul>
<p>禁用System.gc()，因为它会触发Full GC，这是很浪费性能的，JVM会在需要GC的时候自己触发GC。</p>
<ul>
<li>-XX:CMSFullGCsBeforeCompaction </li>
</ul>
<p>在多少次GC后进行内存压缩，这个是因为并行收集器不对内存空间进行压缩的，所以运行一段时间后会产生很多碎片，使得运行效率降低。</p>
<ul>
<li>-XX:+CMSParallelRemarkEnabled</li>
</ul>
<p>降低标记停顿</p>
<ul>
<li>-XX:+UseCMSCompactAtFullCollection </li>
</ul>
<p>在每一次Full GC时对老年代区域碎片整理，因为CMS是不会移动内存的，因此会非常容易出现碎片导致内存不够用的</p>
<ul>
<li>-XX:+UseCmsInitiatingOccupancyOnly </li>
</ul>
<p>使用手动触发或者自定义触发cms 收集，同时也会禁止hostspot 自行触发CMS GC</p>
<ul>
<li>-XX:CMSInitiatingOccupancyFraction </li>
</ul>
<p>使用CMS作为垃圾回收，使用70%后开始CMS收集</p>
<ul>
<li>-XX:CMSInitiatingPermOccupancyFraction </li>
</ul>
<p>设置perm gen使用达到多少％比时触发垃圾回收，默认是92%</p>
<ul>
<li>-XX:+CMSIncrementalMode </li>
</ul>
<p>设置为增量模式</p>
<ul>
<li>-XX:+CmsClassUnloadingEnabled </li>
</ul>
<p>CMS是不会默认对永久代进行垃圾回收的，设置此参数则是开启</p>
<ul>
<li>-XX:+PrintGCDetails</li>
</ul>
<p>开启详细GC日志模式，日志的格式是和所使用的算法有关</p>
<ul>
<li>-XX:+PrintGCDateStamps</li>
</ul>
<p>将时间和日期也加入到GC日志中</p>
<h2 id="配置参考："><a href="#配置参考：" class="headerlink" title="配置参考："></a><strong>配置参考：</strong></h2><img data-src="http://f.ngall-in.com/alan87/static/images/java/java-jvm-param/java-jvm-param-1.png/w600">

<h2 id="前同事分享的一个不错案例："><a href="#前同事分享的一个不错案例：" class="headerlink" title="前同事分享的一个不错案例："></a><strong>前同事分享的一个不错案例：</strong></h2><img data-src="http://f.ngall-in.com/alan87/static/images/java/java-jvm-param/java-jvm-param-2.png/w600">


<h1 id="线上Jvm堆参数调整"><a href="#线上Jvm堆参数调整" class="headerlink" title="线上Jvm堆参数调整"></a>线上Jvm堆参数调整</h1><p>下面是社区的一个线上dubbo应用的jvm参数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">-XX:CICompilerCount=<span class="number">3</span> -XX:InitialHeapSize=<span class="number">130023424</span> -XX:+ManagementServer -XX:MaxHeapSize=<span class="number">2063597568</span> -XX:MaxNewSize=<span class="number">687865856</span> -XX:MinHeapDeltaBytes=<span class="number">524288</span> -XX:NewSize=<span class="number">42991616</span> -XX:OldSize=<span class="number">87031808</span> -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC </span><br><span class="line"></span><br><span class="line"><span class="comment">// 注：考虑安全性，部分数据删除</span></span><br></pre></td></tr></table></figure>

<p>采用默认值，新生代只有600多M，堆区总大小也只有2个G</p>
<p><strong>社区这边的线上机器基本都是标配4核8G，上面的配置太浪费，如果活动期间有较高并发量，估计新生代会不足，挤压老年代，持续gc，很容易雪崩。</strong></p>
<p>线上jvm参数调整</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">-Xms5020m -Xmx5020m -Xmn2500m -XX:PermSize=<span class="number">96</span>m -XX:MaxPermSize=<span class="number">256</span>m -XX:ParallelGCThreads=<span class="number">4</span>  -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSMaxAbortablePrecleanTime=<span class="number">5000</span> -XX:+CMSClassUnloadingEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=<span class="number">80</span></span><br></pre></td></tr></table></figure>
<p>========================</p>
<p>用了两台线上机做测试，配置一样</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">192.168.16.16（参数未调整）</span><br><span class="line">192.168.18.18 （参数调整）</span><br></pre></td></tr></table></figure>
<p>发布上线后，beta了一天，对比结果如下：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-jvm-param/java-jvm-param-3.png/w600">

<p>192.168.16.16（未调整参数），一天发生了YGC4000多次，整个gc时间26s</p>
<p>192.168.18.18 （参数调整），一天YGC只有500多次，整个gc时间只有2s</p>
<p>如果并发量大的情况下，估计这个差异会更大，支持的最大QPS应该会有很大提升，如果要准确数据的话可以性能压测对比下</p>
<h1 id="jcmd-pid-VM-flags"><a href="#jcmd-pid-VM-flags" class="headerlink" title="jcmd pid VM.flags"></a>jcmd pid VM.flags</h1><p>查看运行中进程JVM相关参数 </p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Jvm内存结构</title>
    <url>/java/jvm%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h1 id="虚拟机运行时的数据区"><a href="#虚拟机运行时的数据区" class="headerlink" title="虚拟机运行时的数据区"></a>虚拟机运行时的数据区</h1><a id="more"></a>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-mem-struct/java-mem-struct-1.png/w600">

<p>对于这五个区域我大概做一个大概介绍:</p>
<ol>
<li><p>程序计数器（program counter register）:线程私有，一块较小的内存空间，可以看作当前线程所执行的字节码的行号指示器。由于java虚拟机是采用多线程，通过线程切换获得时间片得到cpu的控制权。为了线程切换后能恢复到正确的执行位置。</p>
</li>
<li><p>虚拟机栈: 线程私有，生命周期与线程相同，虚拟机栈描述的是Java方法执行的内存模型，每个方法在执行时会形成一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，一个方法从调用到执行完毕，就是一个栈帧从进栈到出栈的过程。通过 -Xss控制大小，如果线程请求的栈深度大于虚拟机所允许的深度，会抛出StatckOverflowError。通过递归死锁会引发这种问题。<br><img data-src="https://img-blog.csdnimg.cn/20190618095048367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hvbGxha2U=,size_16,color_FFFFFF,t_70" alt=""></p>
</li>
<li><p>本地方法栈: 线程私有，作用于Java虚拟机栈类似，只不过Java虚拟机栈执行Java方法，而本地方法栈运行本地的Native方法。</p>
</li>
<li><p>堆（heap），所有线程共享，Java虚拟机管理的最大的一块内存区域，用于存放对象实例。也就是说对象的出生和回收都是在这个区域进行的。堆分为初生代（Young Gen）和老年代（Tenured Gen），比例默认为1:2，而初生代又分为Eden和From和To三个区域，比例默认为8:1:1，通过-Xmx和-Xms控制大小，如果内存不足会抛OutOfMemoryError。通过GC释放<br><img data-src="https://img-blog.csdnimg.cn/20190618102015904.png" alt=""></p>
</li>
<li><p>方法区：线程共享，用于存储已经被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。在1.7及之前方法区是由永久代实现的(HotSpot虚拟机)，1.8开始由元空间（MetaDataSpace）实现。</p>
</li>
</ol>
<ul>
<li><p>Young GC<br>Eden Space 满了 ；Survivor Space 满了</p>
</li>
<li><p>Full GC<br>老年代满了；持久代满了</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jstat –gcutil  进程ID  刷新时间（可以实时监控jvm 的gc情况)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h1 id="JDK1-7和JDK1-8的内存结构比较"><a href="#JDK1-7和JDK1-8的内存结构比较" class="headerlink" title="JDK1.7和JDK1.8的内存结构比较"></a>JDK1.7和JDK1.8的内存结构比较</h1><h2 id="JDK1-7内存结构"><a href="#JDK1-7内存结构" class="headerlink" title="JDK1.7内存结构"></a>JDK1.7内存结构</h2><p>方法区: 也叫持久代，通过-XXMaxPerSize控制大小，当方法区无法满足内存分配需求时也会抛出OutOfMemoryError。特别注意动态代理子类，在运行期会创建很多新的子类，导致空间不足。</p>
<p>运行时常量池：在JDK1.7中，是运行时常量池是方法区的一部分，用于存放编译期生成的各种字符变量和符号引用。其实除了运行时常量池，还有字符串常量池，class常量池</p>
<h2 id="JDK1-8内存结构"><a href="#JDK1-8内存结构" class="headerlink" title="JDK1.8内存结构"></a>JDK1.8内存结构</h2><p>JDK1.8与1.7最大的区别是1.8将永久代取消，取而代之的是<strong>元空间</strong>，在1.8中<strong>方法区</strong>是由<strong>元空间</strong>来实现，所以原来属于方法区的运行时常量池就属于元空间了。</p>
<p>元空间属于本地内存，所以元空间的大小仅受本地内存限制，但是可以通过-XX:MaxMetaspaceSize进行增长上限的最大值设置，默认值为<strong>4G</strong>，元空间的初始空间大小可以通过-XX:MetaspaceSize进行设置，默认值为<strong>20.8M</strong>，还有一些其他参数可以进行设置，元空间大小会自动进行调整.</p>
<p>对象分配规则：</p>
<ol>
<li><p>对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。</p>
</li>
<li><p>大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。</p>
</li>
<li><p>长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，直到达到阀值对象进入老年区。</p>
</li>
<li><p>动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。</p>
</li>
<li><p>空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。</p>
</li>
</ol>
<p>这里要说明一下，要区分字符串常量池和运行时常量池:</p>
<ol>
<li>在JDK1.7之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时hotspot虚拟机对方法区的实现为永久代</li>
<li>在JDK1.7字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是hotspot中的永久代</li>
<li>在JDK1.8 hotspot移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace) </li>
</ol>
<h2 id="jdk1-8-默认GC"><a href="#jdk1-8-默认GC" class="headerlink" title="jdk1.8 默认GC"></a>jdk1.8 默认GC</h2><ol>
<li>默认使用ParallelGC收集器，也就是在新生代使用Parallel Scavenge收集器，老年代使用ParallelOld收集器</li>
</ol>
<p><a href="../JDK各个版本发布时间和版本名称">JDK各个版本发布时间和版本名称</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java8函数编程（lambda表达式）</title>
    <url>/java/lambda/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>面向对象编程是对数据进行抽象；函数式编程是对行为进行抽象。</p>
<p>核心思想：使用不可变值和函数，函数对一个值进行处理，映射成另一个值。</p>
<a id="more"></a>

<p>对核心类库的改进主要包括集合类的API和新引入的流Stream。流使程序员可以站在更高的抽象层次上对集合进行操作。</p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/Xhr9aNEMr0fIUWh27mH1pw" target="_blank" rel="noopener">Lambda 表达式的 10 个示例</a></li>
<li><a href="https://github.com/biezhi/learn-java8" target="_blank" rel="noopener">learn-java8</a></li>
<li><a href="https://github.com/aalansehaiyang/java8-tutorial" target="_blank" rel="noopener">java8-tutorial</a></li>
<li><a href="https://mp.weixin.qq.com/s/9mgD2aV6gML57RAPIEbZeQ" target="_blank" rel="noopener">一文让你明白lambda用法与源码分析</a></li>
</ul>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><h2 id="1-惰性求值方法"><a href="#1-惰性求值方法" class="headerlink" title="1.惰性求值方法"></a>1.惰性求值方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">lists.stream().filter(f -&gt; f.getName().equals(<span class="string">"p1"</span>))</span><br></pre></td></tr></table></figure>
<p>如上示例，这行代码并未做什么实际性的工作，filter只是<strong>描述</strong>了Stream，<strong>没有产生新的集合</strong>。</p>
<p>如果是多个条件组合，可以通过代码块{}</p>
<h2 id="2-及早求值方法"><a href="#2-及早求值方法" class="headerlink" title="2.及早求值方法"></a>2.及早求值方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Persion&gt; list2 = lists.stream().filter(f -&gt; f.getName().equals(<span class="string">"p1"</span>)).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>
<p>如上示例，collect最终会从Stream产生新值，拥有终止操作。</p>
<p>理想方式是形成一个惰性求值的链，最后用一个及早求值的操作返回想要的结果。与建造者模式相似，建造者模式先是使用一系列操作设置属性和配置，最后调用build方法，创建对象。</p>
<h1 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h1><h2 id="1-collect-Collectors-toList"><a href="#1-collect-Collectors-toList" class="headerlink" title="1.collect(Collectors.toList())"></a>1.collect(Collectors.toList())</h2><p>Stream流生成一个List列表</p>
<p>Collectors.toSet() ，生成set集合。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Collectors.toMap(MemberModel::getUid, Function.identity())</span><br><span class="line"></span><br><span class="line">Function.identity() <span class="comment">//表示遍历的对象</span></span><br></pre></td></tr></table></figure>

<p>Collectors里提供了很多方法，比如字符串拼接。</p>
<h2 id="2-map"><a href="#2-map" class="headerlink" title="2.map"></a>2.map</h2><p>将一种类型转换成另外一种类型</p>
<h2 id="3-filter"><a href="#3-filter" class="headerlink" title="3.filter"></a>3.filter</h2><p>对Stream流中的元素过滤。</p>
<p>true：保留；false：扔掉。</p>
<h2 id="4-flatMap"><a href="#4-flatMap" class="headerlink" title="4.flatMap"></a>4.flatMap</h2><p>将多个Stream连接成一个Stream</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; result= Stream.of(Arrays.asList(<span class="number">1</span>,<span class="number">3</span>),Arrays.asList(<span class="number">5</span>,<span class="number">6</span>)).flatMap(a-&gt;a.stream()).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>
<p> 结果： [1, 3, 5, 6]</p>
<h2 id="5-distinct"><a href="#5-distinct" class="headerlink" title="5.distinct"></a>5.distinct</h2><p>去重</p>
<h2 id="6-count"><a href="#6-count" class="headerlink" title="6.count"></a>6.count</h2><p>计总数</p>
<h2 id="7-min-max"><a href="#7-min-max" class="headerlink" title="7.min,max"></a>7.min,max</h2><p>最小值，最大值</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Persion&gt; lists = <span class="keyword">new</span> ArrayList&lt;Persion&gt;();</span><br><span class="line">lists.add(<span class="keyword">new</span> Persion(<span class="number">1L</span>, <span class="string">"p1"</span>));</span><br><span class="line">lists.add(<span class="keyword">new</span> Persion(<span class="number">2L</span>, <span class="string">"p2"</span>));</span><br><span class="line">lists.add(<span class="keyword">new</span> Persion(<span class="number">3L</span>, <span class="string">"p3"</span>));</span><br><span class="line">lists.add(<span class="keyword">new</span> Persion(<span class="number">4L</span>, <span class="string">"p4"</span>));</span><br><span class="line">Persion a = lists.stream().max(Comparator.comparing(t -&gt; t.getId())).get();</span><br><span class="line">System.out.println(a.getId());</span><br></pre></td></tr></table></figure>
<p>如果比较器涉及多个条件，比较复杂，可以定制</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Persion a = lists.stream().min(<span class="keyword">new</span> Comparator&lt;Persion&gt;() &#123;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Persion o1, Persion o2)</span> </span>&#123;</span><br><span class="line">         <span class="keyword">if</span> (o1.getId() &gt; o2.getId()) <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">         <span class="keyword">if</span> (o1.getId() &lt; o2.getId()) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">         <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;).get();</span><br></pre></td></tr></table></figure>

<h1 id="代码调试"><a href="#代码调试" class="headerlink" title="代码调试"></a>代码调试</h1><p>可以使用peek方法，peek方法可只包含一个空的方法体，只要能设置断点即可，但有些IDE不允许空，可以如下文示例，简单写一个打印逻辑。</p>
<p>注意，调试完后要删掉。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Persion&gt; lists = <span class="keyword">new</span> ArrayList&lt;Persion&gt;();</span><br><span class="line">lists.add(<span class="keyword">new</span> Persion(<span class="number">1L</span>, <span class="string">"p1"</span>));</span><br><span class="line">lists.add(<span class="keyword">new</span> Persion(<span class="number">2L</span>, <span class="string">"p2"</span>));</span><br><span class="line">lists.add(<span class="keyword">new</span> Persion(<span class="number">3L</span>, <span class="string">"p3"</span>));</span><br><span class="line">lists.add(<span class="keyword">new</span> Persion(<span class="number">4L</span>, <span class="string">"p4"</span>));</span><br><span class="line">System.out.println(lists);</span><br><span class="line"></span><br><span class="line">List&lt;Persion&gt; list2 = lists.stream()</span><br><span class="line">      .filter(f -&gt; f.getName().startsWith(<span class="string">"p"</span>))</span><br><span class="line">      .peek(t -&gt; &#123;</span><br><span class="line">          System.out.println(t.getName());</span><br><span class="line">      &#125;)</span><br><span class="line">      .collect(Collectors.toList());</span><br><span class="line">                </span><br><span class="line">System.out.println(list2);</span><br></pre></td></tr></table></figure>

<h1 id="一些例子"><a href="#一些例子" class="headerlink" title="一些例子"></a>一些例子</h1><ul>
<li>集合–》取元素的一个属性–》去重—》组装成List–》返回</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;LikeDO&gt; likeDOs=<span class="keyword">new</span> ArrayList&lt;LikeDO&gt;();</span><br><span class="line"> <span class="comment">//add一系列元素 </span></span><br><span class="line"> <span class="comment">//得到收藏贴子的tid列表</span></span><br><span class="line">List&lt;Long&gt; likeTidList = likeDOs.stream().map(LikeDO::getTid)</span><br><span class="line">                .distinct().collect(Collectors.toList());</span><br></pre></td></tr></table></figure>

<ul>
<li><p>集合–》按表达式过滤–》遍历、每个元系处理–》放入预先定义的集合中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String, StkProduct&gt; newStockName2Product = Maps.newConcurrentMap();</span><br><span class="line">      stockProducts.stream().filter(stkProduct -&gt; stkProduct.enabled).forEach(stkProduct -&gt; &#123;</span><br><span class="line">          String newName = BCConvert.bj2qj(StringUtils.replace(stkProduct.name, <span class="string">" "</span>, <span class="string">""</span>));</span><br><span class="line">          newStockName2Product.put(newName, stkProduct);</span><br><span class="line">      &#125;);</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Set&lt;String&gt; qjStockNames;</span><br><span class="line">qjStockNames.stream().filter(name -&gt; !acAutomaton.getKey2link().containsKey(name)).forEach(name -&gt; &#123;</span><br><span class="line">           String value = <span class="string">""</span>;</span><br><span class="line">           StkProduct stkProduct = stockNameQj2Product.get(name);</span><br><span class="line">           <span class="keyword">if</span> (stkProduct != <span class="keyword">null</span>) &#123;</span><br><span class="line">               value = stkProduct.name;</span><br><span class="line">           &#125;</span><br><span class="line">           acAutomaton.getKey2link().put(name, value);</span><br><span class="line">       &#125;);</span><br></pre></td></tr></table></figure>

</li>
</ul>
<ul>
<li><p>集合–》map</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;ImageModel&gt; imageModelList = <span class="keyword">null</span>;</span><br><span class="line">Map&lt;Long, String&gt; imagesMap = <span class="keyword">null</span>;</span><br><span class="line">imagesMap = imageModelList.stream().collect(Collectors.toMap(ImageModel::getAid, o -&gt; IMAGE_ADDRESS_PREFIX + o.getUrl()));</span><br><span class="line">              </span><br><span class="line">Map&lt;String, String&gt; kvMap = postDetailCacheList.stream().collect(Collectors.toMap((detailCache) -&gt;</span><br><span class="line">                getBbsSimplePostKey(detailCache.getTid()), JSON::toJSONString));</span><br><span class="line"></span><br><span class="line">Map&lt;Long, Long&gt; pidToTid；</span><br><span class="line">List&lt;String&gt; pidKeyList = pidToTid.entrySet().stream().map((o) -&gt; getKeyBbsReplyPid(o.getValue(), o.getKey())).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>
</li>
<li><p>DO模型—》Model模型</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;AdDO&gt; adDOList;</span><br><span class="line">adDOList.stream().map(adDo -&gt; convertAdModel(adDo))</span><br><span class="line">               .collect(Collectors.toList());</span><br></pre></td></tr></table></figure>
</li>
<li><p>phones 是一个List&lt;String&gt;，将相同的元素分组、归类</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; phones=<span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">        phones.add(<span class="string">"a"</span>);</span><br><span class="line">        phones.add(<span class="string">"b"</span>);</span><br><span class="line">        phones.add(<span class="string">"a"</span>);</span><br><span class="line">        phones.add(<span class="string">"a"</span>);</span><br><span class="line">        phones.add(<span class="string">"c"</span>);</span><br><span class="line">        phones.add(<span class="string">"b"</span>);</span><br><span class="line">        Map&lt;String, List&lt;String&gt;&gt; phoneClassify = phones.stream().collect(Collectors.groupingBy(item -&gt; item));</span><br><span class="line">        System.out.println(phoneClassify);</span><br><span class="line">        </span><br><span class="line"><span class="comment">// 返回结果：</span></span><br><span class="line">&#123;a=[a, a, a], b=[b, b], c=[c]&#125;</span><br></pre></td></tr></table></figure>

<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><a href="http://blog.csdn.net/renfufei/article/details/24600507" target="_blank" rel="noopener">http://blog.csdn.net/renfufei/article/details/24600507</a></li>
<li><a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/Lambda-QuickStart/index.html" target="_blank" rel="noopener">http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/Lambda-QuickStart/index.html</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java LinkedList图解</title>
    <url>/java/linkedlist/</url>
    <content><![CDATA[<h1 id="初识LinkedList"><a href="#初识LinkedList" class="headerlink" title="初识LinkedList"></a><strong>初识LinkedList</strong></h1><p><a href="../arraylist">上一篇中讲解了ArrayList</a>，本篇文章讲解一下LinkedList的实现。</p>
<p>LinkedList是基于链表实现的，所以先讲解一下什么是链表。链表原先是C/C++的概念，是一种线性的存储结构，意思是将要存储的数据存在一个存储单元里面，这个存储单元里面除了存放有待存储的数据以外，还存储有其下一个存储单元的地址（下一个存储单元的地址是必要的，有些存储结构还存放有其前一个存储单元的地址），每次查找数据的时候，通过某个存储单元中的下一个存储单元的地址寻找其后面的那个存储单元。</p>
<a id="more"></a>

<p>这么讲可能有点抽象，先提一句，LinkedList是一种双向链表，双向链表我认为有两点含义：</p>
<ol>
<li><p>链表中任意一个存储单元都可以通过向前或者向后寻址的方式获取到其前一个存储单元和其后一个存储单元</p>
</li>
<li><p>链表的尾节点的后一个节点是链表的头结点，链表的头结点的前一个节点是链表的尾节点</p>
</li>
</ol>
<p>LinkedList既然是一种双向链表，必然有一个存储单元，看一下LinkedList的基本存储单元，它是LinkedList中的一个内部类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line">  E element;</span><br><span class="line">  Entry&lt;next;</span><br><span class="line">  Entry&lt;E&gt; previous;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看到LinkedList的Entry中的”E element”，就是它真正存储的数据。”Entry<E> next”和”Entry<E> previous”表示的就是这个存储单元的前一个存储单元的引用地址和后一个存储单元的引用地址。用图表示就是：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/linkedlist/1.png/w600">

<h1 id="四个关注点在LinkedList上的答案"><a href="#四个关注点在LinkedList上的答案" class="headerlink" title="四个关注点在LinkedList上的答案"></a><strong>四个关注点在LinkedList上的答案</strong></h1><img data-src="http://f.ngall-in.com/alan87/static/images/java/linkedlist/2.png/w600">

<h1 id="添加元素"><a href="#添加元素" class="headerlink" title="添加元素"></a><strong>添加元素</strong></h1><p>首先看下LinkedList添加一个元素是怎么做的，假如我有一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">  &amp;nbsp;List&lt;String&gt; list = <span class="keyword">new</span> LinkedList&lt;String&gt;();</span><br><span class="line">  &amp;nbsp;list.add(<span class="string">"111"</span>);</span><br><span class="line">  &amp;nbsp;list.add(<span class="string">"222"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>逐行分析main函数中的三行代码是如何执行的，首先是第3行，看一下LinkedList的源码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractSequentialList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">Deque</span>&lt;<span class="title">E</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">transient</span> Entry&lt;E&gt; header = <span class="keyword">new</span> Entry&lt;E&gt;(<span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">int</span> size = <span class="number">0</span>;&amp;nbsp;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  &amp;nbsp;* Constructs an empty list.</span></span><br><span class="line"><span class="comment">  &amp;nbsp;*/</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">LinkedList</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  header.next = header.previous = header;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看到，new了一个Entry出来名为header，Entry里面的previous、element、next都为null，执行构造函数的时候，将previous和next的值都设置为header的引用地址，还是用画图的方式表示。32位JDK的字长为4个字节，而目前64位的JDK一般采用的也是4字长，所以就以4个字长为单位。header引用地址的字长就是4个字节，假设是0×00000000，那么执行完”List<String> list = new LinkedList<String>()”之后可以这么表示：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/linkedlist/3.png/w600">

<p>接着看第4行add一个字符串”111″做了什么：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">&amp;nbsp;addBefore(e, header);</span><br><span class="line">&amp;nbsp;<span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> Entry&lt;E&gt; <span class="title">addBefore</span><span class="params">(E e, Entry&lt;E&gt; entry)</span> </span>&#123;</span><br><span class="line">  Entry&lt;E&gt; newEntry = <span class="keyword">new</span> Entry&lt;E&gt;(e, entry, entry.previous);</span><br><span class="line">  newEntry.previous.next = newEntry;</span><br><span class="line">  newEntry.next.previous = newEntry;</span><br><span class="line">  size++;</span><br><span class="line">  modCount++;</span><br><span class="line">  <span class="keyword">return</span> newEntry;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第2行new了一个Entry出来，可能不太好理解，根据Entry的构造函数，我把这句话”翻译”一下，可能就好理解了：</p>
<ol>
<li>newEntry.element = e;</li>
<li>newEntry.next = header.next;</li>
<li>newEntry.previous = header.previous;</li>
</ol>
<p>header.next和header.previous上图中已经看到了，都是0×00000000，那么假设new出来的这个Entry的地址是0×00000001，继续画图表示：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/linkedlist/4.png/w600">

<p>一共五步，每一步的操作步骤都用数字表示出来了：</p>
<ol>
<li><p>新的entry的element赋值为111;</p>
</li>
<li><p>新的entry的next是header的next，header的next是0×00000000，所以新的entry的next即0×00000000;</p>
</li>
<li><p>新的entry的previous是header的previous，header的previous是0×00000000，所以新的entry的next即0×00000000;</p>
</li>
<li><p>”newEntry.previous.next = newEntry”，首先是newEntry的previous，由于newEntry的previous为0×00000000，所以newEntry.previous表示的是header，header的next为newEntry，即header的next为0×00000001;</p>
</li>
<li><p>”newEntry.next.previous = newEntry”，和4一样，把header的previous设置为0×00000001;</p>
</li>
</ol>
<p>为什么要这么做？还记得双向链表的两个特点吗，一是任意节点都可以向前和向后寻址，二是整个链表头的previous表示的是链表的尾Entry，链表尾的next表示的是链表的头Entry。现在链表头就是0×00000000这个Entry，链表尾就是0×00000001，可以自己看图观察、思考一下是否符合这两个条件。</p>
<p>最后看一下add了一个字符串”222″做了什么，假设新new出来的Entry的地址是0×00000002，画图表示：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/linkedlist/5.png/w600">

<p>还是执行的那5步，图中每一步都标注出来了，只要想清楚previous、next各自表示的是哪个节点就不会出问题了。</p>
<p>至此，往一个LinkedList里面添加一个字符串”111″和一个字符串”222″就完成了。从这张图中应该理解双向链表比较容易：</p>
<ol>
<li><p>中间的那个Entry，previous的值为0×00000000，即header；next的值为0×00000002，即tail，这就是任意一个Entry既可以向前查找Entry，也可以向后查找Entry</p>
</li>
<li><p>头Entry的previous的值为0×00000002，即tail，这就是双向链表中头Entry的previous指向的是尾Entry</p>
</li>
<li><p>尾Entry的next的值为0×00000000，即header，这就是双向链表中尾Entry的next指向的是头Entry&nbsp;</p>
</li>
</ol>
<h1 id="查看元素"><a href="#查看元素" class="headerlink" title="查看元素"></a><strong>查看元素</strong></h1><p>看一下LinkedList的代码是怎么写的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> entry(index).element;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">```java </span><br><span class="line"><span class="function"><span class="keyword">private</span> Entry&lt;E&gt; <span class="title">entry</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (index &lt; <span class="number">0</span> || index &gt;= size)</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(<span class="string">"Index: "</span>+index+<span class="string">", Size: "</span>+size);</span><br><span class="line">    Entry&lt;E&gt; e = header;</span><br><span class="line">    <span class="keyword">if</span> (index &lt; (size &gt;&gt; <span class="number">1</span>)) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= index; i++)</span><br><span class="line"></span><br><span class="line">      e = e.next;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = size; i &gt; index; i--)</span><br><span class="line">      e = e.previous;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> e;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码就体现出了双向链表的好处了。双向链表增加了一点点的空间消耗（每个Entry里面还要维护它的前置Entry的引用），同时也增加了一定的编程复杂度，却大大提升了效率。</p>
<p>由于LinkedList是双向链表，所以LinkedList既可以向前查找，也可以向后查找，第6行~第12行的作用就是：当index小于数组大小的一半的时候（size &gt;&gt; 1表示size / 2，使用移位运算提升代码运行效率），向后查找；否则，向前查找。</p>
<p>这样，在我的数据结构里面有10000个元素，刚巧查找的又是第10000个元素的时候，就不需要从头遍历10000次了，向后遍历即可，一次就能找到我要的元素。</p>
<h1 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a><strong>删除元素</strong></h1><p>看完了添加元素，我们看一下如何删除一个元素。和ArrayList一样，LinkedList支持按元素删除和按下标删除，前者会删除从头开始匹配的第一个元素。用按下标删除举个例子好了，比方说有这么一段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">List&lt;String&gt; list = <span class="keyword">new</span> LinkedList&lt;String&gt;();</span><br><span class="line">list.add(<span class="string">"111"</span>);</span><br><span class="line">list.add(<span class="string">"222"</span>);</span><br><span class="line">list.remove(<span class="number">0</span>);&#125;</span><br></pre></td></tr></table></figure>
<p>也就是我想删除”111″这个元素。看一下第6行是如何执行的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">remove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">&amp;nbsp;<span class="keyword">return</span> remove(entry(index));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> E <span class="title">remove</span><span class="params">(Entry&lt;E&gt; e)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (e == header)</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException();&amp;nbsp;</span><br><span class="line"></span><br><span class="line">  E result = e.element;e.previous.next = e.next;e.next.previous = e.previous;</span><br><span class="line">&amp;nbsp; &amp;nbsp;e.next = e.previous = <span class="keyword">null</span>;</span><br><span class="line">&amp;nbsp; &amp;nbsp;e.element = <span class="keyword">null</span>;size--;modCount++;</span><br><span class="line">&amp;nbsp; &amp;nbsp;<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当然，首先是找到元素在哪里，这和get是一样的。接着，用画图的方式来说明比较简单：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/linkedlist/6.png/w600">

<p>比较简单，只要找对引用地址就好了，每一步的操作也都详细标注在图上了。</p>
<p>这里我提一点，第3步、第4步、第5步将待删除的Entry的previous、element、next都设置为了null，这三步的作用是让虚拟机可以回收这个Entry。</p>
<p>但是，这个问题我稍微扩展深入一点：按照Java虚拟机HotSpot采用的垃圾回收检测算法—-根节点搜索算法来说，即使previous、element、next不设置为null也是可以回收这个Entry的，因为此时这个Entry已经没有任何地方会指向它了，tail的previous与header的next都已经变掉了，所以这块Entry会被当做”垃圾”对待。之所以还要将previous、element、next设置为null，我认为可能是为了兼容另外一种垃圾回收检测算法—-引用计数法，这种垃圾回收检测算法，只要对象之间存在相互引用，那么这块内存就不会被当作”垃圾”对待。</p>
<h1 id="插入元素"><a href="#插入元素" class="headerlink" title="插入元素"></a><strong>插入元素</strong></h1><p>插入元素就不细讲了，看一下删除元素的源代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</span><br><span class="line">  addBefore(element, (index==size ? header : entry(index)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Entry&lt;E&gt; <span class="title">addBefore</span><span class="params">(E e, Entry&lt;E&gt; entry)</span> </span>&#123;</span><br><span class="line">Entry&lt;E&gt; newEntry = <span class="keyword">new</span> Entry&lt;E&gt;(e, entry, entry.previous);</span><br><span class="line">newEntry.previous.next = newEntry;</span><br><span class="line">newEntry.next.previous = newEntry;</span><br><span class="line">size++;</span><br><span class="line">modCount++;&amp;nbsp; &amp;nbsp;<span class="keyword">return</span> newEntry;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果朋友们理解了前面的内容，我认为这两个方法对你来说，应该是很容易看懂的。</p>
<h1 id="LinkedList和ArrayList的对比"><a href="#LinkedList和ArrayList的对比" class="headerlink" title="LinkedList和ArrayList的对比"></a><strong>LinkedList和ArrayList的对比</strong></h1><p>老生常谈的问题了，这里我尝试以自己的理解尽量说清楚这个问题，顺便在这里就把LinkedList的优缺点也给讲了。</p>
<ol>
<li><p>顺序插入速度ArrayList会比较快，因为ArrayList是基于数组实现的，数组是事先new好的，只要往指定位置塞一个数据就好了；LinkedList则不同，每次顺序插入的时候LinkedList将new一个对象出来，如果对象比较大，那么new的时间势必会长一点，再加上一些引用赋值的操作，所以顺序插入LinkedList必然慢于ArrayList</p>
</li>
<li><p>基于上一点，因为LinkedList里面不仅维护了待插入的元素，还维护了Entry的前置Entry和后继Entry，如果一个LinkedList中的Entry非常多，那么LinkedList将比ArrayList更耗费一些内存</p>
</li>
<li><p>数据遍历的速度，看最后一部分，这里就不细讲了，结论是：使用各自遍历效率最高的方式，ArrayList的遍历效率会比LinkedList的遍历效率高一些</p>
</li>
<li><p>有些说法认为LinkedList做插入和删除更快，这种说法其实是不准确的：</p>
<ul>
<li><p>（1）LinkedList做插入、删除的时候，慢在寻址，快在只需要改变前后Entry的引用地址</p>
</li>
<li><p>（2）ArrayList做插入、删除的时候，慢在数组元素的批量copy，快在寻址</p>
</li>
</ul>
</li>
</ol>
<p>所以，如果待插入、删除的元素是在数据结构的前半段尤其是非常靠前的位置的时候，LinkedList的效率将大大快过ArrayList，因为ArrayList将批量copy大量的元素；越往后，对于LinkedList来说，因为它是双向链表，所以在第2个元素后面插入一个数据和在倒数第2个元素后面插入一个元素在效率上基本没有差别，但是ArrayList由于要批量copy的元素越来越少，操作速度必然追上乃至超过LinkedList。</p>
<p>从这个分析看出，如果你十分确定你插入、删除的元素是在前半段，那么就使用LinkedList；如果你十分确定你删除、删除的元素在比较靠后的位置，那么可以考虑使用ArrayList。如果你不能确定你要做的插入、删除是在哪儿呢？那还是建议你使用LinkedList吧，因为一来LinkedList整体插入、删除的执行效率比较稳定，没有ArrayList这种越往后越快的情况；二来插入元素的时候，弄得不好ArrayList就要进行一次扩容，记住，ArrayList底层数组扩容是一个既消耗时间又消耗空间的操作，在我的文章Java代码优化中，第9点有详细的解读。</p>
<p>最后一点，一切都是纸上谈兵，在选择了List后，有条件的最好可以做一些性能测试，比如在你的代码上下文记录List操作的时间消耗。</p>
<h1 id="对LinkedList以及ArrayList的迭代"><a href="#对LinkedList以及ArrayList的迭代" class="headerlink" title="对LinkedList以及ArrayList的迭代"></a><strong>对LinkedList以及ArrayList的迭代</strong></h1><p>在我的Java代码优化一文中，第19点，专门提到过，ArrayList使用最普通的for循环遍历，LinkedList使用foreach循环比较快，看一下两个List的定义：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArrayList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">RandomAccess</span>, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">extends</span> <span class="title">AbstractSequentialList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class"><span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">Deque</span>&lt;<span class="title">E</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span></span><br></pre></td></tr></table></figure>

<p>注意到ArrayList是实现了RandomAccess接口而LinkedList则没有实现这个接口，关于RandomAccess这个接口的作用，看一下JDK API上的说法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">RamdomAcess</span></span></span><br></pre></td></tr></table></figure>
<p>为此，我写一段代码证明一下这一点，注意，虽然上面的例子用的Iterator，但是做foreach循环的时候，编译器默认会使用这个集合的Iterator，具体可参见foreach循环原理。测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMain</span></span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> SIZE = <span class="number">111111</span>;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">loopList</span><span class="params">(List&lt;Integer&gt; list)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; list.size(); i++)&#123;</span><br><span class="line">    list.get(i);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  System.out.println(list.getClass().getSimpleName() + <span class="string">"使用普通for循环遍历时间为"</span>  + (System.currentTimeMillis() - startTime) + <span class="string">"ms"</span>);</span><br><span class="line"></span><br><span class="line">  startTime = System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (Integer i : list)&#123;</span><br><span class="line">  &amp;nbsp;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  System.out.println(list.getClass().getSimpleName() + <span class="string">"使用foreach循环遍历时间为"</span> +</span><br><span class="line">  (System.currentTimeMillis() - startTime) + <span class="string">"ms"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  &amp;nbsp;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">  List&lt;Integer&gt; arrayList = <span class="keyword">new</span> ArrayList&lt;Integer&gt;(SIZE);</span><br><span class="line"></span><br><span class="line">  List&lt;Integer&gt; linkedList = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">  &amp;nbsp;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; SIZE; i++)&#123;</span><br><span class="line">    arrayList.add(i);</span><br><span class="line">    linkedList.add(i);</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  loopList(arrayList);</span><br><span class="line"></span><br><span class="line">  loopList(linkedList);</span><br><span class="line"></span><br><span class="line">  System.out.println();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我截取三次运行结果：</p>
<blockquote>
<p>ArrayList使用普通for循环遍历时间为6msArrayList使用foreach循环遍历时间为12msLinkedList使用普通for循环遍历时间为38482msLinkedList使用foreach循环遍历时间为11ms</p>
</blockquote>
<blockquote>
<p>ArrayList使用普通for循环遍历时间为5msArrayList使用foreach循环遍历时间为12msLinkedList使用普通for循环遍历时间为43287msLinkedList使用foreach循环遍历时间为9ms</p>
</blockquote>
<blockquote>
<p>ArrayList使用普通for循环遍历时间为4msArrayList使用foreach循环遍历时间为12msLinkedList使用普通for循环遍历时间为22370msLinkedList使用foreach循环遍历时间为5ms</p>
</blockquote>
<p>有了JDK API的解释，这个结果并不让人感到意外，最最想要提出的一点是：如果使用普通for循环遍历LinkedList，其遍历速度将慢得令人发指。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java锁</title>
    <url>/java/lock/</url>
    <content><![CDATA[<p>并发 (Concurrency)：一个处理器“同时”处理多个任务<br>并行 (Parallelism)：多个处理器 “同时”处理多个任务</p>
<a id="more"></a>
<h1 id="常见锁类型："><a href="#常见锁类型：" class="headerlink" title="常见锁类型："></a>常见锁类型：</h1><p>1.互斥锁（Mutex）</p>
<ul>
<li><p>同步块 synchronized block</p>
</li>
<li><p>对象锁 object.lock()</p>
</li>
<li><p>可重入锁</p>
</li>
</ul>
<p>可重入锁，也叫做递归锁，指的是同一线程外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。ReentrantLock 和synchronized 都是 可重入锁。</p>
<p>在lock函数内，应验证线程是否为已经获得锁的线程。当unlock（）第一次调用时，实际上不应释放锁。（采用计数进行统计）</p>
<p>可重入锁最大的特点是避免死锁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">get</span><span class="params">()</span></span>&#123;</span><br><span class="line">		System.out.println(Thread.currentThread().getId());</span><br><span class="line">		set();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">()</span></span>&#123;</span><br><span class="line">		System.out.println(Thread.currentThread().getId());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		get();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		Test ss=<span class="keyword">new</span> Test();</span><br><span class="line">		<span class="keyword">new</span> Thread(ss).start();</span><br><span class="line">		<span class="keyword">new</span> Thread(ss).start();</span><br><span class="line">		<span class="keyword">new</span> Thread(ss).start();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//返回结果：</span></span><br><span class="line"></span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="number">11</span></span><br><span class="line"><span class="number">11</span></span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">	ReentrantLock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		lock.lock();</span><br><span class="line">		System.out.println(Thread.currentThread().getId());</span><br><span class="line">		set();</span><br><span class="line">		lock.unlock();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		lock.lock();</span><br><span class="line">		System.out.println(Thread.currentThread().getId());</span><br><span class="line">		lock.unlock();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		get();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		Test ss = <span class="keyword">new</span> Test();</span><br><span class="line">		<span class="keyword">new</span> Thread(ss).start();</span><br><span class="line">		<span class="keyword">new</span> Thread(ss).start();</span><br><span class="line">		<span class="keyword">new</span> Thread(ss).start();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2.信号量（Semaphore）</p>
<ul>
<li>公平和非公平</li>
</ul>
<p>3.乐观锁（CAS）</p>
<ul>
<li>ABA问题：无锁堆栈实现</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java日志</title>
    <url>/java/log/</url>
    <content><![CDATA[<h1 id="一、Log4"><a href="#一、Log4" class="headerlink" title="一、Log4"></a>一、Log4</h1><p>Log4j是Apache的一个开源项目，它允许开发者以任意间隔输出日志信息.。主要分为两部分：一是appender，是输出日志的方式；二是logger，是具体日志输出器</p>
<a id="more"></a>

<h2 id="1-Appender"><a href="#1-Appender" class="headerlink" title="1.Appender"></a><strong>1.Appender</strong></h2><h3 id="其中，Log4j提供的appender有以下几种："><a href="#其中，Log4j提供的appender有以下几种：" class="headerlink" title="其中，Log4j提供的appender有以下几种："></a>其中，Log4j提供的appender有以下几种：</h3><p>　　</p>
<ul>
<li>org.apache.log4j.ConsoleAppender（输出到控制台）</li>
<li>org.apache.log4j.FileAppender（输出到文件）</li>
<li>org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）</li>
<li>org.apache.log4j.RollingFileAppender（文件到达指定大小的时候产生一个新的文件）</li>
<li>org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）</li>
</ul>
<p>例如：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">" ConsoleAppenderA"</span><span class="attr">class</span>=<span class="string">"org.apache.log4j.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"target"</span> <span class="attr">value</span>=<span class="string">"System.out"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">layout</span> <span class="attr">class</span>=<span class="string">"org.apache.log4j.PatternLayout"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"ConversionPattern"</span><span class="attr">value</span>=<span class="string">"%-5p %x %c&#123;2&#125; -%m%n"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">layout</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"BUSINESSERRORAPPENDER"</span> <span class="attr">class</span>=<span class="string">"com.alibaba.common.logging.spi.log4j.DailyRollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"file"</span> <span class="attr">value</span>=<span class="string">"$&#123;luna_loggingRoot&#125;/usr/common/business-error.log"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"append"</span> <span class="attr">value</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"encoding"</span> <span class="attr">value</span>=<span class="string">"GBK"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">layout</span> <span class="attr">class</span>=<span class="string">"org.apache.log4j.PatternLayout"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"ConversionPattern"</span> <span class="attr">value</span>=<span class="string">"%d %-5p %c&#123;2&#125; - %m%n"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">layout</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">     <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"cacheFile"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">File</span>&gt;</span>$&#123;LOG_HOME&#125;/redis-cache.log<span class="tag">&lt;/<span class="name">File</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LOG_HOME&#125;/redis-cache-%d&#123;yyyy-MM-dd&#125;.%i.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>100MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">Pattern</span>&gt;</span>%date&#123;ISO8601&#125; %-5level [%thread] %logger&#123;32&#125; - %message%n<span class="tag">&lt;/<span class="name">Pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="其中，Log4j提供的layout有以下几种："><a href="#其中，Log4j提供的layout有以下几种：" class="headerlink" title="其中，Log4j提供的layout有以下几种："></a><strong>其中，Log4j提供的layout有以下几种：</strong></h3><ul>
<li>org.apache.log4j.HTMLLayout（以HTML表格形式布局）</li>
<li>org.apache.log4j.PatternLayout（可以灵活地指定布局模式）</li>
<li>org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）</li>
<li>org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）</li>
</ul>
<p><strong>格式化日志信息Log4J采用类似C语言中的printf函数的打印格式格式化日志信息，打印参数如下：</strong></p>
<ul>
<li>%m 输出代码中指定的消息</li>
<li>%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL</li>
<li>%r 输出自应用启动到输出该log信息耗费的毫秒数</li>
<li>%c 输出所属的类目，通常就是所在类的全名</li>
<li>%t 输出产生该日志事件的线程名</li>
<li>%n 输出一个回车换行符，Windows平台为“rn”，Unix平台为“n”</li>
<li>%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyyy MMM ddHH:mm:ss,SSS}，输出类似：2002年10月18日 22：10：28，921</li>
<li>%l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。</li>
</ul>
<h2 id="2-Logger"><a href="#2-Logger" class="headerlink" title="2.Logger"></a><strong>2.Logger</strong></h2><p>Log4j中有一个根日志器</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">root</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">level</span> <span class="attr">value</span>=<span class="string">"$luna_loggingLevel"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"PROJECT"</span>/&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"EXCEPTION_LOG"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br></pre></td></tr></table></figure>


<p>默认时系统中其他所有非根logger都会继承根日志器，logger如果有level属性就会覆盖继承日志器（比如根日志器)的level属性。而appender会叠加，即本logger的配置的appender加上继承日志器上的appender。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.alibaba.service.VelocityService"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">level</span> <span class="attr">value</span>=<span class="string">"INFO"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"ConsoleAppenderA"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>根据继承原则得到这个logger的level是INFO，appender是ConsoleAppenderA、PROJECT、EXCEPTION_LOG。<br>也可以使logger不继承其他logger，使用additivity=”false”</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.alibaba.china.pylon.enhancedmit.domain.Handler"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">level</span> <span class="attr">value</span>=<span class="string">"info"</span>/&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"enhancedMITAppender"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>其中，level 是日志记录的优先级，分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者自定义的级别。</p>
<p>Log4j常用的四个级别，优先级从高到低分别是ERROR、WARN、INFO、DEBUG。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。<strong>比如在这里定义了INFO级别，只有等于及高于这个级别的才会处理，而DEBUG级别的日志信息将不会被打印出来。</strong></p>
<p>ALL：打印所有的日志，OFF：关闭所有的日志输出。<br>appender-ref属性即使用logger引用之前配置过的appender。</p>
<h2 id="在程序中怎么创建logger，并调用呢？"><a href="#在程序中怎么创建logger，并调用呢？" class="headerlink" title="在程序中怎么创建logger，并调用呢？"></a><strong>在程序中怎么创建logger，并调用呢？</strong></h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Logger logger =Logger.getLogger(VelocityService<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;　</span><br><span class="line"><span class="comment">//或</span></span><br><span class="line">Logger logger =LogFactory.getLog(VelocityService<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">logger.debug(<span class="string">"Justtesting a log message with priority set to DEBUG"</span>);</span><br><span class="line">logger.info(<span class="string">"Just testinga log message with priority set to INFO"</span>);</span><br><span class="line">logger.warn(<span class="string">"Just testinga log message with priority set to WARN"</span>);</span><br><span class="line">logger.error(<span class="string">"Justtesting a log message with priority set to ERROR"</span>);</span><br><span class="line">logger.fatal(<span class="string">"Justtesting a log message with priority set to FATAL"</span>);</span><br></pre></td></tr></table></figure>

<p>另外，logger对name的前缀默认也有继承性，例：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.alibaba.service"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">level</span> <span class="attr">value</span>=<span class="string">"INFO"</span>/&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"ConsoleAppenderA"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.alibaba.service.VelocityService"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">level</span> <span class="attr">value</span>=<span class="string">"INFO"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"FileAppenderA"</span>/&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>根据继承原则名为com.alibaba.service.VelocityService的logger的appender是FileAppenderA和ConsoleAppenderA，level的为INFO。</p>
<h1 id="二、SLF4J"><a href="#二、SLF4J" class="headerlink" title="二、SLF4J"></a>二、SLF4J</h1><p>Log4J （Simple Logging Facade for Java）使用普遍，但是框架较重，引入了很多无用的包，相比SLF4J就灵活很多。SLF4J很好地解耦了API和实现，例如，你可以强制使用SLF4J的API，而保持生产环境中用了几年的旧的Log4J.properties文件。</p>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Logger.debug(<span class="string">"Hello "</span> + name);</span><br></pre></td></tr></table></figure>

<p>由于字符串拼接的问题（注：上述语句会先拼接字符串，再根据当前级别是否低于debug决定是否输出本条日志，即使不输出日志，字符串拼接操作也会执行），许多公司强制使用下面的语句，这样只有当前处于DEBUG级别时才会执行字符串拼接：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">    LOGGER.debug(“Hello ” + name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>它避免了字符串拼接问题，但有点太繁琐了是不是？相对地，SLF4J提供下面这样简单的语法:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">LOGGER.debug(<span class="string">"Hello &#123;&#125;"</span>, name);</span><br></pre></td></tr></table></figure>

<p>它的形式类似第一条示例，而又没有字符串拼接问题，也不像第二条那样繁琐。</p>
<p><strong>pom依赖：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jcl-over-slf4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-over-slf4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>ch.qos.logback<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>logback-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>ch.qos.logback<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>logback-classic<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a><strong>参考资料：</strong></h1><p><a href="https://www.slf4j.org/" target="_blank" rel="noopener">https://www.slf4j.org/</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java位运算符 &amp;、|、^、~、&lt;&lt;、&gt;&gt;、&gt;&gt;&gt;</title>
    <url>/java/java%E4%BD%8D%E8%BF%90%E7%AE%97/</url>
    <content><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1)前言"></a>1)前言</h2><p>关于位运算符 与(&amp;)、或(|)、异或(^)、取反(~)、左移(&lt;&lt;)、右移(&gt;&gt;)、无符号右移(&gt;&gt;&gt;)</p>
<p>位运算其实就是二进制的运算，加减乘除适用于十进制，而位运算就是二进制的运算,但是由于我们的运算都是基于十进制来说的，所以会有点绕，略微有点难懂</p>
<h2 id="2-关于二进制"><a href="#2-关于二进制" class="headerlink" title="2)关于二进制"></a>2)关于二进制</h2><p>我们在编码过程中应该会了解很多不同的进制，除去常用的十进制，还有二进制、八进制、十六进制，因为我们的位运算符主要用到二进制，就只讲讲二进制</p>
<p>几进制就是一个位上最多能表示几个数，如十进制的个位有0~9十个数字，八进制有0~7八个数字，二进制我们自然想到就是0~1两个数字</p>
<p>我们编码中最小的单位应该是字节，而一个字节有8位，每一位就是一个0或1，所以一个字节用二进制表示就是</p>
<p><img data-src="https://img2018.cnblogs.com/blog/1470032/201810/1470032-20181023161659387-1137743233.png" alt=""></p>
<p>这样的</p>
<h2 id="3-与运算符-amp"><a href="#3-与运算符-amp" class="headerlink" title="3) 与运算符(&amp;)"></a>3) 与运算符(&amp;)</h2><p>  如果 4&amp;7  那么这个应该怎么运算呢？</p>
<p>  首先我们需要把两个十进制的数转换成二进制 </p>
<p>   4 ： 0000 0100</p>
<p>   7 ： 0000 0111</p>
<p><img data-src="https://img2018.cnblogs.com/blog/1470032/201810/1470032-20181023204022745-1107563193.png" alt=""></p>
<p>在这里要提到一点，1表示true，0表示false</p>
<p>而与运算的时候相同位之间其实就是两个Boolean的运算 </p>
<ul>
<li><p>全true(1),即为true(1)</p>
</li>
<li><p>全false(0),即为false(0)</p>
</li>
<li><p>一false(0)一true(1),还是false(0) </p>
</li>
</ul>
<h2 id="4-或运算符"><a href="#4-或运算符" class="headerlink" title="4)或运算符(|)"></a>4)或运算符(|)</h2><p>  以  5|9  为例</p>
<p>  5 ： 0000 0101 </p>
<p>  9 ： 0000 1001</p>
<p><img data-src="https://img2018.cnblogs.com/blog/1470032/201810/1470032-20181023204023575-1172288145.png" alt=""></p>
<p>在做与运算的时候</p>
<p><strong>遇true(1)就是true(1),</strong></p>
<p><strong>无true(1)就是false(0)</strong></p>
<h2 id="5-异或运算符"><a href="#5-异或运算符" class="headerlink" title="5) 异或运算符(^)"></a>5) 异或运算符(^)</h2><p><strong>以 7^15 为例</strong></p>
<p><strong>7：  0000 0111</strong></p>
<p><strong>15： 0000 1111</strong></p>
<p><img data-src="https://img2018.cnblogs.com/blog/1470032/201810/1470032-20181023204024149-967390106.png" alt=""></p>
<p> 在异或的时候</p>
<ul>
<li><p>只要相同都是false(0)</p>
</li>
<li><p>只有不同才是true(1)</p>
</li>
</ul>
<h2 id="6-取反运算符"><a href="#6-取反运算符" class="headerlink" title="6) 取反运算符(~)"></a>6) 取反运算符(~)</h2><p>例：  ~15</p>
<p>同样的先变成二进制：15：0000 1111</p>
<p><img data-src="https://img2018.cnblogs.com/blog/1470032/201810/1470032-20181023204024870-227422826.png" alt=""></p>
<p>这个其实挺简单的，就是把1变0，0变1</p>
<p>注意：二进制中，最高位是符号位  1表示负数，0表示正数</p>
<h2 id="7-左移运算-lt-lt"><a href="#7-左移运算-lt-lt" class="headerlink" title="7) 左移运算(&lt;&lt;)"></a>7) 左移运算(&lt;&lt;)</h2><p>左移就是把所有位向左移动几位</p>
<p>如：  12 &lt;&lt; 2  意思就是12向左移动两位</p>
<p>12的二进制是： 0000 1100</p>
<p><img data-src="https://img2018.cnblogs.com/blog/1470032/201810/1470032-20181023204025326-1518482974.png" alt=""></p>
<p>通过这个图我们可以看出来，所有的位全都向左移动两位，然后把右边空的两个位用0补上，最左边多出的两个位去掉，最后得到的结果就是00110000 结果就是48</p>
<p>我们用同样的办法算 <strong>12&lt;&lt;3 结果是 96</strong> , <strong>8&lt;&lt;4 结果是 128</strong></p>
<p><strong>由此我们得出一个快速的算法  M &lt;&lt; n  其实可以这么算  M &lt;&lt; n = M * 2<sup>n </sup></strong></p>
<h2 id="8-右移运算符-gt-gt"><a href="#8-右移运算符-gt-gt" class="headerlink" title="8) 右移运算符(&gt;&gt;)"></a><strong>8) 右移运算符(&gt;&gt;)</strong></h2><p><strong>这个跟左移运算大体是一样的</strong></p>
<p><strong>例： 12 &gt;&gt; 2</strong></p>
<p><img data-src="https://img2018.cnblogs.com/blog/1470032/201810/1470032-20181023204025862-1215072643.png" alt=""></p>
<p><strong>我们可以看出来右移和左移其实是一样的，但是还是有点不同的，不同点在于对于正数和负数补位的时候补的不一样，负数补1，正数补0</strong></p>
<p><strong>如我们再做一个 -8 的  -8&gt;&gt;2</strong></p>
<p><img data-src="https://img2018.cnblogs.com/blog/1470032/201810/1470032-20181023204026563-746326181.png" alt=""></p>
<p><strong>这里总结一下，关于负数或者正数来说，移位的时候是一样的，但是在补位的时候，如果最高位是0就补0，如果最高位是1就补1</strong></p>
<p>由此我们得出一个快速的算法  M &gt;&gt; n  其实可以这么算  M &gt;&gt; n = M / 2^n  </p>
<h2 id="9无符号右移-gt-gt-gt"><a href="#9无符号右移-gt-gt-gt" class="headerlink" title="9无符号右移(&gt;&gt;&gt;)"></a>9无符号右移(&gt;&gt;&gt;)</h2><p>无符号右移(&gt;&gt;&gt;)只对32位和64位有意义</p>
<p>在移动位的时候与右移运算符的移动方式一样的，区别只在于补位的时候不管是0还是1，都补0</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis</title>
    <url>/java/mybatis/</url>
    <content><![CDATA[<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><ul>
<li><a href="http://mp.weixin.qq.com/s/BLY1HZUtmYA_w1_MZfcYRQ" target="_blank" rel="noopener">MyBatis 动态 SQL 底层原理分析</a></li>
<li><a href="https://mp.weixin.qq.com/s/O8DfUjIw18WehILOWsR8ug" target="_blank" rel="noopener">基于mybatis读写分离插件</a></li>
</ul>
<a id="more"></a>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java NIO</title>
    <url>/java/nio/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>NIO 是java 1.4引入的新特性。是对原来的standard IO的扩展。</p>
<p>Standard IO是对字节流的读写，在进行IO之前，首先创建一个流对象，流对象进行读写操作都是按字节<br>，一个字节一个字节的来读或写。而NIO把IO抽象成块，类似磁盘的读写，每次IO操作的单位都是一个块，块被读入内存之后就是一个byte[]，NIO一次可以读或写多个字节。</p>
<a id="more"></a>

<h1 id="NIO的几大组件："><a href="#NIO的几大组件：" class="headerlink" title="NIO的几大组件："></a>NIO的几大组件：</h1><h2 id="1-Selector"><a href="#1-Selector" class="headerlink" title="1.Selector"></a>1.Selector</h2><p>多路复用选择器，基于“事件驱动”，其核心就是通过Selector来轮询注册在其上的Channel，当发现某个或多个Channel处于就绪状态后，从阻塞状态返回就绪的Channel的SelectionKey集合，进行I/O操作。</p>
<ul>
<li>创建多路复用器并启动线程</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Selector selector=Selector.open();</span><br><span class="line"><span class="keyword">new</span> Thread(<span class="keyword">new</span> ReactorTask()).start();</span><br></pre></td></tr></table></figure>

<ul>
<li>创建Channel<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 打开ServerSocketChannel，用于监听客户端的连接</span></span><br><span class="line">ServerSocketChannel ssc=ServerSocketChannel.open();</span><br><span class="line"><span class="comment">//设置连接为非阻塞模式</span></span><br><span class="line">ssc.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line"><span class="comment">//绑定监听端口</span></span><br><span class="line">ServerSocket ss=ssc.socket();</span><br><span class="line">ss.bind(<span class="keyword">new</span> InetSocketAddress(InetAdderss.getByName(<span class="string">"ip"</span>),port));</span><br><span class="line"><span class="comment">//将ServerSocketChannel注册到多路复用器Selector上，监听ACCEPT事件</span></span><br><span class="line">ssc.register(selector,SelectionKey.OP_ACCEPT);</span><br></pre></td></tr></table></figure></li>
<li>等待客户端的连接<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">// selector.select是阻塞的，一直等到有客户端连接过来才返回，然后会检查发生的是哪一种事件，然后根据不同的事件做不同的操作</span></span><br><span class="line">    selector.select();</span><br><span class="line">    Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();</span><br><span class="line">    Iterator&lt;SelectionKey&gt; it = selectionKeys.iterator();</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">        SelectionKey key = it.next();</span><br><span class="line">        <span class="keyword">if</span> (key.isAcceptable()) &#123;</span><br><span class="line">            <span class="comment">// 处理新接入的请求消息</span></span><br><span class="line">            ServerSocketChannel ssc = (ServerSocketChannel) key.channel();</span><br><span class="line">            SocketChannel sc = ssc.accept();</span><br><span class="line">            sc.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">// 注册读事件</span></span><br><span class="line">            sc.register(selector, SelectionKey.OP_READ);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (key.isReadable()) &#123;</span><br><span class="line">            <span class="comment">// 处理读请求</span></span><br><span class="line">            SocketChannel sc = (SocketChannel) key.channel();</span><br><span class="line">            ByteBuffer readBuffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">            <span class="keyword">int</span> readBytes = sc.read(readBuffer);</span><br><span class="line">            <span class="keyword">if</span> (readBytes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                readBuffer.flip();</span><br><span class="line">                <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[readBuffer.remaining()];</span><br><span class="line">                readBuffer.get(bytes);</span><br><span class="line">                System.out.println(<span class="keyword">new</span> String(bytes, <span class="string">"UTF-8"</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="2-Channel"><a href="#2-Channel" class="headerlink" title="2.Channel"></a>2.Channel</h2><p>Channel是NIO对IO抽象的一个新概念，NIO在进行IO时需要创建一个Channel对象，是双向的，不象Standard IO分为输入流和输出流</p>
<h2 id="3-Buffer"><a href="#3-Buffer" class="headerlink" title="3.Buffer"></a>3.Buffer</h2><p>Buffer和Channel都是一起使用的，每次都是从一个Channel中读出一个Buffer或者把一个Buffer写入到一个Channel中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 处理读请求</span></span><br><span class="line">SocketChannel sc = (SocketChannel) key.channel();</span><br><span class="line">ByteBuffer readBuffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line"><span class="keyword">int</span> readBytes = sc.read(readBuffer);</span><br><span class="line"><span class="keyword">if</span> (readBytes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    readBuffer.flip();</span><br><span class="line">    <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[readBuffer.remaining()];</span><br><span class="line">    readBuffer.get(bytes);</span><br><span class="line">    System.out.println(<span class="keyword">new</span> String(bytes, <span class="string">"UTF-8"</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Buffer有3个重要的属性</p>
<div class="note primary">
            <ul><li>position 正整数，指向Buffer中下一个要读取或写入的字节位置</li><li>limit 正整数，指向Buffer中的某个位置，在IO时只读写下标小于limit的字节内容</li><li>capacity  正整数，Buffer所能容纳的最大字节数</li></ul>
          </div>

<p>0 &lt;= position &lt;= limit &lt;= capacity</p>
<p>初始状态：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-nio/java-nio-1.png/w600">

<p>从Channel中读入5个字到ByteBuffer</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-nio/java-nio-2.png/w600">

<p>flip()，准备写入或输出</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">flip</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    limit = position;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-nio/java-nio-3.png/w600">

<p>输出内容后，position就移动到跟limit相同的位置上</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-nio/java-nio-4.png/w600">

<p>ByteBuffer如果要重复利用，需要清理，position和limit回到初始状态时的位置，然后可以接着用这个Buffer来读写数据，不需要再New 新的Buffer</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    limit = capacity;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-nio/java-nio-5.png/w600">


<h1 id="比较好的基于NIO的开源框架（Netty）"><a href="#比较好的基于NIO的开源框架（Netty）" class="headerlink" title="比较好的基于NIO的开源框架（Netty）"></a>比较好的基于NIO的开源框架（Netty）</h1><p><strong>优点：</strong></p>
<ul>
<li>api简单，开发门槛低</li>
<li>功能强大，内置了多种编码、解码功能</li>
<li>与其它业界主流的NIO框架对比，netty的综合性能最优</li>
<li>社区活跃，使用广泛，经历过很多商业应用项目的考验</li>
<li>定制能力强，可以对框架进行灵活的扩展</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.jboss.netty<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>netty<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.5.Final<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h2><h3 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h3><p>接收客户端请求并将内容打印出来，同时发送一个消息收到回执。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NettyServer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> HEADER_LENGTH = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">bind</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        ServerBootstrap b = <span class="keyword">new</span> ServerBootstrap(<span class="keyword">new</span> NioServerSocketChannelFactory(Executors.newCachedThreadPool(),</span><br><span class="line">                                                                                           Executors.newCachedThreadPool()));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 构造对应的pipeline</span></span><br><span class="line">        b.setPipelineFactory(<span class="keyword">new</span> ChannelPipelineFactory() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ChannelPipeline <span class="title">getPipeline</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                ChannelPipeline pipelines = Channels.pipeline();</span><br><span class="line">                pipelines.addLast(MessageHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>(), <span class="title">new</span> <span class="title">MessageHandler</span>())</span>;</span><br><span class="line">                <span class="keyword">return</span> pipelines;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 监听端口号</span></span><br><span class="line">        b.bind(<span class="keyword">new</span> InetSocketAddress(port));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 处理消息</span></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MessageHandler</span> <span class="keyword">extends</span> <span class="title">SimpleChannelHandler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">messageReceived</span><span class="params">(ChannelHandlerContext ctx, MessageEvent e)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="comment">// 接收客户端请求</span></span><br><span class="line">            ChannelBuffer buffer = (ChannelBuffer) e.getMessage();</span><br><span class="line">            String message = <span class="keyword">new</span> String(buffer.readBytes(buffer.readableBytes()).array(), <span class="string">"UTF-8"</span>);</span><br><span class="line">            System.out.println(<span class="string">"&lt;服务端&gt;收到内容="</span> + message);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 给客户端发送回执</span></span><br><span class="line">            <span class="keyword">byte</span>[] body = <span class="string">"服务端已收到"</span>.getBytes();</span><br><span class="line">            <span class="keyword">byte</span>[] header = ByteBuffer.allocate(HEADER_LENGTH).order(ByteOrder.BIG_ENDIAN).putInt(body.length).array();</span><br><span class="line">            Channels.write(ctx.getChannel(), ChannelBuffers.wrappedBuffer(header, body));</span><br><span class="line">            System.out.println(<span class="string">"&lt;服务端&gt;发送回执,time="</span> + System.currentTimeMillis());</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">new</span> NettyServer().bind(<span class="number">1088</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="客户端。"><a href="#客户端。" class="headerlink" title="客户端。"></a>客户端。</h3><p>向服务端发送一个请求，然后打印服务端响应的内容。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NettyClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ByteBuffer readHeader  = ByteBuffer.allocate(<span class="number">4</span>).order(ByteOrder.BIG_ENDIAN);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ByteBuffer writeHeader = ByteBuffer.allocate(<span class="number">4</span>).order(ByteOrder.BIG_ENDIAN);</span><br><span class="line">    <span class="keyword">private</span> SocketChannel    channel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessage</span><span class="params">(<span class="keyword">byte</span>[] body)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 创建客户端通道</span></span><br><span class="line">        channel = SocketChannel.open();</span><br><span class="line">        channel.socket().setSoTimeout(<span class="number">60000</span>);</span><br><span class="line">        channel.connect(<span class="keyword">new</span> InetSocketAddress(AddressUtils.getHostIp(), <span class="number">1088</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 客户端发请求</span></span><br><span class="line">        writeWithHeader(channel, body);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 接收服务端响应的信息</span></span><br><span class="line">        readHeader.clear();</span><br><span class="line">        read(channel, readHeader);</span><br><span class="line">        <span class="keyword">int</span> bodyLen = readHeader.getInt(<span class="number">0</span>);</span><br><span class="line">        ByteBuffer bodyBuf = ByteBuffer.allocate(bodyLen).order(ByteOrder.BIG_ENDIAN);</span><br><span class="line">        read(channel, bodyBuf);</span><br><span class="line">        System.out.println(<span class="string">"&lt;客户端&gt;收到响应内容："</span> + <span class="keyword">new</span> String(bodyBuf.array(), <span class="string">"UTF-8"</span>) + <span class="string">",长度:"</span> + bodyLen);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeWithHeader</span><span class="params">(SocketChannel channel, <span class="keyword">byte</span>[] body)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        writeHeader.clear();</span><br><span class="line">        writeHeader.putInt(body.length);</span><br><span class="line">        writeHeader.flip();</span><br><span class="line">        <span class="comment">// channel.write(writeHeader);</span></span><br><span class="line">        channel.write(ByteBuffer.wrap(body));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">(SocketChannel channel, ByteBuffer buffer)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (buffer.hasRemaining()) &#123;</span><br><span class="line">            <span class="keyword">int</span> r = channel.read(buffer);</span><br><span class="line">            <span class="keyword">if</span> (r == -<span class="number">1</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"end of stream when reading header"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String body = <span class="string">"客户发的测试请求！"</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">new</span> NettyClient().sendMessage(body.getBytes());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>java random</title>
    <url>/java/random/</url>
    <content><![CDATA[<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.nio.charset.Charset;</span><br><span class="line"><span class="keyword">import</span> java.security.NoSuchAlgorithmException;</span><br><span class="line"><span class="keyword">import</span> java.security.SecureRandom;</span><br><span class="line">&lt;!-- more --&gt;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicLong;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantLock;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.google.common.hash.HashFunction;</span><br><span class="line"><span class="keyword">import</span> com.google.common.hash.Hashing;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 用于生成随机token</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> onlyone</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RandomService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ReentrantLock lock           = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">    <span class="keyword">private</span> AtomicLong    resetCounter   = <span class="keyword">new</span> AtomicLong(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">private</span> HashFunction  sha1           = Hashing.sha1();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>           resetThreshold = <span class="number">10000</span>;</span><br><span class="line">    <span class="keyword">private</span> Charset       encoding       = Charset.forName(<span class="string">"UTF-8"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> SecureRandom  random;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RandomService</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.resetSecureRandom();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">resetSecureRandom</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.random = SecureRandom.getInstance(<span class="string">"NativePRNGNonBlocking"</span>);</span><br><span class="line">            <span class="comment">// this.random = SecureRandom.getInstanceStrong(); // for windows</span></span><br><span class="line">            <span class="keyword">this</span>.random.generateSeed(<span class="number">32</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getToken</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.resetCounter.incrementAndGet() &gt; <span class="keyword">this</span>.resetThreshold) &#123;</span><br><span class="line">            <span class="keyword">this</span>.resetSecureRandom();</span><br><span class="line">            <span class="keyword">this</span>.resetCounter.set(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">32</span>];</span><br><span class="line">        <span class="keyword">this</span>.random.nextBytes(bytes);</span><br><span class="line">        <span class="keyword">byte</span>[] seedBytes = UUID.randomUUID().toString().getBytes(<span class="keyword">this</span>.encoding);</span><br><span class="line">        <span class="keyword">byte</span>[] seeds = <span class="keyword">new</span> <span class="keyword">byte</span>[seedBytes.length + bytes.length];</span><br><span class="line">        System.arraycopy(bytes, <span class="number">0</span>, seeds, <span class="number">0</span>, bytes.length);</span><br><span class="line">        System.arraycopy(seedBytes, <span class="number">0</span>, seeds, bytes.length - <span class="number">1</span>, seedBytes.length);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.sha1.hashBytes(bytes).toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        RandomService randomService = <span class="keyword">new</span> RandomService();</span><br><span class="line">        List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;String&gt;(<span class="number">200000</span>);</span><br><span class="line">        List&lt;String&gt; repetition = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</span><br><span class="line">            String t = randomService.getToken();</span><br><span class="line">            <span class="keyword">if</span> (list.contains(t)) &#123;</span><br><span class="line">                repetition.add(t);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                list.add(t);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(t);</span><br><span class="line">            System.out.println(<span class="string">"i="</span> + i + <span class="string">", 重复列表"</span> + repetition + <span class="string">",list size="</span> + list.size());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>快速排查线上问题</title>
    <url>/java/online-question/</url>
    <content><![CDATA[<h1 id="工作案例"><a href="#工作案例" class="headerlink" title="工作案例"></a>工作案例</h1><ul>
<li><a href="../highload-troubleshoot">java服务器load飚高排查思路</a></li>
</ul>
<a id="more"></a>
<ul>
<li><p><a href="http://blog.csdn.net/itomge/article/details/48803575" target="_blank" rel="noopener">APNS开源包的内存泄露问题</a></p>
</li>
<li><p><a href="../java-param">jvm堆参数调整</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/fU4i-jDVHgdJfRtWtXaxrQ" target="_blank" rel="noopener">线上服务CPU100%问题快速定位</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/tVvqVVigmvzLfPjnt2oK0g" target="_blank" rel="noopener">线上服务内存OOM问题定位三板斧</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/34GVlaYDOdY1OQ9eZs-iXg" target="_blank" rel="noopener">教你如何成为Java的OOM Killer</a></p>
</li>
<li><p><a href="https://github.com/cncounter/outofmemoryerror" target="_blank" rel="noopener">java.lang.OutOfMemoryError 8种典型案例</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/RnHfphZp3wmS2b78RZFugw" target="_blank" rel="noopener">一次内存溢出的排查经历</a></p>
</li>
</ul>
<h1 id="帮助手册"><a href="#帮助手册" class="headerlink" title="帮助手册"></a>帮助手册</h1><ul>
<li><p><a href="http://blog.csdn.net/itomge/article/details/9904555" target="_blank" rel="noopener">JDK内置命令</a></p>
</li>
<li><p><a href="../common-jdk-cmd">JDK内置工具补充</a></p>
</li>
<li><p><a href="http://blog.csdn.net/itomge/article/details/48719527" target="_blank" rel="noopener">MAT使用教程</a></p>
</li>
<li><p><a href="https://github.com/CSUG/HouseMD" target="_blank" rel="noopener">java系统诊断命令行工具–HouseMD</a></p>
</li>
<li><p><a href="../anatomy">java系统诊断命令行工具–anatomy</a></p>
</li>
<li><p><a href="https://github.com/alibaba/arthas" target="_blank" rel="noopener">【推荐】Alibaba Java诊断利器 — Arthas </a>    <a href="https://mp.weixin.qq.com/s/VcnJDuYgsqrGNrOsrpUmpw" target="_blank" rel="noopener">Link2</a></p>
</li>
<li><p><a href="https://github.com/oldratlee/useful-scripts" target="_blank" rel="noopener">一些常用的shell脚本</a></p>
</li>
<li><p><a href="https://github.com/vipshop/vjtools" target="_blank" rel="noopener">唯品会的排查线上问题的一些封装工具</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/d_Tl6eiTmpde6eGT5pTaCg" target="_blank" rel="noopener">史上最全的高可用服务系统线上问题排查工具单（一）</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/6EBgu__zwkYbGDjnVsbDlQ" target="_blank" rel="noopener">史上最全的高可用服务系统线上问题排查工具单（二）</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java知识汇总</title>
    <url>/java/summary/</url>
    <content><![CDATA[<h1 id="一、基础"><a href="#一、基础" class="headerlink" title="一、基础"></a>一、基础</h1><ul>
<li>基本语法<ul>
<li>基本数据类型；运算符；表达式；选择与循环语句；</li>
<li>类与对象（普通类、抽象类、接口、枚举、Annotation、内部类）；</li>
<li>继承与实现；重载与覆盖；异常；package与jar包；</li>
<li>序列化与反序列化；正则表达式；</li>
</ul>
</li>
</ul>
<a id="more"></a>
<ul>
<li>数组 —— 一维数组；二维数组。。。</li>
<li>集合 —— Collection接口；Set相关；List相关；Map相关</li>
<li>线程 —— Thread；Runnable；Callable；线程状态；优先级；</li>
<li>IO<br>File类；字节流（InputStream、OutputStream）；字符流（Reader、Writer）；<br>转换流（OutputStreamWriter、InputStreamReader）；压缩流；</li>
<li>网络 —— TCP编程；UDP编程</li>
<li>泛型</li>
<li>反射 —— 提供api方法取得类的结构；调用类的方法；动态代理</li>
</ul>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><ul>
<li>List<ul>
<li><a href="../arraylist">ArrayList</a> </li>
<li><a href="../linkedlist">LinkedList</a> </li>
<li><a href="../CopyOnWriteArrayList">CopyOnWriteArrayList</a></li>
</ul>
</li>
<li>Map<ul>
<li><a href="../hashmap">HashMap</a></li>
<li><a href="../LinkedHashMap">LinkedHashMap</a></li>
<li><a href="../ConcurrentHashMap1">ConcurrentHashMap(上)</a></li>
<li><a href="../ConcurrentHashMap2">ConcurrentHashMap(下)</a></li>
<li>ConcurrentHashMap，Java 7为实现并行访问，引入了Segment这一结构，实现了分段锁，理论上最大并发度与Segment个数相等。Java 8为进一步提高并发性，摒弃了分段锁的方案，而是直接使用一个大的数组。同时为了提高哈希碰撞下的寻址性能，Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(long(N))），<a href="http://www.jasongj.com/java/concurrenthashmap/" target="_blank" rel="noopener">原文链接</a></li>
</ul>
</li>
</ul>
<h1 id="二、进阶"><a href="#二、进阶" class="headerlink" title="二、进阶"></a>二、进阶</h1><ul>
<li><a href="../modifier">Java关键字</a></li>
<li><a href="../regex">正则表达式</a></li>
<li><a href="../lock">常见锁</a></li>
<li><a href="../common-class-lib">常用Java类库</a></li>
<li><a href="http://blog.csdn.net/itomge/article/details/9098207" target="_blank" rel="noopener">java的System.getProperty()方法使用</a></li>
<li><a href="../lambda">Java8函数编程（lambda表达式）</a></li>
<li><a href="../thread-state">Java的线程状态</a></li>
<li><a href="../threadlocal">ThreadLocal原理机制</a></li>
<li><a href="../hashmap-expand">HashMap的扩容机制</a></li>
<li><a href="../exception">Exception</a></li>
<li><a href="../io">IO类型</a></li>
<li><a href="../some-sink">各种坑</a></li>
</ul>
<h2 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h2><ul>
<li><a href="../nio">NIO</a></li>
<li><a href="https://mp.weixin.qq.com/s/Nk7gcwsgBhgMWTRkgAFpRA" target="_blank" rel="noopener">深度解读 Tomcat 中的 NIO 模型</a></li>
<li><a href="https://mp.weixin.qq.com/s/RmONdyXuJZa8WyJCu2j7WA" target="_blank" rel="noopener">epoll 浅析以及 nio 中的 Selector</a></li>
<li><a href="https://segmentfault.com/a/1190000003063859" target="_blank" rel="noopener">Linux IO模式及 select、poll、epoll详解</a></li>
</ul>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/D3TIYMaCSGtY5Dv38vMHpA" target="_blank" rel="noopener">Java 多线程知识汇总(1)</a></li>
<li><a href="https://mp.weixin.qq.com/s/e9avHfZtfiQ4v3fhVHIcAA" target="_blank" rel="noopener">Java 多线程知识汇总(2)</a></li>
<li><a href="https://mp.weixin.qq.com/s/s6UvYe1CP8zigR7E6mK9Og" target="_blank" rel="noopener">Java 多线程知识汇总(3)</a></li>
</ul>
<h2 id="java并发包"><a href="#java并发包" class="headerlink" title="java并发包"></a>java并发包</h2><ul>
<li><a href="../concurrent-class">jdk并发包里常用的类</a></li>
<li><a href="https://mp.weixin.qq.com/s/K8y6wMNDLwsmU7EFRx7Dsw" target="_blank" rel="noopener">Java 并发源码合集</a></li>
<li><a href="https://mp.weixin.qq.com/s/Y9IcHAwa4VkJN02_U1fDWg" target="_blank" rel="noopener">CyclicBarrier</a></li>
<li><a href="https://mp.weixin.qq.com/s/UA8hoHiJj5vzb2-c08lpDA" target="_blank" rel="noopener">CountDownLatch</a></li>
<li><a href="https://mp.weixin.qq.com/s/i_-seey2Du-99SyLSC9OiQ" target="_blank" rel="noopener">Semaphore</a></li>
</ul>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/FRF-c2t_Un1Krw29yuxyaw" target="_blank" rel="noopener">JAVA集合框架中的常用集合及其特点、适用场景、实现原理简介</a></li>
</ul>
<h2 id="netty"><a href="#netty" class="headerlink" title="netty"></a>netty</h2><ul>
<li><a href="https://www.dozer.cc/2014/12/netty-long-connection.html" target="_blank" rel="noopener">Netty 长连接服务</a></li>
</ul>
<h1 id="三、JVM虚拟机"><a href="#三、JVM虚拟机" class="headerlink" title="三、JVM虚拟机"></a>三、JVM虚拟机</h1><ul>
<li><a href="../jvm内存模型">内存模型</a></li>
<li><a href="../class-loader">类加载</a></li>
<li><a href="../gc">GC垃圾回收</a></li>
<li><a href="../class-reference">强引用、软引用、弱引用、幻象引用</a><h2 id="JVM-调优"><a href="#JVM-调优" class="headerlink" title="JVM 调优"></a>JVM 调优</h2></li>
<li><a href="../jvm-param">jvm参数</a></li>
<li><a href="https://mp.weixin.qq.com/s/QNr8somjodyvU9dRAQG2oA" target="_blank" rel="noopener">jvm自带命令</a></li>
<li><a href="https://mp.weixin.qq.com/s/ydkEkh_Uc1paftJLKIsm0w" target="_blank" rel="noopener">如何优化Java GC</a></li>
<li><a href="https://mp.weixin.qq.com/s/bOarreWhQJmS6VTZfFcsZw" target="_blank" rel="noopener">大型跨境电商 JVM 调优经历</a></li>
<li><a href="https://mp.weixin.qq.com/s/4c9K5eYMFGVV2WyKaYXVBA" target="_blank" rel="noopener">Jvm知识汇总</a></li>
<li><a href="https://mp.weixin.qq.com/s/jt_BCAo8krxPAhLhhLdIrg" target="_blank" rel="noopener">海量连接服务端jvm参数调优杂记</a><h2 id="JVM-调优工具"><a href="#JVM-调优工具" class="headerlink" title="JVM 调优工具"></a>JVM 调优工具</h2></li>
<li><a href="http://xxfox.perfma.com/" target="_blank" rel="noopener">XXFox</a></li>
</ul>
<h1 id="四、前沿"><a href="#四、前沿" class="headerlink" title="四、前沿"></a>四、前沿</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/wcF14v11QaS21UFczqGbVg" target="_blank" rel="noopener">Java 的版本历史与特性</a></li>
<li><a href="http://www.iteye.com/news/27980" target="_blank" rel="noopener">JavaEE 7 正式发布</a></li>
<li><a href="https://mp.weixin.qq.com/s/w_Uqi5PBkWCqh7qHq6XaKw" target="_blank" rel="noopener">Java 8-从持久代到metaspace</a></li>
<li><a href="https://mp.weixin.qq.com/s/CWNIRk9xGu2XSbrWELTKNg" target="_blank" rel="noopener">Java 8的新特性—终极版</a></li>
<li><a href="https://mp.weixin.qq.com/s/YalBtZ_dZayMec8aprk6Xw" target="_blank" rel="noopener">Java 9 中的新特性</a></li>
<li><a href="https://mp.weixin.qq.com/s/UX_tP95fTR99B53DYgHNJQ" target="_blank" rel="noopener">Java 10正式发布，带来了这些新特性</a></li>
</ul>
<h1 id="五、其它"><a href="#五、其它" class="headerlink" title="五、其它"></a>五、其它</h1><ul>
<li><a href="http://hongjiang.info/java8-nativeprng-blocking/" target="_blank" rel="noopener">随机数生成 — NativePRNGNonBlocking </a></li>
<li><a href="../random">随机token 生成代码</a></li>
<li><a href="https://yq.aliyun.com/articles/225660?spm=5176.100238.spm-cont-list.1.LYRwKV" target="_blank" rel="noopener">HashMap扩容、散列碰撞</a></li>
<li><a href="https://mp.weixin.qq.com/s/lQkPltX3yS3bGb9EbxHGAg" target="_blank" rel="noopener">一台Java服务器跑多少个线程</a></li>
<li><a href="https://mp.weixin.qq.com/s/--AMdl0GZQkY1MWIWQ-HHA" target="_blank" rel="noopener">【死磕Java并发】—- 深入分析CAS</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-hotdeploy/index.html" target="_blank" rel="noopener">深入探索 Java 热部署</a></li>
<li>signal 信号<ul>
<li><a href="http://hongjiang.info/jvm-and-signals-2/" target="_blank" rel="noopener">jvm与系统信号(2)</a></li>
<li><a href="https://www.cnblogs.com/MYSQLZOUQI/p/5258898.html" target="_blank" rel="noopener">kill 命令详解 系统信号</a></li>
<li><a href="http://www.kgc.cn/bbs/post/90262.shtml" target="_blank" rel="noopener">Linux系统下如何优雅地关闭Java进程方法</a></li>
<li><a href="https://blog.csdn.net/aa4790139/article/details/8584931" target="_blank" rel="noopener">signal信号捕捉</a></li>
<li>drools-demo 代码示例，java工程优雅关闭（kill pid , 默认信号 15）</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java关键字</title>
    <url>/java/modifier/</url>
    <content><![CDATA[<h1 id="1-volatile介绍"><a href="#1-volatile介绍" class="headerlink" title="1.volatile介绍"></a>1.volatile介绍</h1><p>volatile是java最轻量级的同步机制。</p>
<a id="more"></a>
<p><strong>特性：</strong></p>
<ul>
<li>可见性。变量读写直接操作主存而不是CPU Cache。当一个线程修改了volatile修饰的变量后，无论是否加锁，其它线程都可以立即看到最新的修改。</li>
<li>禁止指令重排序优化。</li>
<li>保证变量可见性，但无法保证原子性。也就是说非线程安全</li>
</ul>
<h2 id="java内存模型："><a href="#java内存模型：" class="headerlink" title="java内存模型："></a>java内存模型：</h2><img data-src="http://f.ngall-in.com/alan87/static/images/java/java-modifier/java-mem-mod.png/w600">

<p><a href="https://mp.weixin.qq.com/s/mcR8_FHHGA2zb0aW1N02ag?from=groupmessage&isappinstalled=0" target="_blank" rel="noopener">深入分析volatile的实现原理</a></p>
<h1 id="2-synchronized介绍"><a href="#2-synchronized介绍" class="headerlink" title="2.synchronized介绍"></a>2.synchronized介绍</h1><p>线程安全，锁区域内容一次只允许一个线程执行，通过锁机制控制。</p>
<ul>
<li>一、当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。</li>
<li>二、然而，当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。</li>
<li>三、尤其关键的是，当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有其它synchronized(this)同步代码块的访问将被阻塞。</li>
</ul>
<ul>
<li>同步方法</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">method</span><span class="params">(<span class="keyword">int</span> i)</span></span>;</span><br></pre></td></tr></table></figure>
<p>每个类实例对应一把锁，类的两个实例没有这个限制。类实例中所有的synchronized方法共用这一把锁，锁的范围有点大。</p>
<ul>
<li>同步块<br>相比上面的同步方法，锁的范围可缩小。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(syncObject) &#123;  </span><br><span class="line"><span class="comment">//允许访问控制的代码  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中的代码执行前必须获得对象 syncObject 锁，可以针对任意代码块，且可任意指定上锁的对象，故灵活性较高。</p>
<h1 id="3-final介绍"><a href="#3-final介绍" class="headerlink" title="3.final介绍"></a>3.final介绍</h1><p>如果修饰变量标识为常量，运行过程中会将值直接替换到变量这个占位符中（避免根据内存地址再次查找这层消耗）；如果修改方法，方法不允许被覆盖；修饰类，类不允许被继承。</p>
<p>基础类型，如String，不允许修改。</p>
<p>集合，如Map、List，引用地址不允许改，但可以put、get等操作。</p>
<p>java8编译会检查，如果是修改常量，会编译失败。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-modifier/java-final.png/w600">

<h1 id="4-static"><a href="#4-static" class="headerlink" title="4.static"></a>4.static</h1><ul>
<li>声明属性 —— 为全局属性，放在全局数据区，只分配一次</li>
<li>声明方法 —— 类方法，可以由类名称直接调用</li>
<li>声明类</li>
</ul>
<h1 id="5-transient"><a href="#5-transient" class="headerlink" title="5.transient"></a>5.transient</h1><p>如果一个对象中的某个属性不希望被序列化，则可以使用transient关键字进行声明。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java正则表达式</title>
    <url>/java/regex/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在Sun的Java JDK 1.40版本中，Java自带了支持正则表达式的包，主要是放在java.util.regex包下面。</p>
<a id="more"></a>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> Pattern p_script = Pattern.compile(<span class="string">"正则表达式"</span>, Pattern.CASE_INSENSITIVE);</span><br><span class="line"> Matcher m_script = p_script.matcher(content);</span><br><span class="line"> <span class="keyword">while</span> (m_script.find()) &#123;</span><br><span class="line">    <span class="comment">// 找到匹配内容，进行后续事情</span></span><br><span class="line">    String strAid = m_script.group(<span class="number">1</span>);</span><br><span class="line">    。。。。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Matcher类的常用方法："><a href="#Matcher类的常用方法：" class="headerlink" title="Matcher类的常用方法："></a><strong>Matcher类的常用方法：</strong></h2><ul>
<li><p>matches()：返回整个目标字符串与Pattern是否匹配</p>
</li>
<li><p>find()：返回与Pattern匹配的下一个子串</p>
</li>
<li><p>group()：返回上一次与Pattern匹配的子串中的内容。group是针对（）来说的，group（0）就是指的整个串，group（1） 指的是第一个括号里的东西，group（2）指的第二个括号里的东西</p>
</li>
<li><p>start()：返回上一次与Pattern匹配的子串在目标字符串中的开始位置。</p>
</li>
<li><p>end()：返回上一次与Pattern匹配的子串在目标字符串中的结束位置加1。</p>
</li>
</ul>
<h2 id="正则表达式语法"><a href="#正则表达式语法" class="headerlink" title="正则表达式语法"></a><strong>正则表达式语法</strong></h2><table>
<thead>
<tr>
<th>元字符</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>\</td>
<td>将下一个字符标记符、或一个向后引用、或一个八进制转义符。例如，“\n”匹配\n。“\n”匹配换行符。序列“\”匹配“\”而“(”则匹配“(”。即相当于多种编程语言中都有的“转义字符”的概念。</td>
</tr>
<tr>
<td>^</td>
<td>匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配“\n”或“\r”之后的位置。</td>
</tr>
<tr>
<td>$</td>
<td>匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，$也匹配“\n”或“\r”之前的位置。</td>
</tr>
<tr>
<td>*</td>
<td>匹配前面的子表达式任意次。例如，zo<em>能匹配“z”，“zo”以及“zoo”。</em>等价于{0,}</td>
</tr>
<tr>
<td>+</td>
<td>匹配前面的子表达式一次或多次(大于等于1次）。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。</td>
</tr>
<tr>
<td>?</td>
<td>匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“do”或“does”中的“do”。?等价于{0,1}。</td>
</tr>
<tr>
<td>{n}</td>
<td>n是一个非负整数。匹配确定的n次。例如，“o{2}”不能匹配“Bob”中的“o”，但是能匹配“food”中的两个o。</td>
</tr>
<tr>
<td>{n,}</td>
<td>n是一个非负整数。至少匹配n次。例如，“o{2,}”不能匹配“Bob”中的“o”，但能匹配“foooood”中的所有o。“o{1,}”等价于“o+”。“o{0,}”则等价于“o*”。</td>
</tr>
<tr>
<td>{n,m}</td>
<td>m和n均为非负整数，其中n&lt;=m。最少匹配n次且最多匹配m次。例如，“o{1,3}”将匹配“fooooood”中的前三个o。“o{0,1}”等价于“o?”。请注意在逗号和两个数之间不能有空格。</td>
</tr>
<tr>
<td>x|y</td>
<td>匹配x或y。例如，“z</td>
</tr>
<tr>
<td>[xyz]</td>
<td>字符集合。匹配所包含的任意一个字符。例如，“[abc]”可以匹配“plain”中的“a”。</td>
</tr>
<tr>
<td>[^xyz]</td>
<td>负值字符集合。匹配未包含的任意字符。例如，“[^abc]”可以匹配“plain”中的“plin”。</td>
</tr>
<tr>
<td>[a-z]</td>
<td>字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配“a”到“z”范围内的任意小写字母字符。</td>
</tr>
<tr>
<td>[^a-z]</td>
<td>负值字符范围。匹配任何不在指定范围内的任意字符。例如，“[^a-z]”可以匹配任何不在“a”到“z”范围内的任意字符。</td>
</tr>
<tr>
<td>.</td>
<td>可以匹配任何字符</td>
</tr>
<tr>
<td>\d</td>
<td>匹配一个数字字符。等价于[0-9]</td>
</tr>
<tr>
<td>\D</td>
<td>匹配一个非数字字符。等价于[^0-9]</td>
</tr>
<tr>
<td>\s</td>
<td>匹配所有的空白字符，包括空格、制表符、换页符、换行符、回车符 等等。等价于[ \f\n\r\t\v]。</td>
</tr>
<tr>
<td>\S</td>
<td>匹配所有的非空白字符</td>
</tr>
</tbody></table>
<h2 id="常用正则表达式"><a href="#常用正则表达式" class="headerlink" title="常用正则表达式"></a><strong>常用正则表达式</strong></h2><table>
<thead>
<tr>
<th>规则</th>
<th>正则表达式语法</th>
</tr>
</thead>
<tbody><tr>
<td>一个或多个汉字</td>
<td>^[\u0391-\uFFE5]+$</td>
</tr>
<tr>
<td>邮政编码</td>
<td>^[1-9]\d{5}$</td>
</tr>
<tr>
<td>QQ号码</td>
<td>^[1-9]\d{4,10}$</td>
</tr>
<tr>
<td>用户名（字母开头 + 数字/字母/下划线）</td>
<td>^[A-Za-z][A-Za-z1-9_-]+$</td>
</tr>
<tr>
<td>手机号码</td>
<td>^1[3|4|5|8][0-9]\d{8}$</td>
</tr>
<tr>
<td>URL</td>
<td>^((http|https)://)?([\w-]+.)+[\w-]+(/[\w-./?%&amp;=]*)?$</td>
</tr>
<tr>
<td>18位身份证号</td>
<td>^(\d{6})(18|19|20)?(\d{2})([01]\d)([0123]\d)(\d{3})(\d|X|x)?$</td>
</tr>
<tr>
<td>邮箱</td>
<td>^[a-zA-Z_]{1,}[0-9]{0,}@(([a-zA-z0-9]-*){1,}.){1,3}[a-zA-z-]{1,}$</td>
</tr>
</tbody></table>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><h2 id="匹配验证Email是否正确"><a href="#匹配验证Email是否正确" class="headerlink" title="匹配验证Email是否正确"></a>匹配验证Email是否正确</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 要验证的字符串</span></span><br><span class="line">    String str = <span class="string">"service@xsoftlab.net"</span>;</span><br><span class="line">    <span class="comment">// 邮箱验证规则</span></span><br><span class="line">    String regEx = <span class="string">"[a-zA-Z_]&#123;1,&#125;[0-9]&#123;0,&#125;@(([a-zA-z0-9]-*)&#123;1,&#125;\\.)&#123;1,3&#125;[a-zA-z\\-]&#123;1,&#125;"</span>;</span><br><span class="line">    <span class="comment">// 编译正则表达式</span></span><br><span class="line">    Pattern pattern = Pattern.compile(regEx);</span><br><span class="line">    <span class="comment">// 忽略大小写的写法</span></span><br><span class="line">    <span class="comment">// Pattern pat = Pattern.compile(regEx, Pattern.CASE_INSENSITIVE);</span></span><br><span class="line">    Matcher matcher = pattern.matcher(str);</span><br><span class="line">    <span class="comment">// 字符串是否与正则表达式相匹配</span></span><br><span class="line">    <span class="keyword">boolean</span> rs = matcher.matches();</span><br><span class="line">    System.out.println(rs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="在字符串中查询字符或者字符串"><a href="#在字符串中查询字符或者字符串" class="headerlink" title="在字符串中查询字符或者字符串"></a>在字符串中查询字符或者字符串</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 要验证的字符串</span></span><br><span class="line">    String str = <span class="string">"baike.qianxun.net"</span>;</span><br><span class="line">    <span class="comment">// 正则表达式规则</span></span><br><span class="line">    String regEx = <span class="string">"baike.*"</span>;</span><br><span class="line">    <span class="comment">// 编译正则表达式</span></span><br><span class="line">    Pattern pattern = Pattern.compile(regEx);</span><br><span class="line">    <span class="comment">// 忽略大小写的写法</span></span><br><span class="line">    <span class="comment">// Pattern pat = Pattern.compile(regEx, Pattern.CASE_INSENSITIVE);</span></span><br><span class="line">    Matcher matcher = pattern.matcher(str);</span><br><span class="line">    <span class="comment">// 查找字符串中是否有匹配正则表达式的字符/字符串</span></span><br><span class="line">    <span class="keyword">boolean</span> rs = matcher.find();</span><br><span class="line">    System.out.println(rs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java的线程状态</title>
    <url>/java/thread-state/</url>
    <content><![CDATA[<h1 id="线程有5种状态"><a href="#线程有5种状态" class="headerlink" title="线程有5种状态"></a>线程有5种状态</h1><div class="note primary">
            <ol><li>new，创建线程，尚未启动</li><li>Runable，此状态的线程有可能正在执行，也有可能正在等待cpu为它分配时间片</li><li>waiting，处于此状态的线程不会被分配时间片，必须要等待被其他线程显式的唤醒，notify或notify all</li></ol><a id="more"></a><ol start="4"><li>timed waiting ，处于此状态的线程不会被分配时间片，不过无须等待其它线程显式的唤醒，在一定时间后会由系统自动唤醒</li><li>blocked，线程被阻塞了，必须要等待获取锁</li><li>terminated，线程已执行结束，如一个线程的run()函数执行完毕后线程就进入死亡状态</li></ol>
          </div>

<h1 id="影响的命令："><a href="#影响的命令：" class="headerlink" title="影响的命令："></a>影响的命令：</h1><ul>
<li><p>run、start</p>
<p>需要并行处理的代码放在run()方法中，start()方法启动线程将自动调用 run()方法，这是由Java的内存机制规定的。并且run()方法必须是public访问权限，返回值类型为void。</p>
</li>
<li><p>wait</p>
<p>  当前线程暂停执行并释放对象锁标志，让其他线程可以进入Synchronized数据块，当前线程被放入对象等待池中</p>
</li>
<li><p>notify</p>
<p>唤醒一个线程</p>
</li>
<li><p>notifyAll</p>
<p>  唤醒所有线程</p>
</li>
<li><p>sleep</p>
<p>  休眠一段时间后，会自动唤醒。但它并不释放对象锁。也就是如果有Synchronized同步块，其他线程仍然不能访问共享数据。注意该方法要捕获异常</p>
</li>
<li><p>join</p>
<p>  当前线程停下来等待，直至另一个调用join方法的线程终止，线程在被激活后不一定马上就运行，而是进入到可运行线程的队列中</p>
</li>
<li><p>yield</p>
<p>停止当前线程，让同等优先权的线程运行。如果没有同等优先权的线程，那么yield()方法将不会起作用</p>
</li>
<li><p>daemon</p>
</li>
</ul>
<p>操会作系统维护一个ready queue（就绪线程队列），某一时刻cpu只为ready queue中位于队列头部的线程服务。 </p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-thread-state/java-thread-state-1.png/w600">

<h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h1><p><a href="http://www.jianshu.com/p/c9f847101fae" target="_blank" rel="noopener">http://www.jianshu.com/p/c9f847101fae</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java各种坑</title>
    <url>/java/some-sink/</url>
    <content><![CDATA[<h1 id="1-SimpleDateFormat-不是线程安全的"><a href="#1-SimpleDateFormat-不是线程安全的" class="headerlink" title="1. SimpleDateFormat 不是线程安全的"></a>1. SimpleDateFormat 不是线程安全的</h1><p>使用过程不要定义为静态全局变量。</p>
<a id="more"></a>

<p><strong>正确使用：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 时间是否是今天</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isToday</span><span class="params">(Long second)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (second == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    SimpleDateFormat sf = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>);</span><br><span class="line">    String today = sf.format(System.currentTimeMillis());</span><br><span class="line">    String compare = sf.format(<span class="keyword">new</span> Date(second * <span class="number">1000L</span>));</span><br><span class="line">    <span class="keyword">return</span> StringUtils.equals(today, compare);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="2-cache模型里面字段数据范围"><a href="#2-cache模型里面字段数据范围" class="headerlink" title="2.cache模型里面字段数据范围"></a>2.cache模型里面字段数据范围</h1><p>通常预发环境和线上环境会共用一套cache，如何避免两套环境间的数据干扰。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">写入：DO --&gt; cacheModel</span><br><span class="line">读出：cacheModel --&gt; DO</span><br><span class="line">查询接口：DO --&gt; ServiceModel</span><br></pre></td></tr></table></figure>
<h1 id="3-字符串不变性"><a href="#3-字符串不变性" class="headerlink" title="3.字符串不变性"></a>3.字符串不变性</h1><p>下面这张图展示了这段代码做了什么</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">"abcd"</span>;</span><br><span class="line">s = s.concat(<span class="string">"ef"</span>);</span><br></pre></td></tr></table></figure>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-some-sink/java-some-sink-1.png/w600">

<h1 id="4-HashCode被设计用来提高性能。"><a href="#4-HashCode被设计用来提高性能。" class="headerlink" title="4.HashCode被设计用来提高性能。"></a>4.HashCode被设计用来提高性能。</h1><p>equals()方法与hashCode()方法的区别在于：</p>
<p>如果两个对象相等(equal)，那么他们一定有相同的哈希值。<br>如果两个对象的哈希值相同，但他们未必相等(equal)。</p>
<p>注：== 表示两对象内存地址相同</p>
<h1 id="5-maven自己添加的依赖下载了，但是它的依赖没有下载"><a href="#5-maven自己添加的依赖下载了，但是它的依赖没有下载" class="headerlink" title="5.maven自己添加的依赖下载了，但是它的依赖没有下载"></a>5.maven自己添加的依赖下载了，但是它的依赖没有下载</h1><p>又正好其他包引用了其他版本，这时不会报错，但是可能跑不起来</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Caused by: java.lang.ClassNotFoundException: io.micrometer.core.instrument.config.validate.Validated</span><br><span class="line">	at java.base&#x2F;jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581) ~[na:na]</span><br><span class="line">	at java.base&#x2F;jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178) ~[na:na]</span><br><span class="line">	at java.base&#x2F;java.lang.ClassLoader.loadClass(ClassLoader.java:522) ~[na:na]</span><br><span class="line">	... 70 common frames omitted</span><br></pre></td></tr></table></figure>
<p>micrometer-registry-prometheus 1.5.1 依赖 micrometer-core 1.5.1 没有下载成功自动换到了已有版本1.3.8</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.micrometer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>micrometer-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>从ConcurrentHashMap的演进看Java多线程核心技术</title>
    <url>/java/%E4%BB%8EConcurrentHashMap%E7%9A%84%E6%BC%94%E8%BF%9B%E7%9C%8BJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h1 id="线程不安全的HashMap"><a href="#线程不安全的HashMap" class="headerlink" title="线程不安全的HashMap"></a>线程不安全的HashMap</h1><p>众所周知，HashMap是非线程安全的。而HashMap的线程不安全主要体现在resize时的死循环及使用迭代器时的fail-fast上。</p>
<p>注：本章的代码均基于JDK 1.7.0_67</p>
<h2 id="HashMap工作原理"><a href="#HashMap工作原理" class="headerlink" title="HashMap工作原理"></a>HashMap工作原理</h2><h3 id="HashMap数据结构"><a href="#HashMap数据结构" class="headerlink" title="HashMap数据结构"></a>HashMap数据结构</h3><p>常用的底层数据结构主要有数组和链表。数组存储区间连续，占用内存较多，寻址容易，插入和删除困难。链表存储区间离散，占用内存较少，寻址困难，插入和删除容易。</p>
<p>HashMap要实现的是哈希表的效果，尽量实现O(1)级别的增删改查。它的具体实现则是同时使用了数组和链表，可以认为最外层是一个数组，数组的每个元素是一个链表的表头。</p>
<h3 id="HashMap寻址方式"><a href="#HashMap寻址方式" class="headerlink" title="HashMap寻址方式"></a>HashMap寻址方式</h3><p>对于新插入的数据或者待读取的数据，HashMap将Key的哈希值对数组长度取模，结果作为该Entry在数组中的index。在计算机中，取模的代价远高于位操作的代价，因此HashMap要求数组的长度必须为2的N次方。此时将Key的哈希值对2^N-1进行与运算，其效果即与取模等效。HashMap并不要求用户在指定HashMap容量时必须传入一个2的N次方的整数，而是会通过Integer.highestOneBit算出比指定整数大的最小的2^N值，其实现方法如下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">highestOneBit</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">  i |= (i &gt;&gt;  <span class="number">1</span>);</span><br><span class="line">  i |= (i &gt;&gt;  <span class="number">2</span>);</span><br><span class="line">  i |= (i &gt;&gt;  <span class="number">4</span>);</span><br><span class="line">  i |= (i &gt;&gt;  <span class="number">8</span>);</span><br><span class="line">  i |= (i &gt;&gt; <span class="number">16</span>);</span><br><span class="line">  <span class="keyword">return</span> i - (i &gt;&gt;&gt; <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于Key的哈希值的分布直接决定了所有数据在哈希表上的分布或者说决定了哈希冲突的可能性，因此为防止糟糕的Key的hashCode实现（例如低位都相同，只有高位不相同，与2^N-1取与后的结果都相同），JDK 1.7的HashMap通过如下方法使得最终的哈希值的二进制形式中的1尽量均匀分布从而尽可能减少哈希冲突。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> h = hashSeed;</span><br><span class="line">h ^= k.hashCode();</span><br><span class="line">h ^= (h &gt;&gt;&gt; <span class="number">20</span>) ^ (h &gt;&gt;&gt; <span class="number">12</span>);</span><br><span class="line"><span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">7</span>) ^ (h &gt;&gt;&gt; <span class="number">4</span>);</span><br></pre></td></tr></table></figure>

<h2 id="resize死循环"><a href="#resize死循环" class="headerlink" title="resize死循环"></a>resize死循环</h2><h3 id="transfer方法"><a href="#transfer方法" class="headerlink" title="transfer方法"></a>transfer方法</h3><p>当HashMap的size超过Capacity*loadFactor时，需要对HashMap进行扩容。具体方法是，创建一个新的，长度为原来Capacity两倍的数组，保证新的Capacity仍为2的N次方，从而保证上述寻址方式仍适用。同时需要通过如下transfer方法将原来的所有数据全部重新插入（rehash）到新的数组中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Entry[] newTable, <span class="keyword">boolean</span> rehash)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> newCapacity = newTable.length;</span><br><span class="line">  <span class="keyword">for</span> (Entry&lt;K,V&gt; e : table) &#123;</span><br><span class="line">    <span class="keyword">while</span>(<span class="keyword">null</span> != e) &#123;</span><br><span class="line">      Entry&lt;K,V&gt; next = e.next;</span><br><span class="line">      <span class="keyword">if</span> (rehash) &#123;</span><br><span class="line">        e.hash = <span class="keyword">null</span> == e.key ? <span class="number">0</span> : hash(e.key);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">int</span> i = indexFor(e.hash, newCapacity);</span><br><span class="line">      e.next = newTable[i];</span><br><span class="line">      newTable[i] = e;</span><br><span class="line">      e = next;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法并不保证线程安全，而且在多线程并发调用时，可能出现死循环。其执行过程如下。从步骤2可见，转移时链表顺序反转。</p>
<ol>
<li>遍历原数组中的元素</li>
<li>对链表上的每一个节点遍历：用next取得要转移那个元素的下一个，将e转移到新数组的头部，使用头插法插入节点</li>
<li>循环2，直到链表节点全部转移</li>
<li>循环1，直到所有元素全部转移</li>
</ol>
<h3 id="单线程rehash"><a href="#单线程rehash" class="headerlink" title="单线程rehash"></a>单线程rehash</h3><p>单线程情况下，rehash无问题。下图演示了单线程条件下的rehash过程<br><img data-src="http://www.jasongj.com/img/java/concurrenthashmap/single_thread_rehash.png"></p>
<h3 id="多线程并发下的rehash"><a href="#多线程并发下的rehash" class="headerlink" title="多线程并发下的rehash"></a>多线程并发下的rehash</h3><p>这里假设有两个线程同时执行了put操作并引发了rehash，执行了transfer方法，并假设线程一进入transfer方法并执行完next = e.next后，因为线程调度所分配时间片用完而“暂停”，此时线程二完成了transfer方法的执行。此时状态如下。</p>
<img data-src="http://www.jasongj.com/img/java/concurrenthashmap/multi_thread_rehash_1.png">

<p>接着线程1被唤醒，继续执行第一轮循环的剩余部分</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">e.next = newTable[<span class="number">1</span>] = <span class="keyword">null</span></span><br><span class="line">newTable[<span class="number">1</span>] = e = key(<span class="number">5</span>)</span><br><span class="line">e = next = key(<span class="number">9</span>)</span><br></pre></td></tr></table></figure>

<p>结果如下图所示<br><img data-src="http://www.jasongj.com/img/java/concurrenthashmap/multi_thread_rehash_2.png"></p>
<p>接着执行下一轮循环，结果状态图如下所示<br><img data-src="http://www.jasongj.com/img/java/concurrenthashmap/multi_thread_rehash_3.png"></p>
<p>继续下一轮循环，结果状态图如下所示<br><img data-src="http://www.jasongj.com/img/java/concurrenthashmap/multi_thread_rehash_4.png"></p>
<p>此时循环链表形成，并且key(11)无法加入到线程1的新数组。在下一次访问该链表时会出现死循环。</p>
<h2 id="Fail-fast"><a href="#Fail-fast" class="headerlink" title="Fail-fast"></a>Fail-fast</h2><h3 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h3><p>在使用迭代器的过程中如果HashMap被修改，那么<code>ConcurrentModificationException</code>将被抛出，也即Fail-fast策略。</p>
<p>当HashMap的iterator()方法被调用时，会构造并返回一个新的EntryIterator对象，并将EntryIterator的expectedModCount设置为HashMap的modCount（该变量记录了HashMap被修改的次数）。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">HashIterator() &#123;</span><br><span class="line">  expectedModCount = modCount;</span><br><span class="line">  <span class="keyword">if</span> (size &gt; <span class="number">0</span>) &#123; <span class="comment">// advance to first entry</span></span><br><span class="line">  Entry[] t = table;</span><br><span class="line">  <span class="keyword">while</span> (index &lt; t.length &amp;&amp; (next = t[index++]) == <span class="keyword">null</span>)</span><br><span class="line">    ;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在通过该Iterator的next方法访问下一个Entry时，它会先检查自己的expectedModCount与HashMap的modCount是否相等，如果不相等，说明HashMap被修改，直接抛出<code>ConcurrentModificationException</code>。该Iterator的remove方法也会做类似的检查。该异常的抛出意在提醒用户及早意识到线程安全问题。</p>
<h3 id="线程安全解决方案"><a href="#线程安全解决方案" class="headerlink" title="线程安全解决方案"></a>线程安全解决方案</h3><p>单线程条件下，为避免出现<code>ConcurrentModificationException</code>，需要保证只通过HashMap本身或者只通过Iterator去修改数据，不能在Iterator使用结束之前使用HashMap本身的方法修改数据。因为通过Iterator删除数据时，HashMap的modCount和Iterator的expectedModCount都会自增，不影响二者的相等性。如果是增加数据，只能通过HashMap本身的方法完成，此时如果要继续遍历数据，需要重新调用iterator()方法从而重新构造出一个新的Iterator，使得新Iterator的expectedModCount与更新后的HashMap的modCount相等。</p>
<p>多线程条件下，可使用<code>Collections.synchronizedMap</code>方法构造出一个同步Map，或者直接使用线程安全的ConcurrentHashMap。</p>
<h1 id="Java-7基于分段锁的ConcurrentHashMap"><a href="#Java-7基于分段锁的ConcurrentHashMap" class="headerlink" title="Java 7基于分段锁的ConcurrentHashMap"></a>Java 7基于分段锁的ConcurrentHashMap</h1><p>注：本章的代码均基于JDK 1.7.0_67</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>Java 7中的ConcurrentHashMap的底层数据结构仍然是数组和链表。与HashMap不同的是，ConcurrentHashMap最外层不是一个大的数组，而是一个Segment的数组。每个Segment包含一个与HashMap数据结构差不多的链表数组。整体数据结构如下图所示。<br><img data-src="http://www.jasongj.com/img/java/concurrenthashmap/concurrenthashmap_java7.png"></p>
<h2 id="寻址方式"><a href="#寻址方式" class="headerlink" title="寻址方式"></a>寻址方式</h2><p>在读写某个Key时，先取该Key的哈希值。并将哈希值的高N位对Segment个数取模从而得到该Key应该属于哪个Segment，接着如同操作HashMap一样操作这个Segment。为了保证不同的值均匀分布到不同的Segment，需要通过如下方法计算哈希值。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object k)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> h = hashSeed;</span><br><span class="line">  <span class="keyword">if</span> ((<span class="number">0</span> != h) &amp;&amp; (k <span class="keyword">instanceof</span> String)) &#123;</span><br><span class="line">    <span class="keyword">return</span> sun.misc.Hashing.stringHash32((String) k);</span><br><span class="line">  &#125;</span><br><span class="line">  h ^= k.hashCode();</span><br><span class="line">  h += (h &lt;&lt;  <span class="number">15</span>) ^ <span class="number">0xffffcd7d</span>;</span><br><span class="line">  h ^= (h &gt;&gt;&gt; <span class="number">10</span>);</span><br><span class="line">  h += (h &lt;&lt;   <span class="number">3</span>);</span><br><span class="line">  h ^= (h &gt;&gt;&gt;  <span class="number">6</span>);</span><br><span class="line">  h += (h &lt;&lt;   <span class="number">2</span>) + (h &lt;&lt; <span class="number">14</span>);</span><br><span class="line">  <span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同样为了提高取模运算效率，通过如下计算，ssize即为大于concurrencyLevel的最小的2的N次方，同时segmentMask为2^N-1。这一点跟上文中计算数组长度的方法一致。对于某一个Key的哈希值，只需要向右移segmentShift位以取高sshift位，再与segmentMask取与操作即可得到它在Segment数组上的索引。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> sshift = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> ssize = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (ssize &lt; concurrencyLevel) &#123;</span><br><span class="line">  ++sshift;</span><br><span class="line">  ssize &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">this</span>.segmentShift = <span class="number">32</span> - sshift;</span><br><span class="line"><span class="keyword">this</span>.segmentMask = ssize - <span class="number">1</span>;</span><br><span class="line">Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])<span class="keyword">new</span> Segment[ssize];</span><br></pre></td></tr></table></figure>

<h2 id="同步方式"><a href="#同步方式" class="headerlink" title="同步方式"></a>同步方式</h2><p>Segment继承自ReentrantLock，所以我们可以很方便的对每一个Segment上锁。</p>
<p>对于读操作，获取Key所在的Segment时，需要保证可见性(请参考<a href="http://www.jasongj.com/java/thread_safe/#Java如何保证可见性" target="_blank" rel="noopener">如何保证多线程条件下的可见性</a>)。具体实现上可以使用volatile关键字，也可使用锁。但使用锁开销太大，而使用volatile时每次写操作都会让所有CPU内缓存无效，也有一定开销。ConcurrentHashMap使用如下方法保证可见性，取得最新的Segment。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Segment&lt;K,V&gt; s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)</span><br></pre></td></tr></table></figure>

<p>获取Segment中的HashEntry时也使用了类似方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile</span><br><span class="line">  (tab, ((<span class="keyword">long</span>)(((tab.length - <span class="number">1</span>) &amp; h)) &lt;&lt; TSHIFT) + TBASE)</span><br></pre></td></tr></table></figure>

<p>对于写操作，并不要求同时获取所有Segment的锁，因为那样相当于锁住了整个Map。它会先获取该Key-Value对所在的Segment的锁，获取成功后就可以像操作一个普通的HashMap一样操作该Segment，并保证该Segment的安全性。<br>同时由于其它Segment的锁并未被获取，因此理论上可支持concurrencyLevel（等于Segment的个数）个线程安全的并发读写。</p>
<p>获取锁时，并不直接使用lock来获取，因为该方法获取锁失败时会挂起（参考<a href="http://www.jasongj.com/java/multi_thread/#重入锁" target="_blank" rel="noopener">可重入锁</a>）。事实上，它使用了自旋锁，如果tryLock获取锁失败，说明锁被其它线程占用，此时通过循环再次以tryLock的方式申请锁。如果在循环过程中该Key所对应的链表头被修改，则重置retry次数。如果retry次数超过一定值，则使用lock方法申请锁。</p>
<p>这里使用自旋锁是因为自旋锁的效率比较高，但是它消耗CPU资源比较多，因此在自旋次数超过阈值时切换为互斥锁。</p>
<h2 id="size操作"><a href="#size操作" class="headerlink" title="size操作"></a>size操作</h2><p>put、remove和get操作只需要关心一个Segment，而size操作需要遍历所有的Segment才能算出整个Map的大小。一个简单的方案是，先锁住所有Sgment，计算完后再解锁。但这样做，在做size操作时，不仅无法对Map进行写操作，同时也无法进行读操作，不利于对Map的并行操作。</p>
<p>为更好支持并发操作，ConcurrentHashMap会在不上锁的前提逐个Segment计算3次size，如果某相邻两次计算获取的所有Segment的更新次数（每个Segment都与HashMap一样通过modCount跟踪自己的修改次数，Segment每修改一次其modCount加一）相等，说明这两次计算过程中无更新操作，则这两次计算出的总size相等，可直接作为最终结果返回。如果这三次计算过程中Map有更新，则对所有Segment加锁重新计算Size。该计算方法代码如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> Segment&lt;K,V&gt;[] segments = <span class="keyword">this</span>.segments;</span><br><span class="line">  <span class="keyword">int</span> size;</span><br><span class="line">  <span class="keyword">boolean</span> overflow; <span class="comment">// true if size overflows 32 bits</span></span><br><span class="line">  <span class="keyword">long</span> sum;         <span class="comment">// sum of modCounts</span></span><br><span class="line">  <span class="keyword">long</span> last = <span class="number">0L</span>;   <span class="comment">// previous sum</span></span><br><span class="line">  <span class="keyword">int</span> retries = -<span class="number">1</span>; <span class="comment">// first iteration isn't retry</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">      <span class="keyword">if</span> (retries++ == RETRIES_BEFORE_LOCK) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j)</span><br><span class="line">          ensureSegment(j).lock(); <span class="comment">// force creation</span></span><br><span class="line">      &#125;</span><br><span class="line">      sum = <span class="number">0L</span>;</span><br><span class="line">      size = <span class="number">0</span>;</span><br><span class="line">      overflow = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j) &#123;</span><br><span class="line">        Segment&lt;K,V&gt; seg = segmentAt(segments, j);</span><br><span class="line">        <span class="keyword">if</span> (seg != <span class="keyword">null</span>) &#123;</span><br><span class="line">          sum += seg.modCount;</span><br><span class="line">          <span class="keyword">int</span> c = seg.count;</span><br><span class="line">          <span class="keyword">if</span> (c &lt; <span class="number">0</span> || (size += c) &lt; <span class="number">0</span>)</span><br><span class="line">            overflow = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (sum == last)</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      last = sum;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (retries &gt; RETRIES_BEFORE_LOCK) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j)</span><br><span class="line">        segmentAt(segments, j).unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> overflow ? Integer.MAX_VALUE : size;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="不同之处"><a href="#不同之处" class="headerlink" title="不同之处"></a><a href="#不同之处"></a>不同之处</h2><p>ConcurrentHashMap与HashMap相比，有以下不同点</p>
<ul>
<li>ConcurrentHashMap线程安全，而HashMap非线程安全</li>
<li>HashMap允许Key和Value为null，而ConcurrentHashMap不允许</li>
<li>HashMap不允许通过Iterator遍历的同时通过HashMap修改，而ConcurrentHashMap允许该行为，并且该更新对后续的遍历可见</li>
</ul>
<h1 id="Java-8基于CAS的ConcurrentHashMap"><a href="#Java-8基于CAS的ConcurrentHashMap" class="headerlink" title="Java 8基于CAS的ConcurrentHashMap"></a>Java 8基于CAS的ConcurrentHashMap</h1><p>注：本章的代码均基于JDK 1.8.0_111</p>
<h2 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h2><p>Java 7为实现并行访问，引入了Segment这一结构，实现了分段锁，理论上最大并发度与Segment个数相等。Java 8为进一步提高并发性，摒弃了分段锁的方案，而是直接使用一个大的数组。同时为了提高哈希碰撞下的寻址性能，Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(long(N))）。其数据结构如下图所示</p>
<h2 id="寻址方式-1"><a href="#寻址方式-1" class="headerlink" title="寻址方式"></a><a href="#寻址方式-1"></a>寻址方式</h2><p>Java 8的ConcurrentHashMap同样是通过Key的哈希值与数组长度取模确定该Key在数组中的索引。同样为了避免不太好的Key的hashCode设计，它通过如下方法计算得到Key的最终哈希值。不同的是，Java 8的ConcurrentHashMap作者认为引入红黑树后，即使哈希冲突比较严重，寻址效率也足够高，所以作者并未在哈希值的计算上做过多设计，只是将Key的hashCode值与其高16位作异或并保证最高位为0（从而保证最终结果为正整数）。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">spread</span><span class="params">(<span class="keyword">int</span> h)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (h ^ (h &gt;&gt;&gt; <span class="number">16</span>)) &amp; HASH_BITS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="同步方式-1"><a href="#同步方式-1" class="headerlink" title="同步方式"></a>同步方式</h2><p>对于put操作，如果Key对应的数组元素为null，则通过<a href="http://www.jasongj.com/java/thread_safe/#CAS（compare-and-swap）" target="_blank" rel="noopener">CAS操作</a>将其设置为当前值。如果Key对应的数组元素（也即链表表头或者树的根元素）不为null，则对该元素使用synchronized关键字申请锁，然后进行操作。如果该put操作使得当前链表长度超过一定阈值，则将该链表转换为红黑树，从而提高寻址效率。</p>
<p>对于读操作，由于数组被volatile关键字修饰，因此不用担心数组的可见性问题。同时每个元素是一个Node实例（Java 7中每个元素是一个HashEntry），它的Key值和hash值都由final修饰，不可变更，无须关心它们被修改后的可见性问题。而其Value及对下一个元素的引用由volatile修饰，可见性也有保障。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">  <span class="keyword">final</span> K key;</span><br><span class="line">  <span class="keyword">volatile</span> V val;</span><br><span class="line">  <span class="keyword">volatile</span> Node&lt;K,V&gt; next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对于Key对应的数组元素的可见性，由Unsafe的getObjectVolatile方法保证。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> &lt;K,V&gt; <span class="function">Node&lt;K,V&gt; <span class="title">tabAt</span><span class="params">(Node&lt;K,V&gt;[] tab, <span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((<span class="keyword">long</span>)i &lt;&lt; ASHIFT) + ABASE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="size操作-1"><a href="#size操作-1" class="headerlink" title="size操作"></a>size操作</h2><p>put方法和remove方法都会通过addCount方法维护Map的size。size方法通过sumCount获取由addCount方法维护的Map的size。</p>
<p><a href="http://www.jasongj.com/java/concurrenthashmap/" target="_blank" rel="noopener">原文链接</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据面试题</title>
    <url>/java-other/bigdata-interview/</url>
    <content><![CDATA[<ul>
<li><a href="https://mp.weixin.qq.com/s/3g3pd29Ju6MB0dOAOXkCtg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/3g3pd29Ju6MB0dOAOXkCtg</a></li>
</ul>
<a id="more"></a>

<h1 id="Hadoop部分"><a href="#Hadoop部分" class="headerlink" title="Hadoop部分"></a>Hadoop部分</h1><ul>
<li>hadoop的map-reduce的实现原理？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">首先map task会从本地文件系统读取数据，转换成key-value形式的键值对集合，使用的是hadoop内置的数据类型，比如longwritable、text等，将键值对集合输入mapper进行业务处理过程，将其转换成需要的key-value在输出之后会进行一个partition分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getpartition方法来自定义分区规则，之后会对key进行进行sort排序，grouping分组操作将相同key的value合并分组输出，在这里可以使用自定义的数据类型，重写WritableComparator的Comparator方法来自定义排序规则，重写RawComparator的compara方法来自定义分组规则。</span><br><span class="line"></span><br><span class="line">之后进行一个combiner归约操作，其实就是一个本地段的reduce预处理，以减小后面shuffle和reduce的工作量，reduce task会通过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job</span><br></pre></td></tr></table></figure>


<ul>
<li>hadoop和spark的都是并行计算，那么他们有什么相同和区别</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">两者都是用mr模型来进行并行计算，hadoop的一个作业称为job，job里面分为map task和reduce task，每个task都是在自己的进程中运行的，当task结束时，进程也会结束</span><br><span class="line"></span><br><span class="line">spark用户提交的任务成为application，一个application对应一个sparkcontext，app中存在多个job，每触发一次action操作就会产生一个job</span><br><span class="line"></span><br><span class="line">这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算</span><br><span class="line"></span><br><span class="line">hadoop的job只有map和reduce操作，表达能力比较欠缺而且在mr过程中会重复的读写hdfs，造成大量的io操作，多个job需要自己管理关系</span><br><span class="line"></span><br><span class="line">spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作如join，groupby等，而且通过DAG图可以实现良好的容错</span><br></pre></td></tr></table></figure>

<ul>
<li>工作中，map-reduce程序运行的时候会有什么比较常见的问题？如何解决？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">比如说作业中大部分都完成了，但是总有几个reduce一直在运行。这是因为这几个reduce中的处理的数据要远远大于其他的reduce，可能是因为对键值对任务划分的不均匀造成的数据倾斜。</span><br><span class="line"></span><br><span class="line">解决的方法可以在分区的时候重新定义分区规则对于value数据很多的key可以进行拆分、均匀打散等处理，或者是在map端的combiner中进行数据预处理的操作</span><br></pre></td></tr></table></figure>
<ul>
<li>hadoop的TextInputFormat作用是什么，如何自定义实现</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">InputFormat会在map操作之前对数据进行两方面的预处理 </span><br><span class="line">1.是getSplits，返回的是InputSplit数组，对数据进行split分片，每片交给map操作一次 </span><br><span class="line">2.是getRecordReader，返回的是RecordReader对象，对每个split分片进行转换为key-value键值对格式传递给map</span><br><span class="line"></span><br><span class="line">常用的InputFormat是TextInputFormat，使用的是LineRecordReader对每个分片进行键值对的转换，以行偏移量作为键，行内容作为值</span><br><span class="line"></span><br><span class="line">自定义类继承InputFormat接口，重写createRecordReader和isSplitable方法 </span><br><span class="line">在createRecordReader中可以自定义分隔符</span><br></pre></td></tr></table></figure>
<ul>
<li>为什么要用flume导入hdfs，hdfs的构架是怎样的</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">flume可以实时的导入数据到hdfs中，当hdfs上的文件达到一个指定大小的时候会形成一个文件，或者超过指定时间的话也形成一个文件</span><br><span class="line"></span><br><span class="line">文件都是存储在datanode上面的，namenode记录着datanode的元数据信息，而namenode的元数据信息是存在内存中的，所以当文件切片很小或者很多的时候会卡死</span><br></pre></td></tr></table></figure>

<ul>
<li>简单说一下hadoop和spark的shuffle过程</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop：map端保存分片数据，通过网络收集到reduce端 </span><br><span class="line">spark：spark的shuffle是在DAGSchedular划分Stage的时候产生的，TaskSchedule要分发Stage到各个worker的executor</span><br><span class="line"></span><br><span class="line">减少shuffle可以提高性能</span><br></pre></td></tr></table></figure>

<h1 id="Hbase部分"><a href="#Hbase部分" class="headerlink" title="Hbase部分"></a>Hbase部分</h1><ul>
<li>hbase由哪几部分组成</li>
<li>hbase 插入一条数据，内部是如何处理的？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 首先，Client通过访问ZK来请求目标数据的地址。</span><br><span class="line">2. ZK中保存了-ROOT-表的地址，所以ZK通过访问-ROOT-表来请求数据地址。</span><br><span class="line">3. 同样，-ROOT-表中保存的是.META.的信息，通过访问.META.表来获取具体的RS。</span><br><span class="line">4. .META.表查询到具体RS信息后返回具体RS地址给Client。</span><br><span class="line">5. Client端获取到目标地址后，然后直接向该地址发送数据请求。</span><br></pre></td></tr></table></figure>
<ul>
<li>hbase某台机器宕机了，会不会丢失数据，为什么？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HBase的RegionServer宕机超过一定时间后，HMaster会将其所管理的region重新分布到其他活动的RegionServer上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。</span><br><span class="line">但是重新分配的region需要根据日志（LogFile）恢复原RegionServer中的内存MemoryStore表，这会导致宕机的region在这段时间内无法对外提供服务。</span><br><span class="line">而一旦重分布，宕机的节点重新启动后就相当于一个新的RegionServer加入集群，为了平衡，需要再次将某些region分布到该server。 </span><br><span class="line">因此，Region Server的内存表memstore如何在节点间做到更高的可用，是HBase的一个较大的挑战。</span><br></pre></td></tr></table></figure>
<ul>
<li><p>rowkey的设计原则</p>
</li>
<li><p>hbase 过滤器有哪些？你常用哪个？什么功能？</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Hbase的过滤器有：RowFilter、PrefixFilter、KeyOnlyFilter、RandomRowFilter、InclusiveStopFilter、FirstKeyOnlyFilter、ColumnPrefixFilter、ValueFilter、ColumnCountGetFilter、SingleColumnValueFilter、SingleColumnValueExcludeFilter、WhileMatchFilter、FilterList </span><br><span class="line"></span><br><span class="line">比较常用的过滤器有：RowFilter 用来对rowkey进行过滤的。</span><br><span class="line">http:&#x2F;&#x2F;blog.csdn.net&#x2F;xugen12&#x2F;article&#x2F;details&#x2F;44747465</span><br></pre></td></tr></table></figure>

<ul>
<li>hbase 中cell的结构</li>
</ul>
<p>cell中的数据是没有类型的，全部是字节码形式存贮。</p>
<ul>
<li>hbase 中region 太大问题</li>
</ul>
<p>Hbase的region会自动split</p>
<h1 id="Hive部分"><a href="#Hive部分" class="headerlink" title="Hive部分"></a>Hive部分</h1><ul>
<li>Hive中存放是什么？ </li>
</ul>
<p>表。 存的是和hdfs的映射关系，hive是逻辑上的数据仓库，实际操作的都是hdfs上的文件，HQL就是用sql语法来写的mr程序。</p>
<ul>
<li>Hive与关系型数据库的关系？ </li>
</ul>
<p>没有关系，hive是数据仓库，不能和数据库一样进行实时的CURD操作。 是一次写入多次读取的操作，可以看成是ETL工具。</p>
<h1 id="Spark-部分"><a href="#Spark-部分" class="headerlink" title="Spark 部分"></a>Spark 部分</h1><ul>
<li>spark有哪些组件？ </li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">（1）master：管理集群和节点，不参与计算。 </span><br><span class="line">（2）worker：计算节点，进程本身不参与计算，和master汇报。 </span><br><span class="line">（3）Driver：运行程序的main方法，创建spark context对象。 一个驱动程序可以在spark集群上启动一个或多个作业。</span><br><span class="line">（4）spark context：控制整个application的生命周期，包括dagsheduler和task scheduler等组件。 </span><br><span class="line">（5）client：用户提交程序的入口。</span><br></pre></td></tr></table></figure>
<ul>
<li>spark工作机制？ </li>
</ul>
<p>用户在client端提交作业后，会由Driver运行main方法并创建spark context上下文。<br>执行add算子，形成dag图输入dagscheduler，按照add之间的依赖关系划分stage输入task scheduler。<br>task scheduler会将stage划分为task set分发到各个节点的executor中执行。</p>
<ul>
<li>spark的优化怎么做？ </li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">通过spark-env文件、程序中sparkconf和set property设置。 </span><br><span class="line">（1）计算量大，形成的lineage过大应该给已经缓存了的rdd添加checkpoint，以减少容错带来的开销。 </span><br><span class="line">（2）小分区合并，过小的分区造成过多的切换任务开销，使用repartition。</span><br></pre></td></tr></table></figure>
<ul>
<li><p>spark sql比hive快至少10倍，原因是什么？</p>
</li>
<li><p>mr 和 spark 区别，怎么理解 spark-rdd</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Mr 是文件方式的分布式计算框架，是将中间结果和最终结果记录在文件中，map 和 reduce的数据分发也是在文件中。</span><br><span class="line">spark 是内存迭代式的计算框架，计算的中间结果可以缓存内存，也可以缓存硬盘，但是不是每一步计算都需要缓存的。</span><br><span class="line">Spark-rdd 是一个数据的分区记录集合，是利用内存来计算的，spark之所以快是因为有内存的模式</span><br></pre></td></tr></table></figure>

<ul>
<li>Spark程序的性能和调优方面有什么需要注意的</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">首先，对于大部分数据处理应用程序，磁盘I&#x2F;O都是影响应用程序执行速度的决定性因素。Spark可以让用户在内存中创建数据，请尽量利用这一特性。将数据缓存在内存中可以让应用程序提速100倍以上。当然这也意味着最好使用具有大量内存的计算机搭建Spark集群。</span><br><span class="line"></span><br><span class="line">其次，请避免需要进行数据重排（Data shuffling）的操作。跨越网络进行数据重排是一种开销很高的操作，在编写数据处理逻辑时一定要注意这一点。有时候相同的逻辑也可以通过更高效的操作实现，例如不要使用groupByKey操作，而是可以使用reduceByKey操作。</span><br><span class="line"></span><br><span class="line">第三，优化数据中的分区数量。如果数据尚未分区，就无法充分利用Spark在并行数据处理方面的优势。例如，假设有一个100内核的Spark集群，但如果数据只有2个分区，此时将无法充分运用所有计算能力。</span><br><span class="line"></span><br><span class="line">第四，通过共置的数据节点和计算节点可以获得更好的性能。举例来说，如果数据在HDFS中，请在同一个HDFS集群中安装Spark。Spark会在距离数据尽可能近的位置处理这些数据。例如，它首先会尝试在数据所在计算机上执行任务。如果该计算机无法执行任务，随后会尝试使用同一机机柜的其他计算机。如果依然不可行，最后才会选择使用任意一台计算机。请尽量将磁盘和网络I&#x2F;O降至最低。</span><br></pre></td></tr></table></figure>
<ul>
<li>Spark会取代Hadoop吗？为什么？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">不会。今天的Hadoop代表了多个产品组成的生态系统，Spark也是这个生态系统的成员。就算最核心的Hadoop也包含三个组件：一个集群管理器，一个分布式计算框架，以及一个分布式文件系统。其中集群管理器是YARN，计算框架是MapReduce，分布式文件系统是HDFS。Spark是Hadoop MapReduce组件的继任者。</span><br><span class="line"></span><br><span class="line">很多人在使用Spark作业取代原有的MapReduce作业，或在Spark中编写新的作业。因此可以说Spark会取代MapReduce，但无法取代Hadoop。</span><br><span class="line"></span><br><span class="line">另外有个重要的事情需要注意，Spark可以配合Hadoop使用，但也可以在不具备Hadoop的情况下使用。例如，可以使用Mesos或独立集群管理器替代YARN，同理也可以使用S3或其他数据源代替HDFS。因此使用Spark并非必须要同时使用Hadoop。</span><br></pre></td></tr></table></figure>
<ul>
<li>为什么有人使用Spark代替MapReduce？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">相比MapReduce，Spark可以提供更多优势。</span><br><span class="line"></span><br><span class="line">首先，Spark比MapReduce速度快很多。取决于具体应用，可能会比MapReduce快100倍。Spark如此之快的一个原因在于其先进的作业执行引擎。Spark作业可以划分为任意数量的阶段（Stage），而MapReduce作业只能分为两个阶段。另外Spark可以让应用程序将数据缓存在内存中。缓存机制可极大改进应用程序性能。磁盘I&#x2F;O会大幅影响数据处理应用程序的执行速度，Spark则能将磁盘I&#x2F;O降至最低。</span><br><span class="line"></span><br><span class="line">其次，Spark很易用。Spark提供了丰富的API和超过80种操作，MapReduce只能提供两种操作：Map和Reduce。Spark API可以通过Scala、Python、Java和R四种语言使用。相比在MapReduce中编写的作业，相同数据处理作业使用Scala&#x2F;Spark编写时代码量可以减少5-10倍。因此Spark也能大幅提高开发者的生产力。</span><br><span class="line"></span><br><span class="line">第三，Spark针对不同类型的数据处理任务提供了统一的工具。该产品内置了用于批处理、交互式分析、机器学习、流处理，以及图表分析的集成库，用户不再需要学习多种工具。也不需要将代码和数据复制到多个位置。另外从运营的角度来说，一个集群的管理，无疑要比针对不同类型作业创建多个专用集群管理起来更简单。</span><br></pre></td></tr></table></figure>
<ul>
<li><p>如何解决数据倾斜问题？</p>
</li>
<li><p>Spark Streaming和Storm有何区别？ </p>
</li>
</ul>
<p>一个实时毫秒一个准实时亚秒，不过storm的吞吐率比较低。</p>
<ul>
<li>mllib支持的算法？ </li>
</ul>
<p>大体分为四大类，分类、聚类、回归、协同过滤。</p>
<h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><ul>
<li>给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">每个url大小为64 bytes，那么可以估计每个文件的大小为50G×64&#x3D;320G，远远大于内存限制的4G，所以不可能将其完全加载到内存中处理，可以采用分治的思想来解决。</span><br><span class="line"></span><br><span class="line">　　Step1：遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件(记为a0,a1,...,a999，每个小文件约300M);</span><br><span class="line"></span><br><span class="line">　　Step2:遍历文件b，采取和a相同的方式将url分别存储到1000个小文件(记为b0,b1,...,b999);</span><br><span class="line"></span><br><span class="line">　　巧妙之处：这样处理后，所有可能相同的url都被保存在对应的小文件(a0vsb0,a1vsb1,...,a999vsb999)中，不对应的小文件不可能有相同的url。然后我们只要求出这个1000对小文件中相同的url即可。</span><br><span class="line"></span><br><span class="line">　　Step3：求每对小文件ai和bi中相同的url时，可以把ai的url存储到hash_set&#x2F;hash_map中。然后遍历bi的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。</span><br></pre></td></tr></table></figure>

<ul>
<li>有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M，要求返回频数最高的100个词。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Step1：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件(记为f0,f1,...,f4999)中，这样每个文件大概是200k左右，如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M;</span><br><span class="line"></span><br><span class="line">Step2：对每个小文件，统计每个文件中出现的词以及相应的频率(可以采用trie树&#x2F;hash_map等)，并取出出现频率最大的100个词(可以用含100个结点的最小堆)，并把100词及相应的频率存入文件，这样又得到了5000个文件;</span><br><span class="line"></span><br><span class="line">Step3：把这5000个文件进行归并(类似与归并排序);</span><br></pre></td></tr></table></figure>

<ul>
<li>现有海量日志数据保存在一个超级大的文件中，该文件无法直接读入内存，要求从中提取某天出访问百度次数最多的那个IP</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">问题解法同上，算法思想：分而治之+Hash</span><br><span class="line"></span><br><span class="line">1)IP地址最多有2^32&#x3D;4G种取值情况，所以不能完全加载到内存中处理;</span><br><span class="line"></span><br><span class="line">2)可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址;</span><br><span class="line"></span><br><span class="line">3)对于每一个小文件，可以构建一个IP为key，出现次数为value的Hashmap，同时记录当前出现次数最多的那个IP地址;</span><br><span class="line"></span><br><span class="line">4)可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP;</span><br></pre></td></tr></table></figure>


<h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ul>
<li><a href="https://github.com/devuser/spark-notes" target="_blank" rel="noopener">https://github.com/devuser/spark-notes</a></li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 8实战</title>
    <url>/java-other/book--Java8%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第一部分 基础知识</span><br><span class="line"></span><br><span class="line">第1章　为什么要关心Java 8　　2</span><br><span class="line">1.1　Java怎么还在变　　4</span><br><span class="line">1.1.1　Java在编程语言生态系统中的位置　　4</span><br><span class="line">1.1.2　流处理　　6</span><br><span class="line">1.1.3　用行为参数化把代码传递给方法　　7</span><br><span class="line">1.1.4　并行与共享的可变数据　　7</span><br><span class="line">1.1.5　Java需要演变　　8</span><br><span class="line">1.2　Java中的函数　　8</span><br><span class="line">1.2.1　方法和Lambda作为一等公民　　9</span><br><span class="line">1.2.2　传递代码：一个例子　　11</span><br><span class="line">1.2.3　从传递方法到Lambda　　12</span><br><span class="line">1.3　流　　13</span><br><span class="line">1.4　default 方法　　17</span><br><span class="line">1.5　来自函数式编程的其他好思想　　18</span><br><span class="line">1.6　小结　　19</span><br><span class="line"></span><br><span class="line">第2章　通过行为参数化传递代码　　20</span><br><span class="line">2.1　应对不断变化的需求　　21</span><br><span class="line">2.1.1　初试牛刀：筛选绿苹果　　21</span><br><span class="line">2.1.2　再展身手：把颜色作为参数　　21</span><br><span class="line">2.1.3　第三次尝试：对你能想到的每个属性做筛选　　22</span><br><span class="line">2.2　行为参数化　　23</span><br><span class="line">2.3　对付啰嗦　　27</span><br><span class="line">2.3.1　匿名类　　28</span><br><span class="line">2.3.2　第五次尝试：使用匿名类　　28</span><br><span class="line">2.3.3　第六次尝试：使用Lambda表达式　　30</span><br><span class="line">2.3.4　第七次尝试：将List类型抽象化　　31</span><br><span class="line">2.4　真实的例子　　31</span><br><span class="line">2.4.1　用Comparator来排序　　31</span><br><span class="line">2.4.2　用Runnable执行代码块　　32</span><br><span class="line">2.4.3　GUI事件处理　　32</span><br><span class="line">2.5　小结　　33</span><br><span class="line"></span><br><span class="line">第3章　Lambda表达式　　34</span><br><span class="line">3.1　Lambda管中窥豹　　35</span><br><span class="line">3.2　在哪里以及如何使用Lambda　　37</span><br><span class="line">3.2.1　函数式接口　　37</span><br><span class="line">3.2.2　函数描述符　　39</span><br><span class="line">3.3　把Lambda付诸实践：环绕执行模式　　41</span><br><span class="line">3.3.1　第1步记得行为参数化　　41</span><br><span class="line">3.3.2　第2步：使用函数式接口来传递行为　　42</span><br><span class="line">3.3.3　第3步：执行一个行为　　42</span><br><span class="line">3.3.4　第4步：传递Lambda　　42</span><br><span class="line">3.4　使用函数式接口　　43</span><br><span class="line">3.4.1　Predicate　　44</span><br><span class="line">3.4.2　Consumer　　44</span><br><span class="line">3.4.3　Function　　45</span><br><span class="line">3.5　类型检查、类型推断以及限制　　49</span><br><span class="line">3.5.1　类型检查　　49</span><br><span class="line">3.5.2　同样的Lambda，不同的函数式接口　　50</span><br><span class="line">3.5.3　类型推断　　51</span><br><span class="line">3.5.4　使用局部变量　　52</span><br><span class="line">3.6　方法引用　　53</span><br><span class="line">3.6.1　管中窥豹　　53</span><br><span class="line">3.6.2　构造函数引用　　55</span><br><span class="line">3.7　Lambda和方法引用实战　　57</span><br><span class="line">3.7.1　第1步：传递代码　　58</span><br><span class="line">3.7.2　第2步：使用匿名类　　58</span><br><span class="line">3.7.3　第3步：使用Lambda表达式　　58</span><br><span class="line">3.7.4　第4步：使用方法引用　　59</span><br><span class="line">3.8　复合Lambda表达式的有用方法　　59</span><br><span class="line">3.8.1　比较器复合　　60</span><br><span class="line">3.8.2　谓词复合　　60</span><br><span class="line">3.8.3　函数复合　　61</span><br><span class="line">3.9　数学中的类似思想　　62</span><br><span class="line">3.9.1　积分　　62</span><br><span class="line">3.9.2　与Java 8的Lambda联系起来　　63</span><br><span class="line">3.10　小结　　64</span><br><span class="line"></span><br><span class="line">第二部分 函数式数据处理</span><br><span class="line"></span><br><span class="line">第4章　引入流　　68</span><br><span class="line">4.1　流是什么　　68</span><br><span class="line">4.2　流简介　　72</span><br><span class="line">4.3　流与集合　　74</span><br><span class="line">4.3.1　只能遍历一次　　75</span><br><span class="line">4.3.2　外部迭代与内部迭代　　76</span><br><span class="line">4.4　流操作　　78</span><br><span class="line">4.4.1　中间操作　　78</span><br><span class="line">4.4.2　终端操作　　79</span><br><span class="line">4.4.3　使用流　　80</span><br><span class="line">4.5　小结　　81</span><br><span class="line"></span><br><span class="line">第5章　使用流　　82</span><br><span class="line">5.1　筛选和切片　　83</span><br><span class="line">5.1.1　用谓词筛选　　83</span><br><span class="line">5.1.2　筛选各异的元素　　83</span><br><span class="line">5.1.3　截短流　　84</span><br><span class="line">5.1.4　跳过元素　　85</span><br><span class="line">5.2　映射　　86</span><br><span class="line">5.2.1　对流中每一个元素应用函数　　86</span><br><span class="line">5.2.2　流的扁平化　　87</span><br><span class="line">5.3　查找和匹配　　90</span><br><span class="line">5.3.1　检查谓词是否至少匹配一个元素　　90</span><br><span class="line">5.3.2　检查谓词是否匹配所有元素　　90</span><br><span class="line">5.3.3　查找元素　　91</span><br><span class="line">5.3.4　查找第一个元素　　92</span><br><span class="line">5.4　归约　　92</span><br><span class="line">5.4.1　元素求和　　93</span><br><span class="line">5.4.2　最大值和最小值　　94</span><br><span class="line">5.5　付诸实践　　97</span><br><span class="line">5.5.1　领域：交易员和交易　　98</span><br><span class="line">5.5.2　解答　　99</span><br><span class="line">5.6　数值流　　101</span><br><span class="line">5.6.1　原始类型流特化　　101</span><br><span class="line">5.6.2　数值范围　　102</span><br><span class="line">5.6.3　数值流应用：勾股数　　103</span><br><span class="line">5.7　构建流　　105</span><br><span class="line">5.7.1　由值创建流　　106</span><br><span class="line">5.7.2　由数组创建流　　106</span><br><span class="line">5.7.3　由文件生成流　　106</span><br><span class="line">5.7.4　由函数生成流：创建无限流　　107</span><br><span class="line">5.8　小结　　110</span><br><span class="line"></span><br><span class="line">第6章　用流收集数据　　111</span><br><span class="line">6.1　收集器简介　　112</span><br><span class="line">6.1.1　收集器用作高级归约　　112</span><br><span class="line">6.1.2　预定义收集器　　113</span><br><span class="line">6.2　归约和汇总　　114</span><br><span class="line">6.2.1　查找流中的最大值和最小值　　114</span><br><span class="line">6.2.2　汇总　　115</span><br><span class="line">6.2.3　连接字符串　　116</span><br><span class="line">6.2.4　广义的归约汇总　　117</span><br><span class="line">6.3　分组　　120</span><br><span class="line">6.3.1　多级分组　　121</span><br><span class="line">6.3.2　按子组收集数据　　122</span><br><span class="line">6.4　分区　　126</span><br><span class="line">6.4.1　分区的优势　　126</span><br><span class="line">6.4.2　将数字按质数和非质数分区　　128</span><br><span class="line">6.5　收集器接口　　129</span><br><span class="line">6.5.1　理解Collector接口声明的方法　　130</span><br><span class="line">6.5.2　全部融合到一起　　134</span><br><span class="line">6.6　开发你自己的收集器以获得更好的性能　　135</span><br><span class="line">6.6.1　仅用质数做除数　　136</span><br><span class="line">6.6.2　比较收集器的性能　　139</span><br><span class="line">6.7　小结　　140</span><br><span class="line"></span><br><span class="line">第7章　并行数据处理与性能　　141</span><br><span class="line">7.1　并行流　　141</span><br><span class="line">7.1.1　将顺序流转换为并行流　　142</span><br><span class="line">7.1.2　测量流性能　　144</span><br><span class="line">7.1.3　正确使用并行流　　147</span><br><span class="line">7.1.4　高效使用并行流　　148</span><br><span class="line">7.2　分支&#x2F;合并框架　　149</span><br><span class="line">7.2.1　使用RecursiveTask　　149</span><br><span class="line">7.2.2　使用分支&#x2F;合并框架的最佳做法　　153</span><br><span class="line">7.2.3　工作窃取　　154</span><br><span class="line">7.3　Spliterator　　155</span><br><span class="line">7.3.1　拆分过程　　155</span><br><span class="line">7.3.2　实现你自己的Spliterator　　157</span><br><span class="line">7.4　小结　　162</span><br><span class="line"></span><br><span class="line">第三部分 高效Java 8编程</span><br><span class="line"></span><br><span class="line">第8章　重构、测试和调试　　164</span><br><span class="line">8.1　为改善可读性和灵活性重构代码　　164</span><br><span class="line">8.1.1　改善代码的可读性　　165</span><br><span class="line">8.1.2　从匿名类到Lambda表达式的转换　　165</span><br><span class="line">8.1.3　从Lambda表达式到方法引用的转换　　166</span><br><span class="line">8.1.4　从命令式的数据处理切换到Stream　　167</span><br><span class="line">8.1.5　增加代码的灵活性　　168</span><br><span class="line">8.2　使用Lambda重构面向对象的设计模式　　170</span><br><span class="line">8.2.1　策略模式　　171</span><br><span class="line">8.2.2　模板方法　　172</span><br><span class="line">8.2.3　观察者模式　　173</span><br><span class="line">8.2.4　责任链模式　　175</span><br><span class="line">8.2.5　工厂模式　　177</span><br><span class="line">8.3　测试Lambda表达式　　178</span><br><span class="line">8.3.1　测试可见Lambda函数的行为　　179</span><br><span class="line">8.3.2　测试使用Lambda的方法的行为　　179</span><br><span class="line">8.3.3　将复杂的Lambda表达式分到不同的方法　　180</span><br><span class="line">8.3.4　高阶函数的测试　　180</span><br><span class="line">8.4　调试　　181</span><br><span class="line">8.4.1　查看栈跟踪　　181</span><br><span class="line">8.4.2　使用日志调试　　183</span><br><span class="line">8.5　小结　　184</span><br><span class="line"></span><br><span class="line">第9章　默认方法　　 185</span><br><span class="line">9.1　不断演进的API　　 187</span><br><span class="line">9.1.1　初始版本的API　　188</span><br><span class="line">9.1.2　第二版API　　188</span><br><span class="line">9.2　概述默认方法　　190</span><br><span class="line">9.3　默认方法的使用模式　　192</span><br><span class="line">9.3.1　可选方法　　192</span><br><span class="line">9.3.2　行为的多继承　　192</span><br><span class="line">9.4　解决冲突的规则　　196</span><br><span class="line">9.4.1　解决问题的三条规则　　196</span><br><span class="line">9.4.2　选择提供了最具体实现的默认方法的接口　　197</span><br><span class="line">9.4.3　冲突及如何显式地消除歧义　　198</span><br><span class="line">9.4.4　菱形继承问题　　200</span><br><span class="line">9.5　小结　　201</span><br><span class="line"></span><br><span class="line">第10章　用Optional取代null　　202</span><br><span class="line">10.1　如何为缺失的值建模　　 203</span><br><span class="line">10.1.1　采用防御式检查减少Null-PointerException　　203</span><br><span class="line">10.1.2　null带来的种种问题　　204</span><br><span class="line">10.1.3　其他语言中null的替代品　　205</span><br><span class="line">10.2　Optional类入门　　206</span><br><span class="line">10.3　应用Optional的几种模式　　 207</span><br><span class="line">10.3.1　创建Optional对象　　208</span><br><span class="line">10.3.2　使用map从Optional对象中提取和转换值　　208</span><br><span class="line">10.3.3　使用flatMap链接Optional对象　　209</span><br><span class="line">10.3.4　默认行为及解引用Optional对象　　213</span><br><span class="line">10.3.5　两个Optional对象的组合　　213</span><br><span class="line">10.3.6　使用filter剔除特定的值　　214</span><br><span class="line">10.4　使用Optional的实战示例　　 216</span><br><span class="line">10.4.1　用Optional封装可能为null的值　　216</span><br><span class="line">10.4.2　异常与Optional的对比　　217</span><br><span class="line">10.4.3　把所有内容整合起来　　218</span><br><span class="line">10.5　小结　　219</span><br><span class="line"></span><br><span class="line">第11章　CompletableFuture：组合式异步编程　　220</span><br><span class="line">11.1　Future接口　　222</span><br><span class="line">11.1.1　Future接口的局限性　　223</span><br><span class="line">11.1.2　使用CompletableFuture构建异步应用　　223</span><br><span class="line">11.2　实现异步API　　 224</span><br><span class="line">11.2.1　将同步方法转换为异步方法　　225</span><br><span class="line">11.2.2　错误处理　　227</span><br><span class="line">11.3　让你的代码免受阻塞之苦　　228</span><br><span class="line">11.3.1　使用并行流对请求进行并行操作　　229</span><br><span class="line">11.3.2　使用CompletableFuture发起异步请求　　230</span><br><span class="line">11.3.3　寻找更好的方案　　232</span><br><span class="line">11.3.4　使用定制的执行器　　233</span><br><span class="line">11.4　对多个异步任务进行流水线操作　　234</span><br><span class="line">11.4.1　实现折扣服务　　235</span><br><span class="line">11.4.2　使用Discount服务　　236</span><br><span class="line">11.4.3　构造同步和异步操作　　237</span><br><span class="line">11.4.4　将两个Completable-Future对象整合起来，无论它们是否存在依赖　　239</span><br><span class="line">11.4.5　对Future和Completable-Future的回顾　　241</span><br><span class="line">11.5　响应CompletableFuture的completion事件　　242</span><br><span class="line">11.5.1　对最佳价格查询器应用的优化　　243</span><br><span class="line">11.5.2　付诸实践　　244</span><br><span class="line">11.6　小结　　245</span><br><span class="line"></span><br><span class="line">第12章　新的日期和时间API　　246</span><br><span class="line">12.1　LocalDate、LocalTime、Instant、Duration以及Period　　247</span><br><span class="line">12.1.1　使用LocalDate和LocalTime　　247</span><br><span class="line">12.1.2　合并日期和时间　　248</span><br><span class="line">12.1.3　机器的日期和时间格式　　249</span><br><span class="line">12.1.4　定义Duration或Period　　249</span><br><span class="line">12.2　操纵、解析和格式化日期　　251</span><br><span class="line">12.2.1　使用TemporalAdjuster　　253</span><br><span class="line">12.2.2　打印输出及解析日期－时间对象　　255</span><br><span class="line">12.3　处理不同的时区和历法　　256</span><br><span class="line">12.3.1　利用和UTC&#x2F;格林尼治时间的固定偏差计算时区　　257</span><br><span class="line">12.3.2　使用别的日历系统　　258</span><br><span class="line">12.4　小结　　259</span><br><span class="line"></span><br><span class="line">第四部分 超越Java 8</span><br><span class="line"></span><br><span class="line">第13章　函数式的思考　　262</span><br><span class="line">13.1　实现和维护系统　　262</span><br><span class="line">13.1.1　共享的可变数据　　263</span><br><span class="line">13.1.2　声明式编程　　264</span><br><span class="line">13.1.3　为什么要采用函数式编程　　265</span><br><span class="line">13.2　什么是函数式编程　　265</span><br><span class="line">13.2.1　函数式Java编程　　266</span><br><span class="line">13.2.2　引用透明性　　268</span><br><span class="line">13.2.3　面向对象的编程和函数式编程的对比　　 268</span><br><span class="line">13.2.4　函数式编程实战　　269</span><br><span class="line">13.3　递归和迭代　　271</span><br><span class="line">13.4　小结　　274</span><br><span class="line"></span><br><span class="line">第14章　函数式编程的技巧　　275</span><br><span class="line">14.1　无处不在的函数　　275</span><br><span class="line">14.1.1　高阶函数　　275</span><br><span class="line">14.1.2　科里化　　277</span><br><span class="line">14.2　持久化数据结构　　278</span><br><span class="line">14.2.1　破坏式更新和函数式更新的比较　　279</span><br><span class="line">14.2.2　另一个使用Tree的例子　　281</span><br><span class="line">14.2.3　采用函数式的方法　　282</span><br><span class="line">14.3　Stream的延迟计算　　283</span><br><span class="line">14.3.1　自定义的Stream　　 283</span><br><span class="line">14.3.2　创建你自己的延迟列表　　286</span><br><span class="line">14.4　模式匹配　　290</span><br><span class="line">14.4.1　访问者设计模式　　291</span><br><span class="line">14.4.2　用模式匹配力挽狂澜　　292</span><br><span class="line">14.5　杂项　　295</span><br><span class="line">14.5.1　缓存或记忆表　　295</span><br><span class="line">14.5.2　“返回同样的对象”意味着什么　　296</span><br><span class="line">14.5.3　结合器　　296</span><br><span class="line">14.6　小结　　297</span><br><span class="line"></span><br><span class="line">第15章　面向对象和函数式编程的混合：Java 8和Scala的比较　　 299</span><br><span class="line"></span><br><span class="line">15.1　Scala简介　　300</span><br><span class="line">15.1.1　你好，啤酒　　300</span><br><span class="line">15.1.2　基础数据结构：List、Set、Map、Tuple、Stream以及Option　　302</span><br><span class="line">15.2　函数　　306</span><br><span class="line">15.2.1　Scala中的一等函数　　307</span><br><span class="line">15.2.2　匿名函数和闭包　　307</span><br><span class="line">15.2.3　科里化　　309</span><br><span class="line">15.3　类和trait　　310</span><br><span class="line">15.3.1　更加简洁的Scala类　　310</span><br><span class="line">15.3.2　Scala的trait与Java 8的接口对比　　311</span><br><span class="line">15.4　小结　　312</span><br><span class="line"></span><br><span class="line">第16章　结论以及Java的未来　　313</span><br><span class="line">16.1　回顾Java 8的语言特性　　 313</span><br><span class="line">16.1.1　行为参数化（Lambda 以及方法引用）　　314</span><br><span class="line">16.1.2　流　　314</span><br><span class="line">16.1.3　CompletableFuture　　315</span><br><span class="line">16.1.4　Optional　　315</span><br><span class="line">16.1.5　默认方法　　316</span><br><span class="line">16.2　Java 的未来　　316</span><br><span class="line">16.2.1　集合　　316</span><br><span class="line">16.2.2　类型系统的改进　　317</span><br><span class="line">16.2.3　模式匹配　　318</span><br><span class="line">16.2.4　更加丰富的泛型形式　　319</span><br><span class="line">16.2.5　对不变性的更深层支持　　321</span><br><span class="line">16.2.6　值类型　　322</span><br><span class="line">16.3　写在最后的话　　325</span><br><span class="line"></span><br><span class="line">附录A　其他语言特性的更新　　326</span><br><span class="line">附录B　类库的更新　　330</span><br><span class="line">附录C　如何以并发方式在同一个流上执行多种操作　　338</span><br><span class="line">附录D　Lambda表达式和JVM 字节码　　346</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>三板斧：阿里巴巴管理之道</title>
    <url>/java-other/book--%E4%B8%89%E6%9D%BF%E6%96%A7%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E7%AE%A1%E7%90%86%E4%B9%8B%E9%81%93/</url>
    <content><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第一章 三板斧管理之道解读 &#x2F; 1</span><br><span class="line"></span><br><span class="line">第一节 三板斧的起源 &#x2F; 3</span><br><span class="line">三板斧的由来 &#x2F; 3</span><br><span class="line">何为三板斧？ &#x2F; 4</span><br><span class="line"></span><br><span class="line">第二节 三板斧的定义与详解 &#x2F; 9</span><br><span class="line">关于基层管理者 &#x2F; 9</span><br><span class="line">关于中层管理者 &#x2F; 12</span><br><span class="line">关于高层管理者 &#x2F; 14</span><br><span class="line"></span><br><span class="line">第三节 三板斧的戒定慧 &#x2F; 19</span><br><span class="line">三板斧之戒：戒律 &#x2F; 19</span><br><span class="line">三板斧之定：定心 &#x2F; 20</span><br><span class="line">三板斧之慧：智慧 &#x2F; 29</span><br><span class="line"></span><br><span class="line">第二章 借假修真——项目操练解析 &#x2F; 35</span><br><span class="line"></span><br><span class="line">第一节 项目雏形要考虑的因素 &#x2F; 37</span><br><span class="line">看清你的竞争对手在哪里 &#x2F; 37</span><br><span class="line">拷问关键问题 &#x2F; 38</span><br><span class="line">你的定位是什么 &#x2F; 40</span><br><span class="line">共享经济对闲置资源的整合 &#x2F; 43</span><br><span class="line">拷问关键问题 &#x2F; 44</span><br><span class="line">人才是互联网竞争中的核心 &#x2F; 45</span><br><span class="line">越厉害的团队越容易犯错 &#x2F; 46</span><br><span class="line">传统行业互联网+ &#x2F; 48</span><br><span class="line">拷问关键问题 &#x2F; 49</span><br><span class="line">众筹运营 &#x2F; 51</span><br><span class="line">关键问题解析 &#x2F; 52</span><br><span class="line"></span><br><span class="line">第二节 在混沌中破冰 &#x2F; 55</span><br><span class="line">系统化思考商业问题的工具 &#x2F; 62</span><br><span class="line">团队要在分工中合作 &#x2F; 63</span><br><span class="line"></span><br><span class="line">第三节 项目立项的修炼 &#x2F; 65</span><br><span class="line">导师点评 &#x2F; 74</span><br><span class="line"></span><br><span class="line">第四节 整合上容易遇到的坑 &#x2F; 81</span><br><span class="line"></span><br><span class="line">第五节 项目落地的考量 &#x2F; 89</span><br><span class="line">要有打磨的精神和体系 &#x2F; 89</span><br><span class="line">赚钱，那是创业者的根 &#x2F; 91</span><br><span class="line">最美的风景在哪里？ &#x2F; 93</span><br><span class="line">走遍天下找诸葛亮 &#x2F; 95</span><br><span class="line">太开心的团队死得最快 &#x2F; 95</span><br><span class="line">老板不能心太软 &#x2F; 96</span><br><span class="line">把情感融入到你的产品 &#x2F; 97</span><br><span class="line">我用产品表达对世界的理解 &#x2F; 99</span><br><span class="line">从一个场景入手 &#x2F; 100</span><br><span class="line">成功必须有胸怀 &#x2F; 103</span><br><span class="line">时间相对论 &#x2F; 104</span><br><span class="line">零摩擦才是新商业 &#x2F; 106</span><br><span class="line">弱关系强链接 &#x2F; 106</span><br><span class="line">出一个决心也是结果 &#x2F; 110</span><br><span class="line">情怀是有成本的 &#x2F; 111</span><br><span class="line"></span><br><span class="line">第六节 商业地产O2O的乡村实验之路 &#x2F; 115</span><br><span class="line"></span><br><span class="line">第三章 借事修人 &#x2F; 127</span><br><span class="line"></span><br><span class="line">第一节 第一轮团队建设 &#x2F; 129</span><br><span class="line">关于断言 &#x2F; 129</span><br><span class="line">不破不立 &#x2F; 134</span><br><span class="line">指明方向 &#x2F; 135</span><br><span class="line">奖惩制度 &#x2F; 136</span><br><span class="line">三板斧管理之道 &#x2F; 137</span><br><span class="line">271：去与留 &#x2F; 143</span><br><span class="line">直言不讳是不成熟的表现 &#x2F; 147</span><br><span class="line"></span><br><span class="line">第二节 团队建设锦囊 &#x2F; 152</span><br><span class="line">三板斧亦如道场 &#x2F; 152</span><br><span class="line">自卑能成大业 &#x2F; 155</span><br><span class="line">慈不长兵，义不长财 &#x2F; 162</span><br><span class="line"></span><br><span class="line">第三节 管理者的故事 &#x2F; 165</span><br><span class="line">管理者：任重而道远 &#x2F; 165</span><br><span class="line">管理者的目的：给人方向 &#x2F; 170</span><br><span class="line">无能管理者下场：崖山海战 &#x2F; 174</span><br><span class="line"></span><br><span class="line">第四节 移动互联网产业升级的背后思考 &#x2F; 176</span><br><span class="line">天猫下凡 &#x2F; 176</span><br><span class="line">未来的商业逻辑 &#x2F; 179</span><br><span class="line">移动互联网对于商业逻辑和互联网带来的变化 &#x2F; 191</span><br><span class="line">MOT（关键时刻） &#x2F; 201</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解JVM垃圾收集机制GC</title>
    <url>/java/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h2 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h2><h3 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h3><p>最基础的收集算法是“标记-清除”(Mark-Sweep)算法，分两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。</p>
<a id="more"></a>

<p>不足：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能导致以后在程序运行过程需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一个的垃圾收集动作。</p>
<h3 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h3><p>为了解决效率问题，一种称为复制(Copying)的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块内存用完了，就将还存活着的对象复制到另外一块上，然后再把已经使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。代价是内存缩小为原来的一半。</p>
<p>商业虚拟机用这个回收算法来回收新生代。IBM研究表明98%的对象是“朝生夕死“，不需要按照1-1的比例来划分内存空间，而是将内存分为一块较大的”Eden“空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性复制到另外一个Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。Hotspot虚拟机默认Eden和Survivor的比例是8-1.即每次可用整个新生代的90%, 只有一个survivor，即1/10被”浪费“。当然，98%的对象回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够时，需要依赖其他内存(老年代)进行分配担保(Handle Promotion).</p>
<p>如果另外一块survivor空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。</p>
<h3 id="eden-survivor复制过程概述"><a href="#eden-survivor复制过程概述" class="headerlink" title="eden survivor复制过程概述"></a>eden survivor复制过程概述</h3><p>Eden Space字面意思是伊甸园，对象被创建的时候首先放到这个区域，进行垃圾回收后，不能被回收的对象被放入到空的survivor区域。</p>
<p>Survivor Space幸存者区，用于保存在eden space内存区域中经过垃圾回收后没有被回收的对象。Survivor有两个，分别为To Survivor、 From Survivor，这个两个区域的空间大小是一样的。执行垃圾回收的时候Eden区域不能被回收的对象被放入到空的survivor（也就是To Survivor，同时Eden区域的内存会在垃圾回收的过程中全部释放），另一个survivor（即From Survivor）里不能被回收的对象也会被放入这个survivor（即To Survivor），然后To Survivor 和 From Survivor的标记会互换，始终保证一个survivor是空的。</p>
<p>为啥需要两个survivor？因为需要一个完整的空间来复制过来。当满的时候晋升。每次都往标记为to的里面放，然后互换，这时from已经被清空，可以当作to了。</p>
<h3 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h3><p>复制收集算法在对象成活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以，老年代一般不能直接选用这种算法。</p>
<p>根据老年代的特点，有人提出一种”标记-整理“Mark-Compact算法，标记过程仍然和标记-清除一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理端边界以外的内存.</p>
<h3 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h3><p>当前商业虚拟机的垃圾收集都采用”分代收集“(Generational Collection)算法，这种算法根据对象存活周期的不同将内存划分为几块。一般把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代，每次垃圾收集时都发现大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率较高，没有额外的空间对它进行分配担保，就必须使用”标记-清理“和”标记-整理“算法来进行回收。</p>
<h2 id="HotSpot算法实现"><a href="#HotSpot算法实现" class="headerlink" title="HotSpot算法实现"></a>HotSpot算法实现</h2><p>在Java语言中，可作为GC Roots的对象包括下面几种：</p>
<ul>
<li>虚拟机栈(栈帧中的本地变量表)中引用的对象</li>
<li>方法去中类静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
<li>本地方法栈中JNI(即一般说的Native方法)引用的对象</li>
</ul>
<p>从可达性分析中从GC Roots节点找引用链这个操作为例，可作为GC Roots的节点主要在全局性的引用(例如常量或类静态属性)与执行上下文(例如栈帧中的本地变量表)中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查里面的引用，必然消耗很多时间。</p>
<p>可达性分析对执行时间的敏感还体现在GC停顿上，因为这项分析工作必须在一个能确保一致性的快照中进行–这里”一致性“的意思是指整个分析期间整个执行系统看起来就像被冻结在某个时间点，不可以出现分析过程中对象引用关系还在不断变化的情况，该点不满足的话分析结果准确性就无法得到保证。这点是导致GC进行时必须停顿所有Java执行线程(Sun公司将这件事情称为”Stop The World“)的一个重要原因，即使是在号称(几乎)不会发生停顿的CMS收集器中，枚举根节点时也必须停顿的。</p>
<p>安全点，Safepoint</p>
<h2 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h2><h3 id="Serial-收集器"><a href="#Serial-收集器" class="headerlink" title="Serial 收集器"></a>Serial 收集器</h3><p>标记-复制。</p>
<p>单线程，一个CPU或一条收集线程去完成垃圾收集工作，收集时必须暂停其他所有的工作线程，直到它结束。</p>
<p>虽然如此，它依然是虚拟机运行在Client模式下的默认<strong>新生代</strong>收集器。简单而高效。</p>
<h3 id="ParNew-收集器"><a href="#ParNew-收集器" class="headerlink" title="ParNew 收集器"></a>ParNew 收集器</h3><p>ParNew是Serial收集器的多线程版本。Server模式下默认<strong>新生代</strong>收集器，除了Serial收集器之外，只有它能与CMS收集器配合工作。</p>
<h3 id="并行-Parallel"><a href="#并行-Parallel" class="headerlink" title="并行 Parallel"></a>并行 Parallel</h3><p>指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。</p>
<h3 id="并发-Concurrent"><a href="#并发-Concurrent" class="headerlink" title="并发 Concurrent"></a>并发 Concurrent</h3><p>指用户线程与垃圾收集线程同时执行(但不一定是并行的，可能会交替执行)，用户程序再继续运行，而垃圾收集程序运行于另一个CPU上。</p>
<h3 id="Parallel-Scavenge-收集器"><a href="#Parallel-Scavenge-收集器" class="headerlink" title="Parallel Scavenge 收集器"></a>Parallel Scavenge 收集器</h3><p>Parallel Scavenge 收集器是一个<strong>新生代</strong>收集器，它也是使用复制算法的收集器。看上去来ParNew一样，有什么特别？</p>
<p>Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS等收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间。而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量(Throughput)。所谓吞吐量就是CPU用于运行用户代码的时间和CPU总消耗时间的比值，即吞吐量 = 运行用户代码时间 / (运行用户代码时间+垃圾收集时间)，虚拟机总共运行了100min，其中垃圾收集花费了1min，那吞吐量就是99%.</p>
<div class="note primary">
            <p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效地利用CPU时间，主要适合在后台运算而不需要太多交互的任务。</p>
          </div>

<p>Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间 <code>-XX:MaxGCPauseMillis</code>以及直接设置吞吐量大小的<code>-XX:GCTimeRatio</code>。</p>
<h3 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h3><p>Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器。给Client模式下的虚拟机使用。</p>
<p>新生代采用复制算法，暂停所有用户线程；</p>
<p>老年代采用标记-整理算法，暂停所有用户线程；</p>
<h3 id="Parallel-Old-收集器"><a href="#Parallel-Old-收集器" class="headerlink" title="Parallel Old 收集器"></a>Parallel Old 收集器</h3><p>这里注意，Parallel Scavage 收集器架构中本身有PS MarkSweep收集器来收集老年代，并非直接使用了Serial Old,但二者接近。本人win10 64位系统，jdk1.8.0_102，测试默认垃圾收集器为：<strong>PS MarkSweep *<em>和 *</em>PS Scavenge</strong>。 也就是说Java8的默认并不是G1。</p>
<p>这是”吞吐量优先“，注重吞吐量以及CPU资源敏感的场合都可以优先考虑<strong>Parallel Scavenge</strong>和<strong>Parallel Old(PS Mark Sweep)</strong>。<strong>Java8 默认就是这个</strong>。</p>
<h3 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h3><p>CMS(Concurrent Mark Sweep) 收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类尤其重视服务的响应速度，希望系统停顿时间最短。CMS收集器就非常符合这类应用的需求。</p>
<p>CMS基于 <code>标记-清除</code>算法实现。整个过程分为4个步骤：</p>
<ol>
<li><p>初始标记(CMS initial mark)     -stop the world</p>
</li>
<li><p>并发标记(CMS concurrent mark)</p>
</li>
<li><p>重新标记(CMS remark)           -stop the world</p>
</li>
<li><p>并发清除(CMS concurrent sweep)</p>
</li>
<li><p>初始标记，重新标记这两个步骤仍然需要Stop The World, 初始标记仅仅标记一下GC Roots能直接关联的对象，速度很快。</p>
</li>
<li><p>并发标记就是进行GC Roots Tracing的过程；</p>
</li>
<li><p>而重新标记阶段则是为了修正并发标记期间因为用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。这个阶段停顿比初始标记稍微长，但远比并发标记的时间短。</p>
</li>
<li><p>整个过程耗时最长的并发标记和并发清除过程，收集器都可以与用户线程一起工作。总体上来说，CMS收集器的内存回收过程与用户线程一起并发执行的。</p>
</li>
</ol>
<p>CMS特点：并发收集，低停顿。</p>
<p><strong>缺点</strong></p>
<p>1.CMS收集器对CPU资源非常敏感。默认启动的回收线程数是(CPU+3)/4. 当CPU 4个以上时，并发回收垃圾收集线程不少于25%的CPU资源。</p>
<p>2.CMS收集器无法处理浮动垃圾(Floating Garbage), 可能出现”Concurrent Mode Failure“失败而导致另一次Full GC的产生。由于CMS并发清理时，用户线程还在运行，伴随产生新垃圾，而这一部分出现在标记之后，只能下次GC时再清理。这一部分垃圾就称为”浮动垃圾“。</p>
<p>由于CMS运行时还需要给用户空间继续运行，则不能等老年代几乎被填满再进行收集，需要预留一部分空间提供并发收集时，用户程序运行。JDK1.6中，CMS启动阈值为92%. 若预留内存不够用户使用，则出现一次<code>Concurent Mode Failure</code>失败。这时虚拟机启动后备预案，临时启用Serial Old收集老年代，这样停顿时间很长。</p>
<p>3.CMS基于”标记-清除“算法实现的，则会产生大量空间碎片，空间碎片过多时，没有连续空间分配给大对象，不得不提前触发一次FUll GC。当然可以开启-XX:+UseCMSCompactAtFullCollection(默认开)，在CMS顶不住要FullGC时开启内存碎片合并整理过程。内存整理过程是无法并发的，空间碎片问题没了，但停顿时间变长。</p>
<p><strong>面试题：CMS一共会有几次STW</strong></p>
<ol>
<li><p>首先，回答两次，初始标记和重新标记需要。</p>
</li>
<li><p>然后，CMS并发的代价是预留空间给用户，预留不足的时候触发FUllGC，这时Serail Old会STW.</p>
</li>
<li><p>然后，CMS是标记-清除算法，导致空间碎片，则没有连续空间分配大对象时，FUllGC, 而FUllGC会开始碎片整理， STW.</p>
</li>
</ol>
<p><strong>即2次或多次。</strong></p>
<h2 id="CMS什么时候FUll-GC"><a href="#CMS什么时候FUll-GC" class="headerlink" title="CMS什么时候FUll GC"></a>CMS什么时候FUll GC</h2><p>除直接调用System.gc外，触发Full GC执行的情况有如下四种。</p>
<h3 id="1-旧生代空间不足"><a href="#1-旧生代空间不足" class="headerlink" title="1. 旧生代空间不足"></a>1. 旧生代空间不足</h3><p>旧生代空间只有在新生代对象转入及创建为大对象、大数组时才会出现不足的现象，当执行Full GC后空间仍然不足，则抛出如下错误：<br><code>java.lang.OutOfMemoryError: Java heap space</code><br>为避免以上两种状况引起的FullGC，调优时应尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。</p>
<h3 id="2-Permanet-Generation空间满"><a href="#2-Permanet-Generation空间满" class="headerlink" title="2. Permanet Generation空间满"></a>2. Permanet Generation空间满</h3><p>PermanetGeneration中存放的为一些class的信息等，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation可能会被占满，在未配置为采用CMS GC的情况下会执行Full GC。如果经过Full GC仍然回收不了，那么JVM会抛出如下错误信息：<br><code>java.lang.OutOfMemoryError: PermGen space</code><br>为避免Perm Gen占满造成Full GC现象，可采用的方法为增大Perm Gen空间或转为使用CMS GC。</p>
<h3 id="3-CMS-GC时出现promotion-failed和concurrent-mode-failure"><a href="#3-CMS-GC时出现promotion-failed和concurrent-mode-failure" class="headerlink" title="3. CMS GC时出现promotion failed和concurrent mode failure"></a>3. CMS GC时出现promotion failed和concurrent mode failure</h3><p>对于采用CMS进行旧生代GC的程序而言，尤其要注意GC日志中是否有promotion failed和concurrent mode failure两种状况，当这两种状况出现时可能会触发Full GC。<br>promotion failed是在进行Minor GC时，survivor space放不下、对象只能放入旧生代，而此时旧生代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入旧生代，而此时旧生代空间不足造成的。<br>应对措施为：增大survivor space、旧生代空间或调低触发并发GC的比率，但在JDK 5.0+、6.0+的版本中有可能会由于JDK的bug29导致CMS在remark完毕后很久才触发sweeping动作。对于这种状况，可通过设置-XX:CMSMaxAbortablePrecleanTime=5（单位为ms）来避免。</p>
<h3 id="4-统计得到的Minor-GC晋升到旧生代的平均大小大于旧生代的剩余空间"><a href="#4-统计得到的Minor-GC晋升到旧生代的平均大小大于旧生代的剩余空间" class="headerlink" title="4. 统计得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间"></a>4. 统计得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间</h3><p>这是一个较为复杂的触发情况，Hotspot为了避免由于新生代对象晋升到旧生代导致旧生代空间不足的现象，在进行Minor GC时，做了一个判断，如果之前统计所得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间，那么就直接触发Full GC。</p>
<p>例如程序第一次触发MinorGC后，有6MB的对象晋升到旧生代，那么当下一次Minor GC发生时，首先检查旧生代的剩余空间是否大于6MB，如果小于6MB，则执行Full GC。</p>
<p>当新生代采用PSGC时，方式稍有不同，PS GC是在Minor GC后也会检查，例如上面的例子中第一次Minor GC后，PS GC会检查此时旧生代的剩余空间是否大于6MB，如小于，则触发对旧生代的回收。</p>
<p>除了以上4种状况外，对于使用RMI来进行RPC或管理的Sun JDK应用而言，默认情况下会一小时执行一次Full GC。可通过在启动时通过- java-Dsun.rmi.dgc.client.gcInterval=3600000来设置Full GC执行的间隔时间或通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc。</p>
<h2 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h2><h3 id="什么是垃圾回收"><a href="#什么是垃圾回收" class="headerlink" title="什么是垃圾回收"></a>什么是垃圾回收</h3><p>首先，在了解G1之前，我们需要清楚的知道，垃圾回收是什么？简单的说垃圾回收就是回收内存中不再使用的对象。</p>
<p>垃圾回收的基本步骤</p>
<p>回收的步骤有2步：</p>
<ol>
<li><p>查找内存中不再使用的对象</p>
</li>
<li><p>释放这些对象占用的内存</p>
</li>
</ol>
<h4 id="1-查找内存中不再使用的对象"><a href="#1-查找内存中不再使用的对象" class="headerlink" title="1,查找内存中不再使用的对象"></a>1,查找内存中不再使用的对象</h4><p>那么问题来了，如何判断哪些对象不再被使用呢？我们也有2个方法：</p>
<ol>
<li><p>引用计数法<br>引用计数法就是如果一个对象没有被任何引用指向，则可视之为垃圾。这种方法的缺点就是不能检测到环的存在。</p>
</li>
<li><p>根搜索算法<br>根搜索算法的基本思路就是通过一系列名为”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。</p>
</li>
</ol>
<p>现在我们已经知道如何找出垃圾对象了，如何把这些对象清理掉呢？</p>
<h4 id="2-释放这些对象占用的内存"><a href="#2-释放这些对象占用的内存" class="headerlink" title="2. 释放这些对象占用的内存"></a>2. 释放这些对象占用的内存</h4><p>常见的方式有复制或者直接清理，但是直接清理会存在内存碎片，于是就会产生了清理再压缩的方式。</p>
<p>总得来说就产生了三种类型的回收算法。</p>
<ol>
<li><p>标记-复制</p>
</li>
<li><p>标记-清理</p>
</li>
<li><p>标记-整理</p>
</li>
</ol>
<p>基于分代的假设</p>
<p>由于对象的存活时间有长有短，所以对于存活时间长的对象，减少被gc的次数可以避免不必要的开销。这样我们就把内存分成新生代和老年代，新生代存放刚创建的和存活时间比较短的对象，老年代存放存活时间比较长的对象。这样每次仅仅清理年轻代，老年代仅在必要时时再做清理可以极大的提高GC效率，节省GC时间。</p>
<h3 id="Java垃圾收集器的历史"><a href="#Java垃圾收集器的历史" class="headerlink" title="Java垃圾收集器的历史"></a>Java垃圾收集器的历史</h3><h4 id="第一阶段，Serial（串行）收集器"><a href="#第一阶段，Serial（串行）收集器" class="headerlink" title="第一阶段，Serial（串行）收集器"></a>第一阶段，Serial（串行）收集器</h4><p>在jdk1.3.1之前，java虚拟机仅仅能使用Serial收集器。 Serial收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅是说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。</p>
<p>PS：开启Serial收集器的方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseSerialGC</span><br></pre></td></tr></table></figure>

<h4 id="第二阶段，Parallel（并行）收集器"><a href="#第二阶段，Parallel（并行）收集器" class="headerlink" title="第二阶段，Parallel（并行）收集器"></a>第二阶段，Parallel（并行）收集器</h4><p>Parallel收集器也称吞吐量收集器，相比Serial收集器，Parallel最主要的优势在于使用多线程去完成垃圾清理工作，这样可以充分利用多核的特性，大幅降低gc时间。</p>
<p>PS:开启Parallel收集器的方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseParallelGC -XX:+UseParallelOldGC</span><br></pre></td></tr></table></figure>

<h4 id="第三阶段，CMS（并发）收集器"><a href="#第三阶段，CMS（并发）收集器" class="headerlink" title="第三阶段，CMS（并发）收集器"></a>第三阶段，CMS（并发）收集器</h4><p>CMS收集器在Minor GC时会暂停所有的应用线程，并以多线程的方式进行垃圾回收。在Full GC时不再暂停应用线程，而是使用若干个后台线程定期的对老年代空间进行扫描，及时回收其中不再使用的对象。</p>
<p>PS:开启CMS收集器的方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseParNewGC -XX:+UseConcMarkSweepGC</span><br></pre></td></tr></table></figure>

<h4 id="第四阶段，G1（并发）收集器"><a href="#第四阶段，G1（并发）收集器" class="headerlink" title="第四阶段，G1（并发）收集器"></a>第四阶段，G1（并发）收集器</h4><p>G1收集器（或者垃圾优先收集器）的设计初衷是为了尽量缩短处理超大堆（大于4GB）时产生的停顿。相对于CMS的优势而言是内存碎片的产生率大大降低。</p>
<p>PS:开启G1收集器的方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseG1GC</span><br></pre></td></tr></table></figure>

<h3 id="了解G1"><a href="#了解G1" class="headerlink" title="了解G1"></a>了解G1</h3><p>G1的第一篇paper（附录1）发表于2004年，在2012年才在jdk1.7u4中可用。oracle官方计划在jdk9中将G1变成默认的垃圾收集器，以替代CMS。为何oracle要极力推荐G1呢，G1有哪些优点</p>
<blockquote>
</blockquote>
<ol>
<li><strong>首先，G1的设计原则就是简单可行的性能调优</strong><br>开发人员仅仅需要声明以下参数即可：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis&#x3D;200</span><br></pre></td></tr></table></figure>
<p>其中-XX:+UseG1GC为开启G1垃圾收集器，-Xmx32g 设计堆内存的最大内存为32G，-XX:MaxGCPauseMillis=200设置GC的最大暂停时间为200ms。如果我们需要调优，在内存大小一定的情况下，我们只需要修改最大暂停时间即可。</p>
<ol start="2">
<li><strong>其次，G1将新生代，老年代的物理空间划分取消了。</strong><br>这样我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。</li>
</ol>
<p>取而代之的是，G1算法将堆划分为若干个区域（Region），它仍然属于分代收集器。不过，这些区域的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间。老年代也分成很多区域，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了。</p>
<p>在G1中，还有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。</p>
<p>PS：在java 8中，持久代改为元空间。</p>
<h3 id="对象分配策略"><a href="#对象分配策略" class="headerlink" title="对象分配策略"></a>对象分配策略</h3><p>说起大对象的分配，我们不得不谈谈对象的分配策略。它分为3个阶段：</p>
<ol>
<li>TLAB(Thread Local Allocation Buffer)线程本地分配缓冲区</li>
<li>Eden区中分配</li>
<li>Humongous区分配</li>
</ol>
<p>TLAB为线程本地分配缓冲区，它的目的为了使对象尽可能快的分配出来。如果对象在一个共享的空间中分配，我们需要采用一些同步机制来管理这些空间内的空闲空间指针。在Eden空间中，每一个线程都有一个固定的分区用于分配对象，即一个TLAB。分配对象时，线程之间不再需要进行任何的同步。</p>
<p>对TLAB空间中无法分配的对象，JVM会尝试在Eden空间中进行分配。如果Eden空间无法容纳该对象，就只能在老年代中进行分配空间。</p>
<p>最后，G1提供了两种GC模式，<strong>Young GC</strong>和<strong>Mixed GC</strong>，两种都是Stop The World(STW)的。下面我们将分别介绍一下这2种模式。</p>
<h3 id="G1-Young-GC"><a href="#G1-Young-GC" class="headerlink" title="G1 Young GC"></a>G1 Young GC</h3><p>Young GC主要是对Eden区进行GC，它在Eden空间耗尽时会被触发。在这种情况下，Eden空间的数据移动到Survivor空间中，如果Survivor空间不够，Eden空间的部分数据会直接晋升到年老代空间。Survivor区的数据移动到新的Survivor区中，也有部分数据晋升到老年代空间中。最终Eden空间的数据为空，GC停止工作，应用线程继续执行。</p>
<p>这时，我们需要考虑一个问题，如果仅仅GC 新生代对象，我们如何找到所有的根对象呢？ 老年代的所有对象都是根么？那这样扫描下来会耗费大量的时间。于是，G1引进了RSet的概念。它的全称是Remembered Set，作用是跟踪指向某个heap区内的对象引用。</p>
<p>在CMS中，也有RSet的概念，在老年代中有一块区域用来记录指向新生代的引用。这是一种point-out，在进行Young GC时，扫描根时，仅仅需要扫描这一块区域，而不需要扫描整个老年代。</p>
<p>但在G1中，并没有使用point-out，这是由于一个分区太小，分区数量太多，如果是用point-out的话，会造成大量的扫描浪费，有些根本不需要GC的分区引用也扫描了。于是G1中使用point-in来解决。point-in的意思是哪些分区引用了当前分区中的对象。这样，仅仅将这些对象当做根来扫描就避免了无效的扫描。由于新生代有多个，那么我们需要在新生代之间记录引用吗？这是不必要的，原因在于每次GC时，所有新生代都会被扫描，所以只需要记录老年代到新生代之间的引用即可。</p>
<p>需要注意的是，如果引用的对象很多，赋值器需要对每个引用做处理，赋值器开销会很大，为了解决赋值器开销这个问题，在G1 中又引入了另外一个概念，卡表（Card Table）。一个Card Table将一个分区在逻辑上划分为固定大小的连续区域，每个区域称之为卡。卡通常较小，介于128到512字节之间。Card Table通常为字节数组，由Card的索引（即数组下标）来标识每个分区的空间地址。默认情况下，每个卡都未被引用。当一个地址空间被引用时，这个地址空间对应的数组索引的值被标记为”0″，即标记为脏被引用，此外RSet也将这个数组下标记录下来。一般情况下，这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。</p>
<p><strong>Young GC 阶段</strong>：</p>
<p><strong>阶段1：根扫描</strong></p>
<p>静态和本地对象被扫描</p>
<p><strong>阶段2：更新RS</strong></p>
<p>处理dirty card队列更新RS</p>
<p><strong>阶段3：处理RS</strong></p>
<p>检测从年轻代指向年老代的对象</p>
<p><strong>阶段4：对象拷贝</strong></p>
<p>拷贝存活的对象到survivor/old区域</p>
<p><strong>阶段5：处理引用队列</strong></p>
<p>软引用，弱引用，虚引用处理</p>
<h3 id="G1-Mix-GC"><a href="#G1-Mix-GC" class="headerlink" title="G1 Mix GC"></a>G1 Mix GC</h3><p>Mix GC不仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的老年代分区。</p>
<p>它的GC步骤分2步：</p>
<p>1.全局并发标记（global concurrent marking）<br><br>2.拷贝存活对象（evacuation）</p>
<p>在进行Mix GC之前，会先进行global concurrent marking（全局并发标记）。 global concurrent marking的执行过程是怎样的呢？</p>
<p>在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为五个步骤：</p>
<p><strong>初始标记（initial mark，STW）</strong></p>
<p>在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。</p>
<p><strong>根区域扫描（root region scan</strong></p>
<p>G1 GC 在初始标记的存活区扫描对老年代的引用，并标记被引用的对象。该阶段与应用程序（非 STW）同时运行，并且只有完成该阶段后，才能开始下一次 STW 年轻代垃圾回收。</p>
<p><strong>并发标记（Concurrent Marking）</strong></p>
<p>G1 GC 在整个堆中查找可访问的（存活的）对象。该阶段与应用程序同时运行，可以被 STW 年轻代垃圾回收中断</p>
<p><strong>最终标记（Remark，STW）</strong></p>
<p>该阶段是 STW 回收，帮助完成标记周期。G1 GC 清空 SATB 缓冲区，跟踪未被访问的存活对象，并执行引用处理。</p>
<p><strong>清除垃圾（Cleanup，STW）</strong></p>
<p>在这个最后阶段，G1 GC 执行统计和 RSet 净化的 STW 操作。在统计期间，G1 GC 会识别完全空闲的区域和可供进行混合垃圾回收的区域。清理阶段在将空白区域重置并返回到空闲列表时为部分并发。</p>
<h3 id="三色标记算法"><a href="#三色标记算法" class="headerlink" title="三色标记算法"></a>三色标记算法</h3><p>提到并发标记，我们不得不了解并发标记的三色标记算法。它是描述追踪式回收器的一种有用的方法，利用它可以推演回收器的正确性。 首先，我们将对象分成三种类型的。</p>
<p><strong>黑色</strong>:根对象，或者该对象与它的子对象都被扫描</p>
<p><strong>灰色</strong>:对象本身被扫描,但还没扫描完该对象中的子对象</p>
<p><strong>白色</strong>:未被扫描对象，扫描完成所有对象之后，最终为白色的为不可达对象，即垃圾对象</p>
<p>当GC开始扫描对象时，按照如下图步骤进行对象的扫描：</p>
<p>根对象被置为黑色，子对象被置为灰色。</p>
<p>继续由灰色遍历,将已扫描了子对象的对象置为黑色。</p>
<p>遍历了所有可达的对象后，所有可达的对象都变成了黑色。不可达的对象即为白色，需要被清理。</p>
<p>这看起来很美好，但是如果在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：对象丢失问题</p>
<p>我们看下面一种情况，当垃圾收集器扫描到下面情况时:</p>
<p>这时候应用程序执行了以下操作：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A.c&#x3D;C</span><br><span class="line">B.c&#x3D;null</span><br></pre></td></tr></table></figure>

<p>这样，对象的状态图变成如下情形：</p>
<p>这时候垃圾收集器再标记扫描的时候就会下图成这样：</p>
<p>很显然，此时C是白色，被认为是垃圾需要清理掉，显然这是不合理的。那么我们如何保证应用程序在运行的时候，GC标记的对象不丢失呢？有如下2中可行的方式：</p>
<ol>
<li>在插入的时候记录对象</li>
<li>在删除的时候记录对象</li>
</ol>
<p>刚好这对应CMS和G1的2种不同实现方式：</p>
<p>在CMS采用的是增量更新（Incremental update），只要在写屏障（write barrier）里发现要有一个白对象的引用被赋值到一个黑对象 的字段里，那就把这个白对象变成灰色的。即插入的时候记录下来。</p>
<p>在G1中，使用的是STAB（snapshot-at-the-beginning）的方式，删除的时候记录所有的对象，它有3个步骤：</p>
<ol>
<li><p>在开始标记的时候生成一个快照图标记存活对象</p>
</li>
<li><p>在并发标记的时候所有被改变的对象入队（在write barrier里把所有旧的引用所指向的对象都变成非白的）</p>
</li>
<li><p>可能存在游离的垃圾，将在下次被收集</p>
</li>
</ol>
<p>这样，G1到现在可以知道哪些老的分区可回收垃圾最多。 当全局并发标记完成后，在某个时刻，就开始了Mix GC。这些垃圾回收被称作“混合式”是因为他们不仅仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的分区。混合式垃圾收集如下图：</p>
<p>混合式GC也是采用的复制的清理策略，当GC完成后，会重新释放空间。<br></p>
<h3 id="调优实践"><a href="#调优实践" class="headerlink" title="调优实践"></a>调优实践</h3><p><strong>MaxGCPauseMillis</strong>调优</p>
<p>前面介绍过使用GC的最基本的参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis&#x3D;200</span><br></pre></td></tr></table></figure>

<p>前面2个参数都好理解，后面这个MaxGCPauseMillis参数该怎么配置呢？这个参数从字面的意思上看，就是允许的GC最大的暂停时间。G1尽量确保每次GC暂停的时间都在设置的MaxGCPauseMillis范围内。 那G1是如何做到最大暂停时间的呢？这涉及到另一个概念，CSet(collection set)。它的意思是在一次垃圾收集器中被收集的区域集合。</p>
<ul>
<li><p>Young GC：选定所有新生代里的region。通过控制新生代的region个数来控制young GC的开销。</p>
</li>
<li><p>Mixed GC：选定所有新生代里的region，外加根据global concurrent marking统计得出收集收益高的若干老年代region。在用户指定的开销目标范围内尽可能选择收益高的老年代region。</p>
</li>
</ul>
<p>在理解了这些后，我们再设置最大暂停时间就好办了。 首先，我们能容忍的最大暂停时间是有一个限度的，我们需要在这个限度范围内设置。但是应该设置的值是多少呢？我们需要在吞吐量跟MaxGCPauseMillis之间做一个平衡。如果MaxGCPauseMillis设置的过小，那么GC就会频繁，吞吐量就会下降。如果MaxGCPauseMillis设置的过大，应用程序暂停时间就会变长。G1的默认暂停时间是200毫秒，我们可以从这里入手，调整合适的时间。</p>
<p><strong>其他调优参数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:G1HeapRegionSize&#x3D;n</span><br></pre></td></tr></table></figure>

<p>设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 Java 堆大小划分出约 2048 个区域。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:ParallelGCThreads&#x3D;n</span><br></pre></td></tr></table></figure>

<p>设置 STW 工作线程数的值。将 n 的值设置为逻辑处理器的数量。n 的值与逻辑处理器的数量相同，最多为 8。</p>
<p>如果逻辑处理器不止八个，则将 n 的值设置为逻辑处理器数的 5/8 左右。这适用于大多数情况，除非是较大的 SPARC 系统，其中 n 的值可以是逻辑处理器数的 5/16 左右。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:ConcGCThreads&#x3D;n</span><br></pre></td></tr></table></figure>

<p>设置并行标记的线程数。将 n 设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:InitiatingHeapOccupancyPercent&#x3D;45</span><br></pre></td></tr></table></figure>

<p>设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。</p>
<p>避免使用以下参数：</p>
<p>避免使用 -Xmn 选项或 -XX:NewRatio 等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。</p>
<h3 id="触发Full-GC"><a href="#触发Full-GC" class="headerlink" title="触发Full GC"></a>触发Full GC</h3><p>在某些情况下，G1触发了Full GC，这时G1会退化使用Serial收集器来完成垃圾的清理工作，它仅仅使用单线程来完成GC工作，GC暂停时间将达到秒级别的。整个应用处于假死状态，不能处理任何请求，我们的程序当然不希望看到这些。那么发生Full GC的情况有哪些呢？</p>
<h4 id="并发模式失败"><a href="#并发模式失败" class="headerlink" title="并发模式失败"></a>并发模式失败</h4><p>G1启动标记周期，但在Mix GC之前，老年代就被填满，这时候G1会放弃标记周期。这种情形下，需要增加堆大小，或者调整周期（例如增加线程数-XX:ConcGCThreads等）。</p>
<h4 id="晋升失败或者疏散失败"><a href="#晋升失败或者疏散失败" class="headerlink" title="晋升失败或者疏散失败"></a>晋升失败或者疏散失败</h4><p>G1在进行GC的时候没有足够的内存供存活对象或晋升对象使用，由此触发了Full GC。可以在日志中看到(to-space exhausted)或者（to-space overflow）。解决这种问题的方式是：</p>
<ol>
<li><p>增加 <code>-XX:G1ReservePercent</code> 选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。</p>
</li>
<li><p>通过减少<code>-XX:InitiatingHeapOccupancyPercent</code> 提前启动标记周期。</p>
</li>
<li><p>也可以通过增加 <code>-XX:ConcGCThreads</code> 选项的值来增加并行标记线程的数目。</p>
</li>
</ol>
<h4 id="巨型对象分配失败"><a href="#巨型对象分配失败" class="headerlink" title="巨型对象分配失败"></a>巨型对象分配失败</h4><p>当巨型对象找不到合适的空间进行分配时，就会启动Full GC，来释放空间。这种情况下，应该避免分配大量的巨型对象，增加内存或者增大-XX:G1HeapRegionSize，使巨型对象不再是巨型对象。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>可伸缩服务架构：框架与中间件</title>
    <url>/java-other/book--%E5%8F%AF%E4%BC%B8%E7%BC%A9%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%EF%BC%9A%E6%A1%86%E6%9E%B6%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">第1章 如何设计一款永不重复的高性能分布式发号器 1</span><br><span class="line"></span><br><span class="line">1.1 可选方案及技术选型 2</span><br><span class="line">1.1.1 为什么不用UUID 2</span><br><span class="line">1.1.2 基于数据库的实现方案 2</span><br><span class="line">1.1.3 Snowflake开源项目 3</span><br><span class="line">1.1.4 小结 4</span><br><span class="line"></span><br><span class="line">1.2 分布式系统对发号器的基本需求 4</span><br><span class="line"></span><br><span class="line">1.3 架构设计与核心要点 6</span><br><span class="line">1.3.1 发布模式 6</span><br><span class="line">1.3.2 ID类型 7</span><br><span class="line">1.3.3 数据结构 7</span><br><span class="line">1.3.4 并发 9</span><br><span class="line">1.3.5 机器ID的分配 9</span><br><span class="line">1.3.6 时间同步 10</span><br><span class="line">1.3.7 设计验证 11</span><br><span class="line"></span><br><span class="line">1.4 如何根据设计实现多场景的发号器 11</span><br><span class="line">1.4.1 项目结构 12</span><br><span class="line">1.4.2 服务接口的定义 14</span><br><span class="line">1.4.3 服务接口的实现 15</span><br><span class="line">1.4.4 ID元数据与长整型ID的互相转换 22</span><br><span class="line">1.4.5 时间操作 25</span><br><span class="line">1.4.6 机器ID的生成 27</span><br><span class="line">1.4.7 小结 32</span><br><span class="line"></span><br><span class="line">1.5 如何保证性能需求 32</span><br><span class="line">1.5.1 嵌入发布模式的压测结果 33</span><br><span class="line">1.5.2 中心服务器发布模式的压测结果 33</span><br><span class="line">1.5.3 REST发布模式（Netty实现）的压测结果 33</span><br><span class="line">1.5.4 REST发布模式（Spring Boot + Tomcat实现）的压测结果 34</span><br><span class="line">1.5.5 性能测试总结 34</span><br><span class="line"></span><br><span class="line">1.6 如何让用户快速使用 35</span><br><span class="line">1.6.1 REST发布模式的使用指南 35</span><br><span class="line">1.6.2 服务化模式的使用指南 38</span><br><span class="line">1.6.3 嵌入发布模式的使用指南 41</span><br><span class="line"></span><br><span class="line">1.7 为用户提供API文档 43</span><br><span class="line">1.7.1 RESTful API文档 44</span><br><span class="line">1.7.2 Java API文档 45</span><br><span class="line"></span><br><span class="line">第2章 可灵活扩展的消息队列框架的设计与实现 49</span><br><span class="line"></span><br><span class="line">2.1 背景介绍 50</span><br><span class="line"></span><br><span class="line">2.2 项目目标 50</span><br><span class="line">2.2.1 简单易用 50</span><br><span class="line">2.2.2 高性能 51</span><br><span class="line">2.2.3 高稳定性 51</span><br><span class="line"></span><br><span class="line">2.3 架构难点 51</span><br><span class="line">2.3.1 线程模型 51</span><br><span class="line">2.3.2 异常处理 53</span><br><span class="line">2.3.3 优雅关机 53</span><br><span class="line"></span><br><span class="line">2.4 设计与实现 54</span><br><span class="line">2.4.1 项目结构 54</span><br><span class="line">2.4.2 项目包的规划 55</span><br><span class="line">2.4.3 生产者的设计与实现 57</span><br><span class="line">2.4.4 消费者的设计与实现 58</span><br><span class="line">2.4.5 启动模块的设计与实现 67</span><br><span class="line">2.4.6 消息处理器的体系结构 76</span><br><span class="line">2.4.7 反射机制 79</span><br><span class="line">2.4.8 模板项目的设计 80</span><br><span class="line"></span><br><span class="line">2.5 使用指南 82</span><br><span class="line">2.5.1 安装步骤 82</span><br><span class="line">2.5.2 Java API 83</span><br><span class="line">2.5.3 与Spring环境集成 84</span><br><span class="line">2.5.4 对服务源码进行注解 85</span><br><span class="line"></span><br><span class="line">2.6 API简介 87</span><br><span class="line">2.6.1 Producer API 87</span><br><span class="line">2.6.2 Consumer API 88</span><br><span class="line">2.6.3 消息处理器 88</span><br><span class="line">2.6.4 消息处理器定义的注解 90</span><br><span class="line"></span><br><span class="line">2.7 消息处理机模板项目 91</span><br><span class="line">2.7.1 快速开发向导 91</span><br><span class="line">2.7.2 后台监控和管理 92</span><br><span class="line"></span><br><span class="line">第3章 轻量级的数据库分库分表架构与框架 93</span><br><span class="line"></span><br><span class="line">3.1 什么是分库分表 94</span><br><span class="line">3.1.1 使用数据库的三个阶段 94</span><br><span class="line">3.1.2 在什么情况下需要分库分表 95</span><br><span class="line">3.1.3 分库分表的典型实例 96</span><br><span class="line"></span><br><span class="line">3.2 三种分而治之的解决方案 97</span><br><span class="line">3.2.1 客户端分片 97</span><br><span class="line">3.2.2 代理分片 100</span><br><span class="line">3.2.3 支持事务的分布式数据库 101</span><br><span class="line"></span><br><span class="line">3.3 分库分表的架构设计 102</span><br><span class="line">3.3.1 整体的切分方式 102</span><br><span class="line">3.3.2 水平切分方式的路由过程和分片维度 106</span><br><span class="line">3.3.3 分片后的事务处理机制 107</span><br><span class="line">3.3.4 读写分离 119</span><br><span class="line">3.3.5 分库分表引起的问题 119</span><br><span class="line"></span><br><span class="line">3.4 流行代理分片框架Mycat的初体验 123</span><br><span class="line">3.4.1 安装Mycat 123</span><br><span class="line">3.4.2 配置Mycat 124</span><br><span class="line">3.4.3 配置数据库节点 128</span><br><span class="line">3.4.4 数据迁移 129</span><br><span class="line">3.4.5 Mycat支持的分片规则 129</span><br><span class="line"></span><br><span class="line">3.5 流行的客户端分片框架Sharding JDBC的初体验 138</span><br><span class="line">3.5.1 Sharding JDBC简介 138</span><br><span class="line">3.5.2 Sharding JDBC的功能 139</span><br><span class="line">3.5.3 Sharding JDBC的使用 141</span><br><span class="line">3.5.4 Sharding JDBC的使用限制 152</span><br><span class="line"></span><br><span class="line">3.6 自研客户端分片框架dbsplit的设计、实现与使用 153</span><br><span class="line">3.6.1 项目结构 154</span><br><span class="line">3.6.2 包结构和执行流程 155</span><br><span class="line">3.6.3 切片下标命名策略 159</span><br><span class="line">3.6.4 SQL解析和组装 167</span><br><span class="line">3.6.5 SQL实用程序 168</span><br><span class="line">3.6.6 反射实用程序 173</span><br><span class="line">3.6.7 分片规则的配置 177</span><br><span class="line">3.6.8 支持分片的SplitJdbcTemplate和SimpleSplitJdbcTemplate接口API 179</span><br><span class="line">3.6.9 JdbcTemplate的扩展SimpleJdbcTemplate接口API 184</span><br><span class="line">3.6.10 用于创建分库分表数据库的脚本工具 187</span><br><span class="line">3.6.11 使用dbsplit的一个简单示例 192</span><br><span class="line">3.6.12 使用dbsplit的线上真实示例展示 199</span><br><span class="line"></span><br><span class="line">第4章 缓存的本质和缓存使用的优秀实践 201</span><br><span class="line"></span><br><span class="line">4.1 使用缓存的目的和问题 202</span><br><span class="line"></span><br><span class="line">4.2 自相似，CPU的缓存和系统架构的缓存 203</span><br><span class="line">4.2.1 CPU缓存的架构及性能 205</span><br><span class="line">4.2.2 CPU缓存的运行过程分析 206</span><br><span class="line">4.2.3 缓存行与伪共享 208</span><br><span class="line">4.2.4 从CPU的体系架构到分布式的缓存架构 218</span><br><span class="line"></span><br><span class="line">4.3 常用的分布式缓存解决方案 221</span><br><span class="line">4.3.1 常用的分布式缓存的对比 221</span><br><span class="line">4.3.2 Redis初体验 225</span><br><span class="line"></span><br><span class="line">4.4 分布式缓存的通用方法 229</span><br><span class="line">4.4.1 缓存编程的具体方法 229</span><br><span class="line">4.4.2 应用层访问缓存的模式 233</span><br><span class="line">4.4.3 分布式缓存分片的三种模式 235</span><br><span class="line">4.4.4 分布式缓存的迁移方案 238</span><br><span class="line">4.4.5 缓存穿透、缓存并发和缓存雪崩 244</span><br><span class="line">4.4.6 缓存对事务的支持 246</span><br><span class="line"></span><br><span class="line">4.5 分布式缓存的设计与案例 248</span><br><span class="line">4.5.1 缓存设计的核心要素 248</span><br><span class="line">4.5.2 缓存设计的优秀实践 250</span><br><span class="line">4.5.3 关于常见的缓存线上问题的案例 253</span><br><span class="line"></span><br><span class="line">4.6 客户端缓存分片框架redic的设计与实现 257</span><br><span class="line">4.6.1 什么时候需要redic 258</span><br><span class="line">4.6.2 如何使用redic 258</span><br><span class="line">4.6.3 更多的配置 258</span><br><span class="line">4.6.4 项目结构 260</span><br><span class="line">4.6.5 包结构 261</span><br><span class="line">4.6.6 设计与实现的过程 261</span><br><span class="line"></span><br><span class="line">第5章 大数据利器之Elasticsearch 268</span><br><span class="line"></span><br><span class="line">5.1 Lucene简介 269</span><br><span class="line">5.1.1 核心模块 269</span><br><span class="line">5.1.2 核心术语 270</span><br><span class="line">5.1.3 检索方式 271</span><br><span class="line">5.1.4 分段存储 273</span><br><span class="line">5.1.5 段合并策略 275</span><br><span class="line">5.1.6 Lucene相似度打分 278</span><br><span class="line"></span><br><span class="line">5.2 Elasticsearch简介 286</span><br><span class="line">5.2.1 核心概念 286</span><br><span class="line">5.2.2 3C和脑裂 289</span><br><span class="line">5.2.3 事务日志 291</span><br><span class="line">5.2.4 在集群中写索引 294</span><br><span class="line">5.2.5 集群中的查询流程 295</span><br><span class="line"></span><br><span class="line">5.3 Elasticsearch实战 298</span><br><span class="line">5.3.1 Elasticsearch的配置说明 298</span><br><span class="line">5.3.2 常用的接口 300</span><br><span class="line"></span><br><span class="line">5.4 性能调优 305</span><br><span class="line">5.4.1 写优化 305</span><br><span class="line">5.4.2 读优化 308</span><br><span class="line">5.4.3 堆大小的设置 313</span><br><span class="line">5.4.4 服务器配置的选择 315</span><br><span class="line">5.4.5 硬盘的选择和设置 316</span><br><span class="line">5.4.6 接入方式 318</span><br><span class="line">5.4.7 角色隔离和脑裂 319</span><br><span class="line"></span><br><span class="line">第6章 全面揭秘分布式定时任务 321</span><br><span class="line"></span><br><span class="line">6.1 什么是定时任务 322</span><br><span class="line"></span><br><span class="line">6.2 分布式定时任务 341</span><br><span class="line">6.2.1 定时任务的使用场景 342</span><br><span class="line">6.2.2 传统定时任务存在的问题 342</span><br><span class="line">6.2.3 分布式定时任务及其原理 344</span><br><span class="line"></span><br><span class="line">6.3 开源分布式定时任务的用法 347</span><br><span class="line">6.3.1 Quartz的分布式模式 347</span><br><span class="line">6.3.2 TBSchedule 356</span><br><span class="line">6.3.3 Elastic-Job 365</span><br><span class="line"></span><br><span class="line">第7章 RPC服务的发展历程和对比分析 377</span><br><span class="line"></span><br><span class="line">7.1 什么是RPC服务 378</span><br><span class="line"></span><br><span class="line">7.2 RPC服务的原理 379</span><br><span class="line">7.2.1 Sokcet套接字 379</span><br><span class="line">7.2.2 RPC的调用过程 380</span><br><span class="line"></span><br><span class="line">7.3 在程序中使用RPC服务 382</span><br><span class="line"></span><br><span class="line">7.4 RPC服务的发展历程 383</span><br><span class="line">7.4.1 第一代RPC：以ONC RPC和DCE RPC为代表的函数式RPC 384</span><br><span class="line">7.4.2 第二代RPC：支持面对象的编程 388</span><br><span class="line">7.4.3 第三代RPC：SOA和微服务 398</span><br><span class="line">7.4.4 架构的演进 402</span><br><span class="line"></span><br><span class="line">7.5 主流的RPC框架 403</span><br><span class="line">7.5.1 Thrift 403</span><br><span class="line">7.5.2 ZeroC Ice 410</span><br><span class="line">7.5.3 gRPC 418</span><br><span class="line">7.5.4 Dubbo 430</span><br><span class="line"></span><br><span class="line">第8章 Dubbo实战及源码分析 436</span><br><span class="line"></span><br><span class="line">8.1 Dubbo的四种配置方式 437</span><br><span class="line">8.1.1 XML配置 437</span><br><span class="line">8.1.2 属性配置 440</span><br><span class="line">8.1.3 API配置 441</span><br><span class="line">8.1.4 注解配置 443</span><br><span class="line"></span><br><span class="line">8.2 服务的注册与发现 446</span><br><span class="line">8.2.1 注册中心 446</span><br><span class="line">8.2.2 服务暴露 449</span><br><span class="line">8.2.3 引用服务 451</span><br><span class="line"></span><br><span class="line">8.3 Dubbo通信协议及序列化探讨 455</span><br><span class="line">8.3.1 Dubbo支持的协议 455</span><br><span class="line">8.3.2 协议的配置方法 456</span><br><span class="line">8.3.3 多协议暴露服务 457</span><br><span class="line">8.3.4 Dubbo协议的使用注意事项 458</span><br><span class="line">8.3.5 Dubbo协议的约束 459</span><br><span class="line"></span><br><span class="line">8.4 Dubbo中高效的I&#x2F;O线程模型 459</span><br><span class="line">8.4.1 对Dubbo中I&#x2F;O模型的分析 459</span><br><span class="line">8.4.2 Dubbo中线程配置的相关参数 460</span><br><span class="line">8.4.3 在Dubbo线程方面踩过的坑 461</span><br><span class="line">8.4.4 对Dubbo中线程使用的建议 462</span><br><span class="line"></span><br><span class="line">8.5 集群的容错机制与负载均衡 462</span><br><span class="line">8.5.1 集群容错机制的原理 462</span><br><span class="line">8.5.2 集群容错模式的配置方法 464</span><br><span class="line">8.5.3 六种集群容错模式 464</span><br><span class="line">8.5.4 集群的负载均衡 465</span><br><span class="line"></span><br><span class="line">8.6 监控和运维实践 467</span><br><span class="line">8.6.1 日志适配 467</span><br><span class="line">8.6.2 监控管理后台 467</span><br><span class="line">8.6.3 服务降级 473</span><br><span class="line">8.6.4 优雅停机 475</span><br><span class="line">8.6.5 灰度发布 475</span><br><span class="line"></span><br><span class="line">8.7 Dubbo项目线上案例解析 477</span><br><span class="line">8.7.1 线上问题的通用解决方案 477</span><br><span class="line">8.7.2 耗时服务耗尽了线程池的案例 480</span><br><span class="line">8.7.3 容错重试机制引发服务雪崩的案例 481</span><br><span class="line"></span><br><span class="line">8.8 深入剖析Dubbo源码及其实现 483</span><br><span class="line">8.8.1 Dubbo的总体架构设计 483</span><br><span class="line">8.8.2 配置文件 486</span><br><span class="line">8.8.3 Dubbo的核心RPC 488</span><br><span class="line">8.8.4 Dubbo巧妙的URL总线设计 491</span><br><span class="line">8.8.5 Dubbo的扩展点加载SPI 492</span><br><span class="line">8.8.6 Dubbo服务暴露的过程 493</span><br><span class="line">8.8.7 服务引用 502</span><br><span class="line">8.8.8 集群容错和负载均衡 503</span><br><span class="line">8.8.9 集群容错 504</span><br><span class="line">8.8.10 负载均衡 509</span><br><span class="line"></span><br><span class="line">第9章 高性能网络中间件 512</span><br><span class="line"></span><br><span class="line">9.1 TCP&#x2F;UDP的核心原理及本质探索 513</span><br><span class="line">9.1.1 网络模型 513</span><br><span class="line">9.1.2 UDP、IP及其未解决的问题 515</span><br><span class="line">9.1.3 TCP详解 519</span><br><span class="line">9.1.4 是否可以用UDP代替TCP 527</span><br><span class="line">9.1.5 网络通信的不可靠性讨论 529</span><br><span class="line"></span><br><span class="line">9.2 网络测试优秀实践 530</span><br><span class="line">9.2.1 网络测试的关键点 530</span><br><span class="line">9.2.2 那些必不可少的网络测试工具 532</span><br><span class="line">9.2.3 典型的测试报告 539</span><br><span class="line"></span><br><span class="line">9.3 高性能网络框架的设计与实现 544</span><br><span class="line">9.3.1 对代理功能的测试及分析 545</span><br><span class="line">9.3.2 网络中间件的使用介绍 549</span><br><span class="line">9.3.3 内存和缓存的优化 551</span><br><span class="line">9.3.4 快速解析流数据 554</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>ThreadLocal原理机制</title>
    <url>/java/threadlocal/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>ThreadLocal存取的数据，总是与当前线程相关，也就是说，JVM 为每个运行的线程，绑定了私有的本地实例存取空间，从而为多线程环境常出现的并发访问问题提供了一种隔离机制。</p>
<a id="more"></a>

<p>ThreadLocal是如何做到为每一个线程维护变量的副本的呢？其实实现的思路很简单，在ThreadLocal类中有一个Map，用于存储每一个线程的变量的副本。</p>
<h1 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h1><h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">T <span class="title">get</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>
<p>返回此线程局部变量的当前线程副本中的值，如果这是线程第一次调用该方法，则创建并初始化此副本。</p>
<p>源代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> T <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    <span class="keyword">if</span> (map != <span class="keyword">null</span>) &#123;</span><br><span class="line">        ThreadLocalMap.Entry e = map.getEntry(<span class="keyword">this</span>);</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">            T result = (T)e.value;</span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> setInitialValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="set"><a href="#set" class="headerlink" title="set"></a>set</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">set</span><span class="params">(T value)</span></span></span><br></pre></td></tr></table></figure>
<p>将此线程局部变量的当前线程副本中的值设置为指定值。</p>
<p>源代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    <span class="keyword">if</span> (map != <span class="keyword">null</span>)</span><br><span class="line">        map.set(<span class="keyword">this</span>, value);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        createMap(t, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>
<p>有助于减少线程局部变量的存储需求。</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/mo3-y-45_ao54b5T7ez7iA" target="_blank" rel="noopener">Java多线程之隔离技术ThreadLocal源码详解</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>情商3</title>
    <url>/java-other/book--%E6%83%85%E5%95%863/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第一部分 为什么情商比技能更重要</span><br><span class="line"></span><br><span class="line">第一章 情商新标准：你需要什么样的工作情商</span><br><span class="line">工作情商为什么如此重要</span><br><span class="line">走出情商的误区</span><br><span class="line">情商：被遗忘的重点</span><br><span class="line">为什么现在情商变得至关重要</span><br><span class="line">你随时面临失业的可能</span><br><span class="line">即将到来的危机--智商提高，情商下降1</span><br><span class="line">雇主想要的是什么</span><br><span class="line">阅读本书，真正提升你的工作情商</span><br><span class="line"></span><br><span class="line">第二章 如何成为出类拔萃的员工</span><br><span class="line">被炒鱿鱼的程序设计师</span><br><span class="line">第一类杰出：有局限的智商</span><br><span class="line">第二类杰出：专业技能</span><br><span class="line">第三类杰出：情商</span><br><span class="line">情感能力的天壤之别</span><br><span class="line">什么是情感能力</span><br><span class="line">精英人才是如何造就的</span><br><span class="line"></span><br><span class="line">第三章 最佳模式：情商与专业技能</span><br><span class="line">情感能力究竟占多大比例</span><br><span class="line">用情感能力激励员工施展才华</span><br><span class="line">情感能力头等重要</span><br><span class="line">工作价值的巨大差异</span><br><span class="line">职位越高，效益越高</span><br><span class="line">优秀员工的真正价值到底是什么</span><br><span class="line">精英与庸才的分水岭</span><br><span class="line">情感能力与人员流动</span><br><span class="line">被解雇的首席运营官</span><br><span class="line">这个时代、这个世界需要什么样的人才</span><br><span class="line">职场上的彼得定律</span><br><span class="line">高技术人才情商低？</span><br><span class="line">有效培养情感能力</span><br><span class="line"></span><br><span class="line">第二部分 自我控制：让情绪为我所用</span><br><span class="line"></span><br><span class="line">第四章 发挥你的优势：工作情商的内在准则</span><br><span class="line">跳出“非此即彼”的固定模式</span><br><span class="line">内在感觉的源头</span><br><span class="line">难以作决定的律师</span><br><span class="line">直觉的力量--最初的30秒</span><br><span class="line">感觉之流</span><br><span class="line">自我意识：内心的晴雨表</span><br><span class="line">规划你的事业</span><br><span class="line">注意力--我们宝贵的财富</span><br><span class="line">盲点</span><br><span class="line">我们的优势与劣势</span><br><span class="line">改进之道</span><br><span class="line">天生我材必有用</span><br><span class="line">敢言的勇气</span><br><span class="line"></span><br><span class="line">第五章 情绪的自我控制</span><br><span class="line">300万美元的损失</span><br><span class="line">情绪失控</span><br><span class="line">只会说“不”的神经元</span><br><span class="line">“棉花糖测试”的孩子长大参加工作了</span><br><span class="line">控制情绪</span><br><span class="line">当工作变成了煎熬</span><br><span class="line">无助之感</span><br><span class="line">自我意识的益处</span><br><span class="line">自我控制行为</span><br><span class="line">在压力下保持坚韧</span><br><span class="line">勇气的力量</span><br><span class="line">控制冲动--错误的情绪界限</span><br><span class="line">无声的美德--职业道德</span><br><span class="line">这个世界的景象在不断改变</span><br><span class="line">情绪上的先决条件--在变化中求生</span><br><span class="line">创新者</span><br><span class="line">创新的新旧典范</span><br><span class="line">天使的守护与毁灭的声讨</span><br><span class="line">集体创造力的结晶</span><br><span class="line"></span><br><span class="line">第六章 神驰状态：工作中的忘我境界如何培养</span><br><span class="line">热爱工作，必有回报</span><br><span class="line">置身其中，感同身受</span><br><span class="line">锦上添花</span><br><span class="line">有益的压力--接受挑战</span><br><span class="line">亲和力--团队驱动力</span><br><span class="line">驱动力的神经学基础</span><br><span class="line">预估风险</span><br><span class="line">热衷反馈</span><br><span class="line">获取信息，提高效率</span><br><span class="line">组织内的模范员工</span><br><span class="line">不负责任的员工</span><br><span class="line">“把握每一天”的方法</span><br><span class="line">希望与锲而不舍的精神</span><br><span class="line">过分主动的不良后果</span><br><span class="line">持之以恒，张弛有度</span><br><span class="line">乐观与希望</span><br><span class="line"></span><br><span class="line">第三部分 人际关系中的情商</span><br><span class="line"></span><br><span class="line">第七章 社交雷达：如何养成同理心</span><br><span class="line">同理心由心而生</span><br><span class="line">配合默契的双人舞</span><br><span class="line">同理心模式</span><br><span class="line">倾听的艺术</span><br><span class="line">识破虚情假意</span><br><span class="line">缺乏同理心的“残疾人”</span><br><span class="line">同理心有时带来苦恼</span><br><span class="line">同理心的权术</span><br><span class="line">批评的艺术</span><br><span class="line">皮格马利翁效应</span><br><span class="line">开阔眼界</span><br><span class="line">削减成本的代价</span><br><span class="line">潜在的威胁</span><br><span class="line">陈旧观念的影响</span><br><span class="line">借助他人，迈向成功</span><br><span class="line">政治判断力</span><br><span class="line"></span><br><span class="line">第八章 影响力的艺术</span><br><span class="line">情绪具有感染力</span><br><span class="line">团队精神</span><br><span class="line">调整他人情绪</span><br><span class="line">首先，要建立友好关系</span><br><span class="line">说服失败的原因</span><br><span class="line">马基雅维利主义的玩弄权术者</span><br><span class="line">情绪和含义</span><br><span class="line">保持冷静</span><br><span class="line">察言观色</span><br><span class="line">谈判渠道</span><br><span class="line">发挥创意，解决冲突</span><br><span class="line">领导就是传递能量</span><br><span class="line">领导者的情感能力工具箱</span><br><span class="line">好人有善终</span><br><span class="line">领导的扩散效应</span><br><span class="line">何时需要强势</span><br><span class="line">名副其实的领导者</span><br><span class="line">推动变革的关键因素</span><br><span class="line">变革中的领导者</span><br><span class="line">情感的艺术</span><br><span class="line"></span><br><span class="line">第九章 团队合作与集体智慧</span><br><span class="line">能在社会上生存的人</span><br><span class="line">社会化过程塑造大脑</span><br><span class="line">合作的艺术</span><br><span class="line">群体优势之集体智慧</span><br><span class="line">集体智慧的结晶</span><br><span class="line">人际关系网的艺术</span><br><span class="line">人际关系网是一项个人资本</span><br><span class="line">构建人际关系的管理者</span><br><span class="line">组织内的“婚姻”</span><br><span class="line">上下级犹如夫妻</span><br><span class="line">媚上欺下</span><br><span class="line">团队成就驱动力</span><br><span class="line">优秀团队的价值</span><br><span class="line">有凝聚力的人</span><br><span class="line">能力高强的团队领导者</span><br><span class="line">团队和组织策略</span><br><span class="line">英雄团队</span><br><span class="line">集体精神的神驰状态</span><br><span class="line">团队犹如学习实验室--成功团队五大秘诀</span><br><span class="line"></span><br><span class="line">第四部分 提高情商：如何学，如何做</span><br><span class="line"></span><br><span class="line">第十章 为什么情商培训如此低效：最佳指导原则</span><br><span class="line">消除负面因素的秘诀</span><br><span class="line">培养情感能力与销售能力</span><br><span class="line">情商比智商更容易提高</span><br><span class="line">仅是“知道”还不够</span><br><span class="line">终极考验</span><br><span class="line">不同的学习模式</span><br><span class="line">只问耕耘，不问收获</span><br><span class="line">成效评估标准</span><br><span class="line">强势公司软下来</span><br><span class="line">情感能力训练指导原则</span><br><span class="line">真正实用的技能</span><br><span class="line">专为失业者设计的训练</span><br><span class="line"></span><br><span class="line">第十一章 如何真正提高你的情商：最佳实践方法</span><br><span class="line">评估工作</span><br><span class="line">评估个人能力</span><br><span class="line">谨慎告知评估结果</span><br><span class="line">评估学习的准备状态</span><br><span class="line">动机</span><br><span class="line">自我导向的改变</span><br><span class="line">设立清晰明确的可控目标</span><br><span class="line">避免重蹈覆辙</span><br><span class="line">成果反馈</span><br><span class="line">鼓励实践</span><br><span class="line">彼此帮助，共同提高</span><br><span class="line">角色楷模</span><br><span class="line">鼓励与强化</span><br><span class="line">需要有效的跟踪评估</span><br><span class="line"></span><br><span class="line">第五部分 提升团队情商</span><br><span class="line"></span><br><span class="line">第十二章 如何打造高情商团队</span><br><span class="line">盲点</span><br><span class="line">组织如同家庭</span><br><span class="line">坦诚建言</span><br><span class="line">善于调控情绪</span><br><span class="line">疲惫不堪？受害者反受责备</span><br><span class="line">业绩怎么会降低</span><br><span class="line">成功精神</span><br><span class="line">柔性管理，刚性效果</span><br><span class="line">由上而下</span><br><span class="line"></span><br><span class="line">第十三章 工作业绩与情商</span><br><span class="line">组织智慧最大化</span><br><span class="line">情商组织之案例分析</span><br><span class="line">国际团队需要的人才</span><br><span class="line">我为人人--合作带来经济效益</span><br><span class="line">集体成就</span><br><span class="line">诚信原则</span><br><span class="line">凝聚情感</span><br><span class="line">需要帮助的时候</span><br><span class="line"></span><br><span class="line">人力雷达</span><br><span class="line">后 记</span><br><span class="line">附录一 情商</span><br><span class="line">附录二 评估优秀员工的能力</span><br><span class="line">附录三 性别与同理心</span><br><span class="line">附录四 利用多元化优势</span><br><span class="line">附录五 培训中的其他因素</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>深入分布式缓存：从原理到实践</title>
    <url>/java-other/book--%E6%B7%B1%E5%85%A5%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">前言</span><br><span class="line"></span><br><span class="line">第1章　缓存为王1</span><br><span class="line"></span><br><span class="line">1.1　什么是缓存？1</span><br><span class="line"></span><br><span class="line">1.2　为什么使用缓存？2</span><br><span class="line">1.2.1　从用户体验说起3</span><br><span class="line">1.2.2　关于系统的性能3</span><br><span class="line"></span><br><span class="line">1.3　从网站的架构发展看缓存4</span><br><span class="line"></span><br><span class="line">1.4　客户端缓存5</span><br><span class="line">1.4.1　页面缓存6</span><br><span class="line">1.4.2　浏览器缓存7</span><br><span class="line">1.4.3　APP上的缓存8</span><br><span class="line"></span><br><span class="line">1.5　网络中的缓存11</span><br><span class="line">1.5.1　Web代理缓存11</span><br><span class="line">1.5.2　边缘缓存12</span><br><span class="line"></span><br><span class="line">1.6　服务端缓存14</span><br><span class="line">1.6.1　数据库缓存14</span><br><span class="line">1.6.2　平台级缓存16</span><br><span class="line">1.6.3　应用级缓存18</span><br><span class="line"></span><br><span class="line">第2章　分布式系统理论24</span><br><span class="line"></span><br><span class="line">2.1　分布式系统概论24</span><br><span class="line"></span><br><span class="line">2.2　分布式系统概念26</span><br><span class="line">2.2.1　进程与线程26</span><br><span class="line">2.2.2　并发26</span><br><span class="line">2.2.3　锁26</span><br><span class="line">2.2.4　并行27</span><br><span class="line">2.2.5　集群27</span><br><span class="line">2.2.6　状态特性28</span><br><span class="line">2.2.7　系统重发与幂等性28</span><br><span class="line">2.2.8　硬件异常30</span><br><span class="line"></span><br><span class="line">2.3　分布式系统理论31</span><br><span class="line">2.3.1　CAP理论32</span><br><span class="line">2.3.2　CAP理论澄清34</span><br><span class="line">2.3.3　Paxos35</span><br><span class="line">2.3.4　2PC38</span><br><span class="line">2.3.5　3PC39</span><br><span class="line">2.3.6　Raft40</span><br><span class="line">2.3.7　Lease机制41</span><br><span class="line">2.3.8　解决“脑裂”问题43</span><br><span class="line">2.3.9　Quorum NWR44</span><br><span class="line">2.3.10　MVCC45</span><br><span class="line">2.3.11　Gossip46</span><br><span class="line"></span><br><span class="line">2.4　分布式系统设计策略49</span><br><span class="line">2.4.1　心跳检测50</span><br><span class="line">2.4.2　高可用设计50</span><br><span class="line">2.4.3　容错性52</span><br><span class="line">2.4.4　负载均衡53</span><br><span class="line"></span><br><span class="line">2.5　分布式系统设计实践54</span><br><span class="line">2.5.1　全局ID生成54</span><br><span class="line">2.5.2　哈希取模56</span><br><span class="line">2.5.3　一致性哈希57</span><br><span class="line">2.5.4　路由表58</span><br><span class="line">2.5.5　数据拆分58</span><br><span class="line"></span><br><span class="line">第3章　动手写缓存60</span><br><span class="line"></span><br><span class="line">3.1　缓存定义的规范60</span><br><span class="line">3.1.1　新规范的主要内容及特性60</span><br><span class="line">3.1.2　新规范的API介绍61</span><br><span class="line"></span><br><span class="line">3.2　缓存框架的实现62</span><br><span class="line">3.2.1　前期准备63</span><br><span class="line">3.2.2　缓存的架构介绍63</span><br><span class="line">3.2.3　设计思路以及知识点详解64</span><br><span class="line"></span><br><span class="line">3.3　缓存框架的使用示例74</span><br><span class="line"></span><br><span class="line">第4章 　Ehcache与Guava Cache76</span><br><span class="line"></span><br><span class="line">4.1　Ehcache的主要特性76</span><br><span class="line"></span><br><span class="line">4.2　Ehcache使用介绍77</span><br><span class="line">4.2.1　Ehcache架构图77</span><br><span class="line">4.2.2　缓存数据过期策略78</span><br><span class="line">4.2.3　Ehcache缓存的基本用法81</span><br><span class="line">4.2.4　在Spring中使用Ehcache83</span><br><span class="line"></span><br><span class="line">4.3　Ehcache集群介绍85</span><br><span class="line">4.3.1　集群的方式86</span><br><span class="line">4.3.2　如何配置集群88</span><br><span class="line"></span><br><span class="line">4.4　 Ehcache的适用场景89</span><br><span class="line"></span><br><span class="line">4.5　Guava Cache的使用92</span><br><span class="line">4.5.1　Guava Cache的适用场景92</span><br><span class="line">4.5.2　Guava Cache的创建方式93</span><br><span class="line">4.5.3　缓存数据删除95</span><br><span class="line">4.5.4　并发场景下的使用95</span><br><span class="line">4.6　本章小结96</span><br><span class="line"></span><br><span class="line">第5章　从Memcached开始了解集中式缓存97</span><br><span class="line"></span><br><span class="line">5.1　Memcached基本知识98</span><br><span class="line">5.1.1　Memcached的操作命令98</span><br><span class="line">5.1.2　Memcached使用场景100</span><br><span class="line">5.1.3　Memcached特征100</span><br><span class="line">5.1.4　Memcached的一些问题101</span><br><span class="line"></span><br><span class="line">5.2　Memcached内存存储102</span><br><span class="line">5.2.1　Slab Allocation机制102</span><br><span class="line">5.2.2　使用 Growth Factor进行调优104</span><br><span class="line">5.2.3　Item105</span><br><span class="line"></span><br><span class="line">5.3　典型问题解析106</span><br><span class="line">5.3.1　过期机制106</span><br><span class="line">5.3.2　哈希算法107</span><br><span class="line">5.3.3　热点问题108</span><br><span class="line">5.3.4　缓存与数据库的更新问题108</span><br><span class="line">5.3.5　别把缓存当存储109</span><br><span class="line">5.3.6　命名空间110</span><br><span class="line">5.3.7　CAS110</span><br><span class="line"></span><br><span class="line">5.4　Memcached客户端分析110</span><br><span class="line">5.4.1　Memcached的Client111</span><br><span class="line">5.4.2　Spymemcached设计思想解析111</span><br><span class="line"></span><br><span class="line">5.5　Memcached周边工具发展117</span><br><span class="line"></span><br><span class="line">第6章　Memcached 周边技术119</span><br><span class="line"></span><br><span class="line">6.1　Twemcache119</span><br><span class="line">6.1.1　Twemcache 的设计原理120</span><br><span class="line">6.1.2　Twemcache的安装及命令行详解122</span><br><span class="line">6.1.3　基于Java的Twemcache用法125</span><br><span class="line"></span><br><span class="line">6.2　Twemproxy126</span><br><span class="line">6.2.1　Twemproxy的常用部署模式127</span><br><span class="line">6.2.2　Twemproxy的可扩展性129</span><br><span class="line">6.2.3　Twemproxy源代码简析131</span><br><span class="line"></span><br><span class="line">6.3　Mcrouter137</span><br><span class="line">6.3.1　Mcrouter路由算法138</span><br><span class="line">6.3.2　典型的使用场景139</span><br><span class="line">6.3.3　Mcrouter的可扩展性142</span><br><span class="line">6.3.4　源码简要解析144</span><br><span class="line"></span><br><span class="line">第7章　Redis探秘148</span><br><span class="line"></span><br><span class="line">7.1　数据结构148</span><br><span class="line">7.1.1　value对象的通用结构149</span><br><span class="line">7.1.2　String149</span><br><span class="line">7.1.3　List152</span><br><span class="line">7.1.4　Map155</span><br><span class="line">7.1.5　Set157</span><br><span class="line">7.1.6　Sorted-Set159</span><br><span class="line"></span><br><span class="line">7.2　客户端与服务器的交互160</span><br><span class="line">7.2.1　客户端&#x2F;服务器协议161</span><br><span class="line">7.2.2　请求&#x2F;响应模式163</span><br><span class="line">7.2.3　事务模式164</span><br><span class="line">7.2.4　脚本模式168</span><br><span class="line">7.2.5　发布&#x2F;订阅模式169</span><br><span class="line"></span><br><span class="line">7.3　单机处理逻辑171</span><br><span class="line">7.3.1　多路复用171</span><br><span class="line">7.3.2　定时任务处理173</span><br><span class="line"></span><br><span class="line">7.4　持久化174</span><br><span class="line">7.4.1　基于全量模式的持久化174</span><br><span class="line">7.4.2　基于增量模式的持久化176</span><br><span class="line">7.4.3　基于增量模式持久化的优化178</span><br><span class="line"></span><br><span class="line">第8章　分布式Redis180</span><br><span class="line"></span><br><span class="line">8.1　水平拆分（sharding）181</span><br><span class="line">8.1.1　数据分布181</span><br><span class="line">8.1.2　请求路由182</span><br><span class="line"></span><br><span class="line">8.2　主备复制（replication）182</span><br><span class="line">8.2.1　主备复制流程183</span><br><span class="line">8.2.2　断点续传183</span><br><span class="line"></span><br><span class="line">8.3　故障转移（failover）184</span><br><span class="line">8.3.1　sentinel间的相互感知185</span><br><span class="line">8.3.2　master的故障发现186</span><br><span class="line">8.3.3　failover决策186</span><br><span class="line"></span><br><span class="line">8.4　Redis Cluster187</span><br><span class="line">8.4.1　拓扑结构187</span><br><span class="line">8.4.2　配置的一致性188</span><br><span class="line">8.4.3　sharding190</span><br><span class="line">8.4.4　failover193</span><br><span class="line">8.4.5　可用性和性能196</span><br><span class="line"></span><br><span class="line">第9章　Tair探秘198</span><br><span class="line">9.1　Tair总体架构198</span><br><span class="line">9.2　Config Server简介199</span><br><span class="line">9.3　Data Server简介201</span><br><span class="line">9.4　Tair高可用和负载均衡204</span><br><span class="line">9.4.1　对照表204</span><br><span class="line">9.4.2　数据迁移219</span><br><span class="line">9.5　存储引擎220</span><br><span class="line">9.6　Tair的API222</span><br><span class="line">9.6.1　key&#x2F;value相关API223</span><br><span class="line">9.6.2　prefix相关的API226</span><br><span class="line"></span><br><span class="line">第10章　EVCache探秘229</span><br><span class="line"></span><br><span class="line">10.1　EVCache项目介绍230</span><br><span class="line">10.1.1　EVCache的由来231</span><br><span class="line">10.1.2　EVCache的发展232</span><br><span class="line">10.1.3　EVCache的演进234</span><br><span class="line"></span><br><span class="line">10.2　EVCache 的使用场景238</span><br><span class="line">10.2.1　典型用例238</span><br><span class="line">10.2.2　典型部署239</span><br><span class="line"></span><br><span class="line">10.3　EVCache的性能240</span><br><span class="line">10.3.1　EVCache集群的性能240</span><br><span class="line">10.3.2　全局化复制时的性能问题242</span><br><span class="line">10.3.3　Moneta项目中的组件性能243</span><br><span class="line"></span><br><span class="line">10.4　EVCache 的高可用性244</span><br><span class="line">10.4.1　AWS的多可用区244</span><br><span class="line">10.4.2　EVCache对AWS高可用性的增强245</span><br><span class="line"></span><br><span class="line">10.5　源码与示例245</span><br><span class="line">10.5.1　源码浅析245</span><br><span class="line">10.5.2　EVCache 示例253</span><br><span class="line"></span><br><span class="line">第11章　Aerospike原理及广告业务应用259</span><br><span class="line"></span><br><span class="line">11.1　Aerospike架构259</span><br><span class="line"></span><br><span class="line">11.2　Aerospike具体实现261</span><br><span class="line">11.2.1　Aerospike集群管理261</span><br><span class="line">11.2.2　数据分布263</span><br><span class="line"></span><br><span class="line">11.3　Aerospike集群配置和部署265</span><br><span class="line">11.3.1　搭建集群的方式与配置266</span><br><span class="line">11.3.2　部署集群267</span><br><span class="line"></span><br><span class="line">11.4　Aerospike与Redis的对比271</span><br><span class="line"></span><br><span class="line">11.5　Aeropsike在广告行业的具体应用272</span><br><span class="line">11.5.1　Aerospike在个性化推荐广告中的应用273</span><br><span class="line">11.5.2　Aerospike在实时竞价广告中的应用274</span><br><span class="line"></span><br><span class="line">第12章　社交场景架构进化：从数据库到缓存283</span><br><span class="line"></span><br><span class="line">12.1　社交业务示例283</span><br><span class="line">12.1.1　业务模型283</span><br><span class="line">12.1.2　业务场景284</span><br><span class="line">12.1.3　业务特点285</span><br><span class="line"></span><br><span class="line">12.2　关系（relation）的存储286</span><br><span class="line">12.2.1　基于DB的最简方案286</span><br><span class="line">12.2.2　DB的sharding方案288</span><br><span class="line">12.2.3　引入缓存290</span><br><span class="line"></span><br><span class="line">12.2.4　缓存的优化方案292</span><br><span class="line"></span><br><span class="line">12.3　帖子（post）的存储293</span><br><span class="line">12.3.1　基于DB的方案294</span><br><span class="line">12.3.2　引入服务端缓存296</span><br><span class="line">12.3.3　本地缓存297</span><br><span class="line"></span><br><span class="line">12.4　时间线（timeline）的存储297</span><br><span class="line">12.4.1　基于DB的方案—push模式298</span><br><span class="line">12.4.2　基于DB的方案—pull模式300</span><br><span class="line">12.4.3　增量查询引入服务端缓存302</span><br><span class="line"></span><br><span class="line">第13章　缓存在社交网络Feed系统中的架构实践304</span><br><span class="line"></span><br><span class="line">13.1　Feed系统架构304</span><br><span class="line"></span><br><span class="line">13.2　Feed缓存模型307</span><br><span class="line"></span><br><span class="line">13.3　Feed缓存架构的设计309</span><br><span class="line">13.3.1　简单数据类型的缓存设计310</span><br><span class="line">13.3.2　集合类数据的缓存设计312</span><br><span class="line">13.3.3　其他类型数据的缓存设计314</span><br><span class="line"></span><br><span class="line">13.4　Feed缓存的扩展 315</span><br><span class="line">13.4.1　Redis的扩展315</span><br><span class="line">13.4.2　计数器的扩展316</span><br><span class="line">13.4.3　存在性判断的扩展318</span><br><span class="line"></span><br><span class="line">13.5　Feed缓存的服务化319</span><br><span class="line"></span><br><span class="line">第14章　典型电商应用与缓存324</span><br><span class="line"></span><br><span class="line">14.1　电商类应用的挑战及特点324</span><br><span class="line"></span><br><span class="line">14.2　应用数据静态化架构高性能单页Web应用325</span><br><span class="line">14.2.1　整体架构326</span><br><span class="line">14.2.2　CMS系统326</span><br><span class="line">14.2.3　前端展示系统328</span><br><span class="line">14.2.4　控制系统328</span><br><span class="line"></span><br><span class="line">14.3　应用多级缓存模式支撑海量读服务329</span><br><span class="line">14.3.1　多级缓存介绍329</span><br><span class="line">14.3.2　如何缓存数据331</span><br><span class="line">14.3.3　分布式缓存与应用负载均衡332</span><br><span class="line">14.3.4　热点数据与更新缓存334</span><br><span class="line">14.3.5　更新缓存与原子性336</span><br><span class="line">14.3.6　缓存崩溃与快速修复336</span><br><span class="line"></span><br><span class="line">14.4　构建需求响应式亿级商品详情页337</span><br><span class="line">14.4.1　商品详情页前端结构338</span><br><span class="line">14.4.2　单品页技术架构发展338</span><br><span class="line">14.4.3　详情页架构设计原则343</span><br><span class="line">14.4.4　遇到的一些问题349</span><br><span class="line"></span><br><span class="line">第15章　同程凤凰缓存系统基于Redis的设计与实践357</span><br><span class="line"></span><br><span class="line">15.1　同程凤凰缓存系统要解决什么问题357</span><br><span class="line">15.1.1　Redis用法的凌乱358</span><br><span class="line">15.1.2　从实际案例再看Redis的使用360</span><br><span class="line">15.1.3　如何改变Redis用不好的误区362</span><br><span class="line">15.1.4　凤凰缓存系统对Redis系统化改造364</span><br><span class="line"></span><br><span class="line">15.2　用好Redis先运维好它366</span><br><span class="line">15.2.1　传统的Redis运维方式366</span><br><span class="line">15.2.2　Redis的Docker化部署368</span><br><span class="line">15.2.3　凤凰缓存系统对Redis的监控369</span><br><span class="line">15.2.4　凤凰缓存系统对Redis的集群分片优化370</span><br><span class="line">15.2.5　客户端在运维中的作用371</span><br><span class="line">15.2.6　凤凰缓存系统在Redis运维上的工具372</span><br><span class="line"></span><br><span class="line">15.3　凤凰缓存系统的使用效果373</span><br><span class="line"></span><br><span class="line">第16章　新的旅程374</span><br><span class="line"></span><br><span class="line">16.1　更好的引入缓存技术374</span><br><span class="line">16.1.1　缓存引入前的考量374</span><br><span class="line">16.1.2　缓存组件的选择375</span><br><span class="line">16.1.3　缓存架构的设计376</span><br><span class="line">16.1.4　缓存系统的监控及演进377</span><br><span class="line"></span><br><span class="line">16.2　缓存分类总结377</span><br><span class="line"></span><br><span class="line">16.3　缓存知识结构更多Tips378</span><br><span class="line">16.3.1　缓存使用模式379</span><br><span class="line">16.3.2　缓存协议379</span><br><span class="line">16.3.3　缓存连接池380</span><br><span class="line">16.3.4　几个关注点383</span><br><span class="line">16.3.5　管理缓存387</span><br><span class="line">16.3.6　缓存可用性390</span><br><span class="line">16.3.7　数据一致性392</span><br><span class="line">16.3.8　热点数据处理393</span><br><span class="line">16.3.9　注意事项Tips396</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>亿级流量网站架构核心技术</title>
    <url>/java-other/book--%E4%BA%BF%E7%BA%A7%E6%B5%81%E9%87%8F%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第1部分 概述 &#x2F; 1</span><br><span class="line">1 交易型系统设计的一些原则 &#x2F; 2</span><br><span class="line">1.1 高并发原则 &#x2F; 3</span><br><span class="line">1.1.1 无状态 &#x2F; 3</span><br><span class="line">1.1.2 拆分 &#x2F; 3</span><br><span class="line">1.1.3 服务化 &#x2F; 4</span><br><span class="line">1.1.4 消息队列 &#x2F; 4</span><br><span class="line">1.1.5 数据异构 &#x2F; 6</span><br><span class="line">1.1.6 缓存银弹 &#x2F; 7</span><br><span class="line">1.1.7 并发化 &#x2F; 9</span><br><span class="line">1.2 高可用原则 &#x2F; 10</span><br><span class="line">1.2.1 降级 &#x2F; 10</span><br><span class="line">1.2.2 限流 &#x2F; 11</span><br><span class="line">1.2.3 切流量 &#x2F; 12</span><br><span class="line">1.2.4 可回滚 &#x2F; 12</span><br><span class="line">1.3 业务设计原则 &#x2F; 12</span><br><span class="line">1.3.1 防重设计 &#x2F; 13</span><br><span class="line">1.3.2 幂等设计 &#x2F; 13</span><br><span class="line">1.3.3 流程可定义 &#x2F; 13</span><br><span class="line">1.3.4 状态与状态机 &#x2F; 13</span><br><span class="line">1.3.5 后台系统操作可反馈 &#x2F; 14</span><br><span class="line">1.3.6 后台系统审批化 &#x2F; 14</span><br><span class="line">1.3.7 文档和注释 &#x2F; 14</span><br><span class="line">1.3.8 备份 &#x2F; 14</span><br><span class="line">1.4 总结 &#x2F; 14</span><br><span class="line"></span><br><span class="line">第2部分 高可用 &#x2F; 17</span><br><span class="line">2 负载均衡与反向代理 &#x2F; 18</span><br><span class="line">2.1 upstream配置 &#x2F; 20</span><br><span class="line">2.2 负载均衡算法 &#x2F; 21</span><br><span class="line">2.3 失败重试 &#x2F; 23</span><br><span class="line">2.4 健康检查 &#x2F; 24</span><br><span class="line">2.4.1 TCP心跳检查 &#x2F; 24</span><br><span class="line">2.4.2 HTTP心跳检查 &#x2F; 25</span><br><span class="line">2.5 其他配置 &#x2F; 25</span><br><span class="line">2.5.1 域名上游服务器 &#x2F; 25</span><br><span class="line">2.5.2 备份上游服务器 &#x2F; 26</span><br><span class="line">2.5.3 不可用上游服务器 &#x2F; 26</span><br><span class="line">2.6 长连接 &#x2F; 26</span><br><span class="line">2.7 HTTP反向代理示例 &#x2F; 29</span><br><span class="line">2.8 HTTP动态负载均衡 &#x2F; 30</span><br><span class="line">2.8.1 Consul+Consul-template &#x2F; 31</span><br><span class="line">2.8.2 Consul+OpenResty &#x2F; 35</span><br><span class="line">2.9 Nginx四层负载均衡 &#x2F; 39</span><br><span class="line">2.9.1 静态负载均衡 &#x2F; 39</span><br><span class="line">2.9.2 动态负载均衡 &#x2F; 41</span><br><span class="line">参考资料 &#x2F; 42</span><br><span class="line"></span><br><span class="line">3 隔离术 &#x2F; 43</span><br><span class="line">3.1 线程隔离 &#x2F; 43</span><br><span class="line">3.2 进程隔离 &#x2F; 45</span><br><span class="line">3.3 集群隔离 &#x2F; 45</span><br><span class="line">3.4 机房隔离 &#x2F; 46</span><br><span class="line">3.5 读写隔离 &#x2F; 47</span><br><span class="line">3.6 动静隔离 &#x2F; 48</span><br><span class="line">3.7 爬虫隔离 &#x2F; 49</span><br><span class="line">3.8 热点隔离 &#x2F; 50</span><br><span class="line">3.9 资源隔离 &#x2F; 50</span><br><span class="line">3.10 使用Hystrix实现隔离 &#x2F; 51</span><br><span class="line">3.10.1 Hystrix简介 &#x2F; 51</span><br><span class="line">3.10.2 隔离示例 &#x2F; 52</span><br><span class="line">3.11 基于Servlet 3实现请求隔离 &#x2F; 56</span><br><span class="line">3.11.1 请求解析和业务处理线程池分离 &#x2F; 57</span><br><span class="line">3.11.2 业务线程池隔离 &#x2F; 58</span><br><span class="line">3.11.3 业务线程池监控&#x2F;运维&#x2F;降级 &#x2F; 58</span><br><span class="line">3.11.4 如何使用Servlet 3异步化 &#x2F; 59</span><br><span class="line">3.11.5 一些Servlet 3异步化压测数据 &#x2F; 64</span><br><span class="line"></span><br><span class="line">4 限流详解 &#x2F; 66</span><br><span class="line">4.1 限流算法 &#x2F; 67</span><br><span class="line">4.1.1 令牌桶算法 &#x2F; 67</span><br><span class="line">4.1.2 漏桶算法 &#x2F; 68</span><br><span class="line">4.2 应用级限流 &#x2F; 69</span><br><span class="line">4.2.1 限流总并发&#x2F;连接&#x2F;请求数 &#x2F; 69</span><br><span class="line">4.2.2 限流总资源数 &#x2F; 70</span><br><span class="line">4.2.3 限流某个接口的总并发&#x2F;请求数 &#x2F; 70</span><br><span class="line">4.2.4 限流某个接口的时间窗请求数 &#x2F; 70</span><br><span class="line">4.2.5 平滑限流某个接口的请求数 &#x2F; 71</span><br><span class="line">4.3 分布式限流 &#x2F; 75</span><br><span class="line">4.3.1 Redis+Lua实现 &#x2F; 76</span><br><span class="line">4.3.2 Nginx+Lua实现 &#x2F; 77</span><br><span class="line">4.4 接入层限流 &#x2F; 78</span><br><span class="line">4.4.1 ngx_http_limit_conn_module &#x2F; 78</span><br><span class="line">4.4.2 ngx_http_limit_req_module &#x2F; 80</span><br><span class="line">4.4.3 lua-resty-limit-traffic &#x2F; 88</span><br><span class="line">4.5 节流 &#x2F; 90</span><br><span class="line">4.5.1 throttleFirst&#x2F;throttleLast &#x2F; 90</span><br><span class="line">4.5.2 throttleWithTimeout &#x2F; 91</span><br><span class="line">参考资料 &#x2F; 92</span><br><span class="line"></span><br><span class="line">5 降级特技 &#x2F; 93</span><br><span class="line">5.1 降级预案 &#x2F; 93</span><br><span class="line">5.2 自动开关降级 &#x2F; 95</span><br><span class="line">5.2.1 超时降级 &#x2F; 95</span><br><span class="line">5.2.2 统计失败次数降级 &#x2F; 95</span><br><span class="line">5.2.3 故障降级 &#x2F; 95</span><br><span class="line">5.2.4 限流降级 &#x2F; 95</span><br><span class="line">5.3 人工开关降级 &#x2F; 96</span><br><span class="line">5.4 读服务降级 &#x2F; 96</span><br><span class="line">5.5 写服务降级 &#x2F; 97</span><br><span class="line">5.6 多级降级 &#x2F; 98</span><br><span class="line">5.7 配置中心 &#x2F; 100</span><br><span class="line">5.7.1 应用层API封装 &#x2F; 100</span><br><span class="line">5.7.2 配置文件实现开关配置 &#x2F; 101</span><br><span class="line">5.7.3 配置中心实现开关配置 &#x2F; 102</span><br><span class="line">5.8 使用Hystrix实现降级 &#x2F; 106</span><br><span class="line">5.9 使用Hystrix实现熔断 &#x2F; 108</span><br><span class="line">5.9.1 熔断机制实现 &#x2F; 108</span><br><span class="line">5.9.2 配置示例 &#x2F; 112</span><br><span class="line">5.9.3 采样统计 &#x2F; 113</span><br><span class="line"></span><br><span class="line">6 超时与重试机制 &#x2F; 117</span><br><span class="line">6.1 简介 &#x2F; 117</span><br><span class="line">6.2 代理层超时与重试 &#x2F; 119</span><br><span class="line">6.2.1 Nginx &#x2F; 119</span><br><span class="line">6.2.2 Twemproxy &#x2F; 126</span><br><span class="line">6.3 Web容器超时 &#x2F; 127</span><br><span class="line">6.4 中间件客户端超时与重试 &#x2F; 127</span><br><span class="line">6.5 数据库客户端超时 &#x2F; 131</span><br><span class="line">6.6 NoSQL客户端超时 &#x2F; 134</span><br><span class="line">6.7 业务超时 &#x2F; 135</span><br><span class="line">6.8 前端Ajax超时 &#x2F; 135</span><br><span class="line">6.9 总结 &#x2F; 136</span><br><span class="line">6.10 参考资料 &#x2F; 137</span><br><span class="line"></span><br><span class="line">7 回滚机制 &#x2F; 139</span><br><span class="line">7.1 事务回滚 &#x2F; 139</span><br><span class="line">7.2 代码库回滚 &#x2F; 140</span><br><span class="line">7.3 部署版本回滚 &#x2F; 141</span><br><span class="line">7.4 数据版本回滚 &#x2F; 142</span><br><span class="line">7.5 静态资源版本回滚 &#x2F; 143</span><br><span class="line"></span><br><span class="line">8 压测与预案 &#x2F; 145</span><br><span class="line">8.1 系统压测 &#x2F; 145</span><br><span class="line">8.1.1 线下压测 &#x2F; 146</span><br><span class="line">8.1.2 线上压测 &#x2F; 146</span><br><span class="line">8.2 系统优化和容灾 &#x2F; 147</span><br><span class="line">8.3 应急预案 &#x2F; 148</span><br><span class="line"></span><br><span class="line">第3部分 高并发 &#x2F; 153</span><br><span class="line">9 应用级缓存 &#x2F; 154</span><br><span class="line">9.1 缓存简介 &#x2F; 154</span><br><span class="line">9.2 缓存命中率 &#x2F; 155</span><br><span class="line">9.3 缓存回收策略 &#x2F; 155</span><br><span class="line">9.3.1 基于空间 &#x2F; 155</span><br><span class="line">9.3.2 基于容量 &#x2F; 155</span><br><span class="line">9.3.3 基于时间 &#x2F; 155</span><br><span class="line">9.3.4 基于Java对象引用 &#x2F; 156</span><br><span class="line">9.3.5 回收算法 &#x2F; 156</span><br><span class="line">9.4 Java缓存类型 &#x2F; 156</span><br><span class="line">9.4.1 堆缓存 &#x2F; 158</span><br><span class="line">9.4.2 堆外缓存 &#x2F; 162</span><br><span class="line">9.4.3 磁盘缓存 &#x2F; 162</span><br><span class="line">9.4.4 分布式缓存 &#x2F; 164</span><br><span class="line">9.4.5 多级缓存 &#x2F; 166</span><br><span class="line">9.5 应用级缓存示例 &#x2F; 167</span><br><span class="line">9.5.1 多级缓存API封装 &#x2F; 167</span><br><span class="line">9.5.2 NULL Cache &#x2F; 170</span><br><span class="line">9.5.3 强制获取最新数据 &#x2F; 170</span><br><span class="line">9.5.4 失败统计 &#x2F; 171</span><br><span class="line">9.5.5 延迟报警 &#x2F; 171</span><br><span class="line">9.6 缓存使用模式实践 &#x2F; 172</span><br><span class="line">9.6.1 Cache-Aside &#x2F; 173</span><br><span class="line">9.6.2 Cache-As-SoR &#x2F; 174</span><br><span class="line">9.6.3 Read-Through &#x2F; 174</span><br><span class="line">9.6.4 Write-Through &#x2F; 176</span><br><span class="line">9.6.5 Write-Behind &#x2F; 177</span><br><span class="line">9.6.6 Copy Pattern &#x2F; 181</span><br><span class="line">9.7 性能测试 &#x2F; 181</span><br><span class="line">9.8 参考资料 &#x2F; 182</span><br><span class="line"></span><br><span class="line">10 HTTP缓存 &#x2F; 183</span><br><span class="line">10.1 简介 &#x2F; 183</span><br><span class="line">10.2 HTTP缓存 &#x2F; 184</span><br><span class="line">10.2.1 Last-Modified &#x2F; 184</span><br><span class="line">10.2.2 ETag &#x2F; 190</span><br><span class="line">10.2.3 总结 &#x2F; 192</span><br><span class="line">10.3 HttpClient客户端缓存 &#x2F; 192</span><br><span class="line">10.3.1 主流程 &#x2F; 195</span><br><span class="line">10.3.2 清除无效缓存 &#x2F; 195</span><br><span class="line">10.3.3 查找缓存 &#x2F; 196</span><br><span class="line">10.3.4 缓存未命中 &#x2F; 198</span><br><span class="line">10.3.5 缓存命中 &#x2F; 198</span><br><span class="line">10.3.6 缓存内容陈旧需重新验证 &#x2F; 202</span><br><span class="line">10.3.7 缓存内容无效需重新执行请求 &#x2F; 205</span><br><span class="line">10.3.8 缓存响应 &#x2F; 206</span><br><span class="line">10.3.9 缓存头总结 &#x2F; 207</span><br><span class="line">10.4 Nginx HTTP缓存设置 &#x2F; 208</span><br><span class="line">10.4.1 expires &#x2F; 208</span><br><span class="line">10.4.2 if-modified-since &#x2F; 209</span><br><span class="line">10.4.3 nginx proxy_pass &#x2F; 209</span><br><span class="line">10.5 Nginx代理层缓存 &#x2F; 212</span><br><span class="line">10.5.1 Nginx代理层缓存配置 &#x2F; 212</span><br><span class="line">10.5.2 清理缓存 &#x2F; 215</span><br><span class="line">10.6 一些经验 &#x2F; 216</span><br><span class="line">参考资料 &#x2F; 217</span><br><span class="line"></span><br><span class="line">11 多级缓存 &#x2F; 218</span><br><span class="line">11.1 多级缓存介绍 &#x2F; 218</span><br><span class="line">11.2 如何缓存数据 &#x2F; 220</span><br><span class="line">11.2.1 过期与不过期 &#x2F; 220</span><br><span class="line">11.2.2 维度化缓存与增量缓存 &#x2F; 221</span><br><span class="line">11.2.3 大Value缓存 &#x2F; 221</span><br><span class="line">11.2.4 热点缓存 &#x2F; 221</span><br><span class="line">11.3 分布式缓存与应用负载均衡 &#x2F; 222</span><br><span class="line">11.3.1 缓存分布式 &#x2F; 222</span><br><span class="line">11.3.2 应用负载均衡 &#x2F; 222</span><br><span class="line">11.4 热点数据与更新缓存 &#x2F; 223</span><br><span class="line">11.4.1 单机全量缓存+主从 &#x2F; 223</span><br><span class="line">11.4.2 分布式缓存+应用本地热点 &#x2F; 224</span><br><span class="line">11.5 更新缓存与原子性 &#x2F; 225</span><br><span class="line">11.6 缓存崩溃与快速修复 &#x2F; 226</span><br><span class="line">11.6.1 取模 &#x2F; 226</span><br><span class="line">11.6.2 一致性哈希 &#x2F; 226</span><br><span class="line">11.6.3 快速恢复 &#x2F; 226</span><br><span class="line"></span><br><span class="line">12 连接池线程池详解 &#x2F; 227</span><br><span class="line">12.1 数据库连接池 &#x2F; 227</span><br><span class="line">12.1.1 DBCP连接池配置 &#x2F; 228</span><br><span class="line">12.1.2 DBCP配置建议 &#x2F; 233</span><br><span class="line">12.1.3 数据库驱动超时实现 &#x2F; 234</span><br><span class="line">12.1.4 连接池使用的一些建议 &#x2F; 235</span><br><span class="line">12.2 HttpClient连接池 &#x2F; 236</span><br><span class="line">12.2.1 HttpClient 4.5.2配置 &#x2F; 236</span><br><span class="line">12.2.2 HttpClient连接池源码分析 &#x2F; 240</span><br><span class="line">12.2.3 HttpClient 4.2.3配置 &#x2F; 241</span><br><span class="line">12.2.4 问题示例 &#x2F; 243</span><br><span class="line">12.3 线程池 &#x2F; 244</span><br><span class="line">12.3.1 Java线程池 &#x2F; 245</span><br><span class="line">12.3.2 Tomcat线程池配置 &#x2F; 248</span><br><span class="line"></span><br><span class="line">13 异步并发实战 &#x2F; 250</span><br><span class="line">13.1 同步阻塞调用 &#x2F; 251</span><br><span class="line">13.2 异步Future &#x2F; 252</span><br><span class="line">13.3 异步Callback &#x2F; 253</span><br><span class="line">13.4 异步编排CompletableFuture &#x2F; 254</span><br><span class="line">13.5 异步Web服务实现 &#x2F; 257</span><br><span class="line">13.6 请求缓存 &#x2F; 259</span><br><span class="line">13.7 请求合并 &#x2F; 261</span><br><span class="line"></span><br><span class="line">14 如何扩容 &#x2F; 266</span><br><span class="line">14.1 单体应用垂直扩容 &#x2F; 267</span><br><span class="line">14.2 单体应用水平扩容 &#x2F; 267</span><br><span class="line">14.3 应用拆分 &#x2F; 268</span><br><span class="line">14.4 数据库拆分 &#x2F; 271</span><br><span class="line">14.5 数据库分库分表示例 &#x2F; 275</span><br><span class="line">14.5.1 应用层还是中间件层 &#x2F; 275</span><br><span class="line">14.5.2 分库分表策略 &#x2F; 277</span><br><span class="line">14.5.3 使用sharding-jdbc分库分表 &#x2F; 279</span><br><span class="line">14.5.4 sharding-jdbc分库分表配置 &#x2F; 279</span><br><span class="line">14.5.5 使用sharding-jdbc读写分离 &#x2F; 283</span><br><span class="line">14.6 数据异构 &#x2F; 284</span><br><span class="line">14.6.1 查询维度异构 &#x2F; 284</span><br><span class="line">14.6.2 聚合数据异构 &#x2F; 285</span><br><span class="line">14.7 任务系统扩容 &#x2F; 285</span><br><span class="line">14.7.1 简单任务 &#x2F; 285</span><br><span class="line">14.7.2 分布式任务 &#x2F; 287</span><br><span class="line">14.7.3 Elastic-Job简介 &#x2F; 287</span><br><span class="line">14.7.4 Elastic-Job-Lite功能与架构 &#x2F; 287</span><br><span class="line">14.7.5 Elastic-Job-Lite示例 &#x2F; 288</span><br><span class="line"></span><br><span class="line">15 队列术 &#x2F; 295</span><br><span class="line">15.1 应用场景 &#x2F; 295</span><br><span class="line">15.2 缓冲队列 &#x2F; 296</span><br><span class="line">15.3 任务队列 &#x2F; 297</span><br><span class="line">15.4 消息队列 &#x2F; 297</span><br><span class="line">15.5 请求队列 &#x2F; 299</span><br><span class="line">15.6 数据总线队列 &#x2F; 300</span><br><span class="line">15.7 混合队列 &#x2F; 301</span><br><span class="line">15.8 其他队列 &#x2F; 302</span><br><span class="line">15.9 Disruptor+Redis队列 &#x2F; 303</span><br><span class="line">15.10 下单系统水平可扩展架构 &#x2F; 311</span><br><span class="line">15.10.1 下单服务</span><br><span class="line">15.10.2 同步Worker</span><br><span class="line">15.11 基于Canal实现数据异构</span><br><span class="line">15.11.1 Mysql 主从复制</span><br><span class="line">15.11.2 Canal简介</span><br><span class="line">15.11.3 Canal示例</span><br><span class="line"></span><br><span class="line">第4部分 案例 &#x2F; 323</span><br><span class="line">16 构建需求响应式亿级商品详情页 &#x2F; 324</span><br><span class="line">16.1 商品详情页是什么 &#x2F; 324</span><br><span class="line">16.2 商品详情页前端结构 &#x2F; 325</span><br><span class="line">16.3 我们的性能数据 &#x2F; 327</span><br><span class="line">16.4 单品页流量特点 &#x2F; 327</span><br><span class="line">16.5 单品页技术架构发展 &#x2F; 327</span><br><span class="line">16.5.1 架构1.0 &#x2F; 328</span><br><span class="line">16.5.2 架构2.0 &#x2F; 328</span><br><span class="line">16.5.3 架构3.0 &#x2F; 330</span><br><span class="line">16.6 详情页架构设计原则 &#x2F; 332</span><br><span class="line">16.6.1 数据闭环</span><br><span class="line">16.6.2 数据维度化</span><br><span class="line">16.6.3 拆分系统</span><br><span class="line">16.6.4 Worker无状态化+任务化</span><br><span class="line">16.6.5 异步化+并发化</span><br><span class="line">16.6.6 多级缓存化</span><br><span class="line">16.6.7 动态化</span><br><span class="line">16.6.8 弹性化</span><br><span class="line">16.6.9 降级开关</span><br><span class="line">16.6.10 多机房多活</span><br><span class="line">16.6.11 多种压测方案</span><br><span class="line">16.7 遇到的一些坑和问题 &#x2F; 339</span><br><span class="line">16.7.1 SSD性能差</span><br><span class="line">16.7.2 键值存储选型压测</span><br><span class="line">16.7.3 数据量大时JIMDB同步不动</span><br><span class="line">16.7.4 切换主从</span><br><span class="line">16.7.5 分片配置</span><br><span class="line">16.7.6 模板元数据存储HTML</span><br><span class="line">16.7.7 库存接口访问量600w&#x2F;分钟</span><br><span class="line">16.7.8 微信接口调用量暴增</span><br><span class="line">16.7.9 开启Nginx Proxy Cache性能不升反降</span><br><span class="line">16.7.10 配送至读服务因依赖太多，响应时间偏慢</span><br><span class="line">16.7.11 网络抖动时，返回502错误</span><br><span class="line">16.7.12 机器流量太大</span><br><span class="line">16.8 其他 &#x2F; 347</span><br><span class="line"></span><br><span class="line">17 京东商品详情页服务闭环实践 &#x2F; 348</span><br><span class="line">17.1 为什么需要统一服务 &#x2F; 348</span><br><span class="line">17.2 整体架构 &#x2F; 349</span><br><span class="line">17.3 一些架构思路和总结 &#x2F; 350</span><br><span class="line">17.3.1 两种读服务架构模式</span><br><span class="line">17.3.2 本地缓存</span><br><span class="line">17.3.3多级缓存</span><br><span class="line">17.3.4 统一入口&#x2F;服务闭环</span><br><span class="line">17.4 引入Nginx接入层 &#x2F; 354</span><br><span class="line">17.4.1 数据校验&#x2F;过滤逻辑前置</span><br><span class="line">17.4.2 缓存前置</span><br><span class="line">17.4.3 业务逻辑前置</span><br><span class="line">17.4.4 降级开关前置</span><br><span class="line">17.4.5 AB测试</span><br><span class="line">17.4.6 灰度发布&#x2F;流量切换</span><br><span class="line">17.4.7 监控服务质量</span><br><span class="line">17.4.8 限流</span><br><span class="line">17.5 前端业务逻辑后置 &#x2F; 356</span><br><span class="line">17.6 前端接口服务端聚合 &#x2F; 357</span><br><span class="line">17.7 服务隔离 &#x2F; 359</span><br><span class="line"></span><br><span class="line">18 使用OpenResty开发高性能Web应用 &#x2F; 360</span><br><span class="line">18.1 OpenResty简介 &#x2F; 361</span><br><span class="line">18.1.1 Nginx优点 &#x2F; 361</span><br><span class="line">18.1.2 Lua的优点 &#x2F; 361</span><br><span class="line">18.1.3 什么是ngx_lua &#x2F; 361</span><br><span class="line">18.1.4 开发环境 &#x2F; 362</span><br><span class="line">18.1.5 OpenResty生态 &#x2F; 362</span><br><span class="line">18.1.6 场景 &#x2F; 362</span><br><span class="line">18.2 基于OpenResty的常用架构模式 &#x2F; 363</span><br><span class="line">18.2.1 负载均衡</span><br><span class="line">18.2.2 单机闭环</span><br><span class="line">18.2.3 分布式闭环</span><br><span class="line">18.2.4 接入网关</span><br><span class="line">18.2.5 Web应用</span><br><span class="line">18.3 如何使用OpenResty开发Web应用 &#x2F; 371</span><br><span class="line">18.3.1 项目搭建</span><br><span class="line">18.3.2 启停脚本</span><br><span class="line">18.3.3 配置文件</span><br><span class="line">18.3.4 nginx.conf配置文件</span><br><span class="line">18.3.5 nginx 项目配置文件</span><br><span class="line">18.3.6 业务代码</span><br><span class="line">18.3.7 模板</span><br><span class="line">18.3.8 公共Lua库</span><br><span class="line">18.3.9 功能开发</span><br><span class="line">18.4 基于OpenResty的常用功能总结 &#x2F; 375</span><br><span class="line">18.5 一些问题 &#x2F; 376</span><br><span class="line"></span><br><span class="line">19 应用数据静态化架构高性能单页Web应用 &#x2F; 377</span><br><span class="line">19.1 整体架构 &#x2F; 378</span><br><span class="line">19.1.1 CMS系统</span><br><span class="line">19.1.2 前端展示系统</span><br><span class="line">19.1.3 控制系统</span><br><span class="line">19.2 数据和模板动态化 &#x2F; 381</span><br><span class="line">19.3 多版本机制 &#x2F; 381</span><br><span class="line">19.4 异常问题 &#x2F; 382</span><br><span class="line"></span><br><span class="line">20 使用OpenResty开发Web服务 &#x2F; 383</span><br><span class="line">20.1 架构 &#x2F; 383</span><br><span class="line">20.2 单DB架构 &#x2F; 384</span><br><span class="line">20.2.1 DB+Cache&#x2F;数据库读写分离架构</span><br><span class="line">20.2.2 OpenResty+Local Redis+Mysql集群架构</span><br><span class="line">20.2.3 OpenResty+Redis集群+Mysql集群架构</span><br><span class="line">20.3 实现 &#x2F; 387</span><br><span class="line">20.3.1 后台逻辑</span><br><span class="line">20.3.2 前台逻辑</span><br><span class="line">20.3.3 项目搭建</span><br><span class="line">20.3.4 Redis+Twemproxy配置</span><br><span class="line">20.3.5 Mysql+Atlas配置</span><br><span class="line">20.3.6 Java+Tomcat安装</span><br><span class="line">20.3.7 Java+Tomcat逻辑开发</span><br><span class="line">20.3.8 Nginx+Lua逻辑开发</span><br><span class="line"></span><br><span class="line">21 使用OpenResty开发商品详情页 405</span><br><span class="line">21.1 技术选型 407</span><br><span class="line">21.2 核心流程 408</span><br><span class="line">21.3 项目搭建 408</span><br><span class="line">21.4 数据存储实现 410</span><br><span class="line">21.4.1 商品基本信息SSDB集群配置 410</span><br><span class="line">21.4.2 商品介绍SSDB集群配置 413</span><br><span class="line">21.4.3 其他信息Redis配置 417</span><br><span class="line">21.4.4 集群测试 418</span><br><span class="line">21.4.5 Twemproxy配置 419</span><br><span class="line">21.5 动态服务实现 422</span><br><span class="line">21.5.1 项目搭建 422</span><br><span class="line">21.5.2 项目依赖 422</span><br><span class="line">21.5.3 核心代码 423</span><br><span class="line">21.5.4 web.xml配置 428</span><br><span class="line">21.5.5 打WAR包 428</span><br><span class="line">21.5.10 配置Tomcat 428</span><br><span class="line">21.5.11 测试 429</span><br><span class="line">21.5.12 Nginx配置 429</span><br><span class="line">21.5.13 绑定hosts测试 430</span><br><span class="line">21.6 前端展示实现 430</span><br><span class="line">21.6.1 基础组件 430</span><br><span class="line">21.6.2 商品介绍 432</span><br><span class="line">21.6.4 前端展示 434</span><br><span class="line">21.6.5 测试 442</span><br><span class="line">21.6.6 优化 442</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>清醒思考的艺术</title>
    <url>/java-other/book--%E6%B8%85%E9%86%92%E6%80%9D%E8%80%83%E7%9A%84%E8%89%BA%E6%9C%AF/</url>
    <content><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、幸存偏误</span><br><span class="line">为什么你该去逛逛墓地</span><br><span class="line">2、游泳选手身材错觉</span><br><span class="line">哈佛是好大学还是烂大学？我们不清楚</span><br><span class="line">3、过度自信效应</span><br><span class="line">你为什么会系统性地高估自己的学识和能力</span><br><span class="line">4、从众心理</span><br><span class="line">就算有数百万人声称某件蠢事是对的，这件蠢事也不会因此成为聪明之举</span><br><span class="line">5、纠缠于沉没成本</span><br><span class="line">你为什么应该忽视过去</span><br><span class="line">6、互惠偏误</span><br><span class="line">你为什么不该让别人请你喝饮料</span><br><span class="line">7、确认偏误之一</span><br><span class="line">遇到“特殊情况”这个词，你要格外小心</span><br><span class="line">8、确认偏误之二</span><br><span class="line">干掉你的宠儿</span><br><span class="line">9、权威偏误</span><br><span class="line">你为什么该藐视权威</span><br><span class="line">10、对比效应</span><br><span class="line">你为什么最好别找模特儿等级的朋友一起出门</span><br><span class="line">11、现成偏误</span><br><span class="line">你为什么宁可用一张错误的地图，也不愿没有地图</span><br><span class="line">12、“在好转之前会先恶化”的陷阱</span><br><span class="line">如果有人建议你选择一条“先经历痛苦的道路”，你应该敲响警钟</span><br><span class="line">13、故事偏误</span><br><span class="line">为什么就连真实的故事也是骗局</span><br><span class="line">14、事后诸葛亮偏误</span><br><span class="line">你为什么应该写日记</span><br><span class="line">15、司机的知识</span><br><span class="line">你为什么不可以把新闻播音员说的话当真</span><br><span class="line">16、控制错觉</span><br><span class="line">你实际控制的少于你以为的</span><br><span class="line">17、激励过敏倾向</span><br><span class="line">你为什么不该按实际开销付钱给你的律师</span><br><span class="line">18、回归均值</span><br><span class="line">医生、顾问、教练及心理治疗师的作用令人怀疑</span><br><span class="line">19、公地悲剧</span><br><span class="line">为什么理性的人不去诉诸理性</span><br><span class="line">20、结果偏误</span><br><span class="line">切勿以结果判断决定</span><br><span class="line">21、选择的悖论</span><br><span class="line">为什么更多反而是更少</span><br><span class="line">22、讨喜偏误</span><br><span class="line">你行为不理性，是因为你想讨别人喜欢</span><br><span class="line">23、禀赋效应</span><br><span class="line">请不要死抱着某种东西不放</span><br><span class="line">24、奇迹</span><br><span class="line">不可能事件的必然性</span><br><span class="line">25、团体迷思</span><br><span class="line">共识为什么有可能是危险的</span><br><span class="line">26、忽视概率偏误</span><br><span class="line">累计奖金为什么会越来越多</span><br><span class="line">27、零风险偏误</span><br><span class="line">你为什么会为零风险支付过多</span><br><span class="line">28、稀少性谬误</span><br><span class="line">为什么饼干越少越好吃</span><br><span class="line">29、忽视基本概率</span><br><span class="line">当你在怀俄明州听到马蹄声、见到黑白条纹时</span><br><span class="line">30、赌徒谬误</span><br><span class="line">为什么没有一种平衡命运的力量</span><br><span class="line">31、锚定效应</span><br><span class="line">数字轮盘如何搞得我们晕头转向</span><br><span class="line">32、归纳法</span><br><span class="line">如何把别人的钱弄进自己的口袋</span><br><span class="line">33、规避损失</span><br><span class="line">为什么凶恶的面孔比友善的面孔更容易引起我们注意</span><br><span class="line">34、社会性懈怠</span><br><span class="line">团队为什么会使人懒惰</span><br><span class="line">35、指数增长</span><br><span class="line">一张对折的纸为什么会超出我们的想象</span><br><span class="line">36、赢家的诅咒</span><br><span class="line">你愿意为100欧元支付多少钱？</span><br><span class="line">37、基本特征谬误</span><br><span class="line">千万别问一位作家他的小说是不是自传</span><br><span class="line">38、错误的因果关系</span><br><span class="line">你为什么不该相信仙鹤送子</span><br><span class="line">39、光环效应</span><br><span class="line">长相好的人为什么容易事业有成</span><br><span class="line">40、替代途径</span><br><span class="line">恭喜你赢了俄罗斯轮盘赌</span><br><span class="line">41、预测的错觉</span><br><span class="line">水晶球如何歪曲了你的目光</span><br><span class="line">42、关联谬误</span><br><span class="line">有说服力的故事为什么会误导人</span><br><span class="line">43、框架效应</span><br><span class="line">言为心声</span><br><span class="line">44、行动偏误</span><br><span class="line">为什么不行动光等待是种痛苦</span><br><span class="line">45、不作为偏误</span><br><span class="line">为什么你不是答案就是问题</span><br><span class="line">46、自利偏误</span><br><span class="line">你为什么从不自责</span><br><span class="line">47、享乐适应症</span><br><span class="line">你为什么应该缩短上班路程</span><br><span class="line">48、自我选择偏误</span><br><span class="line">请不要惊讶有你存在</span><br><span class="line">49、联想偏误</span><br><span class="line">为什么经验有时让人变蠢</span><br><span class="line">50、新手的运气</span><br><span class="line">假如开始时一切顺利，请务必多加小心</span><br><span class="line">51、认知失调</span><br><span class="line">你如何撒点小谎，让自己感觉好一些</span><br><span class="line">52、双曲贴现</span><br><span class="line">及时行乐——但请只限于星期天</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>intellij-back-forward</title>
    <url>/java-other/intellij-back-forward/</url>
    <content><![CDATA[<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-other/1.png/w600">
<a id="more"></a>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>读书单</title>
    <url>/java-other/book/</url>
    <content><![CDATA[<h1 id="一、技术类"><a href="#一、技术类" class="headerlink" title="一、技术类"></a>一、技术类</h1><h2 id="1-JAVA、WEB、架构"><a href="#1-JAVA、WEB、架构" class="headerlink" title="1. JAVA、WEB、架构"></a>1. JAVA、WEB、架构</h2><a id="more"></a>
<ul>
<li>《分布式Java应用——基础与实践》</li>
<li>《深入分析Java Web技术内幕》</li>
<li>《大型网站系统与Java中间件实践》</li>
<li>《分布式服务框架原理与实践》</li>
<li>《Java并发编程实战》</li>
<li>《Java7 并发编程实战手册》</li>
<li>《淘宝技术这十年》</li>
<li>《大话设计模式》</li>
<li>《构建高性能Web站点》</li>
<li>《Spring Boot揭秘（快速构建微服务体系）》</li>
<li>《Spring Boot实战》</li>
<li>《Spring Cloud微服务实战 》</li>
<li>《深入理解Java 虚拟机》</li>
<li>《Spring 2.x企业应用开发详解》</li>
<li>《Spring 3.X企业应用开发实践》</li>
<li>《深入剖析Tomcat》</li>
<li>《Java性能优化权威指南》</li>
<li>《Elasticsearch服务器开发（第2版）》</li>
<li>《深入理解ElasticsSearch》</li>
<li>《Elasticsearch技术解析与实战》</li>
<li>《从Paxos到ZooKeeper》</li>
<li>《Java8函数式编程》</li>
<li>《ELKstack权威指南》</li>
<li>《UML与Rational Rose 2003从入门到精通》</li>
<li>《Maven实战》</li>
<li>《iBATIS实战》</li>
<li>《Netty权威指南》</li>
<li>《java 数值计算法编程》</li>
<li>《架构实战（软件架构设计的过程）》</li>
<li><a href="尽在双11——阿里巴巴技术演进与超越.md">《尽在双11——阿里巴巴技术演进与超越》</a></li>
<li><a href="book--亿级流量网站架构核心技术.md">《亿级流量网站架构核心技术——跟开涛学搭建高可用高并发系统》</a></li>
<li>《分布式数据库架构及企业实践——基于Mycat中间件》</li>
<li>《Apache Kafka源码剖析》</li>
<li>《Docker从入门到实战》</li>
<li>《Tomcat架构解析》</li>
<li><a href="book--Java8实战.md">《Java8实战》</a></li>
<li>《分布式服务架构：原理、设计与实战》</li>
<li>《疯狂Spring Cloud微服务架构实战》</li>
<li>《深入理解Spring Cloud与微服务构建》</li>
<li>《Python+Spark 2.0+Hadoop机器学习与大数据实战》</li>
<li><a href="book--深入分布式缓存：从原理到实践.md">《深入分布式缓存：从原理到实践》</a></li>
<li><a href="book--可伸缩服务架构：框架与中间件.md">《可伸缩服务架构：框架与中间件》</a></li>
<li><a href="book--从零开始学架构.md">《从零开始学架构》</a></li>
<li>《NoSQL数据库入门与实践（基于MongoDB、Redis）》</li>
</ul>
<h2 id="2-DB、大数据"><a href="#2-DB、大数据" class="headerlink" title="2. DB、大数据"></a>2. DB、大数据</h2><ul>
<li>《高性能MySQL》</li>
<li>《Oracle Database 11g SQL开发指南》</li>
<li>《Redis入门指南（第2版）》</li>
<li>《Redis实战》</li>
<li>《Redis设计与实现》</li>
<li>《HBase企业应用开发实战》</li>
<li>《HBase应用架构》</li>
<li>《HBase不睡觉书》</li>
<li>《Storm实战》</li>
<li><strong>《Spark Streaming:实时流处理入门与精通》</strong></li>
<li><strong>《Spark大数据分析:核心概念、技术及实践》</strong></li>
<li>《spark大数据处理技术》</li>
<li>《Spark零基础实战》</li>
<li>《大数据架构商业之路:从业务需求到技术方案》</li>
<li>《大数据策略(如何成功使用大数据与10个行业案例分享)/大数据应用与技术丛书》</li>
<li>《大数据架构师指南》</li>
<li>《大数据架构详解:从数据获取到深度学习》</li>
<li>《大数据挖掘:系统方法与实例分析》</li>
</ul>
<h2 id="3-其它"><a href="#3-其它" class="headerlink" title="3. 其它"></a>3. 其它</h2><ul>
<li>《图解TCP/IP》</li>
<li>《Python基础教程》</li>
<li>《快学Scala》</li>
<li>《Github入口与实践》</li>
<li>《精通Android 2》</li>
<li>《疯狂Android讲义》</li>
<li>《实用负载均衡技术 网站性能优化攻略》</li>
<li>《大数据日知录架构与算法》</li>
<li>《深入浅出node.js》</li>
<li>《HTTP权威指南》</li>
<li>《海量数据库解决方案》</li>
<li>《领域驱动设计》</li>
<li>《精通Linux完全自学手册》</li>
<li>《Apache源代码全景分析》</li>
<li>《Apache经典实例》</li>
<li>《巧用jQuery》</li>
<li>《技术之瞳（阿里巴巴技术笔试心得）》</li>
</ul>
<h1 id="二、互联网相关"><a href="#二、互联网相关" class="headerlink" title="二、互联网相关"></a>二、互联网相关</h1><ul>
<li>《人人都是产品经理》</li>
<li>《YES!产品经理》</li>
<li>《在线》</li>
<li>《互联网+ 国家战略行动路线图》</li>
<li>《重新定义公司–谷歌是如何运营的》</li>
<li>《Google:未来之镜(全球创新巨头真正的工作、思索与规划)》</li>
<li><a href="book--三板斧阿里巴巴管理之道.md">《三板斧–阿里巴巴管理之道》</a></li>
<li>《mac Talk 跨越边界》</li>
<li>《mac Talk 人生元编程》</li>
<li>《像外行一样思考，像专家一样实践》</li>
<li>《浪潮之巅》</li>
<li>《引爆点（如何引发流行）》</li>
<li>《异类（不一样的成功启示录）》</li>
<li>《增长黑客》</li>
<li>《挖财：理财就是身边事》</li>
<li>《网易一千零一夜（互网联产品项目管理实战）》</li>
</ul>
<h1 id="三、闲书"><a href="#三、闲书" class="headerlink" title="三、闲书"></a>三、闲书</h1><ul>
<li>《做自己》</li>
<li>《没事别随便思考人生》</li>
<li>《人生所有经过的路，都是必经之路》</li>
<li>《人类简史》</li>
<li>《登天的感觉》</li>
<li>《这个历史挺靠谱（上）》</li>
<li>《这个历史挺靠谱（中）》</li>
<li>《这个历史挺靠谱（下）》</li>
<li>《看见》</li>
<li>《我是爬行者小江》</li>
<li>《富爸爸穷爸爸》</li>
<li>《茶经》</li>
<li>《图解茶经》</li>
<li>《超预测》</li>
<li>《必然》</li>
<li>《天才在左 疯子在右》</li>
<li>《图解犹太人智慧书》</li>
<li>《秘密》</li>
<li>《我的奋斗》</li>
<li>《干法》</li>
<li>《一万小时天才理论》</li>
<li>《围城》</li>
<li>《金刚经·心经》</li>
<li>《人生可以走直线》</li>
<li>《没有做不到的事，只有不会做事的人》</li>
<li>《货币战争》</li>
<li>《自控力》</li>
<li>《马云说》</li>
<li>《李敖自传》</li>
<li>《智慧资本》</li>
<li><a href="book--情商3.md">《情商3》</a></li>
<li>《孙子兵法》</li>
<li>《重来》</li>
<li><a href="book--清醒思考的艺术.md">《清醒思考的艺术》</a></li>
</ul>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>大厂面试题</title>
    <url>/java/%E5%A4%A7%E5%8E%82%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<h1 id="JAVA"><a href="#JAVA" class="headerlink" title="JAVA"></a>JAVA</h1><h2 id="Java常用的数据结构有哪些-哪些是线程安全的-是怎么保证线程安全的？"><a href="#Java常用的数据结构有哪些-哪些是线程安全的-是怎么保证线程安全的？" class="headerlink" title="Java常用的数据结构有哪些?哪些是线程安全的?是怎么保证线程安全的？"></a>Java常用的数据结构有哪些?哪些是线程安全的?是怎么保证线程安全的？</h2><a id="more"></a>
<p><a href="../Java开发中常用的数据结构">Java开发中常用的数据结构</a><br><a href="../Java中满足线程安全的数据结构">简述Java中满足线程安全的数据结构</a></p>
<h2 id="多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？"><a href="#多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？" class="headerlink" title="多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？"></a>多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？</h2><p>ReadWriteLock读写锁</p>
<h2 id="JAVA的AQS是否了解，它是干嘛的？"><a href="#JAVA的AQS是否了解，它是干嘛的？" class="headerlink" title="JAVA的AQS是否了解，它是干嘛的？"></a>JAVA的AQS是否了解，它是干嘛的？</h2><p>AbstractQueuedSynchronizer（AQS）为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁定和相关同步器（信号量、事件，等等）提供一个框架。<br>要明白AQS在功能上有独占锁和共享锁两种功能。</p>
<h2 id="除了synchronized关键字之外，你是怎么来保障线程安全的？"><a href="#除了synchronized关键字之外，你是怎么来保障线程安全的？" class="headerlink" title="除了synchronized关键字之外，你是怎么来保障线程安全的？"></a>除了synchronized关键字之外，你是怎么来保障线程安全的？</h2><pre><code>- 1、互斥同步(阻塞同步)，悲观并发策略
  synchronized关键字 、ReentrantLock
- 2、非阻塞同步，基于冲突检测的乐观并发策略
    非阻塞的实现CAS（compareandswap）：CAS指令需要有3个操作数，分别是内存地址（在java中理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，CAS指令指令时，当且仅当V处的值符合旧预期值A时，处理器用B更新V处的值，否则它就不执行更新，但是无论是否更新了V处的值，都会返回V的旧值，上述的处理过程是一个原子操作。
    CAS缺点：
        - ABA问题：因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。

        - ABA问题的解决思路就是使用版本号。在变量前面追加版本号，每次变量更新的时候把版本号加一，那么A-B-A就变成了1A-2B-3C。JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

- 3、无需同步方案
    要保证线程安全，并不是一定就要进行同步，两者没有因果关系。同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无需任何同步操作去保证正确性，因此会有一些代码天生就是线程安全的。

    - 1）可重入代码
       可重入代码（ReentrantCode）也称为纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码，而在控制权返回后，原来的程序不会出现任何错误。所有的可重入代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。

       可重入代码的特点是不依赖存储在堆上的数据和公用的系统资源、用到的状态量都是由参数中传入、不调用 非可重入的方法等。

       （类比：synchronized拥有锁重入的功能，也就是在使用synchronized时，当一个线程得到一个对象锁后，再次请求此对象锁时时可以再次得到该对象的锁）

    - 2）线程本地存储

       如果一段代码中所需的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内。这样无需同步也能保证线程之间不出现数据的争用问题。

       符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典的Web交互模型中的“一个请求对应一个服务器线程（Thread-per-Request）”的处理方式，这种处理方式的广泛应用使得很多Web服务器应用都可以使用线程本地存储来解决线程安全问题。</code></pre><h2 id="Tomcat本身的参数你一般会怎么调整？"><a href="#Tomcat本身的参数你一般会怎么调整？" class="headerlink" title="Tomcat本身的参数你一般会怎么调整？"></a>Tomcat本身的参数你一般会怎么调整？</h2><h2 id="HashMap和Hashtable的区别。"><a href="#HashMap和Hashtable的区别。" class="headerlink" title="HashMap和Hashtable的区别。"></a>HashMap和Hashtable的区别。</h2><h2 id="实现一个保证迭代顺序的HashMap。"><a href="#实现一个保证迭代顺序的HashMap。" class="headerlink" title="实现一个保证迭代顺序的HashMap。"></a>实现一个保证迭代顺序的HashMap。</h2><h2 id="说说HashMap的原理-以及HashMap如何扩充bucket的大小。"><a href="#说说HashMap的原理-以及HashMap如何扩充bucket的大小。" class="headerlink" title="说说HashMap的原理, 以及HashMap如何扩充bucket的大小。"></a>说说HashMap的原理, 以及HashMap如何扩充bucket的大小。</h2><h2 id="说一说排序算法，稳定性，复杂度。"><a href="#说一说排序算法，稳定性，复杂度。" class="headerlink" title="说一说排序算法，稳定性，复杂度。"></a>说一说排序算法，稳定性，复杂度。</h2><h2 id="TCP如何保证可靠传输？三次握手过程？"><a href="#TCP如何保证可靠传输？三次握手过程？" class="headerlink" title="TCP如何保证可靠传输？三次握手过程？"></a>TCP如何保证可靠传输？三次握手过程？</h2><h2 id="如何控制某个方法允许并发访问线程的个数"><a href="#如何控制某个方法允许并发访问线程的个数" class="headerlink" title="如何控制某个方法允许并发访问线程的个数"></a>如何控制某个方法允许并发访问线程的个数</h2><p>Semaphore（信号量）</p>
<h2 id="死锁是什么意思，形成条件是什么？出现死锁是可以通过什么方式去排查。"><a href="#死锁是什么意思，形成条件是什么？出现死锁是可以通过什么方式去排查。" class="headerlink" title="死锁是什么意思，形成条件是什么？出现死锁是可以通过什么方式去排查。"></a>死锁是什么意思，形成条件是什么？出现死锁是可以通过什么方式去排查。</h2><p>监测死锁可以使用jdk自带的工具。<br>执行jps命令，得到运行的线程的id，<br><code>jps -l</code><br>再执行jstack命令，查看结果。<br><code>jstack -l pid</code></p>
<p>jvisualVM, jconsole</p>
<h2 id="Java中活锁和死锁有什么区别？"><a href="#Java中活锁和死锁有什么区别？" class="headerlink" title="Java中活锁和死锁有什么区别？"></a>Java中活锁和死锁有什么区别？</h2><p>活锁：互相释放资源给对方，结果谁都没有用到这资源。<br>死锁：互相抢着资源，谁都没有抢到。</p>
<h2 id="产生死锁的四个必要条件："><a href="#产生死锁的四个必要条件：" class="headerlink" title="产生死锁的四个必要条件："></a>产生死锁的四个必要条件：</h2><ul>
<li>（1）互斥条件：一个资源每次只能被一个进程使用。</li>
<li>（2）占有且等待：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li>
<li>（3）不可强行占有:进程已获得的资源，在末使用完之前，不能强行剥夺。</li>
<li>（4）循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。</li>
</ul>
<h2 id="如何避免死锁？"><a href="#如何避免死锁？" class="headerlink" title="如何避免死锁？"></a>如何避免死锁？</h2><p>　　加锁顺序（线程按照一定的顺序加锁）；<br>　　加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁）；<br>　　死锁检测。</p>
<h2 id="对于volatile关键字，当且仅当满足以下所有条件时可使用："><a href="#对于volatile关键字，当且仅当满足以下所有条件时可使用：" class="headerlink" title="对于volatile关键字，当且仅当满足以下所有条件时可使用："></a>对于volatile关键字，当且仅当满足以下所有条件时可使用：</h2><ol>
<li>对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。</li>
<li>该变量没有包含在具有其他变量的不变式中。</li>
<li>static是类的属性，存储在类的那块内存，每个线程操作的时候会读取这个内存块，甚至会加载到寄存器或高速缓存中，这样自然不会保证其他线程对该值的可见性；而volatile表示每次读操作直接到内存，如果多个线程都遵循这样的约定，就会读取到最新的状态.<br> PS：synchronized代码块会对变量进行写入操作</li>
</ol>
<h2 id="什么时候需要加volatile关键字？它能保证线程安全吗？"><a href="#什么时候需要加volatile关键字？它能保证线程安全吗？" class="headerlink" title="什么时候需要加volatile关键字？它能保证线程安全吗？"></a>什么时候需要加volatile关键字？它能保证线程安全吗？</h2><p>volatile是不能保证线程安全的，它只是保证了数据的可见性，不会再缓存，</p>
<p>每个线程都是从主存中读到的数据，而不是从缓存中读取的数据，</p>
<p>当synchronized去掉的时候，每个线程的结果是乱的，加上的时候结果才是正确的。</p>
<p>并发编程的3个概念：原子性、可见性、有序性</p>
<ul>
<li>原子性：一个操作或多个操作要么全部执行完成且执行过程不被中断，要么就不执行。</li>
<li>可见性：当多个线程同时访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。</li>
<li>有序性：程序执行的顺序按照代码的先后顺序执行。</li>
</ul>
<h2 id="线程池内的线程如果全部忙，提交一个新的任务，会发生什么？队列全部塞满了之后，还是忙，再提交会发生什么？"><a href="#线程池内的线程如果全部忙，提交一个新的任务，会发生什么？队列全部塞满了之后，还是忙，再提交会发生什么？" class="headerlink" title="线程池内的线程如果全部忙，提交一个新的任务，会发生什么？队列全部塞满了之后，还是忙，再提交会发生什么？"></a>线程池内的线程如果全部忙，提交一个新的任务，会发生什么？队列全部塞满了之后，还是忙，再提交会发生什么？</h2><p>一个任务通过execute(Runnable)方法被添加到线程池，任务就是一个Runnable类型的对象，任务的执行方法就是Runnable类型对象的run()方法。当一个任务通过execute(Runnable)方法想添加到线程池时：</p>
<ul>
<li>如果此时线程池中数量小于corePoolSize,即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。</li>
<li>如果此时线程池中的数量等于corePoolSize,但是缓冲队列workQueue未满，那么任务放入缓冲队列</li>
<li>如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。</li>
<li>如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue 满，并且线程池中的数量等于maximumPoolSize，那么通过handler所指定的策略来处理此任务。也就是：处理任务的优先级为：核心线程 corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务</li>
<li>当线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。<ul>
<li>corePoolSize： 线程池维护线程的最少数量</li>
<li>maxnumPoolSize： 线程池维护线程的最大数量</li>
<li>keepAliveTime： 线程池维护线程所允许的空闲时间</li>
<li>unit： 线程池维护线程所允许的空闲时间的单位</li>
<li>workQueue： 线程池所使用的缓冲队列</li>
<li>handler： 线程池对拒绝任务的处理策略</li>
</ul>
</li>
</ul>
<h2 id="synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？"><a href="#synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？" class="headerlink" title="synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？"></a>synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？</h2><ol>
<li>synchronized锁住的是括号里的对象，不是代码。对于非static的synchronized方法，锁的就是对象本身也就是this。</li>
<li>在java语言中存在两种内建的synchronized语法：<ul>
<li>1、synchronized语句；对于synchronized语句当Java源代码被javac编译成bytecode的时候，会在同步块的入口位置和退出位置分别插入monitorenter和monitorexit字节码指令。</li>
<li>2、synchronized方法。synchronized方法则会被翻译成普通的方法调用和返回指令如:invokevirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象</li>
</ul>
</li>
</ol>
<h2 id="synchronized-的原理是什么？synchronized-和-ReentrantLock-有什么不同？"><a href="#synchronized-的原理是什么？synchronized-和-ReentrantLock-有什么不同？" class="headerlink" title="synchronized 的原理是什么？synchronized 和 ReentrantLock 有什么不同？"></a>synchronized 的原理是什么？synchronized 和 ReentrantLock 有什么不同？</h2><p>这两种方式最大区别就是对于Synchronized来说，它是java语言的关键字，是原生语法层面的互斥，需要jvm实现。而ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。</p>
<p>Synchronized进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。 </p>
<h2 id="wait-notify-notifyAll方法需不需要被包含在synchronized块中？这是为什么？"><a href="#wait-notify-notifyAll方法需不需要被包含在synchronized块中？这是为什么？" class="headerlink" title="wait/notify/notifyAll方法需不需要被包含在synchronized块中？这是为什么？"></a>wait/notify/notifyAll方法需不需要被包含在synchronized块中？这是为什么？</h2><pre><code>Obj.wait()，与Obj.notify()必须要与synchronized(Obj)一起使用，也就是wait,与notify是针对已经获取了Obj锁进行操作。</code></pre><p>　　从语法角度来说就是Obj.wait(),Obj.notify必须synchronized(Obj){…}语句块内。<br>　　从功能上来说wait就是说线程在获取对象锁后，主动释放对象锁，同时本线程休眠。直到有其它线程调用对象的notify()唤醒该线程，才能继续获取对象锁，并继续执行<br>　　如果实例方法含有如下的语句时：wait();则其意义同：this.wait();</p>
<h2 id="Executors类是什么？-Executor和Executors的区别？"><a href="#Executors类是什么？-Executor和Executors的区别？" class="headerlink" title="Executors类是什么？ Executor和Executors的区别？"></a>Executors类是什么？ Executor和Executors的区别？</h2><ol>
<li><p>Executor<br>它是”执行者来”接口，它是来执行任务的。准确的说，Executor提供了execute()接口来执行已提交的 Runnable 任务的对象。Executor存在的目的是提供一源种将”任务提交”与”任务如何运行”分离开来的知机制。它只包含一个函数接口。</p>
</li>
<li><p>Executors<br>Executors是个静态工厂类。它通过静态工厂方法返回到ExecutorService、ScheduledExecutorService、ThreadFactory 和 Callable 等类的对象。</p>
</li>
</ol>
<h2 id="ExecutorService你一般是怎么用的？是每个service放一个还是一个项目里面放一个？有什么好处？"><a href="#ExecutorService你一般是怎么用的？是每个service放一个还是一个项目里面放一个？有什么好处？" class="headerlink" title="ExecutorService你一般是怎么用的？是每个service放一个还是一个项目里面放一个？有什么好处？"></a>ExecutorService你一般是怎么用的？是每个service放一个还是一个项目里面放一个？有什么好处？</h2><p>Java线程池ExecutorService<br>如果有一套相同逻辑的多个任务的情况下,应用一个线程池是个好选择。<br>如果项目中有多套不同的这种任务,那每套任务应该一个线程池。</p>
<h2 id="线程池是什么？为什么要使用它？如何创建一个Java线程池？"><a href="#线程池是什么？为什么要使用它？如何创建一个Java线程池？" class="headerlink" title="线程池是什么？为什么要使用它？如何创建一个Java线程池？"></a>线程池是什么？为什么要使用它？如何创建一个Java线程池？</h2><p>线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。<br>线程池线程都是后台线程。每个线程都使用默认的堆栈大小，以默认的优先级运行，并处于多线程单元中。<br>如果某个线程在托管代码中空闲（如正在等待某个事件），则线程池将插入另一个辅助线程来使所有处理器保持繁忙。<br>如果所有线程池线程都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。<br>超过最大值的线程可以排队，但他们要等到其他线程完成后才启动。</p>
<p>使用线程池的好处:</p>
<ol>
<li>重用存在的线程，减少对象创建、消亡的开销，性能佳。</li>
<li>可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。</li>
<li>提供定时执行、定期执行、单线程、并发数控制等功能。</li>
</ol>
<h2 id="线程池内部工作原理可以说一下么？"><a href="#线程池内部工作原理可以说一下么？" class="headerlink" title="线程池内部工作原理可以说一下么？"></a>线程池内部工作原理可以说一下么？</h2><p>其实java线程池的实现原理很简单，说白了就是一个线程集合workerSet和一个阻塞队列workQueue。当用户向线程池提交一个任务(也就是线程)时，线程池会先将任务放入workQueue中。workerSet中的线程会不断的从workQueue中获取线程然后执行。当workQueue中没有任务的时候，worker就会阻塞，直到队列中有任务了就取出来继续执行。</p>
<h2 id="线程池创建有几种，为什么创建定长的线程池个数最好是5，10，15这样的数字。"><a href="#线程池创建有几种，为什么创建定长的线程池个数最好是5，10，15这样的数字。" class="headerlink" title="线程池创建有几种，为什么创建定长的线程池个数最好是5，10，15这样的数字。"></a>线程池创建有几种，为什么创建定长的线程池个数最好是5，10，15这样的数字。</h2><ol>
<li><p>newCachedThreadPool<br> 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。这种类型的线程池特点是：<br> 工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。<br> 如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。<br> 在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同时运行，很有会造成系统瘫痪。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ExecutorService cachedThreadPool = Executors.newCachedThreadPool();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Thread.sleep(index * <span class="number">1000</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cachedThreadPool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>newFixedThreadPool<br> 创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。</p>
<p> FixedThreadPool是一个典型且优秀的线程池，它具有线程池提高程序效率和节省创建线程时所耗的开销的优点。但是，在线程池空闲时，即线程池中没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源。</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ExecutorService fixedThreadPool = Executors.newFixedThreadPool(<span class="number">3</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    fixedThreadPool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(index);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>newSingleThreadExecutor<br>创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。如果这个线程异常结束，会有另一个取代它，保证顺序执行。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    singleThreadExecutor.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(index);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>newScheduleThreadPool<br>创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(<span class="number">5</span>);</span><br><span class="line">scheduledThreadPool.schedule(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"delay 3 seconds"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;, <span class="number">3</span>, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure></li>
<li><p>newWorkStealingPool：<strong>jdk1.8新增</strong>,创建持有足够线程的线程池来支持给定的并行级别，并通过使用多个队列，减少竞争，它需要穿一个并行级别的参数，如果不传，则被设定为默认的CPU数量。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newWorkStealingPool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ForkJoinPool (Runtime.getRuntime().availableProcessors(),</span><br><span class="line">            ForkJoinPool.defaultForkJoinWorkerThreadFactory,</span><br><span class="line">            <span class="keyword">null</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ForkJoinPool</span><span class="params">(<span class="keyword">int</span> parallelism,</span></span></span><br><span class="line"><span class="function"><span class="params">                    ForkJoinWorkerThreadFactory factory,</span></span></span><br><span class="line"><span class="function"><span class="params">                    UncaughtExceptionHandler handler,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">boolean</span> asyncMode)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(checkParallelism(parallelism),</span><br><span class="line">            checkFactory(factory),</span><br><span class="line">            handler,</span><br><span class="line">            asyncMode ? FIFO_QUEUE : LIFO_QUEUE,</span><br><span class="line">            <span class="string">"ForkJoinPool-"</span> + nextPoolId() + <span class="string">"-worker-"</span>);</span><br><span class="line">    checkPermission();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>可以看出前四种线程池最终都是返回了ThreadPoolExecutor对象，最后一个返回的ForkJoinPool是jdk1.7才新增的。</p>
<p><strong>线程池个数:</strong></p>
<ol>
<li>先看下机器的CPU核数，然后在设定具体参数：</li>
</ol>
<p>即CPU核数 = Runtime.getRuntime().availableProcessors()</p>
<ol start="2">
<li>分析下线程池处理的程序是CPU密集型，还是IO密集型</li>
</ol>
<ul>
<li><p>CPU密集型：核心线程数 = CPU核数 + 1</p>
</li>
<li><p>IO密集型：核心线程数 = CPU核数 * 2</p>
</li>
</ul>
<p>注：IO密集型（某大厂实践经验）</p>
<ul>
<li>核心线程数 = CPU核数 / （1-阻塞系数）<br>例如阻塞系数 0.8，CPU核数为4,则核心线程数为20</li>
</ul>
<h2 id="在交易过程中如何放在用户在支付时的重复支付（交叉支付），请写出你了解的方案或使用的过的方案。"><a href="#在交易过程中如何放在用户在支付时的重复支付（交叉支付），请写出你了解的方案或使用的过的方案。" class="headerlink" title="在交易过程中如何放在用户在支付时的重复支付（交叉支付），请写出你了解的方案或使用的过的方案。"></a>在交易过程中如何放在用户在支付时的重复支付（交叉支付），请写出你了解的方案或使用的过的方案。</h2><h2 id="程序开发时通过开发工具DeBug调试时，控制台显示的内容都包含什么？哪些内容可以帮助你发现问题和解决问题。"><a href="#程序开发时通过开发工具DeBug调试时，控制台显示的内容都包含什么？哪些内容可以帮助你发现问题和解决问题。" class="headerlink" title="程序开发时通过开发工具DeBug调试时，控制台显示的内容都包含什么？哪些内容可以帮助你发现问题和解决问题。"></a>程序开发时通过开发工具DeBug调试时，控制台显示的内容都包含什么？哪些内容可以帮助你发现问题和解决问题。</h2><h2 id="RPC通信过程中，假设A系统提供了一个方法入参是一个JavaBean，出参也是一个JavaBean。另外两个系统B系统、C系统调用接口，调用方B想让提供方A增加一个返回参数，假设服务提供方A增加了返回参数，请问C系统调用方需要做什么处理？"><a href="#RPC通信过程中，假设A系统提供了一个方法入参是一个JavaBean，出参也是一个JavaBean。另外两个系统B系统、C系统调用接口，调用方B想让提供方A增加一个返回参数，假设服务提供方A增加了返回参数，请问C系统调用方需要做什么处理？" class="headerlink" title="RPC通信过程中，假设A系统提供了一个方法入参是一个JavaBean，出参也是一个JavaBean。另外两个系统B系统、C系统调用接口，调用方B想让提供方A增加一个返回参数，假设服务提供方A增加了返回参数，请问C系统调用方需要做什么处理？"></a>RPC通信过程中，假设A系统提供了一个方法入参是一个JavaBean，出参也是一个JavaBean。另外两个系统B系统、C系统调用接口，调用方B想让提供方A增加一个返回参数，假设服务提供方A增加了返回参数，请问C系统调用方需要做什么处理？</h2><h2 id="了解哪些设计模式，用伪代码实现一个你熟悉的设计模式。"><a href="#了解哪些设计模式，用伪代码实现一个你熟悉的设计模式。" class="headerlink" title="了解哪些设计模式，用伪代码实现一个你熟悉的设计模式。"></a>了解哪些设计模式，用伪代码实现一个你熟悉的设计模式。</h2><h2 id="知道哪些负载均衡算法。"><a href="#知道哪些负载均衡算法。" class="headerlink" title="知道哪些负载均衡算法。"></a>知道哪些负载均衡算法。</h2><h2 id="说一下Btree的查找原理。"><a href="#说一下Btree的查找原理。" class="headerlink" title="说一下Btree的查找原理。"></a>说一下Btree的查找原理。</h2><h2 id="简述三次握手，如果c端发起握手请求，s端无法立刻建立连接应该回应什么？"><a href="#简述三次握手，如果c端发起握手请求，s端无法立刻建立连接应该回应什么？" class="headerlink" title="简述三次握手，如果c端发起握手请求，s端无法立刻建立连接应该回应什么？"></a>简述三次握手，如果c端发起握手请求，s端无法立刻建立连接应该回应什么？</h2><h2 id="Java对象四种引用。"><a href="#Java对象四种引用。" class="headerlink" title="Java对象四种引用。"></a>Java对象四种引用。</h2><h2 id="Java字节流、字符流使用场景、为什么有了字符流还要字节流？"><a href="#Java字节流、字符流使用场景、为什么有了字符流还要字节流？" class="headerlink" title="Java字节流、字符流使用场景、为什么有了字符流还要字节流？"></a>Java字节流、字符流使用场景、为什么有了字符流还要字节流？</h2><h2 id="Java序列化Id的作用"><a href="#Java序列化Id的作用" class="headerlink" title="Java序列化Id的作用"></a>Java序列化Id的作用</h2><ul>
<li><p>序列化ID的作用：<br>其实，这个序列化ID起着关键的作用，它决定着是否能够成功反序列化！简单来说，java的序列化机制是通过在运行时判断类的serialVersionUID来验证版本一致性的。在进行反序列化时，JVM会把传来的字节流中的serialVersionUID与本地实体类中的serialVersionUID进行比较，如果相同则认为是一致的，便可以进行反序列化，否则就会报序列化版本不一致的异常。</p>
</li>
<li><p>序列化ID如何产生：<br>当我们一个实体类中没有显示的定义一个名为“serialVersionUID”、类型为long的变量时，Java序列化机制会根据编译时的class自动生成一个serialVersionUID作为序列化版本比较，这种情况下，只有同一次编译生成的class才会生成相同的serialVersionUID。譬如，当我们编写一个类时，随着时间的推移，我们因为需求改动，需要在本地类中添加其他的字段，这个时候再反序列化时便会出现serialVersionUID不一致，导致反序列化失败。那么如何解决呢？便是在本地类中添加一个“serialVersionUID”变量，值保持不变，便可以进行序列化和反序列化。</p>
</li>
</ul>
<h2 id="Java为什么要有基本类型的包装类-为什么要有基本类型。"><a href="#Java为什么要有基本类型的包装类-为什么要有基本类型。" class="headerlink" title="Java为什么要有基本类型的包装类,为什么要有基本类型。"></a>Java为什么要有基本类型的包装类,为什么要有基本类型。</h2><h2 id="什么是泛型-参数化类型"><a href="#什么是泛型-参数化类型" class="headerlink" title="什么是泛型? 参数化类型"></a>什么是泛型? 参数化类型</h2><h2 id="什么是反射"><a href="#什么是反射" class="headerlink" title="什么是反射"></a>什么是反射</h2><h2 id="Java类型擦除（泛型擦除）"><a href="#Java类型擦除（泛型擦除）" class="headerlink" title="Java类型擦除（泛型擦除）"></a>Java类型擦除（泛型擦除）</h2><h2 id="Java有哪几种IO模型"><a href="#Java有哪几种IO模型" class="headerlink" title="Java有哪几种IO模型"></a>Java有哪几种IO模型</h2><h2 id="Jdk代理、cglib代理的区别"><a href="#Jdk代理、cglib代理的区别" class="headerlink" title="Jdk代理、cglib代理的区别"></a>Jdk代理、cglib代理的区别</h2><h2 id="讲一下怎么使用分布式锁"><a href="#讲一下怎么使用分布式锁" class="headerlink" title="讲一下怎么使用分布式锁"></a>讲一下怎么使用分布式锁</h2><h2 id="java-util-concurrent包下CountDownLatch、CyclicBarrier和-Semaphore使用场景"><a href="#java-util-concurrent包下CountDownLatch、CyclicBarrier和-Semaphore使用场景" class="headerlink" title="java.util.concurrent包下CountDownLatch、CyclicBarrier和 Semaphore使用场景"></a>java.util.concurrent包下CountDownLatch、CyclicBarrier和 Semaphore使用场景</h2><ol>
<li><p>CountDownLatch<br> CountDownLatch类利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。</p>
</li>
<li><p>CyclicBarrier<br> 字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。</p>
</li>
<li><p>Semaphore<br> Semaphore翻译成字面意思为 信号量，Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。</p>
</li>
</ol>
<p>区别:<br>CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同：</p>
<ul>
<li>1、CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；</li>
<li>2、CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；</li>
<li>3、另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。<br>Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。</li>
</ul>
<h2 id="什么是线程局部变量ThreadLocal"><a href="#什么是线程局部变量ThreadLocal" class="headerlink" title="什么是线程局部变量ThreadLocal"></a>什么是线程局部变量ThreadLocal</h2><p>线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。</p>
<h2 id="ThreadLoal的作用是什么"><a href="#ThreadLoal的作用是什么" class="headerlink" title="ThreadLoal的作用是什么?"></a>ThreadLoal的作用是什么?</h2><p>简单说ThreadLocal就是一种以空间换时间的做法在每个Thread里面维护了一个ThreadLocal.ThreadLocalMap把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了。</p>
<h1 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h1><h2 id="你知道哪些或者你们线上使用什么GC策略-它有什么优势，适用于什么场景？"><a href="#你知道哪些或者你们线上使用什么GC策略-它有什么优势，适用于什么场景？" class="headerlink" title="你知道哪些或者你们线上使用什么GC策略? 它有什么优势，适用于什么场景？"></a>你知道哪些或者你们线上使用什么GC策略? 它有什么优势，适用于什么场景？</h2><h2 id="JAVA类加载器包括几种？它们之间的父子关系是怎么样的？双亲委派机制是什么意思？有什么好处？"><a href="#JAVA类加载器包括几种？它们之间的父子关系是怎么样的？双亲委派机制是什么意思？有什么好处？" class="headerlink" title="JAVA类加载器包括几种？它们之间的父子关系是怎么样的？双亲委派机制是什么意思？有什么好处？"></a>JAVA类加载器包括几种？它们之间的父子关系是怎么样的？双亲委派机制是什么意思？有什么好处？</h2><h2 id="JVM如何加载一个类的过程，双亲委派模型中有哪些方法？"><a href="#JVM如何加载一个类的过程，双亲委派模型中有哪些方法？" class="headerlink" title="JVM如何加载一个类的过程，双亲委派模型中有哪些方法？"></a>JVM如何加载一个类的过程，双亲委派模型中有哪些方法？</h2><h2 id="如何自定义一个类加载器？你使用过哪些或者你在什么场景下需要一个自定义的类加载器吗？"><a href="#如何自定义一个类加载器？你使用过哪些或者你在什么场景下需要一个自定义的类加载器吗？" class="headerlink" title="如何自定义一个类加载器？你使用过哪些或者你在什么场景下需要一个自定义的类加载器吗？"></a>如何自定义一个类加载器？你使用过哪些或者你在什么场景下需要一个自定义的类加载器吗？</h2><h2 id="堆内存设置的参数是什么？"><a href="#堆内存设置的参数是什么？" class="headerlink" title="堆内存设置的参数是什么？"></a>堆内存设置的参数是什么？</h2><h2 id="Perm-Space中保存什么数据-会引起OutOfMemory吗？"><a href="#Perm-Space中保存什么数据-会引起OutOfMemory吗？" class="headerlink" title="Perm Space中保存什么数据? 会引起OutOfMemory吗？"></a>Perm Space中保存什么数据? 会引起OutOfMemory吗？</h2><h2 id="做gc时，一个对象在内存各个Space中被移动的顺序是什么？"><a href="#做gc时，一个对象在内存各个Space中被移动的顺序是什么？" class="headerlink" title="做gc时，一个对象在内存各个Space中被移动的顺序是什么？"></a>做gc时，一个对象在内存各个Space中被移动的顺序是什么？</h2><h2 id="你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理过程中有哪些收获？"><a href="#你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理过程中有哪些收获？" class="headerlink" title="你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理过程中有哪些收获？"></a>你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理过程中有哪些收获？</h2><h2 id="1-8之后Perm-Space有哪些变动-MetaSpace大小默认是无限的么-还是你们会通过什么方式来指定大小"><a href="#1-8之后Perm-Space有哪些变动-MetaSpace大小默认是无限的么-还是你们会通过什么方式来指定大小" class="headerlink" title="1.8之后Perm Space有哪些变动? MetaSpace大小默认是无限的么? 还是你们会通过什么方式来指定大小?"></a>1.8之后Perm Space有哪些变动? MetaSpace大小默认是无限的么? 还是你们会通过什么方式来指定大小?</h2><h2 id="Jstack是干什么的-Jstat呢-如果线上程序周期性地出现卡顿，你怀疑可能是gc导致的，你会怎么来排查这个问题？线程日志一般你会看其中的什么部分？"><a href="#Jstack是干什么的-Jstat呢-如果线上程序周期性地出现卡顿，你怀疑可能是gc导致的，你会怎么来排查这个问题？线程日志一般你会看其中的什么部分？" class="headerlink" title="Jstack是干什么的? Jstat呢? 如果线上程序周期性地出现卡顿，你怀疑可能是gc导致的，你会怎么来排查这个问题？线程日志一般你会看其中的什么部分？"></a>Jstack是干什么的? Jstat呢? 如果线上程序周期性地出现卡顿，你怀疑可能是gc导致的，你会怎么来排查这个问题？线程日志一般你会看其中的什么部分？</h2><h2 id="StackOverFlow异常有没有遇到过？一般你猜测会在什么情况下被触发？如何指定一个线程的堆栈大小？一般你们写多少？"><a href="#StackOverFlow异常有没有遇到过？一般你猜测会在什么情况下被触发？如何指定一个线程的堆栈大小？一般你们写多少？" class="headerlink" title="StackOverFlow异常有没有遇到过？一般你猜测会在什么情况下被触发？如何指定一个线程的堆栈大小？一般你们写多少？"></a>StackOverFlow异常有没有遇到过？一般你猜测会在什么情况下被触发？如何指定一个线程的堆栈大小？一般你们写多少？</h2><h2 id="Jvm的内存屏障"><a href="#Jvm的内存屏障" class="headerlink" title="Jvm的内存屏障"></a>Jvm的内存屏障</h2><h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><h2 id="你有没有用过Spring的AOP-是用来干嘛的-大概会怎么使用？"><a href="#你有没有用过Spring的AOP-是用来干嘛的-大概会怎么使用？" class="headerlink" title="你有没有用过Spring的AOP? 是用来干嘛的? 大概会怎么使用？"></a>你有没有用过Spring的AOP? 是用来干嘛的? 大概会怎么使用？</h2><h2 id="如果一个接口有2个不同的实现-那么怎么来Autowire一个指定的实现？"><a href="#如果一个接口有2个不同的实现-那么怎么来Autowire一个指定的实现？" class="headerlink" title="如果一个接口有2个不同的实现, 那么怎么来Autowire一个指定的实现？"></a>如果一个接口有2个不同的实现, 那么怎么来Autowire一个指定的实现？</h2><h2 id="Spring的声明式事务-Transaction注解一般写在什么位置-抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚"><a href="#Spring的声明式事务-Transaction注解一般写在什么位置-抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚" class="headerlink" title="Spring的声明式事务 @Transaction注解一般写在什么位置? 抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚?"></a>Spring的声明式事务 @Transaction注解一般写在什么位置? 抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚?</h2><h2 id="如果想在某个Bean生成并装配完毕后执行自己的逻辑，可以什么方式实现？"><a href="#如果想在某个Bean生成并装配完毕后执行自己的逻辑，可以什么方式实现？" class="headerlink" title="如果想在某个Bean生成并装配完毕后执行自己的逻辑，可以什么方式实现？"></a>如果想在某个Bean生成并装配完毕后执行自己的逻辑，可以什么方式实现？</h2><h2 id="SpringBoot没有放到web容器里为什么能跑HTTP服务？"><a href="#SpringBoot没有放到web容器里为什么能跑HTTP服务？" class="headerlink" title="SpringBoot没有放到web容器里为什么能跑HTTP服务？"></a>SpringBoot没有放到web容器里为什么能跑HTTP服务？</h2><h2 id="SpringBoot中如果你想使用自定义的配置文件而不仅仅是application-properties，应该怎么弄？"><a href="#SpringBoot中如果你想使用自定义的配置文件而不仅仅是application-properties，应该怎么弄？" class="headerlink" title="SpringBoot中如果你想使用自定义的配置文件而不仅仅是application.properties，应该怎么弄？"></a>SpringBoot中如果你想使用自定义的配置文件而不仅仅是application.properties，应该怎么弄？</h2><h2 id="SpringMVC中RequestMapping可以指定GET-POST方法么？怎么指定？"><a href="#SpringMVC中RequestMapping可以指定GET-POST方法么？怎么指定？" class="headerlink" title="SpringMVC中RequestMapping可以指定GET, POST方法么？怎么指定？"></a>SpringMVC中RequestMapping可以指定GET, POST方法么？怎么指定？</h2><h2 id="SpringMVC如果希望把输出的Object-例如XXResult或者XXResponse-这种包装为JSON输出-应该怎么处理"><a href="#SpringMVC如果希望把输出的Object-例如XXResult或者XXResponse-这种包装为JSON输出-应该怎么处理" class="headerlink" title="SpringMVC如果希望把输出的Object(例如XXResult或者XXResponse)这种包装为JSON输出, 应该怎么处理?"></a>SpringMVC如果希望把输出的Object(例如XXResult或者XXResponse)这种包装为JSON输出, 应该怎么处理?</h2><h2 id="怎样拦截SpringMVC的异常，然后做自定义的处理，比如打日志或者包装成JSON"><a href="#怎样拦截SpringMVC的异常，然后做自定义的处理，比如打日志或者包装成JSON" class="headerlink" title="怎样拦截SpringMVC的异常，然后做自定义的处理，比如打日志或者包装成JSON"></a>怎样拦截SpringMVC的异常，然后做自定义的处理，比如打日志或者包装成JSON</h2><h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><h2 id="如果有很多数据插入MYSQL-你会选择什么方式"><a href="#如果有很多数据插入MYSQL-你会选择什么方式" class="headerlink" title="如果有很多数据插入MYSQL 你会选择什么方式?"></a>如果有很多数据插入MYSQL 你会选择什么方式?</h2><h2 id="如果查询很慢，你会想到的第一个方式是什么？索引是干嘛的"><a href="#如果查询很慢，你会想到的第一个方式是什么？索引是干嘛的" class="headerlink" title="如果查询很慢，你会想到的第一个方式是什么？索引是干嘛的?"></a>如果查询很慢，你会想到的第一个方式是什么？索引是干嘛的?</h2><h2 id="如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？"><a href="#如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？" class="headerlink" title="如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？"></a>如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？</h2><h2 id="如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？"><a href="#如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？" class="headerlink" title="如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？"></a>如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？</h2><h2 id="接上题，如果where条件后面带有一个-i-5-lt-100-会使用到这个索引吗？"><a href="#接上题，如果where条件后面带有一个-i-5-lt-100-会使用到这个索引吗？" class="headerlink" title="接上题，如果where条件后面带有一个 i + 5 &lt; 100 会使用到这个索引吗？"></a>接上题，如果where条件后面带有一个 i + 5 &lt; 100 会使用到这个索引吗？</h2><h2 id="怎么看是否用到了某个索引？"><a href="#怎么看是否用到了某个索引？" class="headerlink" title="怎么看是否用到了某个索引？"></a>怎么看是否用到了某个索引？</h2><h2 id="数据库索引有哪几种，他们之间的区别。"><a href="#数据库索引有哪几种，他们之间的区别。" class="headerlink" title="数据库索引有哪几种，他们之间的区别。"></a>数据库索引有哪几种，他们之间的区别。</h2><h2 id="like-aaa-会使用索引吗-like-aaa-呢"><a href="#like-aaa-会使用索引吗-like-aaa-呢" class="headerlink" title="like %aaa%会使用索引吗? like aaa%呢?"></a>like %aaa%会使用索引吗? like aaa%呢?</h2><h2 id="drop、truncate、delete的区别？"><a href="#drop、truncate、delete的区别？" class="headerlink" title="drop、truncate、delete的区别？"></a>drop、truncate、delete的区别？</h2><h2 id="平时你们是怎么监控数据库的-慢SQL是怎么排查的？"><a href="#平时你们是怎么监控数据库的-慢SQL是怎么排查的？" class="headerlink" title="平时你们是怎么监控数据库的? 慢SQL是怎么排查的？"></a>平时你们是怎么监控数据库的? 慢SQL是怎么排查的？</h2><h2 id="你们数据库是否支持emoji表情，如果不支持，如何操作"><a href="#你们数据库是否支持emoji表情，如果不支持，如何操作" class="headerlink" title="你们数据库是否支持emoji表情，如果不支持，如何操作?"></a>你们数据库是否支持emoji表情，如果不支持，如何操作?</h2><h2 id="你们的数据库单表数据量是多少？一般多大的时候开始出现查询性能急剧下降？"><a href="#你们的数据库单表数据量是多少？一般多大的时候开始出现查询性能急剧下降？" class="headerlink" title="你们的数据库单表数据量是多少？一般多大的时候开始出现查询性能急剧下降？"></a>你们的数据库单表数据量是多少？一般多大的时候开始出现查询性能急剧下降？</h2><h2 id="查询死掉了，想要找出执行的查询进程用什么命令？找出来之后一般你会干嘛？"><a href="#查询死掉了，想要找出执行的查询进程用什么命令？找出来之后一般你会干嘛？" class="headerlink" title="查询死掉了，想要找出执行的查询进程用什么命令？找出来之后一般你会干嘛？"></a>查询死掉了，想要找出执行的查询进程用什么命令？找出来之后一般你会干嘛？</h2><h2 id="读写分离是怎么做的？你认为中间件会怎么来操作？这样操作跟事务有什么关系？"><a href="#读写分离是怎么做的？你认为中间件会怎么来操作？这样操作跟事务有什么关系？" class="headerlink" title="读写分离是怎么做的？你认为中间件会怎么来操作？这样操作跟事务有什么关系？"></a>读写分离是怎么做的？你认为中间件会怎么来操作？这样操作跟事务有什么关系？</h2><h2 id="分库分表有没有做过？线上的迁移过程是怎么样的？如何确定数据是正确的？"><a href="#分库分表有没有做过？线上的迁移过程是怎么样的？如何确定数据是正确的？" class="headerlink" title="分库分表有没有做过？线上的迁移过程是怎么样的？如何确定数据是正确的？"></a>分库分表有没有做过？线上的迁移过程是怎么样的？如何确定数据是正确的？</h2><h2 id="Mysql索引的分类-Btree-hash-，各自使用什么情况-。"><a href="#Mysql索引的分类-Btree-hash-，各自使用什么情况-。" class="headerlink" title="Mysql索引的分类(Btree, hash)，各自使用什么情况 。"></a>Mysql索引的分类(Btree, hash)，各自使用什么情况 。</h2><h2 id="说说Myisam-Innodb区别。"><a href="#说说Myisam-Innodb区别。" class="headerlink" title="说说Myisam, Innodb区别。"></a>说说Myisam, Innodb区别。</h2><h1 id="Linux命令"><a href="#Linux命令" class="headerlink" title="Linux命令"></a>Linux命令</h1><h2 id="日志特别大只想看最后100行怎么弄-如果想一直看日志的持续输出，用什么命令"><a href="#日志特别大只想看最后100行怎么弄-如果想一直看日志的持续输出，用什么命令" class="headerlink" title="日志特别大只想看最后100行怎么弄? 如果想一直看日志的持续输出，用什么命令?"></a>日志特别大只想看最后100行怎么弄? 如果想一直看日志的持续输出，用什么命令?</h2><h2 id="如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？"><a href="#如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？" class="headerlink" title="如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？"></a>如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？</h2><h2 id="grep如果忽略大小写应该怎么弄-正则表达式呢？"><a href="#grep如果忽略大小写应该怎么弄-正则表达式呢？" class="headerlink" title="grep如果忽略大小写应该怎么弄? 正则表达式呢？"></a>grep如果忽略大小写应该怎么弄? 正则表达式呢？</h2><h2 id="vim往下一行是什么键？往下30行呢-跳到文件末尾一行是什么-跳回来是什么-向后搜索是什么"><a href="#vim往下一行是什么键？往下30行呢-跳到文件末尾一行是什么-跳回来是什么-向后搜索是什么" class="headerlink" title="vim往下一行是什么键？往下30行呢? 跳到文件末尾一行是什么? 跳回来是什么? 向后搜索是什么?"></a>vim往下一行是什么键？往下30行呢? 跳到文件末尾一行是什么? 跳回来是什么? 向后搜索是什么?</h2><h2 id="如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？"><a href="#如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？" class="headerlink" title="如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？"></a>如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？</h2><h2 id="如果把上面的出现次数排个序应该怎么弄-想按照数字本身的顺序而不是字符串的顺序排列怎么弄？"><a href="#如果把上面的出现次数排个序应该怎么弄-想按照数字本身的顺序而不是字符串的顺序排列怎么弄？" class="headerlink" title="如果把上面的出现次数排个序应该怎么弄? 想按照数字本身的顺序而不是字符串的顺序排列怎么弄？"></a>如果把上面的出现次数排个序应该怎么弄? 想按照数字本身的顺序而不是字符串的顺序排列怎么弄？</h2><h2 id="Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？"><a href="#Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？" class="headerlink" title="Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？"></a>Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？</h2><h2 id="给某个文件权设置限比如设置为644-是用什么命令？这个6是什么意思？"><a href="#给某个文件权设置限比如设置为644-是用什么命令？这个6是什么意思？" class="headerlink" title="给某个文件权设置限比如设置为644 是用什么命令？这个6是什么意思？"></a>给某个文件权设置限比如设置为644 是用什么命令？这个6是什么意思？</h2><h2 id="Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么"><a href="#Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么" class="headerlink" title="Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么?"></a>Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么?</h2><h2 id="top命令里面，有时候所有进程的CPU使用率加起来超过100-是怎么回事？"><a href="#top命令里面，有时候所有进程的CPU使用率加起来超过100-是怎么回事？" class="headerlink" title="top命令里面，有时候所有进程的CPU使用率加起来超过100%是怎么回事？"></a>top命令里面，有时候所有进程的CPU使用率加起来超过100%是怎么回事？</h2><h2 id="还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？"><a href="#还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？" class="headerlink" title="还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？"></a>还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？</h2><h2 id="想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？"><a href="#想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？" class="headerlink" title="想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？"></a>想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？</h2><p>Linux常问题</p>
<h2 id="有没有做过Linux系统参数方面的优化，大概优化过什么？"><a href="#有没有做过Linux系统参数方面的优化，大概优化过什么？" class="headerlink" title="有没有做过Linux系统参数方面的优化，大概优化过什么？"></a>有没有做过Linux系统参数方面的优化，大概优化过什么？</h2><h2 id="系统参数里面有个叫做backlog的可以用来干什么？"><a href="#系统参数里面有个叫做backlog的可以用来干什么？" class="headerlink" title="系统参数里面有个叫做backlog的可以用来干什么？"></a>系统参数里面有个叫做backlog的可以用来干什么？</h2><h2 id="查看网络连接发现好多TIME-WAIT-可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIME-WAIT"><a href="#查看网络连接发现好多TIME-WAIT-可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIME-WAIT" class="headerlink" title="查看网络连接发现好多TIME_WAIT 可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIME_WAIT"></a>查看网络连接发现好多TIME_WAIT 可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIME_WAIT</h2><h2 id="可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？"><a href="#可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？" class="headerlink" title="可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？"></a>可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？</h2><h2 id="KeepAlive是用来干什么的？这样的好处是什么？"><a href="#KeepAlive是用来干什么的？这样的好处是什么？" class="headerlink" title="KeepAlive是用来干什么的？这样的好处是什么？"></a>KeepAlive是用来干什么的？这样的好处是什么？</h2><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><ol>
<li>缓存穿透可以介绍一下么？你认为应该如何解决这个问题</li>
<li>你是怎么触发缓存更新的？(比如设置超时时间(被动方式), 比如更新的时候主动update)？如果是被动的方式如何控制多个入口同时触发某个缓存更新？</li>
<li>你们用Redis来做什么？为什么不用其他的KV存储例如Memcached,Cassandra等?</li>
<li>你们用什么Redis客户端? Redis高性能的原因大概可以讲一些?</li>
<li>你熟悉哪些Redis的数据结构? zset是干什么的? 和set有什么区别?</li>
<li>Redis的hash, 存储和获取的具体命令叫什么名字?</li>
<li>LPOP和BLPOP的区别?</li>
<li>Redis的有一些包含SCAN关键字的命令是干嘛的? SCAN返回的数据量是固定的吗?</li>
<li>Redis中的Lua有没有使用过? 可以用来做什么? 为什么可以这么用?</li>
<li>Redis的Pipeline是用来干什么的?</li>
</ol>
<h1 id="去哪儿网面试题"><a href="#去哪儿网面试题" class="headerlink" title="去哪儿网面试题"></a>去哪儿网面试题</h1><ol>
<li>mysql数据库调优。</li>
<li>sql优化。</li>
<li>like能用索引吗？</li>
<li></li>
<li>GC原理。</li>
<li>jvm内存结构。</li>
<li>说一下你学过jvm 在书写代码上对你有什么帮助和提高。</li>
<li>千万数据量的查询你会怎么做？</li>
<li>HashMap在jdk1.7和1.8的区别，为什么引入这个概念？hash碰撞怎么解决，为什么1.8要比1.7更好，好在哪？</li>
<li>关于你的项目，如果并发很大，你会怎么改造。</li>
<li>方法区里什么样的对象有可能被回收。</li>
<li>线上cpu飙升100%你怎么处理。</li>
<li>频繁FullGC怎么处理。</li>
<li>linux命令。(快速文件处理命令)</li>
<li>伊甸区和幸存区可动态变化吗？</li>
<li>redis和memcached区别。</li>
<li>说几个jdk命令，jmap是什么意思。</li>
<li>如果并发很大，你对数据的正确性怎么保证。</li>
</ol>
<h1 id="饿了么面试题"><a href="#饿了么面试题" class="headerlink" title="饿了么面试题"></a>饿了么面试题</h1><ol>
<li>http和https的区别，https原理，http2.0与1.0的区别。</li>
<li>Java的垃圾回收机制，Java文件加载机制，tomcat类加载机制，锁机制，jvm原理及线上调优，jvm内存模型。</li>
<li>多线程，有哪些可以保持进程同步的方法，创建线程的几种方法，对i++多线程访问你会怎么做。</li>
<li>Java的设计模式，单例有什么模式，懒汉为什么加volotile，volotile的内存屏障，如何避免死锁。</li>
<li>考虑单例模式的编写，要线程安全且内存消耗小（剑指offer原题）。</li>
<li>String、StringBuilder、StringBuffer区别；String类能被继承吗？为什么？</li>
<li>在白纸上手写二分法排序算法（lintcode上原题）；二分查找的思想。</li>
<li>查找单链表中倒数第k个节点的算法，手写（lintcode上原题）；最常见的排序算法你见过哪些，快排的基本思想及时间复杂度。</li>
<li>常见的数据结构有哪些。</li>
<li>hashmap、hashcode一样，不equals怎么处理 ；hashcode实现原理，currentHashMap原理，实现细节，怎么实现同步的；类为什么要有hascode方法，是不是主要在集合类中都要实现hashcode方法；equals方法怎么实现；两个不同的对象可能有相同的hashcode值吗；常用集合有哪些。</li>
<li>tcp三次握手，四次挥手协议。</li>
<li>架构设计一个开发性问题，设计一个Nginx管理的中间件，怎么设计。</li>
<li>所有的类都继承与object，你用过object类的直接子类有哪些，object类常用的方法有哪些。</li>
<li>Java会出现内存泄漏吗，如果回，在哪种情况下？</li>
<li>抽象类和接口的区别。</li>
<li>平时怎么扩展自己的专业知识水平。</li>
</ol>
<h1 id="百度面试题"><a href="#百度面试题" class="headerlink" title="百度面试题"></a>百度面试题</h1><ol>
<li><p>什么是 Java 的反射机制。</p>
</li>
<li><p>Cookie 和 Session的区别。</p>
</li>
<li><p>get 和 post请求的区别。</p>
</li>
<li><p>IOC的优点是什么。</p>
</li>
<li><p>IO 和 NIO的区别，NIO优点。</p>
</li>
<li><p>JRE、JDK、JVM 及 JIT 之间有什么不同。</p>
</li>
<li><p>Hashcode 的作用。</p>
</li>
<li><p>简述一致性 Hash 算法。</p>
</li>
<li><p>为什么在重写 equals 方法的时候需要重写 hashCode 方法？equals与 hashCode 的异同点在哪里。</p>
</li>
<li><p>为什么 Map 接口不继承 Collection 接口。</p>
</li>
<li><p>说出几点 Java 中使用 Collections 的最佳实践？</p>
</li>
<li><p>GC是什么？为什么要有GC。</p>
</li>
<li><p>什么时候会导致垃圾回收。</p>
</li>
<li><p>GC 有几种方式？怎么配置。</p>
</li>
<li><p>什么时候一个对象会被GC？ 如何判断一个对象是否存活。</p>
</li>
<li><p>垃圾回收器的基本原理是什么？</p>
</li>
<li><p>Serial 与 Parallel GC之间的不同之处。</p>
</li>
<li><p>JVM 中一次完整的 GC 流程是怎样的？ 对象如何晋升到老年代。</p>
</li>
<li><p>吞吐量优先和响应优先的垃圾收集器选择。</p>
</li>
<li><p>说说你知道的几种主要的jvm 参数。</p>
</li>
<li><p>Java中存在内存泄漏问题吗？请举例说明。</p>
</li>
<li><p>什么是线程，多线程的优点是什么？以及简单说一下多线程的几种实现方式。</p>
</li>
<li><p>ThreadLocal 用途是什么，原理是什么，用的时候要注意什么?</p>
</li>
<li><p>有T1，T2，T3三个线程，怎么确保它们按顺序执行？怎样保证T2在T1执行完后执行，T3在T2执行完后执行同步块内的线程抛出异常会发生什么？</p>
</li>
<li><p>什么是乐观锁（Optimistic Locking）？如何实现乐观锁？如何避免ABA问题。</p>
</li>
<li><p>什么是设计模式（Design Patterns）？你用过哪种设计模式？用在什么场合？</p>
</li>
<li><p>你能写出三种单例模式实现么？</p>
</li>
<li><p>你知道Google是如何在一秒内把搜索结果返回给用户？</p>
</li>
<li><p>高并发下，如何做到安全的修改同一行数据？</p>
</li>
<li><p>如何避免浏览器缓存。</p>
</li>
<li><p>大型网站在架构上应当考虑哪些问题？</p>
</li>
<li><p>最近有在看什么书么，印象最深刻的是什么？</p>
</li>
<li><p>你们线上应用的 JVM 参数有哪些？</p>
</li>
<li><p>能简单说下你对算法的理解么？</p>
</li>
</ol>
<h1 id="经验分享"><a href="#经验分享" class="headerlink" title="经验分享"></a>经验分享</h1><p>如果你的技术扎实没问题，接下来的面试也决定你是否能得到认可拿到offer，列出以下几点经验，面试前提前准备好答案。</p>
<ul>
<li>最好准备好1-2两个问题来应对“你有什么想问的吗？”之类的问题。</li>
<li>离职原因，不要抱怨现在和以前的雇主。</li>
<li>保持谈话的时间安排节奏顺利进行, 但不要就某个问题说过多，通过一个问题引入到下一个问题。</li>
<li>面谈的过程中面试官的问题可能会比较细，比较犀利，那是正常环节，不必紧张。</li>
<li>如果遇到不太了解问题，最好不要说模棱两可的答案。</li>
<li>沟通过程中最好保持高度的愿意性。</li>
<li>准备要充分，知识面要尽量的广，同时深度也要够。</li>
<li>面试安排上，如果不着急，尽量给自己留多时间，两天一家，及时做总结和补充。</li>
<li>简历投递方面，拉勾上投了很多经常不匹配，有一些打击自信心，如果有同样感受的，不妨换BOSS或者其他平台。避免打击自信心。</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Intellij idea汇总</title>
    <url>/java-other/intellij/</url>
    <content><![CDATA[<ul>
<li><a href="https://www.jetbrains.com/idea/" target="_blank" rel="noopener">下载地址</a><a id="more"></a>

</li>
</ul>
<h1 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h1><ul>
<li><a href="http://blog.csdn.net/boot_strap/article/details/21729143" target="_blank" rel="noopener">将intellij idea的快捷键与Eclipse的快捷键设置成一样</a></li>
<li><a href="https://blog.csdn.net/gnail_oug/article/details/78281354" target="_blank" rel="noopener">快捷键—IntelliJ IDEA全局内容搜索和替换</a></li>
<li><a href="https://jingyan.baidu.com/article/36d6ed1f62e9821bcf4883af.html" target="_blank" rel="noopener">如何打开Intellij IDEA的代码提示功能</a></li>
<li><a href="https://blog.csdn.net/qq465235530/article/details/78900863" target="_blank" rel="noopener">IntelliJ IDEA 设置选中标识符高亮</a></li>
<li><a href="https://www.oschina.net/question/100896_83213" target="_blank" rel="noopener">IDEA提示方法的注释</a></li>
<li><a href="https://blog.csdn.net/u012050154/article/details/53535637" target="_blank" rel="noopener">Intellij IDEA打开多项目窗口</a></li>
<li><a href="https://blog.csdn.net/qq_27093465/article/details/52857307" target="_blank" rel="noopener">查看一个类的父子依赖关系</a></li>
<li><a href="https://blog.csdn.net/sky19891212/article/details/44172127" target="_blank" rel="noopener">自动生成 serialVersionUID</a> </li>
<li>sout —&gt;  System.out.println();</li>
<li><a href="https://blog.csdn.net/z4ever/article/details/53339925" target="_blank" rel="noopener">IDEA插件配置之Eclipse Code Formatter</a></li>
<li><a href="https://zhidao.baidu.com/question/244544584549976524.html" target="_blank" rel="noopener">自动定位类在工程中的位置</a></li>
<li><a href="https://blog.csdn.net/qq_33547169/article/details/76618329" target="_blank" rel="noopener">idea 行号栏太宽以及显示一些图标问题解决</a></li>
<li><a href="intellij-back-forward.md">返回到上次或下次查看的地方</a></li>
<li>Intellij IDEA中常用快捷键(main, try/catch) —&gt; command+option+Z</li>
<li><a href="https://mp.weixin.qq.com/s/e7zxUmEWHesfajyPk9Jxnw?from=groupmessage&isappinstalled=0" target="_blank" rel="noopener">Eclipse 转 IDEA 一定要改的 8 条配置</a></li>
</ul>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ul>
<li><a href="https://blog.csdn.net/geekun/article/details/51325510" target="_blank" rel="noopener">修改IntelliJ IDEA中Maven项目的默认JDK版</a></li>
<li><a href="https://www.cnblogs.com/gradven/p/7228142.html" target="_blank" rel="noopener">idea的环境变量设置(Enviroment variables)</a></li>
<li><a href="https://blog.csdn.net/u014653854/article/details/80700408" target="_blank" rel="noopener">IDEA设置Maven下载source、document</a></li>
</ul>
<h1 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/b994EvxMRZIvPedHi8x2Yw" target="_blank" rel="noopener">Java程序员必备的Intellij插件</a></li>
<li><a href="https://plugins.jetbrains.com/" target="_blank" rel="noopener">Intellij 插件下载</a></li>
<li><a href="https://mp.weixin.qq.com/s/3hRv1VspB4wSogjajZb_ZA" target="_blank" rel="noopener">推荐几个IDEA插件</a></li>
</ul>
<h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/sxsFa8bWJn2sVSscW0uV2A" target="_blank" rel="noopener">IntelliJ IDEA 使用教程(2019图文版) – 从入门到上瘾</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始学架构</title>
    <url>/java-other/book--%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第1部分 概念和基础</span><br><span class="line"></span><br><span class="line">第１章 架构基础</span><br><span class="line">1.1 “架构”到底指什么</span><br><span class="line">1.1.1 系统与子系统</span><br><span class="line">1.1.2 模块与组件</span><br><span class="line">1.1.3 框架与架构</span><br><span class="line">1.1.4 重新定义架构</span><br><span class="line">1.2 架构设计的目的</span><br><span class="line">1.2.1 架构设计的误区</span><br><span class="line">1.2.2 以史为鉴</span><br><span class="line">1.2.3 架构设计的真正目的</span><br><span class="line">1.3 复杂度来源</span><br><span class="line">1.3.1 高性能</span><br><span class="line">1.3.2 高可用</span><br><span class="line">1.3.3 可扩展性</span><br><span class="line">1.3.4 低成本</span><br><span class="line">1.3.5 安全</span><br><span class="line">1.3.6 规模</span><br><span class="line">1.4 本章小结</span><br><span class="line"></span><br><span class="line">第2章 架构设计原则</span><br><span class="line">2.1 合适原则</span><br><span class="line">2.2 简单原则</span><br><span class="line">2.3 演化原则</span><br><span class="line">2.4 本章小结</span><br><span class="line"></span><br><span class="line">第3章 架构设计流程</span><br><span class="line">3.1 有的放矢—识别复杂度</span><br><span class="line">3.2 按图索骥—设计备选方案</span><br><span class="line">3.3 深思熟虑—评估和选择备选方案</span><br><span class="line">3.3.1 业务背景</span><br><span class="line">3.3.2 备选方案设计</span><br><span class="line">3.3.3 备选方案360度环评</span><br><span class="line">3.4 精雕细琢—详细方案设计</span><br><span class="line">3.5 本章小结</span><br><span class="line"></span><br><span class="line">第2部分 高性能架构模式</span><br><span class="line"></span><br><span class="line">第4章 存储高性能</span><br><span class="line">4.1 关系数据库</span><br><span class="line">4.1.1 读写分离</span><br><span class="line">4.1.2 分库分表</span><br><span class="line">4.1.3 实现方法</span><br><span class="line">4.2 NoSQL</span><br><span class="line">4.2.1 K-V存储</span><br><span class="line">4.2.2 文档数据库</span><br><span class="line">4.2.3 列式数据库</span><br><span class="line">4.2.4 全文搜索引擎</span><br><span class="line">4.3 缓存</span><br><span class="line">4.3.1 缓存穿透</span><br><span class="line">4.3.2 缓存雪崩</span><br><span class="line">4.3.3 缓存热点</span><br><span class="line">4.4 本章小结</span><br><span class="line"></span><br><span class="line">第5章 计算高性能</span><br><span class="line">5.1 单服务器高性能</span><br><span class="line">5.1.1 PPC</span><br><span class="line">5.1.2 prefork</span><br><span class="line">5.1.3 TPC</span><br><span class="line">5.1.4 prethread</span><br><span class="line">5.1.5 Reactor</span><br><span class="line">5.1.6 Proactor</span><br><span class="line">5.2 集群高性能</span><br><span class="line">5.2.1 负载均衡分类</span><br><span class="line">5.2.2 负载均衡架构</span><br><span class="line">5.2.3 负载均衡的算法</span><br><span class="line">5.3 本章小结</span><br><span class="line"></span><br><span class="line">第3部分 高可用架构模式</span><br><span class="line"></span><br><span class="line">第6章 CAP</span><br><span class="line">6.1 CAP理论</span><br><span class="line">6.1.1 一致性（Consistency）</span><br><span class="line">6.1.2 可用性</span><br><span class="line">6.1.3 分区容忍性（Partition Tolerance）</span><br><span class="line">6.2 CAP应用</span><br><span class="line">6.2.1 CP—Consistency&#x2F;Partition Tolerance</span><br><span class="line">6.2.2 AP—Availability&#x2F;Partition Tolerance</span><br><span class="line">6.3 CAP细节</span><br><span class="line">6.4 ACID、BASE</span><br><span class="line">6.4.1 ACID</span><br><span class="line">6.4.2 BASE</span><br><span class="line">6.5 本章小结</span><br><span class="line"></span><br><span class="line">第7章 FMEA</span><br><span class="line">7.1 FMEA介绍</span><br><span class="line">7.2 FMEA方法</span><br><span class="line">7.3 FMEA实战</span><br><span class="line">7.4 本章小结</span><br><span class="line"></span><br><span class="line">第8章 存储高可用</span><br><span class="line">8.1 主备复制</span><br><span class="line">8.1.1 基本实现</span><br><span class="line">8.1.2 优缺点分析</span><br><span class="line">8.2 主从复制</span><br><span class="line">8.2.1 基本实现</span><br><span class="line">8.2.2 优缺点分析</span><br><span class="line">8.3 主备倒换与主从倒换</span><br><span class="line">8.3.1 设计关键</span><br><span class="line">8.3.2 常见架构</span><br><span class="line">8.4 主主复制</span><br><span class="line">8.5 数据集群</span><br><span class="line">8.5.1 数据集中集群</span><br><span class="line">8.5.2 数据分散集群</span><br><span class="line">8.5.3 分布式事务算法</span><br><span class="line">8.5.4 分布式一致性算法</span><br><span class="line">8.6 数据分区</span><br><span class="line">8.6.1 数据量</span><br><span class="line">8.6.2 分区规则</span><br><span class="line">8.6.3 复制规则</span><br><span class="line">8.7 本章小结</span><br><span class="line"></span><br><span class="line">第9章 计算高可用</span><br><span class="line">9.1 主备</span><br><span class="line">9.2 主从</span><br><span class="line">9.3 对称集群</span><br><span class="line">9.4 非对称集群</span><br><span class="line">9.5 本章小结</span><br><span class="line"></span><br><span class="line">第10章 业务高可用</span><br><span class="line">10.1 异地多活</span><br><span class="line">10.1.1 异地多活架构</span><br><span class="line">10.1.2 异地多活设计技巧</span><br><span class="line">10.1.3 异地多活设计步骤</span><br><span class="line">10.2 接口级的故障应对方案</span><br><span class="line">10.2.1 降级</span><br><span class="line">10.2.2 熔断</span><br><span class="line">10.2.3 限流</span><br><span class="line">10.2.4 排队</span><br><span class="line">10.3 本章小结</span><br><span class="line"></span><br><span class="line">第4部分 可扩展架构模式</span><br><span class="line"></span><br><span class="line">第11章 可扩展模式</span><br><span class="line">11.1 可扩展概述</span><br><span class="line">11.2 可扩展的基本思想</span><br><span class="line">11.3 可扩展方式</span><br><span class="line">11.4 本章小结</span><br><span class="line"></span><br><span class="line">第12章 分层架构</span><br><span class="line">12.1 分层架构类型</span><br><span class="line">12.2 分层架构详解</span><br><span class="line">12.3 本章小结</span><br><span class="line"></span><br><span class="line">第13章 SOA架构</span><br><span class="line">13.1 SOA历史</span><br><span class="line">13.2 SOA详解</span><br><span class="line">13.3 本章小结</span><br><span class="line"></span><br><span class="line">第14章 微服务</span><br><span class="line">14.1 微服务历史</span><br><span class="line">14.2 微服务与SOA的关系</span><br><span class="line">14.3 微服务的陷阱</span><br><span class="line">14.4 微服务佳实践</span><br><span class="line">14.4.1 服务粒度</span><br><span class="line">14.4.2 拆分方法</span><br><span class="line">14.4.3 基础设施</span><br><span class="line">14.5 本章小结</span><br><span class="line"></span><br><span class="line">第15章 微内核架构</span><br><span class="line">15.1 基本概念</span><br><span class="line">15.2 设计关键点</span><br><span class="line">15.3 OSGi架构简析</span><br><span class="line">15.4 规则引擎架构简析</span><br><span class="line">15.5 本章小结</span><br><span class="line"></span><br><span class="line">第5部分 架构实战</span><br><span class="line"></span><br><span class="line">第16章 消息队列设计实战</span><br><span class="line">16.1 需求</span><br><span class="line">16.2 设计流程</span><br><span class="line">16.2.1 识别复杂度</span><br><span class="line">16.2.2 设计备选方案</span><br><span class="line">16.2.3 评估和选择备选方案</span><br><span class="line">16.2.4 细化方案</span><br><span class="line">16.3 本章小结</span><br><span class="line"></span><br><span class="line">第17章 互联网架构演进</span><br><span class="line">17.1 技术演进</span><br><span class="line">17.1.1 技术演进的动力</span><br><span class="line">17.1.2 淘宝</span><br><span class="line">17.1.3 手机QQ</span><br><span class="line">17.1.4 微信</span><br><span class="line">17.2 技术演进的模式</span><br><span class="line">17.3 互联网业务发展</span><br><span class="line">17.3.1 业务复杂性</span><br><span class="line">17.3.2 用户规模</span><br><span class="line">17.3.3 量变到质变</span><br><span class="line">17.4 本章小结</span><br><span class="line"></span><br><span class="line">第18章 互联网架构模板</span><br><span class="line">18.1 总体结构</span><br><span class="line">18.2 存储层技术</span><br><span class="line">18.2.1 SQL</span><br><span class="line">18.2.2 NoSQL</span><br><span class="line">18.2.3 小文件存储</span><br><span class="line">18.2.4 大文件存储</span><br><span class="line">18.3 开发层技术</span><br><span class="line">18.3.1 开发框架</span><br><span class="line">18.3.2 Web服务器</span><br><span class="line">18.3.3 容器</span><br><span class="line">18.4 服务层技术</span><br><span class="line">18.4.1 配置中心</span><br><span class="line">18.4.2 服务中心</span><br><span class="line">18.4.3 消息队列</span><br><span class="line">18.5 网络层技术</span><br><span class="line">18.5.1 负载均衡</span><br><span class="line">18.5.2 CDN</span><br><span class="line">18.5.3 多机房</span><br><span class="line">18.5.4 多中心</span><br><span class="line">18.6 用户层技术</span><br><span class="line">18.6.1 用户管理</span><br><span class="line">18.6.2 消息推送</span><br><span class="line">18.6.3 存储云与图片云</span><br><span class="line">18.7 业务层技术</span><br><span class="line">18.8 平台技术</span><br><span class="line">18.8.1 运维平台</span><br><span class="line">18.8.2 测试平台</span><br><span class="line">18.8.3 数据平台</span><br><span class="line">18.8.4 管理平台</span><br><span class="line">18.9 本章小结</span><br><span class="line"></span><br><span class="line">第19章 架构重构</span><br><span class="line">19.1 有的放矢</span><br><span class="line">19.2 合纵连横</span><br><span class="line">19.2.1 合纵</span><br><span class="line">19.2.2 连横</span><br><span class="line">19.3 运筹帷幄</span><br><span class="line">19.4 文武双全—项目管理+技术能力</span><br><span class="line">19.5 本章小结</span><br><span class="line"></span><br><span class="line">第20章 开源系统</span><br><span class="line">20.1 选：如何选择一个开源项目</span><br><span class="line">20.1.1 聚焦是否满足业务</span><br><span class="line">20.1.2 聚焦是否成熟</span><br><span class="line">20.1.3 聚焦运维能力</span><br><span class="line">20.2 用：如何使用开源方案</span><br><span class="line">20.2.1 深入研究，仔细测试</span><br><span class="line">20.2.2 小心应用，灰度发布</span><br><span class="line">20.2.3 做好应急，以防万一</span><br><span class="line">20.3 改：如何基于开源项目做二次开发</span><br><span class="line">20.3.1 保持纯洁，加以包装</span><br><span class="line">20.3.2 发明你要的轮子</span><br><span class="line">20.4 本章小结</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>常见的java面试题</title>
    <url>/java-other/java-interview/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><a id="more"></a>

<ul>
<li><a href="/java-basic">java基础</a></li>
<li><a href="https://mp.weixin.qq.com/s/cJkiienGduLUsqMJ9_4pwA" target="_blank" rel="noopener">Java工程师成神之路</a></li>
<li><a href="https://github.com/CyC2018/Interview-Notebook" target="_blank" rel="noopener">技术面试需要掌握的基础知识整理</a></li>
<li><a href="https://mp.weixin.qq.com/s/VDGXJeKZM_U_9tcZOb0q4Q" target="_blank" rel="noopener">如何面试工程师？</a></li>
<li><a href="https://mp.weixin.qq.com/s/2Lne6O6q5cZ43Msdxm-jnQ" target="_blank" rel="noopener">阿里面试回来，想和 Java 程序员谈一谈</a></li>
<li><a href="https://mp.weixin.qq.com/s/8xB_sxBXZ6a9xoYkXunCQQ" target="_blank" rel="noopener">面试心得与总结：BAT、网易、蘑菇街</a></li>
<li><a href="https://mp.weixin.qq.com/s/RtfEPR2oclUAu0tXnYAn4Q" target="_blank" rel="noopener">Java面试题-基础知识</a></li>
<li><a href="https://mp.weixin.qq.com/s/BGo3RY6JLFeg87hH3Y60KA" target="_blank" rel="noopener">2017的金秋，派卧底去阿里、京东、美团、滴滴带回来的面试题及答案</a></li>
<li><a href="https://mp.weixin.qq.com/s/dc6z7G7ej0m5dCc80r1Rlw" target="_blank" rel="noopener">面试常被问的65个问题及回答技巧</a></li>
<li><a href="https://mp.weixin.qq.com/s/VpIDFNYmFof6Tob95dTcow" target="_blank" rel="noopener">记录一次壮烈牺牲的阿里巴巴面试</a></li>
<li><a href="https://mp.weixin.qq.com/s/xHOSVG5tGzj1RzpEutH_wg" target="_blank" rel="noopener">线程与进程的区别</a></li>
<li><a href="https://mp.weixin.qq.com/s/5dexEENTqJWXN_17c6Lz6A" target="_blank" rel="noopener">线程池的成长之路</a></li>
<li><a href="https://mp.weixin.qq.com/s/aizEy6vOrb4LPKD3qeajiw" target="_blank" rel="noopener">一次惊险的跳槽面试经历（阿里/美团/头条/网易/有赞…)</a></li>
<li><a href="https://mp.weixin.qq.com/s/wDDsa5na4b3MSdsIgh3upw" target="_blank" rel="noopener">有赞面试经历</a></li>
<li><a href="https://mp.weixin.qq.com/s/ENQZii1xgxlsIbR-oMseKw" target="_blank" rel="noopener">关于 MySQL 的知识点与面试常见问题都在这里</a></li>
<li><a href="https://mp.weixin.qq.com/s/md2r34uwVC13KSeROmuZDg" target="_blank" rel="noopener">Java架构师面试题全分享</a></li>
<li><a href="https://mp.weixin.qq.com/s/SodWSw-3zSWRYmxZNvjlgA" target="_blank" rel="noopener">作为面试官，我是怎么快速判断程序员能力的？</a></li>
<li><a href="https://mp.weixin.qq.com/s/uqTPgHZmu7rljRNA61HlVQ" target="_blank" rel="noopener">Java 面试题 —— 老田的蚂蚁金服面试经历</a></li>
</ul>
<h1 id="github-面试知识汇总"><a href="#github-面试知识汇总" class="headerlink" title="github 面试知识汇总"></a>github 面试知识汇总</h1><ul>
<li><a href="https://github.com/kdn251/interviews" target="_blank" rel="noopener">interviews （出自github）</a></li>
<li><a href="https://github.com/crossoverJie/JCSprout" target="_blank" rel="noopener">JCSprout（出自github）</a></li>
<li><a href="https://github.com/Snailclimb/Java-Guide" target="_blank" rel="noopener">Java-Guide（出自github）</a></li>
<li><a href="https://github.com/InterviewMap/CS-Interview-Knowledge-Map" target="_blank" rel="noopener">CS-Interview-Knowledge-Map （出自github）</a></li>
<li><a href="https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8" target="_blank" rel="noopener">system-design-primer（出自github） </a></li>
<li><a href="https://github.com/Snailclimb/JavaGuide" target="_blank" rel="noopener">JavaGuide</a>    </li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>其它</title>
    <url>/java-other/other/</url>
    <content><![CDATA[<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><hr>
<h2 id="编程语言"><a href="#编程语言" class="headerlink" title="编程语言"></a>编程语言</h2><ul>
<li><a href="https://blog.csdn.net/qq_34163820/article/details/51828625" target="_blank" rel="noopener">动态语言和静态语言</a><a id="more"></a>
<h2 id="其它-1"><a href="#其它-1" class="headerlink" title="其它"></a>其它</h2></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>互联网时代架构师的职责与思考</title>
    <url>/java-other/person-1/</url>
    <content><![CDATA[<p>在当下的互联网时代，架构师是互联网行业的热点关键词，人云亦云者居多，那互联网架构师<br>到底是做什么的，如何来评价互联网架构师的优劣呢？</p>
<a id="more"></a>
<h1 id="架构师产生的历史渊源"><a href="#架构师产生的历史渊源" class="headerlink" title="架构师产生的历史渊源"></a>架构师产生的历史渊源</h1><p>互联网应用脱胎于传统软件应用，伴随着要求更为快捷与面向未知需求的互联网应用的兴起，对技术团队的要求也陡然升高，不再是按部就班的开发，而是需要快速迭代、快速响应来自市场和用户的需求和反馈，互联网应用的反应和迭代快慢决定了生死的微妙差别。<br>互联网时代的变更也带来了技术团队中组织结构和技术栈的快速升级与变化，所有的这些都来自于行业的快速演进和进化。于是乎之前的项目经理带领一帮高级程序员、中级/初级程序猿的组织结构显然已经不太适应时代的需求，<code>产品经理、技术经理、系统架构师、数据架构师、运维架构师、前端开发与架构师</code> 等等诸多的细分职位与之伴生而为大家所接受和理解。<br>在这里，我们重点需要讨论的是互联网项目中的软件系统架构师的这个职位。</p>
<h1 id="众人眼中的”架构师”"><a href="#众人眼中的”架构师”" class="headerlink" title="众人眼中的”架构师”"></a>众人眼中的”架构师”</h1><p>在技术团队中，除了众多开发工程师、项目经理、技术经理和产品经理之外，还有一个架构师，通常大家都是把这个职位当作高级工程师中的资深工程师，经验和阅历都很丰富，有问题找他来解决就是了。<br>整个技术团队的主要管理内容包括： 人员管理、资源协调、进度管理、技术管理等等内容，分别分配到项目经理、技术经理和架构师等类似的职位上，一般架构师这个职位不承担技术之外的管理职能，主要专注于项目所使用的技术栈的评估与选取，关键的技术问题的分析与解决、核心代码和系统的设计与实现等任务；但是在实际的工作中，架构师和技术经理的角色在技术选型和关键部分的把控方面是由冲突和重叠的；另外，在技术团队中，人员和技术方面的工作实际上是无法分开的，重要的原因是人员大部分都是技术人员，其主要的工作是技术工作，很多时候都是需要听取来自专业技术方面的意见和反馈之后，才可以制定相应的排期以及计划，包括风险管理、工作量评估等内容。<br>在项目经理以及诸多的领导眼里，架构师就是做技术的，技术大牛，整个项目的技术架构以及技术问题都由其来承担和负责，出了问题就是架构师的问题。其实在实际情况中，一个项目出现了问题，固然有技术方面的因素，但是绝大多数情况下，技术都是次要的因素，技术之外的因素往往扮演了各种复杂的角色；产品的成败由业务线（比如产品经理）来负责，产品本身的质量由技术团队来负责，当然这个只是理想的状况下的自然推理。实际的情况，往往南辕北辙，彼此都是纠缠在一起的，业务方面深刻影响了技术架构的选择与设计，快速的业务变化带给技术架构以及技术团队的混乱与损耗都是非常巨大的。</p>
<h1 id="架构师的职责"><a href="#架构师的职责" class="headerlink" title="架构师的职责"></a>架构师的职责</h1><p><code>架构师的职责应该是立足于技术和业务之间的中间角色或者平衡点</code>， 在针对业务深刻理解的基础上，针对业务中存在诸多变数，挑选适合的技术架构和技术方案；结合现有的技术团队的水平与特点，选择合适的技术栈进行落地和实现。<br>架构师在做每一个决定之时都会受到诸多的因素的限制，比如高效的技术栈需要很高的学习曲线，在工期与人员素质之间需要权衡。精妙的技术架构并不能解决业务的快速迭代和变化，技术架构都是后知后觉的，无法准确的预知业务层面的变更与方向，故只能是跟随的角色，这样就必然会面临技术架构迭代和升级的需求，技术架构从来都不是建立了之后，就无需修改，可以承载各方的多重期望；事实上恰恰相反，<code>技术架构是需要与时俱进的，是不断迭代和升级出来</code>，根据不断变更的需求和团队情况来动态调整的。</p>
<h1 id="架构师的应变与坚持"><a href="#架构师的应变与坚持" class="headerlink" title="架构师的应变与坚持"></a>架构师的应变与坚持</h1><p>架构师这个职位的优势所在是将技术方面重要的决定由专门的角色来进行负责和跟踪。当然这个职位的出现是基于现有团队功能的重新划分，将原来从属于技术经理的技术职能剥离出来独立成为架构师，必然带来了彼此之间的职能灰色地带；这也就带来一个巨大的隐患冲突： 技术经理和架构师之间的职责边界以及合作沟通。<br>技术架构的保持、重构与升级都与架构师的沟通技巧、坚持以及妥协技能息息相关，在技术团队之外，其余的角色和上层领导对于技术都是理解肤浅或者不甚了解的；除了自身的关注点之外，对于技术团队所为的技术架构以及业务的变更对于系统的冲击影响不甚关心；一般都是结果导向，在没有如期实现业务功能和目标之前，所谓的“技术架构”的稳定、重构与保持都是没有任何意义的。 所以，架构师需要与业务不停的沟通妥协，在面对对技术架构深远和错误的影响之时，需要有所坚持和信仰，对于对的方向和原则有所坚持；<code>帮助技术团队规避一些人为或者外界带给系统和项目的各种冲击。</code><br>所有的这些都是建立在各个层面可以沟通和愿意承担的基础上，如果各个层面不满足这个基本原则，架构师所有的坚持与妥协都会让自身陷入不利的境地，过程中承担各种抱怨，来自技术团队、业务方和公司高层。建议此时，妥协第一，不必坚持，满足业务需求，尽力做好预防性设计，不做错误解决，已是万幸。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在其位，谋其政，站在架构师的职位上，架构师要本着对团队支持、对系统负责，对领导和业务相关方充分沟通与建议的基本准备，充分利用自身的经验与阅历，帮助团队规避各类或深或浅的系统之坑陷，保证业务线的正常运转，同时保持系统具备一定的灵活性、稳定性和可持续开发性。 尽人事，知天命，有所为，有所不为，架构师其实是技术、业务、管理和资源等各类因素之间进行妥协、沟通和协调的角色，混很容易，做好很难。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>java基础面试题</title>
    <url>/java-other/java-basic/</url>
    <content><![CDATA[<h1 id="1-什么是线程？"><a href="#1-什么是线程？" class="headerlink" title="1) 什么是线程？"></a>1) 什么是线程？</h1><p>线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。程序员可以通过它进行多处理器编程，你可以使用多线程对运算密集型任务提速。比如，如果一个线程完成一个任务要100毫秒，那么用十个线程完成改任务只需10毫秒。Java在语言层面对多线程提供了卓越的支持，它也是一个很好的卖点。</p>
<a id="more"></a>
<h1 id="2-线程和进程有什么区别？"><a href="#2-线程和进程有什么区别？" class="headerlink" title="2) 线程和进程有什么区别？"></a>2) 线程和进程有什么区别？</h1><p>线程是进程的子集，一个进程可以有很多线程，每条线程并行执行不同的任务。不同的进程使用不同的内存空间，而所有的线程共享一片相同的内存空间。别把它和栈内存搞混，每个线程都拥有单独的栈内存用来存储本地数据。</p>
<h1 id="3-如何在Java中实现线程？"><a href="#3-如何在Java中实现线程？" class="headerlink" title="3) 如何在Java中实现线程？"></a>3) 如何在Java中实现线程？</h1><p>在语言层面有两种方式。java.lang.Thread 类的实例就是一个线程但是它需要调用java.lang.Runnable接口来执行，由于线程类本身就是调用的Runnable接口所以你可以继承java.lang.Thread 类或者直接调用Runnable接口来重写run()方法实现线程。</p>
<h1 id="4-用Runnable还是Thread？"><a href="#4-用Runnable还是Thread？" class="headerlink" title="4) 用Runnable还是Thread？"></a>4) 用Runnable还是Thread？</h1><p>这个问题是上题的后续，大家都知道我们可以通过继承Thread类或者调用Runnable接口来实现线程，问题是，那个方法更好呢？什么情况下使用它？这个问题很容易回答，如果你知道Java不支持类的多重继承，但允许你调用多个接口。所以如果你要继承其他类，当然是调用Runnable接口好了。</p>
<h1 id="6-Thread-类中的start-和-run-方法有什么区别？"><a href="#6-Thread-类中的start-和-run-方法有什么区别？" class="headerlink" title="6) Thread 类中的start() 和 run() 方法有什么区别？"></a>6) Thread 类中的start() 和 run() 方法有什么区别？</h1><p>这个问题经常被问到，但还是能从此区分出面试者对Java线程模型的理解程度。start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程。</p>
<h1 id="7-Java中Runnable和Callable有什么不同？"><a href="#7-Java中Runnable和Callable有什么不同？" class="headerlink" title="7) Java中Runnable和Callable有什么不同？"></a>7) Java中Runnable和Callable有什么不同？</h1><p>Runnable和Callable都代表那些要在不同的线程中执行的任务。Runnable从JDK1.0开始就有了，Callable是在JDK1.5增加的。它们的主要区别是Callable的 call() 方法可以返回值和抛出异常，而Runnable的run()方法没有这些功能。Callable可以返回装载有计算结果的Future对象。我的博客有更详细的说明。（<a href="http://java67.blogspot.com/2013/01/difference-between-callable-and-runnable-java.html）" target="_blank" rel="noopener">http://java67.blogspot.com/2013/01/difference-between-callable-and-runnable-java.html）</a></p>
<h1 id="8-Java中CyclicBarrier-和-CountDownLatch有什么不同？"><a href="#8-Java中CyclicBarrier-和-CountDownLatch有什么不同？" class="headerlink" title="8) Java中CyclicBarrier 和 CountDownLatch有什么不同？"></a>8) Java中CyclicBarrier 和 CountDownLatch有什么不同？</h1><p>CyclicBarrier 和 CountDownLatch 都可以用来让一组线程等待其它线程。与 CyclicBarrier 不同的是，CountdownLatch 不能重新使用。点此查看更多信息和示例代码。（<a href="http://javarevisited.blogspot.com/2012/07/cyclicbarrier-example-java-5-concurrency-tutorial.html）" target="_blank" rel="noopener">http://javarevisited.blogspot.com/2012/07/cyclicbarrier-example-java-5-concurrency-tutorial.html）</a></p>
<h1 id="9-Java内存模型是什么？"><a href="#9-Java内存模型是什么？" class="headerlink" title="9) Java内存模型是什么？"></a>9) Java内存模型是什么？</h1><p>Java内存模型规定和指引Java程序在不同的内存架构、CPU和操作系统间有确定性地行为。它在多线程的情况下尤其重要。Java内存模型对一个线程所做的变动能被其它线程可见提供了保证，它们之间是先行发生关系。这个关系定义了一些规则让程序员在并发编程时思路更清晰。比如，先行发生关系确保了：</p>
<ul>
<li><p>线程内的代码能够按先后顺序执行，这被称为程序次序规则。</p>
</li>
<li><p>对于同一个锁，一个解锁操作一定要发生在时间上后发生的另一个锁定操作之前，也叫做管程锁定规则。</p>
</li>
<li><p>前一个对volatile的写操作在后一个volatile的读操作之前，也叫volatile变量规则。</p>
</li>
<li><p>一个线程内的任何操作必需在这个线程的start()调用之后，也叫作线程启动规则。</p>
</li>
<li><p>一个线程的所有操作都会在线程终止之前，线程终止规则。</p>
</li>
<li><p>一个对象的终结操作必需在这个对象构造完成之后，也叫对象终结规则。</p>
</li>
<li><p>可传递性</p>
</li>
</ul>
<p>我强烈建议大家阅读《Java并发编程实践》第十六章来加深对Java内存模型的理解。</p>
<h1 id="10-Java中的volatile-变量是什么？"><a href="#10-Java中的volatile-变量是什么？" class="headerlink" title="10) Java中的volatile 变量是什么？"></a>10) Java中的volatile 变量是什么？</h1><p>volatile是一个特殊的修饰符，只有成员变量才能使用它。在Java并发程序缺少同步类的情况下，多线程对成员变量的操作对其它线程是透明的。volatile变量可以保证下一个读取操作会在前一个写操作之后发生，就是上一题的volatile变量规则。查看更多volatile的相关内容。（<a href="http://javarevisited.blogspot.com/2011/06/volatile-keyword-java-example-tutorial.html）" target="_blank" rel="noopener">http://javarevisited.blogspot.com/2011/06/volatile-keyword-java-example-tutorial.html）</a></p>
<h1 id="11-什么是线程安全？Vector是一个线程安全类吗？"><a href="#11-什么是线程安全？Vector是一个线程安全类吗？" class="headerlink" title="11) 什么是线程安全？Vector是一个线程安全类吗？"></a>11) 什么是线程安全？Vector是一个线程安全类吗？</h1><p>如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。</p>
<h1 id="12-Java中什么是竞态条件？-举个例子说明。"><a href="#12-Java中什么是竞态条件？-举个例子说明。" class="headerlink" title="12) Java中什么是竞态条件？ 举个例子说明。"></a>12) Java中什么是竞态条件？ 举个例子说明。</h1><p>竞态条件会导致程序在并发情况下出现一些bugs。多线程对一些资源的竞争的时候就会产生竞态条件，如果首先要执行的程序竞争失败排到后面执行了，那么整个程序就会出现一些不确定的bugs。这种bugs很难发现而且会重复出现，因为线程间的随机竞争。一个例子就是无序处理，详见答案。（<a href="http://javarevisited.blogspot.com/2012/02/what-is-race-condition-in.html）" target="_blank" rel="noopener">http://javarevisited.blogspot.com/2012/02/what-is-race-condition-in.html）</a></p>
<h1 id="13-Java中如何停止一个线程？"><a href="#13-Java中如何停止一个线程？" class="headerlink" title="13) Java中如何停止一个线程？"></a>13) Java中如何停止一个线程？</h1><p>Java提供了很丰富的API但没有为停止线程提供API。JDK 1.0本来有一些像stop(), suspend() 和 resume()的控制方法但是由于潜在的死锁威胁因此在后续的JDK版本中他们被弃用了，之后Java API的设计者就没有提供一个兼容且线程安全的方法来停止一个线程。当run() 或者 call() 方法执行完的时候线程会自动结束,如果要手动结束一个线程，你可以用volatile 布尔变量来退出run()方法的循环或者是取消任务来中断线程。点击这里查看示例代码。（<a href="http://javarevisited.blogspot.com/2011/10/how-to-stop-thread-java-example.html）" target="_blank" rel="noopener">http://javarevisited.blogspot.com/2011/10/how-to-stop-thread-java-example.html）</a></p>
<h1 id="14-一个线程运行时发生异常会怎样？"><a href="#14-一个线程运行时发生异常会怎样？" class="headerlink" title="14) 一个线程运行时发生异常会怎样？"></a>14) 一个线程运行时发生异常会怎样？</h1><p>这是我在一次面试中遇到的一个很刁钻的Java面试题, 简单的说，如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。</p>
<h1 id="15）-如何在两个线程间共享数据？"><a href="#15）-如何在两个线程间共享数据？" class="headerlink" title="15） 如何在两个线程间共享数据？"></a>15） 如何在两个线程间共享数据？</h1><p>你可以通过共享对象来实现这个目的，或者是使用像阻塞队列这样并发的数据结构。这篇教程《Java线程间通信》（<a href="http://javarevisited.blogspot.sg/2013/12/inter-thread-communication-in-java-wait-notify-example.html）(涉及到在两个线程间共享对象)用wait和notify方法实现了生产者消费者模型。" target="_blank" rel="noopener">http://javarevisited.blogspot.sg/2013/12/inter-thread-communication-in-java-wait-notify-example.html）(涉及到在两个线程间共享对象)用wait和notify方法实现了生产者消费者模型。</a></p>
<h1 id="16-Java中notify-和-notifyAll有什么区别？"><a href="#16-Java中notify-和-notifyAll有什么区别？" class="headerlink" title="16) Java中notify 和 notifyAll有什么区别？"></a>16) Java中notify 和 notifyAll有什么区别？</h1><p>这又是一个刁钻的问题，因为多线程可以等待单监控锁，Java API 的设计人员提供了一些方法当等待条件改变的时候通知它们，但是这些方法没有完全实现。notify()方法不能唤醒某个具体的线程，所以只有一个线程在等待的时候它才有用武之地。而notifyAll()唤醒所有线程并允许他们争夺锁确保了至少有一个线程能继续运行。</p>
<h1 id="17-为什么wait-notify-和-notifyAll这些方法不在thread类里面？"><a href="#17-为什么wait-notify-和-notifyAll这些方法不在thread类里面？" class="headerlink" title="17) 为什么wait, notify 和 notifyAll这些方法不在thread类里面？"></a>17) 为什么wait, notify 和 notifyAll这些方法不在thread类里面？</h1><p>这是个设计相关的问题，它考察的是面试者对现有系统和一些普遍存在但看起来不合理的事物的看法。回答这些问题的时候，你要说明为什么把这些方法放在Object类里是有意义的，还有不把它放在Thread类里的原因。一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。</p>
<h1 id="18-什么是ThreadLocal变量？"><a href="#18-什么是ThreadLocal变量？" class="headerlink" title="18) 什么是ThreadLocal变量？"></a>18) 什么是ThreadLocal变量？</h1><p>ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。线程局部变量的另一个不错的例子是ThreadLocalRandom类，它在多线程环境中减少了创建代价高昂的Random对象的个数。</p>
<h1 id="19-什么是FutureTask？"><a href="#19-什么是FutureTask？" class="headerlink" title="19) 什么是FutureTask？"></a>19) 什么是FutureTask？</h1><p>在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。</p>
<h1 id="20-Java中interrupted-和-isInterruptedd方法的区别？"><a href="#20-Java中interrupted-和-isInterruptedd方法的区别？" class="headerlink" title="20) Java中interrupted 和 isInterruptedd方法的区别？"></a>20) Java中interrupted 和 isInterruptedd方法的区别？</h1><p>interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。而非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。简单的说就是任何抛出InterruptedException异常的方法都会将中断状态清零。无论如何，一个线程的中断状态有有可能被其它线程调用中断来改变。</p>
<h1 id="21-为什么wait和notify方法要在同步块中调用？"><a href="#21-为什么wait和notify方法要在同步块中调用？" class="headerlink" title="21) 为什么wait和notify方法要在同步块中调用？"></a>21) 为什么wait和notify方法要在同步块中调用？</h1><p>主要是因为Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。还有一个原因是为了避免wait和notify之间产生竞态条件。</p>
<h1 id="22-为什么你应该在循环中检查等待条件"><a href="#22-为什么你应该在循环中检查等待条件" class="headerlink" title="22) 为什么你应该在循环中检查等待条件?"></a>22) 为什么你应该在循环中检查等待条件?</h1><p>处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。因此，当一个等待线程醒来时，不能认为它原来的等待状态仍然是有效的，在notify()方法调用之后和等待线程醒来之前这段时间它可能会改变。这就是在循环中使用wait()方法效果更好的原因，你可以在Eclipse中创建模板调用wait和notify试一试。如果你想了解更多关于这个问题的内容，我推荐你阅读《Effective Java》这本书中的线程和同步章节。</p>
<h1 id="23-Java中的同步集合与并发集合有什么区别？"><a href="#23-Java中的同步集合与并发集合有什么区别？" class="headerlink" title="23) Java中的同步集合与并发集合有什么区别？"></a>23) Java中的同步集合与并发集合有什么区别？</h1><p>同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在Java1.5之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。</p>
<h1 id="24）-Java中堆和栈有什么不同？"><a href="#24）-Java中堆和栈有什么不同？" class="headerlink" title="24） Java中堆和栈有什么不同？"></a>24） Java中堆和栈有什么不同？</h1><p>为什么把这个问题归类在多线程和并发面试题里？因为栈是一块和线程紧密相关的内存区域。每个线程都有自己的栈内存，用于存储本地变量，方法参数和栈调用，一个线程中存储的变量对其它线程是不可见的。而堆是所有线程共享的一片公用内存区域。对象都在堆里创建，为了提升效率线程会从堆中弄一个缓存到自己的栈，如果多个线程使用该变量就可能引发问题，这时volatile 变量就可以发挥作用了，它要求线程从主存中读取变量的值。</p>
<h1 id="25）-什么是线程池？-为什么要使用它？"><a href="#25）-什么是线程池？-为什么要使用它？" class="headerlink" title="25） 什么是线程池？ 为什么要使用它？"></a>25） 什么是线程池？ 为什么要使用它？</h1><p>创建线程要花费昂贵的资源和时间，如果任务来了才创建线程那么响应时间会变长，而且一个进程能创建的线程数有限。为了避免这些问题，在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫工作线程。从JDK1.5开始，Java API提供了Executor框架让你可以创建不同的线程池。比如单线程池，每次处理一个任务；数目固定的线程池或者是缓存线程池（一个适合很多生存期短的任务的程序的可扩展线程池）。</p>
<h1 id="26）-如何写代码来解决生产者消费者问题？"><a href="#26）-如何写代码来解决生产者消费者问题？" class="headerlink" title="26） 如何写代码来解决生产者消费者问题？"></a>26） 如何写代码来解决生产者消费者问题？</h1><p>在现实中你解决的许多线程问题都属于生产者消费者模型，就是一个线程生产任务供其它线程进行消费，你必须知道怎么进行线程间通信来解决这个问题。比较低级的办法是用wait和notify来解决这个问题，比较赞的办法是用Semaphore 或者 BlockingQueue来实现生产者消费者模型。</p>
<h1 id="27）-如何避免死锁？"><a href="#27）-如何避免死锁？" class="headerlink" title="27） 如何避免死锁？"></a>27） 如何避免死锁？</h1><p>Java多线程中的死锁</p>
<p>死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足以下四个条件：</p>
<ul>
<li><p>互斥条件：一个资源每次只能被一个进程使用。</p>
</li>
<li><p>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</p>
</li>
<li><p>不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。</p>
</li>
<li><p>循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。</p>
</li>
</ul>
<p>避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。</p>
<h1 id="28-Java中活锁和死锁有什么区别？"><a href="#28-Java中活锁和死锁有什么区别？" class="headerlink" title="28) Java中活锁和死锁有什么区别？"></a>28) Java中活锁和死锁有什么区别？</h1><p>这是上题的扩展，活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可以认为是一种特殊的饥饿。一个现实的活锁例子是两个人在狭小的走廊碰到，两个人都试着避让对方好让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。简单的说就是，活锁和死锁的主要区别是前者进程的状态可以改变但是却不能继续执行。</p>
<h1 id="29）-怎么检测一个线程是否拥有锁？"><a href="#29）-怎么检测一个线程是否拥有锁？" class="headerlink" title="29） 怎么检测一个线程是否拥有锁？"></a>29） 怎么检测一个线程是否拥有锁？</h1><p>我一直不知道我们竟然可以检测一个线程是否拥有锁，直到我参加了一次电话面试。在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。</p>
<h1 id="30-你如何在Java中获取线程堆栈？"><a href="#30-你如何在Java中获取线程堆栈？" class="headerlink" title="30) 你如何在Java中获取线程堆栈？"></a>30) 你如何在Java中获取线程堆栈？</h1><p>对于不同的操作系统，有多种方法来获得Java进程的线程堆栈。当你获取线程堆栈时，JVM会把所有线程的状态存到日志文件或者输出到控制台。在Windows你可以使用Ctrl + Break组合键来获取线程堆栈，Linux下用kill -3命令。你也可以用jstack这个工具来获取，它对线程id进行操作，你可以用jps这个工具找到id。</p>
<h1 id="31-JVM中哪个参数是用来控制线程的栈堆栈小的"><a href="#31-JVM中哪个参数是用来控制线程的栈堆栈小的" class="headerlink" title="31) JVM中哪个参数是用来控制线程的栈堆栈小的"></a>31) JVM中哪个参数是用来控制线程的栈堆栈小的</h1><p>这个问题很简单， -Xss参数用来控制线程的堆栈大小。你可以查看JVM配置列表来了解这个参数的更多信息。</p>
<h1 id="32）-Java中synchronized-和-ReentrantLock-有什么不同？"><a href="#32）-Java中synchronized-和-ReentrantLock-有什么不同？" class="headerlink" title="32） Java中synchronized 和 ReentrantLock 有什么不同？"></a>32） Java中synchronized 和 ReentrantLock 有什么不同？</h1><p>Java在过去很长一段时间只能通过synchronized关键字来实现互斥，它有一些缺点。比如你不能扩展锁之外的方法或者块边界，尝试获取锁时不能中途取消等。Java 5 通过Lock接口提供了更复杂的控制来解决这些问题。 ReentrantLock 类实现了 Lock，它拥有与 synchronized 相同的并发性和内存语义且它还具有可扩展性。</p>
<h1 id="33）-有三个线程T1，T2，T3，怎么确保它们按顺序执行？"><a href="#33）-有三个线程T1，T2，T3，怎么确保它们按顺序执行？" class="headerlink" title="33） 有三个线程T1，T2，T3，怎么确保它们按顺序执行？"></a>33） 有三个线程T1，T2，T3，怎么确保它们按顺序执行？</h1><p>在多线程中有多种方法让线程按特定顺序执行，你可以用线程类的join()方法在一个线程中启动另一个线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个(T3调用T2，T2调用T1)，这样T1就会先完成而T3最后完成。</p>
<h1 id="34-Thread类中的yield方法有什么作用？"><a href="#34-Thread类中的yield方法有什么作用？" class="headerlink" title="34) Thread类中的yield方法有什么作用？"></a>34) Thread类中的yield方法有什么作用？</h1><p>Yield方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法而且只保证当前线程放弃CPU占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在进入到暂停状态后马上又被执行。</p>
<h1 id="35）-Java中ConcurrentHashMap的并发度是什么？"><a href="#35）-Java中ConcurrentHashMap的并发度是什么？" class="headerlink" title="35） Java中ConcurrentHashMap的并发度是什么？"></a>35） Java中ConcurrentHashMap的并发度是什么？</h1><p>ConcurrentHashMap把实际map划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是ConcurrentHashMap类构造函数的一个可选参数，默认值为16，这样在多线程情况下就能避免争用。欲了解更多并发度和内部大小调整请阅读我的文章How ConcurrentHashMap works in Java。</p>
<h1 id="36）-Java中Semaphore是什么？"><a href="#36）-Java中Semaphore是什么？" class="headerlink" title="36） Java中Semaphore是什么？"></a>36） Java中Semaphore是什么？</h1><p>Java中的Semaphore是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动。信号量常常用于多线程的代码中，比如数据库连接池。</p>
<h1 id="37）如果你提交任务时，线程池队列已满。会时发会生什么？"><a href="#37）如果你提交任务时，线程池队列已满。会时发会生什么？" class="headerlink" title="37）如果你提交任务时，线程池队列已满。会时发会生什么？"></a>37）如果你提交任务时，线程池队列已满。会时发会生什么？</h1><p>这个问题问得很狡猾，许多程序员会认为该任务会阻塞直到线程池队列有空位。事实上如果一个任务不能被调度执行那么ThreadPoolExecutor’s submit()方法将会抛出一个RejectedExecutionException异常。</p>
<h1 id="38-Java线程池中submit-和-execute-方法有什么区别？"><a href="#38-Java线程池中submit-和-execute-方法有什么区别？" class="headerlink" title="38) Java线程池中submit() 和 execute()方法有什么区别？"></a>38) Java线程池中submit() 和 execute()方法有什么区别？</h1><p>两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中, 而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。</p>
<h1 id="39-什么是阻塞式方法？"><a href="#39-什么是阻塞式方法？" class="headerlink" title="39) 什么是阻塞式方法？"></a>39) 什么是阻塞式方法？</h1><p>阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。</p>
<h1 id="40-Swing是线程安全的吗？-为什么？"><a href="#40-Swing是线程安全的吗？-为什么？" class="headerlink" title="40) Swing是线程安全的吗？ 为什么？"></a>40) Swing是线程安全的吗？ 为什么？</h1><p>你可以很肯定的给出回答，Swing不是线程安全的，但是你应该解释这么回答的原因即便面试官没有问你为什么。当我们说swing不是线程安全的常常提到它的组件，这些组件不能在多线程中进行修改，所有对GUI组件的更新都要在AWT线程中完成，而Swing提供了同步和异步两种回调方法来进行更新。</p>
<h1 id="41）-Java中invokeAndWait-和-invokeLater有什么区别？"><a href="#41）-Java中invokeAndWait-和-invokeLater有什么区别？" class="headerlink" title="41） Java中invokeAndWait 和 invokeLater有什么区别？"></a>41） Java中invokeAndWait 和 invokeLater有什么区别？</h1><p>这两个方法是Swing API 提供给Java开发者用来从当前线程而不是事件派发线程更新GUI组件用的。InvokeAndWait()同步更新GUI组件，比如一个进度条，一旦进度更新了，进度条也要做出相应改变。如果进度被多个线程跟踪，那么就调用invokeAndWait()方法请求事件派发线程对组件进行相应更新。而invokeLater()方法是异步调用更新组件的。</p>
<h1 id="42-Swing-API中那些方法是线程安全的？"><a href="#42-Swing-API中那些方法是线程安全的？" class="headerlink" title="42) Swing API中那些方法是线程安全的？"></a>42) Swing API中那些方法是线程安全的？</h1><p>这个问题又提到了swing和线程安全，虽然组件不是线程安全的但是有一些方法是可以被多线程安全调用的，比如repaint(), revalidate()。 JTextComponent的setText()方法和JTextArea的insert() 和 append() 方法也是线程安全的。</p>
<h1 id="43-如何在Java中创建Immutable对象？"><a href="#43-如何在Java中创建Immutable对象？" class="headerlink" title="43) 如何在Java中创建Immutable对象？"></a>43) 如何在Java中创建Immutable对象？</h1><p>这个问题看起来和多线程没什么关系， 但不变性有助于简化已经很复杂的并发程序。Immutable对象可以在没有同步的情况下共享，降低了对该对象进行并发访问时的同步化开销。可是Java没有@Immutable这个注解符，要创建不可变类，要实现下面几个步骤：通过构造方法初始化所有成员、对变量不要提供setter方法、将所有的成员声明为私有的，这样就不允许直接访问这些成员、在getter方法中，不要直接返回对象本身，而是克隆对象，并返回对象的拷贝。我的文章how to make an object Immutable in Java有详细的教程，看完你可以充满自信。</p>
<h1 id="44）-Java中的ReadWriteLock是什么？"><a href="#44）-Java中的ReadWriteLock是什么？" class="headerlink" title="44） Java中的ReadWriteLock是什么？"></a>44） Java中的ReadWriteLock是什么？</h1><p>一般而言，读写锁是用来提升并发程序性能的锁分离技术的成果。Java中的ReadWriteLock是Java 5 中新增的一个接口，一个ReadWriteLock维护一对关联的锁，一个用于只读操作一个用于写。在没有写线程的情况下一个读锁可能会同时被多个读线程持有。写锁是独占的，你可以使用JDK中的ReentrantReadWriteLock来实现这个规则，它最多支持65535个写锁和65535个读锁。</p>
<h1 id="45-多线程中的忙循环是什么"><a href="#45-多线程中的忙循环是什么" class="headerlink" title="45) 多线程中的忙循环是什么?"></a>45) 多线程中的忙循环是什么?</h1><p>忙循环就是程序员用循环让一个线程等待，不像传统方法wait(), sleep() 或 yield() 它们都放弃了CPU控制，而忙循环不会放弃CPU，它就是在运行一个空循环。这么做的目的是为了保留CPU缓存，在多核系统中，一个等待线程醒来的时候可能会在另一个内核运行，这样会重建缓存。为了避免重建缓存和减少等待重建的时间就可以使用它了。</p>
<h1 id="46）volatile-变量和-atomic-变量有什么不同？"><a href="#46）volatile-变量和-atomic-变量有什么不同？" class="headerlink" title="46）volatile 变量和 atomic 变量有什么不同？"></a>46）volatile 变量和 atomic 变量有什么不同？</h1><p>这是个有趣的问题。首先，volatile 变量和 atomic 变量看起来很像，但功能却不一样。Volatile变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰count变量那么 count++ 操作就不是原子性的。而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。</p>
<h1 id="47-如果同步块内的线程抛出异常会发生什么？"><a href="#47-如果同步块内的线程抛出异常会发生什么？" class="headerlink" title="47) 如果同步块内的线程抛出异常会发生什么？"></a>47) 如果同步块内的线程抛出异常会发生什么？</h1><p>这个问题坑了很多Java程序员，若你能想到锁是否释放这条线索来回答还有点希望答对。无论你的同步块是正常还是异常退出的，里面的线程都会释放锁，所以对比锁接口我更喜欢同步块，因为它不用我花费精力去释放锁，该功能可以在finally block里释放锁实现。</p>
<h1 id="48）-单例模式的双检锁是什么？"><a href="#48）-单例模式的双检锁是什么？" class="headerlink" title="48） 单例模式的双检锁是什么？"></a>48） 单例模式的双检锁是什么？</h1><p>这个问题在Java面试中经常被问到，但是面试官对回答此问题的满意度仅为50%。一半的人写不出双检锁还有一半的人说不出它的隐患和Java1.5是如何对它修正的。它其实是一个用来创建线程安全的单例的老方法，当单例实例第一次被创建时它试图用单个锁进行性能优化，但是由于太过于复杂在JDK1.4中它是失败的，我个人也不喜欢它。无论如何，即便你也不喜欢它但是还是要了解一下，因为它经常被问到。你可以查看how double checked locking on Singleton works这篇文章获得更多信息。</p>
<h1 id="49）-如何在Java中创建线程安全的Singleton？"><a href="#49）-如何在Java中创建线程安全的Singleton？" class="headerlink" title="49） 如何在Java中创建线程安全的Singleton？"></a>49） 如何在Java中创建线程安全的Singleton？</h1><p>这是上面那个问题的后续，如果你不喜欢双检锁而面试官问了创建Singleton类的替代方法，你可以利用JVM的类加载和静态变量初始化特征来创建Singleton实例，或者是利用枚举类型来创建Singleton，我很喜欢用这种方法。</p>
<h1 id="50-写出3条你遵循的多线程最佳实践"><a href="#50-写出3条你遵循的多线程最佳实践" class="headerlink" title="50) 写出3条你遵循的多线程最佳实践"></a>50) 写出3条你遵循的多线程最佳实践</h1><p>这种问题我最喜欢了，我相信你在写并发代码来提升性能的时候也会遵循某些最佳实践。以下三条最佳实践我觉得大多数Java程序员都应该遵循：</p>
<ul>
<li><p>给你的线程起个有意义的名字。<br>这样可以方便找bug或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比 Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要框架甚至JDK都遵循这个最佳实践。</p>
</li>
<li><p>避免锁定和缩小同步的范围<br>锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。</p>
</li>
<li><p>多用同步类少用wait 和 notify<br>首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而用wait和notify很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的JDK中它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。</p>
</li>
<li><p>多用并发集合少用同步集合<br>这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程时使用并发集合效果更好。如果下一次你需要用到map，你应该首先想到用ConcurrentHashMap。我的文章Java并发集合有更详细的说明。</p>
</li>
</ul>
<h1 id="51-如何强制启动一个线程？"><a href="#51-如何强制启动一个线程？" class="headerlink" title="51) 如何强制启动一个线程？"></a>51) 如何强制启动一个线程？</h1><p>这个问题就像是如何强制进行Java垃圾回收，目前还没有觉得方法，虽然你可以使用System.gc()来进行垃圾回收，但是不保证能成功。在Java里面没有办法强制启动一个线程，它是被线程调度器控制着且Java没有公布相关的API。</p>
<h1 id="52-Java中的fork-join框架是什么？"><a href="#52-Java中的fork-join框架是什么？" class="headerlink" title="52) Java中的fork join框架是什么？"></a>52) Java中的fork join框架是什么？</h1><p>fork join框架是JDK7中出现的一款高效的工具，Java开发人员可以通过它充分利用现代服务器上的多处理器。它是专门为了那些可以递归划分成许多子模块设计的，目的是将所有可用的处理能力用来提升程序的性能。fork join框架一个巨大的优势是它使用了工作窃取算法，可以完成更多任务的工作线程可以从其它线程中窃取任务来执行。</p>
<h1 id="53）-Java多线程中调用wait-和-sleep-方法有什么不同？"><a href="#53）-Java多线程中调用wait-和-sleep-方法有什么不同？" class="headerlink" title="53） Java多线程中调用wait() 和 sleep()方法有什么不同？"></a>53） Java多线程中调用wait() 和 sleep()方法有什么不同？</h1><p>Java程序中wait 和 sleep都会造成某种形式的暂停，它们可以满足不同的需要。wait()方法用于线程间通信，如果等待条件为真且其它线程被唤醒时它会释放锁，而sleep()方法仅仅释放CPU资源或者让当前线程停止执行一段时间，但不会释放锁。</p>
<h1 id="54）ArrayList、Vector、LinkedList-的区别及其优缺点？HashMap、HashTable-的区别及优缺点？"><a href="#54）ArrayList、Vector、LinkedList-的区别及其优缺点？HashMap、HashTable-的区别及优缺点？" class="headerlink" title="54）ArrayList、Vector、LinkedList 的区别及其优缺点？HashMap、HashTable 的区别及优缺点？"></a>54）ArrayList、Vector、LinkedList 的区别及其优缺点？HashMap、HashTable 的区别及优缺点？</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ArrayList 和 Vector 是采用数组方式存储数据的,是根据索引来访问元素的，都可以根据需要自动扩展内部数据长度，以便增加和插入元素，都允许直接序号索引元素，但是插入数据要涉及到数组元素移动等内存操作，所以索引数据快插入数据慢，他们最大的区别就是 synchronized 同步的使用。</span><br><span class="line"></span><br><span class="line">LinkedList 使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项的前后项即可，所以插入数度较快！如果只是查找特定位置的元素或只在集合的末端增加、移除元素，那么使用 Vector或 ArrayList 都可以。如果是对其它指定位置的插入、删除操作，最好选择 LinkedList</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">HashMap、HashTable 的区别及其优缺点：</span><br><span class="line"></span><br><span class="line">HashTable 中的方法是同步的 HashMap 的方法在缺省情况下是非同步的 因此在多线程环境下需要做额外的同步机制。</span><br><span class="line">HashTable 不允许有 null 值 key 和 value 都不允许，而 HashMap 允许有 null 值 key和 value 都允许 因此 HashMap 使用 containKey（）来判断是否存在某个键。</span><br><span class="line">HashTable 使用 Enumeration ，而 HashMap 使用 iterator。</span><br><span class="line">Hashtable 是 Dictionary 的子类，HashMap 是 Map 接口的一个实现类。</span><br></pre></td></tr></table></figure>

<h1 id="55）Java中Class-forName和ClassLoader-loadClass的区别"><a href="#55）Java中Class-forName和ClassLoader-loadClass的区别" class="headerlink" title="55）Java中Class.forName和ClassLoader.loadClass的区别"></a>55）Java中Class.forName和ClassLoader.loadClass的区别</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Class.forName(&quot;xx.xx&quot;)等同于Class.forName(&quot;xx.xx&quot;,true,CALLClass.class.getClassLoader())，第二个参数(bool)表示装载类的时候是否初始化该类，即调用类的静态块的语句及初始化静态成员变量。</span><br><span class="line"></span><br><span class="line">ClassLoader loader &#x3D; Thread.currentThread.getContextClassLoader(); &#x2F;&#x2F;也可以用(ClassLoader.getSystemClassLoader())</span><br><span class="line"></span><br><span class="line">Class cls &#x3D; loader.loadClass(&quot;xx.xx&quot;); &#x2F;&#x2F;这句话没有执行初始化</span><br><span class="line">forName可以控制是否初始化类，而loadClass加载时是没有初始化的。</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员素养</title>
    <url>/java-other/programer/</url>
    <content><![CDATA[<p>在日常工作中肯定会遇到各种棘手问题，需要我们去查资料、认真思考，不断充实自己，提高自己。象大地之神盖亚的儿子——乌拉诺斯，每次跌倒都能站起来，并且拥有比之前更大的能量。</p>
<a id="more"></a>
<h2 id="心得体会"><a href="#心得体会" class="headerlink" title="心得体会"></a>心得体会</h2><ul>
<li><p>写代码往小的方面讲是完成一个功能，往大的方面讲是做一个平台。抽象和枚举分寸拿捏恰当，做到最大通用性。需求变更和新功能接入时，做到最少的改动。做到这一点才称的上最佳程序员。</p>
</li>
<li><p>关注最新流行的开源框架，能快速分析其优缺点。做好技术框架选型、测试、集成，上线使用。<strong>(注：框架选型要特别小心，最好能将里面的原理细节研究透彻，可能一些bug需要特殊的场景才能触发出来，比如很高的并发量等。另外以经验来看，最好选一些市面上普及率较高的框架，因为很多潜在的坑都已经被踩出来了！)</strong></p>
</li>
<li><p>对于很多框架要知道其如何使用、然后要深入了解其原理。做到知其然，知其所以然。</p>
</li>
<li><p>框架设计尽量要考虑其业务场景，每个领域都有其个性特征，大而全且通用的设计很难满足需求。</p>
</li>
<li><p>做优化时要结合数据反馈，不能盲目瞎搞。</p>
</li>
<li><p>墨菲定律：任何事情都没有表面看起来那么简单。所有的事都比你预估的时间长。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>学习网站</title>
    <url>/java-other/study/</url>
    <content><![CDATA[<h2 id="技术网站"><a href="#技术网站" class="headerlink" title="技术网站"></a>技术网站</h2><a id="more"></a>
<ul>
<li><a href="http://www.infoq.com/cn/" target="_blank" rel="noopener">infoQ</a></li>
<li><a href="https://yq.aliyun.com/" target="_blank" rel="noopener">云栖社区</a></li>
<li><a href="http://ifeve.com/" target="_blank" rel="noopener">并发编程网</a></li>
<li><a href="http://www.oschina.net/" target="_blank" rel="noopener">开源中国</a></li>
<li><a href="http://stackoverflow.com/" target="_blank" rel="noopener">stackoverflow</a></li>
<li><a href="https://www.w3cschool.cn/" target="_blank" rel="noopener">w3cschool</a></li>
</ul>
<h2 id="视频网站"><a href="#视频网站" class="headerlink" title="视频网站"></a>视频网站</h2><ul>
<li><a href="http://www.imooc.com/" target="_blank" rel="noopener">慕课网</a></li>
<li><a href="http://study.163.com/" target="_blank" rel="noopener">网易云课堂</a></li>
<li><a href="https://ke.qq.com/course/list/spark" target="_blank" rel="noopener">腾讯课堂</a></li>
</ul>
<h2 id="优秀博客"><a href="#优秀博客" class="headerlink" title="优秀博客"></a>优秀博客</h2><ul>
<li><a href="https://coolshell.cn/articles/18360.html" target="_blank" rel="noopener">酷 壳</a></li>
<li><a href="http://www.iocoder.cn/" target="_blank" rel="noopener">芋道源码解读</a></li>
<li><a href="https://github.com/YunaiV/Blog" target="_blank" rel="noopener">芋道源码（github）</a><ul>
<li>涉及RocketMQ、Sharding-JDBC、MyCAT、TCC-Transaction、 Elastic-Job、Eureka、Dubbo、Spring Cloud、Disconf 等框架源码分析解读。</li>
</ul>
</li>
<li></li>
</ul>
<h2 id="github资料集（强烈推荐）"><a href="#github资料集（强烈推荐）" class="headerlink" title="github资料集（强烈推荐）"></a>github资料集（强烈推荐）</h2><ul>
<li><a href="https://github.com/jobbole" target="_blank" rel="noopener">github 伯乐在线</a></li>
<li><a href="https://github.com/jobbole/awesome-java-cn" target="_blank" rel="noopener">Java资源大全中文版</a></li>
<li><a href="https://github.com/stanzhai/be-a-professional-programmer" target="_blank" rel="noopener">成为专业程序员路上用到的各种优秀资料、神器及框架</a></li>
<li><a href="https://github.com/taojintianxia/github-bookmark" target="_blank" rel="noopener">收集了Github上的优秀工具,框架,知识合集</a></li>
</ul>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>super-diamond源码分析</title>
    <url>/java-other/super-diamond%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="https://github.com/melin/super-diamond" target="_blank" rel="noopener">源码</a></li>
<li><a href="https://www.oschina.net/p/super-diamond" target="_blank" rel="noopener">项目文档</a><a id="more"></a>
</li>
</ul>
<hr>
<h2 id="源码笔记"><a href="#源码笔记" class="headerlink" title="源码笔记"></a>源码笔记</h2><h2 id="一、客户端部分"><a href="#一、客户端部分" class="headerlink" title="一、客户端部分"></a>一、客户端部分</h2><p>1.初始化xml配置</p>
<!-- more -->
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">name</span>=<span class="string">"bbsWebPropertiesConfiguration"</span> <span class="attr">class</span>=<span class="string">"com.github.diamond.client.PropertiesConfigurationFactoryBean"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"0"</span> <span class="attr">value</span>=<span class="string">"$&#123;config.server.ip&#125;"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"1"</span> <span class="attr">value</span>=<span class="string">"$&#123;config.server.port&#125;"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"2"</span> <span class="attr">value</span>=<span class="string">"应用名"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"3"</span> <span class="attr">value</span>=<span class="string">"$&#123;profiles.active&#125;"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>初始化bbsWebPropertiesConfiguration时，与服务器建立连接com.github.diamond.client.PropertiesConfiguration.connectServer(String, int, String, String)</p>
<p>2.实例化对象，建立连接</p>
<ul>
<li>本地封装Netty4Client对象，内部实现与netty与服务端的通信逻辑</li>
<li>如果已经建立连接，向服务端发送请求（应用启动时，需要加载最新的配置项）</li>
<li>响应，获取配置项</li>
<li>备份数据到本机文件</li>
<li>加载配置项到本机内存中</li>
<li>如果没有建立连接，直接使用本机备份预热到内存中</li>
<li>启动一个线程任务（一直运行）<ul>
<li>如果建立连接，client.receiveMessage()，从服务器端读信息，如果没有新消息，该方法会被阻塞</li>
<li>否则，休眠1秒</li>
</ul>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">connectServer</span><span class="params">(String host, <span class="keyword">int</span> port, <span class="keyword">final</span> String projCode, <span class="keyword">final</span> String profile)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> String clientMsg = <span class="string">"superdiamond,"</span> + projCode + <span class="string">","</span> + profile;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            client = <span class="keyword">new</span> Netty4Client(host, port, <span class="keyword">new</span> ClientChannelInitializer(), clientMsg);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (client.isConnected()) &#123;</span><br><span class="line">                client.sendMessage(clientMsg);</span><br><span class="line">                String message = client.receiveMessage();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (message != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    String versionStr = message.substring(<span class="number">0</span>, message.indexOf(<span class="string">"\r\n"</span>));</span><br><span class="line">                    LOGGER.info(<span class="string">"加载远程配置信息，项目编码：&#123;&#125;，Profile：&#123;&#125;, Version：&#123;&#125;"</span>, projCode, profile,</span><br><span class="line">                        versionStr.split(<span class="string">" = "</span>)[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">                    FileUtils.saveData(projCode, profile, message);</span><br><span class="line">                    load(<span class="keyword">new</span> StringReader(message), <span class="keyword">false</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                String message = FileUtils.readConfigFromLocal(projCode, profile);</span><br><span class="line">                <span class="keyword">if</span> (message != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    String versionStr = message.substring(<span class="number">0</span>, message.indexOf(<span class="string">"\r\n"</span>));</span><br><span class="line">                    LOGGER.info(<span class="string">"加载本地备份配置信息，项目编码：&#123;&#125;，Profile：&#123;&#125;, Version：&#123;&#125;"</span>, projCode, profile,</span><br><span class="line">                        versionStr.split(<span class="string">" = "</span>)[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">                    load(<span class="keyword">new</span> StringReader(message), <span class="keyword">false</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span></span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> ConfigurationRuntimeException(</span><br><span class="line">                        <span class="string">"本地没有备份配置数据，PropertiesConfiguration 初始化失败。"</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            reloadExecutorService.submit(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="keyword">private</span> <span class="keyword">final</span> String projCodeString = projCode;</span><br><span class="line">                <span class="keyword">private</span> <span class="keyword">final</span> String profileString = profile;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">while</span>(reloadable) &#123;</span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            <span class="keyword">if</span>(client.isConnected()) &#123;</span><br><span class="line">                                String message = client.receiveMessage();</span><br><span class="line">                                <span class="keyword">if</span>(message != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                    String versionStr = message.substring(<span class="number">0</span>, message.indexOf(<span class="string">"\r\n"</span>));</span><br><span class="line">                                    LOGGER.info(<span class="string">"==================== 重新加载配置信息，项目编码：&#123;&#125;，Profile：&#123;&#125;, Version：&#123;&#125;"</span>, projCodeString, profileString, versionStr.split(<span class="string">" = "</span>)[<span class="number">1</span>]);</span><br><span class="line">                                    FileUtils.saveData(projCodeString, profileString, message);</span><br><span class="line">                                    load(<span class="keyword">new</span> StringReader(message), <span class="keyword">true</span>);</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                TimeUnit.SECONDS.sleep(<span class="number">1</span>);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (client != <span class="keyword">null</span>) &#123;</span><br><span class="line">                client.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ConfigurationRuntimeException(e.getMessage(), e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>3.初始化Netty4Client对象，内部主要是做心跳检测，保证Connection有效</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Netty4Client</span><span class="params">(String host, <span class="keyword">int</span> port, ClientChannelInitializer channelInitializer, String reconnectMsg)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    	<span class="keyword">this</span>.host = host;</span><br><span class="line">		<span class="keyword">this</span>.port = port;</span><br><span class="line">		<span class="keyword">this</span>.channelInitializer = channelInitializer;</span><br><span class="line">		<span class="keyword">this</span>.reconnectMsg = reconnectMsg;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">            doOpen();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            close();</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"Failed to start "</span> + getClass().getSimpleName() + <span class="string">" "</span> + NetUtils.getLocalAddress() </span><br><span class="line">                                        + <span class="string">" connect to the server "</span> + host + <span class="string">", cause: "</span> + t.getMessage(), t);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            connect();</span><br><span class="line">                </span><br><span class="line">            logger.info(<span class="string">"Start "</span> + getClass().getSimpleName() + <span class="string">" "</span> + NetUtils.getLocalAddress() + <span class="string">" connect to the server "</span> + host);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t)&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"Failed to start "</span> + getClass().getSimpleName() + <span class="string">" "</span> + NetUtils.getLocalAddress() </span><br><span class="line">                    + <span class="string">" connect to the server "</span> + host + <span class="string">", cause: "</span> + t.getMessage(), t);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>实例化 io.netty.bootstrap.Bootstrap对象</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doOpen</span><span class="params">()</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">  	bootstrap = <span class="keyword">new</span> Bootstrap();</span><br><span class="line">  	</span><br><span class="line">  	bootstrap.option(ChannelOption.SO_KEEPALIVE, <span class="keyword">true</span>);</span><br><span class="line">  	bootstrap.option(ChannelOption.TCP_NODELAY, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">  	bootstrap.group(group)</span><br><span class="line">   	.channel(NioSocketChannel<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">   	.<span class="title">handler</span>(<span class="title">channelInitializer</span>)</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="connect内部做的事情"><a href="#connect内部做的事情" class="headerlink" title="connect内部做的事情"></a>connect内部做的事情</h3><ul>
<li>创建Runnable线程任务，职责往服务端发请求，由 ScheduledThreadPoolExecutor控制，每10秒发一次请求。心跳检测，保证Connection有效</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private synchronized void initConnectStatusCheckCommand()&#123;</span><br><span class="line">        if(reconnectExecutorFuture &#x3D;&#x3D; null || reconnectExecutorFuture.isCancelled())&#123;</span><br><span class="line">            Runnable connectStatusCheckCommand &#x3D;  new Runnable() &#123;</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        if (! isConnected()) &#123;</span><br><span class="line">                            connect();</span><br><span class="line">                            if(isConnected()) &#123;</span><br><span class="line">	                            if(reconnectMsg !&#x3D; null) &#123;</span><br><span class="line">	                            	sendMessage(reconnectMsg);</span><br><span class="line">	                            &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; else &#123;</span><br><span class="line">                            lastConnectedTime &#x3D; System.currentTimeMillis();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; catch (Throwable t) &#123; </span><br><span class="line">                        String errorMsg &#x3D; &quot;client reconnect to &quot;+getRemoteAddress()+&quot; find error . &quot;;</span><br><span class="line">                        if (System.currentTimeMillis() - lastConnectedTime &gt; shutdown_timeout)&#123;</span><br><span class="line">                            if (!reconnect_error_log_flag.get())&#123;</span><br><span class="line">                                reconnect_error_log_flag.set(true);</span><br><span class="line">                                logger.error(errorMsg, t);</span><br><span class="line">                                return ;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                        if ( reconnect_count.getAndIncrement() % reconnect_warning_period &#x3D;&#x3D; 0)&#123;</span><br><span class="line">                            logger.warn(errorMsg, t);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">            reconnectExecutorFuture &#x3D; reconnectExecutorService.scheduleWithFixedDelay(connectStatusCheckCommand, 2 * 1000, 10 * 1000, TimeUnit.MILLISECONDS);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>如果Channel还没有建立，先建立连接</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doConnect</span><span class="params">()</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">        future = bootstrap.connect(getConnectAddress());</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="keyword">boolean</span> ret = future.awaitUninterruptibly(getConnectTimeout(), TimeUnit.MILLISECONDS);</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> (ret &amp;&amp; future.isSuccess()) &#123;</span><br><span class="line">                Channel newChannel = future.sync().channel();</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 关闭旧的连接</span></span><br><span class="line">                    Channel oldChannel = Netty4Client.<span class="keyword">this</span>.channel;</span><br><span class="line">                    <span class="keyword">if</span> (oldChannel != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        logger.info(<span class="string">"Close old netty channel "</span> + oldChannel + <span class="string">" on create new netty channel "</span> + newChannel);</span><br><span class="line">                        oldChannel.close();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                	Netty4Client.<span class="keyword">this</span>.channel = newChannel;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (future.cause() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"client failed to connect to server "</span></span><br><span class="line">                        + getRemoteAddress() + <span class="string">", error message is:"</span> + future.cause().getMessage(), future.cause());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"client failed to connect to server "</span></span><br><span class="line">                        + getRemoteAddress() + <span class="string">" client-side timeout "</span></span><br><span class="line">                        + getConnectTimeout() + <span class="string">"ms (elapsed: "</span> + (System.currentTimeMillis() - start) + <span class="string">"ms) from netty client "</span></span><br><span class="line">                        + NetUtils.getLocalHost());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (! isConnected()) &#123;</span><br><span class="line">                future.cancel(<span class="keyword">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>


<h2 id="二、服务端部分"><a href="#二、服务端部分" class="headerlink" title="二、服务端部分"></a>二、服务端部分</h2>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>常用软件工具</title>
    <url>/java-other/tool/</url>
    <content><![CDATA[<h2 id="常用软件工具"><a href="#常用软件工具" class="headerlink" title="常用软件工具"></a>常用软件工具</h2><hr>
<a id="more"></a>
<ul>
<li><a href="http://www.pc6.com/mac/152875.html" target="_blank" rel="noopener">类反编译 — JD-GUI</a></li>
<li><a href="http://blog.vetcafe.net/2013/12/charlesproxyiphonehttps.html" target="_blank" rel="noopener">HTTPS 抓包工具—–charles</a></li>
<li><a href="swagger.md">自动生成Restful api接口规范文档—–swagger</a></li>
<li><a href="https://www.getpostman.com/apps" target="_blank" rel="noopener">模拟构造HTTP请求—–postman</a></li>
<li><a href="http://www.xmindchina.net/" target="_blank" rel="noopener">头脑风暴软件—–xmind</a></li>
<li><a href="http://www.chinapyg.com/forum.php?mod=viewthread&tid=79022&page=1" target="_blank" rel="noopener">统一建模语言画图——StarUML</a></li>
<li><a href="">服务器界面式管理终端——-secureCRT</a></li>
<li><a href="intellij.md">编码工具——-intellij idea</a></li>
<li><a href="https://www.axure.com.cn/" target="_blank" rel="noopener">原型设计工具——-Axure</a></li>
<li><a href="">亿图——-EdrawMax</a></li>
<li><a href="https://www.jianshu.com/p/421cc442f06c" target="_blank" rel="noopener">gitbook</a></li>
</ul>
<p>mac系统</p>
<ul>
<li><a href="http://www.jianshu.com/p/d229ac7fe77d" target="_blank" rel="noopener">Homebrew安装</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/19556676" target="_blank" rel="noopener">终极 Shell——ZSH</a></li>
<li><a href="https://blog.csdn.net/a19891024/article/details/53869574" target="_blank" rel="noopener">Mac下切换zsh和bash</a></li>
<li><a href="https://www.cnblogs.com/xishuai/p/mac-iterm2.html" target="_blank" rel="noopener">终端利器 —- iTerm2</a></li>
<li><a href="zoc.md">远程服务器文件下载工具 — ZOC</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>个人成长与职业规划</title>
    <url>/java-other/person/</url>
    <content><![CDATA[<h1 id="成长历程"><a href="#成长历程" class="headerlink" title="成长历程"></a>成长历程</h1><a id="more"></a>
<ul>
<li>早期阶段，技术人员，要拓展自己的技术宽度。以自己工作的项目为中心，涉及的方方面面的技术都要有所了解。另外要具有工程化的能力，让自己具备开发商业软件的能力。</li>
<li>根据自己的兴趣，加强在某一领域的技术深度。选择：偏业务方向还是偏基础技术方向<ul>
<li>偏业务方向<ul>
<li>对业务发展的未来有一定的预判，有商业的敏感意识</li>
<li>复杂的业务能合理的抽象</li>
<li>系统的设计上能对未来业务的变化有一定的预留处理</li>
</ul>
</li>
<li>偏基础方向<ul>
<li>对基础技术的方向有一定的预判，避免业务发展受到基础技术的拖累</li>
<li>对业界的技术发展方向有自己的认知和判断</li>
<li>对应的基础技术领域有不错的技术深度</li>
</ul>
</li>
</ul>
</li>
<li>团队TL<ul>
<li>重要的能力是在方向的判断上</li>
<li>根据方向的判断来组织建设（团队搭建、人才识别、培养、招聘等）</li>
</ul>
</li>
<li>架构师<ul>
<li>无论是业务架构还是基础方向的架构，领域的知识宽度是非常重要的。这意味着能做多大范围的事。一个好的架构师在技术风险的控制能力要非常强。</li>
</ul>
</li>
</ul>
<h1 id="技术提升（高P）"><a href="#技术提升（高P）" class="headerlink" title="技术提升（高P）"></a>技术提升（高P）</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/trcK2J_a8h3C4fqPaKSc6g" target="_blank" rel="noopener">程序员不能错过的28份技术知识图谱，你的进阶路上必备</a></li>
<li><a href="http://mp.weixin.qq.com/s/Ck71qeyACk0Zn5j3ro87YQ" target="_blank" rel="noopener">8年开发经验，网易Java开发工程师的成长感悟</a></li>
<li><a href="http://mp.weixin.qq.com/s/SayDuFnWFIRaKgVfd3Km7g" target="_blank" rel="noopener">张一鸣：我遇到的优秀年轻人的5个特质</a></li>
<li><a href="http://mp.weixin.qq.com/s/FdmwguWsn28IutA8V70YbA" target="_blank" rel="noopener">培养这些软技能，可以有效提升程序员的幸福感</a></li>
<li><a href="https://mp.weixin.qq.com/s/4UCZkOetWFrFRHZcAP0fQg" target="_blank" rel="noopener">阿里人的进阶宝典：都是知识点</a></li>
<li><a href="https://mp.weixin.qq.com/s/Q7SDi-ZLA7p-mMp4Xz1L8w" target="_blank" rel="noopener">技术团队里什么样的人会被清除？抢老板的工作干合适吗？</a></li>
<li><a href="person-1.md">互联网时代架构师的职责与思考</a></li>
<li><a href="https://mp.weixin.qq.com/s/xD7hofy2vhmjvEMp3Ip9GQ" target="_blank" rel="noopener">免试晋升为研究员，他在阿里十年经历了什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s/TtOhnf7OcEwMOL5wc3DWqw" target="_blank" rel="noopener">职场“35岁危机”：这是我看过的最棒建议</a></li>
<li><a href="https://mp.weixin.qq.com/s/k6QeIzq3uL1pmmdnQB2AFg" target="_blank" rel="noopener">论三年内快速成长为一名技术专家</a></li>
<li><a href="https://mp.weixin.qq.com/s/a3X1J-TkJ3ThTdc0YCyIKw" target="_blank" rel="noopener">快速成长为一名技术专家</a></li>
<li><a href="https://mp.weixin.qq.com/s/zMneLwJkhJ0jA96cIzxLKw" target="_blank" rel="noopener">美丽联合集团VP顶天：总结这一年，我们在技术上的变与不变</a></li>
<li><a href="https://mp.weixin.qq.com/s/PJeCdbpILQiOc9gpQEQ9rA" target="_blank" rel="noopener">架构经验老司机的技术选型哲学</a></li>
<li><a href="https://mp.weixin.qq.com/s/CCYJ4TmAM5ht_DSZMWB5ow" target="_blank" rel="noopener">一个NB架构师的必备素质</a></li>
<li><a href="https://mp.weixin.qq.com/s/6ePpYgwm8t1EY2PtFOX5rg" target="_blank" rel="noopener">你写的代码，是别人的噩梦吗？</a></li>
<li><a href="http://mp.weixin.qq.com/s/tc3hWHPw2JvqdnhXnWEGbQ" target="_blank" rel="noopener">论架构师的自我修养</a></li>
<li><a href="https://mp.weixin.qq.com/s/N00rWLkkLjV7zQnzxBVKaA" target="_blank" rel="noopener">佛系程序员的月薪五万指南</a></li>
</ul>
<hr>
<h1 id="技术（P）-–-gt-管理（M）"><a href="#技术（P）-–-gt-管理（M）" class="headerlink" title="技术（P） –&gt; 管理（M）"></a>技术（P） –&gt; 管理（M）</h1><ul>
<li><a href="http://www.infoq.com/cn/news/2015/08/developer-to-manager" target="_blank" rel="noopener">从开发人员到管理者，我学到了什么</a></li>
<li><a href="http://mp.weixin.qq.com/s/FWrhT2jl1TUq80d8gNinww" target="_blank" rel="noopener">从纯技术到技术管理，那些跌宕起伏的转型经历</a></li>
<li><a href="http://mp.weixin.qq.com/s/tyTrBg9vk5Ft16oWEb4-bA" target="_blank" rel="noopener">从普通程序员到三百人团队CTO，技术人成长的易与不易</a></li>
<li><a href="https://mp.weixin.qq.com/s/lmO4WD7axWqm5DhlFuagzg" target="_blank" rel="noopener">这二十个问题，可能是你技术人生中已经或即将遭遇的痛点，怎么解？</a></li>
<li><a href="https://mp.weixin.qq.com/s/T06ycmFiIoEOMP7xgreMoQ" target="_blank" rel="noopener">当我们在谈组织效率的时候，我们在谈什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s/v2kIPwjeYWY3JoPzBwQWrg" target="_blank" rel="noopener">技术专家 or 技术管理？程序员职场规划中如何定位？</a></li>
<li><a href="https://mp.weixin.qq.com/s/HLJ84XqmH_EzjRqni-3I9w" target="_blank" rel="noopener">CTO不得不面对的9大困境</a></li>
<li><a href="https://mp.weixin.qq.com/s/xxwgs7wJR1O213VJsBammw" target="_blank" rel="noopener">从大公司到创业公司，技术人转型怎样转变思路与处事之道？</a></li>
<li><a href="https://mp.weixin.qq.com/s/C_p1hVzVwGEyj8udrgsjBw" target="_blank" rel="noopener">从来往到钉钉，从技术Leader到产品负责人，陶钧到底经历了什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s/LsLH1N6cFTpV_TyIqUqAvA" target="_blank" rel="noopener">如何成为一个合格的技术Leader？</a></li>
<li><a href="https://mp.weixin.qq.com/s/A2v0gGIl09X6Bwz9L060aw" target="_blank" rel="noopener">技术人员的发展之路</a></li>
<li><a href="https://mp.weixin.qq.com/s/Yx1fXO9RfnLeBGZg_P-g3g" target="_blank" rel="noopener">从技术 Leader 到产品负责人</a></li>
<li><a href="https://mp.weixin.qq.com/s/EHh4D22LG-BoksppsZZ2Tg" target="_blank" rel="noopener">蘑菇街顶天：真诚与尊重是技术团队的管理要点</a></li>
<li><a href="https://mp.weixin.qq.com/s/lkDiaEbFKAGcxeq8WLF3hg" target="_blank" rel="noopener">年轻技术管理者的涅槃重生之路</a></li>
<li><a href="https://mp.weixin.qq.com/s/Xq4zjEzaRGGOjghUHxLYFw" target="_blank" rel="noopener">想从技术转管理？这些坑你可要注意了！</a></li>
<li><a href="https://mp.weixin.qq.com/s/LZ5mUUv1jnb1TAvpQs_F3Q" target="_blank" rel="noopener">双面管理者：雷霆手段，菩萨心肠</a></li>
<li><a href="https://mp.weixin.qq.com/s/rSbFfzVT10OLwJy0QOaGpQ" target="_blank" rel="noopener">作为部门领导，自己天天撸代码忙成狗，下属却没事干，怎么办？</a></li>
<li><a href="https://mp.weixin.qq.com/s/LtrgO4aY5w9ykMfW61czzg" target="_blank" rel="noopener">好不容易当上技术管理者，却时常担心被下属diss技术水平，怎么办？</a></li>
</ul>
<hr>
<h1 id="软能力"><a href="#软能力" class="headerlink" title="软能力"></a>软能力</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/ejD1susXEn8uncmAusPW2w" target="_blank" rel="noopener">工作10年才懂的道理，早知道职位比现在高两级</a></li>
<li><a href="https://mp.weixin.qq.com/s/TPViDjviDPuitjyaTf9I3g" target="_blank" rel="noopener">程序员怎样快速成长？</a></li>
<li><a href="https://mp.weixin.qq.com/s/h-32WUi1far1WAchf-X_PQ" target="_blank" rel="noopener">阿里P9技术专家：程序员的技术实力是什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s/3obF9ltx_l28ZFU1z3jcCw" target="_blank" rel="noopener">成为一名优秀架构师有标准吗？这12点或许能带给你一些启发</a></li>
<li><a href="https://mp.weixin.qq.com/s/jv_56Y91gkZ6z_reF8nchA" target="_blank" rel="noopener">想要成为一个合格的架构师</a></li>
<li><a href="https://mp.weixin.qq.com/s/HpevoT6g5UXP4PaL0NUvGw" target="_blank" rel="noopener">架构师不写代码，能行吗？</a></li>
</ul>
<hr>
<h1 id="团队"><a href="#团队" class="headerlink" title="团队"></a>团队</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/WIWclRDVTcpUICwSS7lpIg" target="_blank" rel="noopener">技术牛人告诉你，什么才是真正的工程师文化？</a></li>
<li><a href="https://mp.weixin.qq.com/s/lYqPNQ2ngfiQlEBVNnwXhA" target="_blank" rel="noopener">最出色的员工往往最先离职，原因却不是因为钱</a></li>
<li><a href="https://mp.weixin.qq.com/s/gKbMkreF50w0u5m4BuFjZA" target="_blank" rel="noopener">如果你是技术leader，团队成员不停向你抱怨时你会怎么做？</a></li>
<li><a href="https://mp.weixin.qq.com/s/pRlzJQ4SEmkKPBX52EmZLA" target="_blank" rel="noopener">张雪峰：创业团队极速发展过程中的分分合合</a></li>
<li>沟通<ul>
<li><a href="https://mp.weixin.qq.com/s/waTzuYQFOQmkC33AO3sywQ" target="_blank" rel="noopener">带团队，强势真是好事么？</a></li>
<li><a href="https://mp.weixin.qq.com/s/Fio662OSxpCgaCxQKNEICA" target="_blank" rel="noopener">带团队，要不要言传身教？</a></li>
<li><a href="https://mp.weixin.qq.com/s/k0j8LkV7XVZflYIXJm5zYg" target="_blank" rel="noopener">带团队，不要轻易放弃任何一个队友</a></li>
<li><a href="https://mp.weixin.qq.com/s/l8P1JfNtFVBA9MDOlfsdFA" target="_blank" rel="noopener">这些年，leader教我的那些事</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="HR技能"><a href="#HR技能" class="headerlink" title="HR技能"></a>HR技能</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/FqYlDf0mz3-AOgkjT3ittg" target="_blank" rel="noopener">从管人到管人才，一个年薪80w的HRBP到底是什么样？</a></li>
<li><a href="http://www.360doc.com/content/17/0705/12/35463569_669039203.shtml" target="_blank" rel="noopener">阿里Job model</a></li>
</ul>
<hr>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/7OL6rO2D9hIJ68uPEBco3Q" target="_blank" rel="noopener">创业大神马斯克和蔡文胜都用过的第一性原理，到底是啥东东？</a></li>
<li><a href="http://mp.weixin.qq.com/s/UZx3HYA6JdQYBxfS8wbfLA" target="_blank" rel="noopener">8年创业反思：技术人应该如何选择创业项目？</a></li>
<li><a href="https://mp.weixin.qq.com/s/L-bLtzThdBj_M2iBvXGlRg" target="_blank" rel="noopener">给我五分钟，带你走出迷茫！</a></li>
<li><a href="https://mp.weixin.qq.com/s/ShqzvXI6L28Lxw5X61IfiA" target="_blank" rel="noopener">思维的局限</a></li>
<li><a href="https://mp.weixin.qq.com/s/Az9y8HzdpGOOfR4JWcIVkA" target="_blank" rel="noopener">7 年老员工的 6 点离职忠告：浮躁的年轻人请你读完</a></li>
<li><a href="https://mp.weixin.qq.com/s/42wmdg0VqcYWSgNP9iIGpg" target="_blank" rel="noopener">阿里前资深副总裁邓康明：BAT之后，人与组织的未来</a></li>
<li><a href="https://mp.weixin.qq.com/s/n5BkGFOFtS2tMcKMqi5psw" target="_blank" rel="noopener">一名7年总监的6点离职忠告</a></li>
<li><a href="https://mp.weixin.qq.com/s/ZcxxugWNpzL_WHT8GfVGZQ" target="_blank" rel="noopener">程序员增加收入实用指南</a></li>
<li><a href="https://mp.weixin.qq.com/s/BnkmICaK2duAu6URlNuKLg" target="_blank" rel="noopener">程序员必看—程序员如何高效提升自己？</a></li>
</ul>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>zoc</title>
    <url>/java-other/zoc/</url>
    <content><![CDATA[<ul>
<li><a href="https://blog.csdn.net/bai_ye_88/article/details/78593333" target="_blank" rel="noopener">macbook使用ZOC连接Linux云主机</a></li>
<li><a href="http://mac.orsoon.com/Mac/155483.html" target="_blank" rel="noopener">下载</a></li>
<li><a href="https://blog.csdn.net/czhenjie/article/details/74637168" target="_blank" rel="noopener">Mac下通过iterm2使用rz、sz上传下载文件</a></li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>一致性hash算法</title>
    <url>/java-other/%E4%B8%80%E8%87%B4%E6%80%A7hash/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>一致性hash在缓存方面用的比较多，一般用来寻找路由节点，避免节点扩容导致的大面积数据原节点失效。</p>
<p>1.构造节点，循环，每一个cache节点会将Long类型数字拆成160份。</p>
<a id="more"></a>
<p>TreeMap的大小=节点数*160</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">nodes = <span class="keyword">new</span> TreeMap&lt;Long, Node&gt;();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i != shards.size(); ++i) &#123;</span><br><span class="line">	<span class="keyword">final</span> Node shardInfo = shards.get(i);</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> n = <span class="number">0</span>; n &lt; <span class="number">160</span> ; n++) &#123;</span><br><span class="line">		nodes.put(MurmurHash.hash(<span class="string">"SHARD-"</span> + i + <span class="string">"-NODE-"</span> + n), shardInfo);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MurmurHash算法：高运算性能，低碰撞率，由Austin Appleby创建于2008年，现已应用到Hadoop、libstdc++、nginx、libmemcached等开源系统。2011年Appleby被Google雇佣，随后Google推出其变种的CityHash算法。 </p>
<p>官方网站：<a href="https://sites.google.com/site/murmurhash/" target="_blank" rel="noopener">https://sites.google.com/site/murmurhash/</a> </p>
<p>MurmurHash算法，自称超级快的hash算法，是FNV的4-5倍。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">hash64A</span><span class="params">(ByteBuffer buf, <span class="keyword">int</span> seed)</span> </span>&#123;</span><br><span class="line">	ByteOrder byteOrder = buf.order();</span><br><span class="line">	buf.order(ByteOrder.LITTLE_ENDIAN);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">long</span> m = <span class="number">0xc6a4a7935bd1e995L</span>;</span><br><span class="line">	<span class="keyword">int</span> r = <span class="number">47</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">long</span> h = seed ^ (buf.remaining() * m);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">long</span> k;</span><br><span class="line">	<span class="keyword">while</span> (buf.remaining() &gt;= <span class="number">8</span>) &#123;</span><br><span class="line">		k = buf.getLong();</span><br><span class="line"></span><br><span class="line">		k *= m;</span><br><span class="line">		k ^= k &gt;&gt;&gt; r;</span><br><span class="line">		k *= m;</span><br><span class="line"></span><br><span class="line">		h ^= k;</span><br><span class="line">		h *= m;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (buf.remaining() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">		ByteBuffer finish = ByteBuffer.allocate(<span class="number">8</span>).order(ByteOrder.LITTLE_ENDIAN);</span><br><span class="line">		<span class="comment">// for big-endian version, do this first:</span></span><br><span class="line">		<span class="comment">// finish.position(8-buf.remaining());</span></span><br><span class="line">		finish.put(buf).rewind();</span><br><span class="line">		h ^= finish.getLong();</span><br><span class="line">		h *= m;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	h ^= h &gt;&gt;&gt; r;</span><br><span class="line">	h *= m;</span><br><span class="line">	h ^= h &gt;&gt;&gt; r;</span><br><span class="line"></span><br><span class="line">	buf.order(byteOrder);</span><br><span class="line">	<span class="keyword">return</span> h;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>初始化的TreeMap的内容：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/java/java-other/20160613_8.png/w600">

<p>2.根据缓存key找具体的数据节点</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Node <span class="title">getNodeByKey</span><span class="params">(<span class="keyword">byte</span>[] key)</span> </span>&#123;</span><br><span class="line">		<span class="comment">//取大于或等于hash key的列表</span></span><br><span class="line">		SortedMap&lt;Long, Node&gt; tail = nodes.tailMap(MurmurHash.hash(key));</span><br><span class="line">		<span class="keyword">if</span> (tail.isEmpty())</span><br><span class="line">			<span class="keyword">return</span> nodes.get(nodes.firstKey());</span><br><span class="line">		<span class="keyword">return</span> tail.get(tail.firstKey());</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>五种开源协议(GPL,LGPL,BSD,MIT,Apache)</title>
    <url>/java-other/%E4%BA%94%E7%A7%8D%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<h1 id="什么是许可协议？"><a href="#什么是许可协议？" class="headerlink" title="什么是许可协议？"></a>什么是许可协议？</h1><p>什么是许可，当你为你的产品签发许可，你是在出让自己的权利，不过，你仍然拥有版权和专利（如果申请了的话），许可的目的是，向使用你产品的人提供 一定的权限。</p>
<a id="more"></a>

<p>不管产品是免费向公众分发，还是出售，制定一份许可协议非常有用，否则，对于前者，你相当于放弃了自己所有的权利，任何人都没有义务表明你的原始作者身份，对于后者，你将不得不花费比开发更多的精力用来逐个处理用户的授权问题。</p>
<p>而开源许可协议使这些事情变得简单，开发者很容易向一个项目贡献自己的代码，它还可以保护你原始作者的身份，使你 至少获得认可，开源许可协议还可以阻止其它人将某个产品据为己有。以下是开源界的 5 大许可协议。</p>
<h1 id="GNU-GPL"><a href="#GNU-GPL" class="headerlink" title="GNU GPL"></a>GNU GPL</h1><p>GNU General Public Licence (GPL) 有可能是开源界最常用的许可模式。GPL 保证了所有开发者的权利，同时为使用者提供了足够的复制，分发，修改的权利：</p>
<ul>
<li>可自由复制<br>你可以将软件复制到你的电脑，你客户的电脑，或者任何地方。复制份数没有任何限制。</li>
<li>可自由分发<br>在你的网站提供下载，拷贝到U盘送人，或者将源代码打印出来从窗户扔出去（环保起见，请别这样做）。</li>
<li>可以用来盈利<br>你可以在分发软件的时候收费，但你必须在收费前向你的客户提供该软件的 GNU GPL 许可协议，以便让他们知道，他们可以从别的渠道免费得到这份软件，以及你收费的理由。</li>
<li>可自由修改<br>如果你想添加或删除某个功能，没问题，如果你想在别的项目中使用部分代码，也没问题，唯一的要求是，使用了这段代码的项目也必须使用 GPL 协议。</li>
</ul>
<p>需要注意的是，分发的时候，需要明确提供源代码和二进制文件，另外，用于某些程序的某些协议有一些问题和限制，你可以看一下 @PierreJoye 写的 Practical Guide to GPL Compliance 一文。使用 GPL 协议，你必须在源代码代码中包含相应信息，以及协议本身。</p>
<h1 id="GNU-LGPL"><a href="#GNU-LGPL" class="headerlink" title="GNU LGPL"></a>GNU LGPL</h1><p>GNU 还有另外一种协议，叫做 LGPL （Lesser General Public Licence），它对产品所保留的权利比 GPL 少，总的来说，LGPL 适合那些用于非 GPL 或非开源产品的开源类库或框架。因为 GPL 要求，使用了 GPL 代码的产品必须也使用 GPL 协议，开发者不允许将 GPL 代码用于商业产品。LGPL 绕过了这一限制。</p>
<h1 id="BSD"><a href="#BSD" class="headerlink" title="BSD"></a>BSD</h1><p>BSD 在软件分发方面的限制比别的开源协议（如 GNU GPL）要少。该协议有多种版本，最主要的版本有两个，新 BSD 协议与简单 BSD 协议，这两种协议经过修正，都和 GPL 兼容，并为开源组织所认可。</p>
<p>新 BSD 协议（3条款协议）在软件分发方面，除需要包含一份版权提示和免责声明之外，没有任何限制。另外，该协议还禁止拿开发者的名义为衍生产品背书，但简单 BSD 协议删除了这一条款。</p>
<h1 id="MIT"><a href="#MIT" class="headerlink" title="MIT"></a>MIT</h1><p>MIT 协议可能是几大开源协议中最宽松的一个，核心条款是：</p>
<p>该软件及其相关文档对所有人免费，可以任意处置，包括使用，复制，修改，合并，发表，分发，再授权，或者销售。唯一的限制是，软件中必须包含上述版权和许可提示。</p>
<p>这意味着：</p>
<ul>
<li>你可以自由使用，复制，修改，可以用于自己的项目。</li>
<li>可以免费分发或用来盈利。</li>
<li>唯一的限制是必须包含许可声明。</li>
</ul>
<p>MIT 协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制。</p>
<h1 id="Apache"><a href="#Apache" class="headerlink" title="Apache"></a>Apache</h1><p>Apache 协议 2.0 和别的开源协议相比，除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合（这里有 一篇文章阐述这个问题）。</p>
<p>Apache 协议还有以下需要说明的地方:</p>
<ul>
<li>永久权利<br>一旦被授权，永久拥有。</li>
<li>全球范围的权利<br>在一个国家获得授权，适用于所有国家。假如你在美国，许可是从印度授权的，也没有问题。</li>
<li>授权免费，且无版税<br>前期，后期均无任何费用。</li>
<li>授权无排他性<br>任何人都可以获得授权</li>
<li>授权不可撤消<br>一旦获得授权，没有任何人可以取消。比如，你基于该产品代码开发了衍生产品，你不用担心会在某一天被禁止使用该代码。</li>
</ul>
<p>分发代码方面包含一些要求，主要是，要在声明中对参与开发的人给予认可并包含一份许可协议原文。</p>
<h1 id="Creative-Commons"><a href="#Creative-Commons" class="headerlink" title="Creative Commons"></a>Creative Commons</h1><p>Creative Commons (CC) 并非严格意义上的开源许可，它主要用于设计。Creative Commons 有多种协议，每种都提供了相应授权模式，CC 协议主要包含 4 种基本形式：</p>
<ul>
<li>署名权<br>必须为原始作者署名，然后才可以修改，分发，复制。</li>
<li>保持一致<br>作品同样可以在 CC 协议基础上修改，分发，复制。</li>
<li>非商业<br>作品可以被修改，分发，复制，但不能用于商业用途。但商业的定义有些模糊，比如，有的人认为非商业用途指的是不能销售，有的认为是甚至不能放在有广告的网站，也有人认为非商业的意思是非盈利。</li>
<li>不能衍生新作品<br>你可以复制，分发，但不能修改，也不能以此为基础创作自己的作品。</li>
</ul>
<p>这些许可形式可以结合起来用，其中最严厉的组合是“署名，非商用，不能衍生新作品”，意味着，你可以分享作品，但不能改动或以此盈利，而且必须为原作者署名。在这种许可模式下，原始作者对作品还拥有完全的控制权，而最宽松的组合是“署名”，意味着，只要为原始作者署名了，就可以自由处置。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>回车与换行的区别</title>
    <url>/java-other/%E5%9B%9E%E8%BD%A6%E4%B8%8E%E6%8D%A2%E8%A1%8C%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>在计算机还没有出现之前，有一种叫做电传打字机（Teletype Model 33）的玩意，每秒钟可以打10个字符。但是它有一个问题，就是打完一行换行的时候，要用去0.2秒，正好可以打两个字符。要是在这0.2秒里面，又有新的字符传过来，那么这个字符将丢失。</p>
<a id="more"></a>

<p>于是，研制人员想了个办法解决这个问题，就是在每行后面加两个表示结束的字符。一个叫做”回车”，告诉打字机把打印头定位在左边界；另一个叫做”换行”，告诉打字机把纸向下移一行。</p>
<p>这就是”换行”和”回车”的来历，从它们的英语名字上也可以看出一二。</p>
<p>后来，计算机发明了，这两个概念也就被般到了计算机上。那时，存储器很贵，一些科学家认为在每行结尾加两个字符太浪费了，加一个就可以。于是，就出现了分歧。</p>
<ul>
<li>Unix系统里，每行结尾只有”&lt;换行&gt;”，即”\n”；</li>
<li>Windows系统里面，每行结尾是”&lt;回车&gt;&lt;换行&gt;”，即”\r\n”；</li>
<li>Mac系统里，每行结尾是”&lt;回车&gt;”。</li>
</ul>
<p>一个直接后果是，Unix/Mac系统下的文件在Windows里打开的话，所有文字会变成一行；而Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>尽在双11——阿里巴巴技术演进与超越</title>
    <url>/java-other/%E5%B0%BD%E5%9C%A8%E5%8F%8C11%E2%80%94%E2%80%94%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E4%B8%8E%E8%B6%85%E8%B6%8A/</url>
    <content><![CDATA[<h1 id="第1章-阿里技术架构演进-1"><a href="#第1章-阿里技术架构演进-1" class="headerlink" title="第1章 阿里技术架构演进 1"></a>第1章 阿里技术架构演进 1</h1><p>双11是阿里技术发展的强大驱动力，双11业务的快速发展造就了阿里具备高度水平伸缩能力、低成本的电商架构体系。这个架构体系是如何一步一步形成的呢？在形成过程中阿里遇到了哪些问题，做了哪些尝试，最终用什么样的思路、方法和技术解决了问题？</p>
<ul>
<li>1.1 五彩石，电商架构新起点 3</li>
<li>1.2 异地多活，解除单地域部署限制的新型双11扩容方式 9</li>
<li>1.3混合云，利用阿里云弹性大幅降低双11成本 17</li>
<li>1.4 OceanBase，云时代的关系数据库 23</li>
<li>1.5 手机淘宝，移动互联网电商新时代 30</li>
<li>1.6 蚂蚁技术架构演进 36</li>
</ul>
<a id="more"></a>

<h1 id="第2章-稳定，双11的生命线-43"><a href="#第2章-稳定，双11的生命线-43" class="headerlink" title="第2章 稳定，双11的生命线 43"></a>第2章 稳定，双11的生命线 43</h1><p>双11最大的困难在于零点峰值的稳定性保障。面对这种世界级的场景、独一无二的挑战，阿里建设了大量高可用技术产品，形成了全链路一体化的解决方案，用更加逼真和自动化的方式，去评估、优化和保护整个技术链条，最大化地为用户提供稳定可靠的服务。</p>
<ul>
<li>2.1 容量规划，资源分配的指南针 45</li>
<li>2.2 全链路压测，大促备战的核武器 51</li>
<li>2.3 全链路功能，提前开始的狂欢盛宴 58</li>
<li>2.4 自动化备战，喝着咖啡搞大促 65</li>
<li>2.5 实时业务审计，从系统可用到业务正确 70</li>
<li>2.6 故障演练，系统健壮性的探测仪 75</li>
<li>2.7 系统自我保护，稳定性的最后一道屏障 82</li>
</ul>
<h1 id="第3章-技术拓展商业边界-89"><a href="#第3章-技术拓展商业边界-89" class="headerlink" title="第3章 技术拓展商业边界 89"></a>第3章 技术拓展商业边界 89</h1><p>双11业务驱动技术发展的同时，技术的创新与发展也不断推动着商业模式的升级与变革，实践着技术拓展商业的边界。</p>
<ul>
<li>3.1 招商报名，活动基础设施建设 91</li>
<li>3.2 会场，小二与商家共同打造的购物清单 99</li>
<li>3.3 搜索，大促场景下智能化演进之路 107</li>
<li>3.4 个性化推荐，大数据和智能时代的新航路 114</li>
<li>3.5 供应链，从飞速增长到精耕细作 120</li>
<li>3.6 蚂蚁花呗，无忧支付的完美体验 127</li>
</ul>
<h1 id="第4章-移动端的技术创新之路-133"><a href="#第4章-移动端的技术创新之路-133" class="headerlink" title="第4章 移动端的技术创新之路 133"></a>第4章 移动端的技术创新之路 133</h1><p>从2010年开始，国内爆发了从PC向移动端技术和业务的持续迁移，移动深刻地改变着人们的衣食住行和人际交往。阿里的双11始于2009年，正好经历了移动互联网崛起的全程，双11在移动端的主要创新有哪些呢？</p>
<ul>
<li>4.1 Weex，让双11更流畅 135</li>
<li>4.2 互动，让购物变成狂欢 143</li>
<li>4.3 VR&amp;AR，移动端创新体验 153</li>
<li>4.4 奥创&amp;TMF，让双11多端业务腾飞 163</li>
</ul>
<h1 id="第5章-繁荣生态，赋能商家-171"><a href="#第5章-繁荣生态，赋能商家-171" class="headerlink" title="第5章 繁荣生态，赋能商家 171"></a>第5章 繁荣生态，赋能商家 171</h1><p>双11从阿里内部员工的一个点子到全球购物狂欢节，其背后支撑是服务、物流、大数据、云计算、金融服务等，是商家自身业务结构的调整、消费者消费习惯的转变、第三方开发者的大量入驻，以及整个生态的变迁。</p>
<ul>
<li>5.1 聚石塔，开放的电商云工作台 173</li>
<li>5.2 菜鸟电子面单，大数据改变物流 179</li>
<li>5.3 生意参谋，数据赋能商家的“黑科技” 184</li>
<li>5.4 阿里小蜜，用智能重新定义服务 191</li>
<li>5.5 阿里中间件，让传统企业插上互联网的翅膀 198</li>
<li>5.6 蚂蚁金服，金融机构间协同运维的探索和实践 205</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(一)——定义及技术要点</title>
    <url>/cn/cn%E5%AE%9A%E4%B9%89%E5%8F%8A%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9/</url>
    <content><![CDATA[<p>本章要点</p>
<div class="note primary">
            <p>*云原生技术发展历程（为什么要学习）<br>*云原生的定义与技术要点（本节正式内容）</p>
          </div>


<a id="more"></a>
<h1 id="一、为什么要学习云原生技术？"><a href="#一、为什么要学习云原生技术？" class="headerlink" title="一、为什么要学习云原生技术？"></a>一、为什么要学习云原生技术？</h1><h2 id="云原生技术发展简史"><a href="#云原生技术发展简史" class="headerlink" title="云原生技术发展简史"></a>云原生技术发展简史</h2><p>首先从第一个问题进行分享，那就是“为什么要学习云原生技术？”云原生、CNCF 都是目前非常热门的关键词，但是这些技术并不是非常新鲜的内容。</p>
<ul>
<li>2004 年— 2007 年，Google 已在内部大规模地使用像 Cgroups 这样的容器技术；</li>
<li>2008 年，Google 将 Cgroups 合并进入了 Linux 内核主干；</li>
<li>2013 年，Docker 项目正式发布。</li>
<li>2014 年，Kubernetes 项目也正式发布。这样的原因也非常容易理解，因为有了容器和 Docker 之后，就需要有一种方式去帮助大家方便、快速、优雅地管理这些容器，这就是 Kubernetes 项目的初衷。在 Google 和 Redhat 发布了 Kubernetes 之后，这个项目的发展速度非常之快。</li>
<li>2015 年，由Google、Redhat 以及微软等大型云计算厂商以及一些开源公司共同牵头成立了 CNCF 云原生基金会。CNCF 成立之初，就有 22 个创始会员，而且 Kubernetes 也成为了 CNCF 托管的第一个开源项目。在这之后，CNCF 的发展速度非常迅猛；</li>
<li>2017 年，CNCF 达到 170 个成员和 14 个基金项目；</li>
<li>2018 年，CNCF 成立三周年有了 195 个成员，19 个基金会项目和 11 个孵化项目，如此之快的发展速度在整个云计算领域都是非常罕见的。</li>
</ul>
<h2 id="云原生技术生态现状"><a href="#云原生技术生态现状" class="headerlink" title="云原生技术生态现状"></a>云原生技术生态现状</h2><p>因此，如今我们所讨论的云原生技术生态是一个庞大的技术集合。CNCF 有一张<a href="https://github.com/cncf/landscape" target="_blank" rel="noopener">云原生全景图</a>，在这个全景图里已经有 200 多个项目和产品了，这些项目和产品也都是和 CNCF 的观点所契合的。所以如果以这张全景图作为背景，加以思考就会发现，我们今天所讨论的云原生其实主要谈论了以下几点：</p>
<ol>
<li>云原生基金会 —— CNCF；</li>
<li>云原生技术社区，比如像 CNCF 目前正式托管的 20 多个项目共同构成了现代云计算生态的基石，其中像 Kubernetes 这样的项目已经成为了世界第四活跃的开源项目；</li>
<li>除了前面两点之外，现在全球各大公有云厂商都已经支持了 Kubernetes。此外，还有 100 多家技术创业公司也在持续地进行投入。现在阿里巴巴也在谈全面上云，而且上云就要上云原生，这也是各大技术公司拥抱云原生的一个例子。</li>
</ol>
<h3 id="我们正处于时代的关键节点"><a href="#我们正处于时代的关键节点" class="headerlink" title="我们正处于时代的关键节点"></a>我们正处于时代的关键节点</h3><p>2019 年正是云原生时代的关键节点，为什么这么说？我们这里就为大家简单梳理一下。</p>
<p>从 2013 年 Docker 项目发布开始说起，Docker 项目的发布使得全操作系统语义的沙盒技术唾手可得，使得用户能够更好地、更完整地打包自己的应用，使得开发者可以轻而易举的获得了一个应用的最小可运行单位，而不需要依赖任何 PaaS 能力。这对经典 PaaS 产业其实是一个“降维打击”。</p>
<p>2014 年的时候，Kubernetes 项目发布，其意义在于 Google 将内部的 Borg/Omega 系统思想借助开源社区实现了“重生”，并且提出了“容器设计模式”的思想。而 Google 之所以选择间接开源 Kubernetes 而不是直接开源 Borg 项目，其实背后的原因也比较容易理解：Borg/Omega 这样的系统太复杂了，是没办法提供给 Google 之外的人使用，但是 Borg/Omega 这样的设计思想却可以借助 Kubernetes 让大家接触到，这也是开源 Kubernetes 的重要背景。</p>
<p>这样到了 2015 年到 2016 年，就到了容器编排“三国争霸”的时代，当时 Docker、Swarm、Mesos、Kubernetes 都在容器编排领域展开角逐，他们竞争的原因其实也比较容易理解， 那就是 Docker 或者容器本身的价值虽然大，但是如果想要让其产生商业价值或者说对云的价值，那么就一定需要在编排上面占据一个有利的位置。</p>
<p>Swarm 和 Mesos 的特点，那就是各自只在生态和技术方面比较强，其中，Swarm 更偏向于生态，而 Mesos 技术更强一些。相比之下， Kubernetes 则兼具了两者优势，最终在 2017 年“三国争霸”的局面中得以胜出，成为了当时直到现在的容器编排标准。这一过程的代表性事件就是 Docker 公司宣布在核心产品中内置了 Kubernetes 服务，并且 Swarm 项目逐渐停止维护。</p>
<p>到了 2018 年的时候，云原生技术理念开始逐渐萌芽，这是因为此时 Kubernetes 以及容器都成为了云厂商的既定标准，以“云”为核心的软件研发思想逐步形成。</p>
<p>而到了 2019 年，情况似乎又将发生一些变化。</p>
<h3 id="2019年——云原生技术普及元年"><a href="#2019年——云原生技术普及元年" class="headerlink" title="2019年——云原生技术普及元年"></a>2019年——云原生技术普及元年</h3><p>为什么说 2019 年很可能是一个关键节点呢？我们认为 2019 年是云原生技术的普及元年。</p>
<p>首先大家可以看到，在 2019 年，阿里巴巴宣布要全面上云，而且“上云就要上云原生”。我们还可以看到，以“云”为核心的软件研发思想，正逐步成为所有开发者的默认选项。像 Kubernetes 等云原生技术正在成为技术人员的必修课，大量的工作岗位正在涌现出来。</p>
<p>这种背景下，“会 Kubernetes”已经远远不够了，“懂 Kubernetes”、“会云原生架构”的重要性正日益凸显出来。 从 2019 年开始，云原生技术将会大规模普及，这也是为什么大家都要在这个时间点上学习和投资云原生技术的重要原因。</p>
<h1 id="二、什么是“云原生”？云原生该怎么落地？"><a href="#二、什么是“云原生”？云原生该怎么落地？" class="headerlink" title="二、什么是“云原生”？云原生该怎么落地？"></a>二、什么是“云原生”？云原生该怎么落地？</h1><p>我们再来详细的聊一聊“云原生”：什么是“云原生”？云原生该怎么落地？这两个问题也是整个课程的核心内容。</p>
<h2 id="云原生的定义"><a href="#云原生的定义" class="headerlink" title="云原生的定义"></a>云原生的定义</h2><p>很多人都会问“到底什么是云原生？”</p>
<p>实际上，云原生是一条最佳路径或者最佳实践。更详细的说，云原生为用户指定了一条低心智负担的、敏捷的、能够以可扩展、可复制的方式最大化地利用云的能力、发挥云的价值的最佳路径。</p>
<p>因此，云原生其实是一套指导进行软件架构设计的思想。按照这样的思想而设计出来的软件：首先，天然就“生在云上，长在云上”；其次，能够最大化地发挥云的能力，使得我们开发的软件和“云”能够天然地集成在一起，发挥出“云”的最大价值。</p>
<p>所以，云原生的最大价值和愿景，就是认为未来的软件，会从诞生起就生长在云上，并且遵循一种新的软件开发、发布和运维模式，从而使得软件能够最大化地发挥云的能力。说到了这里，大家可以思考一下为什么容器技术具有革命性？</p>
<p>其实，容器技术和集装箱技术的革命性非常类似，即：容器技术使得应用具有了一种“自包含”的定义方式。所以，这样的应用才能以敏捷的、以可扩展可复制的方式发布在云上，发挥出云的能力。这也就是容器技术对云发挥出的革命性影响所在，所以说，容器技术正是云原生技术的核心底盘。</p>
<div class="tabs" id="cloud_native_desc"><ul class="nav-tabs"><li class="tab active"><a href="#cloud_native_desc-1">技术范畴</a></li><li class="tab"><a href="#cloud_native_desc-2">两个理论</a></li><li class="tab"><a href="#cloud_native_desc-3">演进的过程</a></li><li class="tab"><a href="#cloud_native_desc-4">演进的意义</a></li></ul><div class="tab-content"><div class="tab-pane active" id="cloud_native_desc-1"><h2 id="云原生的技术范畴"><a href="#云原生的技术范畴" class="headerlink" title="云原生的技术范畴"></a>云原生的技术范畴</h2><p>云原生的技术范畴包括了以下几个方面：</p>
<ul>
<li>第一部分是云应用定义与开发流程。这包括应用定义与镜像制作、配置 CI/CD、消息和 Streaming 以及数据库等。</li>
<li>第二部分是云应用的编排与管理流程。这也是 Kubernetes 比较关注的一部分，包括了应用编排与调度、服务发现治理、远程调用、API 网关以及 Service Mesh。</li>
<li>第三部分是监控与可观测性。这部分所强调的是云上应用如何进行监控、日志收集、Tracing 以及在云上如何实现破坏性测试，也就是混沌工程的概念。</li>
<li>第四部分就是云原生的底层技术，比如容器运行时、云原生存储技术、云原生网络技术等。</li>
<li>第五部分是云原生工具集，在前面的这些核心技术点之上，还有很多配套的生态或者周边的工具需要使用，比如流程自动化与配置管理、容器镜像仓库、云原生安全技术以及云端密码管理等。</li>
<li>最后则是 Serverless。Serverless 是一种 PaaS 的特殊形态，它定义了一种更为“极端抽象”的应用编写方式，包含了 FaaS 和 BaaS 这样的概念。而无论是 FaaS 还是 BaaS，其最为典型的特点就是按实际使用计费（Pay as you go），因此 Serverless 计费也是重要的知识和概念。</li>
</ul>
<img title="云原生的技术范畴" alt="云原生的技术范畴" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-1/cloud-native-1-1.png/w600"></div><div class="tab-pane" id="cloud_native_desc-2"><h2 id="云原生思想的两个理论"><a href="#云原生思想的两个理论" class="headerlink" title="云原生思想的两个理论"></a>云原生思想的两个理论</h2><p>在了解完云原生的技术范畴之后你就会发现，其所包含的技术内容还是很多的，但是这些内容的技术本质却是类似的。云原生技术的本质是两个理论基础。</p>
<ul>
<li><strong>第一个理论基础是：不可变基础设施。</strong>这一点目前是通过容器镜像来实现的，其含义就是应用的基础设施应该是不可变的，是一个自包含、自描述可以完全在不同环境中迁移的东西；</li>
<li><strong>第二个理论基础就是：云应用编排理论。</strong>当前的实现方式就是 Google 所提出来的“容器设计模式”，这也是本系列课程中的 Kubernetes 部分所需主要讲解的内容。</li>
</ul></div><div class="tab-pane" id="cloud_native_desc-3"><h2 id="基础设施向云演进的过程"><a href="#基础设施向云演进的过程" class="headerlink" title="基础设施向云演进的过程"></a>基础设施向云演进的过程</h2><p>首先为大家介绍一下“不可变基础设施”的概念。其实，应用所依赖的基础设施也在经历一个向云演进的过程，举例而言，对于传统的应用基础设施而言，其实往往是可变的。</p>
<p>大家可能经常会干这样一件事情，比如需要发布或者更新一个软件，那么流程大致是这样的，先通过 SSH 连到服务器，然后手动升级或者降级软件包，逐个调整服务器上的配置文件，并且将新代码直接都部署到现有服务器上。因此，这套基础设施会不断地被调整和修改。</p>
<p>但是在云上，对“云”友好的应用基础设施是不可变的。</p>
<p>这种场景下的上述更新过程会这么做：一旦应用部署完成之后，那么这套应用基础设施就不会再修改了。如果需要更新，那么需要现更改公共镜像来构建新服务直接替换旧服务。而我们之所以能够实现直接替换，就是因为容器提供了自包含的环境（包含应用运行所需的所有依赖）。所以对于应用而言，完全不需要关心容器发生了什么变化，只需要把容器镜像本身修改掉就可以了。因此，对于云友好的基础设施是随时可以替换和更换的，这就是因为容器具有敏捷和一致性的能力，也就是云时代的应用基础设施。</p>
<p>所以，总结而言，云时代的基础设施就像是可以替代的“牲口”，可以随时替换；而传统的基础设施则是独一无二的“宠物”，需要细心呵护，这就体现出了云时代不可变基础设施的优点。</p></div><div class="tab-pane" id="cloud_native_desc-4"><h2 id="基础设施向云演进的意义"><a href="#基础设施向云演进的意义" class="headerlink" title="基础设施向云演进的意义"></a>基础设施向云演进的意义</h2><p>所以，像这样的基础设施向“不可变”演进的过程，为我们提供了两个非常重要的优点。</p>
<ol>
<li><p>基础设施的一致性和可靠性。同样一个镜像，无论是在美国打开，在中国打开，还是在印度打开都是一样的。并且其中的 OS 环境对于应用而言都是一致的。而对于应用而言，它就不需要关心容器跑在哪里，这就是基础设施一致性非常重要的一个特征。</p>
</li>
<li><p>这样的镜像本身就是自包含的，其包含了应用运行所需要的所有依赖，因此也可以漂移到云上的任何一个位置。</p>
</li>
</ol>
<p>此外，云原生的基础设施还提供了简单、可预测的部署和运维能力。由于现在有了镜像，应用还是自描述的，通过镜像运行起来的整个容器其实可以像 Kubernetes 的 Operator 技术一样将其做成自运维的，所以整个应用本身都是自包含的行为，使得其能够迁移到云上任何一个位置。这也使得整个流程的自动化变得非常容易。</p>
<p>应用本身也可以更好地扩容，从 1 个实例变成 100 个实例，进而变成 1 万个实例，这个过程对于容器化后的应用没有任何特殊的。最后，我们这时也能够通过不可变的基础设施来地快速周围的管控系统和支撑组件。因为，这些组件本身也是容器化的，是符合不可变基础设施这样一套理论的组件。</p>
<p>以上就是不可变基础设施为用户带来的最大的优点。</p></div></div></div>

<h2 id="云原生关键技术点"><a href="#云原生关键技术点" class="headerlink" title="云原生关键技术点"></a>云原生关键技术点</h2><p>当我们回过头来看云原生关键技术点或者说它所依赖的技术理论的时候，可以看到主要有这样的四个方向：</p>
<ol>
<li>如何构建自包含、可定制的应用镜像；</li>
<li>能不能实现应用快速部署与隔离能力；</li>
<li>应用基础设施创建和销毁的自动化管理；</li>
<li>可复制的管控系统和支撑组件。</li>
</ol>
<p>这四个云原生关键技术点是落地实现云原生技术的四个主要途径，而这四个技术点也是本门课程的 17 个技术点所主要讲述的核心知识。</p>
<div class="note danger">
            <h1 id="本章总结"><a href="#本章总结" class="headerlink" title="本章总结"></a>本章总结</h1><ul><li>“云原生”具备着重要的意义，它是云时代技术人自我提升的必备路径；</li><li>“云原生”定义了一条云时代应用从开发到交付的最佳路径；</li><li>“云原生”应用生在云上，长在云上，希望能够将云的能力发挥到极致。</li></ul>
          </div>

<h1 id="点评："><a href="#点评：" class="headerlink" title="点评："></a>点评：</h1><p>“未来的软件一定是生长于云上的”这是云原生理念的最核心假设。而所谓“云原生”，实际上就是在定义一条能够让应用最大程度利用云的能力、发挥云的价值的最佳路径。在这条路径上，脱离了“应用”这个载体，“云原生”就无从谈起；容器技术，则是将这个理念落地、将软件交付的革命持续进行下去的重要手段之一。</p>
<p>而云原生重点讲解的 Kubernetes 项目，则是整个“云原生”理念落地的核心与关键所在。它正在迅速成为连通“云”与“应用”的高速公路，以标准、高效的方式将“应用”快速交付到世界上任何一个位置。如今”云原生应用交付“，已经成为了 2019 年云计算市场上最热门的技术关键词之一。希望学习课程的同学们能够学以致用，持续关注以 K8s 为基础进行“云原生应用管理与交付”的技术趋势。</p>
]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Docker</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(二)——容器基本概念</title>
    <url>/cn/cn%E5%AE%B9%E5%99%A8%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>本章要点</p>
<div class="note primary">
            <ol><li>什么是容器与镜像？如何构建容器与镜像</li><li>容器的生命周期</li><li>容器项目的架构</li><li>容器 VS.VM</li></ol>
          </div>

<a id="more"></a>
<h1 id="一、容器与镜像"><a href="#一、容器与镜像" class="headerlink" title="一、容器与镜像"></a>一、容器与镜像</h1><h2 id="什么是容器？"><a href="#什么是容器？" class="headerlink" title="什么是容器？"></a>什么是容器？</h2><p>在介绍容器的具体概念之前，先简单回顾一下操作系统是如何管理进程的。</p>
<p>首先，当我们登录到操作系统之后，可以通过 ps 等操作看到各式各样的进程，这些进程包括系统自带的服务和用户的应用进程。那么，这些进程都有什么样的特点？</p>
<ul>
<li>第一，这些进程可以相互看到、相互通信；</li>
<li>第二，它们使用的是同一个文件系统，可以对同一个文件进行读写操作；</li>
<li>第三，这些进程会使用相同的系统资源。</li>
</ul>
<p>这样的三个特点会带来什么问题呢？</p>
<ul>
<li>因为这些进程能够相互看到并且进行通信，高级权限的进程可以攻击其他进程；</li>
<li>因为它们使用的是同一个文件系统，因此会带来两个问题：这些进程可以对于已有的数据进行增删改查，具有高级权限的进程可能会将其他进程的数据删除掉，破坏掉其他进程的正常运行；此外，进程与进程之间的依赖可能会存在冲突，如此一来就会给运维带来很大的压力；</li>
<li>因为这些进程使用的是同一个宿主机的资源，应用之间可能会存在资源抢占的问题，当一个应用需要消耗大量 CPU 和内存资源的时候，就可能会破坏其他应用的运行，导致其他应用无法正常地提供服务。</li>
</ul>
<p>针对上述的三个问题，如何为进程提供一个独立的运行环境呢？</p>
<ul>
<li><p>针对不同进程使用同一个文件系统所造成的问题而言，Linux 和 Unix 操作系统可以通过 chroot 系统调用将子目录变成根目录，达到视图级别的隔离；进程在 chroot 的帮助下可以具有独立的文件系统，对于这样的文件系统进行增删改查不会影响到其他进程；</p>
</li>
<li><p>因为进程之间相互可见并且可以相互通信，使用 Namespace 技术来实现进程在资源的视图上进行隔离。在 chroot 和 Namespace 的帮助下，进程就能够运行在一个独立的环境下了；</p>
</li>
<li><p>但在独立的环境下，进程所使用的还是同一个操作系统的资源，一些进程可能会侵蚀掉整个系统的资源。为了减少进程彼此之间的影响，可以通过 Cgroup 来限制其资源使用率，设置其能够使用的 CPU 以及内存量。</p>
</li>
</ul>
<p>那么，应该如何定义这样的进程集合呢？</p>
<p>其实，<strong>容器就是一个视图隔离、资源可限制、独立文件系统的进程集合</strong>。所谓“视图隔离”就是能够看到部分进程以及具有独立的主机名等；控制资源使用率则是可以对于内存大小以及 CPU 使用个数等进行限制。容器就是一个进程集合，它将系统的其他资源隔离开来，具有自己独立的资源视图。</p>
<p>容器具有一个独立的文件系统，因为使用的是系统的资源，所以在独立的文件系统内不需要具备内核相关的代码或者工具，我们只需要提供容器所需的二进制文件、配置文件以及依赖即可。只要容器运行时所需的文件集合都能够具备，那么这个容器就能够运行起来。</p>
<h2 id="什么是镜像？"><a href="#什么是镜像？" class="headerlink" title="什么是镜像？"></a>什么是镜像？</h2><p>综上所述，我们将这些容器运行时所需要的所有的文件集合称之为容器镜像。</p>
<p>那么，一般都是通过什么样的方式来构建镜像的呢？通常情况下，我们会采用 Dockerfile 来构建镜像，这是因为 Dockerfile 提供了非常便利的语法糖，能够帮助我们很好地描述构建的每个步骤。当然，每个构建步骤都会对已有的文件系统进行操作，这样就会带来文件系统内容的变化，我们将这些变化称之为 changeset。当我们把构建步骤所产生的变化依次作用到一个空文件夹上，就能够得到一个完整的镜像。</p>
<p><strong>changeset</strong> 的分层以及复用特点能够带来几点优势：</p>
<ul>
<li><p>第一，能够提高分发效率，简单试想一下，对于大的镜像而言，如果将其拆分成各个小块就能够提高镜像的分发效率，这是因为镜像拆分之后就可以并行下载这些数据；</p>
</li>
<li><p>第二，因为这些数据是相互共享的，也就意味着当本地存储上包含了一些数据的时候，只需要下载本地没有的数据即可，举个简单的例子就是 golang 镜像是基于 alpine 镜像进行构建的，当本地已经具有了 alpine 镜像之后，在下载 golang 镜像的时候只需要下载本地 alpine 镜像中没有的部分即可；</p>
</li>
<li><p>第三，因为镜像数据是共享的，因此可以节约大量的磁盘空间，简单设想一下，当本地存储具有了 alpine 镜像和 golang 镜像，在没有复用的能力之前，alpine 镜像具有 5M 大小，golang 镜像有 300M 大小，因此就会占用 305M 空间；而当具有了复用能力之后，只需要 300M 空间即可。</p>
</li>
</ul>
<h2 id="如何构建镜像？"><a href="#如何构建镜像？" class="headerlink" title="如何构建镜像？"></a>如何构建镜像？</h2><p>如下图所示的 Dockerfile 适用于描述如何构建 golang 应用的。</p>
<img title="Dockerfile" alt="Dockerfile" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-2/cloud-native-2-1.png/w600">

<p>如图所示：</p>
<ul>
<li>FROM 行表示以下的构建步骤基于什么镜像进行构建，正如前面所提到的，镜像是可以复用的；</li>
<li>WORKDIR 行表示会把接下来的构建步骤都在哪一个相应的具体目录下进行，其起到的作用类似于 Shell 里面的 cd；</li>
<li>COPY 行表示的是可以将宿主机上的文件拷贝到容器镜像内；</li>
<li>RUN 行表示在具体的文件系统内执行相应的动作。当我们运行完毕之后就可以得到一个应用了；</li>
<li>CMD 行表示使用镜像时的默认程序名字。</li>
</ul>
<p>当有了 Dockerfile 之后，就可以通过 docker build 命令构建出所需要的应用。构建出的结果存储在本地，一般情况下，镜像构建会在打包机或者其他的隔离环境下完成。</p>
<p>那么，这些镜像如何运行在生产环境或者测试环境上呢？这时候就需要一个中转站或者中心存储，我们称之为 docker registry，也就是镜像仓库，其负责存储所有产生的镜像数据。我们只需要通过 docker push 就能够将本地镜像推动到镜像仓库中，这样一来，就能够在生产环境上或者测试环境上将相应的数据下载下来并运行了。</p>
<h2 id="如何运行容器？"><a href="#如何运行容器？" class="headerlink" title="如何运行容器？"></a>如何运行容器？</h2><p>运行一个容器一般情况下分为三步：</p>
<ul>
<li>第一步：从镜像仓库中将相应的镜像下载下来；</li>
<li>第二步：当镜像下载完成之后就可以通过 docker images 来查看本地镜像，这里会给出一个完整的列表，我们可以在列表中选中想要的镜像；</li>
<li>第三步：当选中镜像之后，就可以通过 docker run 来运行这个镜像得到想要的容器，当然可以通过多次运行得到多个容器。一个镜像就相当于是一个模板，一个容器就像是一个具体的运行实例，因此镜像就具有了一次构建、到处运行的特点。</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><div class="note danger">
            <p>简单回顾一下，容器就是和系统其它部分隔离开来的进程集合，这里的其他部分包括进程、网络资源以及文件系统等。而镜像就是容器所需要的所有文件集合，其具备一次构建、到处运行的特点。</p>
          </div>

<h1 id="二、容器的生命周期"><a href="#二、容器的生命周期" class="headerlink" title="二、容器的生命周期"></a>二、容器的生命周期</h1><h2 id="容器运行时的生命周期"><a href="#容器运行时的生命周期" class="headerlink" title="容器运行时的生命周期"></a>容器运行时的生命周期</h2><p>容器是一组具有隔离特性的进程集合，在使用 docker run 的时候会选择一个镜像来提供独立的文件系统并指定相应的运行程序。这里指定的运行程序称之为 initial 进程，这个 initial 进程启动的时候，容器也会随之启动，当 initial 进程退出的时候，容器也会随之退出。</p>
<p>因此，可以认为容器的生命周期和 initial 进程的生命周期是一致的。当然，因为容器内不只有这样的一个 initial 进程，initial 进程本身也可以产生其他的子进程或者通过 docker exec 产生出来的运维操作，也属于 initial 进程管理的范围内。当 initial 进程退出的时候，所有的子进程也会随之退出，这样也是为了防止资源的泄漏。</p>
<p>但是这样的做法也会存在一些问题，首先应用里面的程序往往是有状态的，其可能会产生一些重要的数据，当一个容器退出被删除之后，数据也就会丢失了，这对于应用方而言是不能接受的，所以需要将容器所产生出来的重要数据持久化下来。容器能够直接将数据持久化到指定的目录上，这个目录就称之为数据卷。</p>
<p>数据卷有一些特点，其中非常明显的就是数据卷的生命周期是独立于容器的生命周期的，也就是说容器的创建、运行、停止、删除等操作都和数据卷没有任何关系，因为它是一个特殊的目录，是用于帮助容器进行持久化的。简单而言，我们会将数据卷挂载到容器内，这样一来容器就能够将数据写入到相应的目录里面了，而且容器的退出并不会导致数据的丢失。</p>
<p>通常情况下，数据卷管理主要有两种方式：</p>
<ul>
<li>第一种是通过 bind 的方式，直接将宿主机的目录直接挂载到容器内；这种方式比较简单，但是会带来运维成本，因为其依赖于宿主机的目录，需要对于所有的宿主机进行统一管理。</li>
<li>第二种是将目录管理交给运行引擎。</li>
</ul>
<h1 id="三、容器项目架构"><a href="#三、容器项目架构" class="headerlink" title="三、容器项目架构"></a>三、容器项目架构</h1><h2 id="moby-容器引擎架构"><a href="#moby-容器引擎架构" class="headerlink" title="moby 容器引擎架构"></a>moby 容器引擎架构</h2><p>moby 是目前最流行的容器管理引擎，moby daemon 会对上提供有关于容器、镜像、网络以及 Volume的管理。moby daemon 所依赖的最重要的组件就是 containerd，containerd 是一个容器运行时管理引擎，其独立于 moby daemon ，可以对上提供容器、镜像的相关管理。</p>
<p><strong>containerd</strong> 底层有 containerd shim 模块，其类似于一个守护进程，这样设计的原因有几点：</p>
<ul>
<li><p>首先，containerd 需要管理容器生命周期，而容器可能是由不同的容器运行时所创建出来的，因此需要提供一个灵活的插件化管理。而 shim 就是针对于不同的容器运行时所开发的，这样就能够从 containerd 中脱离出来，通过插件的形式进行管理。</p>
</li>
<li><p>其次，因为 shim 插件化的实现，使其能够被 containerd 动态接管。如果不具备这样的能力，当 moby daemon 或者 containerd daemon 意外退出的时候，容器就没人管理了，那么它也会随之消失、退出，这样就会影响到应用的运行。</p>
</li>
<li><p>最后，因为随时可能会对 moby 或者 containerd 进行升级，如果不提供 shim 机制，那么就无法做到原地升级，也无法做到不影响业务的升级，因此 containerd shim 非常重要，它实现了动态接管的能力。</p>
</li>
</ul>
<p>本章课程只是针对于 moby 进行一个大致的介绍，在后续的课程也会详细介绍。</p>
<h1 id="四、容器-VS-VM"><a href="#四、容器-VS-VM" class="headerlink" title="四、容器 VS VM"></a>四、容器 VS VM</h1><h2 id="容器和-VM-之间的差异"><a href="#容器和-VM-之间的差异" class="headerlink" title="容器和 VM 之间的差异"></a>容器和 VM 之间的差异</h2><div class="tabs" id="your_tabs_name"><ul class="nav-tabs"><li class="tab active"><a href="#your_tabs_name-1"><i class="fa fa-reorder"></i>VM</a></li><li class="tab"><a href="#your_tabs_name-2"><i class="fa fa-reorder"></i>容器</a></li></ul><div class="tab-content"><div class="tab-pane active" id="your_tabs_name-1"><p>VM 利用 Hypervisor 虚拟化技术来模拟 CPU、内存等硬件资源，这样就可以在宿主机上建立一个 Guest OS，这是常说的安装一个虚拟机。</p>
<p>每一个 Guest OS 都有一个独立的内核，比如 Ubuntu、CentOS 甚至是 Windows 等，在这样的 Guest OS 之下，每个应用都是相互独立的，VM 可以提供一个更好的隔离效果。<br>但这样的隔离效果需要付出一定的代价，因为需要把一部分的计算资源交给虚拟化，这样就很难充分利用现有的计算资源，并且每个 Guest OS 都需要占用大量的磁盘空间，比如 Windows 操作系统的安装需要10<del>30G 的磁盘空间，Ubuntu 也需要 5</del>6G，同时这样的方式启动很慢。正是因为虚拟机技术的缺点，催生出了容器技术。</p></div><div class="tab-pane" id="your_tabs_name-2"><p>容器是针对于进程而言的，因此无需 Guest OS，只需要一个独立的文件系统提供其所需要文件集合即可。所有的文件隔离都是进程级别的，因此启动时间快于 VM，并且所需的磁盘空间也小于 VM。当然了，进程级别的隔离并没有想象中的那么好，隔离效果相比 VM 要差很多。</p></div></div></div>

<p>总体而言，容器和 VM 相比，各有优劣，因此容器技术也在向着强隔离方向发展。</p>
<div class="note danger">
            <h1 id="本节总结"><a href="#本节总结" class="headerlink" title="本节总结"></a>本节总结</h1><ul><li>容器是一个进程集合，具有自己独特的视图视角；</li><li>镜像是容器所需要的所有文件集合，其具备一次构建、到处运行的特点；</li><li>容器的生命周期和 initial 进程的生命周期是一样的；</li><li>容器和 VM 相比，各有优劣，容器技术在向着强隔离方向发展。</li></ul>
          </div>

]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Docker</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s超详细总结</title>
    <url>/cn/k8s-%E8%B6%85%E8%AF%A6%E7%BB%86%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>一个目标：容器操作；两地三中心；四层服务发现；五种Pod共享资源；六个CNI常用插件；七层负载均衡；八种隔离维度；九个网络模型原则；十类IP地址；百级产品线；千级物理机；万级容器；亿级日服务人次。</p>
<h1 id="一个目标：容器操作"><a href="#一个目标：容器操作" class="headerlink" title="一个目标：容器操作"></a><strong>一个目标：容器操作</strong></h1><p>Kubernetes(k8s)是自动化容器操作的开源平台。这些容器操作包括：部署，调度和节点集群间扩展。<br>具体功能：</p>
<ul>
<li>自动化容器部署和复制。</li>
<li>实时弹性收缩容器规模。</li>
<li>容器编排成组，并提供容器间的负载均衡。</li>
<li>调度：容器在哪个机器上运行。<br>组成：</li>
<li>kubectl:客户端命令行工具，作为整个系统的操作入口。</li>
<li>kube-apiserver:以REST API服务形式提供接口，作为整个系统的控制入口。</li>
<li>kube-controller-manager:执行整个系统的后台任务，包括节点状态状况、Pod个数、Pods和Service的关联等。</li>
<li>kube-scheduler:负责节点资源管理，接收来自kube-apiserver创建Pods任务，并分配到某个节点。</li>
<li>etcd:负责节点间的服务发现和配置共享。</li>
<li>kube-proxy:运行在每个计算节点上，负责Pod网络代理。定时从etcd获取到service信息来做相应的策略。</li>
<li>kubelet:运行在每个计算节点上，作为agent，接收分配该节点的Pods任务及管理容器，周期性获取容器状态，反馈给kube-apiserver。</li>
<li>DNS：一个可选的DNS服务，用于为每个Service对象创建DNS记录，这样所有的Pod就可以通过DNS访问服务了。<br>下面是K8s的架构拓扑图：<img  data-src="http://img.mukewang.com/5b0d07e90001142313480686.jpg" />

</li>
</ul>
<h1 id="两地三中心"><a href="#两地三中心" class="headerlink" title="两地三中心"></a><strong>两地三中心</strong></h1><p>两地三中心包括本地生产中心、本地灾备中心、异地灾备中心。<br><img  data-src="http://img.mukewang.com/5b0d084d00014d4413201062.jpg" /><br>两地三中心要解决的一个重要问题就是数据一致性问题。k8s使用etcd组件作为一个高可用、强一致性的服务发现存储仓库。用于配置共享和服务发现。</p>
<p>它作为一个受到Zookeeper和doozer启发而催生的项目。除了拥有他们的所有功能之外，还拥有以下4个特点：</p>
<ul>
<li>简单：基于http+json的api让你用curl命令就可以轻松使用。</li>
<li>安全：可选SSL客户认证机制。</li>
<li>快速：每个实例每秒支持一千次写操作。</li>
<li>可信：使用Raft算法充分实现了分布式。</li>
</ul>
<h1 id="四层服务发现"><a href="#四层服务发现" class="headerlink" title="四层服务发现"></a><strong>四层服务发现</strong></h1><p>先一张图解释一下网络七层协议：<br><img  data-src="http://img.mukewang.com/5b0d085e0001fa2112361724.jpg" /><br>k8s提供了两种方式进行服务发现：</p>
<ol>
<li>环境变量：当创建一个Pod的时候，kubelet会在该Pod中注入集群内所有Service的相关环境变量。需要注意的是，要想一个Pod中注入某个Service的环境变量，则必须Service要先比该Pod创建。这一点，几乎使得这种方式进行服务发现不可用。<br>比如，一个ServiceName为redis-master的Service，对应的ClusterIP:Port为10.0.0.11:6379，则对应的环境变量为：<img  data-src="http://img.mukewang.com/5b0d092200012b4f12040644.jpg" /></li>
<li>DNS：可以通过cluster add-on的方式轻松的创建KubeDNS来对集群内的Service进行服务发现。</li>
</ol>
<p>以上两种方式，一个是基于tcp，众所周知，DNS是基于UDP的，它们都是建立在四层协议之上。</p>
<h1 id="五种Pod共享资源"><a href="#五种Pod共享资源" class="headerlink" title="五种Pod共享资源"></a><strong>五种Pod共享资源</strong></h1><p>Pod是K8s最基本的操作单元，包含一个或多个紧密相关的容器，一个Pod可以被一个容器化的环境看作应用层的“逻辑宿主机”；一个Pod中的多个容器应用通常是紧密耦合的，Pod在Node上被创建、启动或者销毁；每个Pod里运行着一个特殊的被称之为Volume挂载卷，因此他们之间通信和数据交换更为高效，在设计时我们可以充分利用这一特性将一组密切相关的服务进程放入同一个Pod中。<img  data-src="http://img.mukewang.com/5b0d094100014e1812240840.jpg" /><br>同一个Pod里的容器之间仅需通过localhost就能互相通信。一个Pod中的应用容器共享五种资源：</p>
<ul>
<li>PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID。</li>
<li>网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围。</li>
<li>IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信。</li>
<li>UTS命名空间：Pod中的多个容器共享一个主机名。</li>
<li>Volumes(共享存储卷)：Pod中的各个容器可以访问在Pod级别定义的Volumes。<br>Pod的生命周期通过Replication Controller来管理；通过模板进行定义，然后分配到一个Node上运行，在Pod所包含容器运行结束后，Pod结束。<br>Kubernetes为Pod设计了一套独特的网络配置，包括：为每个Pod分配一个IP地址，使用Pod名作为荣期间通信的主机名等。</li>
</ul>
<h1 id="六个CNI常用插件"><a href="#六个CNI常用插件" class="headerlink" title="六个CNI常用插件"></a><strong>六个CNI常用插件</strong></h1><p>CNI(Container Network Interface)容器网络接口，是Linux容器网络配置的一组标准和库，用户需要根据这些标准和库来开发自己的容器网络插件。CNI只专注解决容器网络连接和容器销毁时的资源释放，提供一套框架，所以CNI可以支持大量不同的网络模式，并且容易实现。<br>下面用一张图表示六个CNI常用插件：<br><img  data-src="http://img.mukewang.com/5b0d095d000118ed12000752.jpg" /></p>
<h1 id="七层负载均衡"><a href="#七层负载均衡" class="headerlink" title="七层负载均衡"></a><strong>七层负载均衡</strong></h1><p>提负载均衡就不得不先提服务器之间的通信。<br>IDC(Internet Data Center),也可称 数据中心、机房，用来放置服务器。IDC网络是服务器间通信的桥梁。<br><img  data-src="http://img.mukewang.com/5b0d0b300001e75011660882.jpg" /><br>上图里画了很多网络设备，它们都是干啥用的呢？<br>路由器、交换机、MGW/NAT都是网络设备，按照性能、内外网划分不同的角色。</p>
<ul>
<li>内网接入交换机：也称为TOR(top of rack),是服务器接入网络的设备。每台内网接入交换机下联40-48台服务器，使用一个掩码为/24的网段作为服务器内网网段。</li>
<li>内网核心交换机：负责IDC内各内网接入交换机的流量转发及跨IDC流量转发。</li>
<li>MGW/NAT：MGW即LVS用来做负载均衡，NAT用于内网设备访问外网时做地址转换。</li>
<li>外网核心路由器：通过静态互联运营商或BGP互联美团统一外网平台。</li>
</ul>
<p>先说说各层负载均衡：</p>
<ul>
<li>二层负载均衡：基于MAC地址的二层负载均衡。</li>
<li>三层负载均衡：基于IP地址的负载均衡。</li>
<li>四层负载均衡：基于IP+端口的负载均衡。</li>
<li>七层负载均衡：基于URL等应用层信息的负载均衡。<br>这里用一张图来说说四层和七层负载均衡的区别：<img  data-src="http://img.mukewang.com/5b0d0b3e0001f76312240782.jpg" />
上面四层服务发现讲的主要是k8s原生的kube-proxy方式。K8s关于服务的暴露主要是通过NodePort方式，通过绑定minion主机的某个端口，然后进行pod的请求转发和负载均衡，但这种方式有下面的缺陷：
Service可能有很多个，如果每个都绑定一个node主机端口的话，主机需要开放外围的端口进行服务调用，管理混乱。
无法应用很多公司要求的防火墙规则。

</li>
</ul>
<p>理想的方式是通过一个外部的负载均衡器，绑定固定的端口，比如80，然后根据域名或者服务名向后面的Service ip转发，Nginx很好的解决了这个需求，但问题是如果有的心得服务加入，如何去修改Nginx的配置，并且加载这些配置？Kubernetes给出的方案就是Ingress。这是一个基于7层的方案。</p>
<h1 id="八种隔离维度"><a href="#八种隔离维度" class="headerlink" title="八种隔离维度"></a><strong>八种隔离维度</strong></h1><img  data-src="http://img.mukewang.com/5b0d0b4f000194dc09420666.jpg" />
K8s集群调度这边需要对上面从上到下从粗粒度到细粒度的隔离做相应的调度策略。

<h1 id="九个网络模型原则"><a href="#九个网络模型原则" class="headerlink" title="九个网络模型原则"></a><strong>九个网络模型原则</strong></h1><p>K8s网络模型要符合4个基础原则，3个网络要求原则，1个架构原则，1个IP原则。<br>每个Pod都拥有一个独立的IP地址，而且假定所有Pod都在一个可以直接连通的、扁平的网络空间中，不管是否运行在同一Node上都可以通过Pod的IP来访问。</p>
<p>K8s中的Pod的IP是最小粒度IP。同一个Pod内所有的容器共享一个网络堆栈，该模型称为IP-per-Pod模型。<br>Pod由docker0实际分配的IP，Pod内部看到的IP地址和端口与外部保持一致。同一个Pod内的不同容器共享网络，可以通过localhost来访问对方的端口，类似同一个VM内不同的进程。<br>IP-per-Pod模型从端口分配、域名解析、服务发现、负载均衡、应用配置等角度看，Pod可以看做是一台独立的VM或物理机。<br>所有容器都可以不用NAT的方式同别的容器通信。<br>所有节点都可以在不同NAT方式下同所有容器心痛，反之亦然。<br>容器的地址和别人看到的地址是同一个地址。<br>要符合下面的架构：<br><img  data-src="http://img.mukewang.com/5b0d0b9a000160ca11820898.jpg" /></p>
<p>由上图架构引申出来IP概念从集群外部到集群内部<img  data-src="http://img.mukewang.com/5b0d0baa0001e65d12360484.jpg" /></p>
<p><strong>十类IP地址</strong><br>大家都知道IP地址分为ABCDE类，另外还有5类特殊用途的IP。</p>
<ol>
<li>A类<br>0.0.0-1226.255.255.255，默认子网掩码/8，即255.0.0.0<ol start="2">
<li>B类</li>
<li>0.0.0-191.255.255.255，默认子网掩码/16，即255.255.0.0</li>
<li>C类</li>
<li>0.0.0-223.255.255.255，默认子网掩码/24，即255.255.255.0</li>
<li>D类</li>
<li>0.0.0-239.255.255.255，一般用于组播</li>
<li>E类</li>
<li>0.0.0-255.255.255.255(其中255.255.255.255为全网广播地址),E类地址一般用于研究用途</li>
</ol>
</li>
<li>0.0.0.0<br> 严格来说，0.0.0.0已经不是一个真正意义上的IP地址了。它表示的是这样一个集合：所有不清楚的主机和目的网络。这里的不清楚是指在本机的路由表里没有特定条目指明如何到达。作为缺省路由。<br> 7.127.0.0.1<br> 本机地址</li>
<li>224.0.0.1<br> 组播地址。如果你的主机开启了IRDP（internet路由发现，使用组播功能），那么你的主机路由表中应该有这样一条路由。</li>
<li>169.254.x.x<br> 使用了DHCP功能自动获取了IP的主机，DHCP服务器发生故障，或响应时间太长而超出了一个系统规定的时间，系统会为你分配这样一个IP，代表网络不能正常运行。</li>
<li>10.xxx、172.16.x.x~172.31.x.x、192.168.x.x<br> 私有地址，大量用于企业内部。保留这样的地址是为了避免亦或是哪个接入公网时引起地址混乱。</p></li>
</ol>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(六)——应用编排与管理:Deployment</title>
    <url>/cn/k8s%E5%BA%94%E7%94%A8%E7%BC%96%E6%8E%92%E4%B8%8E%E7%AE%A1%E7%90%86Deployment/</url>
    <content><![CDATA[<p>本文将主要分享以下四方面的内容：</p>
<div class="note primary">
            <ul><li>需求来源；</li><li>用例解读；</li><li>操作演示以及架构设计。</li></ul>
          </div>

<a id="more"></a>
<h1 id="一、需求来源"><a href="#一、需求来源" class="headerlink" title="一、需求来源"></a>一、需求来源</h1><h2 id="背景问题"><a href="#背景问题" class="headerlink" title="背景问题"></a>背景问题</h2><p>首先，我们来看一下背景问题。如下图所示：如果我们直接管理集群中所有的 Pod，应用 A、B、C 的 Pod，其实是散乱地分布在集群中。</p>
<p>现在有以下的问题：</p>
<ul>
<li>首先，如何保证集群内可用 Pod 的数量？也就是说我们应用 A 四个 Pod 如果出现了一些宿主机故障，或者一些网络问题，如何能保证它可用的数量？</li>
<li>如何为所有 Pod 更新镜像版本？我们是否要某一个 Pod 去重建新版本的 Pod？</li>
<li>然后在更新过程中，如何保证服务的可用性？</li>
<li>以及更新过程中，如果发现了问题，如何快速回滚到上一个版本？</li>
</ul>
<h2 id="Deployment：管理部署发布的控制器"><a href="#Deployment：管理部署发布的控制器" class="headerlink" title="Deployment：管理部署发布的控制器"></a>Deployment：管理部署发布的控制器</h2><p>这里就引入了我们今天课程的主题：Deployment 管理部署发布的控制器。</p>
<p>可以看到我们通过 Deployment 将应用 A、B、C 分别规划到不同的 Deployment 中，每个 Deployment 其实是管理的一组相同的应用 Pod，这组 Pod 我们认为它是相同的一个副本，那么 Deployment 能帮我们做什么事情呢？</p>
<ol>
<li><p>首先，Deployment 定义了一种 Pod 期望数量，比如说应用 A，我们期望 Pod 数量是四个，那么这样的话，controller 就会持续维持 Pod 数量为期望的数量。当我们与 Pod 出现了网络问题或者宿主机问题的话，controller 能帮我们恢复，也就是新扩出来对应的 Pod，来保证可用的 Pod 数量与期望数量一致；</p>
</li>
<li><p>配置 Pod 发布方式，也就是说 controller 会按照用户给定的策略来更新 Pod，而且更新过程中，也可以设定不可用 Pod 数量在多少范围内；</p>
</li>
<li><p>如果更新过程中发生问题的话，即所谓“一键”回滚，也就是说你通过一条命令或者一行修改能够将 Deployment 下面所有 Pod 更新为某一个旧版本 。</p>
</li>
</ol>
<h2 id="二、用例解读"><a href="#二、用例解读" class="headerlink" title="二、用例解读"></a>二、用例解读</h2><h3 id="Deployment-语法"><a href="#Deployment-语法" class="headerlink" title="Deployment 语法"></a>Deployment 语法</h3><p>下面我们用一个简单的用例来解读一下如何操作 Deployment。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/1.png/w600">

<p>上图可以看到一个最简单的 Deployment 的 yaml 文件。</p>
<p>“apiVersion：apps/v1”，也就是说 Deployment 当前所属的组是 apps，版本是 v1。“metadata”是我们看到的 Deployment 元信息，也就是往期回顾中的 Labels、Selector、Pod.image，这些都是在往期中提到的知识点。</p>
<p>Deployment 作为一个 K8s 资源，它有自己的 metadata 元信息，这里我们定义的 Deployment.name 是 nginx.Deployment。Deployment.spec 中首先要有一个核心的字段，即 replicas，这里定义期望的 Pod 数量为三个；selector 其实是 Pod 选择器，那么所有扩容出来的 Pod，它的 Labels 必须匹配 selector 层上的 image.labels，也就是 app.nginx。</p>
<p>就如上面的 Pod 模板 template 中所述，这个 template 它其实包含了两部分内容：</p>
<ul>
<li><p>一部分是我们期望 Pod 的 metadata，其中包含了 labels，即跟 selector.matchLabels 相匹配的一个 Labels；</p>
</li>
<li><p>第二部分是 template 包含的一个 Pod.spec。这里 Pod.spec 其实是 Deployment 最终创建出来 Pod 的时候，它所用的 Pod.spec，这里定义了一个 container.nginx，它的镜像版本是 nginx:1.7.9。</p>
</li>
</ul>
<p>下面是遇到的新知识点：</p>
<ul>
<li>第一个是 replicas，就是 Deployment 中期望的或者终态数量；</li>
<li>第二个是 template，也就是 Pod 相关的一个模板。</li>
</ul>
<h3 id="查看-Deployment-状态"><a href="#查看-Deployment-状态" class="headerlink" title="查看 Deployment 状态"></a>查看 Deployment 状态</h3><p>当我们创建出一个 Deployment 的时候，可以通过 kubectl get deployment，看到 Deployment 总体的一个状态。如下图所示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get deployment</span><br><span class="line">NAME                     READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">flink-taskmanager        2/2     2            2           36d</span><br></pre></td></tr></table></figure>
<p>可以看到：</p>
<ul>
<li>DESIRED：期望的 Pod 数量是 3 个；</li>
<li>CURRENT：当前实际 Pod 数量是 3 个；</li>
<li>UP-TO-DATE：其实是到达最新的期望版本的 Pod 数量；</li>
<li>AVAILABLE：这个其实是运行过程中可用的 Pod 数量。后面会提到，这里 AVAILABLE 并不简单是可用的，也就是 Ready 状态的，它其实包含了一些可用超过一定时间长度的 Pod；</li>
<li>AGE：deployment 创建的时长，如上图 Deployment 就是已经创建了 80 分钟。</li>
</ul>
<h3 id="查看-Pod"><a href="#查看-Pod" class="headerlink" title="查看 Pod"></a>查看 Pod</h3><p>最后我们可以查看一下 Pod。如下图所示：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/2.png/w600">

<p>上图中有三个 Pod，Pod 名字格式我们不难看到。</p>
<p>最前面一段：nginx-deployment，其实是 Pod 所属 Deployment.name；中间一段：template-hash，这里三个 Pod 是一样的，因为这三个 Pod 其实都是同一个 template 中创建出来的。</p>
<p>最后一段，是一个 random 的字符串，我们通过 get.pod 可以看到，Pod 的 ownerReferences 即 Pod 所属的 controller 资源，并不是 Deployment，而是一个 ReplicaSet。这个 ReplicaSet 的 name，其实是 nginx-deployment 加上 pod.template-hash，后面会提到。所有的 Pod 都是 ReplicaSet 创建出来的，而 ReplicaSet 它对应的某一个具体的 Deployment.template 版本。</p>
<h3 id="更新镜像"><a href="#更新镜像" class="headerlink" title="更新镜像"></a>更新镜像</h3><p>接下来我们可以看一下，如何对一个给定的 Deployment 更新它所有Pod的镜像版本呢？这里我们可以执行一个 kubectl 命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">set</span> image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1</span><br></pre></td></tr></table></figure>
<ul>
<li><p>首先 kubectl 后面有一个 set image 固定写法，这里指的是设定镜像；其次是一个 deployment.v1.apps，这里也是一个固定写法，写的是我们要操作的资源类型，deployment 是资源名、v1 是资源版本、apps 是资源组，这里也可以简写为 deployment 或者 deployment.apps，比如说写为 deployment 的时候，默认将使用 apps 组 v1 版本。</p>
</li>
<li><p>第三部分是要更新的 deployment 的 name，也就是我们的 nginx-deployment；再往后的 nginx 其实指的是 template，也就是 Pod 中的 container.name；这里我们可以注意到：一个 Pod 中，其实可能存在多个 container，而我们指定想要更新的镜像的 container.name，就是 nginx。</p>
</li>
<li><p>最后，指定我们这个容器期望更新的镜像版本，这里指的是 nginx: 1.9.1。如下图所示：当执行完这条命令之后，可以看到 deployment 中的 template.spec 已经更新为 nginx: 1.9.1。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/3.png/w600">

</li>
</ul>
<h3 id="快速回滚"><a href="#快速回滚" class="headerlink" title="快速回滚"></a>快速回滚</h3><p>如果我们在发布过程中遇到了问题，也支持快速回滚。通过 kubectl 执行的话，其实是“kubectl rollout undo”这个命令，可以回滚到 Deployment 上一版本；通过“rollout undo”加上“to-revision”来指定可以回滚到某一个具体的版本。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/4.png/w600">

<h3 id="DeploymeStatus"><a href="#DeploymeStatus" class="headerlink" title="DeploymeStatus"></a>DeploymeStatus</h3><p>最后我们来看一下 DeploymeStatus。前面的课程我们学习到，每一个资源都有它的 spec.Status。这里可以看一下，deploymentStatus 中描述的三个其实是它的 conversion 状态，也就是 Processing、Complete 以及 Failed。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/5.png/w600">

<p>以 Processing 为例：Processing 指的是 Deployment 正在处于扩容和发布中。比如说 Processing 状态的 deployment，它所有的 replicas 及 Pod 副本全部达到最新版本，而且是 available，这样的话，就可以进入 complete 状态。而 complete 状态如果发生了一些扩缩容的话，也会进入 processing 这个处理工作状态。</p>
<p>如果在处理过程中遇到一些问题：比如说拉镜像失败了，或者说 readiness probe 检查失败了，就会进入 failed 状态；如果在运行过程中即 complete 状态，中间运行时发生了一些 pod readiness probe 检查失败，这个时候 deployment 也会进入 failed 状态。进入 failed 状态之后，除非所有点 replicas 均变成 available，而且是 updated 最新版本，deployment 才会重新进入 complete 状态。</p>
<h1 id="三、操作演示"><a href="#三、操作演示" class="headerlink" title="三、操作演示"></a>三、操作演示</h1><h2 id="Deployment-创建及状态"><a href="#Deployment-创建及状态" class="headerlink" title="Deployment 创建及状态"></a>Deployment 创建及状态</h2><p>下面我们来进行操作演示：这里连接一个阿里云服务集群。我们可以看到当前集群已经有几个可用的 node。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls get node</span><br><span class="line">NAME          STATUS   ROLES    AGE   VERSION</span><br><span class="line">172.16.0.11   Ready    &lt;none&gt;   40d   v1.18.1</span><br><span class="line">172.16.0.15   Ready    &lt;none&gt;   40d   v1.18.1</span><br><span class="line">172.16.0.17   Ready    &lt;none&gt;   40d   v1.18.1</span><br><span class="line">172.16.0.8    Ready    &lt;none&gt;   40d   v1.18.1</span><br><span class="line">172.16.0.9    Ready    &lt;none&gt;   40d   v1.18.1</span><br></pre></td></tr></table></figure>
<p>首先创建对应的 deployment。可以看到 deployment 中的 desired、current、up-to-date 以及 available 已经都达到了可用的期望状态。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls create -f nginx-test.yaml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">$ kubectls get deployment nginx-deployment</span><br><span class="line">NAME               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   2/2     2            2           23s</span><br><span class="line"></span><br><span class="line">$ kubectls get pod</span><br><span class="line">NAME                                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">0          14d</span><br><span class="line">nginx-deployment-5bf87f5f59-m8msf         1/1     Running   0          114s</span><br><span class="line">nginx-deployment-5bf87f5f59-wgg8r         1/1     Running   0          114s</span><br></pre></td></tr></table></figure>
<h2 id="Deployment-的结构"><a href="#Deployment-的结构" class="headerlink" title="Deployment 的结构"></a>Deployment 的结构</h2><p>这里看到 spec 中的 replicas 是三个，selector 以及 template labels中定义的标签都是 app：nginx，spec 中的 image 是我们期望的 nginx: 1.7.9；status 中的 available.replicas，readReplicas 以及 updatedReplicas 都是 3 个。</p>
<h2 id="Pod-状态"><a href="#Pod-状态" class="headerlink" title="Pod 状态"></a>Pod 状态</h2><p>我们可以再选择一个 Pod 看一下状态：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">"2020-05-29T13:38:14Z"</span></span><br><span class="line">  <span class="attr">generateName:</span> <span class="string">nginx-deployment-5bf87f5f59-</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">pod-template-hash:</span> <span class="string">5bf87f5f59</span></span><br><span class="line">  <span class="attr">managedFields:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">ownerReferences:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line">    <span class="attr">blockOwnerDeletion:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nginx-deployment-5bf87f5f59</span></span><br><span class="line">    <span class="attr">uid:</span> <span class="string">64f0c2b6-2807-4e75-a47c-6e1cdc9dab6a</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">"10948296"</span></span><br><span class="line">  <span class="attr">selfLink:</span> <span class="string">/api/v1/namespaces/default/pods/nginx-deployment-5bf87f5f59-m8msf</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">3bf7d218-989f-4c20-909f-fcf0ade5a391</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>
<p>可以看到：Pod 中 ownerReferences 的功能是 ReplicaSet；pod.spec.container 里的镜像是 1.7.9。这个 Pod 已经是 Running 状态，而且它的 conditions.status 是“true”，表示它的服务已经可用了。</p>
<h2 id="更新升级"><a href="#更新升级" class="headerlink" title="更新升级"></a>更新升级</h2><p>当前只有最新版本的 replicaset，那么现在尝试对 deployment 做一次升级。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectls get replicaset -l app=nginx</span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-5bf87f5f59   2         2         2       12m</span><br></pre></td></tr></table></figure>
<p>“kubectl set image”这个操作命令，后面接 “deployment”，加 deployment.name，最后指定容器名，以及我们期望升级的镜像版本。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls <span class="built_in">set</span> image deployment nginx-deployment nginx=nginx:1.9.1</span><br><span class="line">deployment.apps/nginx-deployment image updated</span><br></pre></td></tr></table></figure>
<p>接下来我们看下 deployment 中的 template 中的 image 已经更新为 1.9.1。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls get deployment nginx-deployment -o yaml</span><br></pre></td></tr></table></figure>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.9.1</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>
<p>这个时候我们再 get pod 看一下状态。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls get pod -l app=nginx</span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-deployment-678645bf77-d5dcs   1/1     Running   0          2m35s</span><br><span class="line">nginx-deployment-678645bf77-kdtkx   1/1     Running   0          2m56s</span><br></pre></td></tr></table></figure>
<p>两个 pod 已经升级为新版本，pod 名字中的 pod-template-hash 也已更新。</p>
<p>可以看到：旧版本 replicaset 的 spec 数量以及 pod 数量是都是 0，新版本的 pod 数量是 3 个。</p>
<p>假设又做了一次更新，这个时候 get.pod 其实可以看到：当前的 pod 其实是有两个旧版本的处于 running，另一个旧版本是在删除中；而两个新版本的 pod，一个已经进入 running，一个还在 creating 中。</p>
<p>这时我们可用的 pod 数量即非删除状态的 pod 数量，其实是 4 个，已经超过了 replica 原先在 deployment 设置的数量 3 个。这个原因是我们在 deployment 中有 maxavailable 和 maxsugar 两个操作，这两个配置可以限制我们在发布过程中的一些策略。在后面架构设计中会讲到这个问题。</p>
<h2 id="历史版本保留-revisionHistoryLimit"><a href="#历史版本保留-revisionHistoryLimit" class="headerlink" title="历史版本保留 revisionHistoryLimit"></a>历史版本保留 revisionHistoryLimit</h2><p>上图看到，我们当前最新版本的 replicaset 是 3 个 pod，另外还有两个历史版本的 replicaset，那么会不会存在一种情况：就是随着 deployment 持续的更新，这个旧版本的 replicaset 会越积越多呢？其实 deployment 提供了一个机制来避免这个问题：在 deployment spec 中，有一个 revisionHistoryLimit，它的默认值为 10，它其实保证了保留历史版本的 replicaset 的数量，我们尝试把它改为 1。</p>
<p>由上面第二张图，可以看到两个 replicaset，也就是说，除了当前版本的 replicaset 之外，旧版本的 replicaset 其实只保留了一个。</p>
<h3 id="回滚"><a href="#回滚" class="headerlink" title="回滚"></a>回滚</h3><p>最后再尝试做一下回滚。首先再来看一下 replicaset，这时发现旧版本的 replicaset 数量从 0 个增到 2 个，而新版本的 replicaset 数量从 3 个削减为 1 个，表示它已经开始在做回滚的操作。然后再观察一下， 旧版本的数量已经是 3 个，即已经回滚成功，而新版本的 pod 数量变为 0 个。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls rollout undo deployment nginx-deployment</span><br><span class="line">deployment.apps/nginx-deployment rolled back</span><br><span class="line">$ kubectls get replicaset</span><br><span class="line">NAME                                DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-5bf87f5f59         2         2         2       21m</span><br><span class="line">nginx-deployment-678645bf77         0         0         0       7m18s</span><br></pre></td></tr></table></figure>
<p>我们最后再 get pod 看一下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectls get pod -l app=nginx</span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-deployment-5bf87f5f59-767bz   1/1     Running   0          2m2s</span><br><span class="line">nginx-deployment-5bf87f5f59-zwk2p   1/1     Running   0          2m</span><br></pre></td></tr></table></figure>
<p>这时，3 个 pod.template-hash 已经更新为旧版本的 hash，但其实这 3 个 pod 都是重新创建出来的，而并非我们在前一版本中创建的 3 个 pod。换句话说，也就是我们回滚的时候，其实是创建了 3 个旧版本的 pod，而并非把先前的 3 个 pod 找回来。</p>
<h1 id="四、架构设计"><a href="#四、架构设计" class="headerlink" title="四、架构设计"></a>四、架构设计</h1><h2 id="管理模式"><a href="#管理模式" class="headerlink" title="管理模式"></a>管理模式</h2><p>我们来看一下架构设计。首先简单看一下管理模式：Deployment 只负责管理不同版本的 ReplicaSet，由 ReplicaSet 来管理具体的 Pod 副本数，每个 ReplicaSet 对应 Deployment template 的一个版本。在上文的例子中可以看到，每一次修改 template，都会生成一个新的 ReplicaSet，这个 ReplicaSet 底下的 Pod 其实都是相同的版本。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/6.png/w600">
<p>如上图所示：Deployment 创建 ReplicaSet，而 ReplicaSet 创建 Pod。他们的 OwnerRef 其实都对应了其控制器的资源。</p>
<h2 id="Deployment-控制器"><a href="#Deployment-控制器" class="headerlink" title="Deployment 控制器"></a>Deployment 控制器</h2><p> 我们先简单看一下控制器实现原理。</p>
<p>首先，我们所有的控制器都是通过 Informer 中的 Event 做一些 Handler 和 Watch。这个地方 Deployment 控制器，其实是关注 Deployment 和 ReplicaSet 中的 event，收到事件后会加入到队列中。而 Deployment controller 从队列中取出来之后，它的逻辑会判断 Check Paused，这个 Paused 其实是 Deployment 是否需要新的发布，如果 Paused 设置为 true 的话，就表示这个 Deployment 只会做一个数量上的维持，不会做新的发布。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/7.png/w600">
<p>如上图，可以看到如果 Check paused 为 Yes 也就是 true 的话，那么只会做 Sync replicas。也就是说把 replicas sync 同步到对应的 ReplicaSet 中，最后再 Update Deployment status，那么 controller 这一次的 ReplicaSet 就结束了。</p>
<p>那么如果 paused 为 false 的话，它就会做 Rollout，也就是通过 Create 或者是 Rolling 的方式来做更新，更新的方式其实也是通过 Create/Update/Delete 这种 ReplicaSet 来做实现的。</p>
<h2 id="ReplicaSet-控制器"><a href="#ReplicaSet-控制器" class="headerlink" title="ReplicaSet 控制器"></a>ReplicaSet 控制器</h2><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/8.png/w600">
<p>当 Deployment 分配 ReplicaSet 之后，ReplicaSet 控制器本身也是从 Informer 中 watch 一些事件，这些事件包含了 ReplicaSet 和 Pod 的事件。从队列中取出之后，ReplicaSet controller 的逻辑很简单，就只管理副本数。也就是说如果 controller 发现 replicas 比 Pod 数量大的话，就会扩容，而如果发现实际数量超过期望数量的话，就会删除 Pod。</p>
<p>上面 Deployment 控制器的图中可以看到，Deployment 控制器其实做了更复杂的事情，包含了版本管理，而它把每一个版本下的数量维持工作交给 ReplicaSet 来做。</p>
<h2 id="扩-缩容模拟"><a href="#扩-缩容模拟" class="headerlink" title="扩/缩容模拟"></a>扩/缩容模拟</h2><p>下面来看一些操作模拟，比如说扩容模拟。这里有一个 Deployment，它的副本数是 2，对应的 ReplicaSet 有 Pod1 和 Pod2。这时如果我们修改 Deployment replicas， controller 就会把 replicas 同步到当前版本的 ReplicaSet 中，这个 ReplicaSet 发现当前有 2 个 Pod，不满足当前期望 3 个，就会创建一个新的 Pod3。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/9.png/w600">

<h2 id="发布模拟"><a href="#发布模拟" class="headerlink" title="发布模拟"></a>发布模拟</h2><p>我们再模拟一下发布，发布的情况会稍微复杂一点。这里可以看到 Deployment 当前初始的 template，比如说 template1 这个版本。template1 这个 ReplicaSet 对应的版本下有三个 Pod：Pod1，Pod2，Pod3。</p>
<p>这时修改 template 中一个容器的 image， Deployment controller 就会新建一个对应 template2 的 ReplicaSet。创建出来之后 ReplicaSet 会逐渐修改两个 ReplicaSet 的数量，比如它会逐渐增加 ReplicaSet2 中 replicas 的期望数量，而逐渐减少 ReplicaSet1 中的 Pod 数量。</p>
<p>那么最终达到的效果是：新版本的 Pod 为 Pod4、Pod5和Pod6，旧版本的 Pod 已经被删除了，这里就完成了一次发布。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/10.png/w600">

<h2 id="回滚模拟"><a href="#回滚模拟" class="headerlink" title="回滚模拟"></a>回滚模拟</h2><p>来看一下回滚模拟，根据上面的发布模拟可以知道 Pod4、Pod5、Pod6 已经发布完成。这时发现当前的业务版本是有问题的，如果做回滚的话，不管是通过 rollout 命令还是通过回滚修改 template，它其实都是把 template 回滚为旧版本的 template1。</p>
<p>这个时候 Deployment 会重新修改 ReplicaSet1 中 Pod 的期望数量，把期望数量修改为 3 个，且会逐渐减少新版本也就是 ReplicaSet2 中的 replica 数量，最终的效果就是把 Pod 从旧版本重新创建出来。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/11.png/w600">
<p>发布模拟的图中可以看到，其实初始版本中 Pod1、Pod2、Pod3 是旧版本，而回滚之后其实是 Pod7、Pod8、Pod9。就是说它的回滚并不是把之前的 Pod 重新找出来，而是说重新创建出符合旧版本 template 的 Pod。</p>
<h2 id="spec-字段解析"><a href="#spec-字段解析" class="headerlink" title="spec 字段解析"></a>spec 字段解析</h2><p>最后再来简单看一些 Deployment 中的字段解析。首先看一下 Deployment 中其他的 spec 字段：</p>
<ul>
<li><p>MinReadySeconds：Deployment 会根据 Pod ready 来看 Pod 是否可用，但是如果我们设置了 MinReadySeconds 之后，比如设置为 30 秒，那 Deployment 就一定会等到 Pod ready 超过 30 秒之后才认为 Pod 是 available 的。Pod available 的前提条件是 Pod ready，但是 ready 的 Pod 不一定是 available 的，它一定要超过 MinReadySeconds 之后，才会判断为 available；</p>
</li>
<li><p>revisionHistoryLimit：保留历史 revision，即保留历史 ReplicaSet 的数量，默认值为 10 个。这里可以设置为一个或两个，如果回滚可能性比较大的话，可以设置数量超过 10；</p>
</li>
<li><p>paused：paused 是标识，Deployment 只做数量维持，不做新的发布，这里在 Debug 场景可能会用到；</p>
</li>
<li><p>progressDeadlineSeconds：前面提到当 Deployment 处于扩容或者发布状态时，它的 condition 会处于一个 processing 的状态，processing 可以设置一个超时时间。如果超过超时时间还处于 processing，那么 controller 将认为这个 Pod 会进入 failed 的状态。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/12.png/w600">
<h2 id="升级策略字段解析"><a href="#升级策略字段解析" class="headerlink" title="升级策略字段解析"></a>升级策略字段解析</h2><p>最后来看一下升级策略字段解析。</p>
</li>
</ul>
<p>Deployment 在 RollingUpdate 中主要提供了两个策略，一个是 MaxUnavailable，另一个是 MaxSurge。这两个字段解析的意思，可以看下图中详细的 comment，或者简单解释一下：</p>
<ul>
<li>MaxUnavailable：滚动过程中最多有多少个 Pod 不可用；</li>
<li>MaxSurge：滚动过程中最多存在多少个 Pod 超过预期 replicas 数量。</li>
</ul>
<p>上文提到，ReplicaSet 为 3 的 Deployment 在发布的时候可能存在一种情况：新版本的 ReplicaSet 和旧版本的 ReplicaSet 都可能有两个 replicas，加在一起就是 4 个，超过了我们期望的数量三个。这是因为我们默认的 MaxUnavailable 和 MaxSurge 都是 25%，默认 Deployment 在发布的过程中，可能有 25% 的 replica 是不可用的，也可能超过 replica 数量 25% 是可用的，最高可以达到 125% 的 replica 数量。</p>
<p>这里其实可以根据用户实际场景来做设置。比如当用户的资源足够，且更注重发布过程中的可用性，可设置 MaxUnavailable 较小、MaxSurge 较大。但如果用户的资源比较紧张，可以设置 MaxSurge 较小，甚至设置为 0，这里要注意的是 MaxSurge 和 MaxUnavailable 不能同时为 0。</p>
<p>理由不难理解，当 MaxSurge 为 0 的时候，必须要删除 Pod，才能扩容 Pod；如果不删除 Pod 是不能新扩 Pod 的，因为新扩出来的话，总共的 Pod 数量就会超过期望数量。而两者同时为 0 的话，MaxSurge 保证不能新扩 Pod，而 MaxUnavailable 不能保证 ReplicaSet 中有 Pod 是 available 的，这样就会产生问题。所以说这两个值不能同时为 0。用户可以根据自己的实际场景来设置对应的、合适的值。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-deployment/13.png/w600">

<h1 id="本节总结"><a href="#本节总结" class="headerlink" title="本节总结"></a>本节总结</h1><p>本节课的主要内容就到此为止了，这里为大家简单总结一下。</p>
<div class="note primary">
            <ul><li>Deployment 是 Kubernetes 中常见的一种 Workload，支持部署管理多版本的 Pod；</li><li>Deployment 管理多版本的方式，是针对每个版本的 template 创建一个 ReplicaSet，由 ReplicaSet 维护一定数量的 Pod 副本，而 Deployment 只需要关心不同版本的 ReplicaSet 里要指定多少数量的 Pod；</li><li>因此，Deployment 发布部署的根本原理，就是 Deployment 调整不同版本 ReplicaSet 里的终态副本数，以此来达到多版本 Pod 的升级和回滚。</li></ul>
          </div>
]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(七)——应用编排与管理：Job 和 DaemonSet</title>
    <url>/cn/k8s%E5%BA%94%E7%94%A8%E7%BC%96%E6%8E%92%E4%B8%8E%E7%AE%A1%E7%90%86Job%E5%92%8CDaemonSet/</url>
    <content><![CDATA[<p>本文将主要分享以下四方面的内容：</p>
<div class="note primary">
            <ul><li>Job &amp; CronJobs 基础操作与概念解析；</li><li>DaemonSet 基础操作与概念解析。</li></ul>
          </div>

<a id="more"></a>
<h1 id="一、Job"><a href="#一、Job" class="headerlink" title="一、Job"></a>一、Job</h1><h2 id="需求来源"><a href="#需求来源" class="headerlink" title="需求来源"></a>需求来源</h2><h2 id="Job-背景问题"><a href="#Job-背景问题" class="headerlink" title="Job 背景问题"></a>Job 背景问题</h2><p>首先我们来看一下 Job 的需求来源。我们知道 K8s 里面，最小的调度单元是 Pod，我们可以直接通过 Pod 来运行任务进程。这样做将会产生以下几种问题：</p>
<ul>
<li>我们如何保证 Pod 内进程正确的结束？</li>
<li>如何保证进程运行失败后重试？</li>
<li>如何管理多个任务，且任务之间有依赖关系？</li>
<li>如何并行地运行任务，并管理任务的队列大小？</li>
</ul>
<h2 id="Job：管理任务的控制器"><a href="#Job：管理任务的控制器" class="headerlink" title="Job：管理任务的控制器"></a>Job：管理任务的控制器</h2><p>我们来看一下 Kubernetes 的 Job 为我们提供了什么功能：</p>
<ul>
<li>首先 kubernetes 的 Job 是一个管理任务的控制器，它可以创建一个或多个 Pod 来指定 Pod 的数量，并可以监控它是否成功地运行或终止；</li>
<li>我们可以根据 Pod 的状态来给 Job 设置重置的方式及重试的次数；</li>
<li>我们还可以根据依赖关系，保证上一个任务运行完成之后再运行下一个任务；</li>
<li>同时还可以控制任务的并行度，根据并行度来确保 Pod 运行过程中的并行次数和总体完成大小。</li>
</ul>
<h2 id="用例解读"><a href="#用例解读" class="headerlink" title="用例解读"></a>用例解读</h2><p>我们根据一个实例来看一下Job是如何来完成下面的应用的。</p>
<h3 id="Job-语法"><a href="#Job-语法" class="headerlink" title="Job 语法"></a>Job 语法</h3><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">perl</span></span><br><span class="line">        <span class="attr">command:</span> <span class="string">["perl",</span> <span class="string">"-Mbignum=bpi"</span><span class="string">,</span> <span class="string">"-wle"</span><span class="string">,</span> <span class="string">"print bpi(2000)"</span><span class="string">]</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>上图是 Job 最简单的一个 yaml 格式，这里主要新引入了一个 kind 叫 Job，这个 Job 其实就是 job-controller 里面的一种类型。 然后 metadata 里面的 name 来指定这个 Job 的名称，下面 spec.template 里面其实就是 pod 的 spec。</p>
<p>这里面的内容都是一样的，唯一多了两个点：</p>
<ul>
<li>第一个是 restartPolicy，在 Job 里面我们可以设置 Never、OnFailure、Always 这三种重试策略。在希望 Job 需要重新运行的时候，我们可以用 Never；希望在失败的时候再运行，再重试可以用 OnFailure；或者不论什么情况下都重新运行时 Alway；</li>
<li>另外，Job 在运行的时候不可能去无限的重试，所以我们需要一个参数来控制重试的次数。这个 backoffLimit 就是来保证一个 Job 到底能重试多少次。</li>
</ul>
<p>所以在 Job 里面，我们主要重点关注的一个是 <strong>restartPolicy 重启策略</strong>和 <strong>backoffLimit 重试次数限制</strong>。</p>
<h3 id="Job-状态"><a href="#Job-状态" class="headerlink" title="Job 状态"></a>Job 状态</h3><p>Job 创建完成之后，我们就可以通过 kubectl get jobs 这个命令，来查看当前 job 的运行状态。得到的值里面，基本就有 Job 的名称、当前完成了多少个 Pod，进行多长时间。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls create -f job-test.yaml </span><br><span class="line">job.batch/pi created</span><br><span class="line">$ kubectls get <span class="built_in">jobs</span></span><br><span class="line">NAME   COMPLETIONS   DURATION   AGE</span><br><span class="line">pi     1/1           70s        79s</span><br></pre></td></tr></table></figure>

<p>AGE: 的含义是指这个 Pod 从当前时间算起，减去它当时创建的时间。这个时长主要用来告诉你 Pod 的历史、Pod 距今创建了多长时间。<br>DURATION: 主要来看我们 Job 里面的实际业务到底运行了多长时间，当我们的性能调优的时候，这个参数会非常的有用。<br>COMPLETIONS: 主要来看我们任务里面这个 Pod 一共有几个，然后它其中完成了多少个状态，会在这个字段里面做显示。</p>
<h3 id="查看-Pod"><a href="#查看-Pod" class="headerlink" title="查看 Pod"></a>查看 Pod</h3><p>下面我们来看一下 Pod，其实 Job 最后的执行单元还是 Pod。我们刚才创建的 Job 会创建出来一个叫“pi”的一个 Pod，这个任务就是来计算这个圆周率，Pod 的名称会以“${job-name}-${random-suffix}”，我们可以看一下下面 Pod 的 yaml 格式。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls get pod pi-tklk5 -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: <span class="string">"2020-05-29T15:02:36Z"</span></span><br><span class="line">  generateName: pi-</span><br><span class="line">  labels:</span><br><span class="line">    controller-uid: 1026b056-3763-4e66-bd76-cbff0c0c2373</span><br><span class="line">    job-name: pi</span><br><span class="line">  - apiVersion: v1</span><br><span class="line">    fieldsType: FieldsV1</span><br><span class="line">  name: pi-tklk5</span><br><span class="line">  namespace: default</span><br><span class="line">  ownerReferences:</span><br><span class="line">  - apiVersion: batch/v1</span><br><span class="line">    blockOwnerDeletion: <span class="literal">true</span></span><br><span class="line">    controller: <span class="literal">true</span></span><br><span class="line">    kind: Job</span><br><span class="line">    name: pi</span><br><span class="line">    uid: 1026b056-3763-4e66-bd76-cbff0c0c2373</span><br><span class="line">  resourceVersion: <span class="string">"10966250"</span></span><br><span class="line">  selfLink: /api/v1/namespaces/default/pods/pi-tklk5</span><br><span class="line">  uid: 05892782-464d-423b-8fbc-bfdd50166d8e</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - <span class="built_in">command</span>:</span><br><span class="line">    - perl</span><br><span class="line">    - -Mbignum=bpi</span><br><span class="line">    - -wle</span><br><span class="line">    - <span class="built_in">print</span> bpi(2000)</span><br><span class="line">    image: perl</span><br><span class="line">    imagePullPolicy: Always</span><br><span class="line">    name: pi</span><br><span class="line">    resources: &#123;&#125;</span><br><span class="line">    terminationMessagePath: /dev/termination-log</span><br><span class="line">    terminationMessagePolicy: File</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">      name: default-token-p5kwl</span><br><span class="line">      readOnly: <span class="literal">true</span></span><br><span class="line">  dnsPolicy: ClusterFirst</span><br><span class="line">  enableServiceLinks: <span class="literal">true</span></span><br><span class="line">  nodeName: 172.16.0.17</span><br><span class="line">  restartPolicy: Never</span><br><span class="line">  schedulerName: default-scheduler</span><br><span class="line">  securityContext: &#123;&#125;</span><br><span class="line">  serviceAccount: default</span><br><span class="line">  serviceAccountName: default</span><br><span class="line">  terminationGracePeriodSeconds: 30</span><br><span class="line">  volumes:</span><br><span class="line">  - name: default-token-p5kwl</span><br><span class="line">    secret:</span><br><span class="line">      defaultMode: 420</span><br><span class="line">      secretName: default-token-p5kwl</span><br><span class="line">  hostIP: 172.16.0.17</span><br><span class="line">  phase: Succeeded</span><br><span class="line">  podIP: 172.18.25.4</span><br><span class="line">  podIPs:</span><br><span class="line">  - ip: 172.18.25.4</span><br><span class="line">  qosClass: BestEffort</span><br><span class="line">  startTime: <span class="string">"2020-05-29T15:02:36Z"</span></span><br></pre></td></tr></table></figure>

<p>它比普通的 Pod 多了一个叫 ownerReferences，这个东西来声明此 pod 是归哪个上一层 controller 来管理。可以看到这里的 ownerReferences 是归 batch/v1，也就是上一个 Job 来管理的。这里就声明了它的 controller 是谁，然后可以通过 pod 返查到它的控制器是谁，同时也能根据 Job 来查一下它下属有哪些 Pod。</p>
<h3 id="并行运行-Job"><a href="#并行运行-Job" class="headerlink" title="并行运行 Job"></a>并行运行 Job</h3><p>我们有时候有些需求：希望 Job 运行的时候可以最大化的并行，并行出 n 个 Pod 去快速地执行。同时，由于我们的节点数有限制，可能也不希望同时并行的 Pod 数过多，有那么一个管道的概念，我们可以希望最大的并行度是多少，Job 控制器都可以帮我们来做到。</p>
<p>这里主要看两个参数：一个是 <strong>completions</strong>，一个是 <strong>parallelism</strong>。</p>
<ul>
<li>首先第一个参数是用来指定本 Pod 队列执行次数。可能这个不是很好理解，其实可以把它认为是这个 Job 指定的可以运行的总次数。比如这里设置成 8，即这个任务一共会被执行 8 次；</li>
<li>第二个参数代表这个并行执行的个数。所谓并行执行的次数，其实就是一个管道或者缓冲器中缓冲队列的大小，把它设置成 2，也就是说这个 Job 一定要执行 8 次，每次并行 2 个 Pod，这样的话，一共会执行 4 个批次。</li>
</ul>
<h3 id="查看并行-Job-运行"><a href="#查看并行-Job-运行" class="headerlink" title="查看并行 Job 运行"></a>查看并行 Job 运行</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls get <span class="built_in">jobs</span></span><br><span class="line">NAME      COMPLETIONS   DURATION   AGE</span><br><span class="line">paral-1   8/8           2m19s      9m13s</span><br><span class="line"></span><br><span class="line">$ kubectls get pods</span><br><span class="line">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class="line">paral-1-44zf7                             0/1     Completed   0          7m3s</span><br><span class="line">paral-1-6xjcz                             0/1     Completed   0          5m55s</span><br><span class="line">paral-1-bwbfb                             0/1     Completed   0          5m56s</span><br><span class="line">paral-1-dk8dq                             0/1     Completed   0          6m29s</span><br><span class="line">paral-1-fj6rg                             0/1     Completed   0          7m2s</span><br><span class="line">paral-1-g6knn                             0/1     Completed   0          7m40s</span><br><span class="line">paral-1-pljvm                             0/1     Completed   0          7m40s</span><br><span class="line">paral-1-twpd6                             0/1     Completed   0          6m30s</span><br></pre></td></tr></table></figure>
<p>下面来看一下它的实际运行效果，上图就是当这个 Job 整体运行完毕之后可以看到的效果，首先看到 job 的名字，然后看到它一共创建出来了 8 个 pod，执行了 2 分 23 秒，这是创建的时间。</p>
<p>接着来看真正的 pods，pods 总共出来了 8 个 pod，每个 pod 的状态都是完成的，然后来看一下它的 AGE，就是时间。从下往上看，可以看到分别有 73s、40s、110s 和 2m26s。每一组都有两个 pod 时间是相同的，即：时间段是 40s 的时候是最后一个创建、 2m26s 是第一个创建的。也就是说，总是两个 pod 同时创建出来，并行完毕、消失，然后再创建、再运行、再完毕。</p>
<p>比如说，刚刚我们其实通过第二个参数来控制了当前 Job 并行执行的次数，这里就可以了解到这个缓冲器或者说管道队列大小的作用。</p>
<h3 id="Cronjob-语法"><a href="#Cronjob-语法" class="headerlink" title="Cronjob 语法"></a>Cronjob 语法</h3><p>下面来介绍另外一个 Job，叫做 CronJob，其实也可以叫定时运行 Job。CronJob 其实和 Job 大体是相似的，唯一的不同点就是它可以设计一个时间。比如说可以定时在几点几分执行，特别适合晚上做一些清理任务，还有可以几分钟执行一次，几小时执行一次等等，这就叫定时任务。</p>
<p>定时任务和 Job 相比会多几个不同的字段：</p>
<ul>
<li><p>schedule：schedule 这个字段主要是设置时间格式，它的时间格式和 Linux 的 crontime 是一样的，所以直接根据 Linux 的 crontime 书写格式来书写就可以了。举个例子： */1 指每分钟去执行一下 Job，这个 Job 需要做的事情就是打印出大约时间，然后打印出“Hello from the kubernetes cluster” 这一句话；</p>
</li>
<li><p>startingDeadlineSeconds：即：每次运行 Job 的时候，它最长可以等多长时间，有时这个 Job 可能运行很长时间也不会启动。所以这时，如果超过较长时间的话，CronJob 就会停止这个 Job；</p>
</li>
<li><p>concurrencyPolicy：就是说是否允许并行运行。所谓的并行运行就是，比如说我每分钟执行一次，但是这个 Job 可能运行的时间特别长，假如两分钟才能运行成功，也就是第二个 Job 要到时间需要去运行的时候，上一个 Job 还没完成。如果这个 policy 设置为 true 的话，那么不管你前面的 Job 是否运行完成，每分钟都会去执行；如果是 false，它就会等上一个 Job 运行完成之后才会运行下一个；</p>
</li>
<li><p>JobsHistoryLimit：这个就是每一次 CronJob 运行完之后，它都会遗留上一个 Job 的运行历史、查看时间。当然这个额不能是无限的，所以需要设置一下历史存留数，一般可以设置默认 10 个或 100 个都可以，这主要取决于每个人集群不同，然后根据每个人的集群数来确定这个时间。</p>
</li>
</ul>
<h2 id="操作演示"><a href="#操作演示" class="headerlink" title="操作演示"></a>操作演示</h2><h3 id="Job-的编排文件"><a href="#Job-的编排文件" class="headerlink" title="Job 的编排文件"></a>Job 的编排文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ cat job-test.yaml</span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: pi</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: pi</span><br><span class="line">        image: perl</span><br><span class="line">        <span class="built_in">command</span>: [<span class="string">"perl"</span>, <span class="string">"-Mbignum=bpi"</span>, <span class="string">"-wle"</span>, <span class="string">"print bpi(2000)"</span>]</span><br><span class="line">      restartPolicy: Never</span><br><span class="line">  backoffLimit: 4</span><br></pre></td></tr></table></figure>

<p>下面看一下具体如何使用 Job。</p>
<h3 id="Job-的创建及运行验证"><a href="#Job-的创建及运行验证" class="headerlink" title="Job 的创建及运行验证"></a>Job 的创建及运行验证</h3><p>首先看一下 job.yaml。这是一个非常简单的计算 pi 的一个任务。使用 kubectl creat-f job.yaml，这样 job 就能提交成功了。来看一下 kubectl.get.jobs，可以看到这个 job 正在运行；get pods 可以看到这个 pod 应该是运行完成了，那么接下来 logs 一下这个 job 以及 pod。可以看到下图里面打印出来了圆周率。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls create -f job-test.yaml </span><br><span class="line">job.batch/pi created</span><br><span class="line">$ kubectls get <span class="built_in">jobs</span></span><br><span class="line">NAME   COMPLETIONS   DURATION   AGE</span><br><span class="line">pi     1/1           22s        30s</span><br><span class="line">$ kubectls get pods</span><br><span class="line">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class="line">pi-ttskc                                  0/1     Completed   0          58s</span><br><span class="line">$ kubectls logs pi-ttskc</span><br><span class="line">3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901</span><br></pre></td></tr></table></figure>

<h3 id="并行-Job-的编排文件"><a href="#并行-Job-的编排文件" class="headerlink" title="并行 Job 的编排文件"></a>并行 Job 的编排文件</h3><p>下面再来看第二个例子：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">paral-1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">completions:</span> <span class="number">8</span></span><br><span class="line">  <span class="attr">parallelism:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">paral</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">ubuntu</span></span><br><span class="line">        <span class="attr">command:</span> <span class="string">["/bin/sh"]</span></span><br><span class="line">        <span class="attr">args:</span> <span class="string">["-c",</span> <span class="string">"sleep 30; date"</span><span class="string">]</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br></pre></td></tr></table></figure>
<h3 id="并行-Job-的创建及运行验证"><a href="#并行-Job-的创建及运行验证" class="headerlink" title="并行 Job 的创建及运行验证"></a>并行 Job 的创建及运行验证</h3><p>这个例子就是指刚才的并行运行 Job 创建之后，可以看到有第二个并行的 Job。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls create -f job-more-test.yaml </span><br><span class="line">job.batch/paral-1 created</span><br><span class="line">$ kubectls get <span class="built_in">jobs</span></span><br><span class="line">NAME      COMPLETIONS   DURATION   AGE</span><br><span class="line">paral-1   0/8           21s        21s</span><br><span class="line">pi        1/1           22s        9h</span><br></pre></td></tr></table></figure>

<p>现在已经有两个 Pod 正在 running，可以看到它大概执行了快到 30s</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectls get pods</span><br><span class="line">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class="line">paral-1-g6knn                             1/1     Running     0          34s</span><br><span class="line">paral-1-pljvm                             1/1     Running     0          34s</span><br></pre></td></tr></table></figure>

<p>30s 之后它应该会起第二个。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectls get pods</span><br><span class="line">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class="line">paral-1-dk8dq                             1/1     Running     0          8s</span><br><span class="line">paral-1-g6knn                             0/1     Completed   0          79s</span><br><span class="line">paral-1-pljvm                             0/1     Completed   0          79s</span><br><span class="line">paral-1-twpd6                             1/1     Running     0          9s</span><br></pre></td></tr></table></figure>

<p>第一批的 pod 已经执行完毕，第二批的 pod 正在 running，每批次分别是两个Pod。也就是说后面每隔 40s 左右，就会有两个 pod 在并行执行，它一共会执行 4 批，共 8 个 pod，等到所有的 pod 执行完毕，就是刚才所说的并行执行的缓冲队列功能。</p>
<p>过一段时间再看这个 pods，可以发现第二批已经执行结束，接下来开始创建第三批······</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectls get pods</span><br><span class="line">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class="line">paral-1-44zf7                             0/1     Completed   0          7m3s</span><br><span class="line">paral-1-6xjcz                             0/1     Completed   0          5m55s</span><br><span class="line">paral-1-bwbfb                             0/1     Completed   0          5m56s</span><br><span class="line">paral-1-dk8dq                             0/1     Completed   0          6m29s</span><br><span class="line">paral-1-fj6rg                             0/1     Completed   0          7m2s</span><br><span class="line">paral-1-g6knn                             0/1     Completed   0          7m40s</span><br><span class="line">paral-1-pljvm                             0/1     Completed   0          7m40s</span><br><span class="line">paral-1-twpd6                             0/1     Completed   0          6m30s</span><br></pre></td></tr></table></figure>
<h3 id="Cronjob-的编排文件"><a href="#Cronjob-的编排文件" class="headerlink" title="Cronjob 的编排文件"></a>Cronjob 的编排文件</h3><p>下面来看第三个例子 —— CronJob。 CronJob 是每分钟执行一次，每次一个 job。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ cat cron-test.yaml </span><br><span class="line">apiVersion: batch/v1beta1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line">spec:</span><br><span class="line">  schedule: <span class="string">"*/1 * * * *"</span></span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">          - name: hello</span><br><span class="line">            image: busybox</span><br><span class="line">            args:</span><br><span class="line">            - /bin/sh</span><br><span class="line">            - -c</span><br><span class="line">            - date; <span class="built_in">echo</span> Hello from theKubernetes cluster</span><br><span class="line">          restartPolicy: OnFailure</span><br><span class="line">  startingDeadlineSeconds: 10</span><br><span class="line">  concurrencyPolicy: Allow</span><br><span class="line">  successfulJobsHistoryLimit: 3</span><br></pre></td></tr></table></figure>
<p>Cronjob 的创建及运行验证</p>
<p>如下 CronJob 已经创建了，可以通过 get cronjob 来看到当前有一个 CronJob，这个时候再来看 jobs，由于它是每分钟执行一次，所以得稍微等一下。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls create -f cron-test.yaml </span><br><span class="line">cronjob.batch/hello created</span><br><span class="line">$ kubectls get cronjobs</span><br><span class="line">NAME    SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE</span><br><span class="line">hello   */1 * * * *   False     0        &lt;none&gt;          13s</span><br><span class="line">$ kubectls get <span class="built_in">jobs</span></span><br><span class="line">NAME        COMPLETIONS   DURATION   AGE</span><br><span class="line">paral-1     6/8           104s       104s</span><br></pre></td></tr></table></figure>

<p>同时可以看到，上一个 job 还在运行，它的时间是 2m12s 左右，它的完成度是 7/8、6/8，刚刚看到 7/8 到 8/8，也就是说我们上一个任务执行了最后一步，而且每次都是两个两个地去运行。每次两个运行的 job 都会让我们在运行一些大型工作流或者工作任务的时候感到特别的方便。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls get <span class="built_in">jobs</span></span><br><span class="line">NAME               COMPLETIONS   DURATION   AGE</span><br><span class="line">hello-1590802920   1/1           5s         87s</span><br></pre></td></tr></table></figure>
<p>上图中可以看到突然出现了一个 job，“hello-xxxx”这个 job 就是刚才所说的 CronJob。它距离刚才 CronJob 提交已经过去 1 分钟了，这样就会自动创建出来一个 job，如果不去干扰它的话，它以后大概每一分钟都会创建出来这么一个 job，除非等我们什么时候指定它不可以再运行的时候它才会停止创建。</p>
<p>在这里 CronJob 其实主要是用来运作一些清理任务或者说执行一些定时任务。比如说 Jenkins 构建等方面的一些任务，会特别有效。</p>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><h3 id="Job-管理模式"><a href="#Job-管理模式" class="headerlink" title="Job 管理模式"></a>Job 管理模式</h3><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-job/1.png/w600">

<p>我们来看一下 job 的架构设计。Job Controller 其实还是主要去创建相对应的 pod，然后 Job Controller 会去跟踪 Job 的状态，及时地根据我们提交的一些配置重试或者继续创建。同时我们刚刚也提到，每个 pod 会有它对应的 label，来跟踪它所属的 Job Controller，并且还去配置并行的创建， 并行或者串行地去创建 pod。</p>
<h3 id="Job-控制器"><a href="#Job-控制器" class="headerlink" title="Job 控制器"></a>Job 控制器</h3><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-job/2.png/w600">

<p>上图是一个 Job 控制器的主要流程。所有的 job 都是一个 controller，它会 watch 这个 API Server，我们每次提交一个 Job 的 yaml 都会经过 api-server 传到 ETCD 里面去，然后 Job Controller 会注册几个 Handler，每当有添加、更新、删除等操作的时候，它会通过一个内存级的消息队列，发到 controller 里面。</p>
<p>通过 Job Controller 检查当前是否有运行的 pod，如果没有的话，通过 Scale up 把这个 pod 创建出来；如果有的话，或者如果大于这个数，对它进行 Scale down，如果这时 pod 发生了变化，需要及时 Update 它的状态。</p>
<p>同时要去检查它是否是并行的 job，或者是串行的 job，根据设置的配置并行度、串行度，及时地把 pod 的数量给创建出来。最后，它会把 job 的整个的状态更新到 API Server 里面去，这样我们就能看到呈现出来的最终效果了。</p>
<h1 id="二、DaemonSet"><a href="#二、DaemonSet" class="headerlink" title="二、DaemonSet"></a>二、DaemonSet</h1><h2 id="需求来源-1"><a href="#需求来源-1" class="headerlink" title="需求来源"></a>需求来源</h2><h2 id="DaemonSet-背景问题"><a href="#DaemonSet-背景问题" class="headerlink" title="DaemonSet 背景问题"></a>DaemonSet 背景问题</h2><p>下面介绍第二个控制器：DaemonSet。同样的问题：如果我们没有 DaemonSet 会怎么样？下面有几个需求：</p>
<ul>
<li>首先如果希望每个节点都运行同样一个 pod 怎么办？</li>
<li>如果新节点加入集群的时候，想要立刻感知到它，然后去部署一个 pod，帮助我们初始化一些东西，这个需求如何做？</li>
<li>如果有节点退出的时候，希望对应的 pod 会被删除掉，应该怎么操作？</li>
<li>如果 pod 状态异常的时候，我们需要及时地监控这个节点异常，然后做一些监控或者汇报的一些动作，那么这些东西运用什么控制器来做？</li>
</ul>
<h2 id="DaemonSet：守护进程控制器"><a href="#DaemonSet：守护进程控制器" class="headerlink" title="DaemonSet：守护进程控制器"></a>DaemonSet：守护进程控制器</h2><p>DaemonSet 也是 Kubernetes 提供的一个 default controller，它实际是做一个守护进程的控制器，它能帮我们做到以下几件事情：</p>
<ul>
<li>首先能保证集群内的每一个节点都运行一组相同的 pod；</li>
<li>同时还能根据节点的状态保证新加入的节点自动创建对应的 pod；</li>
<li>在移除节点的时候，能删除对应的 pod；</li>
<li>而且它会跟踪每个 pod 的状态，当这个 pod 出现异常、Crash 掉了，会及时地去 recovery 这个状态。</li>
</ul>
<h2 id="用例解读-1"><a href="#用例解读-1" class="headerlink" title="用例解读"></a>用例解读</h2><h3 id="DaemonSet-语法"><a href="#DaemonSet-语法" class="headerlink" title="DaemonSet 语法"></a>DaemonSet 语法</h3><p>下面举个例子来看一下，DaemonSet.yaml 会稍微长一些。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-daemon/1.png/w600">

<p>首先是 kind:DaemonSet。如果前面学过 deployment 后，其实我们再看这个 yaml 会比较简单。例如它会有 matchLabel，通过 matchLabel 去管理对应所属的 pod，这个 pod.label 也要和这个 DaemonSet.controller.label 想匹配，它才能去根据 label.selector 去找到对应的管理 Pod。下面 spec.container 里面的东西都是一致的。</p>
<p>这里用 fluentd 来做例子。DaemonSet 最常用的点在于以下几点内容：</p>
<ul>
<li><p>首先是存储，GlusterFS 或者 Ceph 之类的东西，需要每台节点上都运行一个类似于 Agent 的东西，DaemonSet 就能很好地满足这个诉求；</p>
</li>
<li><p>另外，对于日志收集，比如说 logstash 或者 fluentd，这些都是同样的需求，需要每台节点都运行一个 Agent，这样的话，我们可以很容易搜集到它的状态，把各个节点里面的信息及时地汇报到上面；</p>
</li>
<li><p>还有一个就是，需要每个节点去运行一些监控的事情，也需要每个节点去运行同样的事情，比如说 Promethues 这些东西，也需要 DaemonSet 的支持。</p>
</li>
</ul>
<h3 id="查看-DaemonSet-状态"><a href="#查看-DaemonSet-状态" class="headerlink" title="查看 DaemonSet 状态"></a>查看 DaemonSet 状态</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls get ds -n kube-system</span><br><span class="line">NAME                    DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">fluentd-elasticsearch   5         5         5       5            5           &lt;none&gt;          117s</span><br><span class="line"></span><br><span class="line">$ kubectls get pods -n kube-system</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">fluentd-elasticsearch-6fszd   1/1     Running   0          3m21s</span><br><span class="line">fluentd-elasticsearch-9kfvv   1/1     Running   0          3m21s</span><br><span class="line">fluentd-elasticsearch-dvl9t   1/1     Running   0          3m21s</span><br><span class="line">fluentd-elasticsearch-l4zq4   1/1     Running   0          3m21s</span><br><span class="line">fluentd-elasticsearch-tzh4t   1/1     Running   0          3m21s</span><br></pre></td></tr></table></figure>

<p>创建完 DaemonSet 之后，我们可以使用 kubectl get DaemonSet（DaemonSet 缩写为 ds）。可以看到 DaemonSet 返回值和 deployment 特别像，即它当前一共有正在运行的几个，然后我们需要几个，READY 了几个。当然这里面，READY 都是只有 Pod，所以它最后创建出来所有的都是 pod。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-daemon/2.png/w600">

<p>这里有几个参数，分别是：</p>
<ul>
<li>DESIRED: 需要的 pod 个数、</li>
<li>CURRENT: 当前已经创建的 pod 个数、</li>
<li>READY: 就绪的个数，</li>
<li>AVAILABLE: 以及所有可用的、通过健康检查的 pod</li>
<li>UP-TO-DATE: 最新创建的pod个数；</li>
<li>还有 NODE SELECTOR，因为 NODE SELECTOR 在 DaemonSet 里面非常有用。有时候我们可能希望只有部分节点去运行这个 pod 而不是所有的节点，所以有些节点上被打了标的话，DaemonSet 就只运行在这些节点上。比如，我只希望 master 节点运行某些 pod，或者只希望 Worker 节点运行某些 pod，就可以使用这个 NODE SELECTOR。</li>
</ul>
<h3 id="更新-DaemonSet"><a href="#更新-DaemonSet" class="headerlink" title="更新 DaemonSet"></a>更新 DaemonSet</h3><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-daemon/3.png/w600">
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls <span class="built_in">set</span> image ds/fluentd-elasticsearch fluentd-elasticsearch=fluent/fluentd:v1.4</span><br><span class="line">daemonset.apps/fluentd-elasticsearch image updated</span><br><span class="line"></span><br><span class="line">$ kubectls rollout status ds/fluentd-elasticsearch -n kube-system</span><br><span class="line">daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> successfully rolled out</span><br></pre></td></tr></table></figure>
<p>其实 DaemonSet 和 deployment 特别像，它也有两种更新策略：一个是 <strong>RollingUpdate</strong>，另一个是 <strong>OnDelete</strong>。</p>
<ul>
<li><p>RollingUpdate 其实比较好理解，就是会一个一个的更新。先更新第一个 pod，然后老的 pod 被移除，通过健康检查之后再去见第二个 pod，这样对于业务上来说会比较平滑地升级，不会中断；</p>
</li>
<li><p>OnDelete 其实也是一个很好的更新策略，就是模板更新之后，pod 不会有任何变化，需要我们手动控制。我们去删除某一个节点对应的 pod，它就会重建，不删除的话它就不会重建，这样的话对于一些我们需要手动控制的特殊需求也会有特别好的作用。</p>
</li>
</ul>
<h2 id="操作演示-1"><a href="#操作演示-1" class="headerlink" title="操作演示"></a>操作演示</h2><h2 id="DaemonSet-的编排"><a href="#DaemonSet-的编排" class="headerlink" title="DaemonSet 的编排"></a>DaemonSet 的编排</h2><p>下面举一个例子。比如说我们去改了些 DaemonSet 的镜像，然后看到了它的状态，它就会去一个一个地更新。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">fluentd-logging</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">fluent/fluentd:v1.4-1</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br></pre></td></tr></table></figure>
<p>上图这个就是刚才 DaemonSet 的 yaml，会比刚才会多一些， 我们做一些资源的限制，这个都不影响。</p>
<h3 id="DaemonSet-的创建与运行验证"><a href="#DaemonSet-的创建与运行验证" class="headerlink" title="DaemonSet 的创建与运行验证"></a>DaemonSet 的创建与运行验证</h3><p>下面我们创建一下 DaemonSet ，然后再看一下它的状态。下图就是我们刚才看到的 DaemonSet 在 ready 里打出来的状态。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls create -f daemonset-test.yaml </span><br><span class="line">daemonset.apps/fluentd-elasticsearch created</span><br><span class="line"></span><br><span class="line">$ kubectls get ds</span><br><span class="line">NAME                    DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">fluentd-elasticsearch   5         5         5       5            5           &lt;none&gt;          10s</span><br></pre></td></tr></table></figure>
<p>从下图中可以看到，一共有 5 个 pod 被创建出来。为什么是 5 个 pod呢？因为只有 5 个节点，所以每个节点上都会运行一个对应的 pod。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectls get pods</span><br><span class="line">NAME                                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">fluentd-elasticsearch-8t4vl               1/1     Running   0          82s</span><br><span class="line">fluentd-elasticsearch-9tb8q               1/1     Running   0          82s</span><br><span class="line">fluentd-elasticsearch-pfghj               1/1     Running   0          82s</span><br><span class="line">fluentd-elasticsearch-r4wfx               1/1     Running   0          82s</span><br><span class="line">fluentd-elasticsearch-wkkx4               1/1     Running   0          82s</span><br></pre></td></tr></table></figure>
<h3 id="DaemonSet-的更新"><a href="#DaemonSet-的更新" class="headerlink" title="DaemonSet 的更新"></a>DaemonSet 的更新</h3><p>这时，我们来更新 DaemonSet， 执行完了kubectl apply -f 后，它的 DaemonSet 就已经更新了。接下来我们去查看 DaemonSet 的更新状态。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectls rollout status ds/fluentd-elasticsearch</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 2 out of 5 new pods have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 2 out of 5 new pods have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 3 out of 5 new pods have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 3 out of 5 new pods have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 3 out of 5 new pods have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 4 out of 5 new pods have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 4 out of 5 new pods have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 4 out of 5 new pods have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> rollout to finish: 4 of 5 updated pods are available...</span><br><span class="line">daemon <span class="built_in">set</span> <span class="string">"fluentd-elasticsearch"</span> successfully rolled out</span><br></pre></td></tr></table></figure>
<p>可以看到：DaemonSet 默认这个是 RollingUpdate 的，我们看到是 0-5，现在是 1-5，也就是说它在更新第一个，第一个更新完成会去更新第二个，第二个更新完，就更新第三个······这个就是 RollingUpdate。RollingUpdate 可以做到全自动化的更新，不用有人值守，而是一个一个地去自动更新，更新的过程也比较平滑，这样可以有利于我们在现场发布或者做一些其他操作。</p>
<p>结尾处可以看到，整个的 DaemonSet 已经 RollingUpdate 完毕。</p>
<h2 id="架构设计-1"><a href="#架构设计-1" class="headerlink" title="架构设计"></a>架构设计</h2><h3 id="DaemonSet-管理模式"><a href="#DaemonSet-管理模式" class="headerlink" title="DaemonSet 管理模式"></a>DaemonSet 管理模式</h3><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-daemon/4.png/w600">

<p>接下来看一下 DaemonSet 架构设计。DaemonSet 还是一个 controller，它最后真正的业务单元也是 Pod，DaemonSet 其实和 Job controller 特别相似，它也是通过 controller 去 watch API Server 的状态，然后及时地添加 pod。唯一不同的是，它会监控节点的状态，节点新加入或者消失的时候会在节点上创建对应的 pod，然后同时根据你配置的一些 affinity 或者 label 去选择对应的节点。</p>
<h3 id="DaemonSet-控制器"><a href="#DaemonSet-控制器" class="headerlink" title="DaemonSet 控制器"></a>DaemonSet 控制器</h3><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-daemon/5.png/w600">

<p>最后我们来看一下 DaemonSet 的控制器，DaemonSet 其实和 Job controller 做的差不多：两者都需要根据 watch 这个 API Server 的状态。现在 DaemonSet 和 Job controller 唯一的不同点在于，DaemonsetSet Controller需要去 watch node 的状态，但其实这个 node 的状态还是通过 API Server 传递到 ETCD 上。</p>
<p>当有 node 状态节点发生变化时，它会通过一个内存消息队列发进来，然后DaemonSet controller 会去 watch 这个状态，看一下各个节点上是都有对应的 Pod，如果没有的话就去创建。当然它会去做一个对比，如果有的话，它会比较一下版本，然后加上刚才提到的是否去做 RollingUpdate？如果没有的话就会重新创建，Ondelete 删除 pod 的时候也会去做 check 它做一遍检查，是否去更新，或者去创建对应的 pod。</p>
<p>当然最后的时候，如果全部更新完了之后，它会把整个 DaemonSet 的状态去更新到 API Server 上，完成最后全部的更新。</p>
<h1 id="本节总结"><a href="#本节总结" class="headerlink" title="本节总结"></a>本节总结</h1><p>本节课的主要内容就到此为止了，这里为大家简单总结一下。</p>
<div class="note primary">
            <ul><li>Job &amp; CronJobs 基础操作与概念解析：本节详细介绍了 Job 和 CronJob 的概念，并通过两个实际的例子介绍了 Job 和 CronJob 的使用，对于 Job 和 CronJob 内的各种功能便签都进行了详细的演示； </li><li>DaemonSet 基础操作与概念解析：通过类比 Deployment 控制器，我们理解了一下 DaemonSet 控制器的工作流程与方式，并且通过对 DaemonSet 的更新了解了滚动更新的概念和相对应的操作方式。</li></ul>
          </div>
]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(五)——应用编排与管理</title>
    <url>/cn/k8s%E5%BA%94%E7%94%A8%E7%BC%96%E6%8E%92%E4%B8%8E%E7%AE%A1%E7%90%86%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>本文将主要分享以下四方面的内容：</p>
<div class="note warning">
            <ul><li>K8s 资源的重要元信息；</li><li>演示一下如何去修改或查看 K8s 重要元数据；</li><li>详细分析控制器模式；</li><li>总结控制器模式特点。</li></ul>
          </div>

<a id="more"></a>
<h1 id="一、资源元信息"><a href="#一、资源元信息" class="headerlink" title="一、资源元信息"></a>一、资源元信息</h1><h2 id="1-Kubernetes-资源对象"><a href="#1-Kubernetes-资源对象" class="headerlink" title="1. Kubernetes 资源对象"></a>1. Kubernetes 资源对象</h2><p>首先，我们来回顾一下 Kubernetes 的资源对象组成：主要包括了 Spec、Status 两部分。</p>
<ul>
<li>Spec: 用来描述期望的状态，</li>
<li>Status: 用来描述观测到的状态。</li>
</ul>
<p>今天我们将为大家介绍 K8s 的另外一个部分，即<strong>元数据部分</strong>。该部分主要包括了:</p>
<ol>
<li>Labels: 用来识别资源的标签</li>
<li>Annotations: 用来描述资源的注解</li>
<li>OwnerReference: 用来描述多个资源之间相互关系的<br>这些元数据在 K8s 运行中有非常重要的作用。<div class="tabs" id="your_tabs_name"><ul class="nav-tabs"><li class="tab active"><a href="#your_tabs_name-1"><i class="fa fa-reorder"></i>labels</a></li><li class="tab"><a href="#your_tabs_name-2"><i class="fa fa-reorder"></i>Selector</a></li><li class="tab"><a href="#your_tabs_name-3"><i class="fa fa-reorder"></i>Annotations</a></li><li class="tab"><a href="#your_tabs_name-4"><i class="fa fa-reorder"></i>Ownereference</a></li></ul><div class="tab-content"><div class="tab-pane active" id="your_tabs_name-1"><h2 id="2-labels"><a href="#2-labels" class="headerlink" title="2. labels"></a>2. labels</h2><p>第一个元数据，也是最重要的一个元数据是：资源标签。资源标签是一种具有标识型的 Key：Value 元数据，这里展示了几个常见的标签。</p>
<p>前三个标签都打在了 Pod 对象上，分别标识了对应的应用环境、发布的成熟度和应用的版本。从应用标签的例子可以看到，标签的名字包括了一个域名的前缀，用来描述打标签的系统和工具， 最后一个标签打在 Node 对象上，还在域名前增加了版本的标识 beta 字符串。</p>
<p>标签主要用来筛选资源和组合资源，可以使用类似于 SQL 查询 select，来根据 Label 查询相关的资源。<br><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-label.png/w600"></p></div><div class="tab-pane" id="your_tabs_name-2"><h2 id="3-Selector"><a href="#3-Selector" class="headerlink" title="3. Selector"></a>3. Selector</h2><p>最常见的 Selector 就是相等型 Selector。现在举一个简单的例子：</p>
<p>假设系统中有四个 Pod，每个 Pod 都有标识系统层级和环境的标签，我们通过 Tie：front 这个标签，可以匹配左边栏的 Pod，相等型 Selector 还可以包括多个相等条件，多个相等条件之间是逻辑”与“的关系。</p>
<p>在刚才的例子中，通过 Tie=front,Env=dev 的Selector，我们可以筛选出所有 Tie=front，而且 Env=dev 的 Pod，也就是下图中左上角的 Pod。另外一种 Selector 是集合型 Selector，在例子中，Selector 筛选所有环境是 test 或者 gray 的 Pod。</p>
<p>除了 in 的集合操作外，还有 notin 集合操作，比如 tie notin（front,back），将会筛选所有 tie 不是 front 且不是 back 的 Pod。另外，也可以根据是否存在某 lable 的筛选，如：Selector release，筛选所有带 release 标签的 Pod。集合型和相等型的 Selector，也可以用“，”来连接，同样的标识逻辑”与“的关系。<br><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-selector.png/w600"></p></div><div class="tab-pane" id="your_tabs_name-3"><h2 id="4-Annotations"><a href="#4-Annotations" class="headerlink" title="4. Annotations"></a>4. Annotations</h2><p>另外一种重要的元数据是：annotations。一般是系统或者工具用来存储资源的非标示性信息，可以用来扩展资源的 spec/status 的描述，这里给了几个 annotations 的例子：</p>
<p>第一个例子，存储了阿里云负载器的证书 ID，我们可以看到 annotations 一样可以拥有域名的前缀，标注中也可以包含版本信息。第二个 annotation存储了 nginx 接入层的配置信息，我们可以看到 annotations 中包括“，”这样无法出现在 label 中的特殊字符。第三个 annotations 一般可以在 kubectl apply 命令行操作后的资源中看到， annotation 值是一个结构化的数据，实际上是一个 json 串，标记了上一次 kubectl 操作的资源的 json 的描述。<br><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-annotation.png/w600"></p></div><div class="tab-pane" id="your_tabs_name-4"><h2 id="5-Ownereference"><a href="#5-Ownereference" class="headerlink" title="5. Ownereference"></a>5. Ownereference</h2><p>我们当时讲到最后一个元数据叫做 Ownereference，所谓所有者，一般就是指集合类的资源，比如说 Pod 集合，就有 replicaset、statefulset，这个将在后序的课程中讲到。</p>
<p>集合类资源的控制器会创建对应的归属资源。比如：replicaset 控制器在操作中会创建 Pod，被创建 Pod 的 Ownereference 就指向了创建 Pod 的 replicaset，Ownereference 使得用户可以方便地查找一个创建资源的对象，另外，还可以用来实现级联删除的效果。<br><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-ownerefence.png/w600"></p></div></div></div>

</li>
</ol>
<h1 id="二、操作演示"><a href="#二、操作演示" class="headerlink" title="二、操作演示"></a>二、操作演示</h1><p>这里通过 kubectl 命令去连接我们 ACK 中已经创建好的一个 K8s 集群，然后来展示一下怎么查看和修改 K8s 对象中的元数据，主要就是 Pod 的一个标签、注解，还有对应的 Ownerference。</p>
<p>首先我们看一下集群里现在的配置情况：</p>
<ol>
<li><p>查看 Pod，现在没有任何的一个 Pod；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get pods</span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后用事先准备好的一个 Pod 的 yaml，创建一个 Pod 出来；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f pod1.yaml</span><br><span class="line">kubectl apply -f pod2.yaml</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">3. 现在查看一下 Pod 打的标签，我们用 --show-labels 这个选项，可以看到这两个 Pod 都打上了一个部署环境和层级的标签；</span><br><span class="line">`kubectl get pods —show-labels`</span><br><span class="line"> </span><br><span class="line">4. 我们也可以通过另外一种方式来查看具体的资源信息。首先查看 nginx1 第一个 Pod 的一个信息，用 -o  yaml 的方式输出，可以看到这个 Pod 元数据里面包括了一个 lables 的字段，里面有两个 lable；</span><br><span class="line">`kubectl get pods nginx1 -o yaml | less`</span><br><span class="line"></span><br><span class="line">5. 现在再想一下，怎么样对 Pod 已有的 lable 进行修改？我们先把它的部署环境，从开发环境改成测试环境，然后指定 Pod 名字，在环境再加上它的一个值 <span class="built_in">test</span> ，看一下能不能成功。 这里报了一个错误，可以看到，它其实是说现在这个 label 已经有值了；</span><br><span class="line">`kubectl label pods nginx1 env=<span class="built_in">test</span>`</span><br><span class="line"> </span><br><span class="line">6. 如果想覆盖掉它的话，得额外再加上一个覆盖的选项。加上之后呢，我们应该可以看到这个打标已经成功了；</span><br><span class="line">`kubectl label pods nginx1 env=<span class="built_in">test</span> —overwrite`</span><br><span class="line"> </span><br><span class="line">7. 我们再看一下现在集群的 lable 设置情况，首先可以看到 nginx1 的确已经加上了一个部署环境 <span class="built_in">test</span> 标签；</span><br><span class="line">`kubectl get pods —show-labels`</span><br><span class="line"> </span><br><span class="line">8. 如果想要对 Pod 去掉一个标签，也是跟打标签一样的操作，但是 env 后就不是等号了。只加上 label 名字，后面不加等号，改成用减号表示去除 label 的 k:v；</span><br><span class="line">`kubectl label pods nginx tie-`</span><br><span class="line"></span><br><span class="line">9. 可以看到这个 label，去标已经完全成功；</span><br><span class="line">`kubectl get pods —show-labels`</span><br><span class="line">&#123;% qnimg cn/cloud-native-k8s-aacp/k8s-pods-show-label.png %&#125;</span><br><span class="line"></span><br><span class="line">10. 下面来看一下配置的 label 值，的确能看到 nginx1 的这个 Pod 少了一个 tie=front 的标签。有了这个 Pod 标签之后，可以看一下怎样用 label Selector 进行匹配？首先 label Selector 是通过 -l 这个选项来进行指定的 ，指定的时候，先试一下用相等型的一个 label 来筛选，所以我们指定的是部署环境等于测试的一个 Pod，我们可以看到能够筛选出一台；</span><br><span class="line">`kubectl get pods —show-labels -l env=<span class="built_in">test</span>`</span><br><span class="line"> </span><br><span class="line">11. 假如说有多个相等的条件需要指定的，实际上这是一个与的关系，假如说 env 再等于 dev，我们实际上是一个 Pod 都拿不到的；</span><br><span class="line">`kubectl get pods —show-labels -l env=<span class="built_in">test</span>,env=dev`</span><br><span class="line"> </span><br><span class="line">12. 然后假如说 env=dev，但是 tie=front，我们能够匹配到第二个 Pod，也就是 nginx2；</span><br><span class="line">`kubectl get pods —show-labels -l env=dev,tie=front`</span><br><span class="line"></span><br><span class="line">13. 我们还可以再试一下怎么样用集合型的 label Selector 来进行筛选。这一次我们还是想要匹配出所有部署环境是 <span class="built_in">test</span> 或者是 dev 的一个 Pod，所以在这里加上一个引号，然后在括号里面指定所有部署环境的一个集合。这次能把两个创建的 Pod 都筛选出来；</span><br><span class="line">`kubectl get pods —show-labels -l ’env <span class="keyword">in</span> (dev,<span class="built_in">test</span>)’`</span><br><span class="line"> </span><br><span class="line">14. 我们再试一下怎样对 Pod 增加一个注解，注解的话，跟打标是一样的操作，但是把 label 命令改成 annotate 命令；然后，一样指定类型和对应的名字。后面就不是加上 label 的 k:v 了，而是加上 annotation 的 k:v。这里我们可以指定一个任意的字符串，比如说加上空格、加上逗号都可以；</span><br><span class="line">`kubectl annotate pods nginx1 my-annotate=‘my annotate,ok’`</span><br><span class="line"> </span><br><span class="line">15. 然后，我们再看一下这个 Pod 的一些元数据，我们这边能够看到这个 Pod 的元数据里面 annotations，这是有一个 my-annotate 这个 Annotations；</span><br><span class="line">`kubectl get pods nging1 -o yaml | less`</span><br><span class="line"> </span><br><span class="line">然后我们这里其实也能够看到有一个 kubectl apply 的时候，kubectl 工具增加了一个 annotation，这也是一个 json 串。</span><br><span class="line"></span><br><span class="line">16. 然后我们再演示一下看 Pod 的 Ownereference 是怎么出来的。原来的 Pod 都是直接通过创建 Pod 这个资源方式来创建的，这次换一种方式来创建：通过创建一个 ReplicaSet 对象来创建 Pod 。首先创建一个 ReplicaSet 对象，这个 ReplicaSet 对象可以具体查看一下；</span><br><span class="line">```shell</span><br><span class="line">kubectl apply -f rs.yaml</span><br><span class="line">kubectl get replicasets  nginx-replicasets -o yaml |less</span><br></pre></td></tr></table></figure>
</li>
<li><p>我们可以关注一下这个 ReplicaSet 里面 spec 里面，提到会创建两个 Pod，然后 selector 通过匹配部署环境是 product 生产环境的这个标签来进行匹配。所以我们可以看一下，现在集群中的 Pod 情况；<br><code>kubectl get pods</code></p>
</li>
</ol>
<ol start="18">
<li>将会发现多了两个 Pod，仔细查看这两个 Pod，可以看到 ReplicaSet 创建出来的 Pod 有一个特点，即它会带有 Ownereference，然后 Ownereference 里面指向了是一个 replicasets 类型，名字就叫做 nginx-replicasets；<br><code>kubectl get pods nginx-replicasets-rhd68 -o yaml | less</code></li>
</ol>
<h1 id="三、控制器模式"><a href="#三、控制器模式" class="headerlink" title="三、控制器模式"></a>三、控制器模式</h1><h2 id="1、控制循环"><a href="#1、控制循环" class="headerlink" title="1、控制循环"></a>1、控制循环</h2><p>控制型模式最核心的就是控制循环的概念。在控制循环中包括了控制器，被控制的系统，以及能够观测系统的传感器，三个逻辑组件。</p>
<p>当然这些组件都是逻辑的，外界通过修改资源 spec 来控制资源，控制器比较资源 spec 和 status，从而计算一个 diff，diff 最后会用来决定执行对系统进行什么样的控制操作，控制操作会使得系统产生新的输出，并被传感器以资源 status 形式上报，控制器的各个组件将都会是独立自主地运行，不断使系统向 spec 表示终态趋近。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-controll-loop.png/w600">

<h2 id="2、Sensor"><a href="#2、Sensor" class="headerlink" title="2、Sensor"></a>2、Sensor</h2><p>控制循环中逻辑的传感器主要由 Reflector、Informer、Indexer 三个组件构成。</p>
<p>Reflector 通过 List 和 Watch K8s server 来获取资源的数据。List 用来在 Controller 重启以及 Watch 中断的情况下，进行系统资源的全量更新；而 Watch 则在多次 List 之间进行增量的资源更新；Reflector 在获取新的资源数据后，会在 Delta 队列中塞入一个包括资源对象信息本身以及资源对象事件类型的 Delta 记录，Delta 队列中可以保证同一个对象在队列中仅有一条记录，从而避免 Reflector 重新 List 和 Watch 的时候产生重复的记录。</p>
<p>Informer 组件不断地从 Delta 队列中弹出 delta 记录，然后把资源对象交给 indexer，让 indexer 把资源记录在一个缓存中，缓存在默认设置下是用资源的命名空间来做索引的，并且可以被 Controller Manager 或多个 Controller 所共享。之后，再把这个事件交给事件的回调函数</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-sensor.png/w600">
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-controller.png/w600">

<p>控制循环中的控制器组件主要由事件处理函数以及 worker 组成，事件处理函数之间会相互关注资源的新增、更新、删除的事件，并根据控制器的逻辑去决定是否需要处理。对需要处理的事件，会把事件关联资源的命名空间以及名字塞入一个工作队列中，并且由后续的 worker 池中的一个 Worker 来处理，工作队列会对存储的对象进行去重，从而避免多个 Woker 处理同一个资源的情况。</p>
<p>Worker 在处理资源对象时，一般需要用资源的名字来重新获得最新的资源数据，用来创建或者更新资源对象，或者调用其他的外部服务，Worker 如果处理失败的时候，一般情况下会把资源的名字重新加入到工作队列中，从而方便之后进行重试。</p>
<h2 id="3、控制循环例子-扩容"><a href="#3、控制循环例子-扩容" class="headerlink" title="3、控制循环例子-扩容"></a>3、控制循环例子-扩容</h2><p>这里举一个简单的例子来说明一下控制循环的工作原理。</p>
<p>ReplicaSet 是一个用来描述无状态应用的扩缩容行为的资源， ReplicaSet controler 通过监听 ReplicaSet 资源来维持应用希望的状态数量，ReplicaSet 中通过 selector 来匹配所关联的 Pod，在这里考虑 ReplicaSet rsA 的，replicas 从 2 被改到 3 的场景。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-controle-expand.png/w600">

<p>首先，Reflector 会 watch 到 ReplicaSet 和 Pod 两种资源的变化，为什么我们还会 watch pod 资源的变化稍后会讲到。发现 ReplicaSet 发生变化后，在 delta 队列中塞入了对象是 rsA，而且类型是更新的记录。</p>
<p>Informer 一方面把新的 ReplicaSet 更新到缓存中，并与 Namespace nsA 作为索引。另外一方面，调用 Update 的回调函数，ReplicaSet 控制器发现 ReplicaSet 发生变化后会把字符串的 nsA/rsA 字符串塞入到工作队列中，工作队列后的一个 Worker 从工作队列中取到了 nsA/rsA 这个字符串的 key，并且从缓存中取到了最新的 ReplicaSet 数据。</p>
<p>Worker 通过比较 ReplicaSet 中 spec 和 status 里的数值，发现需要对这个 ReplicaSet 进行扩容，因此 ReplicaSet 的 Worker 创建了一个 Pod，这个 pod 中的 Ownereference 取向了 ReplicaSet rsA。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-controller-onupdate.png/w600">

<p>然后 Reflector Watch 到的 Pod 新增事件，在 delta 队列中额外加入了 Add 类型的 deta 记录，一方面把新的 Pod 记录通过 Indexer 存储到了缓存中，另一方面调用了 ReplicaSet 控制器的 Add 回调函数，Add 回调函数通过检查 pod ownerReferences 找到了对应的 ReplicaSet，并把包括 ReplicaSet 命名空间和字符串塞入到了工作队列中。</p>
<p>ReplicaSet 的 Woker 在得到新的工作项之后，从缓存中取到了新的 ReplicaSet 记录，并得到了其所有创建的 Pod，因为 ReplicaSet 的状态不是最新的，也就是所有创建 Pod 的数量不是最新的。因此在此时 ReplicaSet 更新 status 使得 spec 和 status 达成一致。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-controller-onadd.png/w600">

<h1 id="四、控制器模式总结"><a href="#四、控制器模式总结" class="headerlink" title="四、控制器模式总结"></a>四、控制器模式总结</h1><h2 id="1、两种-API-设计方法"><a href="#1、两种-API-设计方法" class="headerlink" title="1、两种 API 设计方法"></a>1、两种 API 设计方法</h2><p>Kubernetes 控制器模式依赖声明式的 API。另外一种常见的 API 类型是命令式 API。为什么 Kubernetes 采用声明式 API，而不是命令式 API 来设计整个控制器呢？</p>
<p>首先，比较两种 API 在交互行为上的差别。在生活中，常见的命令式的交互方式是家长和孩子交流方式，因为孩子欠缺目标意识，无法理解家长期望，家长往往通过一些命令，教孩子一些明确的动作，比如说：吃饭、睡觉类似的命令。我们在容器编排体系中，命令式 API 就是通过向系统发出明确的操作来执行的。</p>
<p>而常见的声明式交互方式，就是老板对自己员工的交流方式。老板一般不会给自己的员工下很明确的决定，实际上可能老板对于要操作的事情本身，还不如员工清楚。因此，老板通过给员工设置可量化的业务目标的方式，来发挥员工自身的主观能动性。比如说，老板会要求某个产品的市场占有率达到 80%，而不会指出要达到这个市场占有率，要做的具体操作细节。</p>
<p>类似的，在容器编排体系中，我们可以执行一个应用实例副本数保持在 3 个，而不用明确的去扩容 Pod 或是删除已有的 Pod，来保证副本数在三个。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-two-api.png/w600">

<h2 id="2、命令式-API-的问题"><a href="#2、命令式-API-的问题" class="headerlink" title="2、命令式 API 的问题"></a>2、命令式 API 的问题</h2><p>在理解两个交互 API 的差别后，可以分析一下命令式 API 的问题。</p>
<ul>
<li>命令 API 最大的一个问题在于错误处理；</li>
</ul>
<p>在大规模的分布式系统中，错误是无处不在的。一旦发出的命令没有响应，调用方只能通过反复重试的方式来试图恢复错误，然而盲目的重试可能会带来更大的问题。</p>
<p>假设原来的命令，后台实际上已经执行完成了，重试后又多执行了一个重试的命令操作。为了避免重试的问题，系统往往还需要在执行命令前，先记录一下需要执行的命令，并且在重启等场景下，重做待执行的命令，而且在执行的过程中，还需要考虑多个命令的先后顺序、覆盖关系等等一些复杂的逻辑情况。</p>
<ul>
<li>实际上许多命令式的交互系统后台往往还会做一个巡检的系统，用来修正命令处理超时、重试等一些场景造成数据不一致的问题； </li>
</ul>
<p>然而，因为巡检逻辑和日常操作逻辑是不一样的，往往在测试上覆盖不够，在错误处理上不够严谨，具有很大的操作风险，因此往往很多巡检系统都是人工来触发的。</p>
<ul>
<li>最后，命令式 API 在处理多并发访问时，也很容易出现问题；</li>
</ul>
<p>假如有多方并发的对一个资源请求进行操作，并且一旦其中有操作出现了错误，就需要重试。那么最后哪一个操作生效了，就很难确认，也无法保证。很多命令式系统往往在操作前会对系统进行加锁，从而保证整个系统最后生效行为的可预见性，但是加锁行为会降低整个系统的操作执行效率。</p>
<ul>
<li>相对的，声明式 API 系统里天然地记录了系统现在和最终的状态。</li>
</ul>
<p>不需要额外的操作数据。另外因为状态的幂等性，可以在任意时刻反复操作。在声明式系统运行的方式里，正常的操作实际上就是对资源状态的巡检，不需要额外开发巡检系统，系统的运行逻辑也能够在日常的运行中得到测试和锤炼，因此整个操作的稳定性能够得到保证。</p>
<p>最后，因为资源的最终状态是明确的，我们可以合并多次对状态的修改。可以不需要加锁，就支持多方的并发访问。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-command-declare.png/w600">

<h2 id="3、控制器模式总结"><a href="#3、控制器模式总结" class="headerlink" title="3、控制器模式总结"></a>3、控制器模式总结</h2><p>最后我们总结一下：</p>
<ol>
<li>Kubernetes 所采用的控制器模式，是由声明式 API 驱动的。确切来说，是基于对 Kubernetes 资源对象的修改来驱动的；</li>
<li>Kubernetes 资源之后，是关注该资源的控制器。这些控制器将异步的控制系统向设置的终态驱近；</li>
<li>这些控制器是自主运行的，使得系统的自动化和无人值守成为可能；</li>
<li>因为 Kubernetes 的控制器和资源都是可以自定义的，因此可以方便的扩展控制器模式。特别是对于有状态应用，我们往往通过自定义资源和控制器的方式，来自动化运维操作。这个也就是后续会介绍的 operator 的场景。<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-aacp/k8s-controller-summary.png/w600">

</li>
</ol>
<h1 id="本节总结"><a href="#本节总结" class="headerlink" title="本节总结"></a>本节总结</h1><div class="note danger">
            <ul><li>Kubernetes 资源对象中的元数据部分，主要包括了用来识别资源的标签：Labels， 用来描述资源的注解；Annotations， 用来描述多个资源之间相互关系的 OwnerReference。这些元数据在 K8s 运行中有非常重要的作用；</li><li>控制型模式中最核心的就是控制循环的概念；</li><li>两种 API 设计方法：声明式 API 和命令式 API ；Kubernetes 所采用的控制器模式，是由声明式 API 驱动的；</li></ul>
          </div>]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(九)——应用存储和持久化数据卷核心知识</title>
    <url>/cn/k8s%E5%BA%94%E7%94%A8%E5%AD%98%E5%82%A8%E5%92%8C%E6%8C%81%E4%B9%85%E5%8C%96%E6%95%B0%E6%8D%AE%E5%8D%B7%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p>本文将主要分享以下内容：</p>
<div class="note primary">
            <ol><li>K8s Volume 使用场景</li><li>PVC/PV/StorageClass 基本操作和概念解析</li><li>PVC+PV 体系的设计与实现原理</li></ol>
          </div>

<a id="more"></a>
<h1 id="一、Volumes-介绍"><a href="#一、Volumes-介绍" class="headerlink" title="一、Volumes 介绍"></a>一、Volumes 介绍</h1><h2 id="Pod-Volumes"><a href="#Pod-Volumes" class="headerlink" title="Pod Volumes"></a>Pod Volumes</h2><p>首先来看一下 Pod Volumes 的使用场景：</p>
<ul>
<li>场景一：如果 pod 中的某一个容器在运行时异常退出，被 kubelet 重新拉起之后，如何保证之前容器产生的重要数据没有丢失？</li>
<li>场景二：如果同一个 pod 中的多个容器想要共享数据，应该如何去做？</li>
</ul>
<p>以上两个场景，其实都可以借助 Volumes 来很好地解决，接下来首先看一下 Pod Volumes 的常见类型：</p>
<ul>
<li>本地存储，常用的有 emptydir/hostpath；</li>
<li>网络存储：网络存储当前的实现方式有两种，一种是 in-tree，它的实现的代码是放在 K8s 代码仓库中的，随着k8s对存储类型支持的增多，这种方式会给k8s本身的维护和发展带来很大的负担；而第二种实现方式是 out-of-tree，它的实现其实是给 K8s 本身解耦的，通过抽象接口将不同存储的driver实现从k8s代码仓库中剥离，因此out-of-tree 是后面社区主推的一种实现网络存储插件的方式；</li>
<li>Projected Volumes：它其实是将一些配置信息，如 secret/configmap 用卷的形式挂载在容器中，让容器中的程序可以通过POSIX接口来访问配置数据；</li>
<li>PV 与 PVC 就是今天要重点介绍的内容。</li>
</ul>
<h2 id="Persistent-Volumes"><a href="#Persistent-Volumes" class="headerlink" title="Persistent Volumes"></a>Persistent Volumes</h2><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-storage/1.jpg/w600">
<p>接下来看一下 PV（Persistent Volumes）。既然已经有了 Pod Volumes，为什么又要引入 PV 呢？我们知道 pod 中声明的 volume 生命周期与 pod 是相同的，以下有几种常见的场景：</p>
<ul>
<li>场景一：pod 重建销毁，如用 Deployment 管理的 pod，在做镜像升级的过程中，会产生新的 pod并且删除旧的 pod ，那新旧 pod 之间如何复用数据？</li>
<li>场景二：宿主机宕机的时候，要把上面的 pod 迁移，这个时候 StatefulSet 管理的 pod，其实已经实现了带卷迁移的语义。这时通过 Pod Volumes 显然是做不到的；</li>
<li>场景三：多个 pod 之间，如果想要共享数据，应该如何去声明呢？我们知道，同一个 pod 中多个容器想共享数据，可以借助 Pod Volumes 来解决；当多个 pod 想共享数据时，Pod Volumes 就很难去表达这种语义；</li>
<li>场景四：如果要想对数据卷做一些功能扩展性，如：snapshot、resize 这些功能，又应该如何去做呢？</li>
</ul>
<p>以上场景中，通过 Pod Volumes 很难准确地表达它的复用/共享语义，对它的扩展也比较困难。因此 K8s 中又引入了 Persistent Volumes 概念，它可以将存储和计算分离，通过不同的组件来管理存储资源和计算资源，然后解耦 pod 和 Volume 之间生命周期的关联。这样，当把 pod 删除之后，它使用的PV仍然存在，还可以被新建的 pod 复用。</p>
<h2 id="PVC-设计意图"><a href="#PVC-设计意图" class="headerlink" title="PVC 设计意图"></a>PVC 设计意图</h2><img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-storage/2.jpg/w600">
<p>了解 PV 后，应该如何使用它呢？</p>
<p>用户在使用 PV 时其实是通过 PVC，为什么有了 PV 又设计了 PVC 呢？主要原因是为了简化K8s用户对存储的使用方式，做到职责分离。通常用户在使用存储的时候，只用声明所需的存储大小以及访问模式。</p>
<p>访问模式是什么？其实就是：我要使用的存储是可以被多个node共享还是只能单node独占访问(注意是node level而不是pod level)？只读还是读写访问？用户只用关心这些东西，与存储相关的实现细节是不需要关心的。</p>
<p>通过 PVC 和 PV 的概念，将用户需求和实现细节解耦开，用户只用通过 PVC 声明自己的存储需求。PV是有集群管理员和存储相关团队来统一运维和管控，这样的话，就简化了用户使用存储的方式。可以看到，PV 和 PVC 的设计其实有点像面向对象的接口与实现的关系。用户在使用功能时，只需关心用户接口，不需关心它内部复杂的实现细节。</p>
<p>既然 PV 是由集群管理员统一管控的，接下来就看一下 PV 这个对象是怎么产生的。</p>
<h2 id="Static-Volume-Provisioning"><a href="#Static-Volume-Provisioning" class="headerlink" title="Static Volume Provisioning"></a>Static Volume Provisioning</h2><p>第一种产生方式：静态产生方式 - 静态 Provisioning。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-storage/3.jpg/w600">

<p>静态 Provisioning：由集群管理员事先去规划这个集群中的用户会怎样使用存储，它会先预分配一些存储，也就是预先创建一些 PV；然后用户在提交自己的存储需求（也就是 PVC）的时候，K8s 内部相关组件会帮助它把 PVC 和 PV 做绑定；之后用户再通过 pod 去使用存储的时候，就可以通过 PVC 找到相应的 PV，它就可以使用了。</p>
<p>静态产生方式有什么不足呢？可以看到，首先需要集群管理员预分配，预分配其实是很难预测用户真实需求的。举一个最简单的例子：如果用户需要的是 20G，然而集群管理员在分配的时候可能有 80G 、100G 的，但没有 20G 的，这样就很难满足用户的真实需求，也会造成资源浪费。有没有更好的方式呢？</p>
<h2 id="Dynamic-Volume-Provisioning"><a href="#Dynamic-Volume-Provisioning" class="headerlink" title="Dynamic Volume Provisioning"></a>Dynamic Volume Provisioning</h2><p>第二种访问方式：动态 Dynamic Provisioning。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-storage/4.png/w600">
<p>动态供给是什么意思呢？就是说现在集群管理员不预分配 PV，他写了一个模板文件，这个模板文件是用来表示创建某一类型存储（块存储，文件存储等）所需的一些参数，这些参数是用户不关心的，给存储本身实现有关的参数。用户只需要提交自身的存储需求，也就是PVC文件，并在 PVC 中指定使用的存储模板（StorageClass）。</p>
<p>K8s 集群中的管控组件，会结合 PVC 和 StorageClass 的信息动态，生成用户所需要的存储（PV），将 PVC 和 PV 进行绑定后，pod 就可以使用 PV 了。通过 StorageClass 配置生成存储所需要的存储模板，再结合用户的需求动态创建 PV 对象，做到按需分配，在没有增加用户使用难度的同时也解放了集群管理员的运维工作。</p>
<h1 id="二、用例解读"><a href="#二、用例解读" class="headerlink" title="二、用例解读"></a>二、用例解读</h1><p>接下来看一下 Pod Volumes、PV、PVC 及 StorageClass 具体是如何使用的。</p>
<h2 id="Pod-Volumes-的使用"><a href="#Pod-Volumes-的使用" class="headerlink" title="Pod Volumes 的使用"></a>Pod Volumes 的使用</h2><p>首先来看一下 Pod Volumes 的使用。如上图左侧所示，我们可以在 pod yaml 文件中的 Volumes 字段中，声明我们卷的名字以及卷的类型。声明的两个卷，一个是用的是 emptyDir，另外一个用的是 hostPath，这两种都是本地卷。在容器中应该怎么去使用这个卷呢？它其实可以通过 volumeMounts 这个字段，volumeMounts 字段里面指定的 name 其实就是它使用的哪个卷，mountPath 就是容器中的挂载路径。</p>
<p>这里还有个 subPath，subPath 是什么？</p>
<p>先看一下，这两个容器都指定使用了同一个卷，就是这个 cache-volume。那么，在多个容器共享同一个卷的时候，为了隔离数据，我们可以通过 subPath 来完成这个操作。它会在卷里面建立两个子目录，然后容器 1 往 cache 下面写的数据其实都写在子目录 cache1 了，容器 2 往 cache 写的目录，其数据最终会落在这个卷里子目录下面的 cache2 下。</p>
<p>还有一个 readOnly 字段，readOnly 的意思其实就是只读挂载，这个挂载你往挂载点下面实际上是没有办法去写数据的。</p>
<p>另外emptyDir、hostPath 都是本地存储，它们之间有什么细微的差别呢？emptyDir 其实是在 pod 创建的过程中会临时创建的一个目录，这个目录随着 pod 删除也会被删除，里面的数据会被清空掉；hostPath 顾名思义，其实就是宿主机上的一个路径，在 pod 删除之后，这个目录还是存在的，它的数据也不会被丢失。这就是它们两者之间一个细微的差别。</p>
<h2 id="静态-PV-使用"><a href="#静态-PV-使用" class="headerlink" title="静态 PV 使用"></a>静态 PV 使用</h2><p>接下来再看一下，PV 和 PVC 是怎么使用的。</p>
<p>先看一个静态 PV 创建方式。静态 PV 的话，首先是由管理员来创建的，管理员我们这里以 NAS，就是阿里云文件存储为例。我需要先在阿里云的文件存储控制台上去创建 NAS 存储，然后把 NAS 存储的相关信息要填到 PV 对象中，这个 PV 对象预创建出来后，用户可以通过 PVC 来声明自己的存储需求，然后再去创建 pod。创建 pod 还是通过我们刚才讲解的字段把存储挂载到某一个容器中的某一个挂载点下面。</p>
<p>那么接下来看一下 yaml 怎么写。集群管理员首先是在云存储厂商那边先去把存储创建出来，然后把相应的信息填写到 PV 对象中。</p>
<p>刚刚创建的阿里云 NAS 文件存储对应的PV，有个比较重要的字段：capacity，即创建的这个存储的大小，accessModes，创建出来的这个存储它的访问方式，我们后面会讲解总共有几种访问方式。 </p>
<p>然后有个 ReclaimPolicy，ReclaimPolicy 的意思就是：这块存储在被使用后，等它的使用方 pod 以及 PVC 被删除之后，这个 PV 是应该被删掉还是被保留呢？其实就是PV的回收策略。</p>
<p>接下来看看用户怎么去使用该PV对象。用户在使用存储的时候，需要先创建一个 PVC 对象。PVC 对象里面，只需要指定存储需求，不用关心存储本身的具体实现细节。存储需求包括哪些呢？首先是需要的大小，也就是 resources.requests.storage；然后是它的访问方式，即需要这个存储的访问方式，这里声明为ReadWriteMany，也即支持多node读写访问，这也是文件存储的典型特性。</p>
<p>上图中左侧，可以看到这个声明：它的 size 和它的access mode，跟我们刚才静态创建这块 PV 其实是匹配的。这样的话，当用户在提交 PVC 的时候，K8s 集群相关的组件就会把 PV 的 PVC bound 到一起。之后，用户在提交 pod yaml 的时候，可以在卷里面写上 PVC声明，在 PVC声明里面可以通过 claimName 来声明要用哪个 PVC。这时，挂载方式其实跟前面讲的一样，当提交完 yaml 的时候，它可以通过 PVC 找到 bound 着的那个 PV，然后就可以用那块存储了。这是静态 Provisioning到被pod使用的一个过程。</p>
<h2 id="动态-PV-使用"><a href="#动态-PV-使用" class="headerlink" title="动态 PV 使用"></a>动态 PV 使用</h2><p>然后再看一下动态 Provisioning。动态 Provisioning 上面提到过，系统管理员不再预分配 PV，而只是创建一个模板文件。</p>
<p>这个模板文件叫 StorageClass，在StorageClass里面，我们需要填的重要信息：第一个是 provisioner，provisioner 是什么？它其实就是说我当时创建 PV 和对应的存储的时候，应该用哪个存储插件来去创建。</p>
<p>这些参数是通过k8s创建存储的时候，需要指定的一些细节参数。对于这些参数，用户是不需要关心的，像这里 regionld、zoneld、fsType 和它的类型。ReclaimPolicy跟我们刚才讲解的 PV 里的意思是一样的，就是说动态创建出来的这块 PV,当使用方使用结束、Pod 及 PVC 被删除后，这块 PV 应该怎么处理，我们这个地方写的是 delete，意思就是说当使用方 pod 和 PVC 被删除之后，这个 PV 也会被删除掉。</p>
<p>接下来看一下，集群管理员提交完 StorageClass，也就是提交创建 PV 的模板之后，用户怎么用，首先还是需要写一个 PVC 的文件。</p>
<p>PVC 的文件里存储的大小、访问模式是不变的。现在需要新加一个字段，叫 StorageClassName，它的意思是指定动态创建PV的模板文件的名字，这里StorageClassName填的就是上面声明的csi-disk。</p>
<p>在提交完 PVC之后，K8s 集群中的相关组件就会根据 PVC 以及对应的 StorageClass 动态生成这块 PV 给这个 PVC 做一个绑定，之后用户在提交自己的 yaml 时，用法和接下来的流程和前面的静态使用方式是一样的，通过 PVC 找到我们动态创建的 PV，然后把它挂载到相应的容器中就可以使用了。</p>
<h2 id="PV-Spec-重要字段解析"><a href="#PV-Spec-重要字段解析" class="headerlink" title="PV Spec 重要字段解析"></a>PV Spec 重要字段解析</h2><p>接下来，我们讲解一下 PV 的一些重要字段：</p>
<p>Capacity：这个很好理解，就是存储对象的大小；<br>AccessModes：也是用户需要关心的，就是说我使用这个 PV 的方式。它有三种使用方式。<br>一种是单 node 读写访问；<br>第二种是多个 node 只读访问，是常见的一种数据的共享方式；<br>第三种是多个 node 上读写访问。<br>用户在提交 PVC 的时候，最重要的两个字段 —— Capacity 和 AccessModes。在提交 PVC 后，k8s 集群中的相关组件是如何去找到合适的 PV 呢？首先它是通过为 PV 建立的 AccessModes 索引找到所有能够满足用户的 PVC 里面的 AccessModes 要求的 PV list，然后根据PVC的 Capacity，StorageClassName, Label Selector 进一步筛选 PV，如果满足条件的 PV 有多个，选择 PV 的 size 最小的，accessmodes 列表最短的 PV，也即最小适合原则。</p>
<p>ReclaimPolicy：这个就是刚才提到的，我的用户方 PV 的 PVC 在删除之后，我的 PV 应该做如何处理？常见的有三种方式。<br>第一种方式我们就不说了，现在 K8s 中已经不推荐使用了；<br>第二种方式 delete，也就是说 PVC 被删除之后，PV 也会被删除；<br>第三种方式 Retain，就是保留，保留之后，后面这个 PV 需要管理员来手动处理。<br>StorageClassName：StorageClassName 这个我们刚才说了，我们动态 Provisioning 时必须指定的一个字段，就是说我们要指定到底用哪一个模板文件来生成 PV ；<br>NodeAffinity：就是说我创建出来的 PV，它能被哪些 node 去挂载使用，其实是有限制的。然后通过 NodeAffinity 来声明对node的限制，这样其实对 使用该PV的pod调度也有限制，就是说 pod 必须要调度到这些能访问 PV 的 node 上，才能使用这块 PV，这个字段在我们下一讲讲解存储拓扑调度时在细说。</p>
<h2 id="PV-状态流转"><a href="#PV-状态流转" class="headerlink" title="PV 状态流转"></a>PV 状态流转</h2><p>接下来我们看一下 PV 的状态流转。首先在创建 PV 对象后，它会处在短暂的pending 状态；等真正的 PV 创建好之后，它就处在 available 状态。</p>
<p>available 状态意思就是可以使用的状态，用户在提交 PVC 之后，被 K8s 相关组件做完 bound（即：找到相应的 PV），这个时候 PV 和 PVC 就结合到一起了，此时两者都处在 bound 状态。当用户在使用完 PVC，将其删除后，这个 PV 就处在 released 状态，之后它应该被删除还是被保留呢？这个就会依赖我们刚才说的 ReclaimPolicy。</p>
<p>这里有一个点需要特别说明一下：当 PV 已经处在 released 状态下，它是没有办法直接回到 available 状态，也就是说接下来无法被一个新的 PVC 去做绑定。如果我们想把已经 released 的 PV 复用，我们这个时候通常应该怎么去做呢？</p>
<p>第一种方式：我们可以新建一个 PV 对象，然后把之前的 released 的 PV 的相关字段的信息填到新的 PV 对象里面，这样的话，这个 PV 就可以结合新的 PVC 了；第二种是我们在删除 pod 之后，不要去删除 PVC 对象，这样给 PV 绑定的 PVC 还是存在的，下次 pod 使用的时候，就可以直接通过 PVC 去复用。K8s中的 StatefulSet 管理的 Pod 带存储的迁移就是通过这种方式。</p>
<h1 id="三、操作演示"><a href="#三、操作演示" class="headerlink" title="三、操作演示"></a>三、操作演示</h1><p>接下来，我会在实际的环境中给大家演示一下，静态 Provisioning 以及动态 Provisioning 具体操作方式。</p>
<h2 id="静态-Provisioning-例子"><a href="#静态-Provisioning-例子" class="headerlink" title="静态 Provisioning 例子"></a>静态 Provisioning 例子</h2><p>静态 Provisioning 主要用的是阿里云的 NAS 文件存储；动态 Provisioning 主要用了阿里云的云盘。它们需要相应存储插件，插件我已经提前部署在我的 K8s 集群中了(csi-nasplugin<em>是为了在k8s中使用阿里云NAS所需的插件，csi-disk</em>是为了在k8s中使用阿里云云盘所需要的插件)。</p>
<p>我们接下来先看一下静态 Provisioning 的 PV 的 yaml 文件。</p>
<p>volumeAttributes是我在阿里云nas控制台预先创建的 NAS 文件系统的相关信息，我们主要需要关心的有 capacity 为5Gi; accessModes 为多node读写访问; reclaimPolicy：Retain，也就是当我使用方的 PVC 被删除之后，我这个 PV 是要保留下来的；以及在使用这个卷的过程中使用的driver。</p>
<p>然后我们把对应的 PV 创建出来：</p>
<p>我们看一下上图 PV 的状态，已经处在 Available，也就是说它已经可以被使用了。</p>
<p>再创建出来 nas-pvc：</p>
<p>我们看这个时候 PVC 已经新创建出来了，而且也已经和我们上面创建的PV绑定到一起了。我们看一下 PVC 的 yaml 里面写的什么。</p>
<p>其实很简单 ，就是我需要的大小以及我需要的 accessModes。提交完之后，它就与我们集群中已经存在的 PV 做匹配，匹配成功之后，它就会做 bound。</p>
<p>接下来我们去创建使用 nas-fs 的 pod：</p>
<p>上图看到，这两个 Pod 都已经处在 running 状态了。</p>
<p>我们先看一下这个 pod yaml：</p>
<p>pod yaml 里面声明了刚才我们创建出来的 PVC 对象，然后把它挂载到 nas-container 容器中的 /data 下面。我们这个 pod 是通过前面课程中讲解 deployment 创建两个副本，通过反亲和性，将两个副本调度在不同的 node 上面。</p>
<p>上图我们可以看一下，两个Pod所在的宿主机是不一样的。</p>
<p>如下图所示：我们登陆到第一个上面，findmnt 看一下它的挂载信息，这个其实就挂载在我声明的 nas-fs 上，那我们再在下面 touch 个 test.test.test 文件，我们也会登陆到另外一个容器看一下，它有没有被共享。</p>
<p>我们退出再登陆另外一个 pod（刚才登陆的是第一个，现在登陆第二个）。</p>
<p>如下图所示：我们也 findmnt 一下，可以看到，这两个 pod 的远程挂载路径一样，也就是说我们用的是同一个 NAS PV，我们再看一下刚才创建出来的那个是否存在。</p>
<p>可以看到，这个也是存在的，就说明这两个运行在不同node上的 pod 共享了同一个 nas 存储。</p>
<p>接下来我们看一下把两个 pod 删掉之后的情况。先删Pod，接着再删一下对应的 PVC (K8s 内部对 pvc 对象由保护机制，在删除 pvc 对象时如果发现有 pod 在使用 pvc，pvc 是删除不掉的)，这个可能要稍等一下。</p>
<p>看一下下图对应的 PVC 是不是已经被删掉了。</p>
<p>上图显示，它已经被删掉了。再看一下，刚才的 nas PV 还是在的，它的状态是处在 Released 状态，也就是说刚才使用它的 PVC 已经被删掉了，然后它被 released 了。又因为我们 RECLAIN POLICY 是 Retain，所以它这个 PV 是被保留下来的。</p>
<p>动态 Provisioning 例子</p>
<p>接下来我们来看第二个例子，动态 Provisioning 的例子。我们先把保留下来的 PV 手动删掉，可以看到集群中没有 PV了。接下来演示一下动态 Provisioning。</p>
<p>首先，先去创建一个生成 PV 的模板文件，也就是 storageclass。看一下 storageclass 里面的内容，其实很简单。</p>
<p>如上图所示，我事先指定的是我要创建存储的卷插件(阿里云云盘插件，由阿里云团队开发)，这个我们已经提前部署好了；我们可以看到，parameters部分是创建存储所需要的一些参数，但是用户不需要关心这些信息；然后是 reclaimPolicy，也就是说通过这个 storageclass 创建出来的 PV 在给绑定到一起的 PVC 删除之后，它是要保留还是要删除。</p>
<p>如上图所示：现在这个集群中是没有 PV 的，我们动态提交一个 PVC 文件，先看一下它的 PVC 文件。它的 accessModes-ReadWriteOnce (因为阿里云云盘其实只能是单 node 读写的，所以我们声明这样的方式），它的存储大小需求是 30G，它的 storageClassName 是 csi-disk，就是我们刚才创建的 storageclass，也就是说它指定要通过这个模板去生成 PV。</p>
<p>这个 PVC 此时正处在 pending 状态，这就说明它对应的 PV 还在创建过程中。</p>
<p>稍过一会，我们看到已经有一个新的 PV 生成，这个 PV 其实就是根据我们提交的 PVC 以及 PVC 里面指定的storageclass 动态生成的。之后k8s会将生成的 PV 以及我们提交的 PVC，就是这个 disk PVC 做绑定，之后我们就可以通过创建 pod 来使用了。</p>
<p>再看一下 pod yaml：</p>
<p>pod yaml 很简单，也是通过 PVC 声明，表明使用这个 PVC。然后是挂载点，下面我们可以创建看一下。</p>
<p>如下图所示：我们可以大概看一下 Events，首先被调度器调度，调度完之后，接下来会有个 attachdetach controller，它会去做 disk的attach操作，就是把我们对应的 PV 挂载到调度器调度的 node 上，然后Pod对应的容器才能启动，启动容器才能使用对应的盘。</p>
<p>接下来我会把 PVC 删掉，看一下PV 会不会根据我们的 reclaimPolicy 随之删掉呢？我们先看一下，这个时候 PVC 还是存在的，对应的 PV 也是存在的。</p>
<p>然后删一下 PVC，删完之后再看一下：我们的 PV 也被删了，也就是说根据 reclaimPolicy，我们在删除 PVC 的同时，PV 也会被删除掉。</p>
<h1 id="四、架构设计"><a href="#四、架构设计" class="headerlink" title="四、架构设计"></a>四、架构设计</h1><h2 id="PV-和-PVC-的处理流程"><a href="#PV-和-PVC-的处理流程" class="headerlink" title="PV 和 PVC 的处理流程"></a>PV 和 PVC 的处理流程</h2><p>我们接下来看一下 K8s 中的 PV 和 PVC 体系的完整处理流程。我首先看一下这张图的右下部分里面提到的 csi。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-storage/5.png/w600">

<p>csi 是什么？csi 的全称是 container storage interface，它是K8s社区后面对存储插件实现(out of tree)的官方推荐方式。csi 的实现大体可以分为两部分：</p>
<ul>
<li>第一部分是由k8s社区驱动实现的通用的部分，像我们这张图中的 csi-provisioner和 csi-attacher controller；</li>
<li>另外一种是由云存储厂商实践的，对接云存储厂商的 OpenApi，主要是实现真正的 create/delete/mount/unmount 存储的相关操作，对应到上图中的csi-controller-server和csi-node-server。</li>
</ul>
<p>接下来看一下，当用户提交 yaml 之后，k8s内部的处理流程。用户在提交 PVCyaml 的时候，首先会在集群中生成一个 PVC 对象，然后 PVC 对象会被 csi-provisioner controller watch到，csi-provisioner 会结合 PVC 对象以及 PVC 对象中声明的 storageClass，通过 GRPC 调用 csi-controller-server，然后，到云存储服务这边去创建真正的存储，并最终创建出来 PV 对象。最后，由集群中的 PV controller 将 PVC 和 PV 对象做 bound 之后，这个 PV 就可以被使用了。</p>
<p>用户在提交 pod 之后，首先会被调度器调度选中某一个合适的node，之后该 node 上面的 kubelet 在创建 pod 流程中会通过首先 csi-node-server 将我们之前创建的 PV 挂载到我们 pod 可以使用的路径，然后 kubelet 开始  create &amp;&amp; start pod 中的所有 container。</p>
<h2 id="PV、PVC-以及通过-csi-使用存储流程"><a href="#PV、PVC-以及通过-csi-使用存储流程" class="headerlink" title="PV、PVC 以及通过 csi 使用存储流程"></a>PV、PVC 以及通过 csi 使用存储流程</h2><p>我们接下来通过另一张图来更加详细看一下我们 PV、PVC 以及通过 CSI 使用存储的完整流程。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-storage/6.png/w600">

<p>主要分为三个阶段：</p>
<ul>
<li>第一个阶段(Create阶段)是用户提交完 PVC，由 csi-provisioner 创建存储，并生成 PV 对象，之后 PV controller 将 PVC 及生成的 PV 对象做 bound，bound 之后，create 阶段就完成了；</li>
<li>之后用户在提交 pod yaml 的时候，首先会被调度选中某一个 合适的node，等 pod 的运行 node 被选出来之后，会被 AD Controller watch 到 pod 选中的 node，它会去查找 pod 中使用了哪些 PV。然后它会生成一个内部的对象叫 VolumeAttachment 对象，从而去触发 csi-attacher去调用csi-controller-server 去做真正的 attache 操作，attach操作调到云存储厂商OpenAPI。这个 attach 操作就是将存储 attach到 pod 将会运行的 node 上面。第二个阶段 —— attach阶段完成；</li>
<li>然后我们接下来看第三个阶段。第三个阶段 发生在kubelet 创建 pod的过程中，它在创建 pod 的过程中，首先要去做一个 mount，这里的 mount 操作是为了将已经attach到这个 node 上面那块盘，进一步 mount 到 pod 可以使用的一个具体路径，之后 kubelet 才开始创建并启动容器。这就是 PV 加 PVC 创建存储以及使用存储的第三个阶段 —— mount 阶段。</li>
</ul>
<p>总的来说，有三个阶段：</p>
<ul>
<li>第一个 create 阶段，主要是创建存储；</li>
<li>第二个 attach 阶段，就是将那块存储挂载到 node 上面(通常为将存储load到node的/dev下面)；</li>
<li>第三个 mount 阶段，将对应的存储进一步挂载到 pod 可以使用的路径。<br>这就是我们的 PVC、PV、已经通过CSI实现的卷从创建到使用的完整流程。</li>
</ul>
<h1 id="本节总结"><a href="#本节总结" class="headerlink" title="本节总结"></a>本节总结</h1><p>本节课的主要内容就到此为止了，这里为大家简单总结一下。</p>
<div class="note primary">
            <ul><li>介绍了 K8s Volume 的使用场景，以及本身局限性；</li><li>通过介绍 K8s 的 PVC 和 PV 体系，说明 K8s 通过 PVC 和 PV 体系增强了 K8s Volumes 在多 Pod 共享/迁移/存储扩展等场景下的能力的必要性以及设计思想；</li><li>通过介绍 PV（存储）的不同供给模式 (static and dynamic)，学习了如何通过不同方式为集群中的 Pod 供给所需的存储；</li><li>通过 PVC&amp;PV 在 K8s 中完整的处理流程，深入理解 PVC&amp;PV 的工作原理。</li></ul>
          </div>
]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(八)——应用配置管理</title>
    <url>/cn/k8s%E5%BA%94%E7%94%A8%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>本文将主要分享以下内容：</p>
<div class="note primary">
            <ol><li>ConfigMaps 和 Secret 资源的创建和使用；</li><li>Pod 身份认证的实现和原理；</li><li>容器资源、安全、前置校验等配置和使用。</li></ol>
          </div>

<a id="more"></a>
<h1 id="一、需求来源"><a href="#一、需求来源" class="headerlink" title="一、需求来源"></a>一、需求来源</h1><h2 id="背景问题"><a href="#背景问题" class="headerlink" title="背景问题"></a>背景问题</h2><p>首先一起来看一下需求来源。大家应该都有过这样的经验，就是用一个容器镜像来启动一个 container。要启动这个容器，其实有很多需要配套的问题待解决：</p>
<ul>
<li>第一，比如说一些可变的配置。因为我们不可能把一些可变的配置写到镜像里面，当这个配置需要变化的时候，可能需要我们重新编译一次镜像，这个肯定是不能接受的；</li>
<li>第二就是一些敏感信息的存储和使用。比如说应用需要使用一些密码，或者用一些 token；</li>
<li>第三就是我们容器要访问集群自身。比如我要访问 kube-apiserver，那么本身就有一个身份认证的问题；</li>
<li>第四就是容器在节点上运行之后，它的资源需求；</li>
<li>第五个就是容器在节点上，它们是共享内核的，那么它的一个安全管控怎么办？</li>
<li>最后一点我们说一下容器启动之前的一个前置条件检验。比如说，一个容器启动之前，我可能要确认一下 DNS 服务是不是好用？又或者确认一下网络是不是联通的？那么这些其实就是一些前置的校验。</li>
</ul>
<h2 id="Pod-的配置管理"><a href="#Pod-的配置管理" class="headerlink" title="Pod 的配置管理"></a>Pod 的配置管理</h2><p>在 Kubernetes 里面，它是怎么做这些配置管理的呢？如下图所示：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/1.png/w600">

<ul>
<li>可变配置就用 ConfigMap；</li>
<li>敏感信息是用 Secret；</li>
<li>身份认证是用 ServiceAccount 这几个独立的资源来实现的；</li>
<li>资源配置是用 Resources；</li>
<li>安全管控是用 SecurityContext；</li>
<li>前置校验是用 InitContainers 这几个在 spec 里面加的字段，来实现的这些配置管理。</li>
</ul>
<h1 id="二、ConfigMap"><a href="#二、ConfigMap" class="headerlink" title="二、ConfigMap"></a>二、ConfigMap</h1><h2 id="ConfigMap-介绍"><a href="#ConfigMap-介绍" class="headerlink" title="ConfigMap 介绍"></a>ConfigMap 介绍</h2><p>下面我们来介绍第一个部分，就是 ConfigMap。我们先来介绍 ConfigMap 它是用来做什么的、以及它带来的一个好处。它其实主要是管理一些可变配置信息，比如说我们应用的一些配置文件，或者说它里面的一些环境变量，或者一些命令行参数。</p>
<p>它的好处在于它可以让一些可变配置和容器镜像进行解耦，这样也保证了容器的可移植性。看一下下图中右边的编排文件截图。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/2.png/w600">

<p>这是 ConfigMap 本身的一个定义，它包括两个部分：一个是 ConfigMap 元信息，我们关注 name 和 namespace 这两个信息。接下来这个 data 里面，可以看到它管理了两个配置文件。它的结构其实是这样的：从名字看ConfigMap中包含Map单词，Map 其实就是 key:value，key 是一个文件名，value 是这个文件的内容。</p>
<h2 id="ConfigMap-创建"><a href="#ConfigMap-创建" class="headerlink" title="ConfigMap 创建"></a>ConfigMap 创建</h2><p>看过介绍之后，再具体看一下它是怎么创建的。我们推荐用 kubectl 这个命令来创建，它带的参数主要有两个：一个是指定 name，第二个是 DATA。其中 DATA 可以通过指定文件或者指定目录，以及直接指定键值对，下面可以看一下这个例子。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/3.png/w600">

<p>指定文件的话，文件名就是 Map 中的 key，文件内容就是 Map 中的 value。然后指定键值对就是指定数据键值对，即：key:value 形式，直接映射到 Map 的key:value。</p>
<h2 id="ConfigMap-使用"><a href="#ConfigMap-使用" class="headerlink" title="ConfigMap 使用"></a>ConfigMap 使用</h2><p>创建完了之后，应该怎么使用呢？</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/4.png/w600">

<p>如上图所示，主要是在 pod 里来使用 ConfigMap：</p>
<ul>
<li>第一种是环境变量。环境变量的话通过 valueFrom，然后 ConfigMapKeyRef 这个字段，下面的 name 是指定 ConfigMap 名，key 是 ConfigMap.data 里面的 key。这样的话，在 busybox 容器启动后容器中执行 env 将看到一个 SPECIAL_LEVEL_KEY 环境变量；</li>
<li>第二个是命令行参数。命令行参数其实是第一行的环境变量直接拿到 cmd 这个字段里面来用；</li>
<li>最后一个是通过 volume 挂载的方式直接挂到容器的某一个目录下面去。上面的例子是把 special-config 这个 ConfigMap 里面的内容挂到容器里面的 /etc/config 目录下，这个也是使用的一种方式。</li>
</ul>
<h2 id="ConfigMap-注意要点"><a href="#ConfigMap-注意要点" class="headerlink" title="ConfigMap 注意要点"></a>ConfigMap 注意要点</h2><p>现在对 ConfigMap 的使用做一个总结，以及它的一些注意点，注意点一共列了以下五条：</p>
<ol>
<li>ConfigMap 文件的大小。虽然说 ConfigMap 文件没有大小限制，但是在 ETCD 里面，数据的写入是有大小限制的，现在是限制在 1MB 以内；</li>
<li>第二个注意点是 pod 引入 ConfigMap 的时候，必须是相同的 Namespace 中的 ConfigMap，前面其实可以看到，ConfigMap.metadata 里面是有 namespace 字段的；</li>
<li>第三个是 pod 引用的 ConfigMap。假如这个 ConfigMap 不存在，那么这个 pod 是无法创建成功的，其实这也表示在创建 pod 前，必须先把要引用的 ConfigMap 创建好；</li>
<li>第四点就是使用 envFrom 的方式。把 ConfigMap 里面所有的信息导入成环境变量时，如果 ConfigMap 里有些 key 是无效的，比如 key 的名字里面带有数字，那么这个环境变量其实是不会注入容器的，它会被忽略。但是这个 pod 本身是可以创建的。这个和第三点是不一样的方式，是 ConfigMap 文件存在基础上，整体导入成环境变量的一种形式；</li>
<li>最后一点是：什么样的 pod 才能使用 ConfigMap？这里只有通过 K8s api 创建的 pod 才能使用 ConfigMap，比如说通过用命令行 kubectl 来创建的 pod，肯定是可以使用 ConfigMap 的，但其他方式创建的 pod，比如说 kubelet 通过 manifest 创建的 static pod，它是不能使用 ConfigMap 的。</li>
</ol>
<h1 id="三、Secret"><a href="#三、Secret" class="headerlink" title="三、Secret"></a>三、Secret</h1><h2 id="Secret-介绍"><a href="#Secret-介绍" class="headerlink" title="Secret 介绍"></a>Secret 介绍</h2><p>现在我们讲一下 Secret，Secret 是一个主要用来存储密码 token 等一些敏感信息的资源对象。其中，敏感信息是采用 base-64 编码保存起来的，我们来看下图中 Secret 数据的定义。</p>
<p>元数据的话，里面主要是 name、namespace 两个字段；接下来是 type，它是非常重要的一个字段，是指 Secret 的一个类型。Secret 类型种类比较多，下面列了常用的四种类型：</p>
<ul>
<li>第一种是 Opaque，它是普通的 Secret 文件；</li>
<li>第二种是 service-account-token，是用于 service-account 身份认证用的 Secret；</li>
<li>第三种是 dockerconfigjson，这是拉取私有仓库镜像的用的一种 Secret；</li>
<li>第四种是 bootstrap.token，是用于节点接入集群校验用的 Secret。</li>
</ul>
<p>再接下来是 data，是存储的 Secret 的数据，它也是 key-value 的形式存储的。</p>
<h2 id="Secret-创建"><a href="#Secret-创建" class="headerlink" title="Secret 创建"></a>Secret 创建</h2><p>接下来我们看一下 Secret 的创建。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/5.png/w600">

<p>如上图所示，有两种创建方式：</p>
<ul>
<li>系统创建：比如 K8s 为每一个 namespace 的默认用户（default ServiceAccount）创建 Secret；</li>
<li>用户手动创建：手动创建命令，推荐 kubectl 这个命令行工具，它相对 ConfigMap 会多一个 type 参数。其中 data 也是一样，它也是可以指定文件和键值对的。type 的话，要是你不指定的话，默认是 Opaque 类型。</li>
</ul>
<p>上图中两个例子。第一个是通过指定文件，创建了一个拉取私有仓库镜像的 Secret，指定的文件是 /root/.docker/config.json。type 的话指定的是 dockerconfigjson，另外一个我们指定键值对，我们 type 没有指定，默认是 Opaque。键值对是 key:value 的形式，其中对 value 内容进行 base64 加密。创建 Secret 就是这么一个情况。</p>
<h2 id="Secret-使用"><a href="#Secret-使用" class="headerlink" title="Secret 使用"></a>Secret 使用</h2><p>创建完 Secret 之后，再来看一下如何使用它。它主要是被 pod 来使用，一般是通过 volume 形式挂载到容器里指定的目录，然后容器里的业务进程再到目录下读取 Secret 来进行使用。另外在需要访问私有镜像仓库时，也是通过引用 Secret 来实现。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/6.png/w600">

<p>我们先来看一下挂载到用户指定目录的方式：</p>
<ul>
<li>第一种方式：如上图左侧所示，用户直接指定，把 mysecret 挂载到容器 /etc/foo 目录下面；</li>
<li>第二种方式：如上图右侧所示，系统自动生成，把 serviceaccount-secret 自动挂载到容器 /var/run/secrets/kubernetes.io/serviceaccount 目录下，它会生成两个文件，一个是 ca.crt，一个是 token。这是两个保存了认证信息的证书文件。</li>
</ul>
<h2 id="使用私有镜像库"><a href="#使用私有镜像库" class="headerlink" title="使用私有镜像库"></a>使用私有镜像库</h2><p>下面看一下用 Secret 来使用私有镜像仓库。首先，私有镜像仓库的信息是存储在 Secret 里面的(具体参照上述的Secret创建章节)，然后拉取私有仓库镜像，那么通过下图中两种方法的配置就可以：</p>
<ul>
<li>第一种方式：如下图左侧所示，直接在 pod 里面，通过 imagePullSecrets 字段来配置；</li>
<li>第二种方式是自动注入。用户提前在 pod 会使用的 serviceaccount 里配置 imagePullSecrets，Pod创建时系统自动注入这个 imagePullSecrets。<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/7.png/w600">

</li>
</ul>
<h2 id="Secret-使用注意要点"><a href="#Secret-使用注意要点" class="headerlink" title="Secret 使用注意要点"></a>Secret 使用注意要点</h2><p>最后来看一下 Secret 使用的一些注意点，下面列了三点：</p>
<ul>
<li><p>第一个是 Secret 的文件大小限制。这个跟 ConfigMap 一样，也是 1MB；</p>
</li>
<li><p>第二个是 Secret 采用了 base-64 编码，但是它跟明文也没有太大区别。所以说，如果有一些机密信息要用 Secret 来存储的话，还是要很慎重考虑。也就是说谁会来访问你这个集群，谁会来用你这个 Secret，还是要慎重考虑，因为它如果能够访问这个集群，就能拿到这个 Secret。</p>
<p>如果是对 Secret 敏感信息要求很高，对加密这块有很强的需求，推荐可以使用 Kubernetes 和开源的 vault做一个解决方案，来解决敏感信息的加密和权限管理。</p>
</li>
<li><p>第三个就是 Secret 读取的最佳实践，建议不要用 list/watch，如果用 list/watch 操作的话，会把 namespace 下的所有 Secret 全部拉取下来，这样其实暴露了更多的信息。推荐使用 GET 的方法，这样只获取你自己需要的那个 Secret。</p>
</li>
</ul>
<h1 id="四、ServiceAccount"><a href="#四、ServiceAccount" class="headerlink" title="四、ServiceAccount"></a>四、ServiceAccount</h1><h2 id="ServiceAccount-介绍"><a href="#ServiceAccount-介绍" class="headerlink" title="ServiceAccount 介绍"></a>ServiceAccount 介绍</h2><p>接下来，我们讲一下 ServiceAccount。ServiceAccount 首先是用于解决 pod 在集群里面的身份认证问题，身份认证信息是存在于 Secret 里面。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/8.png/w600">

<p>先看一下上面的左侧截图，可以看到最下面的红框里，有一个 Secret 字段，它指定 ServiceAccount 用哪一个 Secret，这个是 K8s 自动为 ServiceAccount 加上的。然后再来看一下上图中的右侧截图，它对应的 Secret 的 data 里有两块数据，一个是 ca.crt，一个是 token。ca.crt 用于对服务端的校验，token 用于 Pod 的身份认证，它们都是用 base64 编码过的。然后可以看到 metadata 即元信息里，其实是有关联 ServiceAccount 信息的（这个 secret 被哪个 ServiceAccount 使用）。最后我们注意一下 type，这个就是 service-account-token 这种类型。</p>
<p>举例：Pod 里的应用访问它所属的 K8s 集群</p>
<p>介绍完 ServiceAccount 以及它对应的 secret 后，我们来看一下，pod 是怎么利用 ServiceAccount 或者说它是怎么利用 secret 来访问所属 K8s 集群的。</p>
<p>其实 pod 创建的时候，首先它会把这个 secret 挂载到容器固定的目录下，这是 K8s 功能上实现的。它要把这个 ca.crt 和 token 这两个文件挂载到固定目录下面。</p>
<p>pod 要访问集群的时候，它是怎么来利用这个文件的呢？我们看一下下面的代码截图：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/9.png/w600">

<p>我们在 Go 里面实现 Pod 访问 K8s 集群时，一般直接会调一个 InClusterConfig 方法，来生成这个访问服务 Client 的一些信息。然后可以看一下，最后这个 Config 里面有两部分信息：</p>
<ul>
<li>一个是 tlsClientConfig，这个主要是用于 ca.crt 校验服务端；</li>
<li>第二个是 Bearer Token，这个就是 pod 的身份认证。在服务端，会利用 token 对 pod 进行一个身份认证。</li>
</ul>
<p>再次回到上图左侧。认证完之后 pod 的身份信息会有两部分：一个是 Group，一个是 User。身份认证是就是认证这两部分信息。接着可以使用 RBAC 功能，对 pod 进行一个授权管理。</p>
<p>假如 RBAC 没有配置的话，默认的 pod 具有资源 GET 权限，就是可以从所属的 K8s 集群里 get 数据。如果是需要更多的权限，那么就需要 自行配置 RBAC 。RBAC 的相关知识，我们在后面的课程里面会详细介绍，大家可以关注一下。</p>
<h1 id="五、Resource"><a href="#五、Resource" class="headerlink" title="五、Resource"></a>五、Resource</h1><h2 id="容器资源配合管理"><a href="#容器资源配合管理" class="headerlink" title="容器资源配合管理"></a>容器资源配合管理</h2><p>下面介绍一下 Resource，即：容器的一个资源配置管理。</p>
<p>目前内部支持类型有三种：CPU、内存，以及临时存储。当用户觉得这三种不够，有自己的一些资源，比如说 GPU，或者其他资源，也可以自己来定义，但配置时，指定的数量必须为整数。目前资源配置主要分成 request 和 limit 两种类型，一个是需要的数量，一个是资源的界限。CPU、内存以及临时存储都是在 container 下的 Resource 字段里进行一个声明。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/10.png/w600">

<p>举个例子，wordpress 容器的资源需求，一个是 request ，一个是 limits，它分别对需要的资源和资源临界进行一个声明。</p>
<h2 id="Pod-服务质量-QoS-配置"><a href="#Pod-服务质量-QoS-配置" class="headerlink" title="Pod 服务质量 (QoS) 配置"></a>Pod 服务质量 (QoS) 配置</h2><p>根据 CPU 对容器内存资源的需求，我们对 pod 的服务质量进行一个分类，分别是 Guaranteed、Burstable 和 BestEffort。</p>
<ul>
<li>Guaranteed ：pod 里面每个容器都必须有内存和 CPU 的 request 以及 limit 的一个声明，且 request 和 limit 必须是一样的，这就是 Guaranteed；</li>
<li>Burstable：Burstable 至少有一个容器存在内存和 CPU 的一个 request；</li>
<li>BestEffort：只要不是 Guaranteed 和 Burstable，那就是 BestEffort。</li>
</ul>
<p>那么这个服务质量是什么样的呢？资源配置好后，当这个节点上 pod 容器运行，比如说节点上 memory 配额资源不足，kubelet会把一些低优先级的，或者说服务质量要求不高的（如：BestEffort、Burstable）pod 驱逐掉。它们是按照先去除 BestEffort，再去除 Burstable 的一个顺序来驱逐 pod 的。</p>
<h1 id="六、SecurityContext"><a href="#六、SecurityContext" class="headerlink" title="六、SecurityContext"></a>六、SecurityContext</h1><h2 id="SecurityContext-介绍"><a href="#SecurityContext-介绍" class="headerlink" title="SecurityContext 介绍"></a>SecurityContext 介绍</h2><p>SecurityContext 主要是用于限制容器的一个行为，它能保证系统和其他容器的安全。这一块的能力不是 Kubernetes 或者容器 runtime 本身的能力，而是 Kubernetes 和 runtime 通过用户的配置，最后下传到内核里，再通过内核的机制让 SecurityContext 来生效。所以这里讲的内容，会比较简单或者说比较抽象一点。</p>
<p>SecurityContext 主要分为三个级别：</p>
<ul>
<li>第一个是容器级别，仅对容器生效；</li>
<li>第二个是 pod 级别，对 pod 里所有容器生效；</li>
<li>第三个是集群级别，就是 PSP，对集群内所有 pod 生效。</li>
</ul>
<p>权限和访问控制设置项，现在一共列有七项（这个数量后续可能会变化）：</p>
<ol>
<li>第一个就是通过用户 ID 和组 ID 来控制文件访问权限；</li>
<li>第二个是 SELinux，它是通过策略配置来控制用户或者进程对文件的访问控制；</li>
<li>第三个是特权容器；</li>
<li>第四个是 Capabilities，它也是给特定进程来配置一个 privileged 能力；</li>
<li>第五个是 AppArmor，它也是通过一些配置文件来控制可执行文件的一个访问控制权限，比如说一些端口的读写；</li>
<li>第六个是一个对系统调用的控制；</li>
<li>第七个是对子进程能否获取比父亲更多的权限的一个限制。</li>
</ol>
<p>最后其实都是落到内核来控制它的一些权限。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/11.png/w600">
<p>上图是对 pod 级别和容器级别配置 SecurityContext 的一个例子，如果大家对这些内容有更多的需求，可以根据这些信息去搜索更深入的资料来学习。</p>
<h1 id="七、InitContainer"><a href="#七、InitContainer" class="headerlink" title="七、InitContainer"></a>七、InitContainer</h1><h2 id="InitContainer-介绍"><a href="#InitContainer-介绍" class="headerlink" title="InitContainer 介绍"></a>InitContainer 介绍</h2><p>接下来看一下 InitContainer，首先介绍 InitContainer 和普通 container 的区别，有以下三点内容：</p>
<ol>
<li>InitContainer 首先会比普通 container 先启动，并且直到所有的 InitContainer 执行成功后，普通 container 才会被启动；</li>
<li>InitContainer 之间是按定义的次序去启动执行的，执行成功一个之后再执行第二个，而普通的 container 是并发启动的；</li>
<li>InitContainer 执行成功后就结束退出，而普通容器可能会一直在执行。它可能是一个 longtime 的，或者说失败了会重启，这个也是 InitContainer 和普通 container 不同的地方。</li>
</ol>
<p>根据上面三点内容，我们看一下 InitContainer 的一个用途。它其实主要为普通 container 服务，比如说它可以为普通 container 启动之前做一个初始化，或者为它准备一些配置文件， 配置文件可能是一些变化的东西。再比如做一些前置条件的校验，如网络是否联通。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-config/12.png/w600">

<p>上面的截图是 flannel 组件的 InitContainer 的一个配置，它的 InitContainer 主要是为 kube-flannel 这个普通容器启动之前准备一些网络配置文件。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><div class="note primary">
            <ol><li>ConfigMap 和 Secret: 首先介绍了 ConfigMap 和 Secret 的创建方法和使用场景，然后对 ConfigMap 和 Secret 的常见使用注意点进行了分类和整理。最后介绍了私有仓库镜像的使用和配置；</li><li>Pod 身份认证: 首先介绍了 ServiceAccount 和 Secret 的关联关系，然后从源码角度对 Pod 身份认证流程和实现细节进行剖析，同时引出了 Pod 的权限管理(即 RBAC 的配置管理)；</li><li>容器资源和安全： 首先介绍了容器常见资源类型 (CPU/Memory) 的配置，然后对 Pod 服务质量分类进行详细的介绍。同时对 SecurityContext 有效层级和权限配置项进行简要说明；</li><li>InitContainer: 首先介绍了 InitContainer 和普通 container 的区别以及InitContainer 的用途。然后基于实际用例对 InitContainer 的用途进行了说明。</li></ol>
          </div>
]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(四)——理解Pod和容器设计模式</title>
    <url>/cn/k8s%E7%90%86%E8%A7%A3Pod%E5%92%8C%E5%AE%B9%E5%99%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<p>本章的分享主要围绕以下三个部分：</p>
<div class="note primary">
            <ul><li>为什么需要 Pod；</li><li>Pod 的实现机制；</li><li>详解容器设计模式。</li></ul>
          </div>

<a id="more"></a> 

<h1 id="一、为什么需要-Pod"><a href="#一、为什么需要-Pod" class="headerlink" title="一、为什么需要 Pod"></a>一、为什么需要 Pod</h1><h2 id="容器的基本概念"><a href="#容器的基本概念" class="headerlink" title="容器的基本概念"></a>容器的基本概念</h2><p>现在来看第一个问题：为什么需要 Pod？我们知道 Pod 是 Kubernetes 项目里面一个非常重要的概念，也是非常重要的一个原子调度单位，但是为什么我们会需要这样一个概念呢？我们在使用容器 Docker 的时候，也没有这个说法。其实如果要理解 Pod，我们首先要理解容器，所以首先来回顾一下容器的概念：</p>
<p><strong>容器的本质实际上是一个进程，是一个视图被隔离，资源受限的进程。</strong></p>
<p>容器里面 PID=1 的进程就是应用本身，这意味着管理虚拟机等于管理基础设施，因为我们是在管理机器，但管理容器却等于直接管理应用本身。这也是之前说过的不可变基础设施的一个最佳体现，这个时候，你的应用就等于你的基础设施，它一定是不可变的。</p>
<p>在以上面的例子为前提的情况下，Kubernetes 又是什么呢？我们知道，很多人都说 Kubernetes 是云时代的操作系统，这个非常有意思，因为如果以此类推，容器镜像就是这个操作系统的软件安装包，它们之间是这样的一个类比关系。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-hg-container.png/w600">

<h2 id="真实操作系统里的例子"><a href="#真实操作系统里的例子" class="headerlink" title="真实操作系统里的例子"></a>真实操作系统里的例子</h2><p>如果说 Kubernetes 就是操作系统的话，那么我们不妨看一下真实的操作系统的例子。</p>
<p>例子里面有一个程序叫做 Helloworld，这个 Helloworld 程序实际上是由一组进程组成的，需要注意一下，这里说的进程实际上等同于 Linux 中的线程。</p>
<p>因为 Linux 中的线程是轻量级进程，所以如果从 Linux 系统中去查看 Helloworld 中的 pstree，将会看到这个 Helloworld 实际上是由四个线程组成的，分别是 {api、main、log、compute}。也就是说，四个这样的线程共同协作，共享 Helloworld 程序的资源，组成了 Helloworld 程序的真实工作情况。</p>
<p>这是操作系统里面进程组或者线程组中一个非常真实的例子，以上就是进程组的一个概念。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-real-os-demo.png/w600">

<p>那么大家不妨思考一下，在真实的操作系统里面，一个程序往往是根据进程组来进行管理的。Kubernetes 把它类比为一个操作系统，比如说 Linux。针对于容器我们前面提到可以类比为进程，就是前面的 Linux 线程。那么 Pod 又是什么呢？实际上 Pod 就是我们刚刚提到的进程组，也就是 Linux 里的线程组。</p>
<h2 id="进程组概念"><a href="#进程组概念" class="headerlink" title="进程组概念"></a>进程组概念</h2><p>说到进程组，首先建议大家至少有个概念上的理解，然后我们再详细的解释一下。</p>
<p>还是前面那个例子：Helloworld 程序由四个进程组成，这些进程之间会共享一些资源和文件。那么现在有一个问题：假如说现在把 Helloworld 程序用容器跑起来，你会怎么去做？</p>
<p>当然，最自然的一个解法就是，我现在就启动一个 Docker 容器，里面运行四个进程。可是这样会有一个问题，这种情况下容器里面 PID=1 的进程该是谁? 比如说，它应该是我的 main 进程，那么问题来了，“谁”又负责去管理剩余的 3 个进程呢？</p>
<p>这个核心问题在于，容器的设计本身是一种“单进程”模型，不是说容器里只能起一个进程，由于容器的应用等于进程，所以只能去管理 PID=1 的这个进程，其他再起来的进程其实是一个托管状态。 所以说服务应用进程本身就具有“进程管理”的能力。</p>
<p>比如说 Helloworld 的程序有 system 的能力，或者直接把容器里 PID=1 的进程直接改成 systemd，否则这个应用，或者是容器是没有办法去管理很多个进程的。因为 PID=1 进程是应用本身，如果现在把这个 PID=1 的进程给 kill 了，或者它自己运行过程中死掉了，那么剩下三个进程的资源就没有人回收了，这个是非常非常严重的一个问题。</p>
<p>而反过来真的把这个应用本身改成了 systemd，或者在容器里面运行了一个 systemd，将会导致另外一个问题：使得管理容器，不再是管理应用本身了，而等于是管理 systemd，这里的问题就非常明显了。比如说我这个容器里面 run 的程序或者进程是 systemd，那么接下来，这个应用是不是退出了？是不是 fail 了？是不是出现异常失败了？实际上是没办法直接知道的，因为容器管理的是 systemd。这就是为什么在容器里面运行一个复杂程序往往比较困难的一个原因。</p>
<p>这里再帮大家梳理一下：<strong>由于容器实际上是一个“单进程”模型</strong>，所以如果你在容器里启动多个进程，只有一个可以作为 PID=1 的进程，而这时候，如果这个 PID=1 的进程挂了，或者说失败退出了，那么其他三个进程就会自然而然的成为孤儿，没有人能够管理它们，没有人能够回收它们的资源，这是一个非常不好的情况。</p>
<div class="note warning">
            <p>注意：Linux 容器的“单进程”模型，指的是容器的生命周期等同于 PID=1 的进程（容器应用进程）的生命周期，而不是说容器里不能创建多进程。当然，一般情况下，容器应用进程并不具备进程管理能力，所以你通过 exec 或者 ssh 在容器里创建的其他进程，一旦异常退出（比如 ssh 终止）是很容易变成孤儿进程的。</p>
          </div>

<p>反过来，其实可以在容器里面 run 一个 systemd，用它来管理其他所有的进程。这样会产生第二个问题：实际上没办法直接管理我的应用了，因为我的应用被 systemd 给接管了，那么这个时候应用状态的生命周期就不等于容器生命周期。这个管理模型实际上是非常非常复杂的。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-cgroup.png/w600">

<h2 id="Pod-“进程组”"><a href="#Pod-“进程组”" class="headerlink" title="Pod = “进程组”"></a>Pod = “进程组”</h2><p>在 kubernetes 里面，Pod 实际上正是 kubernetes 项目为你抽象出来的一个可以类比为进程组的概念。</p>
<p>前面提到的，由四个进程共同组成的一个应用 Helloworld，在 Kubernetes 里面，实际上会被定义为一个拥有四个容器的 Pod，这个概念大家一定要非常仔细的理解。</p>
<p>就是说现在有四个职责不同、相互协作的进程，需要放在容器里去运行，在 Kubernetes 里面并不会把它们放到一个容器里，因为这里会遇到两个问题。那么在 Kubernetes 里会怎么去做呢？它会把四个独立的进程分别用四个独立的容器启动起来，然后把它们定义在一个 Pod 里面。</p>
<p>所以当 Kubernetes 把 Helloworld 给拉起来的时候，你实际上会看到四个容器，它们共享了某些资源，这些资源都属于 Pod，所以我们说 Pod 在 Kubernetes 里面只有一个逻辑单位，没有一个真实的东西对应说这个就是 Pod，不会有的。真正起来在物理上存在的东西，就是四个容器。这四个容器，或者说是多个容器的组合就叫做 Pod。并且还有一个概念一定要非常明确，Pod 是 Kubernetes 分配资源的一个单位，因为里面的容器要共享某些资源，所以 Pod 也是 Kubernetes 的原子调度单位。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-cgroup-pod.png/w600">

<p>上面提到的 Pod 设计，也不是 Kubernetes 项目自己想出来的， 而是早在 Google 研发 Borg 的时候，就已经发现了这样一个问题。这个在 Borg paper 里面有非常非常明确的描述。简单来说 Google 工程师发现在 Borg 下面部署应用时，很多场景下都存在着类似于“进程与进程组”的关系。更具体的是，这些应用之前往往有着密切的协作关系，使得它们必须部署在同一台机器上并且共享某些信息。</p>
<p>以上就是进程组的概念，也是 Pod 的用法。</p>
<h2 id="为什么-Pod-必须是原子调度单位？"><a href="#为什么-Pod-必须是原子调度单位？" class="headerlink" title="为什么 Pod 必须是原子调度单位？"></a>为什么 Pod 必须是原子调度单位？</h2><p>可能到这里大家会有一些问题：虽然了解这个东西是一个进程组，但是为什么要把 Pod 本身作为一个概念抽象出来呢？或者说能不能通过调度把 Pod 这个事情给解决掉呢？为什么 Pod 必须是 Kubernetes 里面的原子调度单位？ </p>
<p>下面我们通过一个例子来解释。</p>
<p>假如现在有两个容器，它们是紧密协作的，所以它们应该被部署在一个 Pod 里面。具体来说，第一个容器叫做 App，就是业务容器，它会写日志文件；第二个容器叫做 LogCollector，它会把刚刚 App 容器写的日志文件转发到后端的 ElasticSearch 中。</p>
<p>两个容器的资源需求是这样的：App 容器需要 1G 内存，LogCollector 需要 0.5G 内存，而当前集群环境的可用内存是这样一个情况：Node_A：1.25G 内存，Node_B：2G 内存。</p>
<p>假如说现在没有 Pod 概念，就只有两个容器，这两个容器要紧密协作、运行在一台机器上。可是，如果调度器先把 App 调度到了 Node_A 上面，接下来会怎么样呢？这时你会发现：LogCollector 实际上是没办法调度到 Node_A 上的，因为资源不够。其实此时整个应用本身就已经出问题了，调度已经失败了，必须去重新调度。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-why-pod.png/w600">

<p>以上就是一个非常典型的成组调度失败的例子。英文叫做：Task co-scheduling 问题，这个问题不是说不能解，在很多项目里面，这样的问题都有解法。</p>
<p>比如说在 Mesos 里面，它会做一个事情，叫做资源囤积（resource hoarding）：即当所有设置了 Affinity 约束的任务都达到时，才开始统一调度，这是一个非常典型的成组调度的解法。</p>
<p>所以上面提到的“App”和“LogCollector”这两个容器，在 Mesos 里面，他们不会说立刻调度，而是等两个容器都提交完成，才开始统一调度。这样也会带来新的问题，首先调度效率会损失，因为需要等待。由于需要等还会有外一个情况会出现，就是产生死锁，就是互相等待的一个情况。这些机制在 Mesos 里都是需要解决的，也带来了额外的复杂度。</p>
<p>另一种解法是 Google 的解法。它在 Omega 系统（就是 Borg 下一代）里面，做了一个非常复杂且非常厉害的解法，叫做乐观调度。比如说：不管这些冲突的异常情况，先调度，同时设置一个非常精妙的回滚机制，这样经过冲突后，通过回滚来解决问题。这个方式相对来说要更加优雅，也更加高效，但是它的实现机制是非常复杂的。这个有很多人也能理解，就是悲观锁的设置一定比乐观锁要简单。</p>
<p>而像这样的一个 Task co-scheduling 问题，在 Kubernetes 里，就直接通过 Pod 这样一个概念去解决了。因为在 Kubernetes 里，这样的一个 App 容器和 LogCollector 容器一定是属于一个 Pod 的，它们在调度时必然是以一个 Pod 为单位进行调度，所以这个问题是根本不存在的。</p>
<h2 id="再次理解-Pod"><a href="#再次理解-Pod" class="headerlink" title="再次理解 Pod"></a>再次理解 Pod</h2><p>在讲了前面这些知识点之后，我们来再次理解一下 Pod，首先 Pod 里面的容器是“超亲密关系”。</p>
<p>这里有个“超”字需要大家理解，正常来说，有一种关系叫做亲密关系，这个亲密关系是一定可以通过调度来解决的。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-again-pod.png/w600">

<p>比如说现在有两个 Pod，它们需要运行在同一台宿主机上，那这样就属于亲密关系，调度器一定是可以帮助去做的。但是对于超亲密关系来说，有一个问题，即它必须通过 Pod 来解决。因为如果超亲密关系赋予不了，那么整个 Pod 或者说是整个应用都无法启动。</p>
<p>什么叫做超亲密关系呢？大概分为以下几类：</p>
<ul>
<li>比如说两个进程之间会发生文件交换，前面提到的例子就是这样，一个写日志，一个读日志；</li>
<li>两个进程之间需要通过 localhost 或者说是本地的 Socket 去进行通信，这种本地通信也是超亲密关系；</li>
<li>这两个容器或者是微服务之间，需要发生非常频繁的 RPC 调用，出于性能的考虑，也希望它们是超亲密关系；</li>
<li>两个容器或者是应用，它们需要共享某些 Linux Namespace。最简单常见的一个例子，就是我有一个容器需要加入另一个容器的 Network Namespace。这样我就能看到另一个容器的网络设备，和它的网络信息。</li>
</ul>
<p>像以上几种关系都属于超亲密关系，它们都是在 Kubernetes 中会通过 Pod 的概念去解决的。</p>
<p>现在我们理解了 Pod 这样的概念设计，理解了为什么需要 Pod。它解决了两个问题：</p>
<ul>
<li>我们怎么去描述超亲密关系；</li>
<li>我们怎么去对超亲密关系的容器或者说是业务去做统一调度，这是 Pod 最主要的一个诉求。</li>
</ul>
<h1 id="二、Pod-的实现机制"><a href="#二、Pod-的实现机制" class="headerlink" title="二、Pod 的实现机制"></a>二、Pod 的实现机制</h1><h2 id="Pod-要解决的问题"><a href="#Pod-要解决的问题" class="headerlink" title="Pod 要解决的问题"></a>Pod 要解决的问题</h2><p>像 Pod 这样一个东西，本身是一个逻辑概念。那在机器上，它究竟是怎么实现的呢？这就是我们要解释的第二个问题。</p>
<p>既然说 Pod 要解决这个问题，核心就在于如何让一个 Pod 里的多个容器之间最高效的共享某些资源和数据。 </p>
<p>因为容器之间原本是被 Linux Namespace 和 cgroups 隔开的，所以现在实际要解决的是怎么去打破这个隔离，然后共享某些事情和某些信息。这就是 Pod 的设计要解决的核心问题所在。</p>
<p><strong>所以说具体的解法分为两个部分：网络和存储。</strong></p>
<h3 id="1-共享网络"><a href="#1-共享网络" class="headerlink" title="1.共享网络"></a>1.共享网络</h3><p>第一个问题是 Pod 里的多个容器怎么去共享网络？下面是个例子：</p>
<p>比如说现在有一个 Pod，其中包含了一个容器 A 和一个容器 B，它们两个就要共享 Network Namespace。在 Kubernetes 里的解法是这样的：它会在每个 Pod 里，额外起一个 Infra container 小容器来共享整个 Pod 的  Network Namespace。</p>
<p>Infra container 是一个非常小的镜像，大概 100~200KB 左右，是一个汇编语言写的、永远处于“暂停”状态的容器。由于有了这样一个 Infra container 之后，其他所有容器都会通过 Join Namespace 的方式加入到 Infra container 的 Network Namespace 中。</p>
<p>所以说一个 Pod 里面的所有容器，它们看到的网络视图是完全一样的。即：它们看到的网络设备、IP地址、Mac地址等等，跟网络相关的信息，其实全是一份，这一份都来自于 Pod 第一次创建的这个 Infra container。这就是 Pod 解决网络共享的一个解法。</p>
<p>在 Pod 里面，一定有一个 IP 地址，是这个 Pod 的 Network Namespace 对应的地址，也是这个 Infra container 的 IP 地址。所以大家看到的都是一份，而其他所有网络资源，都是一个 Pod 一份，并且被 Pod 中的所有容器共享。这就是 Pod 的网络实现方式。</p>
<p>由于需要有一个相当于说中间的容器存在，所以整个 Pod 里面，必然是 Infra container 第一个启动。并且整个 Pod 的生命周期是等同于 Infra container 的生命周期的，与容器 A 和 B 是无关的。这也是为什么在 Kubernetes 里面，它是允许去单独更新 Pod 里的某一个镜像的，即：做这个操作，整个 Pod 不会重建，也不会重启，这是非常重要的一个设计。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-share-inte.png/w600">

<h3 id="2-共享存储"><a href="#2-共享存储" class="headerlink" title="2.共享存储"></a>2.共享存储</h3><p>第二问题：Pod 怎么去共享存储？Pod 共享存储就相对比较简单。</p>
<p>比如说现在有两个容器，一个是 Nginx，另外一个是非常普通的容器，在 Nginx 里放一些文件，让我能通过 Nginx 访问到。所以它需要去 share 这个目录。我 share 文件或者是 share 目录在 Pod 里面是非常简单的，实际上就是把 volume 变成了 Pod level。然后所有容器，就是所有同属于一个 Pod 的容器，他们共享所有的 volume。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-share-volumn.png/w600">

<p>比如说上图的例子，这个 volume 叫做 shared-data，它是属于 Pod level 的，所以在每一个容器里可以直接声明：要挂载 shared-data 这个 volume，只要你声明了你挂载这个 volume，你在容器里去看这个目录，实际上大家看到的就是同一份。这个就是 Kubernetes 通过 Pod 来给容器共享存储的一个做法。</p>
<p>所以在之前的例子中，应用容器 App 写了日志，只要这个日志是写在一个 volume 中，只要声明挂载了同样的 volume，这个 volume 就可以立刻被另外一个 LogCollector 容器给看到。以上就是 Pod 实现存储的方式。</p>
<h1 id="三、详解容器设计模式"><a href="#三、详解容器设计模式" class="headerlink" title="三、详解容器设计模式"></a>三、详解容器设计模式</h1><p>现在我们知道了为什么需要 Pod，也了解了 Pod 这个东西到底是怎么实现的。最后，以此为基础，详细介绍一下 Kubernetes 非常提倡的一个概念，叫做容器设计模式。</p>
<p><strong>举例</strong><br>接下来将会用一个例子来给大家进行讲解。</p>
<p>比如我现在有一个非常常见的一个诉求：我现在要发布一个应用，这个应用是 JAVA 写的，有一个 WAR 包需要把它放到 Tomcat 的 web APP 目录下面，这样就可以把它启动起来了。可是像这样一个 WAR 包或 Tomcat 这样一个容器的话，怎么去做，怎么去发布？这里面有几种做法。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-war-tomcat.png/w600">

<ul>
<li><p>第一种方式：可以把 WAR 包和 Tomcat 打包放进一个镜像里面。但是这样带来一个问题，就是现在这个镜像实际上揉进了两个东西。那么接下来，无论是我要更新 WAR 包还是说我要更新 Tomcat，都要重新做一个新的镜像，这是比较麻烦的；</p>
</li>
<li><p>第二种方式：就是镜像里面只打包 Tomcat。它就是一个 Tomcat，但是需要使用数据卷的方式，比如说 hostPath，从宿主机上把 WAR 包挂载进我们 Tomcat 容器中，挂到我的 web APP 目录下面，这样把这个容器启用起来之后，里面就能用了。</p>
</li>
</ul>
<p>但是这时会发现一个问题：这种做法一定需要维护一套分布式存储系统。因为这个容器可能第一次启动是在宿主机 A 上面，第二次重新启动就可能跑到 B 上去了，容器它是一个可迁移的东西，它的状态是不保持的。所以必须维护一套分布式存储系统，使容器不管是在 A 还是在 B 上，都可以找到这个 WAR 包，找到这个数据。</p>
<p>注意，即使有了分布式存储系统做 Volume，你还需要负责维护 Volume 里的 WAR 包。比如：你需要单独写一套 Kubernetes Volume 插件，用来在每次 Pod 启动之前，把应用启动所需的 WAR 包下载到这个 Volume 里，然后才能被应用挂载使用到。</p>
<p>这样操作带来的复杂程度还是比较高的，且这个容器本身必须依赖于一套持久化的存储插件（用来管理 Volume 里的 WAR 包内容）。</p>
<h2 id="InitContainer"><a href="#InitContainer" class="headerlink" title="InitContainer"></a>InitContainer</h2><p>所以大家有没有考虑过，像这样的组合方式，有没有更加通用的方法？哪怕在本地 Kubernetes 上，没有分布式存储的情况下也能用、能玩、能发布。</p>
<p>实际上方法是有的，在 Kubernetes 里面，像这样的组合方式，叫做 Init Container。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-initcontainer.png/w600">

<p>还是同样一个例子：在上图的 yaml 里，首先定义一个 Init Container，它只做一件事情，就是把 WAR 包从镜像里拷贝到一个 Volume 里面，它做完这个操作就退出了，所以 Init Container 会比用户容器先启动，并且严格按照定义顺序来依次执行。</p>
<p>然后，这个关键在于刚刚拷贝到的这样一个目的目录：APP 目录，实际上是一个 Volume。而我们前面提到，一个 Pod 里面的多个容器，它们是可以共享 Volume 的，所以现在这个 Tomcat 容器，只是打包了一个 Tomcat 镜像。但在启动的时候，要声明使用 APP 目录作为我的 Volume，并且要把它们挂载在 Web APP 目录下面。</p>
<p>而这个时候，由于前面已经运行过了一个 Init Container，已经执行完拷贝操作了，所以这个 Volume 里面已经存在了应用的 WAR 包：就是 sample.war，绝对已经存在这个 Volume 里面了。等到第二步执行启动这个 Tomcat 容器的时候，去挂这个 Volume，一定能在里面找到前面拷贝来的 sample.war。 </p>
<p>所以可以这样去描述：这个 Pod 就是一个自包含的，可以把这一个 Pod 在全世界任何一个 Kubernetes 上面都顺利启用起来。不用担心没有分布式存储、Volume 不是持久化的，它一定是可以公布的。</p>
<p>所以这是一个通过组合两个不同角色的容器，并且按照这样一些像 Init Container 这样一种编排方式，统一的去打包这样一个应用，把它用 Pod 来去做的非常典型的一个例子。像这样的一个概念，在 Kubernetes 里面就是一个非常经典的容器设计模式，叫做：“Sidecar”。</p>
<h2 id="容器设计模式：Sidecar"><a href="#容器设计模式：Sidecar" class="headerlink" title="容器设计模式：Sidecar"></a>容器设计模式：Sidecar</h2><p>什么是 Sidecar？就是说其实在 Pod 里面，可以定义一些专门的容器，来执行主业务容器所需要的一些辅助工作，比如我们前面举的例子，其实就干了一个事儿，这个 Init Container，它就是一个 Sidecar，它只负责把镜像里的 WAR 包拷贝到共享目录里面，以便被 Tomcat 能够用起来。</p>
<p>其它有哪些操作呢？比如说：</p>
<ul>
<li><p>原本需要在容器里面执行 SSH 需要干的一些事情，可以写脚本、一些前置的条件，其实都可以通过像 Init Container 或者另外像 Sidecar 的方式去解决；</p>
</li>
<li><p>当然还有一个典型例子就是我的日志收集，日志收集本身是一个进程，是一个小容器，那么就可以把它打包进 Pod 里面去做这个收集工作；</p>
</li>
<li><p>还有一个非常重要的东西就是 Debug 应用，实际上现在 Debug 整个应用都可以在应用 Pod 里面再次定义一个额外的小的 Container，它可以去 exec 应用 pod 的 namespace；</p>
</li>
<li><p>查看其他容器的工作状态，这也是它可以做的事情。不再需要去 SSH 登陆到容器里去看，只要把监控组件装到额外的小容器里面就可以了，然后把它作为一个 Sidecar 启动起来，跟主业务容器进行协作，所以同样业务监控也都可以通过 Sidecar 方式来去做。</p>
</li>
</ul>
<p>这种做法一个非常明显的优势就是在于其实将辅助功能从我的业务容器解耦了，所以我就能够独立发布 Sidecar 容器，并且更重要的是这个能力是可以重用的，即同样的一个监控 Sidecar 或者日志 Sidecar，可以被全公司的人共用的。这就是设计模式的一个威力。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-sidecar-design.png/w600">

<h3 id="Sidecar：应用与日志收集"><a href="#Sidecar：应用与日志收集" class="headerlink" title="Sidecar：应用与日志收集"></a>Sidecar：应用与日志收集</h3><p>接下来，我们再详细细化一下 Sidecar 这样一个模式，它还有一些其他的场景。</p>
<p>比如说前面提到的应用日志收集，业务容器将日志写在一个 Volume 里面，而由于 Volume 在 Pod 里面是被共享的，所以日志容器 —— 即 Sidecar 容器一定可以通过共享该 Volume，直接把日志文件读出来，然后存到远程存储里面，或者转发到另外一个例子。现在业界常用的 Fluentd 日志进程或日志组件，基本上都是这样的工作方式。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-sidecar-app.png/w600"> 

<h3 id="Sidecar：代理容器"><a href="#Sidecar：代理容器" class="headerlink" title="Sidecar：代理容器"></a>Sidecar：代理容器</h3><p>Sidecar 的第二个用法，可以称作为代理容器 Proxy。什么叫做代理容器呢？</p>
<p>假如现在有个 Pod 需要访问一个外部系统，或者一些外部服务，但是这些外部系统是一个集群，那么这个时候如何通过一个统一的、简单的方式，用一个 IP 地址，就把这些集群都访问到？有一种方法就是：修改代码。因为代码里记录了这些集群的地址；另外还有一种解耦的方法，即通过 Sidecar 代理容器。</p>
<p>简单说，单独写一个这么小的 Proxy，用来处理对接外部的服务集群，它对外暴露出来只有一个 IP 地址就可以了。所以接下来，业务容器主要访问 Proxy，然后由 Proxy 去连接这些服务集群，这里的关键在于 Pod 里面多个容器是通过 localhost 直接通信的，因为它们同属于一个 network Namespace，网络视图都一样，所以它们俩通信 localhost，并没有性能损耗。</p>
<p>所以说代理容器除了做了解耦之外，并不会降低性能，更重要的是，像这样一个代理容器的代码就又可以被全公司重用了。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-sidecar-proxy.png/w600">

<h3 id="Sidecar：适配器容器"><a href="#Sidecar：适配器容器" class="headerlink" title="Sidecar：适配器容器"></a>Sidecar：适配器容器</h3><p>Sidecar 的第三个设计模式 —— 适配器容器 Adapter，什么叫 Adapter 呢？</p>
<p>现在业务暴露出来的 API，比如说有个 API 的一个格式是 A，但是现在有一个外部系统要去访问我的业务容器，它只知道的一种格式是 API B ,所以要做一个工作，就是把业务容器怎么想办法改掉，要去改业务代码。但实际上，你可以通过一个 Adapter 帮你来做这层转换。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-k8s-pod/k8s-sidecar-adapter.png/w600">

<p>现在有个例子：现在业务容器暴露出来的监控接口是 /metrics，访问这个这个容器的 metrics 的这个 URL 就可以拿到了。可是现在，这个监控系统升级了，它访问的 URL 是 /health，我只认得暴露出 health 健康检查的 URL，才能去做监控，metrics 不认识。那这个怎么办？那就需要改代码了，但可以不去改代码，而是额外写一个 Adapter，用来把所有对 health 的这个请求转发给 metrics 就可以了，所以这个 Adapter 对外暴露的是 health 这样一个监控的 URL，这就可以了，你的业务就又可以工作了。</p>
<p>这样的关键还在于 Pod 之中的容器是通过 localhost 直接通信的，所以没有性能损耗，并且这样一个 Adapter 容器可以被全公司重用起来，这些都是设计模式给我们带来的好处。</p>
<h1 id="本节总结"><a href="#本节总结" class="headerlink" title="本节总结"></a>本节总结</h1><div class="note danger">
            <ul><li>Pod 是 Kubernetes 项目里实现“容器设计模式”的核心机制；</li><li>“容器设计模式”是 Google Borg 的大规模容器集群管理最佳实践之一，也是 Kubernetes 进行复杂应用编排的基础依赖之一；</li><li>所有“设计模式”的本质都是：解耦和重用。</li></ul>
          </div>

<h1 id="点评"><a href="#点评" class="headerlink" title="点评"></a>点评</h1><p>Pod 与 容器设计模式 是 Kubernetes 体系里面最重要的一个基础知识点，希望读者能够仔细揣摩和掌握。在这里，我建议你去重新审视一下之前自己公司或者团队里使用 Pod 方式，是不是或多或少采用了所谓“富容器”这种设计呢？这种设计，只是一种过渡形态，会培养出很多非常不好的运维习惯。我强烈建议你逐渐采用容器设计模式的思想对富容器进行解耦，将它们拆分成多个容器组成一个 Pod。</p>
]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL时间线,MySQL各版本的主要特性和区别</title>
    <url>/db/MySQL%E5%90%84%E7%89%88%E6%9C%AC%E7%9A%84%E4%B8%BB%E8%A6%81%E7%89%B9%E6%80%A7%E5%92%8C%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>在选择 Mysql 版本的时候，了解一下版本的变迁历史是有帮助的。<br>| 版本 | 发行日期<br>| — | —<br>| 3.23 | 2001<br>| 4.0 | 2003<br>| 4.1 | 2005<br>| 5.0 | 2006<br>| 5.1 | 2008<br>| 5.5 | 2010<br>| 5.6 | 2012<br>| 5.7 | 2015</p>
<h2 id="版本3-23（2001）"><a href="#版本3-23（2001）" class="headerlink" title="版本3.23（2001）"></a>版本3.23（2001）</h2><p>一般认为这个版本的发布是Mysql真正“诞生”的时刻，其开始获得广泛使用。</p>
<ul>
<li>在这个版本，Mysql依然只是一个在平面文件（Flat File） 上实现了 SQL 查询的系统。</li>
<li>但一个重要的改进是引入 MyISAM 代替了老旧而且有诸多限制的 ISAM 引擎。</li>
<li>InnoDB 引擎也已经可以使用，但没有包含在默认的二进制发行版中，因为它太新了。所以如果要使用 InnoDB，必须手工编译。</li>
<li>版本 3.23 还引入了全文索引和复制。复制是 Mysql 成为互联网应用的数据库系统的关键特性。</li>
</ul>
<h2 id="版本4-0（2003）"><a href="#版本4-0（2003）" class="headerlink" title="版本4.0（2003）"></a>版本4.0（2003）</h2><ul>
<li>支持新的语法，比如 UNION 和多表 DELETE 语法。</li>
<li>重写了复制，在备库使用了两个现成来实现复制，避免了之前一个线程所有复制工作的模式下任务切换导致的问题。</li>
<li>InnoDB 成为标准配备，包括了全部的特性：行级锁、外键等。</li>
<li>引入了查询缓存（自那以后这部门改动不大），同时还支持通过 SSL 进行连接。</li>
</ul>
<h2 id="版本4-1（2005）"><a href="#版本4-1（2005）" class="headerlink" title="版本4.1（2005）"></a>版本4.1（2005）</h2><ul>
<li>引入了更多新的语法，比如子查询和 INSERT ON DUPLICATE KEY UPDATE。</li>
<li>开始支持 UTF-8 字符集。</li>
<li>支持新的二进制协议和 prepared 语句。</li>
</ul>
<h2 id="版本5-0（2006）"><a href="#版本5-0（2006）" class="headerlink" title="版本5.0（2006）"></a>版本5.0（2006）</h2><ul>
<li>这个版本出现了一些“企业级”特性：视图、触发器、存储过程和存储函数。</li>
<li>老的 ISAM 引擎的代码被彻底移除，同时引入了新的 Federated 等引擎。</li>
</ul>
<h2 id="版本5-1（2008）"><a href="#版本5-1（2008）" class="headerlink" title="版本5.1（2008）"></a>版本5.1（2008）</h2><ul>
<li>这是 Sun 收购 MySQL AB 以后发布的首个版本，研发时间长达五年。</li>
<li>引入了分区、基于行的复制，以及 plugin API（包括可插拔存储引擎的 API）。</li>
<li>移除了 BerkeyDB 引擎，这是 MySQL 最早的事务存储引擎。</li>
<li>其他如 Federated 引擎也被放弃。</li>
<li>同时 Oracle 收购的 InnoDB Oy发布了 InnoDB plugin。</li>
</ul>
<h2 id="版本5-5（2010）"><a href="#版本5-5（2010）" class="headerlink" title="版本5.5（2010）"></a>版本5.5（2010）</h2><h3 id="性能提升"><a href="#性能提升" class="headerlink" title="性能提升"></a><strong>性能提升</strong></h3><ul>
<li>默认InnoDB plugin引擎。具有提交、回滚和crash恢复功能、ACID兼容。</li>
<li>行级锁(一致性的非锁定读 MVCC)。- 表与索引存储在表空间、表大小无限制。</li>
<li>支持dynamic(primary key缓存内存 避免主键查询引起的IO )与compressed(支持数据及索引压缩)行格式。</li>
<li>InnoDB plugin文件格式Barracuda、支持表压缩、节约存储、提供内存命中率、truncate table速度更快。</li>
<li>原InnoDB只有一个UndoSegment，最多支持1023的并发；现在有128个Segments，支持128K个并发（同样，解决高并发带来的事务回滚）。</li>
<li>Innodb_thread_concurrency默认为0，线程并发数无限制，可根据具体应用设置最佳值。</li>
<li>Innodb_io_capacity可以动态调整刷新脏页的数量，改善大批量更新时刷新脏页跟不上导致的性能下降问题。Default：200，跟硬盘的IOPS有关。</li>
<li>充分利用CPU多核处理能力innodb_read_io_threads阈值：1-64innodb_write_io_threads 阈值：1-64根据数据库的读写比灵活设置，充分发挥多CPU、高性能存储设备的性能，不支持动态加载 。</li>
<li>自适应刷新脏页</li>
<li>热数据存活更久</li>
<li>buffer pool多实例 ：innodb_buffer_pool_instances 参数增加innodb_buffer_pool实例个数，大大降低buffer pool的mutex争抢过热情况。</li>
<li>Linux上实现异步IO</li>
<li>重新支持组提交</li>
</ul>
<h3 id="稳定性提升"><a href="#稳定性提升" class="headerlink" title="稳定性提升"></a><strong>稳定性提升</strong></h3><ul>
<li>支持半同步Replication。- 增加Relay Log 自我修复功能。</li>
<li>Crash recovery。</li>
<li>引入红-黑树做插入排序的中间数据结构，时间复杂度大大降低，减少恢复时间。</li>
<li>Thread Pool 分组排队 限流</li>
<li>增加Relay Log 自我修复功能。</li>
</ul>
<h2 id="版本5-6（2012）"><a href="#版本5-6（2012）" class="headerlink" title="版本5.6（2012）"></a>版本5.6（2012）</h2><ul>
<li>默认参数的改变</li>
<li>Back_log 排队队列</li>
<li>支持全文索引</li>
<li>支持online DDL create,alter,drop</li>
<li>可以在建表时指定表空间位置<br> create table external (x int unsigned not null primary key)data directory = ‘/volumes/external1/data’;</li>
<li>新增参数innodb_page_size可以设置page大小</li>
<li>整合了memcached API，可以使用API来直接访问innodb表，并非SQL（减少SQL解析、查询优化代价）</li>
<li>innodb只读事务，不需要设置TRX_ID字段，</li>
<li>减少内部数据结构开销，减少read view</li>
<li>仅仅非只读事务依然需要TRX_ID</li>
</ul>
<h3 id="innodb改进点"><a href="#innodb改进点" class="headerlink" title="innodb改进点"></a><strong>innodb改进点</strong></h3><ul>
<li>innodb表空间在线迁移(TransportableTablespaces)</li>
<li>undo log可独立出系统表空间</li>
<li>redo log最大可增长到512G</li>
<li>innodb后台线程独立出来</li>
</ul>
<h3 id="优化器改进"><a href="#优化器改进" class="headerlink" title="优化器改进"></a><strong>优化器改进</strong></h3><ul>
<li>ICP<br>可以在引擎层直接过滤数据，避免二次回表<br>节省BP空间，提高查询性能</li>
<li>BKA<br>全称Batch Key Access：<br>SQL通过辅助索引要访问表数据时候，将大量的随机访问放入缓存，交给MRR接口合并为顺序访问。</li>
<li>MRR<br>全称Multi Range Read：<br>在BKA算法应用之后，通过MRR接口合并随机访问为顺序访问，再去检索表数据。<br>变大量随机为顺序访问。在通过辅助索引检索大量数据时，性能提升明显<br>磁头无需来回寻道，page只需读取一次，且较好利用了innodb线性预读功能（每次预读64个连续page）。</li>
<li>统计信息持久化，mysqld重启后不丢失</li>
<li>explain语句支持insert，update，delete，replace语句，并且支持JSON格式</li>
<li>子查询优化提升。</li>
</ul>
<h2 id="版本5-7（2015年）"><a href="#版本5-7（2015年）" class="headerlink" title="版本5.7（2015年）"></a>版本5.7（2015年）</h2><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a><strong>安全性</strong></h3><ul>
<li>用户表 mysql.user 的 plugin字段不允许为空， 默认值是 mysql_native_password，而不是 mysql_old_password，不再支持旧密码格式；</li>
<li>增加密码过期机制，过期后需要修改密码，否则可能会被禁用，或者进入沙箱模式；</li>
<li>提供了更为简单SSL安全访问配置，并且默认连接就采用SSL的加密方式。</li>
</ul>
<h3 id="灵活性"><a href="#灵活性" class="headerlink" title="灵活性"></a><strong>灵活性</strong></h3><ul>
<li>MySQL数据库从5.7.8版本开始，也提供了对JSON的支持。</li>
<li>可以混合存储结构化数据和非结构化数据，同时拥有关系型数据库和非关系型数据库的优点</li>
<li>能够提供完整的事务支持</li>
<li>generated column是MySQL 5.7引入的新特性，所谓generated column，就是数据库中这一列由其他列计算而得</li>
</ul>
<h3 id="易用性"><a href="#易用性" class="headerlink" title="易用性"></a><strong>易用性</strong></h3><ul>
<li>在MySQL 5.7 之前，如果用户输入了错误的SQL语句，按下 ctrl+c ，虽然能够”结束”SQL语句的运行，但是，也会退出当前会话，MySQL 5.7对这一违反直觉的地方进行了改进，不再退出会话。</li>
<li>MySQL 5.7可以explain一个正在运行的SQL，这对于DBA分析运行时间较长的语句将会非常有用。</li>
<li>sys schema是MySQL 5.7.7中引入的一个系统库，包含了一系列视图、函数和存储过程， 该项目专注于MySQL的易用性。<br>例如：如何查看数据库中的冗余索引；如何获取未使用的索引；如何查看使用全表扫描的SQL语句。</li>
</ul>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a><strong>可用性</strong></h3><ul>
<li>在线设置 复制的过滤规则 不再需要重启MySQL，只需要停止SQLthread，修改完成以后，启动SQLthread。</li>
<li>在线修改buffer pool的大小。</li>
<li>Online DDL MySQL 5.7支持重命名索引和修改varchar的大小，这两项操作在之前的版本中，都需要重建索引或表。</li>
<li>在线开启GTID ，在之前的版本中，由于不支持在线开启GTID，用户如果希望将低版本的数据库升级到支持GTID的数据库版本，需要先关闭数据库，再以GTID模式启动，所以导致升级起来特别麻烦。</li>
</ul>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a><strong>性能</strong></h3><ul>
<li>临时表的性能改进。<br>临时表只在当前会话中可见<br>临时表的生命周期是当前连接（MySQL宕机或重启，则当前连接结束）</li>
<li>只读事务性能改进。<br>MySQL 5.7通过 避免为只读事务分配事务ID ，不为只读事务分配回滚段，减少锁竞争等多种方式，优化了只读事务的开销，提高了数据库的整体性能。</li>
<li>加速连接处理。<br>在MySQL 5.7之前，变量的初始化操作（THD、VIO）都是在连接接收线程里面完成的，现在将这些工作下发给工作线程，以减少连接接收线程的工作量，提高连接的处理速度。这个优化对那些频繁建立短连接的应用，将会非常有用。</li>
<li>复制性能的改进 （支持多线程复制（Multi-Threaded Slaves, 简称MTS）<br>MySQL的默认配置是库级别的并行复制，为了充分发挥MySQL 5.7的并行复制的功能，我们需要将slave-parallel-type配置成LOGICAL_CLOCK。</li>
<li>支持多源复制（Multi-source replication）<h3 id="严格性改变"><a href="#严格性改变" class="headerlink" title="严格性改变"></a><strong>严格性改变</strong></h3></li>
<li>默认启用 STRICT_TRANS_TABLES 模式。</li>
<li>对 ONLY_FULL_GROUP_BY 模式实现了更复杂的特性支持，并且也被默认启用。</li>
<li>其他被默认启用的sql mode还有 NO_ENGINE_SUBSTITUTION。</li>
</ul>
<h3 id="默认参数的改变"><a href="#默认参数的改变" class="headerlink" title="默认参数的改变"></a>默认参数的改变</h3><ul>
<li>默认binlog格式调整为ROW格式</li>
<li>默认binlog错误后的操作调整为ABORT_SERVER<br>在先前的选项下（binlog_error_action=IGNORE_ERROR），如果一个错误发生，导致无法写入binlog，mysql-server会在错误日志中记录错误并强制关闭binlog功能。这会使mysql-server在不记录binlog的模式下继续运行，导致从库无法继续获取到主库的binlog。</li>
<li>默认开启mysql崩溃时的binlog安全。</li>
<li>默认调低slave_net_timeout。</li>
</ul>
<h3 id="安装不同"><a href="#安装不同" class="headerlink" title="安装不同"></a><strong>安装不同</strong></h3><ul>
<li>mysql_install_db已经不再推荐使用了，建议改成mysqld –initialize 完成实例初始化。如果 datadir 指向的目标目录下已经有数据文件，则会有[ERROR] Aborting；</li>
<li>在初始化时如果加上 –initial-insecure，则会创建空密码的 root@localhost 账号，否则会创建带密码的 root@localhost 账号，密码直接写在 log-error 日志文件中；新用户登入后需要立刻修改密码，否则无法继续后续的工作。</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务</title>
    <url>/db/distributed-transaction/</url>
    <content><![CDATA[<p>分布式事务场景如何设计系统架构及解决数据一致性问题，个人理解最终方案把握以下原则就可以了，那就是：大事务=小事务（原子事务）+异步（消息通知），<strong>解决分布式事务的最好办法其实就是不考虑分布式事务，将一个大的业务进行拆分，整个大的业务流程，转化成若干个小的业务流程，然后通过设计补偿流程从而考虑最终一致性。</strong></p>
<a id="more"></a>

<h2 id="What’s-事务"><a href="#What’s-事务" class="headerlink" title="What’s 事务"></a>What’s 事务</h2><p>事务（Transaction）及其ACID属性</p>
<p>事务是由一组SQL语句组成的逻辑处理单元，事务具有以下4个属性，通常简称为事务的ACID属性：</p>
<ul>
<li>原子性（Atomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。</li>
<li>一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。</li>
<li>隔离性（Isoation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。</li>
<li>持久性（Durabe）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。</li>
</ul>
<h2 id="典型场景：银行转账业务"><a href="#典型场景：银行转账业务" class="headerlink" title="典型场景：银行转账业务"></a>典型场景：银行转账业务</h2><p>例如：李雷账户中有500块钱，韩梅梅账户有200块钱，李雷要从自己的账户中转100块钱给韩梅梅，转账（事务）成功执行完成后应该是李雷账户减100变为400，韩梅梅账户加100变为300，不能出现其他情况，即在事务开始和结束时数据都必须保持一致状态（一致性），事务结束时所有的数据及结构都必须是正确的。并且同样的转账操作（同一流水，即一次转账操作）无论执行多少次结果都相同（幂等性）。</p>
<h2 id="电商场景：流量充值业务"><a href="#电商场景：流量充值业务" class="headerlink" title="电商场景：流量充值业务"></a>电商场景：流量充值业务</h2><p>再说我们做的一个项目：中国移动-流量充值能力中心，核心业务流程为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 用户进入流量充值商品购买页面，选择流量商品；</span><br><span class="line">2. 购买流量充值商品，有库存限制则判断库存，生成流量购买订单；</span><br><span class="line">3. 选择对应的支付方式（和包、银联、支付宝、微信）进行支付操作；</span><br><span class="line">4. 支付成功后，近实时流量到账即可使用流量商品；</span><br></pre></td></tr></table></figure>
<p>此业务流程看似不是很复杂对吧，不涉及到类似电商业务的实物购买，但是我认为其中的区别并不是很大，只是缺少电商中的物流发货流程，其他流程几乎是一样的，也有库存以及优惠折扣等业务存在。</p>
<p>整个系统交互如下图：</p>
<img title="分布式事务" alt="整个系统交互图" data-src="http://f.ngall-in.com/alan87/static/images/db/distributed-transaction/distributed-transaction-1.jpg/w600">


<h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p>上述两个场景的业务需求已经说完了，接着谈谈分布式事务，要说分布式事务那就先聊聊本地事务与分布式事务：</p>
<p>Ps：相同点：首先都是要保证数据正确（即ACID），本地事务与分布式事务还可以对应为：刚性事务与柔性事务，在我个人理解刚性事务与柔性事务的最大区别就是：一个完整的事务操作是否可以在同一物理介质（例如：内存）上同时完成；柔性事务就是一个完整事务需要跨物理介质或跨物理节点（网络通讯），那么排它锁、共享锁等等就没有用武之地了（这里并不是指大事务拆小事务【本地事务】后），无法保证原子性（Atomicity）完成事务。个人理解分布式（柔性）事务本质意义上就是-伪事务，柔性事务其实就是根据不同的业务场景使用不同的方法实现最终一致性，因为可以根据业务的特性做部分取舍，在业务过程中可以容忍一定时间内的数据不一致。</p>
<p>在知乎上面看过一篇文章，支付宝的柔性事务实现方式有四种分别针对不同的业务场景，如下图：</p>
<img title="分布式事务" alt="柔性事务实现方式" data-src="http://f.ngall-in.com/alan87/static/images/db/distributed-transaction/distributed-transaction-2.jpg/w600">

<ol>
<li>两阶段型</li>
<li>补偿型</li>
<li>异步确保型</li>
<li>最大努力通知型</li>
</ol>
<p>回到我们流量交易中心的业务场景：</p>
<p>通过Dubbo实现了微服务化，大致拆分如下：</p>
<ol>
<li>商品服务</li>
<li>订单服务</li>
<li>库存服务</li>
<li>支付服务</li>
<li>直充服务</li>
<li>消息服务</li>
<li>等其他服务</li>
</ol>
<h2 id="场景一："><a href="#场景一：" class="headerlink" title="场景一："></a>场景一：</h2><p>库存数量与订单数量一致性，采用补偿型+最大努力通知型，采用原因为不涉及跨机房和长事务（正常情况下库存与订单服务处理很快）：</p>
<ol>
<li>用户下单先减库存，库存减成功后；</li>
<li>调用下单服务：</li>
<li>2-1. 下单成功，两事务均提交完成；</li>
<li>2-2. 下单失败，库存回滚，两事务均失败，此处还有一个保障机制（最大努力通知型），就是如果调用库存服务异常，确定库存回滚失败了，则放入消息服务（延时消息队列）分阶段定时重试，努力重试保证库存服务正常后成功回滚。</li>
</ol>
<h2 id="场景二："><a href="#场景二：" class="headerlink" title="场景二："></a>场景二：</h2><p>订单信息、支付信息、充值信息三者之间的一致性，采用异步确保型的原因是，整个业务链路太长且跨不同的机房系统，网络延迟较高，业务方面恰好不需要非常高的实时性，所以采用小事务+异步通知，目前正常情况下用户从下单到完成支付到流量到账平均为1-5分钟左右：</p>
<ol>
<li>下单成功即订单服务创建订单成功并发送支付请求到支付网关系统（订单状态-待支付，超过1小时未支付则流转为超时未付撤销，此处用到了RocketMQ的延时消费恰好实现定时器业务场景）。</li>
<li>返回支付页面，用户在支付交易系统完成支付业务流程，支付网关异步通知流量中心，流量中心接收到支付成功状态后修改订单状态-支付成功，并给支付网关返回成功结果（此处并发压力目前不大，暂时没有再进行异步解耦）。</li>
<li>流量中心修改完订单状态后，调用消息服务将直充业务放入消息队列，对直充业务进行解耦（原因是直充需要调用31省移动CRM系统，此链路过长，且部分省CRM系统耗时非常大，每个省的处理能力不同，经常出现20秒以上的超时，因此要考虑部分超时较高的省份拖垮系统，进行业务的削峰填谷）；</li>
<li>3-1. 当直充成功时，修改订单状态-已完成；</li>
<li>3-2. 当直充失败时（移动特性，例如：直充时正好用户销户或者停机了），修改订单状态为待退款，并调用支付网关系统的退款接口，退款成功后支付网关异步通知流量中心，流量中心修改订单状态为-退款成功；</li>
<li>3-3. 当直充超时时，调用定时任务服务进行超时重试机制（第一次重试在10分钟后执行、第二次在30分钟后、第三次…..），直到最大超时重试次数后还得不到直充结果，订单状态会卡在支付成功状态，依赖T+1对账稽核流程保证最终一致性，订单状态根据对账结果流转为：已完成或待退款–&gt;退款成功。</li>
</ol>
<h2 id="场景三："><a href="#场景三：" class="headerlink" title="场景三："></a>场景三：</h2><p>直充到账后的消息通知（APP消息推送或短信通知），采用最大努力通知型，这个业务场景比较简单，在直充成功后，订单状态流转为已完成，此时通过消息服务进行到账通知业务的解耦，调用消息服务失败的情况下，使用定时任务努力通知。</p>
<h2 id="场景四："><a href="#场景四：" class="headerlink" title="场景四："></a>场景四：</h2><p><strong>对账稽核：</strong></p>
<p>按照支付账期每日进行T+1对账，对账原则：以支付交易记录为准，对流量中心订单记录+支付网关交易记录+省CRM充值记录三方比对，将某些中间状态的订单（例如：支付成功、待退款）核对后将订单状态流转完结（已完成、退款成功）。</p>
<p><strong>结算稽核：</strong></p>
<p>对账成功后的数据定期进入结算流程，对支付网关周期内的支付金额与结算数据的金额进行核对，稽核成功后进行财务结算流程，将钱结算给省公司，并提供结算明细给省公司，供省公司与直充成本记录进行复核。<br>Ps：以下是流量中心的部分架构设计，总体原则方向：微服务化</p>
<p><strong>流量中心-架构设计</strong></p>
<img title="分布式事务" alt="流量中心架构设计" data-src="http://f.ngall-in.com/alan87/static/images/db/distributed-transaction/distributed-transaction-3.jpg/w600">


<p>架构设计思想：在系统初期设计时以及部分硬性环境约束下，我们根据业务拆分为多个子系统（微服务）：商品服务、订单服务、库存服务、支付网关、统一接口平台、对账服务、结算服务、网关对接服务等，后续还会增加：账户服务、虚拟货币服务、卡券服务等等…。按照微服务的核心设计思想，所有服务完全独立、隔离，因此所有服务从上至下：请求接入（连接管理）、请求处理（计算服务）、数据存储（存储服务）进行拆分，接入与计算尽最大可能实现无状态，数据存储进行垂直+水平拆分，垂直拆分：商品库-mysql（读多写少，主从架构+读写分离）+redis（读多写少，集群方式）、订单库-mysql（读写均衡，多主多从+水平拆分）、库存专用库-redis（分布式+主备容灾）、外部交易系统-支付网关、外部办理系统-统一接口平台。</p>
<p>Ps：此架构目前已支撑总交易额3.6亿，总订单4680万，日均交易额500万，日订单量50万，后续业务量持续增加的情况下按照微服务思想继续拆分，例如将订单服务再拆分为：下单服务、查单服务，直到根据业务需求与系统关系耦合性拆分到最细粒度为止。</p>
<ol>
<li>性能扩展：应用层计算服务（无状态应用）通过增加服务节点同比提升运算性能，配套质量（性能）监控服务dubbo monitor及整合Netflix的Hystrix熔断器对业务质量进行管理实现应用层的动态扩缩容。</li>
<li>容量扩展：数据层存储服务（有状态应用）通过对数据水平拆分实现容量的无限扩容，Nosql类方案：Codis中间件；关系型数据库：Mycat数据库分库分表中间件。目前项目中采用twitter的snowflake唯一ID生成器（根据业务场景优化后）自己实现数据的水平拆分和路由规则。</li>
<li>存储性能：Nosql：针对读多写少场景-使用淘宝的Tedis（多写随机读的特性提高性能），读写均衡使用-Codis；Mysql：读多写少场景使用一主多从架构（例如商品信息），读写均衡场景使用多主多从架构（例如订单信息）。</li>
</ol>
<p><strong>整体拆分原则如下图：</strong></p>
<img title="分布式事务" alt="整理拆分原则图" data-src="http://f.ngall-in.com/alan87/static/images/db/distributed-transaction/distributed-transaction-4.jpg/w600">


<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>复杂的业务交互过程中，不建议使用强一致性的分布式事务。</p>
<p><strong>解决分布式事务的最好办法就是不考虑分布式事务</strong>。</p>
<p>就像刚说的问题一样，把分布式的事务过程拆解成多个中间状态，中间状态的东西不允许用户直接操作，等状态都一致成功，或者检测到不一致的时候全部失败掉。就解耦了这个强一致性的过程。</p>
<p>一般情况下准实时就成了。涉及到钱，有时候也可以这么搞。</p>
<p>淘宝几s内完整一个订单处理，不是什么问题吧。</p>
<p>银行也不是全部都强一致性。也会扎差，也会冲正。</p>
<p>特别是涉及到多个系统的时候，我们比如买机票，支付完成以后，只支付完成状态，然后返回给用户了，我们过几分钟再刷新页面，才会看到变成已出票，订单完成状态。</p>
<p>这个时候，如果我们要求所有处理，都是强一致性的，那么久完蛋了。页面要死在那儿几分钟，才把这个事务处理完成，返回给用户。</p>
<div class="note primary">
            <ol><li><p>解决分布式事务的最好办法就是不考虑分布式事务。</p></li><li><p>拆分 大的业务流程，转化成几个小的业务流程，然后考虑最终一致性。</p></li></ol>
          </div>


<h2 id="问题：分布式事务是你们自己开发的，还是数据库自带的？"><a href="#问题：分布式事务是你们自己开发的，还是数据库自带的？" class="headerlink" title="问题：分布式事务是你们自己开发的，还是数据库自带的？"></a>问题：分布式事务是你们自己开发的，还是数据库自带的？</h2><p>1、只要一个处理逻辑能保证要么成功，要么跟什么也没做一样，都算是事务。数据库事务，MQ也有事务。</p>
<p>你自己甚至可以写个程序生成两个文件，要么都生成了，要么都删掉不留痕迹，这也算是事务。</p>
<p>2、分布式事务这一块有个XA规范，实现XA接口的事务，都可以加入到一个分布式事务中，被XA容器管理起来。</p>
<p>3、补偿的办法，需要具体情况具体分析，没有一个各种场合都适用的框架。</p>
<h1 id="好用的开源产品"><a href="#好用的开源产品" class="headerlink" title="好用的开源产品"></a>好用的开源产品</h1><ol>
<li>ShardingSphere的分布式事务 <a href="../最好用的开源分布式事务解决方案之一">Sharding-transaction</a></li>
<li>Seata</li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>云原生技术基础(三)——Kubernetes核心概念</title>
    <url>/cn/k8s%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>本章分享主要围绕以下 3 个部分：</p>
<div class="note primary">
            <ul><li>什么是 Kubernetes ：介绍 Kubernetes 的主要功能以及能力；</li><li>Kubernetes 的架构：介绍 Kubernetes 的核心组件，以及介绍它们之间是如何相互互动连接；</li><li>Kubernetes 的核心概念与核心 API。</li></ul>
          </div>

<a id="more"></a>
<h1 id="一、什么是-Kubernetes"><a href="#一、什么是-Kubernetes" class="headerlink" title="一、什么是 Kubernetes"></a>一、什么是 Kubernetes</h1><p>Kubernetes，从官方网站上可以看到，它是一个工业级的容器编排平台。Kubernetes 这个单词是希腊语，它的中文翻译是“舵手”或者“飞行员”。在一些常见的资料中也会看到“ks”这个词，也就是“k8s”，它是通过将8个字母“ubernete ”替换为“8”而导致的一个缩写。</p>
<p>Kubernetes 为什么要用“舵手”来命名呢？大家可以看一下这张图：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/cloud-native-3-0.jpg/w600">

<p>这是一艘载着一堆集装箱的轮船，轮船在大海上运着集装箱奔波，把集装箱送到它们该去的地方。我们之前其实介绍过一个概念叫做 container，container 这个英文单词也有另外的一个意思就是“集装箱”。Kubernetes 也就借着这个寓意，希望成为运送集装箱的一个轮船，来帮助我们管理这些集装箱，也就是管理这些容器。</p>
<p>这个就是为什么会选用 Kubernetes 这个词来代表这个项目的原因。更具体一点地来说：Kubernetes 是一个自动化的容器编排平台，它负责应用的部署、应用的弹性以及应用的管理，这些都是基于容器的。</p>
<h1 id="二、Kubernetes-有如下几个核心的功能："><a href="#二、Kubernetes-有如下几个核心的功能：" class="headerlink" title="二、Kubernetes 有如下几个核心的功能："></a>二、Kubernetes 有如下几个核心的功能：</h1><ul>
<li>服务的发现与负载的均衡；</li>
<li>容器的自动装箱，我们也会把它叫做 scheduling，就是“调度”，把一个容器放到一个集群的某一个机器上，Kubernetes 会帮助我们去做存储的编排，让存储的声明周期与容器的生命周期能有一个连接；</li>
<li>Kubernetes 会帮助我们去做自动化的容器的恢复。在一个集群中，经常会出现宿主机的问题或者说是 OS 的问题，导致容器本身的不可用，Kubernetes 会自动地对这些不可用的容器进行恢复；</li>
<li>Kubernetes 会帮助我们去做应用的自动发布与应用的回滚，以及与应用相关的配置密文的管理；</li>
<li>对于 job 类型任务，Kubernetes 可以去做批量的执行；</li>
<li>为了让这个集群、这个应用更富有弹性，Kubernetes 也支持水平的伸缩。</li>
</ul>
<p>下面，我们希望以三个例子跟大家更切实地介绍一下 Kubernetes 的能力。</p>
<h2 id="1、调度"><a href="#1、调度" class="headerlink" title="1、调度"></a>1、调度</h2><p>Kubernetes 可以把用户提交的容器放到 Kubernetes 管理的集群的某一台节点上去。Kubernetes 的调度器是执行这项能力的组件，它会观察正在被调度的这个容器的大小、规格。</p>
<p>比如说它所需要的 CPU以及它所需要的 memory，然后在集群中找一台相对比较空闲的机器来进行一次 placement，也就是一次放置的操作。在这个例子中，它可能会把红颜色的这个容器放置到第二个空闲的机器上，来完成一次调度的工作。</p>
<img title="Kubernetes-调度" alt="Kubernetes-调度" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/cloud-native-3-1.png/w600">

<h2 id="2、自动修复"><a href="#2、自动修复" class="headerlink" title="2、自动修复"></a>2、自动修复</h2><p>Kubernetes 有一个节点健康检查的功能，它会监测这个集群中所有的宿主机，当宿主机本身出现故障，或者软件出现故障的时候，这个节点健康检查会自动对它进行发现。</p>
<p>下面 Kubernetes 会把运行在这些失败节点上的容器进行自动迁移，迁移到一个正在健康运行的宿主机上，来完成集群内容器的一个自动恢复。</p>
<img title="Kubernetes-调度" alt="Kubernetes-调度" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/cloud-native-3-2.png/w600">

<h2 id="3、水平伸缩"><a href="#3、水平伸缩" class="headerlink" title="3、水平伸缩"></a>3、水平伸缩</h2><p>Kubernetes 有业务负载检查的能力，它会监测业务上所承担的负载，如果这个业务本身的 CPU 利用率过高，或者响应时间过长，它可以对这个业务进行一次扩容。</p>
<p>比如说在下面的例子中，黄颜色的过度忙碌，Kubernetes 就可以把黄颜色负载从一份变为三份。接下来，它就可以通过负载均衡把原来打到第一个黄颜色上的负载平均分到三个黄颜色的负载上去，以此来提高响应的时间。</p>
<img title="Kubernetes-调度" alt="Kubernetes-调度" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/cloud-native-3-3.png/w600">

<p>以上就是 Kubernetes 三个核心能力的简单介绍。</p>
<h1 id="三、Kubernetes-的架构"><a href="#三、Kubernetes-的架构" class="headerlink" title="三、Kubernetes 的架构"></a>三、Kubernetes 的架构</h1><p>Kubernetes 架构是一个比较典型的二层架构和 server-client 架构。Master 作为中央的管控节点，会去与 Node 进行一个连接。</p>
<p>所有 UI 的、clients、这些 user 侧的组件，只会和 Master 进行连接，把希望的状态或者想执行的命令下发给 Master，Master 会把这些命令或者状态下发给相应的节点，进行最终的执行。</p>
<img title="Kubernetes-architecture" alt="Kubernetes-architecture" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-architecture.jpg/w600">

<div class="tabs" id="kubenetes-master-node"><ul class="nav-tabs"><li class="tab active"><a href="#kubenetes-master-node-1"><i class="fa fa-reorder"></i>Kubernetes的架构：Master</a></li><li class="tab"><a href="#kubenetes-master-node-2"><i class="fa fa-reorder"></i>Kubernetes的架构：Node</a></li></ul><div class="tab-content"><div class="tab-pane active" id="kubenetes-master-node-1"><h2 id="Kubernetes-的架构：Master"><a href="#Kubernetes-的架构：Master" class="headerlink" title="Kubernetes 的架构：Master"></a>Kubernetes 的架构：Master</h2><p>Kubernetes 的 Master 包含四个主要的组件：API Server、Controller、Scheduler 以及 etcd。如下图所示：<br><img title="k8s-master-architecture" alt="k8s-master-architecture" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-master-architecture.jpg/w600"></p>
<ul>
<li><p>API Server：顾名思义是用来处理 API 操作的，Kubernetes 中所有的组件都会和 API Server 进行连接，组件与组件之间一般不进行独立的连接，都依赖于 API Server 进行消息的传送；</p>
</li>
<li><p>Controller：是控制器，它用来完成对集群状态的一些管理。比如刚刚我们提到的两个例子之中，第一个自动对容器进行修复、第二个自动进行水平扩张，都是由 Kubernetes 中的 Controller 来进行完成的；</p>
</li>
<li><p>Scheduler：是调度器，“调度器”顾名思义就是完成调度的操作，就是我们刚才介绍的第一个例子中，把一个用户提交的 Container，依据它对 CPU、对 memory 请求大小，找一台合适的节点，进行放置；</p>
</li>
<li><p>etcd：是一个分布式的一个存储系统，API Server 中所需要的这些原信息都被放置在 etcd 中，etcd 本身是一个高可用系统，通过 etcd 保证整个 Kubernetes 的 Master 组件的高可用性。</p>
</li>
</ul>
<p>我们刚刚提到的 API Server，它本身在部署结构上是一个可以水平扩展的一个部署组件；Controller 是一个可以进行热备的一个部署组件，它只有一个 active，它的调度器也是相应的，虽然只有一个 active，但是可以进行热备。</p></div><div class="tab-pane" id="kubenetes-master-node-2"><h2 id="Kubernetes-的架构：Node"><a href="#Kubernetes-的架构：Node" class="headerlink" title="Kubernetes 的架构：Node"></a>Kubernetes 的架构：Node</h2><p>Kubernetes 的 Node 是真正运行业务负载的，每个业务负载会以 Pod 的形式运行。等一下我会介绍一下 Pod 的概念。一个 Pod 中运行的一个或者多个容器，真正去运行这些 Pod 的组件的是叫做 kubelet，也就是 Node 上最为关键的组件，它通过 API Server 接收到所需要 Pod 运行的状态，然后提交到我们下面画的这个 Container Runtime 组件中。<br><img title="k8s-node-architecture" alt="k8s-node-architecture" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-node-architecture.png/w600"></p>
<p>在 OS 上去创建容器所需要运行的环境，最终把容器或者 Pod 运行起来，也需要对存储跟网络进行管理。Kubernetes 并不会直接进行网络存储的操作，他们会靠 Storage Plugin 或者是网络的 Plugin 来进行操作。用户自己或者云厂商都会去写相应的 <strong>Storage Plugin</strong> 或者 <strong>Network Plugin</strong>，去完成存储操作或网络操作。</p>
<p>在 Kubernetes 自己的环境中，也会有 Kubernetes 的 Network，它是为了提供 Service network 来进行搭网组网的。（等一下我们也会去介绍“service”这个概念。）真正完成 service 组网的组件的是 <strong>Kube-proxy</strong>，它是利用了 iptable 的能力来进行组建 Kubernetes 的 Network，就是 cluster network，以上就是 Node 上面的四个组件。</p>
<p>Kubernetes 的 Node 并不会直接和 user 进行 interaction，它的 interaction 只会通过 Master。而 User 是通过 Master 向节点下发这些信息的。Kubernetes 每个 Node 上，都会运行我们刚才提到的这几个组件。</p></div></div></div>

<p>下面我们以一个例子再去看一下 Kubernetes 架构中的这些组件，是如何互相进行 interaction 的。<br>k8s-architecture-demo</p>
<img title="k8s-architecture-demo" alt="k8s-architecture-demo" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-architecture-demo.png/w600">

<p>用户可以通过 UI 或者 CLI 提交一个 Pod 给 Kubernetes 进行部署，这个 Pod 请求首先会通过 CLI 或者 UI 提交给 Kubernetes API Server，下一步 API Server 会把这个信息写入到它的存储系统 etcd，之后 Scheduler 会通过 API Server 的 watch 或者叫做 notification 机制得到这个信息：有一个 Pod 需要被调度。</p>
<p>这个时候 Scheduler 会根据它的内存状态进行一次调度决策，在完成这次调度之后，它会向 API Server report 说：“OK！这个 Pod 需要被调度到某一个节点上。”</p>
<p>这个时候 API Server 接收到这次操作之后，会把这次的结果再次写到 etcd 中，然后 API Server 会通知相应的节点进行这次 Pod 真正的执行启动。相应节点的 kubelet 会得到这个通知，kubelet 就会去调 Container runtime 来真正去启动配置这个容器和这个容器的运行环境，去调度 Storage Plugin 来去配置存储，network Plugin 去配置网络。</p>
<p>这个例子我们可以看到：这些组件之间是如何相互沟通相互通信，协调来完成一次Pod的调度执行操作的。</p>
<h1 id="四、Kubernetes-的核心概念与它的-API"><a href="#四、Kubernetes-的核心概念与它的-API" class="headerlink" title="四、Kubernetes 的核心概念与它的 API"></a>四、Kubernetes 的核心概念与它的 API</h1><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="第一个概念：Pod"><a href="#第一个概念：Pod" class="headerlink" title="第一个概念：Pod"></a>第一个概念：Pod</h3><p>Pod 是 Kubernetes 的一个最小调度以及资源单元。用户可以通过 Kubernetes 的 Pod API 生产一个 Pod，让 Kubernetes 对这个 Pod 进行调度，也就是把它放在某一个 Kubernetes 管理的节点上运行起来。一个 Pod 简单来说是对一组容器的抽象，它里面会包含一个或多个容器。</p>
<p>比如像下面的这幅图里面，它包含了两个容器，每个容器可以指定它所需要资源大小。比如说，一个核一个 G，或者说 0.5 个核，0.5 个 G。</p>
<p>当然在这个 Pod 中也可以包含一些其他所需要的资源：比如说我们所看到的 Volume 卷这个存储资源；比如说我们需要 100 个 GB 的存储或者 20GB 的另外一个存储。</p>
<img title="k8s-pod" alt="k8s-pod" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-pod.png/w600">

<p>在 Pod 里面，我们也可以去定义容器所需要运行的方式。比如说运行容器的 Command，以及运行容器的环境变量等等。Pod 这个抽象也给这些容器提供了一个共享的运行环境，它们会共享同一个网络环境，这些容器可以用 localhost 来进行直接的连接。而 Pod 与 Pod 之间，是互相有 isolation 隔离的。</p>
<h3 id="第二个概念：Volume"><a href="#第二个概念：Volume" class="headerlink" title="第二个概念：Volume"></a>第二个概念：Volume</h3><p>Volume 就是卷的概念，它是用来管理 Kubernetes 存储的，是用来声明在 Pod 中的容器可以访问文件目录的，一个卷可以被挂载在 Pod 中一个或者多个容器的指定路径下面。</p>
<p>而 Volume 本身是一个抽象的概念，一个 Volume 可以去支持多种的后端的存储。比如说 Kubernetes 的 Volume 就支持了很多存储插件，它可以支持本地的存储，可以支持分布式的存储，比如说像 ceph，GlusterFS ；它也可以支持云存储，比如说阿里云上的云盘、AWS 上的云盘、Google 上的云盘等等。</p>
<img title="k8s-volume" alt="k8s-volume" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-volume.png/w600">

<h3 id="第三个概念：Deployment"><a href="#第三个概念：Deployment" class="headerlink" title="第三个概念：Deployment"></a>第三个概念：Deployment</h3><p>Deployment 是在 Pod 这个抽象上更为上层的一个抽象，它可以定义一组 Pod 的副本数目、以及这个 Pod 的版本。一般大家用 Deployment 这个抽象来做应用的真正的管理，而 Pod 是组成 Deployment 最小的单元。</p>
<p>Kubernetes 是通过 Controller，也就是我们刚才提到的控制器去维护 Deployment 中 Pod 的数目，它也会去帮助 Deployment 自动恢复失败的 Pod。</p>
<p>比如说我可以定义一个 Deployment，这个 Deployment 里面需要两个 Pod，当一个 Pod 失败的时候，控制器就会监测到，它重新把 Deployment 中的 Pod 数目从一个恢复到两个，通过再去新生成一个 Pod。通过控制器，我们也会帮助完成发布的策略。比如说进行滚动升级，进行重新生成的升级，或者进行版本的回滚。</p>
<img title="k8s-deployment" alt="k8s-deployment" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-deployment.png/w600">

<h3 id="第四个概念：Service"><a href="#第四个概念：Service" class="headerlink" title="第四个概念：Service"></a>第四个概念：Service</h3><p>Service 提供了一个或者多个 Pod 实例的稳定访问地址。</p>
<p>比如在上面的例子中，我们看到：一个 Deployment 可能有两个甚至更多个完全相同的 Pod。对于一个外部的用户来讲，访问哪个 Pod 其实都是一样的，所以它希望做一次负载均衡，在做负载均衡的同时，我只想访问某一个固定的 VIP，也就是 Virtual IP 地址，而不希望得知每一个具体的 Pod 的 IP 地址。</p>
<p>我们刚才提到，这个 pod 本身可能 terminal go（终止），如果一个 Pod 失败了，可能会换成另外一个新的。</p>
<p>对一个外部用户来讲，提供了多个具体的 Pod 地址，这个用户要不停地去更新 Pod 地址，当这个 Pod 再失败重启之后，我们希望有一个抽象，把所有 Pod 的访问能力抽象成一个第三方的一个 IP 地址，实现这个的 Kubernetes 的抽象就叫 Service。 </p>
<p>实现 Service 有多种方式，Kubernetes 支持 Cluster IP，上面我们讲过的 kuber-proxy 的组网，它也支持 nodePort、 LoadBalancer 等其他的一些访问的能力。</p>
<img title="k8s-service" alt="k8s-service" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-service.png/w600">

<h3 id="第五个概念：Namespace"><a href="#第五个概念：Namespace" class="headerlink" title="第五个概念：Namespace"></a>第五个概念：Namespace</h3><p>Namespace 是用来做一个集群内部的逻辑隔离的，它包括鉴权、资源管理等。Kubernetes 的每个资源，比如刚才讲的 Pod、Deployment、Service 都属于一个 Namespace，同一个 Namespace 中的资源需要命名的唯一性，不同的 Namespace 中的资源可以重名。</p>
<p>Namespace 一个用例，比如像在阿里巴巴，我们内部会有很多个 business units，在每一个 business units 之间，希望有一个视图上的隔离，并且在鉴权上也不一样，在 cuda 上面也不一样，我们就会用 Namespace 来去给每一个 BU 提供一个他所看到的这么一个看到的隔离的机制。</p>
<img title="k8s-namespace" alt="k8s-namespace" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-namespace.png/w600">

<h2 id="Kubernetes-的-API"><a href="#Kubernetes-的-API" class="headerlink" title="Kubernetes 的 API"></a>Kubernetes 的 API</h2><p>下面我们介绍一下 Kubernetes 的 API 的基础知识。从 high-level 上看，Kubernetes API 是由 HTTP+JSON 组成的：用户访问的方式是 HTTP，访问的 API 中 content 的内容是 JSON 格式的。</p>
<p>Kubernetes 的 kubectl 也就是 command tool，Kubernetes UI，或者有时候用 curl，直接与 Kubernetes 进行沟通，都是使用 HTTP + JSON 这种形式。</p>
<p>下面有个例子：比如说，对于这个 Pod 类型的资源，它的 HTTP 访问的路径，就是 API，然后是 apiVesion: V1, 之后是相应的 Namespaces，以及 Pods 资源，最终是 Podname，也就是 Pod 的名字。</p>
<img title="k8s-api" alt="k8s-api" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-api.png/w600">

<p>如果我们去提交一个 Pod，或者 get 一个 Pod 的时候，它的 content 内容都是用 JSON 或者是 YAML 表达的。上图中有个 yaml 的例子，在这个 yaml file 中，对 Pod 资源的描述也分为几个部分。</p>
<p>第一个部分，一般来讲会是 API 的 version。比如在这个例子中是 V1，它也会描述我在操作哪个资源；比如说我的 kind 如果是 pod，在 Metadata 中，就写上这个 Pod 的名字；比如说 nginx，我们也会给它打一些 label，我们等下会讲到 label 的概念。在 Metadata 中，有时候也会去写 annotation，也就是对资源的额外的一些用户层次的描述。</p>
<p>比较重要的一个部分叫做 Spec，Spec 也就是我们希望 Pod 达到的一个预期的状态。比如说它内部需要有哪些 container 被运行；比如说这里面有一个 nginx 的 container，它的 image 是什么？它暴露的 port 是什么？</p>
<p>当我们从 Kubernetes API 中去获取这个资源的时候，一般来讲在 Spec 下面会有一个项目叫 status，它表达了这个资源当前的状态；比如说一个 Pod 的状态可能是正在被调度、或者是已经 running、或者是已经被 terminates，就是被执行完毕了。</p>
<p>刚刚在 API 之中，我们讲了一个比较有意思的 metadata 叫做“label”，这个 label 可以是一组 KeyValuePair。</p>
<p>比如下图的第一个 pod 中，label 就可能是一个 color 等于 red，即它的颜色是红颜色。当然你也可以加其他 label，比如说 size: big 就是大小，定义为大的，它可以是一组 label。</p>
<p>这些 label 是可以被 selector，也就是选择器所查询的。这个能力实际上跟我们的 sql 类型的 select 语句是非常相似的，比如下图中的三个 Pod 资源中，我们就可以进行 select。name color 等于 red，就是它的颜色是红色的，我们也可以看到，只有两个被选中了，因为只有他们的 label 是红色的，另外一个 label 中写的 color 等于 yellow，也就是它的颜色是黄色，是不会被选中的。</p>
 <img title="k8s-label" alt="k8s-label" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-label.png/w600">

<p>通过 label，kubernetes 的 API 层就可以对这些资源进行一个筛选，那这些筛选也是 kubernetes 对资源的集合所表达默认的一种方式。</p>
<p>例如说，我们刚刚介绍的 Deployment，它可能是代表一组的 Pod，它是一组 Pod 的抽象，一组 Pod 就是通过 label selector 来表达的。当然我们刚才讲到说 service 对应的一组 Pod，就是一个 service 要对应一个或者多个的 Pod，来对它们进行统一的访问，这个描述也是通过 label selector 来进行 select 选取的一组 Pod。</p>
<p>所以可以看到 label 是一个非常核心的 kubernetes API 的概念，我们在接下来的课程中也会着重地去讲解和介绍 label 这个概念，以及如何更好地去使用它。</p>
<h1 id="五、以一个-demo-结尾"><a href="#五、以一个-demo-结尾" class="headerlink" title="五、以一个 demo 结尾"></a>五、以一个 demo 结尾</h1><p>最后一部分，我想以一个例子来结束，让大家跟我一起来尝试一个 kubernetes，在尝试 Kubernetes 之前，我希望大家能在本机上安装一下 Kubernetes，安装一个 Kubernetes 沙箱环境。</p>
<p>安装这个沙箱环境，主要有三个步骤：</p>
<ol>
<li>首先需要安装一个虚拟机，来在虚拟机中启动 Kubernetes。我们会推荐大家利用 virtualbox 来作为虚拟机的运行环境；</li>
</ol>
<p>安装 VirtualBox： <a href="https://www.virtualbox.org/wiki/Downloads" target="_blank" rel="noopener">https://www.virtualbox.org/wiki/Downloads</a></p>
<ol start="2">
<li>其次我们需要在虚拟机中启动 Kubernetes，Kubernetes 有一个非常有意思的项目，叫 minikube，也就是启动一个最小的 local 的 Kubernetes 的一个环境。</li>
</ol>
<p>minikube 我们推荐使用下面写到的阿里云的版本，它和官方 minikube 的主要区别就是把 minikube 中所需要的 Google 上的依赖换成国内访问比较快的一些镜像，这样就方便了大家的安装工作；</p>
<p>安装 MiniKube（中国版）: <a href="https://yq.aliyun.com/articles/221687" target="_blank" rel="noopener">https://yq.aliyun.com/articles/221687</a></p>
<ol start="3">
<li>最后在安装完 virtualbox 和 minikube 之后，大家可以对 minikube 进行启动，也就是下面这个命令。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动命令：</span></span><br><span class="line">minikube start —vm-driver virtualbox</span><br></pre></td></tr></table></figure>
<p>如果大家不是 Mac 系统，其他操作系统请访问下面这个链接，查看其它操作系统如何安装 minikube 沙箱环境。</p>
<p><a href="https://kubernetes.io/docs/tasks/tools/install-minikube/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/tools/install-minikube/</a></p>
<p>当大家安装好之后，我会跟大家一起做一个例子，来做三件事情：</p>
<ol>
<li>提交一个 nginx deployment；<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply  -f  https://k8s.io/examples/application/deployment.yaml</span><br></pre></td></tr></table></figure></li>
<li>升级 nginx deployment；<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f  https://k8s.io/examples/application/deployment-update.yaml</span><br></pre></td></tr></table></figure></li>
<li>扩容 nginx deployment。<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f  https://k8s.io/examples/application/deployment-update.yaml</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>第一步，我们提交一个 nginx 的 Deployment，然后对这个 Deployment 进行一次版本升级，也就是改变它中间 Pod 的版本。最后我们也会尝试对 nginx 进行一次扩容，进行一次水平的伸缩，下面就让大家一起跟我来尝试这三个操作吧。</p>
<p>首先，我们先看一下 minikube 的 status，可以看到 kubelet master 和 kubectl 都是配置好的。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ minikube status</span><br><span class="line">host: Running</span><br><span class="line">kubelet: Running</span><br><span class="line">apiserver: Running</span><br></pre></td></tr></table></figure>
<p>下一步我们利用 kubectl 来看一下这个集群中节选的状态，可以看到这个master 的节点已经是running状态：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME          STATUS   ROLES    AGE   VERSION</span><br><span class="line">minikube      Ready    master   1d9h  v1.14.0</span><br></pre></td></tr></table></figure>
<p>我们就以这个为节点，下面我们尝试去看一下现在集群中 Deployment 这个资源：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get deployments</span><br><span class="line">NAME                READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>

<p>可以看到集群中没有任何的 Deployment，我们可以利用 watch 这个语义去看集群中 Deployment 这个资源的变化情况。</p>
<p>下面我们去做刚才想要的三个操作：第一个操作是去创建一个 Deployment。可以看到下面第一个图，这是一个 API 的 content，它的 kind 是 Deployment，name 是 nginx-deployment, 有图中它的 replicas 数目是2，它的镜像版本是 1.14.0。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span> <span class="comment"># for versions before 1.9.0 use apps/v1beta2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span> </span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.14.0</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>我们下面还是回到 kubectl 这个 commnd 来执行这次 Deployment 的真正的操作。我们可以看到一个简单的操作，就会去让 Deployment 不停地生成副本。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f deployment.yaml</span></span><br><span class="line">deployment.apps/nginx-deployment created</span><br></pre></td></tr></table></figure>
<p>Deployment 副本数目是 2 个，下面也可以 describe 一下现在的 Deployment 的状态。我们知道之前是没有这个 Deployment 的，现在我们去 describe 这个 nginx-deployment。</p>
<p>下图中可以看到：有一个 nginx-deployment 已经被生成了，它的 replicas 数目也是我们想要的、selector 也是我们想要的、它的 image 的版本也是 1.14.0。还可以看到，里面的 deployment-controller 这种版本控制器也是在管理它的生成。</p>
<img title="k8s-nginx-1" alt="k8s-nginx-1" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-nginx-1.png/w600">

<p>下面我们去升级这个 Deployment 版本，首先下载另外一个 yaml 文件 deployment-update.yaml，可以看到这里面的 image 本身的版本号从 1.14.0 升级到 1.14.2。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.14.2</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<p>接下来我们重新 apply 新的 deployment-update 这个 yaml 文件。</p>
<p>可以看到，在屏幕上显示出了这个 Deployment 升级的一些操作，最终它的 up-to-date 值从 0 变成了 2，也就是说所有的容器都是最新版本的，所有的 Pod 都是最新版本的。我们也可以 discribe 具体去看一下是不是所有 Pod 的版本都被更新了，可以看到这个 image 的版本由 1.14.0 真正更新到了 1.14.2。</p>
<p>最后，我们也可以看到  controller 又执行了几次新的操作，这个控制器维护了整个 Deployment 和 Pod 状态。</p>
<img title="k8s-nginx-2" alt="k8s-nginx-2" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-nginx-2.png/w600">

<p>最后我们演示一下给 Deployment 做水平扩张，下载另一个 yaml 文件 deployment-scale.yaml，这里面的 replicas 数目已经从 2 改成了 4。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">selector:</span></span><br><span class="line">  <span class="attr">matchLabels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">replicas:</span> <span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>回到最开始的窗口，用 kubectl 去 apply 这个新的 deployment-scale.yaml 文件，在另外一个窗口上可以看到，当我们执行了 deployment-scale 操作之后，它的容器 Pod 数目从 2 变成了 4。我们可以再一次 describ 一下当前集群中的 deployment 的情况，可以看到它的 replicas 的数目从 2 变到了 4，同时也可以看到 controller 又做了几次新的操作，这个 scale up 成功了。</p>
<img title="k8s-nginx-3" alt="k8s-nginx-3" data-src="http://f.ngall-in.com/alan87/static/images/cn/cloud-native-3/k8s-nginx-3.png/w600">

<p>最后，让我们利用 delete 操作把我们刚才生成的 Deployment 给删除掉。kubectl delete deployment，也是刚才我们本身的 deployment name，当我们把它删除掉之后，我们今天所有的操作就完成了。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl delete -f deployment.yaml </span><br><span class="line">deployment.apps <span class="string">"nginx-deployment"</span> deleted</span><br></pre></td></tr></table></figure>

<p>我们再去重新 get 这个 Deployment，也会显示这个资源不再存在，这个集群又回到了最开始干净的状态。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get deployments</span><br><span class="line">NAME                READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>

<p>以上这就是这堂课中所有的内容了，我们关注了 kubernetes 的核心概念以及 kubernetes 的架构设计，希望大家能在这节课中有所收获！</p>
<h1 id="本节总结"><a href="#本节总结" class="headerlink" title="本节总结"></a>本节总结</h1><div class="note danger">
            <ul><li>Kubernetes 是一个自动化的容器编排平台，它负责应用的部署、应用的弹性以及应用的管理，这些都是基于容器的；</li><li>Kubernetes 架构是一个比较典型的二层架构和 server-client 架构；</li></ul>
          </div>

]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql中int长度的意义</title>
    <url>/db/mysql-int-length/</url>
    <content><![CDATA[<p>提问：<br>mysql的字段，unsigned int(3), 和unsinged int(6), 能存储的数值范围是否相同。如果不同，分别是多大？</p>
<p>回答：<br>不同，int(3)最多显示3位无符号整体，int(6)最多显示6位无符号数。<br>如果你的答案和上面的一致，恭喜你和我犯了一样的错误。</p>
<a id="more"></a>

<p>真实情况：<br>我们建立下面这张表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`test`</span> (</span><br><span class="line">    <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">10</span>) <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">    <span class="string">`i1`</span> <span class="built_in">int</span>(<span class="number">3</span>) <span class="keyword">unsigned</span> zerofill <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">    <span class="string">`i2`</span> <span class="built_in">int</span>(<span class="number">6</span>) <span class="keyword">unsigned</span> zerofill <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=MyISAM <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8</span><br></pre></td></tr></table></figure>
<p>插入一些数据后<br><img data-src="https://img-blog.csdn.net/20160531114758318" alt=""></p>
<p>发现，无论是int(3), int(6), 都可以显示6位以上的整数。但是，当数字不足3位或6位时，前面会用0补齐。</p>
<p>查下手册，解释是这样的：</p>
<div class="note primary">
            <p>MySQL还支持选择在该类型关键字后面的括号内指定整数值的显示宽度(例如，INT(4))。该可选显示宽度规定用于显示宽度小于指定的列宽度的值时从左侧填满宽度。显示宽度并不限制可以在列内保存的值的范围，也不限制超过列的指定宽度的值的显示。</p><p>也就是说，int的长度并不影响数据的存储精度，长度只和显示有关，为了让大家看的更清楚，我们在上面例子的建表语句中，使用了zerofill。</p>
          </div>

<p>结论：</p>
<div class="note primary">
            <p>无论是unsigned int(3)或 unsiend int(6)，存储的都是4字节无符号整数， 也就是0~2^32。</p>
          </div>]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql int类型</title>
    <url>/db/mysql-int/</url>
    <content><![CDATA[<div class="note primary">
            <p>Mysql中bigint、int、mediumint、smallint 和 tinyint的取值范围</p>
          </div>
<hr>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>社区这边的业务就遇到过这个坑，由于是用的开源框架，很多表id的字段用的mediumint类型，随着业务增长，数据量暴增，结果有一天超过id的上限，结果insert db就报错了，影响部分业务功能。</p>
<a id="more"></a>

<h3 id="整型数值"><a href="#整型数值" class="headerlink" title="整型数值"></a>整型数值</h3><p>整型的每一种都分有无符号（unsigned）和有符号（signed）两种类型，在默认情况下声明的整型变量都是有符号的类型，如果需声明无符号类型的话就需要在类型前加上unsigned。</p>
<h4 id="bigint"><a href="#bigint" class="headerlink" title="bigint"></a>bigint</h4><p>从 -2^63 (-9223372036854775808) 到 2^63-1 (9223372036854775807) 的整型数据（所有数字），无符号的范围是0到18446744073709551615，共 8 个字节。</p>
<h4 id="int"><a href="#int" class="headerlink" title="int"></a>int</h4><p>一个正常大小整数。有符号的范围是-2^31 (-2,147,483,648) 到 2^31 - 1 (2,147,483,647) 的整型数据（所有数字），无符号的范围是0到4294967295。共 4 个字节。<br>int 的 SQL-92 同义词为 integer。</p>
<h4 id="mediumint"><a href="#mediumint" class="headerlink" title="mediumint"></a>mediumint</h4><p>一个中等大小整数，有符号的范围是-8388608到8388607，无符号的范围是0到16777215，  [0，2^24-1]。 大小为3个字节。</p>
<h4 id="smallint"><a href="#smallint" class="headerlink" title="smallint"></a>smallint</h4><p>一个小整数。有符号的范围是-2^15 (-32,768) 到 2^15 - 1 (32,767) 的整型数据，无符号的范围是0到65535。大小为 2 个字节。MySQL提供的功能已经绰绰有余，而且由于MySQL是开放源码软件，因此可以大大降低总体拥有成本。</p>
<h4 id="tinyint"><a href="#tinyint" class="headerlink" title="tinyint"></a>tinyint</h4><p>有符号的范围是-128 - 127， 无符号的范围是 从 0 到 255 的整型数据。大小为 1 字节。[0，2^8-1]</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>NoSQL 没毛病，为什么 MySQL 还是“王”？</title>
    <url>/db/mysql-nosql/</url>
    <content><![CDATA[<p>NoSQL 出现时，许多人认为关系型数据库已进入死亡倒计时，MySQL 将退出舞台。</p>
<p>然而，在目前的各种数据库榜单中，MySQL 依然保持着领先地位。更令人惊讶的是，虽然甲骨文的受欢迎程度在不断下降，但 MySQL 保持着稳定。 为什么？</p>
<a id="more"></a>
<p>据 DB-Engines 统计，虽然 MySQL 和 Oracle 相对于其它数据库来看已有“失宠”迹象，但成绩仍然不错。而且 MySQL 的走势表现不错：<br><img data-src="http://mmbiz.qpic.cn/mmbiz_png/DmibiaFiaAI4B1bskL5L1rFoaG6uwvEbOtmNfDMiaDhic596KhYveB7lQnd4NqWNicgVXKz95l6JicuTMAwOwHb6pFNfA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt=""></p>
<p>虽然这几年 MySQL 在 Google 的搜索有所下降，但大体上与 Oracle 和 Microsoft SQL Server 的搜索下降幅度一致，专业兴趣（参考 Stack Overflow 趋势）保持相对稳定。</p>
<p>剧本似乎和最初设想的不同。NoSQL 在企业中蓬勃发展，是因为企业都在努力管理其现代数据的数量、速度和多样性。不知何故，MySQL 不仅幸存下来，而且发展不错。</p>
<p>当然，NoSQL 也展示了其潜力。MongoDB 尤其引起了极大的兴趣，该公司今年以来的收入已超过1亿美元。</p>
<p>不过 MongoDB 并没有推翻 MySQL，也没有挤垮 Apache Cassandra 或 Apache Hadoop，它们各自有拿得出手的专属使用案例。部分原因源于当今大多数大数据的性质：本质上仍然是事务性的。</p>
<p>这恰恰也是 MySQL 受欢迎的核心：它是最适合广泛数据库从业人员技能的数据库。他们甚至可以利用从 Oracle、IBM DB2 和 Microsoft SQL Server 学习到的东西，将其应用到这个无处不在、免费和开源的数据库。</p>
<p>Pivotal 的副总裁 James Bayer 曾表示，MySQL 对于苛刻的工作负载来说是一个强大的选择。Compose.io 的开发者 DJ Walker-Morgan 也说过：“NoSQL 就像我购买营养食品去减肥一样，负责的是控制，必须有严格的纪律和谨慎的管理才适用”。</p>
<p>说白了，MySQL 没有 Oracle 喜欢在其数据库上贴的“企业级”标签，没有 NoSQL 所谓的“横向扩展”营销方式，但它是以前也是现在的开发者的默认选择。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL主从详解与实践</title>
    <url>/db/mysql-master-slave/</url>
    <content><![CDATA[<h1 id="Mysql主从原理"><a href="#Mysql主从原理" class="headerlink" title="Mysql主从原理"></a>Mysql主从原理</h1><h2 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h2><p>MySQL 内建的复制功能是构建大型，高性能应用程序的基础。将 MySQL 的数亿数据分布到到多个系统上去，这种分步机制，是通过将 MySQL 的某一台主机的数据复制到其它主机( Slave )上，并重新执行一遍来实现的。<a id="more"></a><br>复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。主服务器将更新写入二进制日志，并维护文件的一个索引以跟踪日志循环。这些日志可以记录发送到从服务器的更新。当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置，从服务器接收从那时起发生的任何更新，然后封锁等等主服务器通知新的更新。</p>
<div class="note warning">
            <p>请注意当你进行复制时，所有对复制中的表的更新必须在主服务器上进行。以避免用户对主服务器上表进行的更新与对从服务器上的表进行的更新 之间的冲突。</p>
          </div>

<h2 id="MySQL支持的复制类型"><a href="#MySQL支持的复制类型" class="headerlink" title="MySQL支持的复制类型"></a>MySQL支持的复制类型</h2><ul>
<li>基于语句的复制。 在主服务器上执行的 SQL 语句，在从服务器上执行同样的语句。配置：<br>注释内容<br><code>binlog_format = STATEMENT</code></li>
<li>基于行的复制。把改变的内容复制过去，而不是把命令在从服务器上执行一遍，从 MySQL 5.0开始支持，配置：<br><code>binlog_format = ROW</code></li>
<li>混合类型的复制。默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制,配置：<br><code>binlog_format = MIXED</code></li>
</ul>
<h2 id="Mysql同步解决的问题"><a href="#Mysql同步解决的问题" class="headerlink" title="Mysql同步解决的问题"></a>Mysql同步解决的问题</h2><ul>
<li>数据分布</li>
<li>负载平衡</li>
<li>备份</li>
<li>高可用性和容错行</li>
</ul>
<h2 id="同步是如何工作的"><a href="#同步是如何工作的" class="headerlink" title="同步是如何工作的"></a>同步是如何工作的</h2><p>MySQL之间数据同步的基础是二进制日志文件（binary log file）。<br>一台MySQL数据库一旦启用二进制日志后，其作为master，它的数据库中所有操作都会以 事件 的方式记录在二进制日志中，<br>其他数据库作为slave通过一个I/O线程与主服务器保持通信，并监控master的二进制日志文件的变化，如果发现master二进制日志文件发生变化，则会把变化同步到自己的中继日志中，<br>然后slave的一个SQL线程会把相关的“事件”执行到自己的数据库中，以此实现从数据库和主数据库的一致性，也就实现了主从同步。</p>
<p>可以简化为三个步骤：</p>
<ol>
<li>Master 将改变记录到二进制日志中。</li>
<li>Slave 将 Master 的二进制日志拷贝到它的中继日志( Relay_log )</li>
<li>Slave 重做中继日志中的事件，将改变反映它自己的数据<br><img data-src="https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=3779862913,258598645&fm=15&gp=0.jpg" alt=""></li>
</ol>
<p>说明:</p>
<div class="note primary">
            <ol><li>Master 记录二进制的日志。在每个事务更新数据之前，Master 在二进制日志记录这些改变。 MySQL 将事务日志的写入二进制日志，及时事务中的语句都市交叉执行的。在事件写入二进制日志完成后，Master 通知存储引擎提交事务。</li><li>Slave 将 Master 的 Binary log 拷贝到它自己的中继日志。首先 Slave 开始一个工作线程–I/O线程。I/O 线程在 Master 上打开一个连接，然后开始从二进制日志中读取事件，如果已经连上 Master，它会并等待master产生新的事件。I/O线程就这些事件写入中继日志。</li><li>SQL Slave Thread ( SQL从线程)处理该过程的最后一步。SQL纯种从中继日志读取事件，并重放其中的事件而更新 Slave 的数据。使其它与 Master 中的数据保持一致。只要该线程与 I/O 线程保持一致，中继日志通常会位于 OS 的缓存中，所以中继日志的开销很小。</li><li>此处，在 Master 中也有一个工作线程，和其他 MySQL 的连接一样，Slave 在 Master 中打开一个连接也会使得 Master 开始一个线程。复制过程有一个很重要的限制—复制在 Slave 上是串行化的，也就是说 Master 上的并行更新操作不能在 Slave 上并行操作。</li></ol>
          </div>

<h2 id="同步实现细节分析"><a href="#同步实现细节分析" class="headerlink" title="同步实现细节分析"></a>同步实现细节分析</h2><p>MySQL主从同步功能使用三个线程实现，一个在主服务器上，两个在从服务器上</p>
<h3 id="1-Binlog转储线程。"><a href="#1-Binlog转储线程。" class="headerlink" title="(1)Binlog转储线程。"></a>(1)Binlog转储线程。</h3><p>当从服务器与主服务器连接时，主服务器会创建一个线程将二进制日志内容发送到从服务器。<br>该线程可以使用 语句 SHOW PROCESSLIST(下面有示例介绍) 在服务器 sql 控制台输出中标识为Binlog Dump线程。</p>
<p>二进制日志转储线程获取服务器上二进制日志上的锁，用于读取要发送到从服务器的每个事件。一旦事件被读取，即使在将事件发送到从服务器之前，锁会被释放。</p>
<h3 id="2-从服务器I-O线程。"><a href="#2-从服务器I-O线程。" class="headerlink" title="(2)从服务器I/O线程。"></a>(2)从服务器I/O线程。</h3><p>当在从服务器sql 控制台发出 START SLAVE语句时，从服务器将创建一个I/O线程，该线程连接到主服务器，并要求它发送记录在主服务器上的二进制更新日志。</p>
<p>从机I/O线程读取主服务器Binlog Dump线程发送的更新 （参考上面 Binlog转储线程 介绍），并将它们复制到自己的本地文件二进制日志中。</p>
<p>该线程的状态显示详情 Slave_IO_running 在输出端 使用 命令SHOW SLAVE STATUS</p>
<p>使用\G语句终结符,而不是分号,是为了，易读的垂直布局</p>
<p>这个命令在上面 查看从服务器状态 用到过</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql&gt; SHOW SLAVE STATUS\G</span><br></pre></td></tr></table></figure>
<h3 id="3-从服务器SQL线程。"><a href="#3-从服务器SQL线程。" class="headerlink" title="(3)从服务器SQL线程。"></a>(3)从服务器SQL线程。</h3><p>从服务器创建一条SQL线程来读取由主服务器I/O线程写入的二级制日志，并执行其中包含的事件。</p>
<p>在前面的描述中，每个主/从连接有三个线程。主服务器为每个当前连接的从服务器创建一个二进制日志转储线程，每个从服务器都有自己的I/O和SQL线程。<br>从服务器使用两个线程将读取更新与主服务器更新事件，并将其执行为独立任务。因此，如果语句执行缓慢，则读取语句的任务不会减慢。</p>
<p>例如，如果从服务器开始几分钟没有运行，或者即使SQL线程远远落后，它的I/O线程也可以从主服务器建立连接时，快速获取所有二进制日志内容。</p>
<p>如果从服务器在SQL线程执行所有获取的语句之前停止，则I/O线程至少获取已经读取到的内容，以便将语句的安全副本存储在自己的二级制日志文件中，准备下次执行主从服务器建立连接，继续同步。</p>
<p>使用命令 SHOW FULL PROCESSLIST\G 可以查看有关复制的信息</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt;  SHOW FULL PROCESSLIST\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">     Id: 22</span><br><span class="line">   User: repl</span><br><span class="line">   Host: node:39114</span><br><span class="line">     db: NULL</span><br><span class="line">Command: Binlog Dump</span><br><span class="line">   Time: 4435</span><br><span class="line">  State: Master has sent all binlog to slave; waiting for more updates</span><br><span class="line">   Info: NULL</span><br></pre></td></tr></table></figure>
<p>Id: 22是Binlog Dump服务连接的从站的复制线程<br>Host: node:39114 是从服务，主机名 及端口<br>State: 信息表示所有更新都已同步发送到从服务器，并且主服务器正在等待更多更新发生。<br>如果Binlog Dump在主服务器上看不到 线程，意味着主从复制没有配置成功; 也就是说，没有从服务器连接主服务器。</p>
<p>命令 SHOW PROCESSLIST\G</p>
<p>在 Slave 从服务器 ，查看两个线程的更新状态</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; SHOW PROCESSLIST\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">     Id: 6</span><br><span class="line">   User: system user</span><br><span class="line">   Host: </span><br><span class="line">     db: NULL</span><br><span class="line">Command: Connect</span><br><span class="line">   Time: 6810</span><br><span class="line">  State: Waiting for master to send event</span><br><span class="line">   Info: NULL</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">     Id: 7</span><br><span class="line">   User: system user</span><br><span class="line">   Host: </span><br><span class="line">     db: NULL</span><br><span class="line">Command: Connect</span><br><span class="line">   Time: 3069</span><br><span class="line">  State: Slave has read all relay log; waiting for more updates</span><br><span class="line">   Info: NULL</span><br></pre></td></tr></table></figure>
<p>Id: 6是与主服务器通信的I/O线程<br>Id: 7是正在处理存储在中继日志中的更新的SQL线程</p>
<p>在 运行 SHOW PROCESSLIST 命令时，两个线程都空闲，等待进一步更新</p>
<p>如果在主服务器上在设置的超时，时间内 Binlog Dump线程没有活动，则主服务器会和从服务器断开连接。超时取决于的 服务器系统变量 值 net_write_timeout(在中止写入之前等待块写入连接的秒数，默认10秒)和 net_retry_count;(如果通信端口上的读取或写入中断，请在重试次数，默认10次) 设置 服务器系统变量</p>
<p>该SHOW SLAVE STATUS语句提供了有关从服务器上复制处理的附加信息。</p>
<h2 id="同步常用类型"><a href="#同步常用类型" class="headerlink" title="同步常用类型"></a>同步常用类型</h2><h3 id="同步的常用体系结构基本原则"><a href="#同步的常用体系结构基本原则" class="headerlink" title="同步的常用体系结构基本原则"></a>同步的常用体系结构基本原则</h3><ol>
<li>每个 Slave 只能有一个 Master；</li>
<li>每个 Slave 只能有一个唯一的服务器ID；</li>
<li>每个 Master 可以有很多 Slave;</li>
</ol>
<p>如果你设置了 log_slave_updates，Slave 可以是其他 Slave 的 Master，从而扩散 Master 的更新<br>MySQL 不支持多主服务器复制—即一个 Slave 可以有多个 Master，但是，通过一些简单的组合，我们却可以建立灵活而强大的复制体系结构。</p>
<div class="tabs" id="master-slave-types"><ul class="nav-tabs"><li class="tab active"><a href="#master-slave-types-1"><i class="fa fa-reorder"></i>一主多从复制架构</a></li><li class="tab"><a href="#master-slave-types-2"><i class="fa fa-reorder"></i>多级复制架构</a></li><li class="tab"><a href="#master-slave-types-3"><i class="fa fa-reorder"></i>双主复制/Dual Master架构</a></li></ul><div class="tab-content"><div class="tab-pane active" id="master-slave-types-1"><h3 id="一主多从复制架构"><a href="#一主多从复制架构" class="headerlink" title="一主多从复制架构"></a>一主多从复制架构</h3><p>场景：<br>在主库读取请求压力非常大的场景下，可以通过配置一主多从复制架构实现读写分离，把大量对实时性要求不是特别高的读请求通过负载均衡到多个从库上，降低主库的读取压力。在主库出现异常宕机的情况下，可以把一个从库切换为主库继续提供服务；</p>
<p>建议：</p>
<ol>
<li>当 Slave 增加到一定数量时，Slave 对 Master 的负载以及网络带宽都会成为一个严重的问题。</li>
<li>不同的 Slave 扮演不同的作用(例如使用不同的索引，或者不同的存储引擎)</li>
<li>用一个 Slave 作为备用 Master，只进行复制</li>
<li>用一个远程的 Slave，用于灾难恢复。</li>
</ol></div><div class="tab-pane" id="master-slave-types-2"><h3 id="多级复制架构"><a href="#多级复制架构" class="headerlink" title="多级复制架构"></a>多级复制架构</h3><p>场景：<br>一主多从的架构能够解决大部分读请求压力特别大的场景需求，但主库的I/O压力和网络压力会随着从库的增加而增长，而使用多级复制架构就可以解决一主多从场景下，主库额外的I/O和网络压力。 但要注意的是，多级复制场景下主库的数据是经历两次才到达读取的从库，期间的延时比一主多从复制场景下只经历一次复制的要大。</p>
<p>建议：</p>
<ol>
<li>可能存在延时较长的风险</li>
<li>这种方案可以与第三方软件结合使用，例如Slave+LVS+Keepalived 实现高可用。</li>
</ol></div><div class="tab-pane" id="master-slave-types-3"><h3 id="双主复制-Dual-Master架构"><a href="#双主复制-Dual-Master架构" class="headerlink" title="双主复制/Dual Master架构"></a>双主复制/Dual Master架构</h3><p>场景：<br>双主/Dual Master架构适用于写压力比较大的场景，或者DBA做维护需要主从切换的场景，通过双主/Dual master架构避免了重复搭建从库的麻烦。</p>
<p>建议：</p>
<ol>
<li>最大问题就是更新冲突。</li>
<li>可以采用MySQL Cluster，以及将Cluster和Replication结合起来，可以建立强大的高性能的数据库平台。</li>
</ol></div></div></div>

<h1 id="mysql主从配置实践"><a href="#mysql主从配置实践" class="headerlink" title="mysql主从配置实践"></a>mysql主从配置实践</h1><h2 id="实现MySQL主从复制需要进行的配置："><a href="#实现MySQL主从复制需要进行的配置：" class="headerlink" title="实现MySQL主从复制需要进行的配置："></a>实现MySQL主从复制需要进行的配置：</h2><p>主服务器：</p>
<ul>
<li>开启二进制日志</li>
<li>配置唯一的server-id</li>
<li>获得master二进制日志文件名及位置</li>
<li>创建一个用于slave和master通信的用户账号</li>
</ul>
<p>从服务器：</p>
<ul>
<li>配置唯一的server-id</li>
<li>使用master分配的用户账号读取master二进制日志</li>
<li>启用slave服务</li>
</ul>
<p>具体实现过程如下：</p>
<h2 id="基础环境配置"><a href="#基础环境配置" class="headerlink" title="基础环境配置"></a>基础环境配置</h2><p>数据库版本： mysql 5.5.71 ( Slave 版本可以大于或者等于 Master版本)<br>操作系统： CentOS 6.7 x86_64<br>IP地址：192.168.18.10 ( Master ) 192.168.18.20 ( Slave )</p>
<h2 id="Master-Server配置"><a href="#Master-Server配置" class="headerlink" title="Master-Server配置"></a>Master-Server配置</h2><h3 id="1-修改Master-mysql配置"><a href="#1-修改Master-mysql配置" class="headerlink" title="(1)修改Master mysql配置"></a>(1)修改Master mysql配置</h3><p>找到主数据库的配置文件my.cnf(或者my.ini)，如在/etc/mysql/my.cnf,在[mysqld]部分插入如下两行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line"><span class="built_in">log</span>-bin=mysql-bin <span class="comment">#开启二进制日志</span></span><br><span class="line">server-id=1 <span class="comment">#设置server-id</span></span><br></pre></td></tr></table></figure>
<p>重启MySQL服务<br><code>$ service mysqld restart</code></p>
<h3 id="2-创建用于同步的用户账号-复制帐号"><a href="#2-创建用于同步的用户账号-复制帐号" class="headerlink" title="(2)创建用于同步的用户账号(复制帐号)"></a>(2)创建用于同步的用户账号(复制帐号)</h3><p>在主服务器上为从服务器分配一个账号，就像一把钥匙，从服务器拿着这个钥匙，才能到主服务器上来共享主服务器的日志文件。</p>
<p>在 Master 的数据库中建立一个复制账户，每个 Slave 使用该账户连接 Master 进行复制，需要 replication slave 和 replication client 权限，Master 的连接信息会存储在文本文件 master.info 文件中。(master.info文件在 Slave 的数据目录中)</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql&gt;grant replication slave on *.* to 'replication'@'192.168.18.20' identified by '123456';#创建用户和分配权限</span><br><span class="line">mysql&gt;flush privileges;#刷新权限</span><br></pre></td></tr></table></figure>
<div class="note warning">
            <p>说明：创建了一个用户名为 replication 的用户，密码为 123456 ,只允许在 192.168.18.20 这个 Slave 上登录。</p>
          </div>

<h3 id="3-查询master的状态"><a href="#3-查询master的状态" class="headerlink" title="(3)查询master的状态"></a>(3)查询master的状态</h3><p>查看 File(日志文件名) 和 Postition(日志地址)，下面配置 Slave 的时候需要用。执行完之后记录下这两值，然后在配置完从服务器之前不要对主服务器进行任何操作，因为每次操作数据库时这两值会发生改变</p>
<p><code>mysql&gt;show master status;</code></p>
<table>
<thead>
<tr>
<th align="left">File</th>
<th align="left">Position</th>
<th align="left">Binlog_Do_DB</th>
<th align="left">Binlog_Ignore_DB</th>
<th align="left">Executed_Gtid_Set</th>
</tr>
</thead>
<tbody><tr>
<td align="left">db01-bin.000002</td>
<td align="left">1169678</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<p>注：执行完这个步骤后不要再操作主数据库了，防止主数据库状态值变化</p>
<h2 id="Slave-Server-配置"><a href="#Slave-Server-配置" class="headerlink" title="Slave-Server 配置"></a>Slave-Server 配置</h2><h3 id="1-修改mysql配置"><a href="#1-修改mysql配置" class="headerlink" title="(1)修改mysql配置"></a>(1)修改mysql配置</h3><p>关闭slave（如果你以前配置过主从的话，一定要先关闭）<br>命令：stop slave;</p>
<p>找到从数据库的配置文件my.cnf(或者my.ini)，如/etc/mysql/my.cnf,在[mysqld]部分插入如下两行：<br>（Master-Server和Slave-Server 的server-id必须不一样）</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">log-bin=mysql-bin <span class="comment">#开启二进制日志</span></span><br><span class="line">server-id=2 <span class="comment">#设置server-id</span></span><br></pre></td></tr></table></figure>
<p>重启MySQL服务<br><code>$ service mysqld restart</code></p>
<h3 id="2-执行同步命令"><a href="#2-执行同步命令" class="headerlink" title="(2)执行同步命令"></a>(2)执行同步命令</h3><p>执行同步命令，设置主数据库ip，同步帐号密码，同步位置</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql&gt; CHANGE MASTER TO</span><br><span class="line">    -&gt;     MASTER_HOST='192.168.18.10',</span><br><span class="line">    -&gt;     MASTER_USER='replication',</span><br><span class="line">    -&gt;     MASTER_PASSWORD='123456',</span><br><span class="line">    -&gt;     MASTER_LOG_FILE='mysql-bin.000002',</span><br><span class="line">    -&gt;     MASTER_LOG_POS=1169678;</span><br></pre></td></tr></table></figure>
<p>选项：</p>
<ul>
<li>master_host：Master 服务器IP</li>
<li>master_user：Master 服务器授权用户，也就是 Master 前面创建的那个用户</li>
<li>master_password：Master 服务器授权用户对应的密码</li>
<li>master_log_file：Master binlog 文件名</li>
<li>master_log_pos：Master binlog 文件中的 Postion 值</li>
</ul>
<p>更多的选项可以看:<a href="http://dev.mysql.com/doc/refman/5.7/en/change-master-to.html" target="_blank" rel="noopener">http://dev.mysql.com/doc/refman/5.7/en/change-master-to.html</a></p>
<div class="note warning">
            <p>说明：使用刚刚在 Master 创建的用户连接，log_file 和 log_pos 就是使用刚刚在 Master 上执行 show master status; 执行出来的结果</p>
          </div>

<h3 id="3-启动slave同步进程："><a href="#3-启动slave同步进程：" class="headerlink" title="(3)启动slave同步进程："></a>(3)启动slave同步进程：</h3><p><code>mysql&gt;start slave;</code></p>
<h3 id="4-查看slave状态："><a href="#4-查看slave状态：" class="headerlink" title="(4)查看slave状态："></a>(4)查看slave状态：</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; show slave status\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">                Slave_IO_State: Waiting for master to send event</span><br><span class="line">                  Master_Host: 192.168.18.10</span><br><span class="line">                  Master_User: replication</span><br><span class="line">                  Master_Port: 3306</span><br><span class="line">                Connect_Retry: 60</span><br><span class="line">              Master_Log_File: mysql-bin.000013</span><br><span class="line">          Read_Master_Log_Pos: 11662</span><br><span class="line">                Relay_Log_File: mysqld-relay-bin.000022</span><br><span class="line">                Relay_Log_Pos: 11765</span><br><span class="line">        Relay_Master_Log_File: mysql-bin.000013</span><br><span class="line">              Slave_IO_Running: Yes</span><br><span class="line">            Slave_SQL_Running: Yes</span><br><span class="line">              Replicate_Do_DB: </span><br><span class="line">          Replicate_Ignore_DB: </span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>

<p>当Slave_IO_Running和Slave_SQL_Running都为YES的时候就表示主从同步设置成功了。接下来就可以进行一些验证了，比如在主master数据库的test数据库的一张表中插入一条数据，在slave的test库的相同数据表中查看是否有新增的数据即可验证主从复制功能是否有效，还可以关闭slave（mysql&gt;stop slave;）,然后再修改master，看slave是否也相应修改（停止slave后，master的修改不会同步到slave），就可以完成主从复制功能的验证了。</p>
<p>还可以用到的其他相关参数：</p>
<p>master开启二进制日志后默认记录所有库所有表的操作，可以通过配置来指定只记录指定的数据库甚至指定的表的操作，具体请看下节</p>
<h2 id="其他可能用到的相关参数"><a href="#其他可能用到的相关参数" class="headerlink" title="其他可能用到的相关参数"></a>其他可能用到的相关参数</h2><p>master端：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 不同步哪些数据库  </span></span><br><span class="line">binlog-ignore-db = mysql  </span><br><span class="line">binlog-ignore-db = test  </span><br><span class="line">binlog-ignore-db = information_schema  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 只同步哪些数据库，除此之外，其他不同步  </span></span><br><span class="line">binlog-<span class="keyword">do</span>-db = game  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志保留时间  </span></span><br><span class="line">expire_logs_days = <span class="number">10</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 控制binlog的写入频率。每执行多少次事务写入一次  </span></span><br><span class="line"><span class="comment"># 这个参数性能消耗很大，但可减小MySQL崩溃造成的损失  </span></span><br><span class="line">sync_binlog = <span class="number">5</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志格式，建议mixed  </span></span><br><span class="line"><span class="comment"># statement 保存SQL语句  </span></span><br><span class="line"><span class="comment"># row 保存影响记录数据  </span></span><br><span class="line"><span class="comment"># mixed 前面两种的结合  </span></span><br><span class="line">binlog_format = mixed</span><br></pre></td></tr></table></figure>
<p>slave端：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 停止主从同步  </span></span><br><span class="line">mysql&gt; stop slave;  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接断开时，重新连接超时时间  </span></span><br><span class="line">mysql&gt; change master to master_connect_retry=50;  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启主从同步  </span></span><br><span class="line">mysql&gt; start slave;</span><br></pre></td></tr></table></figure>

<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在 Master 数据库中执行sql语句操作，观察 Slave 是否同步，如果同步则说明配置成功。</p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol>
<li>主库和从库的数据库名必须相同；</li>
<li>主库和从库的复制可以精确到表，但是在需要更改主库或从库的数据结构时需要立刻重启slave；</li>
<li>不能在mysql配置文件里直接写入master的配置信息，需要用change master命令来完成；</li>
<li>指定replicate_do_db必须在my.cnf里配置，不能用change master命令来完成；</li>
<li>如果不及时清理，日积月累二进制日志文件可能会把磁盘空间占满，可以在配置文件里加上expire_logs_days=7，只保留最近7天的日志，建议当slave不再使用时，通过reset slave来取消relaylog；</li>
<li>写一个监控脚本，用来监控 Slave 中的两个”yes”，如果只有一个”yes”或者零个，就表明主从有问题。</li>
</ol>
<h1 id="MySQL-主从错误处理"><a href="#MySQL-主从错误处理" class="headerlink" title="MySQL 主从错误处理"></a>MySQL 主从错误处理</h1><p>解决和处理主从错误这个是最重要的，比配置更更要。提高处理问题的能力，要熟悉原理，多处理积累，多学习其他网友的处理方式。出现错误都会在 Last_SQL_Error 中显示错误，一般根据错误提示进行处理，如果不太清楚，可以谷歌查询一下，不过操作完之后，同步正常后，一定要核对一下数据是否一致。</p>
<p>以下是收集的几个处理主从问题的链接：</p>
<ul>
<li><a href="http://hzcsky.blog.51cto.com/1560073/479476/" target="_blank" rel="noopener">http://hzcsky.blog.51cto.com/1560073/479476/</a></li>
<li><a href="http://storysky.blog.51cto.com/628458/259280" target="_blank" rel="noopener">http://storysky.blog.51cto.com/628458/259280</a></li>
<li><a href="https://dev.mysql.com/doc/refman/5.7/en/faqs-replication.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/faqs-replication.html</a></li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql 批量修改 表字段/表/数据库 字符集和排序规则</title>
    <url>/db/mysql%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E5%AD%97%E7%AC%A6%E9%9B%86%E5%92%8C%E6%8E%92%E5%BA%8F%E8%A7%84%E5%88%99/</url>
    <content><![CDATA[<h1 id="表字段修复"><a href="#表字段修复" class="headerlink" title="表字段修复"></a>表字段修复</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="keyword">SELECT</span> TABLE_SCHEMA <span class="string">'数据库'</span>,TABLE_NAME <span class="string">'表'</span>,COLUMN_NAME <span class="string">'字段'</span>,CHARACTER_SET_NAME <span class="string">'原字符集'</span>,COLLATION_NAME <span class="string">'原排序规则'</span>,<span class="keyword">CONCAT</span>(<span class="string">'ALTER TABLE '</span>, TABLE_SCHEMA,<span class="string">'.'</span>,TABLE_NAME, <span class="string">' MODIFY COLUMN '</span>,COLUMN_NAME,<span class="string">' '</span>,COLUMN_TYPE,<span class="string">' CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;'</span>) <span class="string">'修正SQL'</span></span><br><span class="line"><span class="keyword">FROM</span> information_schema.<span class="string">`COLUMNS`</span> </span><br><span class="line"><span class="keyword">WHERE</span> COLLATION_NAME <span class="keyword">RLIKE</span> <span class="string">'latin1'</span>;</span><br></pre></td></tr></table></figure>

<h1 id="表修复"><a href="#表修复" class="headerlink" title="表修复"></a>表修复</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="keyword">SELECT</span> TABLE_SCHEMA <span class="string">'数据库'</span>,TABLE_NAME <span class="string">'表'</span>,TABLE_COLLATION <span class="string">'原排序规则'</span>,<span class="keyword">CONCAT</span>(<span class="string">'ALTER TABLE '</span>,TABLE_SCHEMA,<span class="string">'.'</span>, TABLE_NAME, <span class="string">' COLLATE=utf8mb4_general_ci;'</span>) <span class="string">'修正SQL'</span></span><br><span class="line"><span class="keyword">FROM</span> information_schema.<span class="string">`TABLES`</span></span><br><span class="line"><span class="keyword">WHERE</span> TABLE_COLLATION <span class="keyword">RLIKE</span> <span class="string">'latin1'</span>;</span><br></pre></td></tr></table></figure>

<h1 id="表修复-1"><a href="#表修复-1" class="headerlink" title="表修复"></a>表修复</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> SCHEMA_NAME <span class="string">'数据库'</span>,DEFAULT_CHARACTER_SET_NAME <span class="string">'原字符集'</span>,DEFAULT_COLLATION_NAME <span class="string">'原排序规则'</span>,<span class="keyword">CONCAT</span>(<span class="string">'ALTER DATABASE '</span>,SCHEMA_NAME,<span class="string">' CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;'</span>) <span class="string">'修正SQL'</span></span><br><span class="line"><span class="keyword">FROM</span> information_schema.<span class="string">`SCHEMATA`</span></span><br><span class="line"><span class="keyword">WHERE</span> DEFAULT_COLLATION_NAME <span class="keyword">RLIKE</span> <span class="string">'unicode_ci'</span>;</span><br></pre></td></tr></table></figure>

<p>ALTER TABLE attendance1.attendance_apply MODIFY COLUMN time_span varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_apply MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_approve MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_approve MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_copy_user MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_copy_user MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_file MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_file MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_working MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE attendance1.attendance_working MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.company_manage MODIFY COLUMN update_user varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.file_Info MODIFY COLUMN file_name varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.file_Info MODIFY COLUMN model_name varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.polling MODIFY COLUMN org_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.polling MODIFY COLUMN charge_phone varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.polling MODIFY COLUMN picture varchar(500) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.polling MODIFY COLUMN abarbeitung varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.team MODIFY COLUMN adderss varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE emergency.team_type MODIFY COLUMN value varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE iot_device1.video_client MODIFY COLUMN username varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE iot_device1.video_client MODIFY COLUMN password varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE iot_device1.video_client MODIFY COLUMN company_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE iot_device1.video_client MODIFY COLUMN creator varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE iot_device1.video_client MODIFY COLUMN update_user varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN apply_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN company_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN current_approve_node varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN reason varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN remark varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN time_span varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN departure varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN destination varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply_file MODIFY COLUMN company_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply_file MODIFY COLUMN file_save_name varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply_file MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply_file MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_approve MODIFY COLUMN approve_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_approve MODIFY COLUMN company_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_approve MODIFY COLUMN approve_full_opinion varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_approve MODIFY COLUMN approve_remark varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_approve MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_approve MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_copy_user MODIFY COLUMN copy_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_copy_user MODIFY COLUMN company_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_copy_user MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_copy_user MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_settings MODIFY COLUMN company_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_settings MODIFY COLUMN name varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_settings MODIFY COLUMN address varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_settings MODIFY COLUMN longitude varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_settings MODIFY COLUMN latitude varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_user MODIFY COLUMN company_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_user MODIFY COLUMN user_id varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_working MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.attendance_working MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dangerous MODIFY COLUMN company_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dangerous MODIFY COLUMN manage_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dictionary MODIFY COLUMN code varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dictionary MODIFY COLUMN field varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dictionary MODIFY COLUMN field_value varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dictionary MODIFY COLUMN type varchar(1) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dictionary MODIFY COLUMN remark varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dictionary MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.dictionary MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.focus_user MODIFY COLUMN file_src varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.storage_tank MODIFY COLUMN creator varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.storage_tank MODIFY COLUMN update_user varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.storage_tank MODIFY COLUMN design_stock varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.template_attendance_record MODIFY COLUMN user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.template_attendance_record MODIFY COLUMN user_type varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.template_attendance_record MODIFY COLUMN clock_in_type varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.template_attendance_record MODIFY COLUMN created_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER TABLE share.template_attendance_record MODIFY COLUMN modified_user_id varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;</p>
<p>ALTER TABLE emergency.company_category COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.company_label COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.company_manage COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.file_Info COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.garden COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.garden_company COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.label COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.polling COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.sys_dict COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.team COLLATE=utf8mb4_general_ci;<br>ALTER TABLE emergency.team_type COLLATE=utf8mb4_general_ci;<br>ALTER TABLE iot_device1.video_client COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.apply_user_company COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.attendance_apply_file COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.attendance_approve COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.attendance_copy_user COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.attendance_settings COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.attendance_user COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.attendance_working COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.company_expand COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.dangerous COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.dictionary COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.focus_user COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.notice_company COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.notice_user COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.storage_tank COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.sys_dict COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.template_attendance_record COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.user_issue COLLATE=utf8mb4_general_ci;<br>ALTER TABLE share.warehouse COLLATE=utf8mb4_general_ci;</p>
<p>ALTER DATABASE attendance1 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance10 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance2 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance3 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance4 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance5 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance6 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance7 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance8 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;<br>ALTER DATABASE attendance9 CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL技巧,SQL调优,存储引擎——终于全懂了(上)(收藏)</title>
    <url>/db/sql-optimize1/</url>
    <content><![CDATA[<h1 id="SQL技巧"><a href="#SQL技巧" class="headerlink" title="SQL技巧"></a>SQL技巧</h1><ul>
<li>insert ignore <div class="note primary">
            <p>insert ignore 与insert into的区别就是insert ignore 会忽略数据库中已经存在的数据，如果数据库没有数据，就插入新的数据，如果有数据的话就跳过这条数据。这样就可以保留数据库中已经存在数据，达到在间隙中插入数据的目的。</p>
          </div>

</li>
</ul>
<a id="more"></a>
<ul>
<li><p>replace into</p>
<div class="note primary">
            <p>replace into 跟 insert 功能类似，不同点在于：replace into 首先尝试插入数据到表中， </p><ol><li>如果发现表中已经有此行数据（根据主键或者唯一索引判断）则先删除此行数据，然后插入新的数据。 </li><li>否则，直接插入新数据。</li></ol>
          </div>
</li>
<li><p>ON DUPLICATE KEY UPDATE</p>
<div class="note primary">
            <p>当insert已经存在的记录时，执行Update.批量插入数据,自动解决索引冲突。</p><p>ON DUPLICATE KEY UPDATE能够让我们便捷的完成重复插入的开发需求，但它是<span class="label success">Mysql</span>的特有语法，使用时应多注意主键和插入值是否是我们想要插入或修改的key、Value。</p>
          </div> 
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> user_admin_t (_id,<span class="keyword">password</span>) </span><br><span class="line"><span class="keyword">VALUES</span> </span><br><span class="line">(<span class="string">'1'</span>,<span class="string">'多条插入1'</span>) ,</span><br><span class="line">(<span class="string">'UpId'</span>,<span class="string">'多条插入2'</span>)</span><br><span class="line"><span class="keyword">ON</span> <span class="keyword">DUPLICATE</span> <span class="keyword">KEY</span> <span class="keyword">UPDATE</span> </span><br><span class="line"><span class="keyword">password</span> =  <span class="keyword">VALUES</span>(<span class="keyword">password</span>);</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h1 id="数据库调优"><a href="#数据库调优" class="headerlink" title="数据库调优"></a>数据库调优</h1><p>当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化：</p>
<div class="note primary">
            <ul><li>单表优化（字段、索引、SQL优化、存储引擎、系统参数、硬件）</li><li>缓存</li><li>读写分离</li><li>表分区</li><li>分库分表（垂直拆分，水平拆分）</li></ul>
          </div>
<h2 id="单表优化"><a href="#单表优化" class="headerlink" title="单表优化"></a>单表优化</h2><p>除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量：</p>
<h3 id="字段"><a href="#字段" class="headerlink" title="字段"></a>字段</h3><ul>
<li>字段最小原则, 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED</li>
<li>VARCHAR的长度只分配真正需要的空间</li>
<li>使用枚举或整数代替字符串类型</li>
<li>尽量使用TIMESTAMP而非DATETIME</li>
<li>单表不要有太多字段，建议在20以内</li>
<li>避免使用NULL字段，很难查询优化且占用额外索引空间</li>
<li>用整型来存IP</li>
</ul>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ul>
<li>索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描</li>
<li>应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描</li>
<li>值分布很稀少的字段不适合建索引，例如”性别”这种只有两三个值的字段</li>
<li>字符字段只建前缀索引</li>
<li>字符字段最好不要做主键</li>
<li>不用外键，由程序保证约束</li>
<li>尽量不用UNIQUE，由程序保证约束</li>
<li>使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引</li>
</ul>
<h3 id="查询SQL"><a href="#查询SQL" class="headerlink" title="查询SQL"></a>查询SQL</h3><ul>
<li>可通过开启慢查询日志来找出较慢的SQL</li>
<li>不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边</li>
<li>sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库</li>
<li>不用SELECT *</li>
<li>OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内</li>
<li>不用函数和触发器，在应用程序实现</li>
<li>避免%xxx式查询</li>
<li>少用JOIN</li>
<li>使用同类型进行比较，比如用’123’和’123’比，123和123比</li>
<li>尽量避免在WHERE子句中使用 != 或 &lt;&gt; 操作符，否则将引擎放弃使用索引而进行全表扫描</li>
<li>对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5</li>
<li>列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大</li>
</ul>
<h3 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h3><p>目前广泛使用的是MyISAM和InnoDB两种引擎：</p>
<div class="tabs" id="存储引擎"><ul class="nav-tabs"><li class="tab"><a href="#存储引擎-1"><i class="fa fa-reorder"></i>MyISAM</a></li><li class="tab active"><a href="#存储引擎-2"><i class="fa fa-reorder"></i>InnoDB</a></li></ul><div class="tab-content"><div class="tab-pane" id="存储引擎-1"><ul>
<li>MyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是：</li>
<li>不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁</li>
<li>不支持事务</li>
<li>不支持外键</li>
<li>不支持崩溃后的安全恢复</li>
<li>在表有读取查询的同时，支持往表中插入新纪录</li>
<li>支持BLOB和TEXT的前500个字符索引，支持全文索引</li>
<li>支持延迟更新索引，极大提升写入性能</li>
<li>对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用</li>
</ul></div><div class="tab-pane active" id="存储引擎-2"><ul>
<li>InnoDB在MySQL 5.5后成为默认索引，它的特点是：</li>
<li>支持行锁，采用MVCC来支持高并发</li>
<li>支持事务</li>
<li>支持外键</li>
<li>支持崩溃后的安全恢复</li>
<li>不支持全文索引</li>
</ul></div></div></div>
<div class="note primary">
            <p>总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表</p>
          </div>

<h3 id="系统调优参数"><a href="#系统调优参数" class="headerlink" title="系统调优参数"></a>系统调优参数</h3><p>可以使用下面几个工具来做基准测试：</p>
<ul>
<li>sysbench：一个模块化，跨平台以及多线程的性能测试工具</li>
<li>iibench-mysql：基于 Java 的 MySQL/Percona/MariaDB 索引进行插入性能测试工具</li>
<li>tpcc-mysql：Percona开发的TPC-C测试工具</li>
<li>具体的调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数：</li>
<li>back_log：back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。可以从默认的50升至500</li>
<li>wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时</li>
<li>max_user_connection: 最大连接数，默认为0无上限，最好设一个合理上限</li>
<li>thread_concurrency：并发线程数，设为CPU核数的两倍</li>
<li>skip_name_resolve：禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问</li>
<li>key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询show status like ‘key_read%’，保证key_reads / key_read_requests在0.1%以下最好</li>
<li>innodb_buffer_pool_size：缓存数据块和索引块，对InnoDB表性能影响最大。通过查询show status like ‘Innodb_buffer_pool_read%’，保证 (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) / Innodb_buffer_pool_read_requests越高越好</li>
<li>innodb_additional_mem_pool_size：InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小</li>
<li>innodb_log_buffer_size：InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB</li>
<li>query_cache_size：缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。根据命中率(Qcache_hits/(Qcache_hits+Qcache_inserts)*100))进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大.</li>
<li>可以通过命令show status like ‘Qcache_%’查看目前系统Query catch使用大小</li>
<li>read_buffer_size：MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能</li>
<li>sort_buffer_size：MySql执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小</li>
<li>read_rnd_buffer_size：MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。</li>
<li>record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值</li>
<li>thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的</li>
<li>table_cache：类似于thread_cache_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM</li>
</ul>
<h3 id="升级硬件"><a href="#升级硬件" class="headerlink" title="升级硬件"></a>升级硬件</h3><p>Scale up，这个不多说了，根据MySQL是CPU密集型还是I/O密集型，通过提升CPU和内存、使用SSD，都能显著提升MySQL性能</p>
<p>为避免篇幅过长，后续章节请看<a href="/sql-optimize2">下文</a>.</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL技巧,SQL调优,存储引擎——终于全懂了(下)(收藏)</title>
    <url>/db/sql-optimize2/</url>
    <content><![CDATA[<h1 id="数据库调优"><a href="#数据库调优" class="headerlink" title="数据库调优"></a>数据库调优</h1><p>当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化：</p>
<div class="note primary">
            <ul><li>单表优化（字段、索引、SQL优化、存储引擎、系统参数、硬件）</li><li>缓存</li><li>读写分离</li><li>表分区</li><li>分库分表（垂直拆分，水平拆分）</li></ul>
          </div>
<a id="more"></a>
<h2 id="单表优化"><a href="#单表优化" class="headerlink" title="单表优化"></a>单表优化</h2><p><a href="/sql-optimize1">查看 单表优化 详解</a>.</p>
<h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><p>是目前常用的优化，从库读主库写，一般不要采用双主或多主，引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离。</p>
<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存可以发生在这些层次：</p>
<ul>
<li><p>MySQL内部：在系统调优参数介绍了相关设置</p>
</li>
<li><p>数据访问层：比如MyBatis针对SQL语句做缓存，而Hibernate可以精确到单个记录，这里缓存的对象主要是持久化对象Persistence Object</p>
</li>
<li><p>应用服务层：这里可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象Data Transfer Object</p>
</li>
<li><p>Web层：针对web页面做缓存</p>
</li>
<li><p>浏览器客户端：用户端的缓存</p>
</li>
</ul>
<p>可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现，目前主要有两种方式：</p>
<div class="tabs" id="服务缓存实现方式"><ul class="nav-tabs"><li class="tab active"><a href="#服务缓存实现方式-1"><i class="fa fa-reorder"></i>直写式</a></li><li class="tab"><a href="#服务缓存实现方式-2"><i class="fa fa-reorder"></i>回写式</a></li></ul><div class="tab-content"><div class="tab-pane active" id="服务缓存实现方式-1"><p>直写式（Write Through）：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。这也是当前大多数应用缓存框架如Spring Cache的工作方式。这种实现非常简单，同步好，但效率一般。</p></div><div class="tab-pane" id="服务缓存实现方式-2"><p>回写式（Write Back）：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。</p></div></div></div>

<h2 id="表分区"><a href="#表分区" class="headerlink" title="表分区"></a>表分区</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>MySQL在5.1版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码</p>
<p>对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对SQL层来说是一个完全封装底层的黑盒子。MySQL实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-1.webp/w600">

<p>用户的SQL语句是需要针对分区表做优化，SQL条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过EXPLAIN PARTITIONS来查看某条SQL语句会落在那些分区上，从而进行SQL优化，如下5条记录落在两个分区上：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql&gt; explain partitions select count(1) from user_partition where id in (1,2,3,4,5);</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="center">id</th>
<th align="left">select_type</th>
<th align="left">table</th>
<th align="left">partitions</th>
<th align="left">type</th>
<th align="left">possible_keys</th>
<th align="left">key</th>
<th align="left">key_len</th>
<th align="left">ref</th>
<th align="left">rows</th>
<th align="left">Extra</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="left">SIMPLE</td>
<td align="left">user_partition</td>
<td align="left">p1,p4</td>
<td align="left">range</td>
<td align="left">PRIMARY</td>
<td align="left">PRIMARY</td>
<td align="left">8</td>
<td align="left">NULL</td>
<td align="left">5</td>
<td align="left">Using where; Using index</td>
</tr>
</tbody></table>
<h3 id="分区的好处是："><a href="#分区的好处是：" class="headerlink" title="分区的好处是："></a>分区的好处是：</h3><div class="note primary">
            <ul><li>可以让单表存储更多的数据</li><li>分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作</li><li>部分查询能够从查询条件确定只落在少数分区上，速度会很快</li><li>分区表的数据还可以分布在不同的物理设备上，从而搞笑利用多个硬件设备</li><li>可以使用分区表赖避免某些特殊瓶颈，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争</li><li>可以备份和恢复单个分区</li></ul>
          </div>

<h3 id="分区的限制和缺点："><a href="#分区的限制和缺点：" class="headerlink" title="分区的限制和缺点："></a>分区的限制和缺点：</h3><div class="note warning">
            <ul><li>一个表最多只能有1024个分区</li><li>如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来</li><li>分区表无法使用外键约束</li><li>NULL值会使分区过滤无效</li><li>所有分区必须使用相同的存储引擎</li></ul>
          </div>

<h3 id="分区的类型："><a href="#分区的类型：" class="headerlink" title="分区的类型："></a>分区的类型：</h3><div class="tabs" id="partion"><ul class="nav-tabs"><li class="tab active"><a href="#partion-1">RANGE分区</a></li><li class="tab"><a href="#partion-2">LIST分区</a></li><li class="tab"><a href="#partion-3">HASH分区</a></li><li class="tab"><a href="#partion-4">KEY分区</a></li></ul><div class="tab-content"><div class="tab-pane active" id="partion-1"><ul>
<li>RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区</li>
</ul></div><div class="tab-pane" id="partion-2"><ul>
<li>LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择</li>
</ul></div><div class="tab-pane" id="partion-3"><ul>
<li>HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL中有效的、产生非负整数值的任何表达式</li>
</ul></div><div class="tab-pane" id="partion-4"><ul>
<li>KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值</li>
</ul></div></div></div>

<h3 id="分区适合的场景"><a href="#分区适合的场景" class="headerlink" title="分区适合的场景:"></a>分区适合的场景:</h3><p>最适合的场景数据的时间序列性比较强，则可以按时间来分区，如下所示：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> members (</span><br><span class="line"></span><br><span class="line">    firstname <span class="built_in">VARCHAR</span>(<span class="number">25</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line"></span><br><span class="line">    lastname <span class="built_in">VARCHAR</span>(<span class="number">25</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line"></span><br><span class="line">    username <span class="built_in">VARCHAR</span>(<span class="number">16</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line"></span><br><span class="line">    email <span class="built_in">VARCHAR</span>(<span class="number">35</span>),</span><br><span class="line"></span><br><span class="line">    joined <span class="built_in">DATE</span> <span class="keyword">NOT</span> <span class="literal">NULL</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span>( <span class="keyword">YEAR</span>(joined) ) (</span><br><span class="line"></span><br><span class="line">    <span class="keyword">PARTITION</span> p0 <span class="keyword">VALUES</span> <span class="keyword">LESS</span> <span class="keyword">THAN</span> (<span class="number">1960</span>),</span><br><span class="line"></span><br><span class="line">    <span class="keyword">PARTITION</span> p1 <span class="keyword">VALUES</span> <span class="keyword">LESS</span> <span class="keyword">THAN</span> (<span class="number">1970</span>),</span><br><span class="line"></span><br><span class="line">    <span class="keyword">PARTITION</span> p2 <span class="keyword">VALUES</span> <span class="keyword">LESS</span> <span class="keyword">THAN</span> (<span class="number">1980</span>),</span><br><span class="line"></span><br><span class="line">    <span class="keyword">PARTITION</span> p3 <span class="keyword">VALUES</span> <span class="keyword">LESS</span> <span class="keyword">THAN</span> (<span class="number">1990</span>),</span><br><span class="line"></span><br><span class="line">    <span class="keyword">PARTITION</span> p4 <span class="keyword">VALUES</span> <span class="keyword">LESS</span> <span class="keyword">THAN</span> MAXVALUE</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>查询时加上时间范围条件效率会非常高，同时对于不需要的历史数据能很容的批量删除。</p>
<p>如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存。</p>
<blockquote>
<p>另外MySQL有一种早期的简单的分区实现 – 合并表（merge table），限制较多且缺乏优化，不建议使用，应该用新的分区机制来替代。</p>
</blockquote>
<h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><div class="tabs" id="sub-db-sub-table"><ul class="nav-tabs"><li class="tab active"><a href="#sub-db-sub-table-1"><i class="fa fa-reorder"></i>垂直拆分</a></li><li class="tab"><a href="#sub-db-sub-table-2"><i class="fa fa-reorder"></i>水平拆分</a></li></ul><div class="tab-content"><div class="tab-pane active" id="sub-db-sub-table-1"><h3 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h3><p>垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联</p>
<p>比如原始的用户表是：<br><img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-2.webp/w600"></p>
<p>垂直拆分后是：<br><img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-3.webp/w600"></p>
<p>垂直拆分的优点是：</p>
<ul>
<li>可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少I/O次数(每次查询时读取的Block 就少)</li>
<li>可以达到最大化利用Cache的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起</li>
<li>数据维护简单</li>
</ul>
<p>缺点是：</p>
<ul>
<li>主键出现冗余，需要管理冗余列</li>
<li>会引起表连接JOIN操作（增加CPU开销）可以通过在业务服务器上进行join来减少数据库压力</li>
<li>依然存在单表数据量过大的问题（需要水平拆分）</li>
<li>事务处理复杂</li>
</ul></div><div class="tab-pane" id="sub-db-sub-table-2"><h3 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h3><p>概述<br>水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的MySQL表或库，达到分布式的效果，能够支持非常大的数据量。前面的表分区本质上也是一种特殊的库内分表。</p>
<p>库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻MySQL服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的IO、CPU、网络，这个就要通过分库来解决</p>
<p>前面垂直拆分的用户表如果进行水平拆分，结果是：<br><img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-4.webp/w600"></p>
<p>实际情况中往往会是垂直拆分和水平拆分的结合，即将Users_A_M和Users_N_Z再拆成Users和UserExtras，这样一共四张表</p>
<p>水平拆分的优点是:</p>
<ul>
<li>不存在单库大数据和高并发的性能瓶颈</li>
<li>应用端改造较少</li>
<li>提高了系统的稳定性和负载能力</li>
</ul>
<p>缺点是：</p>
<ul>
<li>分片事务一致性难以解决</li>
<li>跨节点Join性能差，逻辑复杂</li>
<li>数据多次扩展难度跟维护量极大</li>
</ul></div></div></div>

<h3 id="分片原则"><a href="#分片原则" class="headerlink" title="分片原则"></a>分片原则</h3><ul>
<li>能不分就不分，参考单表优化</li>
<li>分片数量尽量少，分片尽量均匀分布在多个数据结点上，因为一个查询SQL跨分片越多，则总体性能越差，虽然要好于所有数据在一个分片的结果，只在必要的时候进行扩容，增加分片数量</li>
<li>分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题，最近的分片策略为范围分片，枚举分片，一致性Hash分片，这几种分片都有利于扩容</li>
<li>尽量不要在一个事务中的SQL跨越多个分片，分布式事务一直是个不好处理的问题</li>
<li>查询条件尽量优化，尽量避免Select * 的方式，大量数据结果集下，会消耗大量带宽和CPU资源，查询尽量避免返回大量结果集，并且尽量为频繁使用的查询语句建立索引。</li>
<li>通过数据冗余和表分区赖降低跨库Join的可能</li>
</ul>
<div class="note primary">
            <p>这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等，则他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤。<br>比较好的方案是:</p><ul><li>当前活跃的数据，采用跨度比较短的时间段进行分片，</li><li>历史性的数据，则采用比较长的跨度存储。</li></ul>
          </div>
<p>总体上来说，分片的选择是取决于最频繁的查询SQL的条件，因为不带任何Where语句的查询SQL，会遍历所有的分片，性能相对最差，因此这种SQL越多，对系统的影响越大，所以我们要尽量避免这种SQL的产生。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>由于水平拆分牵涉的逻辑比较复杂，当前也有了不少比较成熟的解决方案。这些方案分为两大类：客户端架构和代理架构。</p>
<h4 id="客户端架构"><a href="#客户端架构" class="headerlink" title="客户端架构"></a>客户端架构</h4><p>通过修改数据访问层，如JDBC、Data Source、MyBatis，通过配置来管理多个数据源，直连数据库，并在模块内完成数据的分片整合，一般以Jar包的方式呈现</p>
<p>这是一个客户端架构的例子：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-5.webp/w600">

<p>可以看到分片的实现是和应用服务器在一起的，通过修改Spring JDBC层来实现</p>
<p>客户端架构优缺点:</p>
<div class="tabs" id="client_is_good"><ul class="nav-tabs"><li class="tab active"><a href="#client_is_good-1"><i class="fa fa-reorder"></i>优点</a></li><li class="tab"><a href="#client_is_good-2"><i class="fa fa-reorder"></i>缺点</a></li></ul><div class="tab-content"><div class="tab-pane active" id="client_is_good-1"><p>客户端架构的优点是：</p>
<ul>
<li>应用直连数据库，降低外围系统依赖所带来的宕机风险</li>
<li>集成成本低，无需额外运维的组件</li>
</ul></div><div class="tab-pane" id="client_is_good-2"><p>客户端架构缺点是：</p>
<ul>
<li>限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心</li>
<li>将分片逻辑的压力放在应用服务器上，造成额外风险</li>
</ul></div></div></div>

<h4 id="代理架构"><a href="#代理架构" class="headerlink" title="代理架构"></a>代理架构</h4><p>通过独立的中间件来统一管理所有数据源和数据分片整合，后端数据库集群对前端应用程序透明，需要独立部署和运维代理组件。</p>
<p>这是一个代理架构的例子：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-6.webp/w600">

<p>代理组件为了分流和防止单点，一般以集群形式存在，同时可能需要Zookeeper之类的服务组件来管理</p>
<p>代理架构的优缺点：</p>
<div class="tabs" id="proxy_is_good"><ul class="nav-tabs"><li class="tab active"><a href="#proxy_is_good-1"><i class="fa fa-reorder"></i>优点</a></li><li class="tab"><a href="#proxy_is_good-2"><i class="fa fa-reorder"></i>缺点</a></li></ul><div class="tab-content"><div class="tab-pane active" id="proxy_is_good-1"><p>优点是：</p>
<ul>
<li>能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强</li>
<li>对于应用服务器透明且没有增加任何额外负载</li>
</ul></div><div class="tab-pane" id="proxy_is_good-2"><p>缺点是：</p>
<ul>
<li>需部署和运维独立的代理中间件，成本高</li>
<li>应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险</li>
</ul></div></div></div>

<h4 id="各方案比较"><a href="#各方案比较" class="headerlink" title="各方案比较"></a>各方案比较</h4><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-7.webp/w600"></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-8.webp/w600"></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img data-src="http://f.ngall-in.com/alan87/static/images/db/sql-optimize/sql-optimize-9.webp/w600"></div></div></div></div>

<p>如此多的方案，如何进行选择？可以按以下思路来考虑：</p>
<div class="note primary">
            <ul><li>确定是使用代理架构还是客户端架构。中小型规模或是比较简单的场景倾向于选择客户端架构，复杂场景或大规模系统倾向选择代理架构</li><li>具体功能是否满足，比如需要跨节点ORDER BY，那么支持该功能的优先考虑</li><li>不考虑一年内没有更新的产品，说明开发停滞，甚至无人维护和技术支持</li><li>最好按大公司-&gt;社区-&gt;小公司-&gt;个人这样的出品方顺序来选择</li><li>选择口碑较好的，比如github星数、使用者数量质量和使用者反馈</li><li>开源的优先，往往项目有特殊需求可能需要改动源代码</li></ul>
          </div>

<p>按照上述思路，推荐以下选择：</p>
<ul>
<li><p>客户端架构：ShardingJDBC</p>
</li>
<li><p>代理架构：MyCat或者Atlas</p>
</li>
</ul>
<h3 id="兼容MySQL且可水平扩展的数据库"><a href="#兼容MySQL且可水平扩展的数据库" class="headerlink" title="兼容MySQL且可水平扩展的数据库"></a>兼容MySQL且可水平扩展的数据库</h3><p>目前也有一些开源数据库兼容MySQL协议，如：</p>
<ul>
<li>TiDB</li>
<li>Cubrid</li>
</ul>
<p>但其工业品质和MySQL尚有差距，且需要较大的运维投入，如果想将原始的MySQL迁移到可水平扩展的新数据库中，可以考虑一些云数据库：</p>
<ul>
<li>阿里云OceanBase</li>
<li>腾讯云DCDB</li>
</ul>
<h1 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h1><p>在MySQL上做Sharding是一种戴着镣铐的跳舞，事实上很多大表本身对MySQL这种RDBMS的需求并不大，并不要求ACID，可以考虑将这些表迁移到NoSQL，彻底解决水平扩展问题，例如：</p>
<ul>
<li>日志类、监控类、统计类数据</li>
<li>非结构化或弱结构化数据</li>
<li>对事务要求不强，且无太多关联操作的数据</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库事务</title>
    <url>/db/transaction/</url>
    <content><![CDATA[<h3 id="事务特性"><a href="#事务特性" class="headerlink" title="事务特性"></a>事务特性</h3><p>原子性、一致性、隔离性、持久性，这四个属性通常称为ACID特性。</p>
<a id="more"></a>
<ul>
<li>原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。</li>
<li>一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。</li>
<li>隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。</li>
<li>持久性（durability）。持久性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。</li>
</ul>
<h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><ul>
<li><a href="/distributed-transaction/">分布式事务</a></li>
<li><a href="https://mp.weixin.qq.com/s/ja0VRPkfHL9dtOP_PxwxKw" target="_blank" rel="noopener">分布式系统常见的事务处理机制</a></li>
<li><a href="https://mp.weixin.qq.com/s/RKwvfKXIHrrkuCqOGZ4CPw" target="_blank" rel="noopener">微服务架构下处理分布式事务的典型方案</a></li>
<li><a href="https://mp.weixin.qq.com/s/kzmTKKH-t6tpJ97fa6TYPg" target="_blank" rel="noopener">解决分布式系统事务一致性的几种方案对比</a></li>
<li><a href="https://mp.weixin.qq.com/s/FvB-hOBT13SMfZko5iagAg" target="_blank" rel="noopener">多库多事务降低数据不一致概率</a></li>
<li><a href="https://mp.weixin.qq.com/s/abjDjGGz5RUoCNCdnoxOjQ" target="_blank" rel="noopener">蚂蚁技术专家：一篇文章带你学习分布式事务</a></li>
</ul>
<h4 id="开源框架"><a href="#开源框架" class="headerlink" title="开源框架"></a>开源框架</h4><ul>
<li><a href="https://github.com/changmingxie/tcc-transaction" target="_blank" rel="noopener">tcc-transaction是TCC型事务java实现</a></li>
<li><a href="https://mp.weixin.qq.com/s/K0PCZmdXyJYwyuEPW8bvFg" target="_blank" rel="noopener">TCC分布式事务的实现原理</a></li>
<li><a href="https://mp.weixin.qq.com/s/WRH8C3MYSFghFopBKmshJw" target="_blank" rel="noopener">分布式事务 TCC-Transaction 源码分析 —— Dubbo 支持</a></li>
<li><a href="https://mp.weixin.qq.com/s/vPr4yMUzurtVkW3BGXit5g" target="_blank" rel="noopener">分布式事务 TCC-Transaction 源码分析 —— 项目实战</a></li>
<li><a href="https://mp.weixin.qq.com/s/bUtu2nTs0bybnTvk-iLt6Q" target="_blank" rel="noopener">GTS来了！阿里微服务架构下的分布式事务解决方案</a></li>
<li><a href="https://yq.aliyun.com/articles/39054" target="_blank" rel="noopener">Atomikos</a></li>
<li><a href="https://mp.weixin.qq.com/s/BWrGw5dkRfR7gws2XY8vHQ" target="_blank" rel="noopener">微服务架构下分布式事务解决方案 —— 阿里GTS</a></li>
<li><a href="https://github.com/liuyangming/ByteJTA" target="_blank" rel="noopener">ByteJTA是一个兼容JTA规范的基于XA/2PC的分布式事务管理器</a></li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>分库分表</title>
    <url>/db/sub-db-sub-table/</url>
    <content><![CDATA[<h2 id="分库分表详解"><a href="#分库分表详解" class="headerlink" title="分库分表详解"></a>分库分表详解</h2><p><a href="/sql-optimize2">点击查看详解</a></p>
<h2 id="分库分表注意事项："><a href="#分库分表注意事项：" class="headerlink" title="分库分表注意事项："></a>分库分表注意事项：</h2><ul>
<li>表操作尽量搞成单表形式，如果涉及join操作或表关联，需要在业务层做处理，而非sql解决</li>
<li>分表键字段确定</li>
</ul>
<a id="more"></a>
<ul>
<li>所有的sql语句都要包含分表字段</li>
<li>如果类似于交易订单场景，需要从买家、卖家两个维度，可以分为读库、写库，如何保证两个库之间数据同步</li>
<li>全局主键id如何获取</li>
</ul>
<h2 id="一些成熟的开源框架："><a href="#一些成熟的开源框架：" class="headerlink" title="一些成熟的开源框架："></a>一些成熟的开源框架：</h2><ul>
<li>Cobar</li>
<li>MyCat</li>
<li>Sharding-Sphere</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Ingress对外暴露端口</title>
    <url>/k8s/Ingress%E5%AF%B9%E5%A4%96%E6%9A%B4%E9%9C%B2%E7%AB%AF%E5%8F%A3/</url>
    <content><![CDATA[<h1 id="http-https端口"><a href="#http-https端口" class="headerlink" title="http,https端口"></a>http,https端口</h1><a id="more"></a>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">"nginx"</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">"HTTPS"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks.hongda.com</span></span><br><span class="line">    <span class="attr">secretName:</span> <span class="string">hongda-com-tls-secret</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">ks.hongda.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">443</span></span><br></pre></td></tr></table></figure>
<p>执行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f ingress-kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>
<h1 id="具体说明"><a href="#具体说明" class="headerlink" title="具体说明"></a>具体说明</h1><ul>
<li>kubernetes.io/ingress.class: “nginx”：Inginx Ingress Controller 根据该注解自动发现 Ingress；</li>
<li>nginx.ingress.kubernetes.io/backend-protocol: Controller 向后端 Service 转发时使用 HTTPS 协议</li>
<li>secretName: kube-dasboard-ssl：https 证书 Secret；</li>
<li>host: ks.hongda.com：对外访问的域名；</li>
<li>serviceName: kubernetes-dashboard：集群对外暴露的 Service 名称；</li>
<li>servicePort: 443：service 监听的端口；<br>注意：创建的 Ingress 必须要和对外暴露的 Service 在同一命名空间下！</li>
</ul>
<h1 id="ConfigMap暴露TCP端口"><a href="#ConfigMap暴露TCP端口" class="headerlink" title="ConfigMap暴露TCP端口"></a>ConfigMap暴露TCP端口</h1><p>Ingress 不支持TCP 和 UDP 服务，可以通过 Ingress controller 来实现</p>
<p>默认的yaml中已经设置：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">   <span class="attr">hostNetwork:</span> <span class="literal">true</span> <span class="comment"># &lt;--</span></span><br><span class="line">   <span class="attr">containers:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">/nginx-ingress-controller</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--configmap=$(POD_NAMESPACE)/nginx-configuration</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--tcp-services-configmap=$(POD_NAMESPACE)/tcp-services</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--udp-services-configmap=$(POD_NAMESPACE)/udp-services</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--publish-service=$(POD_NAMESPACE)/ingress-nginx</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--annotations-prefix=nginx.ingress.kubernetes.io</span></span><br><span class="line">     <span class="attr">env:</span></span><br></pre></td></tr></table></figure>
<p>通过 tcp-services-configmap.yaml 设置映射tcp， 通过 udp-services-configmap.yaml 映射udp</p>
<ul>
<li>tcp-services-configmap.yaml<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tcp-services</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">2181:</span> <span class="string">"kafka/kafka-zookeeper:2181"</span></span><br><span class="line">  <span class="attr">9092:</span> <span class="string">"kafka/kafka:9092"</span></span><br></pre></td></tr></table></figure></li>
<li>udp-services-configmap.yaml<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">udp-services</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">53:</span> <span class="string">"kube-system/kube-dns:53"</span></span><br></pre></td></tr></table></figure>
<h1 id="Ingress服务公开端口"><a href="#Ingress服务公开端口" class="headerlink" title="Ingress服务公开端口"></a>Ingress服务公开端口</h1>更新Ingress安装文件<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">proxied-tcp-9000</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">9000</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9000</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">ingress-nginx</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>更新：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">helm upgrade nginx-ingress stable&#x2F;nginx-ingress \</span><br><span class="line">-f ingress-nginx.yaml</span><br></pre></td></tr></table></figure>
<p>查看：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@master home]<span class="comment"># netstat -ano |grep 2181</span></span><br><span class="line">tcp        0      0 0.0.0.0:2181            0.0.0.0:*               LISTEN      off (0.00/0/0)</span><br><span class="line">tcp6       0      0 :::2181                 :::*                    LISTEN      off (0.00/0/0)</span><br></pre></td></tr></table></figure>
<p>这样暴露以后就可以直接调用zk,连接地址：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zk.hongda.com:2181</span><br><span class="line">18.16.202.163:2181</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>最好用的开源分布式事务解决方案之一</title>
    <url>/db/%E6%9C%80%E5%A5%BD%E7%94%A8%E7%9A%84%E5%BC%80%E6%BA%90%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E4%B9%8B%E4%B8%80/</url>
    <content><![CDATA[<h1 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h1><p>相比于数据分片方案的逐渐成熟，集性能、透明化、自动化、强一致、并能适用于各种应用场景于一体的分布式事务解决方案则显得凤毛麟角。基于两、三阶段提交的分布式事务的性能瓶颈以及柔性事务的业务改造问题，使得分布式事务至今依然是令架构师们头疼的问题。</p>
<p>Apache ShardingSphere（Incubating）不失时机的在2019年初，提供了一个刚柔并济的一体化分布式事务解决方案。如果您的应用系统正在受到这方面的困扰，不妨倒上一杯咖啡，花十分钟阅读此文，说不定会有些收获呢？</p>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>数据库事务需要满足ACID（原子性、一致性、隔离性、持久性）4个特性。</p>
<ul>
<li><p>原子性（Atomicity）指事务作为整体来执行，要么全部执行，要么全不执行。</p>
</li>
<li><p>一致性（Consistency）指事务应确保数据从一个一致的状态转变为另一个一致的状态。</p>
</li>
<li><p>隔离性（Isolation）指多个事务并发执行时，一个事务的执行不应影响其他事务的执行。</p>
</li>
<li><p>持久性（Durability）指已提交的事务修改数据会被持久保存。</p>
</li>
</ul>
<p>在单一数据节点中，事务仅限于对单一数据库资源的访问控制，称之为本地事务。几乎所有的成熟的关系型数据库都提供了对本地事务的原生支持。 但是在基于微服务的分布式应用环境下，越来越多的应用场景要求对多个服务的访问及其相对应的多个数据库资源能纳入到同一个事务当中，分布式事务应运而生。</p>
<p>关系型数据库虽然对本地事务提供了完美的ACID原生支持。 但在分布式的场景下，它却成为系统性能的桎梏。如何让数据库在分布式场景下满足ACID的特性或找寻相应的替代方案，是分布式事务的重点工作。</p>
<h1 id="★本地事务★"><a href="#★本地事务★" class="headerlink" title="★本地事务★"></a>★本地事务★</h1><p>在不开启任何分布式事务管理器的前提下，让每个数据节点各自管理自己的事务。 它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 本地事务在性能方面无任何损耗，但在强一致性以及最终一致性方面则力不从心。</p>
<h1 id="★两阶段提交★"><a href="#★两阶段提交★" class="headerlink" title="★两阶段提交★"></a>★两阶段提交★</h1><p>XA协议最早的分布式事务模型是由X/Open国际联盟提出的X/Open Distributed Transaction Processing（DTP）模型，简称XA协议。</p>
<p>基于XA协议实现的分布式事务对业务侵入很小。 它最大的优势就是对使用方透明，用户可以像使用本地事务一样使用基于XA协议的分布式事务。 XA协议能够严格保障事务ACID特性。</p>
<p>严格保障事务ACID特性是一把双刃剑。 事务执行在过程中需要将所需资源全部锁定，它更加适用于执行时间确定的短事务。 对于长事务来说，整个事务进行期间对数据的独占，将导致对热点数据依赖的业务系统并发性能衰退明显。 因此，在高并发的性能至上场景中，基于XA协议两阶段提交类型的分布式事务并不是最佳选择。</p>
<h1 id="★柔性事务★"><a href="#★柔性事务★" class="headerlink" title="★柔性事务★"></a>★柔性事务★</h1><p>如果将实现了ACID的事务要素的事务称为刚性事务的话，那么基于BASE事务要素的事务则称为柔性事务。 BASE是基本可用、柔性状态和最终一致性这3个要素的缩写。</p>
<ul>
<li><p>基本可用（Basically Available）保证分布式事务参与方不一定同时在线。</p>
</li>
<li><p>柔性状态（Soft state）则允许系统状态更新有一定的延时，这个延时对客户来说不一定能够察觉。</p>
</li>
<li><p>最终一致性（Eventually consistent）通常是通过消息传递的方式保证系统的最终一致性。</p>
</li>
</ul>
<p>在ACID事务中对一致性和隔离性的要求很高，在事务执行过程中，必须将所有的资源占用。 柔性事务的理念则是通过业务逻辑将互斥锁操作从资源层面上移至业务层面。通过放宽对强一致性和隔离性的要求，只要求当整个事务最终结束的时候，数据是一致的。而在事务执行期间，任何读取操作得到的数据都有可能被改变。这种弱一致性的设计可以用来换取系统吞吐量的提升。</p>
<ul>
<li><p>Saga是典型的柔性事务管理器。Sagas这个概念来源于三十多年前的一篇数据库论文[<a href="http://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf]" target="_blank" rel="noopener">http://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf]</a> ，一个Saga事务是一个有多个短时事务组成的长时的事务。 在分布式事务场景下，我们把一个Saga分布式事务看做是一个由多个本地事务组成的事务，每个本地事务都有一个与之对应的补偿事务。在Saga事务的执行过程中，如果某一步执行出现异常，Saga事务会被终止，同时会调用对应的补偿事务完成相关的恢复操作，这样保证Saga相关的本地事务要么都是执行成功，要么通过补偿恢复成为事务执行之前的状态。</p>
</li>
<li><p>TCC（Try-Cancel/Confirm实现)是另一种柔性事务的协调实现。TCC借助两阶段提交协议提供了一种比较完美的恢复方式。在TCC方式下，cancel补偿显然是在第二阶段需要执行业务逻辑来取消第一阶段产生的后果。Try是在第一阶段执行相关的业务操作，完成相关业务资源的占用，例如预先分配票务资源，或者检查并刷新用户账户信用额度。 在取消阶段释放相关的业务资源，例如释放预先分配的票务资源或者恢复之前占用的用户信用额度。 那我们为什么还要加入确认操作呢？这需要从业务资源的使用生命周期来入手。在try过程中，我们只是占用的业务资源，相关的执行操作只是出于待定状态，只有在确认操作执行完毕之后，业务资源才能真正被确认。</p>
</li>
</ul>
<p>基于ACID的强一致性事务和基于BASE的最终一致性事务都不是银弹，只有在最适合的场景中才能发挥它们的最大长处。可通过下表详细对比它们之间的区别，以帮助开发者进行技术选型。</p>
<table>
<thead>
<tr>
<th align="left">/</th>
<th align="left">本地事务</th>
<th align="left">两阶段提交</th>
<th align="left">柔性事务</th>
</tr>
</thead>
<tbody><tr>
<td align="left">业务改造</td>
<td align="left">无</td>
<td align="left">无</td>
<td align="left">实现相关接口</td>
</tr>
<tr>
<td align="left">一致性</td>
<td align="left">不支持</td>
<td align="left">支持</td>
<td align="left">最终一致</td>
</tr>
<tr>
<td align="left">隔离性</td>
<td align="left">不支持</td>
<td align="left">支持</td>
<td align="left">业务方保证</td>
</tr>
<tr>
<td align="left">并发性能</td>
<td align="left">无影响</td>
<td align="left">严重衰退</td>
<td align="left">略微衰退</td>
</tr>
<tr>
<td align="left">适合场景</td>
<td align="left">业务方处理不一致</td>
<td align="left">短事务 &amp; 低并发</td>
<td align="left">长事务 &amp; 高并发</td>
</tr>
</tbody></table>
<h1 id="★挑战★"><a href="#★挑战★" class="headerlink" title="★挑战★"></a>★挑战★</h1><p>由于应用的场景不同，需要开发者能够合理的在性能与功能之间权衡各种分布式事务。</p>
<p>两阶段提交与柔性事务的API和功能并不完全相同，在它们之间并不能做到自由的透明切换。在开发决策阶段，就不得不在两阶段提交的事务和柔性事务之间抉择，使得设计和开发成本被大幅增加。</p>
<p>基于XA的两阶段提交事务使用相对简单，但是无法很好的应对互联网的高并发或复杂系统的长事务场景；柔性事务则需要开发者对应用进行改造，接入成本非常高，并且需要开发者自行实现资源占用和反向补偿。</p>
<h1 id="ShardingSphere的分布式事务"><a href="#ShardingSphere的分布式事务" class="headerlink" title="ShardingSphere的分布式事务"></a>ShardingSphere的分布式事务</h1><p>整合现有的成熟事务方案，为本地事务、两阶段提交和柔性事务提供统一的分布式事务接口，并弥补当前方案的不足，提供一站式的分布式事务解决方案是Apache ShardingSphere（Incubating）分布式事务模块的主要设计目标。该模块的名称是sharding-transaction。可以用刚柔并济、自动化和透明化这3个关键词来概括sharding-transaction模块的设计理念和功能呈现。</p>
<ol>
<li><p>刚柔并济<br>同时提供基于XA的两阶段提交事务与基于Saga的柔性事务解决方案，并且能够一起配合使用。</p>
</li>
<li><p>自动化<br>XA事务和Saga事务都通过自动化的方式完成，使用方无感知。XA事务无需使用XADataSource接口以及JTA事务管理器；Saga事务也无需用户自行实现补偿接口。</p>
</li>
<li><p>透明化<br>在Apache ShardingSphere（Incubating）的两个接入端——Sharding-JDBC和Sharding-Proxy中，分别提供了面向本地事务接口的封装。使用方完全可以将被ShardingSphere管理的水平分片的多个数据源当成一个数据库使用，通过本地事务API即可实现完全的分布式事务的能力。用户可以透明地在应用中任意切换事务类型。</p>
</li>
</ol>
<div class="note primary">
            <p>sharding-transaction模块由sharding-transaction-core，sharding-transaction-2pc和sharding-transaction-base这3个子模块组成。</p>
          </div>

<ol>
<li><p>sharding-transaction-core: 提供了面向使用者的API与面向开发者的SPI。</p>
</li>
<li><p>sharding-transaction-2pc:<br>两阶段提交事务父模块。目前只有sharding-transaction-xa模块，提供了XA协议的支持。未来会引入更多的基于两阶段提交的事务类型，如：percolator，参见：<br>[<a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf]。" target="_blank" rel="noopener">https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf]。</a></p>
</li>
<li><p>sharding-transaction-base:<br>柔性事务父模块。目前只有sharding-transaction-saga模块，采用Apache ServiceComb Saga Actuator提供的Saga执行器提供柔性事务支持，并在其基础之上提供了反向SQL和快照的能力，并由此实现自动逆向补偿功能。</p>
</li>
</ol>
<p>下面将对ShardingSphere的XA和Saga事务模块的功能亮点进行说明。</p>
<h1 id="★XA事务——三大XA事务管理器共护航★"><a href="#★XA事务——三大XA事务管理器共护航★" class="headerlink" title="★XA事务——三大XA事务管理器共护航★"></a>★XA事务——三大XA事务管理器共护航★</h1><p>成熟的XA事务管理器非常多，Apache ShardingSphere（Incubating）并未选择重新造轮子，而是寄望于打造一个生态，将合适的轮子有机地整合在一起，提供成熟稳定的分布式事务处理能力。它的主要功能如下：</p>
<ol>
<li>复用成熟引擎，自动切换底层实现<br>Sharding-transaction-xa模块进一步定义了面向XA事务管理器开发者的SPI，开发者仅需实现SPI定义的接口，即可自动加入至Apache ShardingSphere（Incubating）生态，作为其XA事务管理器。</li>
</ol>
<p>Apache ShardingSphere（Incubating）官方目前实现了基于Atomikos和Bitronix的SPI，并且邀请了Radhat JBoss的XA事务引擎Narayana [<a href="https://github.com/jbosstm/narayana]" target="_blank" rel="noopener">https://github.com/jbosstm/narayana]</a> 开发团队实现了JBoss的SPI。用户可以自行的在Atomikos，Bitronix和Narayana间选择自己喜欢的XA事务管理器。</p>
<p>受限于Apache基金会项目License的原因，Apache ShardingSphere（Incubating）将采用Apache协议的Atomikos作为其默认实现，关于基于LGPL协议的Bitronix和基于LGPL协议的Narayana，用户可以自行引用相应jar包至项目的classpath即可。</p>
<p>如果这3个XA事务管理器仍未满足用户需求，开发者则可通过扩展SPI来实现定制化的XA事务管理器。</p>
<ol start="2">
<li>数据源透明化自动接入</li>
</ol>
<p>Apache ShardingSphere（Incubating）能够自动将XADataSource作为数据库驱动的数据源接入XA事务管理器。而针对于使用DataSource作为数据库驱动的应用，用户也无需改变其编码以及配置，Apache ShardingSphere（Incubating）通过自动适配的方式，在中间件内部将其转化为支持XA协议的XADataSource和XAConnection，并将其作为XA资源注册到底层的XA事务管理器中。</p>
<p>XA模块的架构图如下：<br><img data-src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/0UoCt9tgpnlcNyImvqD1MEdvsfELO68ibgu5eCuDPevbxtof6xcUnAhQnFzA7BpjV7BEYiasXv1EoV4rpsPIgzxA/640?wx_fmt=png" alt=""></p>
<h1 id="★Saga事务—跨越柔性事务限制，实现自动补偿★"><a href="#★Saga事务—跨越柔性事务限制，实现自动补偿★" class="headerlink" title="★Saga事务—跨越柔性事务限制，实现自动补偿★"></a>★Saga事务—跨越柔性事务限制，实现自动补偿★</h1><p>在柔性事务中，每一次对数据库的更新操作都将数据真正的提交至数据库，以达到高并发系统中最佳资源释放的效果。当数据出现问题需要回滚时，通过柔性事务管理器保持数据的最终一致性以及隔离行为。Apache ShardingSphere（Incubating）采用Apache ServiceComb Saga Actuator [<a href="https://github.com/apache/servicecomb-saga-actuator]" target="_blank" rel="noopener">https://github.com/apache/servicecomb-saga-actuator]</a> 作为Saga事务管理器，它的主要功能如下：</p>
<ol>
<li>自动反向补偿</li>
</ol>
<p>Saga定义了一个事务中的每个子事务都有一个与之对应的反向补偿操作。由Saga事务管理器根据程序执行结果生成一张有向无环图，并在需要执行回滚操作时，根据该图依次按照相反的顺序调用反向补偿操作。Saga事务管理器只用于控制何时重试，合适补偿，并不负责补偿的内容，补偿的具体操作需要由开发者自行提供。</p>
<p>另一个柔性事务管理器TCC与Saga理念相似，均需要由使用方开发者提供补偿操作。除了补偿，TCC还提供了资源占用的能力，但也需要由使用方开发者提供资源占用操作。虽然功能上强于Saga，但TCC的使用成本较之Saga也更高。</p>
<p>由使用方开发者提供资源占用和补偿操作，这就使得柔性事务的解决方案始终难于大规模的在业务系统中落地。并且由于业务系统的介入，使得柔性事务框架的使用范畴始终定位于服务而非数据库，数据库能够直接使用的成熟的柔性事务管理器目前还不多见。</p>
<p>Apache ShardingSphere（Incubating）采用反向SQL技术，将对数据库进行更新操作的SQL自动生成数据快照以及反向SQL，并交由Apache ServiceComb Saga Actuator执行，使用方则无需再关注如何实现补偿方法，将柔性事务管理器的应用范畴成功的定位回了事务的本源——数据库层面。</p>
<p>对于能够处理复杂查询语句的Apache ShardingSphere（Incubating）SQL解析引擎来说，插入/更新/删除等语句解析难度则要小很多；ShardingSphere是通过拦截用户执行的SQL进行数据分片的，所有的SQL都能够被其直接管控。因此将反向SQL和补偿能力与Apache ServiceComb Saga Actuator相结合，达到了自动化柔性事务的能力，是数据分片和柔性事务结合的典范。</p>
<p>Saga模块的架构图如下：<br><img data-src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/0UoCt9tgpnlcNyImvqD1MEdvsfELO68ibgxOZLT9kXJibALEF2MqL6GcEeM8rgqZrD68bBQrdlAglOpH1aNk3Nsw/640?wx_fmt=png" alt=""></p>
<h1 id="★接入端—面向原生事务接口的分布式事务★"><a href="#★接入端—面向原生事务接口的分布式事务★" class="headerlink" title="★接入端—面向原生事务接口的分布式事务★"></a>★接入端—面向原生事务接口的分布式事务★</h1><p>Apache ShardingSphere（Incubating）的目标是像使用一个数据库一样使用分片后的多数据库，在事务模块，这个目标依然适用。无论被ShardingSphere所管理的数据库如何分片，面向开发者的逻辑数据库始终只有一个。因此，ShardingSphere的事务接口依然是原生的本地事务接口，即JDBC的java.sql.Connection的setAutoCommit, commit和rollback方法；以及面向数据库事务管理器的begin, commit和rollback语句。在用户调用原生本地事务接口的同时，ShardingSphere则通过sharding-transaction模块保证后端分片数据库的分布式事务。</p>
<p>由于原生的事务接口并不支持事务类型，因此ShardingSphere提供了3种方式供使用者切换事务类型。</p>
<ol>
<li><p>通过SCTL（sharding-ctl，即ShardingSphere提供的数据库管理命令）切换当前事务类型。以SQL执行的方式输入即可，适用于Sharding-JDBC和Sharding-Proxy。例如：SCTL:SET TRANSACTION_TYPE=BASE</p>
</li>
<li><p>通过Threadlocal切换当前事务类型，适用于Sharding-JDBC。例如：TransactionTypeHolder.set (TransactionType.XA)</p>
</li>
<li><p>通过元注解，并与Spring配合使用切换当前事务类型，适用于Sharding-JDBC和Sharding-Proxy。例如：@ShardingTransactionType (TransactionType.BASE)</p>
</li>
</ol>
<h1 id="线路规划"><a href="#线路规划" class="headerlink" title="线路规划"></a>线路规划</h1><p>分布式事务模块在github的开发分支 [<a href="https://github.com/apache/incubator-shardingsphere]" target="_blank" rel="noopener">https://github.com/apache/incubator-shardingsphere]</a> 已经基本可用，将随着4.0.0.M1的版本发布，这也将是ShardingSphere进入Apache基金会孵化器之后的第一个发布版本。分布式事务是数据分片以及微服务架构的重要组成部分，也是Apache ShardingSphere（Incubating）的关注重心，发布之后仍将继续完善，线路规划如下。</p>
<h1 id="★事务隔离引擎★"><a href="#★事务隔离引擎★" class="headerlink" title="★事务隔离引擎★"></a>★事务隔离引擎★</h1><p>在SQL反向引擎稳定之后，柔性事务的重点将放在打造事务隔离之上。由于事务的隔离性并非Saga所规划的范畴，因此Apache ShardingSphere（Incubating）会在Saga之外将其完善，与SQL反向引擎一起作为整个柔性事务的组成部分。</p>
<p>Apache ShardingSphere（Incubating）将通过乐观锁、悲观锁、无隔离等几种策略，做到读已提交、读未提交、可重复读以及序列化等隔离级别的一一支持。并通过多版本快照进一步提升系统的并发度。</p>
<h1 id="★对外XA事务接口★"><a href="#★对外XA事务接口★" class="headerlink" title="★对外XA事务接口★"></a>★对外XA事务接口★</h1><p>Apache ShardingSphere（Incubating）的两个接入端Sharding-JDBC和Sharding-Proxy在支持自身的内部事务问题之后，将提供融入与其他数据源一起作为被JTA等分布式事务管理器管理的能力。</p>
<p>实现对外XA事务接口之后，Sharding-JDBC的DataSource将实现XADataSource接口，提供与其他数据源共同加入到一个XA事务的可能；Sharding-Proxy的数据库协议也将实现基于XA的两阶段提交协议；使其可以成为被XA所加载的资源管理器。</p>
<p>除此之外，ShardingSphere还会实现XA协议的recovery部分，即在事务处理器出现崩溃的情况时，可以有能力提供in-doubt transactions来实现事务恢复。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Apache ShardingSphere（Incubating）提供的分布式事务能力可以通过下表总结一下，读者不妨与文章开始时的表格对比一下，看看ShardingSphere的分布式事务模块所带来的变化。</p>
<table>
<thead>
<tr>
<th align="left">/</th>
<th align="left">本地事务</th>
<th align="left">两阶段提交</th>
<th align="left">柔性事务</th>
</tr>
</thead>
<tbody><tr>
<td align="left">业务改造</td>
<td align="left">无</td>
<td align="left">无</td>
<td align="left">无</td>
</tr>
<tr>
<td align="left">一致性</td>
<td align="left">不支持</td>
<td align="left">支持</td>
<td align="left">最终一致</td>
</tr>
<tr>
<td align="left">隔离性</td>
<td align="left">不支持</td>
<td align="left">支持</td>
<td align="left">规划中</td>
</tr>
<tr>
<td align="left">并发性能</td>
<td align="left">无影响</td>
<td align="left">严重衰退</td>
<td align="left">略微衰退</td>
</tr>
<tr>
<td align="left">适合场景</td>
<td align="left">业务方处理不一致</td>
<td align="left">短事务 &amp; 低并发</td>
<td align="left">长事务 &amp; 高并发</td>
</tr>
</tbody></table>
<p>在高速发展的Apache ShardingSphere（Incubating）中，分布式事务的雏形已成，我们会尽快将其打造为可用的产品，并持续为社区提供优质解决方案。对于一篇不算短的文章，阅读完此文的您，相信一定对这个领域有一定兴趣。不妨先尝试一下，是否满足您的预期？或者干脆加入我们的社区，一起打造更完善的分布式事务方案。 </p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S有状态服务-StatefulSet使用</title>
    <url>/k8s/K8S%E6%9C%89%E7%8A%B6%E6%80%81%E6%9C%8D%E5%8A%A1-StatefulSet%E4%BD%BF%E7%94%A8%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>StatefulSet是一种给Pod提供唯一标志的控制器，它可以保证部署和扩展的顺序。</p>
<a id="more"></a>
<div class="note primary">
            <ul><li><p>Pod一致性：包含次序（启动、停止次序）、网络一致性。此一致性与Pod相关，与被调度到哪个node节点无关。</p></li><li><p>稳定的次序：对于N个副本的StatefulSet，每个Pod都在[0，N)的范围内分配一个数字序号，且是唯一的。</p></li><li><p>稳定的网络：Pod的hostname模式为$(statefulset名称)-$(序号)。</p></li><li><p>稳定的存储：通过VolumeClaimTemplate为每个Pod创建一个PV。删除、减少副本，不会删除相关的卷。</p></li></ul>
          </div>

<h1 id="部署Statefulset服务"><a href="#部署Statefulset服务" class="headerlink" title="部署Statefulset服务"></a>部署Statefulset服务</h1><p>volumeClaimTemplates：表示一类PVC的模板，系统会根据Statefulset配置的replicas数量，创建相应数量的PVC。这些PVC除了名字不一样之外其他配置都是一样的。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1beta2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">"nginx"</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">disk-data</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">disk-data</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line">      <span class="attr">storageClassName:</span> <span class="string">"data-db"</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">storage:</span> <span class="string">20Gi</span></span><br></pre></td></tr></table></figure>
<h1 id="验证服务伸缩性"><a href="#验证服务伸缩性" class="headerlink" title="验证服务伸缩性"></a>验证服务伸缩性</h1><h2 id="创建Statefulset服务："><a href="#创建Statefulset服务：" class="headerlink" title="创建Statefulset服务："></a>创建Statefulset服务：</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl create -f statefulset.yaml</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          21m</span><br><span class="line">web-1     1/1       Running   0          20m</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME             STATUS    VOLUME                   CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">disk-ssd-web-0   Bound     d-2ze9k2rrtcy92e97d3ie   20Gi       RWO            alicloud-disk-ssd   21m</span><br><span class="line">disk-ssd-web-1   Bound     d-2ze5dwq6gyjnvdcrmtwg   20Gi       RWO            alicloud-disk-ssd   21m</span><br></pre></td></tr></table></figure>
<h2 id="扩容服务到3个Pod，显示会创建新的云盘卷："><a href="#扩容服务到3个Pod，显示会创建新的云盘卷：" class="headerlink" title="扩容服务到3个Pod，显示会创建新的云盘卷："></a>扩容服务到3个Pod，显示会创建新的云盘卷：</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl scale sts web --replicas=3</span><br><span class="line">statefulset.apps <span class="string">"web"</span> scaled</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          24m</span><br><span class="line">web-1     1/1       Running   0          23m</span><br><span class="line">web-2     1/1       Running   0          2m</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME             STATUS    VOLUME                   CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">disk-ssd-web-0   Bound     d-2ze9k2rrtcy92e97d3ie   20Gi       RWO            alicloud-disk-ssd   24m</span><br><span class="line">disk-ssd-web-1   Bound     d-2ze5dwq6gyjnvdcrmtwg   20Gi       RWO            alicloud-disk-ssd   24m</span><br><span class="line">disk-ssd-web-2   Bound     d-2zea5iul9f4vgt82hxjj   20Gi       RWO            alicloud-disk-ssd   2m</span><br></pre></td></tr></table></figure>
<h2 id="缩容服务到2个Pod，显示pvc-pv并不会一同删除："><a href="#缩容服务到2个Pod，显示pvc-pv并不会一同删除：" class="headerlink" title="缩容服务到2个Pod，显示pvc/pv并不会一同删除："></a>缩容服务到2个Pod，显示pvc/pv并不会一同删除：</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl scale sts web --replicas=2</span><br><span class="line">statefulset.apps <span class="string">"web"</span> scaled</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          25m</span><br><span class="line">web-1     1/1       Running   0          25m</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME             STATUS    VOLUME                   CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">disk-ssd-web-0   Bound     d-2ze9k2rrtcy92e97d3ie   20Gi       RWO            alicloud-disk-ssd   25m</span><br><span class="line">disk-ssd-web-1   Bound     d-2ze5dwq6gyjnvdcrmtwg   20Gi       RWO            alicloud-disk-ssd   25m</span><br><span class="line">disk-ssd-web-2   Bound     d-2zea5iul9f4vgt82hxjj   20Gi       RWO            alicloud-disk-ssd   3m</span><br></pre></td></tr></table></figure>
<h3 id="再次扩容到3个Pod，新的pod会复用原来的PVC-PV："><a href="#再次扩容到3个Pod，新的pod会复用原来的PVC-PV：" class="headerlink" title="再次扩容到3个Pod，新的pod会复用原来的PVC/PV："></a>再次扩容到3个Pod，新的pod会复用原来的PVC/PV：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl scale sts web --replicas=3</span><br><span class="line">statefulset.apps <span class="string">"web"</span> scaled</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          27m</span><br><span class="line">web-1     1/1       Running   0          27m</span><br><span class="line">web-2     1/1       Running   0          2m</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME             STATUS    VOLUME                   CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">disk-ssd-web-0   Bound     d-2ze9k2rrtcy92e97d3ie   20Gi       RWO            alicloud-disk-ssd   27m</span><br><span class="line">disk-ssd-web-1   Bound     d-2ze5dwq6gyjnvdcrmtwg   20Gi       RWO            alicloud-disk-ssd   27m</span><br><span class="line">disk-ssd-web-2   Bound     d-2zea5iul9f4vgt82hxjj   20Gi       RWO            alicloud-disk-ssd   5m</span><br></pre></td></tr></table></figure>
<p>删除StatefulSet服务，PVC、PV并不会随着删除；</p>
<h2 id="验证服务稳定性"><a href="#验证服务稳定性" class="headerlink" title="验证服务稳定性"></a>验证服务稳定性</h2><p>删除一个Pod前，Pod引用PVC：disk-ssd-web-1</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl describe pod web-1 | grep ClaimName</span><br><span class="line">ClaimName:  disk-ssd-web-1</span><br><span class="line"></span><br><span class="line">$ kubectl delete pod web-1</span><br><span class="line">pod <span class="string">"web-1"</span> deleted</span><br></pre></td></tr></table></figure>
<p>删除Pod后，重新创建的Pod名字与删除的一致，且使用同一个PVC：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          29m</span><br><span class="line">web-1     1/1       Running   0          6s</span><br><span class="line">web-2     1/1       Running   0          4m</span><br><span class="line"></span><br><span class="line">$ kubectl describe pod web-1 | grep ClaimName</span><br><span class="line">ClaimName:  disk-ssd-web-1</span><br></pre></td></tr></table></figure>

<h2 id="验证服务高可用性"><a href="#验证服务高可用性" class="headerlink" title="验证服务高可用性"></a>验证服务高可用性</h2><h3 id="云盘中创建临时文件："><a href="#云盘中创建临时文件：" class="headerlink" title="云盘中创建临时文件："></a>云盘中创建临时文件：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl <span class="built_in">exec</span> web-1 ls /data</span><br><span class="line">lost+found</span><br><span class="line"></span><br><span class="line">$ kubectl <span class="built_in">exec</span> web-1 touch /data/statefulset</span><br><span class="line">$ kubectl <span class="built_in">exec</span> web-1 ls /data</span><br><span class="line">statefulset</span><br></pre></td></tr></table></figure>
<h3 id="删除Pod，验证数据持久性："><a href="#删除Pod，验证数据持久性：" class="headerlink" title="删除Pod，验证数据持久性："></a>删除Pod，验证数据持久性：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl delete pod web-1</span><br><span class="line">pod <span class="string">"web-1"</span> deleted</span><br><span class="line"></span><br><span class="line">$ kubectl <span class="built_in">exec</span> web-1 ls /data</span><br><span class="line">statefulset</span><br></pre></td></tr></table></figure>

<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ol>
<li>服务都可以启动，但是运行一段时间后kafka的pod全部CrashLoopBackOff</li>
</ol>
<p>解决: 查看kafka日志连接zookeeper超时。查看zookeeper日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2020-05-18 02:39:07,095]WARN Error accepting new connection: Too many connections from &#x2F;172.18.80.0 - max is 2</span><br></pre></td></tr></table></figure>
<p>问题找到了,修改zookeeper配置 maxClientCnxns=200</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes对象之PersistentVolume和PersistentVolumeClaim</title>
    <url>/k8s/Kubernetes%E5%AF%B9%E8%B1%A1%E4%B9%8BPersistentVolume/</url>
    <content><![CDATA[<div class="note primary">
            <p>学习本节内容前，希望你已经对Kubernetes中Volume的概念有了初步的了解，具体请参考这篇文章：</p><ul><li>[Kubernetes基本概念之Volume]</li></ul>
          </div>
<a id="more"></a>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Kubernetes的pod本身是无状态的（stateless）,生命周期通常比较短，只要出现了异常，Kubernetes就会自动创建一个新的Pod来代替它。</p>
<p>而容器产生的数据，会随着Pod消亡而自动消失。</p>
<p>为了实现Pod内数据的存储管理，Kubernetes引入了两个API资源：Persistent Volume（持久卷，以下简称PV）和Persistent Volume Claim（持久卷申请，以下简称PVC）。</p>
<h2 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h2><ul>
<li><p>PV是Kubernetes集群中的一种网络存储实现，跟Node一样，也是属于集群的资源。</p>
</li>
<li><p>PV跟Docker里的Volume(卷)类似，不过会有独立于Pod的生命周期。</p>
</li>
<li><p>PersistentVolume和Volume一样，代表了集群中的一块存储区域，然而Kubernetes将PersistentVolume抽象成了一种集群资源，类似于集群中的Node对象，这意味着我们可以使用Kubernetes API来创建PersistentVolume对象。</p>
</li>
<li><p>PV与Volume最大的不同是PV拥有着独立于Pod的生命周期。</p>
<h3 id="PVC"><a href="#PVC" class="headerlink" title="PVC"></a>PVC</h3><p>PersistentVolumeClaim（PVC）代表了用户对PV资源的请求。用户需要使用PV资源时，只需要创建一个PVC对象（包括指定使用何种存储资源，使用多少GB，以何种模式使用PV等信息），Kubernetes会自动为我们分配我们所需的PV。</p>
</li>
</ul>
<p>如果把PersistentVolume类比成集群中的Node，那么PersistentVolumeClaim就相当于集群中的Pod，Kubernetes为Pod分配可用的Node，为PersistentVolumeClaim分配可用的PersistentVolume。</p>
<h1 id="1-PV的静态创建"><a href="#1-PV的静态创建" class="headerlink" title="1. PV的静态创建"></a>1. PV的静态创建</h1><p>首先是一个创建PV的简单例子：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv0003</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">slow</span></span><br><span class="line">  <span class="attr">mountOptions:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hard</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">nfsvers=4.1</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/tmp</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.2</span></span><br></pre></td></tr></table></figure>
<p>PV 的访问模式（accessModes）有三种：</p>
<ol>
<li>ReadWriteOnce（RWO）：是最基本的方式，可读可写，但只支持被单个 Pod 挂载。</li>
<li>ReadOnlyMany（ROX）：可以以只读的方式被多个 Pod 挂载。</li>
<li>ReadWriteMany（RWX）：这种存储可以以读写的方式被多个 Pod 共享。<br>不是每一种PV都支持这三种方式，例如ReadWriteMany，目前支持的还比较少。在 PVC 绑定 PV 时通常根据两个条件来绑定，一个是存储的大小，另一个就是访问模式。</li>
</ol>
<p>PV 的回收策略（persistentVolumeReclaimPolicy，即 PVC 释放卷的时候 PV 该如何操作）也有三种：</p>
<ul>
<li>Retain，不清理, 保留 Volume（需要手动清理）</li>
<li>Recycle，删除数据，即 rm -rf /thevolume/*（只有 NFS 和 HostPath 支持）</li>
<li>Delete，删除存储资源，比如删除 AWS EBS 卷（只有 AWS EBS, GCE PD, Azure Disk 和 Cinder 支持）</li>
</ul>
<p>PVC释放卷是指用户删除一个PVC对象时，那么与该PVC对象绑定的PV就会被释放。</p>
<p>1.1 PV支持的类型<br>定义PV时，我们需要指定其底层存储的类型，例如上文中创建的PV，底层使用nfs存储。目前Kuberntes支持以下类型：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GCEPersistentDisk</span><br><span class="line">AWSElasticBlockStore</span><br><span class="line">AzureFile</span><br><span class="line">AzureDisk</span><br><span class="line">FC (Fibre Channel)**</span><br><span class="line">FlexVolume</span><br><span class="line">Flocker</span><br><span class="line">NFS</span><br><span class="line">iSCSI</span><br><span class="line">RBD (Ceph Block Device)</span><br><span class="line">CephFS</span><br><span class="line">Cinder (OpenStack block storage)</span><br><span class="line">Glusterfs</span><br><span class="line">VsphereVolume</span><br><span class="line">Quobyte Volumes</span><br><span class="line">HostPath (Single node testing only – local storage is not supported in any way and WILL NOT WORK in a multi-node cluster)</span><br><span class="line">VMware Photon</span><br><span class="line">Portworx Volumes</span><br><span class="line">ScaleIO Volumes</span><br><span class="line">StorageOS</span><br></pre></td></tr></table></figure>
<h1 id="2-PVC的创建"><a href="#2-PVC的创建" class="headerlink" title="2. PVC的创建"></a>2. PVC的创建</h1><p>当我们定义好一个PV后，我们希望像使用Volume那样使用这个PV，那么我们需要做的就是创建一个PVC对象，并在Pod定义中使用这个PVC。<br>定义一个PVC：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myclaim</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">8Gi</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">slow</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">release:</span> <span class="string">"stable"</span></span><br></pre></td></tr></table></figure>
<p>Pod通过挂在Volume的方式应用PVC：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mypod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myfrontend</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">dockerfile/nginx</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">"/var/www/html"</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">mypd</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mypd</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">myclaim</span></span><br></pre></td></tr></table></figure>
<p>下面简要分析一下定义的PVC文件的关键：</p>
<ul>
<li>首先关注这个配置：storageClassName: slow。此配置用于绑定PVC和PV。这表明这个PVC希望使用storageClassName=slow的PV。返回到上文中PV的定义，我们可以看到PV定义中也包含storageClassName=slow的配置。</li>
<li>接下来是accessModes = ReadWriteOnce。这表明这个PV希望使用storageClassName=slow，并且accessModes = ReadWriteOnce的PV。</li>
<li>在上述条件都满足后，PVC还可以指定PV必须满足的Label，如matchLabels: release: “stable”。这表明此PVC希望使用storageClassName=slow，accessModes = ReadWriteOnce并且拥有Label：release: “stable”的PV。</li>
<li>最后是storage: 8Gi。这表明此PVC希望使用8G的Volume资源。</li>
</ul>
<p>通过上面的分析，我们可以看到PVC和PV的绑定，不是简单的通过Label来进行。而是要综合storageClassName，accessModes，matchLabels以及storage来进行绑定。</p>
<h1 id="3-PV的动态创建"><a href="#3-PV的动态创建" class="headerlink" title="3. PV的动态创建"></a>3. PV的动态创建</h1><p>上文中我们通过PersistentVolume描述文件创建了一个PV。这样的创建方式我们成为静态创建。这样的创建方式有一个弊端，那就是假如我们创建PV时指定大小为50G，而PVC请求80G的PV，那么此PVC就无法找到合适的PV来绑定。因此产生了了PV的动态创建。</p>
<p>PV的动态创建依赖于StorageClass对象。我们不需要手动创建任何PV，所有的工作都由StorageClass为我们完成。一个例子如下：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">slow</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/aws-ebs</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">io1</span></span><br><span class="line">  <span class="attr">zones:</span> <span class="string">us-east-1d,</span> <span class="string">us-east-1c</span></span><br><span class="line">  <span class="attr">iopsPerGB:</span> <span class="string">"10"</span></span><br></pre></td></tr></table></figure>
<p>这个例子使用AWS提供的插件（ kubernetes.io/aws-ebs）创建了一个基于AWS底层存储的StorageClass。这意味着使用这个StorageClass，那么所有的PV都是AWSElasticBlockStore类型的。</p>
<p>StorageClass的定义包含四个部分：</p>
<ul>
<li>provisioner：指定 Volume 插件的类型，包括内置插件（如 kubernetes.io/aws-ebs）和外部插件（如 external-storage 提供的 ceph.com/cephfs）。</li>
<li>mountOptions：指定挂载选项，当 PV 不支持指定的选项时会直接失败。比如 NFS 支持 hard 和 nfsvers=4.1 等选项。</li>
<li>parameters：指定 provisioner 的选项，比如 kubernetes.io/aws-ebs 支持 type、zone、iopsPerGB 等参数。</li>
<li>reclaimPolicy：指定回收策略，同 PV 的回收策略。</li>
</ul>
<p>手动创建的PV时，我们指定了storageClassName=slow的配置项，然后Pod定义中也通过指定storageClassName=slow，从而完成绑定。而通过StorageClass实现动态PV时，我们只需要指定StorageClass的metadata.name。</p>
<p>回到上文中创建PVC的例子，此时PVC指定了storageClassName=slow。那么Kubernetes会在集群中寻找是否存在metadata.name=slow的StorageClass，如果存在，此StorageClass会自动为此PVC创建一个accessModes = ReadWriteOnce，并且大小为8GB的PV。</p>
<p>通过StorageClass的使用，使我们从提前构建静态PV池的工作中解放出来。</p>
<h1 id="4-PV的生命周期"><a href="#4-PV的生命周期" class="headerlink" title="4. PV的生命周期"></a>4. PV的生命周期</h1><p>PV的生命周期包括 6 个阶段：</p>
<ol>
<li>Provisioning，即 PV 的创建，可以直接创建 PV（静态方式），也可以使用 StorageClass 动态创建</li>
<li>Binding，将 PV 分配给 PVC</li>
<li>Using，Pod 通过 PVC 使用该 Volume，并可以通过准入控制 StorageProtection（1.9及以前版本为PVCProtection）阻止删除正在使用的 PVC</li>
<li>Releasing，Pod 释放 Volume 并删除 PVC</li>
<li>Reclaiming，回收 PV，可以保留 PV 以便下次使用，也可以直接从云存储中删除</li>
<li>Deleting，删除 PV 并从云存储中删除后段存储<br>根据这 6 个阶段，PV 的状态有以下 4 种</li>
</ol>
<ul>
<li>Available：可用</li>
<li>Bound：已经分配给 PVC</li>
<li>Released：PVC 解绑但还未执行回收策略</li>
<li>Failed：发生错误</li>
</ul>
<p>一个PV从创建到销毁的具体流程如下：</p>
<ol>
<li>一个PV创建完后状态会变成Available，等待被PVC绑定。</li>
<li>一旦被PVC邦定，PV的状态会变成Bound，就可以被定义了相应PVC的Pod使用。</li>
<li>Pod使用完后会释放PV，PV的状态变成Released。</li>
<li>变成Released的PV会根据定义的回收策略做相应的回收工作。有三种回收策略，Retain、Delete 和 Recycle。<ul>
<li>Retain就是保留现场，K8S什么也不做，等待用户手动去处理PV里的数据，处理完后，再手动删除PV。</li>
<li>Delete 策略，K8S会自动删除该PV及里面的数据。</li>
<li>Recycle方式，K8S会将PV里的数据删除，然后把PV的状态变成Available，又可以被新的PVC绑定使用。</li>
</ul>
</li>
</ol>
<h1 id="5-DefaultStorageClass"><a href="#5-DefaultStorageClass" class="headerlink" title="5. DefaultStorageClass"></a>5. DefaultStorageClass</h1><p>前面我们说到，PVC和PV的绑定是通过StorageClassName进行的。然而如果定义PVC时没有指定StorageClassName呢？这取决与admission插件是否开启了DefaultDefaultStorageClass功能：</p>
<p>如果DefaultStorageClass功能开启，那么此PVC的StorageClassName就会被指定为DefaultStorageClass。DefaultStorageClass从何处而来呢？原来在定义StorageClass时，可以在Annotation中添加一个键值对：storageclass.kubernetes.io/is-default-class: true，那么此StorageClass就变成默认的StorageClass了。</p>
<p>如果DefaultStorageClass功能没有开启，那么没有指定StorageClassName的PVC只能被绑定到同样没有指定StorageClassName的PV。</p>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ol>
<li><a href="../pod-has-unbound-PersistentVolumeClaims">pod has unbound immediate PersistentVolumeClaims</a></li>
</ol>
<p>参考文章<br><a href="http://blog.csdn.net/liukuan73/article/details/60089305" target="_blank" rel="noopener">http://blog.csdn.net/liukuan73/article/details/60089305</a><br><a href="https://www.jianshu.com/p/99e610067bc8" target="_blank" rel="noopener">https://www.jianshu.com/p/99e610067bc8</a></p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql5.7性能提升一百倍调优</title>
    <url>/db/mysql5.7%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E4%B8%80%E7%99%BE%E5%80%8D%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<h1 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h1><p>全文中一共有常用的（事实上你如果花1-2周阅读、理解、自己动手设一下后是需要这么多参数的）76个参数，笔者把近10年里3个亿万级项目的数据库调优用此篇浓缩到了可能读者只需要2周时间就可以掌握，同时我是按照：</p>
<a id="more"></a>

<p>每一个参数干吗？<br>在某些典型硬件配置下的db上参数该设多少？<br>设会怎么样？<br>不设会怎么样？<br>有什么坑如何填坑？<br>有些参数怎么算、算法又如何<br>mysql5.7性能提升一百倍调优宝典（赠给有缘人）<br>这种style来写的，相信此篇会对一些使用mysql的尤其是正在或者将要面临万级并发的项目、网站有所帮助。具体请看文档！</p>
<p>一千个DBA就有一千种配置方式!</p>
<p>大家一定记得不要轻易去看网上，要看只看官网！网上很多博客都是错的，连参数都列错了，5.7很多参数和5.6是完全不一样的。</p>
<p>可能你从未看到过这样的一篇集中火力式的把mysql参数列了这么全的文章，很有兴曾参与过超3万并发的18～19年的数轮520、618、双11、双12保卫战。因此这一篇是汇集了最精华和实战的内容把mysql所有的参数列在这边供大家参考。并且以（64c cpu，128gb内存）的mysql cpu和内存来进行了一轮配置。而此文的内存相关参数部分可以延展至256gb～512gb。</p>
<p>另外有一点，建议在mysql的服务器上使用ssd。除非并发数永远控制在500-1000内那就没必要使用ssd，普通高速磁盘就可以了。</p>
<p>你会发觉这篇文章是一篇宝藏，这些参数都能够自己动手试验一篇基本在外面是可以吊打mysql面试官了。</p>
<h1 id="client域："><a href="#client域：" class="headerlink" title="client域："></a>client域：</h1><h2 id="character-set-client"><a href="#character-set-client" class="headerlink" title="character_set_client"></a>character_set_client</h2><ul>
<li><p>推荐设置：utf8mb4</p>
</li>
<li><p>作用：字符集设定，如果前台有连social mobile application一类包括wechat，并且允许有使用emoji表情的，请开启成utf8mb4</p>
</li>
<li><p>如果不配的后果：mysql不支持前端app存表情等字符</p>
</li>
<li><p>配置实例：character_set_client=utf8mb4</p>
</li>
</ul>
<h1 id="mysqld域："><a href="#mysqld域：" class="headerlink" title="mysqld域："></a>mysqld域：</h1><h2 id="1-server-id"><a href="#1-server-id" class="headerlink" title="1)server-id"></a>1)server-id</h2><ul>
<li><p>推荐设置：如果没有做任何主从复制，此值可以不设。</p>
</li>
<li><p>作用：遇有主从复制，必设该值，每个参与主从复制的mysql实例的server-id不能重复，必须为阿拉伯数字。</p>
</li>
<li><p>如果不配的后果：如果你用的是主从复制，这个id不设那么整个mysql的主从复制会失几。</p>
</li>
<li><p>配置实例：server-id=1</p>
</li>
</ul>
<h2 id="2-port"><a href="#2-port" class="headerlink" title="2)port"></a>2)port</h2><ul>
<li><p>推荐设置：3306</p>
</li>
<li><p>作用：mysql实例端口</p>
</li>
<li><p>如果不配的后果：默认为3306</p>
</li>
<li><p>配置实例：port=3306</p>
</li>
</ul>
<h2 id="3-bind-address"><a href="#3-bind-address" class="headerlink" title="3)bind_address"></a>3)bind_address</h2><ul>
<li><p>推荐设置：0.0.0.0</p>
</li>
<li><p>作用：除非有特殊需要，我们会限制只允许mysql实例被某一个ip方问，不支持多个，生产上都为：0.0.0.0然后使用防火墙策略来控制。</p>
</li>
<li><p>如果不配的后果：默认不允许远程登录</p>
</li>
<li><p>配置实例：bind_address=0.0.0.0</p>
</li>
</ul>
<h2 id="4-autocommit"><a href="#4-autocommit" class="headerlink" title="4)autocommit"></a>4)autocommit</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：生产上开启成1，如果你开启的是0会有一个这样的情况：</p>
</li>
</ul>
<p>a运行一条insert语句，并未作commit;b去做查询此时b是查询不到的。这种操作一般用于在写store procedure时用到。</p>
<ul>
<li><p>如果不配的后果：如果在系统的my.cnf层面把它设成了0，如果在使用时（99%情况是用的1）时，你想要用root在生产运行时把它设成set autocommit = 1都开启不了。而如果你在一开始就没它设置成1，那么当碰到某些特殊场景特别是写store procedure时需要把它设成0时，你是可以手动临时把某一个session给开在0的。</p>
</li>
<li><p>配置实例：autocommit = 1</p>
</li>
</ul>
<h2 id="5-character-set-server"><a href="#5-character-set-server" class="headerlink" title="5)character_set_server"></a>5)character_set_server</h2><ul>
<li><p>推荐设置：utf8mb4</p>
</li>
<li><p>作用：字符集设定，如果前台有连social mobile application一类包括wechat，并且允许有使用emoji表情的，请开启成utf8mb4</p>
</li>
<li><p>如果不配的后果：mysql不支持前端app存表情等字符</p>
</li>
</ul>
<p>配置实例：character_set_server=utf8mb4</p>
<h2 id="6-skip-name-resolve"><a href="#6-skip-name-resolve" class="headerlink" title="6)skip_name_resolve"></a>6)skip_name_resolve</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：生产上建议开启成1，这样mysql server不会对客户端连接使用反向dns解析，否则客户端连上后有时在遇有生产高速运行时直接timeout，如果设成了1带来的问题就是你不能在mysql中使用主机名来对客户端权限进行划分，而是需要使用ip。</p>
</li>
</ul>
<p>如果要做成即允许mysql里允许使用主机名来分配客户端连接权限，又要做到不要让mysql去做dns解析，可以在mysql所在主机端的/etc/hosts文件中写上客户端的主机名，因为当客户端连接连上来时，mysql反向查找客户端连接时的域名解析的步骤是：首先查找 /etc/hosts 文件，搜索域名和IP的对应关系。但是这样做也有一个问题，那就是如果你有多个客户端多个mysql主从关系，哪到你要把mysql做成一个dns解析器吗？因此推荐设成1</p>
<ul>
<li><p>如果不配的后果：mysql server每一次会对客户端连接使用反向dns解析，经常会出现客户端连上后有timeout现象。</p>
</li>
<li><p>配置实例：skip_name_resolve=1</p>
</li>
</ul>
<h2 id="7-max-connections"><a href="#7-max-connections" class="headerlink" title="7)max_connections"></a>7)max_connections</h2><ul>
<li><p>推荐设置：20,000</p>
</li>
<li><p>作用：最大连接数，以前端3万的tps并发，假设redis命中失效50%（这是灾难），那么后端mysql单个主或从开启连接数为：20,000，我们公司在前端并发曾达到过6万，80%被waf、vanish、缓存挡掉，落在db上的qps最高一次为20,000连接，再按照mysql官方，max_connections值受系统os最大打开连接数限制，因此我们需要做以下2步操作：</p>
<ul>
<li>1）在 /etc/security/limits.conf 底部增加2行<br>mysql hard nofile 65535<br>mysql soft nofile 65535</li>
<li>2）在/usr/lib/systemd/system/mysqld.service（视如何安装mysql所决定，用编译安装和yum安装会产生path路径不同。）文件最后添加：<br>LimitNOFILE=65535<br>LimitNPROC=65535<br>$ systemctl daemon-reload<br>$ systemctl restart mysqld.service<br>如不生效重启服务器。</li>
</ul>
</li>
<li><p>如果不配的后果：默认只有150</p>
</li>
<li><p>配置实例：max_connections = 20,000</p>
</li>
</ul>
<h2 id="8-max-connect-errors"><a href="#8-max-connect-errors" class="headerlink" title="8)max_connect_errors"></a>8)max_connect_errors</h2><ul>
<li><p>推荐设置：生产上设10, 开发测试上使用默认100</p>
</li>
<li><p>作用：生产上开启成10次，开发测试上使用默认即不设。</p>
<p>max_connect_errors是一个MySQL中与安全有关的计数器值，它负责阻止过多尝试失败的客户端以防止暴力破解密码的情况。如果需要设置此数值，手动添加。当此值设置为10时，意味着如果某一客户端尝试连接此MySQL服务器，但是失败（如密码错误等等）10次，则MySQL会无条件强制阻止此客户端连接。相关的登录错误信息会记录到performance_schema.host_cache表中。如果希望重置此计数器的值，则必须重启MySQL服务器或者执行</p>
<p>Mysql&gt; FLUSH HOSTS;</p>
<p>当这一客户端成功连接一次MySQL服务器后，针对此客户端的max_connect_errors会清零。可以在防火墙上做策略限制某些ip的远程连接。</p>
</li>
<li><p>如果不配的后果：默认为100</p>
</li>
<li><p>配置实例：max_connect_errors =10</p>
</li>
</ul>
<h2 id="9-innodb-flush-log-at-trx-commit"><a href="#9-innodb-flush-log-at-trx-commit" class="headerlink" title="9)innodb_flush_log_at_trx_commit"></a>9)innodb_flush_log_at_trx_commit</h2><ul>
<li><p>推荐设置：2</p>
</li>
<li><p>作用：(核心交易系统设置为1，默认为1，其他2或者0)，</p>
<ul>
<li><p>0代表：log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下在事务提交的时候，不会主动触发写入磁盘的操作。</p>
</li>
<li><p>1代表：每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去，该模式为系统默认（因此会保留每一份redo日志）</p>
</li>
<li><p>2代表：每次事务提交时MySQL都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下，MySQL会每秒执行一次 flush(刷到磁盘)操作。该模式速度较快，也比0安全，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失。</p>
</li>
</ul>
<p>除非你用的是小型机或者是超大规模mysql集群一类如：游戏行业，那么需要保留每一秒的事务，否则请设成2，要不然会严重影响系统性能。这个参数是5.6所没有的。</p>
</li>
<li><p>如果不配的后果：默认为1，影响系统写性能。</p>
</li>
<li><p>配置实例：innodb_flush_log_at_trx_commit=2</p>
</li>
</ul>
<h2 id="10-transaction-isolation"><a href="#10-transaction-isolation" class="headerlink" title="10)transaction_isolation"></a>10)transaction_isolation</h2><ul>
<li><p>推荐设置：READ-COMMITTED</p>
</li>
<li><p>作用：此参数直接决定了mysql的性能，oracle中的事务默认级别就是read-commited，而mysql的默认级别是:repeatable-read，它利用自身独有的Gap Lock解决了”幻读”。但也因为Gap Lock的缘故，相比于READ-COMMITTED级别的Record Lock，REPEATABLE-READ的事务并发插入性能受到很大的限制。离级别的选择取决于实际的业务需求（安全与性能的权衡），如果不是金融、电信等事务级别要求很高的业务，完全可以设置成transaction_isolation=READ-COMMITTED。</p>
<ul>
<li><p>读未提交（READ-UNCOMMITTED）-它是最低的隔离级别，虽然性能最高，但也不推荐<br>它会读取到其他事务修改尚未提交的数据，使用此隔离级别就需要非常小心，认识到这种级别下的查询结果可能不一致或不可复制，这取决于其他事务同时在做什么。通常，具有此隔离级别的事务只执行查询，而不执行插入、更新或删除操作。<br>在实际环境中，应当根据是否允许出现脏读（dirty reads），不可重复读（non-repeatable reads）和幻读（phantom reads ）现象而选择相应的隔离级别。例如在大数据中，少量的数据不一致不会影响到最后的决策，这种情况下可以使用较低的隔离级别以提交性能和并发性。</p>
</li>
<li><p>Read-Committed-推荐: 事务无法看到来自其他事务的未提交数据，但可以看到当前事务启动后另一个事务提交的数据。当拥有这种级别的事务执行 UPDATE … WHERE or DELETE … WHERE操作时，其他事务可能需要等待。但是该事务可以执行 SELECT … FOR UPDATE, and LOCK IN SHARE MODE操作，其他事务不需要等待。</p>
</li>
<li><p>Repeatable-read: 这是MySQL的InnoDB引擎默认的隔离级别，它阻止查询的任何行被其他事务更改。因此，阻塞不可重复读，而不是幻读。也就是说在可重复读中，可能会出现幻读。重复读使用一种中等严格的锁定策略，以便事务中的所有查询都能看到来自相同快照(即事务启动时的数据)的数据。当拥有该级别的事务执行 UPDATE … WHERE, DELETE … WHERE, SELECT … FOR UPDATE和LOCK IN SHARE MODE操作时，其他事务可能需要等待。</p>
</li>
<li><p>串行化（SERIALIZABLE）-极力不推荐，串行化隔离级别是最高的隔离级别，它使用了最保守的锁策略。它阻止任何其他事务插入或更改此事务读取的数据，直到该事务完成。简单的来说，就是一个事务一个事务的来执行，显然性能会很低。在这种隔离级别下，一个事务中的相同查询可以反复执行，每次查询结果是一样的。从当前事务开始执行，任何更改另一个事务提交的数据的尝试都会导致当前事务等待（阻塞）。这是SQL标准指定的默认隔离级别（注意不是MySQL）。在实践中，这种严格程度是很少需要的。</p>
</li>
</ul>
</li>
<li><p>如果不配的后果：默认就是repeatable-read</p>
</li>
<li><p>配置实例：transaction_isolation = READ-COMMITTED</p>
</li>
</ul>
<h2 id="11-explicit-defaults-for-timestamp"><a href="#11-explicit-defaults-for-timestamp" class="headerlink" title="11)explicit_defaults_for_timestamp"></a>11)explicit_defaults_for_timestamp</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：mysql5.7默认对于timestamp字段会显示“系统当前日期”，就算你在插表时这个timestamp字段留空，它在select出来时也会显示系统日期。因此，这个值的影响范围是你在建表时导致的。</p>
<p>系统默认这个值是0，在0的情况下，你要让该表的timestamp字段在为null时不显示系统默认时间，你的建表必须为：create table order(o_id int ,updateed_time timestamp null default null) ;</p>
<p>explicit_defaults_for_timestamp 变量会直接影响表结构，也就是说explicit_defaults_for_timestamp的作用时间是在表定义的时候；你的update | insert 想通过它去改变行为已经太晚了！</p>
<p>因此，我推荐把这个值设为1.</p>
</li>
<li><p>如果不配的后果：默认为0</p>
</li>
<li><p>配置实例：explicit_defaults_for_timestamp = 1</p>
</li>
</ul>
<h2 id="12-join-buffer-size"><a href="#12-join-buffer-size" class="headerlink" title="12)join_buffer_size"></a>12)join_buffer_size</h2><ul>
<li><p>推荐设置：16M</p>
</li>
<li><p>作用：系统默认大小为：512k，mac下默认大小为：256k，针对128GB，1万并发的mysql我推荐给到的值为：8~16M<br>对于JOIN KEY 有索引和二级索引，JOIN KEY 无索引mysql会使用到join_buffer_size，一般建议设置一个很小的 GLOBAL 值，完了在 SESSION 或者 QUERY 的基础上来做一个合适的调整。</p>
<p>如果你拍脑袋给也个4g，我们有1000个并发，就是用掉了4T的内存。。。4T啊。。。你以为你是小型机。适当的去改变它确实可以带来一定的提速，但并不是说很多值越大越好.</p>
<p>为什么我们设置成4m呢？我们假设我们的mysql所在的vm是128gb，一根这样的join（如果被用到）是4M，1万个也不过用掉40G,而根据官方说法，total加在一起产生的join_buffer_size不要超过你所在系统的50%.默认512k肯定是小了点，我们可以适当放宽，比如说：2M.</p>
<p>在实际使用场景时我们发觉有这样的高频操作（要看高频出现的有意义的sql的执行计划，并确认该计划的：执行cost如： “<strong>query_cost</strong>“: “1003179606.87”，它产生的cost为：0.93个G,如果它真的很高频出现在调优sql到无法调优的程度，我们会去做set session join_buffer_size = 1024 * 1024 * 1024;这样的操作。</p>
<p>而不是在一开始的my.cnf中去分配一个暴大的值，我们这边基于128gb，1万connection的并发来说，你给个16M不算小也不算多，我推荐给到8~16M间（这是指在一开始）。</p>
</li>
<li><p>如果不配的后果：默认的为256k</p>
</li>
<li><p>配置实例：join_buffer_size = 16M</p>
</li>
</ul>
<h2 id="13-tmp-table-size"><a href="#13-tmp-table-size" class="headerlink" title="13)tmp_table_size"></a>13)tmp_table_size</h2><ul>
<li><p>推荐设置：67108864</p>
</li>
<li><p>作用：如果是128gb内存的服务器，我建议是在my.cnf中设成64M<br>通过设置tmp_table_size选项来增加一张临时表的大小，例如做高级GROUP BY操作生成的临时表。默认系统为32M，如果当你的临时表越来越多加在一起超过了这个值，那么mysql会在系统磁盘上创建，这个值不是越多越好，也没有一个合适的值。一开始的建议为&gt;64M，然后在运行时我们通过以下公式来做临时调优</p>
<p><code>show global status like &#39;created_tmp%&#39;;</code></p>
<p>把得到的结果中的：(Created_tmp_disk_tables / Created_tmp_tables) * 100% 如果&lt;=25%为最佳值。注意了，在生产时热设定时一定要用类似以下语法：<br><code>set global tmp_table_size=64*1024*1024</code>而不是<code>set global tmp_table_size=64M</code>。</p>
</li>
<li><p>如果不配的后果：默认为32M</p>
</li>
<li><p>配置实例：tmp_table_size = 67108864</p>
</li>
</ul>
<h2 id="14-tmpdir"><a href="#14-tmpdir" class="headerlink" title="14)tmpdir"></a>14)tmpdir</h2><p>这块参数可以让运维给到，放到大空间里就行了，没什么太敏感的。</p>
<h2 id="15-max-allowed-packet"><a href="#15-max-allowed-packet" class="headerlink" title="15)max_allowed_packet"></a>15)max_allowed_packet</h2><ul>
<li><p>推荐设置：134217728</p>
</li>
<li><p>作用：如果你经常在应用层碰到了：Got a packet bigger than’max_allowed_packet’ bytes，这时你可以使用<br>show variables like ‘%max_allowed_packet%’;来查看这个值，这个值没有合适，一般如：用客户端导入数据的时候，遇到 错误代码: 1153 - Got a packet bigger than ‘max_allowed_packet’ bytes 终止了数据导入。这样的场景下，当MySQL客户端或mysqld服务器收到大于max_allowed_packet字节的信息包时，将发出“信息包过大”错误，并关闭连接。对于某些客户端，如果通信信息包过大，在执行查询期间，可能会遇到“丢失与MySQL服务器的连接”错误。</p>
<p>客户端和服务器均有自己的max_allowed_packet变量，因此，如你打算处理大的信息包，必须增加客户端和服务器上的该变量。一般情况下，服务器默认max-allowed-packet为1MB,可以通过在交换机上抓包或者是图形化分析来抓返回结果判断。<br>一般推荐在128gb内存下设置的置为128M.也可以在运行时动态调整：set global max_allowed_packet = 128<em>1024</em>1024</p>
</li>
<li><p>如果不配的后果：1M</p>
</li>
<li><p>配置实例：max_allowed_packet = 134217728</p>
</li>
</ul>
<h2 id="16-sql-mode"><a href="#16-sql-mode" class="headerlink" title="16)sql_mode"></a>16)sql_mode</h2><p>不需要去设置，使用默认的，这块和性能无关。我们的中台中的sql如果碰到有sql报错，因该是在测试环境上就已经报了，它的作用是用来约束你sql的写法的，如果是一个从头开始开发的应用，我们比如说约束好都是ansi sql写法，对于一个产品，不要去做这种画蛇添足的做法。</p>
<h2 id="17-interactive-timeout"><a href="#17-interactive-timeout" class="headerlink" title="17)interactive_timeout"></a>17)interactive_timeout</h2><ul>
<li><p>推荐设置：600</p>
</li>
<li><p>作用：单位为s，系统默认为：28800s即8小时。如果这个值太大，你会发觉在mysql中有大量sleep的连接，这些连接又被称为：僵尸连接，僵尸连接一多你真正要用的时候就会抛：too many connection这样的错，因此对于长久不用的连接，我们一般要使用“踢出机制”，多久对于一个活动累的sql进行踢呢？</p>
<p>我们说如果有一个长事务，它要执行1小时，我不知道这是不是属于正常？当然如果你设了太短，说1分钟就把它踢了，还真不一定踢的对，按照我们在oracle中设置的best practice我们都会把它放到10分钟。你有一条sql连着，10分钟不用，我就把它踢了，这也算正常。</p>
<p>但是在高并发的场景下这个timeout会缩短至3-5分钟，这就是为什么我提倡我们的非报表即时类查询需要优化到sql的运行时间不超过300ms的原因，因为在高并发场景下，超过500ms的sql都已经很夸张了。保守点我觉得可以设成10分钏，在应用端由其通过jdbc连接数据库的，做的好的应用都会在jdbc里有一个autoconnect参数，这个autoconnect参数就要和mysql中的wait_timeout来做匹配了。</p>
<p>同时在应用端要有相应的validate sql一类的操作来keep alived。不过我更推荐使用”连接池内连接的生存周期（idleConnectionTestPeriod）”来做设置，把这个值设成 &lt; mysql内的这两个值将会是最好，同时，idleConnectionTestPeriod会使用到异步的方式去做超时check。<br>如c3p0中的：idleConnectionTestPeriod和testConnectionOnCheckin相当可靠</p>
<ul>
<li>interactive_timeout：交互式连接超时时间(mysql工具、mysqldump等)</li>
<li>wait_timeout：非交互式连接超时时间，默认的连接mysql api程序,jdbc连接数据库等<br>interactive_timeout针对交互式连接，wait_timeout针对非交互式连接。所谓的交互式连接，即在mysql_real_connect()函数中使用了CLIENT_INTERACTIVE选项。</li>
</ul>
<p><code>show global variables like &#39;wait_timeout&#39;;</code></p>
<ol>
<li><p>wait_timeout 只是针对空闲会话有影响。</p>
</li>
<li><p>session级别的wait_timeout继承global级别的interactive_timeout的值。而global级别的session则不受interactive_timeout的影响。</p>
</li>
<li><p>交互式会话的timeout时间受global级别的interactive_timeout影响。因此要修改非交互模式下的timeout，必须同时修改interactive_timeout的值。</p>
</li>
<li><p>非交互模式下，wait_timeout参数继承global级别的wait_timeout。</p>
</li>
</ol>
</li>
<li><p>如果不配的后果：系统默认为28800</p>
</li>
<li><p>配置实例：interactive_timeout = 600</p>
</li>
</ul>
<h2 id="18-wait-timeout"><a href="#18-wait-timeout" class="headerlink" title="18)wait_timeout"></a>18)wait_timeout</h2><p>同interactive_timeout，两个值都设成一样。</p>
<h2 id="19-read-buffer-size"><a href="#19-read-buffer-size" class="headerlink" title="19)read_buffer_size"></a>19)read_buffer_size</h2><ul>
<li><p>推荐设置：4194304</p>
</li>
<li><p>作用：这个值其实轻易是用不到的，因为，它只对2种场景的full table scan产生影响而不是所有的full table scan，同时从mysql5.6以后开始没有数据块多块读的功能,与是否设置 read_buffer_size参数无关。应用场景：</p>
<ul>
<li><p>1）SELECT INTO … OUTFILE ‘fileName‘</p>
</li>
<li><p>2）When filesort is used, during merge buffers and when merged results are written to a temporary file, then writes are buffered</p>
</li>
</ul>
<p>一般保留默认:64k，保守作法是设置在1～4M，不过它的应用场景很有限，对于互联网场景真的不太用，我推荐设成4M</p>
</li>
<li><p>如果不配的后果：默认为64k</p>
</li>
<li><p>配置实例：read_buffer_size = 4194304</p>
</li>
</ul>
<h2 id="20-read-rnd-buffer-size"><a href="#20-read-rnd-buffer-size" class="headerlink" title="20)read_rnd_buffer_size"></a>20)read_rnd_buffer_size</h2><ul>
<li><p>推荐设置：8388608</p>
</li>
<li><p>作用：就是当数据块的读取需要满足一定的顺序的情况下，MySQL 就需要产生随机读取，进而使用到 read_rnd_buffer_size 参数所设置的内存缓冲区。</p>
<p>它的默认为256k，最大可以设到2G，它会对order by关键字起作用，当order by的计划成本超出了sort_buffer_size后，mysql会产用随机读取并消耗额外的内容，很多外面的博客说它是只对myisam引擎起作用，</p>
<p>但其实不是，该参数还真的覆盖到所有引擎，一般它的推荐设置在8-16M，我推荐8M，根据sql分析计划如果碰到高频的查询且order by的返回包体都很大，那么再在session级别去放。</p>
</li>
<li><p>如果不配的后果：默认为256k</p>
</li>
<li><p>配置实例：read_rnd_buffer_size = 8388608</p>
</li>
</ul>
<h2 id="21-sort-buffer-size"><a href="#21-sort-buffer-size" class="headerlink" title="21)sort_buffer_size"></a>21)sort_buffer_size</h2><ul>
<li><p>推荐设置：4194304</p>
</li>
<li><p>作用：每个会话执行排序操作所分配的内存大小。想要增大max_sort_length参数，需要增大sort_buffer_size参数。</p>
<p>如果在SHOW GLOBAL STATUS输出结果中看到每秒输出的Sort_merge_passes状态参数很大，可以考虑增大sort_buffer_size这个值来提高ORDER BY 和 GROUP BY的处理速度。建议设置为1~4MB。</p>
<p>当个别会话需要执行大的排序操作时，在会话级别增大这个参数。所谓会话级别，我举个例子，你拍脑袋一下，说我设个32M,你所它乘10,000请求，这得多大内存。</p>
<p>另外，千万要注意，在mysql内存，当你的sort_buffer_size在超过2K时在底层使用的是mmap()的c函数去做内存分配的，而不是malloc()，做过c的都知道mmap()是一个矢量单位，因此它会付出性能的影响，能影响多少呢？单条sql影响值在30%。</p>
</li>
<li><p>如果不配的后果：默认值为1M</p>
</li>
<li><p>配置实例：sort_buffer_size =4194304</p>
</li>
</ul>
<h2 id="22-innodb-page-size"><a href="#22-innodb-page-size" class="headerlink" title="22)innodb_page_size"></a>22)innodb_page_size</h2><ul>
<li><p>推荐设置：8192</p>
</li>
<li><p>作用：这个值可要小心，一般它在设置后就不能轻易改了，一般来说我们都认为，值越大越好，不是的， 这个值它的原理是这样的：size越小，内存划分粒度越大，使用率越高，但是会有其他问题，就是限制了索引字段还有整行的大小。</p>
<p>innodb引擎读取内存还有更新都是一页一页更新的，这个innodb_page_size决定了，一个基本页的大小。常用B+Tree索引，B+树是为磁盘及其他存储辅助设备而设计一种平衡查找树（不是二叉树）。</p>
<p>B+树中，所有记录的节点按大小顺序存放在同一层的叶子节点中，各叶子节点用指针进行连接。MySQL将每个叶子节点的大小设置为一个页的整数倍，利用磁盘的预读机制，能有效减少磁盘I/O次数，提高查询效率。 </p>
<p>如果一个行数据，超过了一页的一半，那么一个页只能容纳一条记录，这样B+Tree在不理想的情况下就变成了双向链表。我们拿白话来说就是：你越大，空间利用率更高，但是越小呢越有助于性能但是这边一定一定有一个“但是”，但是小到一定的量反而性能不好，为什么呢？太大上面我已经举例了，太小。。。mysql的页间的check point太频繁。怎么样做才能达到一个合理值呢？</p>
<p>这个我们是在全真生产环境、全数据量下用测试工具去对4k,8k,16k三种场景压测得到的吞吐量即tps来做观察的，我这边可以给出一个推荐值，以单表超1000w条数据基于中台1.1的数据库结果（每个表都超1000w），我们在设置该值为：8K时，它的吞吐达到最优。</p>
</li>
<li><p>如果不配的后果：32位下默认为8192 , 64位下默认为16384</p>
</li>
<li><p>配置实例：innodb_page_size = 8192</p>
</li>
</ul>
<h2 id="23-innodb-buffer-pool-size"><a href="#23-innodb-buffer-pool-size" class="headerlink" title="23)innodb_buffer_pool_size"></a>23)innodb_buffer_pool_size</h2><ul>
<li><p>推荐设置：72G</p>
</li>
<li><p>作用：这个值和innodb_buffer_pool_instances相辅相成。在32位机器下，innodb_buffer_pool_instances一般为1，在64位机器上，这个值为8-64.</p>
<p>pool_instances其实为cpu核数，它的作用是：</p>
<ul>
<li><p>1）对于缓冲池在数千兆字节范围内的系统，通过减少争用不同线程对缓存页面进行读写的争用，将缓冲池划分为多个单独的实例可以提高并发性。</p>
</li>
<li><p>2）使用散列函数将存储在缓冲池中或从缓冲池读取的每个页面随机分配给其中一个缓冲池实例。每个缓冲池管理自己的空闲列表， 刷新列表， LRU和连接到缓冲池的所有其他数据结构，并受其自己的缓冲池互斥量保护。</p>
</li>
</ul>
<p>innodb_buffer_pool_size的设置需要为pool_instance的整数倍。</p>
<p>网上很多说innodb_buffer_pool_size为系统的70%，这是错的！因为你真的设了70%你的swap空间会被挤压，你不要忘了你还有os，上面还可能有监控agent端。一旦swap空间被挤压后你的mysql反面严重拖慢读写。</p>
<p>此处强烈建议设成内存的20%-65%间（独立的mysql服务器），为什么有一个20%呢？对于&lt;4gb的mysql用服务器来说按照20%系统内存来设置。由于我们是128gb的内存，此处我建议使用72G,如果内存超过128gb，一般我们会把pool instance设成16个，每个开启10g左右的buffer_pool_size，对于256gb内存的服务器来说我们可以这样设。</p>
</li>
<li><p>如果不配的后果：默认为64</p>
</li>
<li><p>配置实例：innodb_buffer_pool_size = 72G</p>
</li>
</ul>
<h2 id="24-innodb-buffer-pool-instances-8"><a href="#24-innodb-buffer-pool-instances-8" class="headerlink" title="24)innodb_buffer_pool_instances = 8"></a>24)innodb_buffer_pool_instances = 8</h2><p>这个参数同innodb_buffer_pool_size一起讲解了。</p>
<h2 id="25-innodb-buffer-pool-load-at-startup"><a href="#25-innodb-buffer-pool-load-at-startup" class="headerlink" title="25)innodb_buffer_pool_load_at_startup"></a>25)innodb_buffer_pool_load_at_startup</h2><ul>
<li><p>推荐设置：0</p>
</li>
<li><p>作用：这两个参数几乎没人用一般dba也不曾听说过，它是什么意思呢？<br>Mysql在第一次（重启）时，它的buffer_pool_size中是空的，随着mysql运行时间1-2小时后，它的buffer_pool_size里开始被塞入东西，它分为old block与new block，而此时mysql性能开始一点点读写效率上去了，那是因为在buffer_pool_size没有放入东西时，mysql很多读写发生在硬盘上，从硬盘到内存的加载过程是一个比较漫长和耗时的过程，因此我们往往会设一个startup=1以加快这个“预热”过程。</p>
<p>它与参数shutdown配合使用，即相当于把上次使用的innot_db_buffer_pool里的东西在启动时先做一次加载，以加快mysql的性能。它会在innodb的数据目录中生成一个文件：ib_buffer_pool。</p>
<p>高度注意：加入了startup和shutdown=1时，mysql的启动过程会比较慢，如果你上次的dump出的buffer_pool里的东西有50多g那么mysql启动时的加载过程会变得比较慢。这个值很多人使用默认的0（不开启），它的影响就是你在mysql重启后，一开始你的系统读写性能不如在你系统运行了2-4小时（视db读写而定）反而它的读写性能变好了。不设使用默认值0。</p>
</li>
<li><p>如果不配的后果：不配的话系统默认为0</p>
</li>
<li><p>配置实例：innodb_buffer_pool_load_at_startup = 0</p>
</li>
</ul>
<h2 id="26-innodb-buffer-pool-dump-at-shutdown"><a href="#26-innodb-buffer-pool-dump-at-shutdown" class="headerlink" title="26)innodb_buffer_pool_dump_at_shutdown"></a>26)innodb_buffer_pool_dump_at_shutdown</h2><p>同上面的startup参数以及解说</p>
<h2 id="27-innodb-lru-scan-depth"><a href="#27-innodb-lru-scan-depth" class="headerlink" title="27)innodb_lru_scan_depth"></a>27)innodb_lru_scan_depth</h2><ul>
<li><p>推荐设置：2000</p>
</li>
<li><p>作用：innodb_io_capactiy 在sas 15000转的下配置800就可以了，在ssd下面配置2000以上。<br>可使用默认配置。即不设。</p>
</li>
<li><p>如果不配的后果：默认为200，db吞吐量上不去。</p>
</li>
<li><p>配置实例：innodb_lru_scan_depth = 2000</p>
</li>
</ul>
<p>28)innodb_lock_wait_timeout</p>
<ul>
<li><p>推荐设置：60</p>
</li>
<li><p>作用：我们一般会碰到，mysql innodb_lock_wait_timeout这个错，这个错是慢sql导致，<br>它代表的是慢sql的事务锁超过了mysql锁超时的设置了。默认这个值为：50s，这个值是可以动态改变的，我不建议去改这个值，因为一个sql能达50s这得多夸张？</p>
<p>动态改变命令如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> <span class="keyword">VARIABLES</span> <span class="keyword">LIKE</span> <span class="string">'innodb_lock_wait_timeout'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> innodb_lock_wait_timeout=<span class="number">500</span>;</span><br></pre></td></tr></table></figure>
<p>把它设成60s足够了。</p>
</li>
<li><p>如果不配的后果：默认为50s</p>
</li>
<li><p>配置实例：innodb_lock_wait_timeout = 60</p>
</li>
</ul>
<h2 id="29-innodb-io-capacity-max"><a href="#29-innodb-io-capacity-max" class="headerlink" title="29)innodb_io_capacity_max"></a>29)innodb_io_capacity_max</h2><ul>
<li><p>推荐设置：8000</p>
</li>
<li><p>作用：这个值很重要，它对读无效，对写很有决定意义。</p>
<p>它会直接决定mysql的tps（吞吐性能），这边给出参考：sata/sas硬盘这个值在200. sas raid10: 2000，ssd硬盘：8000， fusion-io（闪存卡）：25,000-50,000</p>
<p>本调优基于的是ssd，此值设置为8000，笔者上一家公司互联网金融是把一整个mysql扔到了闪存卡里的，因此设置的值为：50,000. 需要根据paas或者是ias的vm的硬盘性号来定</p>
</li>
<li><p>如果不配的后果：默认为200，系统吞吐上不去。</p>
</li>
<li><p>配置实例：innodb_io_capacity_max = 8000</p>
</li>
</ul>
<h2 id="30-innodb-io-capacity"><a href="#30-innodb-io-capacity" class="headerlink" title="30)innodb_io_capacity"></a>30)innodb_io_capacity</h2><p>它是io_capacity_max的一半，同样，它对读无效对写有决定意义。</p>
<ul>
<li>配置实例：innodb_io_capacity_max = 4000</li>
</ul>
<h2 id="31-innodb-flush-method"><a href="#31-innodb-flush-method" class="headerlink" title="31)innodb_flush_method"></a>31)innodb_flush_method</h2><ul>
<li><p>推荐设置：O_DIRECT</p>
</li>
<li><p>作用：推荐使用O_DIRECT。让我们一起来理解一下，它有3种模式去刷数据文件与redo log的buffer：</p>
<ul>
<li><p>1）fdatasync 写数据时，write这一步并不需要真正写到磁盘才算完成（可能写入到操作系统buffer中就会返回完成），真正完成是flush操作，buffer交给操作系统去flush,并且文件的元数据信息也都需要更新到磁盘。</p>
<p>fsync(int fd)函数，该函数作用是flush时将与fd文件描述符所指文件有关的buffer刷写到磁盘，并且flush完元数据信息(比如修改日期、创建日期等)才算flush成功。它对磁盘的io读写会很频繁.</p>
</li>
<li><p>2) O_DSYNC 写日志操作是在write这步完成，而数据文件的写入是在flush这步通过fsync完成</p>
</li>
<li><p>3）O_DIRECT则表示我们的write操作是从mysql innodb buffer里直接向磁盘上写，它会充分利用缓存<br>O_DIRECT模式的free内存下降比较慢，因为它是据文件的写入操作是直接从mysql innodb buffer到磁盘的，并不用通过操作系统的缓冲，而真正的完成也是在flush这步,日志还是要经过OS缓冲，O_DIRECT在SQL吞吐能力上较好。<br><img data-src="https://img-blog.csdn.net/20170525170219701?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc21vb3RoMDA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
</li>
</ul>
</li>
<li><p>如果不配的后果：它的默认值为fdatasync。</p>
</li>
<li><p>配置实例：innodb_flush_method = O_DIRECT</p>
</li>
</ul>
<h2 id="32-innodb-file-format"><a href="#32-innodb-file-format" class="headerlink" title="32)innodb_file_format"></a>32)innodb_file_format</h2><ul>
<li><p>推荐设置：Barracuda</p>
</li>
<li><p>作用：推荐使用Barracuda模式,它是启用表压缩用的，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`test_1`</span> (</span><br><span class="line"></span><br><span class="line"><span class="string">`x`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span></span><br><span class="line"></span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=<span class="number">8</span>;</span><br></pre></td></tr></table></figure>

<p>建完后可以通过：<code>show table status like &#39;test_1&#39;;</code>来查看是否已经启用了表压缩了。</p>
<p>innodb_file_format有这么几种模式：</p>
<p>Antelope-羚羊模式，支持Redundant（冗余）、Compact（紧凑）模式</p>
<p>Barracuda-梭子鱼,是InnoDB Plugin支持的文件格式，在原来的基础上新增了两种数据表格式的支持：Dynamic 和 Compressed</p>
<p>因此我推荐使用：Barracude模式，因为它可以兼容其它数据模式。</p>
<p>它也可以在运行时动态改变：<code>SET GLOBAL innodb_file_format_max = barracuda;</code></p>
</li>
<li><p>如果不配的后果：它默认使用的是叫“联合模式”，即不是棱子鱼也不是羚羊。</p>
</li>
<li><p>配置实例：innodb_file_format = Barracuda</p>
</li>
</ul>
<h2 id="33-innodb-file-format-max"><a href="#33-innodb-file-format-max" class="headerlink" title="33)innodb_file_format_max"></a>33)innodb_file_format_max</h2><p>这个参数必须和innodb_file_format参数一致，一定记住，要不然不生效。</p>
<h2 id="34-innodb-log-group-home-dir-redolog"><a href="#34-innodb-log-group-home-dir-redolog" class="headerlink" title="34)innodb_log_group_home_dir = /redolog/"></a>34)innodb_log_group_home_dir = /redolog/</h2><p>这个就不用解释了，太傻瓜了。这种路径的都可由运维决定，记得挂在大磁盘下。</p>
<h2 id="35-innodb-undo-directory-undolog"><a href="#35-innodb-undo-directory-undolog" class="headerlink" title="35)innodb_undo_directory = /undolog/"></a>35)innodb_undo_directory = /undolog/</h2><p>这个就不用解释了，太傻瓜了。这种路径的都可由运维决定，记得挂在大磁盘下。</p>
<h2 id="36-innodb-undo-logs-128"><a href="#36-innodb-undo-logs-128" class="headerlink" title="36)innodb_undo_logs = 128"></a>36)innodb_undo_logs = 128</h2><ul>
<li><p>推荐设置：128</p>
</li>
<li><p>作用：指定回滚段的个数（早期版本该参数名字是innodb_rollback_segments），默认128个。每个回滚段可同时支持1024个在线事务。这些回滚段会平均分布到各个undo表空间中。该变量可以动态调整，但是物理上的回滚段不会减少，只是会控制用到的回滚段的个数。现在SSD非常普及。innodb_undo_logs可以默认为128不变。</p>
</li>
<li><p>如果不配的后果：默认就是128</p>
</li>
<li><p>配置实例：innodb_undo_logs = 128</p>
</li>
</ul>
<h2 id="37-innodb-undo-tablespaces"><a href="#37-innodb-undo-tablespaces" class="headerlink" title="37)innodb_undo_tablespaces"></a>37)innodb_undo_tablespaces</h2><ul>
<li><p>推荐设置：3</p>
</li>
<li><p>作用：推荐：3，默认为3<br>定单独存放的undo表空间个数，例如如果设置为3，则undo表空间为undo001、undo002、undo003，每个文件初始大小默认为10M。该参数我们推荐设置为大于等于3，更多的碎片文件会影响磁盘的io性能，而不够碎片同样影响mysql的吞吐率，在ssd上一般最佳的配置在3.</p>
<p>如果只有1个undo表空间，那么整个系统在此过程中将处于不可用状态。为了尽可能降低truncate对系统的影响，建议将该参数最少设置为3；</p>
</li>
<li><p>如果不配的后果：默认为：3</p>
</li>
<li><p>配置实例：innodb_undo_tablespaces = 3</p>
</li>
</ul>
<h2 id="38-innodb-flush-neighbors"><a href="#38-innodb-flush-neighbors" class="headerlink" title="38)innodb_flush_neighbors"></a>38)innodb_flush_neighbors</h2><ul>
<li><p>推荐设置：推荐为：0</p>
</li>
<li><p>作用：这个参数很要紧，目前在ssd盛行的情况下我们都把它设为0（不开启），如果你设置成了1即开启（默认状态）InnoDB就会刷新一个extent中的所有页面，因为SSD在随机IO上没有额外负载，所以不需要启用该特性，开启了反而多此一句。下面给出一段mysql5.7源码编译前程序员看的readme里的一句话：</p>
<p>This new default changes MySQL to cater for SSDs and fast storage devices by default. We expect that for the majority of users, this will result in a small performance gain. Users who are using slower hard drives may see a performance loss, and are encouraged to revert to the previous defaults by setting innodb_flush_neighbors=1.</p>
</li>
<li><p>如果不配的后果：它的默认是1，不是0.这个参数对机械硬盘来说很有效，可以减少随机io，增加性能。如果是ssd类磁盘，建议设置为0，可以更快的刷新脏页。如果你把它设为1同时又是ssd那就显得没必要了。这边普及一下小知识，如果你装过8.0，你可以去看一下，8.0已经把这个默认值设为0了。</p>
</li>
<li><p>配置实例：innodb_flush_neighbors = 0</p>
</li>
</ul>
<h2 id="39-innodb-log-file-size"><a href="#39-innodb-log-file-size" class="headerlink" title="39)innodb_log_file_size"></a>39)innodb_log_file_size</h2><ul>
<li><p>推荐设置：</p>
<ul>
<li><p>第1步：<code>show engine innodb status;</code></p>
<p>得到：</p>
<p>Log sequence number 2944118284</p>
<p>Log flushed up to 2944118283</p>
<p>Last checkpoint at 2724318261</p>
</li>
<li><p>第2步：设innodb_log_file_size=Log sequence number-last checkpoint at=select (2944118284-2724318261)/1024/1024; =209M</p>
</li>
<li><p>第3步：设真正的innodb_log_file_size&lt;=(innodb_log_files_in_group<em>innodb_log_file_size)</em>0.75,innodb_log_files_in_group为2（默认），得：</p>
</li>
<li><p>第4步：select 209/(2*0.75); =139.33即：139m，此时可把这个值设为140M</p>
</li>
</ul>
</li>
<li><p>作用：这个值的默认为5M，是远远不够的，在安装完mysql时需要尽快的修改这个值。</p>
<p>如果对 Innodb 数据表有大量的写入操作，那么选择合适的 innodb_log_file_size 值对提升MySQL性能很重要。然而设置太大了，就会增加恢复的时间，因此在MySQL崩溃或者突然断电等情况会令MySQL服务器花很长时间来恢复。</p>
<p>而这个值是没有一个绝对的概念的，MySQL的InnoDB 存储引擎使用一个指定大小的Redo log空间（一个环形的数据结构）。Redo log的空间通过innodb_log_file_size和innodb_log_files_in_group（默认2）参数来调节。</p>
<p>将这俩参数相乘即可得到总的可用Redo log 空间。尽管技术上并不关心你是通过innodb_log_file_size还是innodb_log_files_in_group来调整Redo log空间，不过多数情况下还是通过innodb_log_file_size 来调节。</p>
<p>为InnoDB引擎设置合适的Redo log空间对于写敏感的工作负载来说是非常重要的。然而，这项工作是要做出权衡的。你配置的Redo空间越大，InnoDB就能更好的优化写操作；然而，增大Redo空间也意味着更长的恢复时间当出现崩溃或掉电等意外时。</p>
<p>我们是通过“测试”得到，怎么测试下面给出方法论：一般情况下我们可以按照每1GB的Redo log的恢复时间大约在5分钟左右来估算。如果恢复时间对于你的使用环境来说很重要，我建议你做一些模拟测试，在正常工作负载下（预热完毕后）模拟系统崩溃，来评估更准确的恢复时间。你可以安装 Percona Monitoring and Management，在该pmm的percona monitoring and management图表中，主要看：</p>
<ul>
<li><p>1）Uncheckpointed Bytes ，如果它已经非常接近 Max Checkpoint Age，那么你几乎可以确定当前的 innodb_log_file_size 值因为太小已经某种程度上限制了系统性能。增加该值可以较为显著的提升系统性能。</p>
</li>
<li><p>2）Uncheckpointed Bytes 远小于 Max Checkpoint Age，这种情况下再增加 innodb_log_file_size 就不会有明显性能提升。</p>
</li>
</ul>
<p>在调整完log_file_size后我们再到pmm中去看：Redo Log空间指标，比如说我们看到了1小时内有60g数据被写入日志文件，差不多就是每10分钟会有10g数据在进行“写日志“，我们需要牢牢记得，这个”写日日土已“的时间拖得越久、出现的频次越少就越有助于mysql的innodb的性能。因此这个值没有绝对推荐。如果你没有pmm，那么我们来人肉算，在上面我已经给出了人肉算的详细例子！</p>
</li>
<li><p>如果不配的后果：默认是5M，这是肯定不够的。</p>
</li>
<li><p>配置实例：innodb_log_file_size = 140M</p>
</li>
</ul>
<h2 id="40-innodb-log-buffer-size"><a href="#40-innodb-log-buffer-size" class="headerlink" title="40)innodb_log_buffer_size"></a>40)innodb_log_buffer_size</h2><ul>
<li><p>推荐设置：16777216</p>
</li>
<li><p>作用：对于较小的innodb_buffer_pool_size，我们会把它设成和innodb_buffer_pool_size一样。<br>而当超过4gb的innodb_buffer_pool_size时，我们的建议是把它切的够碎，这是mysql5.7里新带的特性，它的默认在8m，但是对于大量有事务操作的mysql我们推荐在写操作库上设置：16m</p>
<p>此参数确定写日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，但意外的故障将会丢失数据.官方的方档建议设置为1－8M之间！</p>
</li>
<li><p>如果不配的后果：默认是8M</p>
</li>
<li><p>配置实例：innodb_log_buffer_size = 16777216</p>
</li>
</ul>
<h2 id="41-innodb-purge-threads"><a href="#41-innodb-purge-threads" class="headerlink" title="41)innodb_purge_threads"></a>41)innodb_purge_threads</h2><ul>
<li><p>推荐设置：0</p>
</li>
<li><p>作用：这个参数轻易不用的，我推荐它设为：0，为什么呢？这个参数是和innodb_force_recovery关联起来的，只有当数据库崩溃后重启时才会临时去设的。它的使用场景如下：</p>
<p>mysql断电，重启后无效，起不来。所以我们根据innodb_force_recovery的参数：</p>
<ol>
<li><p>(SRV_FORCE_IGNORE_CORRUPT):忽略检查到的corrupt页。</p>
</li>
<li><p>(SRV_FORCE_NO_BACKGROUND):阻止主线程的运行，如主线程需要执行full purge操作，会导致crash。</p>
</li>
<li><p>(SRV_FORCE_NO_TRX_UNDO):不执行事务回滚操作。</p>
</li>
<li><p>(SRV_FORCE_NO_IBUF_MERGE):不执行插入缓冲的合并操作。</p>
</li>
<li><p>(SRV_FORCE_NO_UNDO_LOG_SCAN):不查看重做日志，InnoDB存储引擎会将未提交的事务视为已提交。</p>
</li>
<li><p>(SRV_FORCE_NO_LOG_REDO):不执行前滚的操作。</p>
</li>
</ol>
<p>我们在my.cnf中如下设置：</p>
<p>innodb_force_recovery = 6</p>
<p>innodb_purge_threads = 0</p>
<p>记住，一旦当innodb_force_recovery&gt;2时，要把innodb_purge_threads设成0.</p>
</li>
<li><p>如果不配的后果：默认不要去设，可以不配，出现了问题在recover需要时再去改。</p>
</li>
<li><p>配置实例：innodb_purge_threads = 0</p>
</li>
</ul>
<h2 id="42-innodb-large-prefix"><a href="#42-innodb-large-prefix" class="headerlink" title="42)innodb_large_prefix"></a>42)innodb_large_prefix</h2><p>推荐设置：1</p>
<p>作用：如果你的客户端和服务端的字符集设成了utf8mb4，那么我们需要把这个开关开启，为什么呢？mysql在5.6之前一直都是单列索引限制767，起因是256×3-1。这个3是字符最大占用空间（utf8）。但是在5.6以后，开始支持4个字节的uutf8。255×4&gt;767, 于是增加了这个参数。这个参数默认值是OFF。当改为ON时，允许列索引最大达到3072.<br>  在mysql5.6中这个开关叫on, off。而在5.7中叫0和1，由于我们前面设置了utf8mb4，因此这边我们必须把这个参数开启。</p>
<ul>
<li><p>如果不配的后果：不配会有问题，特别是索引会无效、或者不是走最优计划，如果你的字符集是utf8mb4，那么这个值必开启。</p>
</li>
<li><p>配置实例：innodb_large_prefix = 1</p>
</li>
</ul>
<h2 id="43-innodb-thread-concurrency"><a href="#43-innodb-thread-concurrency" class="headerlink" title="43)innodb_thread_concurrency"></a>43)innodb_thread_concurrency</h2><ul>
<li><p>推荐设置：装mysql的服务器的cpu的核数</p>
</li>
<li><p>作用：如：64核cpu，那么推荐：64（&lt;=cpu核数）<br>如果一个工作负载中，并发用户线程的数量小于等于64，建议设置innodb_thread_concurrency=0;而事实上我们的系统是处于大并发大事务的情况下的，怎么来算这个值？建议是先设置为128，然后我们不断的降这个值，直到发现能够提供最佳性能的线程数。为了安全起间我们会把它设成和cpu一样大小。</p>
</li>
<li><p>如果不配的后果：默认在64位下会是8</p>
</li>
<li><p>配置实例：innodb_thread_concurrency = 64</p>
</li>
</ul>
<h2 id="44-innodb-print-all-deadlocks"><a href="#44-innodb-print-all-deadlocks" class="headerlink" title="44)innodb_print_all_deadlocks"></a>44)innodb_print_all_deadlocks</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：推荐：1 ，当mysql 数据库发生死锁时， innodb status 里面会记录最后一次死锁的相关信息，但mysql 错误日志里面不会记录死锁相关信息，要想记录，启动 innodb_print_all_deadlocks 参数 。</p>
</li>
<li><p>如果不配的后果：不会记录该信息。</p>
</li>
<li><p>配置实例：innodb_print_all_deadlocks = 1</p>
</li>
</ul>
<h2 id="45-innodb-strict-mode"><a href="#45-innodb-strict-mode" class="headerlink" title="45)innodb_strict_mode"></a>45)innodb_strict_mode</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：必须开启，没得选择，1，为什么？<br>从MySQL5.5.X版本开始，你可以开启InnoDB严格检查模式，尤其采用了页数据压缩功能后，最好是开启该功能。开启此功能后，当创建表（CREATE TABLE）、更改表（ALTER TABLE）和创建索引（CREATE INDEX）语句时，如果写法有错误，不会有警告信息，而是直接抛出错误，这样就可直接将问题扼杀在摇篮里。</p>
</li>
<li><p>如果不配的后果：如果不配碰到开发或者非专业的dba会把旧ddl语句生效在5.7内，另外一个问题就是ddl语句出错时报错不明显，这会影响到“主从复制”，至于dll为什么会影响到主从复制，我们后面会在“slave_skip_errors = ddl_exist_errors”中详细解说。</p>
</li>
<li><p>配置实例：innodb_strict_mode = 1</p>
</li>
</ul>
<h2 id="46-log-error"><a href="#46-log-error" class="headerlink" title="46)log_error"></a>46)log_error</h2><p>error log所在位置，这个不用多讲，可以和mysql log放在同一路径下，文件名能够和其它log区分开来。</p>
<h2 id="47-slow-query-log"><a href="#47-slow-query-log" class="headerlink" title="47)slow_query_log"></a>47)slow_query_log</h2><p>建议开启</p>
<h2 id="48-slow-query-log-file"><a href="#48-slow-query-log-file" class="headerlink" title="48)slow_query_log_file"></a>48)slow_query_log_file</h2><p>慢sql所在位置，这个不用多讲，可以和mysql log放在同一路径下，文件名能够和其它log区分开来。</p>
<h2 id="49-log-queries-not-using-indexes-1"><a href="#49-log-queries-not-using-indexes-1" class="headerlink" title="49)log_queries_not_using_indexes=1"></a>49)log_queries_not_using_indexes=1</h2><p>强烈建议开启成1.</p>
<h2 id="50-log-slow-admin-statements-1"><a href="#50-log-slow-admin-statements-1" class="headerlink" title="50)log_slow_admin_statements = 1"></a>50)log_slow_admin_statements = 1</h2><p>强烈建议开启成1.</p>
<h2 id="51-log-slow-slave-statements-1"><a href="#51-log-slow-slave-statements-1" class="headerlink" title="51)log_slow_slave_statements = 1"></a>51)log_slow_slave_statements = 1</h2><p>强烈建议开启成1.</p>
<h2 id="52-log-throttle-queries-not-using-indexes"><a href="#52-log-throttle-queries-not-using-indexes" class="headerlink" title="52)log_throttle_queries_not_using_indexes"></a>52)log_throttle_queries_not_using_indexes</h2><ul>
<li><p>推荐设置：在一开始上线后的初期我们会开成30～50条。随着性能逐渐优化我们会把这个数量开成10.</p>
</li>
<li><p>作用：上线前一段时间会不太稳定，我们发生过近几十条sql没有走index</p>
</li>
<li><p>如果不配的后果：不配不开启，建议开启。</p>
</li>
<li><p>配置实例：log_throttle_queries_not_using_indexes = 50</p>
</li>
</ul>
<h2 id="53-expire-logs-days"><a href="#53-expire-logs-days" class="headerlink" title="53)expire_logs_days"></a>53)expire_logs_days</h2><ul>
<li><p>推荐设置：30</p>
</li>
<li><p>作用：这个值不能太大，因为你不是土豪，不能让binlog无限占用你的磁盘空间，记得这个值一旦设小，你需要做好binlog备份策略，30这个值就是30天，前提是你的binlog的备份做的有效且不占用mysql的磁盘空间。</p>
</li>
<li><p>如果不配的后果：默认是0，即永不过期。</p>
</li>
<li><p>配置实例：expire_logs_days = 30</p>
</li>
</ul>
<h2 id="54-long-query-time"><a href="#54-long-query-time" class="headerlink" title="54)long_query_time"></a>54)long_query_time</h2><ul>
<li><p>推荐设置：10</p>
</li>
<li><p>作用：默认为10秒种，即一切&gt;=10s的sql都会被记录。我建议在开始刚上线期设成10（用默认值），越着慢sql调优越来越好，可以把这个值设成1.因为秒数越低，记录的sql越多，记录越多，也会造成mysql过慢。<br>另外不能完全依赖于mysql的慢sql log，而是应该布署druid sql实时查看器或者是apm或者是专业的慢sql实时查询器。</p>
</li>
<li><p>如果不配的后果：默认为10</p>
</li>
<li><p>配置实例：long_query_time = 10</p>
</li>
</ul>
<h2 id="55-min-examined-row-limit"><a href="#55-min-examined-row-limit" class="headerlink" title="55)min_examined_row_limit"></a>55)min_examined_row_limit</h2><ul>
<li><p>推荐设置：100</p>
</li>
<li><p>作用：这个值配合着慢查询sql记录用，指定为少于该值的行的查询就算慢sql不被记录成”慢sql日志“。</p>
</li>
<li><p>如果不配的后果：不开启的话以慢sql的long_query_time为优先规则。</p>
</li>
<li><p>配置实例：min_examined_row_limit = 100</p>
</li>
</ul>
<h2 id="56-master-info-repository"><a href="#56-master-info-repository" class="headerlink" title="56)master_info_repository"></a>56)master_info_repository</h2><ul>
<li><p>推荐设置：TABLE</p>
</li>
<li><p>作用：主从复制时用，推荐TABLE.<br>从机保存主节点信息方式，设成file时 会生成master.info 和 relay-log.info 2个文件，设成table，信息就会存在mysql.master_slave_info表中。不管是设置的哪种值，都不要移动或者编辑相关的文件和表。</p>
</li>
<li><p>如果不配的后果：不配的话默认存成file格式。</p>
</li>
<li><p>配置实例：master_info_repository = TABLE</p>
</li>
</ul>
<h2 id="57-relay-log-info-repository"><a href="#57-relay-log-info-repository" class="headerlink" title="57)relay_log_info_repository"></a>57)relay_log_info_repository</h2><ul>
<li><p>推荐设置：TABLE</p>
</li>
<li><p>作用：主从复制时用，推荐TABLE.</p>
<p>这个参数和上面的master_info_repository必须保持一致，要不然mysql实例启不起来。</p>
<p>不过需要注意的是，这几个table默认用的是myIsAM引擎，要开启成TABLE模式的话一定记得把这两个表的引擎改成innodb</p>
<p>alter table slave_master_info engine=innodb;<br>alter table slave_relay_log_info engine=innodb;<br>alter table slave_worker_info engine=innodb;</p>
</li>
<li><p>如果不配的后果：</p>
<p>这个参数和上面的master_info_repository必须保持一致，要不然mysql实例启不起来</p>
</li>
<li><p>配置实例：relay_log_info_repository = TABLE</p>
</li>
</ul>
<h2 id="58-log-bin-bin-log"><a href="#58-log-bin-bin-log" class="headerlink" title="58)log_bin = bin.log"></a>58)log_bin = bin.log</h2><p>主从复制时用，主从复制下的bin.log日志所在文件夹。</p>
<h2 id="59-sync-binlog"><a href="#59-sync-binlog" class="headerlink" title="59)sync_binlog"></a>59)sync_binlog</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：主从复制时用，这个值是要看业务的，它可以有0，1，非零共3种设置方式。</p>
<ul>
<li><p>1）0-代表mysql不控制写binlog的时间，由file system自由去控制，此时的mysql的并发性达到最好，但是一旦系统崩溃你会丢失很多还会写入binlog的数据（比如说你正在删数据和更新数据）</p>
</li>
<li><p>2）1-最安全，你最多丢掉一个事务或者是一条语句，但是此时它的性能很差，此参数设为0或者是1之间的性能能差4～5倍。</p>
</li>
<li><p>3）如果你用的是万兆光纤高速磁盘像或者是ssd同时data和binlog都放在一个目录下的同时你要为了安全可以开启成1.</p>
</li>
</ul>
</li>
<li><p>如果不配的后果：默认为0</p>
</li>
<li><p>配置实例：sync_binlog = 1</p>
</li>
</ul>
<h2 id="60-gtid-mode"><a href="#60-gtid-mode" class="headerlink" title="60)gtid_mode"></a>60)gtid_mode</h2><ul>
<li><p>推荐设置：on</p>
</li>
<li><p>作用：主从复制时用，推荐开启成on，它的用处就是允许你在从库上进行”备份“，从库上在进行备份时它能够获取主库的binlog位点。<br>该参数也可以动态在线设定。如果你要在线运行时设定，在my.cnf文件中必须把它设成on。在开启该参数时，log-bin和log-slave-updates也必须开启，否则MySQL Server拒绝启动，当开启GTID模式时，集群中的全部MySQL Server必须同时配置gtid_mod = ON，否则无法同步。</p>
</li>
<li><p>如果不配的后果：默认为off</p>
</li>
<li><p>配置实例：gtid_mode = on</p>
</li>
</ul>
<h2 id="61-enforce-gtid-consistency"><a href="#61-enforce-gtid-consistency" class="headerlink" title="61)enforce_gtid_consistency"></a>61)enforce_gtid_consistency</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：主从复制时用，见gtid_mode，这是牵连参数，随着gtid_mode的开启一起开启。</p>
</li>
<li><p>如果不配的后果：必须跟着gtid_mode一起开启，要不然mysql实例起不来。</p>
</li>
<li><p>配置实例：enforce_gtid_consistency = 1</p>
</li>
</ul>
<h2 id="62-log-slave-updates"><a href="#62-log-slave-updates" class="headerlink" title="62)log_slave_updates"></a>62)log_slave_updates</h2><ul>
<li><p>推荐设置：它只要标注在my.cnf里就代表起作用了。</p>
</li>
<li><p>作用：主从复制时用，见gtid_mode，这是牵连参数，随着gtid_mode的开启一起开启。它只要标注在这就可以了，代表开启，否则也就不要有这一行了。</p>
</li>
<li><p>如果不配的后果：它是牵连参数，随着gtid_mode的开启一起开启。</p>
</li>
<li><p>配置实例：log_slave_updates</p>
</li>
</ul>
<h2 id="63-binlog-format"><a href="#63-binlog-format" class="headerlink" title="63)binlog_format"></a>63)binlog_format</h2><ul>
<li><p>推荐设置：row</p>
</li>
<li><p>作用：主从复制时用，mysql5.7有3种bin log模式：</p>
<ol>
<li><p>STATEMENT：历史悠久，技术成熟,binlog文件较小,binlog中包含了所有数据库更改信息，可以据此来审核数据库的安全等情况。binlog可以用于实时的还原，而不仅仅用于复制主从版本可以不一样，从服务器版本可以比主服务器版本高。缺点是：不是所有的UPDATE语句都能被复制，尤其是包含不确定操作的时候。调用具有不确定因素的 UDF 时复制也可能出问题，使用以下函数的语句也无法被复制：</p>
<ul>
<li><p>LOAD_FILE()</p>
</li>
<li><p>UUID()</p>
</li>
<li><p>USER()</p>
</li>
<li><p>FOUND_ROWS()</p>
</li>
<li><p>SYSDATE() (除非启动时启用了 –sysdate-is-now 选项)</p>
</li>
</ul>
<p>同时，INSERT … SELECT 会产生比 ROW 更多的行级锁，复制需要进行全表扫描(WHERE 语句中没有使用到索引)的 UPDATE 时，需要比 RBR 请求更多的行级锁</p>
<p>对于有 AUTO_INCREMENT 字段的 InnoDB表而言，INSERT 语句会阻塞其他 INSERT 语句，对于一些复杂的语句，在从服务器上的耗资源情况会更严重，而 RBR 模式下，只会对那个发生变化的记录产生影响，存储函数(不是存储过程)在被调用的同时也会执行一次 NOW() 函数，这个可以说是坏事也可能是好事，确定了的 UDF 也需要在从服务器上执行，数据表必须几乎和主服务器保持一致才行，否则可能会导致复制出错，执行复杂语句如果出错的话，会消耗更多资源。</p>
</li>
<li><p>ROW：任何情况都可以被复制，这对复制来说是最安全可靠的，和其他大多数数据库系统的复制技术一样。多数情况下，从服务器上的表如果有主键的话，复制就会快了很多。复制以下几种语句时的行锁更少：</p>
<ul>
<li><p>INSERT … SELECT</p>
</li>
<li><p>包含 AUTO_INCREMENT 字段的 INSERT</p>
</li>
<li><p>没有附带条件或者并没有修改很多记录的 UPDATE 或 DELETE 语句</p>
</li>
</ul>
</li>
</ol>
<p>执行 INSERT，UPDATE，DELETE 语句时锁更少，从服务器上采用多线程来执行复制成为可能，它的缺点是：inlog 大了很多，复杂的回滚时 binlog 中会包含大量的数据，主服务器上执行 UPDATE 语句时，所有发生变化的记录都会写到 binlog 中，而 SBR 只会写一次，这会导致频繁发生 binlog 的并发写问题，UDF 产生的大 BLOB 值会导致复制变慢，无法从 binlog 中看到都复制了写什么语句。</p>
<p>从安全和稳定性的缩合考虑上来说我们选择ROW模式。</p>
<ol start="3">
<li>混合式-不推荐</li>
</ol>
</li>
<li><p>如果不配的后果：5.7.6之前默认为STATEMENT模式。MySQL 5.7.7之后默认为ROW模式</p>
</li>
<li><p>配置实例：binlog_format = row</p>
</li>
</ul>
<h2 id="64-relay-log"><a href="#64-relay-log" class="headerlink" title="64)relay_log"></a>64)relay_log</h2><p>主从复制用，定义relay_log的位置和名称，如果值为空，则默认位置在数据文件的目录（datadir），文件名为host_name-relay-bin.nnnnnn（By default, relay log file names have the form host_name-relay-bin.nnnnnn in the data directory）</p>
<h2 id="65-relay-log-recovery"><a href="#65-relay-log-recovery" class="headerlink" title="65)relay_log_recovery"></a>65)relay_log_recovery</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：主从复制用，推荐值为1，建议打开。<br>当slave从库宕机后，假如relay-log损坏了，导致一部分中继日志没有处理，则自动放弃所有未执行的relay-log，并且重新从master上获取日志，这样就保证了relay-log的完整性。默认情况下该功能是关闭的，将relay_log_recovery的值设置为 1时，可在slave从库上开启该功能，建议开启。</p>
</li>
<li><p>如果不配的后果：默认情况下是关闭的。</p>
</li>
<li><p>配置实例：relay_log_recovery = 1</p>
</li>
</ul>
<h2 id="66-slave-skip-errors"><a href="#66-slave-skip-errors" class="headerlink" title="66)slave_skip_errors"></a>66)slave_skip_errors</h2><ul>
<li><p>推荐设置：ddl_exist_errors</p>
</li>
<li><p>作用：主从复制用，推荐值：ddl_exist_errors。理论上我们不应该设置这个值的。即它在my.cnf文件中应该是消失的或者是这样的表示的：</p>
<p>#slave_skip_errors = ddl_exist_errors</p>
<p>但是有时我们的一些表（特别是不熟悉mysql的一些开发）真的是用的是mysql5.6旧版的建表语句，这个问题在平时单机模式下很难发现，一旦主从结构一上后，在5.7上真的是有一定机率（有10%-20%的机率）碰到ddl语句是旧版mysql而运行在mysql5.7上，这时在主从复制时会抛一个无法主从复制的错，那么这时我们需要抓数据，表已经建好了，这个影响不大、微乎其微，因此我们可以把它设成”忽略“。这个是本人的吐血经验，为什么要提这个梗。。。你们懂的。</p>
</li>
<li><p>如果不配的后果：如果因为建表语句和mysql5.7有冲突时在单实例模式下mysql运行时不会发现，在主从复制时如果没有设跳过值，一旦发生，会影响主从复制，表现就是：主从复制失败。</p>
</li>
<li><p>配置实例：slave_skip_errors = ddl_exist_errors</p>
</li>
</ul>
<h2 id="67-innodb-buffer-pool-dump-pct"><a href="#67-innodb-buffer-pool-dump-pct" class="headerlink" title="67)innodb_buffer_pool_dump_pct"></a>67)innodb_buffer_pool_dump_pct</h2><ul>
<li><p>推荐设置：25~40</p>
</li>
<li><p>作用：锦上添花的值，非必要，这边给出一些best practice:<br>通常来说我们会设成25%。对于大并发前提下我们会使用40这个值，这个值越大，mysql启动时间越长。它是你的innodb_buffer_pool_size的百分比！</p>
<p>MySQL默认在InnoDB缓冲池（而不是整个缓冲池）中仅保留最频繁访问页的25%。请注意，这个变量是基于内存中的实际数据量，而不是缓冲池的大小。例如，如果有100GB的缓冲池，但只有10GB的数据，默认只有10GB的25%（即2.5GB）数据保存在内存中。</p>
<p>在多数使用场景下，合理的选择是：保留最有用的数据页，比加载所有的页(很多页可能在后续的工作中并没有访问到)在缓冲池中要更快。你可以更改innodb_buffer_pool_dump_pct变量的值。</p>
</li>
<li><p>如果不配的后果：不配的话不生效。</p>
</li>
<li><p>配置实例：innodb_buffer_pool_dump_pct=25</p>
</li>
</ul>
<h2 id="68-innodb-page-cleaners-8"><a href="#68-innodb-page-cleaners-8" class="headerlink" title="68)innodb_page_cleaners=8"></a>68)innodb_page_cleaners=8</h2><p>这值一般会在主从延迟的情况下会去设，它的值最好是=innodb_buffer_pool_instance的值，它就是cpu的核数。</p>
<h2 id="69-innodb-undo-log-truncate"><a href="#69-innodb-undo-log-truncate" class="headerlink" title="69)innodb_undo_log_truncate"></a>69)innodb_undo_log_truncate</h2><ul>
<li><p>推荐设置：1</p>
</li>
<li><p>作用：建议开启，设为1<br>innodb_undo_log_truncate参数设置为1，即开启在线回收（收缩）undo log日志文件，支持动态设置。</p>
</li>
<li><p>如果不配的后果：不配的话是不生效的。</p>
</li>
<li><p>配置实例：innodb_undo_log_truncate=1</p>
</li>
</ul>
<h2 id="70-innodb-max-undo-log-size"><a href="#70-innodb-max-undo-log-size" class="headerlink" title="70)innodb_max_undo_log_size"></a>70)innodb_max_undo_log_size</h2><ul>
<li><p>推荐设置：推荐在默认值的2倍（默认为1GB）</p>
</li>
<li><p>作用：推荐在默认值的2倍（默认为1GB），一般我们不会轻易去设它。</p>
<p>这个值和innodb_undo_tablespaces、innodb_undo_logs以及innodb_purge_rseg_truncate_frequency有关，这4个值是互相有牵连的。</p>
<ul>
<li><p>1）innodb_undo_tablespaces必须为&gt;=3</p>
</li>
<li><p>2）innodb_undo_logs必须开启</p>
</li>
<li><p>3）innodb_purge_rseg_truncate_frequence必须开启</p>
</li>
</ul>
</li>
<li><p>如果不配的后果：系统按照1GB来计算。</p>
</li>
<li><p>配置实例：innodb_max_undo_log_size=2G</p>
</li>
</ul>
<h2 id="71-innodb-purge-rseg-truncate-frequency"><a href="#71-innodb-purge-rseg-truncate-frequency" class="headerlink" title="71)innodb_purge_rseg_truncate_frequency"></a>71)innodb_purge_rseg_truncate_frequency</h2><ul>
<li><p>推荐设置：128</p>
</li>
<li><p>作用：默认值在128，这个值不太会去碰。控制回收undo log的频率。 指定purge操作被唤起多少次之后才释放rollback segments。当undo表空间里面的rollback segments被释放时，undo表空间才会被truncate。由此可见，该参数越小，undo表空间被尝试truncate的频率越高。</p>
</li>
<li><p>如果不配的后果：系统默认按照：128去设定。</p>
</li>
<li><p>配置实例：innodb_purge_rseg_truncate_frequency=128</p>
</li>
</ul>
<h2 id="72-binlog-gtid-simple-recovery"><a href="#72-binlog-gtid-simple-recovery" class="headerlink" title="72)binlog_gtid_simple_recovery"></a>72)binlog_gtid_simple_recovery</h2><ul>
<li><p>推荐设置：建议开启</p>
</li>
<li><p>作用：前提是你的mysql必须&gt;5.7.6，否则要设为关闭。<br>这个参数控制了当mysql启动或重启时，mysql在搜寻GTIDs时是如何迭代使用binlog文件的。</p>
<p>这个选项设置为真，会提升mysql执行恢复的性能。因为这样mysql-server启动和binlog日志清理更快。该参数为真时，mysql-server只需打开最老的和最新的这2个binlog文件。</p>
</li>
<li><p>如果不配的后果：默认为0</p>
</li>
<li><p>配置实例：binlog_gtid_simple_recovery=1</p>
</li>
</ul>
<h2 id="73-log-timestamps"><a href="#73-log-timestamps" class="headerlink" title="73)log_timestamps"></a>73)log_timestamps</h2><ul>
<li><p>推荐设置：system</p>
</li>
<li><p>作用：推荐使用:system<br>这个参数主要是控制错误日志、慢查询日志等日志中的显示时间。但它不会影响查询日志和慢日志写到表 (mysql.general_log, mysql.slow_log) 中的显示时间，此参数是全局的，可以动态修改。</p>
</li>
<li><p>如果不配的后果：默认值为:UTC</p>
</li>
<li><p>配置实例：log_timestamps=system</p>
</li>
</ul>
<h2 id="74-transaction-write-set-extraction"><a href="#74-transaction-write-set-extraction" class="headerlink" title="74)transaction_write_set_extraction"></a>74)transaction_write_set_extraction</h2><ul>
<li><p>推荐设置：这个值不需要去设，因为你用的不是mysql8.0，在5.7.6版以后这个制不是很成熟，如果要开启一般会使用：XXHASH64.</p>
</li>
<li><p>作用：这个值是基于group(并行）复制用的，推荐值为：XXHASH64，如果没有开启基于group（并行）的复制千万不要去设这个参数，设都不用去设，保持默认就可以了。</p>
</li>
<li><p>如果不配的后果：默认为off状态，即不生效。</p>
</li>
<li><p>配置实例：<br>transaction_write_set_extraction = OFF<br>transaction_write_set_extraction = XXHASH64<br>transaction_write_set_extraction = MURMUR32</p>
</li>
</ul>
<h2 id="75-show-compatibility-56"><a href="#75-show-compatibility-56" class="headerlink" title="75)show_compatibility_56"></a>75)show_compatibility_56</h2><ul>
<li><p>推荐设置：on</p>
</li>
<li><p>作用：推荐打开。这个参数是兼容mysql5.6版的INFORMATION_SCHEMA.GLOBAL_STATUS相关功能的，它有利于从5.6到5.7的过渡时非mysql专职dba但是懂mysql的运维用的。</p>
</li>
<li><p>如果不配的后果：默认是off。相当于严格模式。</p>
</li>
<li><p>配置实例：show_compatibility_56=on</p>
</li>
</ul>
<h1 id="查看数据库-运维SQL"><a href="#查看数据库-运维SQL" class="headerlink" title="查看数据库 运维SQL"></a>查看数据库 运维SQL</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">PROCESSLIST</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> <span class="keyword">status</span> <span class="keyword">like</span> <span class="string">'created_tmp%'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">variables</span> <span class="keyword">like</span> <span class="string">'%max_allowed_packet%'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> <span class="keyword">VARIABLES</span> <span class="keyword">LIKE</span> <span class="string">'innodb_lock_wait_timeout'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> innodb_lock_wait_timeout=<span class="number">500</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">engine</span> <span class="keyword">innodb</span> <span class="keyword">status</span>;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes系列——持久化存储StorageClass</title>
    <url>/k8s/Kubernetes%E7%B3%BB%E5%88%97-%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8StorageClass/</url>
    <content><![CDATA[<div class="note primary">
            <p>学习本节内容前，希望你已经对Kubernetes中PV和PVC的概念有了初步的了解，具体请参考这篇文章：</p><ul><li>[Kubernetes对象之PersistentVolume和PersistentVolumeClaim]</li></ul>
          </div>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>前面的课程中我们学习了 PV 和 PVC 的使用方法，但是前面的 PV 都是静态的，什么意思？<a id="more"></a>就是我要使用的一个 PVC 的话就必须手动去创建一个 PV，我们也说过这种方式在很大程度上并不能满足我们的需求，比如我们有一个应用需要对存储的并发度要求比较高，而另外一个应用对读写速度又要求比较高，特别是对于 StatefulSet 类型的应用简单的来使用静态的 PV 就很不合适了，这种情况下我们就需要用到动态 PV，也就是我们今天要讲解的 StorageClass。</p>
<h1 id="创建-Provisioner"><a href="#创建-Provisioner" class="headerlink" title="创建 Provisioner"></a>创建 Provisioner</h1><p>要使用 StorageClass，我们就得安装对应的自动配置程序，比如我们这里存储后端使用的是 nfs，那么我们就需要使用到一个 nfs-client 的自动配置程序，我们也叫它 Provisioner，这个程序使用我们已经配置好的 nfs 服务器，来自动创建持久卷，也就是自动帮我们创建 PV。</p>
<ul>
<li>自动创建的 PV 以${namespace}-${pvcName}-${pvName}这样的命名格式创建在 NFS 服务器上的共享数据目录中</li>
<li>而当这个 PV 被回收后会以archieved-${namespace}-${pvcName}-${pvName}这样的命名格式存在 NFS 服务器上。</li>
</ul>
<p>当然在部署nfs-client之前，我们需要先成功安装上 nfs 服务器，前面的课程中我们已经过了，服务地址是1192.168.3.131，共享数据目录是/data/k8s/，然后接下来我们部署 nfs-client 即可，我们也可以直接参考nfs-client 的文档，进行安装即可。</p>
<h2 id="第一步：配置-Deployment"><a href="#第一步：配置-Deployment" class="headerlink" title="第一步：配置 Deployment"></a>第一步：配置 Deployment</h2><p>将里面的对应的参数替换成我们自己的 nfs 配置（nfs-client.yaml）</p>
<p>将环境变量 NFS_SERVER 和 NFS_PATH 替换<br>当然也包括下面的 nfs 配置，我们可以看到我们这里使用了一个名为 nfs-client-provisioner 的serviceAccount，所以我们也需要创建一个 sa，然后绑定上对应的权限：（nfs-client-sa.yaml）</p>
<h2 id="第二步：创建account并绑定角色"><a href="#第二步：创建account并绑定角色" class="headerlink" title="第二步：创建account并绑定角色"></a>第二步：创建account并绑定角色</h2><p>我们这里新建的一个名为 nfs-client-provisioner 的ServiceAccount，然后绑定了一个名为 nfs-client-provisioner-runner 的ClusterRole，而该ClusterRole声明了一些权限，其中就包括对persistentvolumes的增、删、改、查等权限，所以我们可以利用该ServiceAccount来自动创建 PV。</p>
<h3 id="第三步-创建storageclass"><a href="#第三步-创建storageclass" class="headerlink" title="第三步 创建storageclass"></a>第三步 创建storageclass</h3><p>nfs-client 的 Deployment 声明完成后，我们就可以来创建一个StorageClass对象了：（nfs-client-class.yaml）</p>
<p>我们声明了一个名为 data-nfs 的StorageClass对象，注意下面的provisioner对应的值一定要和上面的Deployment下面的 PROVISIONER_NAME 这个环境变量的值一样。</p>
<p>现在我们来创建这些资源对象吧：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f nfs-client.yaml</span><br><span class="line">kubectl apply -f nfs-client-sa.yaml</span><br><span class="line">kubectl apply -f nfs-client-class.yaml</span><br></pre></td></tr></table></figure>
<p>创建完成后查看下资源状态：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost nfs]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                                      READY   STATUS              RESTARTS   AGE</span><br><span class="line">nfs-client-provisioner-5db79cb75f-nk952   0/1     ContainerCreating   0          12s</span><br><span class="line"></span><br><span class="line">[root@localhost nfs]<span class="comment"># kubectl get storageclass</span></span><br><span class="line">NAME                 PROVISIONER      AGE</span><br><span class="line">data-nfs             fuseim.pri/ifs   31s</span><br><span class="line">harbor-data          fuseim.pri/ifs   90d</span><br></pre></td></tr></table></figure>
<h1 id="新建-StorageClass"><a href="#新建-StorageClass" class="headerlink" title="新建 StorageClass"></a>新建 StorageClass</h1><p>上面把StorageClass资源对象创建成功了，接下来我们来通过一个示例测试下动态 PV，首先创建一个 PVC 对象：(test-pvc.yaml)</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Mi</span></span><br></pre></td></tr></table></figure>
<p>我们这里声明了一个PVC对象，采用 ReadWriteMany 的访问模式，请求 1Mi 的空间，但是我们可以看到上面的 PVC 文件我们没有标识出任何和 StorageClass 相关联的信息，那么如果我们现在直接创建这个 PVC 对象能够自动绑定上合适的 PV 对象吗？显然是不能的(前提是没有合适的 PV)，我们这里有两种方法可以来利用上面我们创建的 StorageClass 对象来自动帮我们创建一个合适的 PV:</p>
<ul>
<li>第一种方法：在这个PVC对象中添加一个声明StorageClass对象的标识，这里我们可以利用一个annotations属性来标识，如下<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pvc</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">volume.beta.kubernetes.io/storage-class:</span> <span class="string">"data-nfs"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Mi</span></span><br></pre></td></tr></table></figure></li>
<li>第二种方法：我们可以设置这个 data-nfs 的 StorageClass 为 Kubernetes 的默认存储后端，我们可以用kubectl patch命令来更新： yaml $ kubectl patch storageclass data-nfs -p ‘{“metadata”: {“annotations”:{“storageclass.kubernetes.io/is-default-class”:”true”}}}’<br>上面这两种方法都是可以的，当然为了不影响系统的默认行为，我们这里还是采用第一种方法，直接创建即可：</li>
</ul>
<p>上面这两种方法都是可以的，当然为了不影响系统的默认行为，我们这里还是采用第一种方法，直接创建即可：</p>
<p>（注意网络问题 这里需要拉取外网镜像）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f <span class="built_in">test</span>-pvc.yaml</span><br><span class="line">persistentvolumeclaim <span class="string">"test-pvc"</span> created</span><br><span class="line">[root@localhost nfs]<span class="comment"># kubectl get pvc</span></span><br><span class="line">NAME       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS         AGE</span><br><span class="line">pvc-nfs    Bound    pv1                                        1Gi        RWO                                 12h</span><br><span class="line"><span class="built_in">test</span>-pvc   Bound    pvc-a7293619-bb8c-11e9-93e7-000c29ecf8a8   1Mi        RWX            data-nfs   11h</span><br></pre></td></tr></table></figure>
<p>我们可以看到一个名为 test-pvc 的 PVC 对象创建成功了，状态已经是Bound了，是不是也产生了一个对应的VOLUME 对象，最重要的一栏是STORAGECLASS，现在是不是也有值了，就是我们刚刚创建的StorageClass对象 data-nfs。</p>
<p>然后查看下 PV 对象呢：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost nfs]<span class="comment"># kubectl get pv</span></span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM              STORAGECLASS         REASON   AGE</span><br><span class="line">pvc-a7293619-bb8c-11e9-93e7-000c29ecf8a8   1Mi        RWX            Delete           Bound    default/<span class="built_in">test</span>-pvc   data-nfs            3m48s</span><br></pre></td></tr></table></figure>
<p>可以看到是不是自动生成了一个关联的 PV 对象，访问模式是RWX，回收策略是 Delete，这个 PV 对象并不是我们手动创建的吧，这是通过我们上面的 StorageClass 对象自动创建的。这就是 StorageClass 的创建方法。</p>
<h1 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h1><h2 id="创建StorageClass持久化存储"><a href="#创建StorageClass持久化存储" class="headerlink" title="创建StorageClass持久化存储"></a>创建StorageClass持久化存储</h2><p>以NFS 作为后端存储资源，在主节点安装NFS，共享/data/k8s/目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ systemctl stop firewalld.service</span><br><span class="line">$ yum -y install nfs-utils rpcbind</span><br><span class="line">$ mkdir -p /data/k8s</span><br><span class="line">$ chmod 755 /data/k8s</span><br><span class="line">$ vim /etc/exports</span><br><span class="line">/data/k8s  *(rw,sync,no_root_squash)</span><br><span class="line"></span><br><span class="line">$ exportfs -r <span class="comment">#修改生效</span></span><br><span class="line">$ systemctl start rpcbind.service</span><br><span class="line">$ systemctl start nfs-server.service</span><br></pre></td></tr></table></figure>
<ol>
<li>创建 Provisioner，使用nfs-client 的自动配置程序， nfs-client.yaml<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Recreate</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">quay.io/external_storage/nfs-client-provisioner:latest</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">fuseim.pri/ifs</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span></span><br><span class="line">              <span class="attr">value:</span> <span class="number">172.16</span><span class="number">.0</span><span class="number">.12</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">/data/k8s</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span></span><br><span class="line">          <span class="attr">nfs:</span></span><br><span class="line">            <span class="attr">server:</span> <span class="number">172.16</span><span class="number">.0</span><span class="number">.12</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/data/k8s</span></span><br></pre></td></tr></table></figure></li>
<li>创建 sa，然后绑定上对应的权限：（nfs-client-sa.yaml）<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["persistentvolumes"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"create"</span><span class="string">,</span> <span class="string">"delete"</span><span class="string">]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["persistentvolumeclaims"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">["storage.k8s.io"]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["storageclasses"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["events"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["list",</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"create"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">,</span> <span class="string">"patch"</span><span class="string">]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["endpoints"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["create",</span> <span class="string">"delete"</span><span class="string">,</span> <span class="string">"get"</span><span class="string">,</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"patch"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></li>
<li>创建StorageClass，elasticsearch-storageclass.yaml<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">data-db</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">fuseim.pri/ifs</span></span><br></pre></td></tr></table></figure></li>
<li>部署<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl create -f nfs-client.yaml</span><br><span class="line">$ kubectl create -f nfs-client-sa.yaml</span><br><span class="line">$ kubectl create -f elasticsearch-storageclass.yaml </span><br><span class="line">$ kubectl  get pods </span><br><span class="line">NAME                                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">nfs-client-provisioner-5b486d9c65-9fzjz   1/1     Running   9          13d</span><br><span class="line">$ kubectl get storageclass</span><br><span class="line">NAME                PROVISIONER      AGE</span><br><span class="line">data-db          fuseim.pri/ifs   13d</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h1 id="问题处理"><a href="#问题处理" class="headerlink" title="问题处理"></a>问题处理</h1><ol>
<li><p>排查问题命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get events </span><br><span class="line">mount failed: <span class="built_in">exit</span> status 32</span><br><span class="line"></span><br><span class="line">$ kubectl kubectls describe nfs-client-provisioner-5f4c97f67c-jcprd</span><br><span class="line"><span class="comment"># kubectl logs nfs-client-provisioner-5f4c97f67c-jcprd</span></span><br><span class="line"></span><br><span class="line">Warning  Failed     11s (x2 over 16s)  kubelet, 172.16.0.17  Error: Error response from daemon: invalid volume specification: <span class="string">'/var/lib/kubelet/pods/1dadc905-1ebc-408b-ba97-5558c7ed4181/volumes/kubernetes.io~nfs/nfs-client-root:/'</span>: invalid mount config <span class="keyword">for</span> <span class="built_in">type</span> <span class="string">"bind"</span>: invalid specification: destination can<span class="string">'t be '</span>/<span class="string">'</span></span><br></pre></td></tr></table></figure>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">containers:</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span></span><br><span class="line">      <span class="attr">nfs:</span></span><br><span class="line">        <span class="attr">server:</span> <span class="number">172.16</span><span class="number">.0</span><span class="number">.12</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/data/k8s</span></span><br></pre></td></tr></table></figure>
<p>containers.volumeMounts.mountPath 挂载点不对,不能为 / 根目录</p>
</li>
<li><p>mount failed: exit status 32</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mount: wrong fs <span class="built_in">type</span>, bad option, bad superblock on 172.16.0.12:/data/k8s,</span><br><span class="line">       missing codepage or helper program, or other error</span><br><span class="line">       (<span class="keyword">for</span> several filesystems (e.g. nfs, cifs) you might</span><br><span class="line">       need a /sbin/mount.&lt;<span class="built_in">type</span>&gt; helper program)</span><br><span class="line"></span><br><span class="line">       In some cases useful info is found <span class="keyword">in</span> syslog - try</span><br><span class="line">       dmesg | tail or so.</span><br><span class="line">5s          Warning   FailedMount   pod/nfs-client-provisioner-5f4c97f67c-wgbjc   MountVolume.SetUp failed <span class="keyword">for</span> volume <span class="string">"nfs-client-root"</span> : mount failed: <span class="built_in">exit</span> status 32</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li><p>解决方法</p>
<ul>
<li><p>mount 命令查看是否有错误挂载。umount -l /alan</p>
</li>
<li><p>要想成功挂载nfs，必须在kubernetes集群的每个node上安装nfs-utils 或nfs-common。</p>
</li>
<li><p>在创建persistentvolume和persistentvolumeclaim时他们的name必须相同，而且和pod中的spec.containers.volumeMounts.name以及spec.volumes.name，spec.volumes.persistentVolumeClaim.claimName全都相同，此时才能成功挂载，启动Pod。</p>
</li>
</ul>
</li>
</ul>
<p>经过以上，应该就能顺利解决问题了。这不知道算不算是k8s的一个bug，碰到问题在网上找了各种方案都不行，差点想放弃，最后自己经过多次尝试，终于解决了。希望分享出来能够帮助到其他人。</p>
<p>OK，到这里我们大体明白了StorageClass的作用，下一篇我们会实际把它利用起来。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s排查问题命令</title>
    <url>/k8s/k8s%E6%8E%92%E6%9F%A5%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="排查问题命令"><a href="#排查问题命令" class="headerlink" title="排查问题命令"></a>排查问题命令</h1><h2 id="1-kubectl-get-events"><a href="#1-kubectl-get-events" class="headerlink" title="1. kubectl get events"></a>1. kubectl get events</h2><h2 id="2-kubectl-kubectls-describe"><a href="#2-kubectl-kubectls-describe" class="headerlink" title="2. kubectl kubectls describe"></a>2. kubectl kubectls describe</h2><h2 id="3-kubectl-logs"><a href="#3-kubectl-logs" class="headerlink" title="3. kubectl logs"></a>3. kubectl logs</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get events </span><br><span class="line">mount failed: <span class="built_in">exit</span> status 32</span><br><span class="line"></span><br><span class="line">$ kubectl kubectls describe nfs-client-provisioner-5f4c97f67c-jcprd</span><br><span class="line"><span class="comment"># kubectl logs nfs-client-provisioner-5f4c97f67c-jcprd</span></span><br><span class="line"></span><br><span class="line">Warning  Failed     11s (x2 over 16s)  kubelet, 172.16.0.17  Error: Error response from daemon: invalid volume specification: <span class="string">'/var/lib/kubelet/pods/1dadc905-1ebc-408b-ba97-5558c7ed4181/volumes/kubernetes.io~nfs/nfs-client-root:/'</span>: invalid mount config <span class="keyword">for</span> <span class="built_in">type</span> <span class="string">"bind"</span>: invalid specification: destination can<span class="string">'t be '</span>/<span class="string">'</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes部署Ingress-nginx</title>
    <url>/k8s/kubernetes%E9%83%A8%E7%BD%B2Ingress-nginx/</url>
    <content><![CDATA[<h1 id="一、Ingress-简介"><a href="#一、Ingress-简介" class="headerlink" title="一、Ingress 简介"></a>一、Ingress 简介</h1><p>在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。<br>为了使外部的应用能够访问集群内的服务，<br>在Kubernetes 目前 提供了以下几种方案：</p>
<a id="more"></a>
<ul>
<li><p>odePort</p>
</li>
<li><p>oadBalancer</p>
</li>
<li><p>ngress</p>
<h2 id="1-1-Ingress-组成"><a href="#1-1-Ingress-组成" class="headerlink" title="1.1.Ingress 组成"></a>1.1.Ingress 组成</h2></li>
<li><p>ingress controller<br>将新加入的Ingress转化成Nginx的配置文件并使之生效</p>
</li>
<li><p>ingress service<br>将Nginx的配置抽象成一个Ingress对象，每添加一个新的服务只需写一个新的Ingress的yaml文件即可</p>
</li>
</ul>
<h2 id="1-2-Ingress-工作原理"><a href="#1-2-Ingress-工作原理" class="headerlink" title="1.2.Ingress 工作原理"></a>1.2.Ingress 工作原理</h2><ul>
<li><p>ingress controller通过和kubernetes api交互，动态的去感知集群中ingress规则变化，</p>
</li>
<li><p>然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段nginx配置，</p>
</li>
<li><p>再写到nginx-ingress-control的pod里，这个Ingress controller的pod里运行着一个Nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中，</p>
</li>
<li><p>然后reload一下使配置生效。<br>以此达到域名分配置和动态更新的问题。</p>
</li>
</ul>
<h2 id="1-3-Ingress-可以解决什么问题？"><a href="#1-3-Ingress-可以解决什么问题？" class="headerlink" title="1.3.Ingress 可以解决什么问题？"></a>1.3.Ingress 可以解决什么问题？</h2><ul>
<li>动态配置服务<br>如果按照传统方式, 当新增加一个服务时, 我们可能需要在流量入口加一个反向代理指向我们新的k8s服务. 而如果用了Ingress, 只需要配置好这个服务, 当服务启动时, 会自动注册到Ingress的中, 不需要而外的操作.</li>
<li>减少不必要的端口暴露<br>配置过k8s的都清楚, 第一步是要关闭防火墙的, 主要原因是k8s的很多服务会以NodePort方式映射出去, 这样就相当于给宿主机打了很多孔, 既不安全也不优雅. 而Ingress可以避免这个问题, 除了Ingress自身服务可能需要映射出去, 其他服务都不要用NodePort方式</li>
</ul>
<h2 id="1-4-Ingress当前的实现方式？"><a href="#1-4-Ingress当前的实现方式？" class="headerlink" title="1.4. Ingress当前的实现方式？"></a>1.4. Ingress当前的实现方式？</h2><p>本文使用的是基于nginx的ingress<br><img data-src="https://upload-images.jianshu.io/upload_images/13868689-6a3d9f6c3eab8d88?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt=""></p>
<h1 id="二、部署配置Ingress"><a href="#二、部署配置Ingress" class="headerlink" title="二、部署配置Ingress"></a>二、部署配置Ingress</h1><h2 id="2-1-部署文件介绍、准备"><a href="#2-1-部署文件介绍、准备" class="headerlink" title="2.1 部署文件介绍、准备"></a>2.1 部署文件介绍、准备</h2><h3 id="第一步：-获取配置文件位置"><a href="#第一步：-获取配置文件位置" class="headerlink" title="第一步： 获取配置文件位置"></a>第一步： 获取配置文件位置</h3><p><a href="https://github.com/kubernetes/ingress-nginx/tree/nginx-0.20.0/deploy" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx/tree/nginx-0.20.0/deploy</a></p>
<h3 id="第二步：-下载部署文件"><a href="#第二步：-下载部署文件" class="headerlink" title="第二步： 下载部署文件"></a>第二步： 下载部署文件</h3><p>提供了两种方式 ：</p>
<ul>
<li>默认下载最新的yaml</li>
<li>指定版本号下载对应的yaml</li>
</ul>
<ol>
<li><p>默认下载最新的yaml</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget  https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>指定版本号下载对应的yaml<br>如下载ingress-nginx 0.17.0对应的yaml</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget  https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.17.0/deploy/mandatory.yaml</span><br></pre></td></tr></table></figure>
<p><img data-src="https://upload-images.jianshu.io/upload_images/13868689-a0219fe75b7092e0?imageMogr2/auto-orient/strip%7CimageView2/2/w/587/format/webp" alt=""></p>
</li>
</ol>
<h3 id="部署文件介绍"><a href="#部署文件介绍" class="headerlink" title="部署文件介绍"></a>部署文件介绍</h3><ol>
<li>namespace.yaml<br>创建一个独立的命名空间 ingress-nginx</li>
<li>configmap.yaml<br>ConfigMap是存储通用的配置变量的，类似于配置文件，使用户可以将分布式系统中用于不同模块的环境变量统一到一个对象中管理；而它与配置文件的区别在于它是存在集群的“环境”中的，并且支持K8S集群中所有通用的操作调用方式。</li>
</ol>
<p>从数据角度来看，ConfigMap的类型只是键值组，用于存储被Pod或者其他资源对象（如RC）访问的信息。这与secret的设计理念有异曲同工之妙，主要区别在于ConfigMap通常不用于存储敏感信息，而只存储简单的文本信息。</p>
<p>ConfigMap可以保存环境变量的属性，也可以保存配置文件。</p>
<p>创建pod时，对configmap进行绑定，pod内的应用可以直接引用ConfigMap的配置。相当于configmap为应用/运行环境封装配置。</p>
<p>pod使用ConfigMap，通常用于：设置环境变量的值、设置命令行参数、创建配置文件。</p>
<ol start="3">
<li><p>default-backend.yaml<br>如果外界访问的域名不存在的话，则默认转发到default-http-backend这个Service，其会直接返回404：</p>
</li>
<li><p>rbac.yaml<br>负责Ingress的RBAC授权的控制，其创建了Ingress用到的ServiceAccount、ClusterRole、Role、RoleBinding、ClusterRoleBinding</p>
</li>
<li><p>with-rbac.yaml<br>是Ingress的核心，用于创建ingress-controller。前面提到过，ingress-controller的作用是将新加入的Ingress进行转化为Nginx的配置</p>
</li>
</ol>
<h2 id="2-2-部署ingress"><a href="#2-2-部署ingress" class="headerlink" title="2.2 部署ingress"></a>2.2 部署ingress</h2><h3 id="第一步：-准备镜像，从这里mandatory-yaml查看需要哪些镜像"><a href="#第一步：-准备镜像，从这里mandatory-yaml查看需要哪些镜像" class="headerlink" title="第一步： 准备镜像，从这里mandatory.yaml查看需要哪些镜像"></a>第一步： 准备镜像，从这里mandatory.yaml查看需要哪些镜像</h3><p>已经准备好， 可以直接点击下载</p>
<table>
<thead>
<tr>
<th align="left">镜像名称</th>
<th align="center">版本</th>
<th align="left">下载地址</th>
</tr>
</thead>
<tbody><tr>
<td align="left">k8s.gcr.io/defaultbackend-amd64</td>
<td align="center">1.5</td>
<td align="left">registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/defaultbackend-amd64</td>
</tr>
<tr>
<td align="left">quay.io/kubernetes-ingress-controller/nginx-ingress-controller</td>
<td align="center">0.20.0</td>
<td align="left">registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/nginx-ingress-controller</td>
</tr>
</tbody></table>
<p>如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/nginx-ingress-controller:0.20.0</span><br></pre></td></tr></table></figure>
<p>将镜像上传到自己的私有仓库，以供下面的步骤使用。</p>
<h3 id="第二步：-更新mandatory-yaml中的镜像地址"><a href="#第二步：-更新mandatory-yaml中的镜像地址" class="headerlink" title="第二步： 更新mandatory.yaml中的镜像地址"></a>第二步： 更新mandatory.yaml中的镜像地址</h3><p>替换成自己的镜像地址：</p>
<p>替换defaultbackend-amd64镜像地址</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s#k8s.gcr.io/defaultbackend-amd64#registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/defaultbackend-amd64#g'</span> mandatory.yaml</span><br></pre></td></tr></table></figure>
<p>替换nginx-ingress-controller镜像地址</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">'s#quay.io/kubernetes-ingress-controller/nginx-ingress-controller#registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/nginx-ingress-controller#g'</span> mandatory.yaml</span><br></pre></td></tr></table></figure>
<p>第三步： 部署nginx-ingress-controller</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f mandatory.yaml</span><br></pre></td></tr></table></figure>

<p>第四步： 查看ingress-nginx组件状态？<br>查看相关pod状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@master ingress-nginx]<span class="comment"># kubectl get pods -n ingress-nginx -owide</span></span><br><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE     IP              NODE     NOMINATED NODE</span><br><span class="line">default-http-backend-7f594549df-nzthj      1/1     Running   0          3m59s   192.168.1.90    slave1   &lt;none&gt;</span><br><span class="line">nginx-ingress-controller-9fc7f4c5f-dr722   1/1     Running   0          3m59s   192.168.2.110   slave2   &lt;none&gt;</span><br></pre></td></tr></table></figure>
<p>查看service状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@master ingress-nginx]<span class="comment"># kubectl get service -n ingress-nginx</span></span><br><span class="line">NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">default-http-backend   ClusterIP   10.104.146.218   &lt;none&gt;        80/TCP    5m37s</span><br></pre></td></tr></table></figure>

<h1 id="三、测试"><a href="#三、测试" class="headerlink" title="三、测试"></a>三、测试</h1><h2 id="3-1-测试default-http-backend-是否起作用？"><a href="#3-1-测试default-http-backend-是否起作用？" class="headerlink" title="3.1 测试default-http-backend 是否起作用？"></a>3.1 测试default-http-backend 是否起作用？</h2><p>系统自动安装了一个default-http-backend pod， 这是一个缺省的http后端服务， 用于返回404结果.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># curl -i 172.16.0.18:80</span><br><span class="line">default backend - 404</span><br></pre></td></tr></table></figure>

<p>参考文献：<br><a href="https://github.com/kubernetes/ingress-nginx/blob/nginx-0.20.0/docs/deploy/index.md" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx/blob/nginx-0.20.0/docs/deploy/index.md</a><br><a href="https://www.jianshu.com/p/e30b06906b77" target="_blank" rel="noopener">https://www.jianshu.com/p/e30b06906b77</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>yum安装软件的默认路径</title>
    <url>/linux/yum%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E7%9A%84%E9%BB%98%E8%AE%A4%E8%B7%AF%E5%BE%84/</url>
    <content><![CDATA[<h1 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h1><table>
<thead>
<tr>
<th align="left">描述</th>
<th align="left">目录</th>
</tr>
</thead>
</table>
<p>| 可执行文件目录 |     /usr/lib/xxx/bin  |<br>| 数据文件 |     /var/lib/xxx/data |<br>| 配置文件目录     |     /etc/xxx |<br>| 依赖项目录     |     /usr/lib/xxx/lib |<br>| 日志文件     |     /var/log/xxx |<br>| 启动相关的脚本、schema 文件     |     /usr/lib/xxx/releases | </p>
<p>以上目录中，用户经常接触与使用的是 bin、etc、data、log 目录。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>linux常用命令</title>
    <url>/linux/linux-command/</url>
    <content><![CDATA[<h1 id="重点"><a href="#重点" class="headerlink" title="重点"></a>重点</h1><h2 id="1、查看内存缓存使用最多的前20个进程"><a href="#1、查看内存缓存使用最多的前20个进程" class="headerlink" title="1、查看内存缓存使用最多的前20个进程"></a>1、查看内存缓存使用最多的前20个进程</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps auxw|head -1; ps auxw|sort -rn -k5|head -20</span><br></pre></td></tr></table></figure>

<h2 id="2、查看最占内存的进程"><a href="#2、查看最占内存的进程" class="headerlink" title="2、查看最占内存的进程"></a>2、查看最占内存的进程</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps auxw|head -1; ps auxw|sort -rm -k5|head -50</span><br></pre></td></tr></table></figure>

<h2 id="3、查看最占CPU进程"><a href="#3、查看最占CPU进程" class="headerlink" title="3、查看最占CPU进程"></a>3、查看最占CPU进程</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps auxw|head -1; ps auxw|sort -rn -k3|head -50</span><br></pre></td></tr></table></figure>

<h2 id="4、内存信息。-free-、-ps"><a href="#4、内存信息。-free-、-ps" class="headerlink" title="4、内存信息。[free]、[ps]"></a>4、内存信息。[free]、[ps]</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/meminfo</span><br></pre></td></tr></table></figure>

<h2 id="5、进程所在路径："><a href="#5、进程所在路径：" class="headerlink" title="5、进程所在路径："></a>5、进程所在路径：</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps -ef|grep abc.biz</span><br><span class="line">ps -ef|grep abc.biz.jar</span><br></pre></td></tr></table></figure>

<h2 id="6、使用比例升序排序"><a href="#6、使用比例升序排序" class="headerlink" title="6、使用比例升序排序"></a>6、使用比例升序排序</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps auxw --sort=rss		//缓存</span><br><span class="line">ps auxw -- sort=%mem	//内存</span><br><span class="line">ps auxw -- sort=%cpu	//CPU</span><br></pre></td></tr></table></figure>

<h2 id="7、清理缓存"><a href="#7、清理缓存" class="headerlink" title="7、清理缓存"></a>7、清理缓存</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sync <span class="comment"># 1</span></span><br><span class="line"><span class="built_in">echo</span> 3 &gt; /proc/sys/vm/drop_caches <span class="comment">#2</span></span><br></pre></td></tr></table></figure>
<p>当然，这个文件可以设置的值分别为1、2、3。它们所表示的含义为：</p>
<ul>
<li>echo 1 &gt; /proc/sys/vm/drop_caches:表示清除pagecache。</li>
<li>echo 2 &gt; /proc/sys/vm/drop_caches:表示清除回收slab分配器中的对象（包括目录项缓存和inode缓存）。slab分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的pagecache。</li>
<li>echo 3 &gt; /proc/sys/vm/drop_caches:表示清除pagecache和slab分配器中的缓存对象。</li>
</ul>
<h1 id="一、CPU相关、进程"><a href="#一、CPU相关、进程" class="headerlink" title="一、CPU相关、进程"></a>一、CPU相关、进程</h1><p>1、 查看cpu硬件配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">less /proc/cpuinfo</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">uname -a                查看内核/操作系统/CPU信息</span><br><span class="line">head -n 1 /etc/issue    查看操作系统版本</span><br><span class="line">less /proc/cpuinfo      查看CPU信息</span><br><span class="line">hostname                查看计算机名</span><br></pre></td></tr></table></figure>

<p>2、 top  命令</p>
<p>实时显示各种系统资源使用情况及进程状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">详细命令参数：</span><br><span class="line">h: 显示帮助</span><br><span class="line">c：显示详细的命令参数</span><br><span class="line">M：按照占用内存大小（%MEM 列）对进程排序；</span><br><span class="line">P：按照 CPU 使用率( %CPU 列）对进程排序；</span><br><span class="line">u：显示指定用户的进程。默认显示所有进程；</span><br><span class="line">T：根据累计运行时间排序</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">第一行：当前时间：系统已运行时间：751天，目前4个用户，1、5、15分钟内的load分别是0.07、0.02 、0.00</span><br><span class="line">第二行：进程情况：总共148个，正在运行的有2个，休眠有139个，僵尸进程1个</span><br><span class="line">第三行：cpu的使用情况（按数字1显示所有cpu）</span><br><span class="line">第四行：内存情况（buffers表示用作内核缓存的内存量）</span><br><span class="line">第五行：虚拟内存情况（系统的物理内存不够用的时候，把硬盘空间中的一部分空间释放出来，以供当前运行的程序使用）</span><br><span class="line">第六行：进程id，虚拟内存，驻留内存使用，cpu，内存使用百分比，运行时间,命令参数等。</span><br><span class="line">VIRT表示进程可以使用的内存总大小，VIRT=SWAP+RES，包括这个进程真实使用的内存, 映射过的文件, 和别的进程共享的内存等。 </span><br><span class="line">RES表示这个进程真实占用内存的大小，一般这个值和JVM的参数配置有关，如果%MEM使用过高则需要关注</span><br><span class="line">SHR表示可以和别的进程共享的内存和库大小。</span><br></pre></td></tr></table></figure>

<ul>
<li>某一个进程下的线程资源使用情况：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">top -p &#123;pid&#125; -H</span><br></pre></td></tr></table></figure>

<ul>
<li>查看系统load、cpu资源的其它命令</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mpstat 1 （汇总的）</span><br><span class="line">mpstat -P ALL 1  （汇总的+每个cpu的）</span><br><span class="line">w</span><br><span class="line">uptime</span><br><span class="line">top -H 和 ps -efL/ -Tel  显示 线程</span><br></pre></td></tr></table></figure>

<p>3、统计一个进程下的线程数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x2F;proc&#x2F;$&#123;pid&#125;&#x2F;status</span><br><span class="line"></span><br><span class="line">返回：</span><br><span class="line">...省略</span><br><span class="line">Threads:	74</span><br><span class="line">....省略</span><br><span class="line"></span><br><span class="line">其它命令：</span><br><span class="line">top -bH -d 3 -p &#123;pid&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>pstree （以树状图的方式展现进程之间的派生关系）<br><a href="http://man.linuxde.net/pstree" target="_blank" rel="noopener">Linux命令大全</a></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pstree -p</span><br><span class="line">pstree -p &#123;pid&#125; | wc -l</span><br></pre></td></tr></table></figure>

<ul>
<li>pstack （显示每个进程的栈跟踪），也可以查看一个进程下的线程总数</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pstack &#123;pid&#125; </span><br><span class="line">// 输出第一行</span><br><span class="line">pstack &#123;pid&#125; | head -1</span><br></pre></td></tr></table></figure>

<p>4、查看所有进程</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps -ef</span><br><span class="line">ps -ef|grep java</span><br></pre></td></tr></table></figure>

<p>5、对于Java应用从操作系统层面观察，就只有进程和线程两个指标，任何东西在操作系统层面都是以文件的形式存储的，进程也不例外。Linux上部署一个Tomcat程序产生一个进程，这个进程所有的东西都在这个目录下</p>
<p>ll /proc/{pid}/</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 可以查看所有的socket连接</span></span><br><span class="line">ll /proc/&#123;pid&#125;/fd | grep socket   </span><br><span class="line">```    </span><br><span class="line"></span><br><span class="line">5、<span class="built_in">ulimit</span> -a （显示当前的各种用户进程限制）</span><br><span class="line">[linux修改max user processes limits](http://blog.csdn.net/bbaiggey/article/details/51004817)    </span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line"><span class="built_in">ulimit</span> -a</span><br><span class="line"></span><br><span class="line">core file size (blocks, -c) 100</span><br><span class="line">data seg size (kbytes, -d) unlimited</span><br><span class="line">file size (blocks, -f) unlimited</span><br><span class="line">pending signals (-i) 15237</span><br><span class="line">max locked memory (kbytes, -l) 64</span><br><span class="line">max memory size (kbytes, -m) unlimited</span><br><span class="line">open files (-n) 1024</span><br><span class="line">pipe size (512 bytes, -p) 8</span><br><span class="line">POSIX message queues (bytes, -q) 819200</span><br><span class="line">stack size (kbytes, -s) 8192</span><br><span class="line">cpu time (seconds, -t) unlimited</span><br><span class="line">max user processes (-u) 15237</span><br><span class="line">virtual memory (kbytes, -v) unlimited</span><br><span class="line">file locks (-x) unlimited</span><br><span class="line">```    </span><br><span class="line">```bash</span><br><span class="line">输出的每一行由资源名字、（单位，<span class="built_in">ulimit</span>命令的参数）、软限制组成。详细解释：</span><br><span class="line">参数 描述</span><br><span class="line">core file size core文件的最大值为100 blocks，</span><br><span class="line">data seg size 进程的数据段可以任意大</span><br><span class="line">file size 文件可以任意大</span><br><span class="line">pending signals 最多有15237个待处理的信号</span><br><span class="line">max locked memory 一个任务锁住的物理内存的最大值为64kB</span><br><span class="line">max memory size 一个任务的常驻物理内存的最大值</span><br><span class="line">open files 一个任务最多可以同时打开1024的文件</span><br><span class="line">pipe size 管道的最大空间为4096字节</span><br><span class="line">POSIX message queues POSIX的消息队列的最大值为819200字节</span><br><span class="line">stack size 进程的栈的最大值为8192字节</span><br><span class="line">cpu time 进程使用的CPU时间</span><br><span class="line">max user processes 当前用户同时打开的进程(包括线程)的最大个数为15237</span><br><span class="line">virtual memory 没有限制进程的最大地址空间</span><br><span class="line">file locks 所能锁住的文件的最大个数没有限制</span><br></pre></td></tr></table></figure>

<h1 id="二、内存相关"><a href="#二、内存相关" class="headerlink" title="二、内存相关"></a>二、内存相关</h1><p>1、vmstat</p>
<p>Virtual Memory Statistics，统计进程、内存、io、cpu等的活动信息。对于多CPU系统，vmstat打印的是所有CPU的平均输出</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">procs</span><br><span class="line">r: 运行队列中进程数量</span><br><span class="line">b: 等待IO的进程数量</span><br><span class="line">memory</span><br><span class="line">swpd: 使用虚拟内存大小</span><br><span class="line">free: 可用内存大小</span><br><span class="line">buff: 用作缓冲的内存大小</span><br><span class="line">cache: 用作缓存的内存大小</span><br><span class="line">swap</span><br><span class="line">si: 每秒从交换区写到内存的大小</span><br><span class="line">so: 每秒从内存写入交换区的大小</span><br><span class="line">io</span><br><span class="line">bi: 每秒读取的块数（现在的Linux版本块的大小为1024bytes）</span><br><span class="line">bo: 每秒写入的块数</span><br><span class="line">system</span><br><span class="line"><span class="keyword">in</span>: 每秒中断数，包括时钟中断</span><br><span class="line">cs: 每秒上下文切换数</span><br><span class="line">cpu（以百分比表示）</span><br><span class="line">us: 用户进程执行时间(user time)</span><br><span class="line">sy: 系统进程执行时间(system time)</span><br><span class="line">id: 空闲时间(包括IO等待时间)</span><br><span class="line">wa: 等待IO时间</span><br></pre></td></tr></table></figure>
<p><strong>注意：排查问题时，要特别关注r的值，如果长时间超过cpu核数2倍，说明系统的负载很重，cpu已经无法及时处理堆积任务。</strong></p>
<p>2、sar -r</p>
<p>3、cat /proc/meminfo </p>
<p>4、free -m</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-m ：表示单位是MB</span><br></pre></td></tr></table></figure>


<h1 id="三、IO及网络"><a href="#三、IO及网络" class="headerlink" title="三、IO及网络"></a>三、IO及网络</h1><p>1、 tsar –traffic：显示网络带宽</p>
<p>2、 netstat </p>
<p>一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。</p>
<p><strong>命令参数：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-a或–all 显示所有连线中的Socket。</span><br><span class="line">-A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。</span><br><span class="line">-c或–continuous 持续列出网络状态。</span><br><span class="line">-C或–cache 显示路由器配置的快取信息。</span><br><span class="line">-e或–extend 显示网络其他相关信息。</span><br><span class="line">-F或–fib 显示FIB。</span><br><span class="line">-g或–groups 显示多重广播功能群组组员名单。</span><br><span class="line">-h或–<span class="built_in">help</span> 在线帮助。</span><br><span class="line">-i或–interfaces 显示网络界面信息表单。</span><br><span class="line">-l或–listening 显示监控中的服务器的Socket。</span><br><span class="line">-M或–masquerade 显示伪装的网络连线。</span><br><span class="line">-n或–numeric 直接使用IP地址，而不通过域名服务器。</span><br><span class="line">-N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。</span><br><span class="line">-o或–timers 显示计时器。</span><br><span class="line">-p或–programs 显示正在使用Socket的程序识别码和程序名称。</span><br><span class="line">-r或–route 显示Routing Table。</span><br><span class="line">-s或–statistice 显示网络工作信息统计表。</span><br><span class="line">-t或–tcp 显示TCP传输协议的连线状况。</span><br><span class="line">-u或–udp 显示UDP传输协议的连线状况。</span><br><span class="line">-v或–verbose 显示指令执行过程。</span><br><span class="line">-V或–version 显示版本信息。</span><br><span class="line">-w或–raw 显示RAW传输协议的连线状况。</span><br><span class="line">-x或–unix 此参数的效果和指定”-A unix”参数相同。</span><br><span class="line">–ip或–inet 此参数的效果和指定”-A inet”参数相同。</span><br></pre></td></tr></table></figure>

<p><strong>输出结果：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">一个是Active Internet connections，称为有源TCP连接，其中<span class="string">"Recv-Q"</span>和<span class="string">"Send-Q"</span>指的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。</span><br><span class="line"></span><br><span class="line">另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。</span><br><span class="line"></span><br><span class="line">Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。</span><br><span class="line"></span><br><span class="line">状态说明：</span><br><span class="line">LISTEN：侦听来自远方的TCP端口的连接请求</span><br><span class="line">SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了）</span><br><span class="line">SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了）</span><br><span class="line">ESTABLISHED：代表一个打开的连接</span><br><span class="line">FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认</span><br><span class="line">FIN-WAIT-2：从远程TCP等待连接中断请求</span><br><span class="line">CLOSE-WAIT：等待从本地用户发来的连接中断请求</span><br><span class="line">CLOSING：等待远程TCP对连接中断的确认</span><br><span class="line">LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击）</span><br><span class="line">TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认</span><br><span class="line">CLOSED：没有任何连接状态</span><br></pre></td></tr></table></figure>

<ul>
<li>找出运行在指定端口的进程</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -anpt | grep <span class="string">':20130'</span></span><br><span class="line">netstat -nat | grep <span class="string">"172.16.49.161:20130"</span></span><br></pre></td></tr></table></figure>

<ul>
<li>其它使用场景</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -nat |awk <span class="string">'&#123;print $6&#125;'</span>|sort|uniq -c    不同网络状态结果统计</span><br><span class="line">netstat -anop | grep 6379     应用连接Redis情况</span><br><span class="line">netstat -pt             输出中显示 PID 和进程名称</span><br><span class="line">netstat -s              查看网络统计信息</span><br><span class="line">netstat -nu             显示当前UDP连接状况</span><br><span class="line">netstat -nt             显示当前TCP连接状况</span><br><span class="line">netstat -i              显示网卡列表</span><br></pre></td></tr></table></figure>


<p>3、 iostat<br>iostat是I/O statistics（输入/输出统计）的缩写，主要的功能是对系统的磁盘I/O操作进行监视。它的输出主要显示磁盘读写操作的统计信息，同时也会给出CPU使用情况。同vmstat一样，iostat也不能对某个进程进行深入分析，仅对系统的整体情况进行分析。</p>
<p><strong>命令参数：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-c 显示CPU使用情况</span><br><span class="line">-d 显示磁盘使用情况</span><br><span class="line">-k 以 KB 为单位显示</span><br><span class="line">-m 以 M 为单位显示</span><br><span class="line">-N 显示磁盘阵列(LVM) 信息</span><br><span class="line">-n 显示NFS 使用情况</span><br><span class="line">-p[磁盘] 显示磁盘和分区的情况</span><br><span class="line">-t 显示终端和CPU的信息</span><br><span class="line">-x 显示详细信息</span><br><span class="line">-V 显示版本信息</span><br></pre></td></tr></table></figure>
<p><code>iostat 2</code></p>
<p><strong>输出结果：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cpu属性值说明：</span><br><span class="line"></span><br><span class="line">%user：CPU处在用户模式下的时间百分比。</span><br><span class="line">%nice：CPU处在带NICE值的用户模式下的时间百分比。</span><br><span class="line">%system：CPU处在系统模式下的时间百分比。</span><br><span class="line">%iowait：CPU等待输入输出完成时间的百分比。</span><br><span class="line">%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。</span><br><span class="line">%idle：CPU空闲时间百分比。</span><br><span class="line"></span><br><span class="line">备注：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">disk属性值说明：（iostat -x）</span><br><span class="line"></span><br><span class="line">rrqm/s:  每秒进行 merge 的读操作数目。即 rmerge/s</span><br><span class="line">wrqm/s:  每秒进行 merge 的写操作数目。即 wmerge/s</span><br><span class="line">r/s:  每秒完成的读 I/O 设备次数。即 rio/s</span><br><span class="line">w/s:  每秒完成的写 I/O 设备次数。即 wio/s</span><br><span class="line">rsec/s:  每秒读扇区数。即 rsect/s</span><br><span class="line">wsec/s:  每秒写扇区数。即 wsect/s</span><br><span class="line">rkB/s:  每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。</span><br><span class="line">wkB/s:  每秒写K字节数。是 wsect/s 的一半。</span><br><span class="line">avgrq-sz:  平均每次设备I/O操作的数据大小 (扇区)。</span><br><span class="line">avgqu-sz:  平均I/O队列长度。</span><br><span class="line">await:  平均每次设备I/O操作的等待时间 (毫秒)。</span><br><span class="line">svctm: 平均每次设备I/O操作的服务时间 (毫秒)。</span><br><span class="line">%util:  一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比</span><br><span class="line"></span><br><span class="line">备注：如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。如果avgqu-sz比较大，也表示有当量io在等待。</span><br></pre></td></tr></table></figure>
<ul>
<li>定时显示所有信息（每隔 2秒刷新显示，且显示3次）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iostat 2 3</span><br></pre></td></tr></table></figure>
<ul>
<li>以kB为单位显示所有信息</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iostat -k 3</span><br></pre></td></tr></table></figure>

<p>4、sar -b：磁盘状态历史记录</p>
<h1 id="四、文件"><a href="#四、文件" class="headerlink" title="四、文件"></a>四、文件</h1><p>1、 lsof (一切皆文件)<br><a href="http://man.linuxde.net/lsof" target="_blank" rel="noopener">命令详情</a></p>
<p>查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 查看sys.log文件被哪个进程打开</span><br><span class="line">lsof sys.log</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// 查看端口被哪个进程占用</span><br><span class="line">lsof  -i：端口号</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// 查看各个进程打开的文件数量</span><br><span class="line">lsof -n |awk <span class="string">'&#123;print $2&#125; " " $3'</span>|sort|uniq -c |sort -nr|more</span><br></pre></td></tr></table></figure>


<p>2、 df</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -hl</span><br><span class="line">磁盘的使用情况</span><br></pre></td></tr></table></figure>

<p>3、 du</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du -hl</span><br><span class="line">当前目录下的最叶子目录的大小</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du -sch * </span><br><span class="line">当前目录下的各目录的大小</span><br></pre></td></tr></table></figure>

<p>4、 find</p>
<p>文件查找</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find . -name sys.log  </span><br><span class="line">当前目录下查找sys.log文件</span><br><span class="line"></span><br><span class="line">find . -name <span class="string">"sy*log"</span></span><br><span class="line">查找文件支持通配符</span><br><span class="line"></span><br><span class="line">find . -size +20M</span><br><span class="line">查找当前目录下大小超过20M的文件  </span><br><span class="line"></span><br><span class="line">find . -size +20M | xargs ls -lh</span><br><span class="line">查找当前目录下大小超过20M的文件，并计算文件大小</span><br><span class="line"></span><br><span class="line">find -<span class="built_in">type</span> f -<span class="built_in">printf</span> <span class="string">'%s %p\n'</span> |sort -nr | head  </span><br><span class="line">查找占用空间最大的10个文件</span><br><span class="line"></span><br><span class="line">find /<span class="built_in">log</span>/backups -mtime +10 -<span class="built_in">exec</span> rm -rf &#123;&#125; \;</span><br><span class="line">查找及删除7天前的文件</span><br></pre></td></tr></table></figure>

<p>5、 tail</p>
<p>从指定点开始将文件标准输出</p>
<ul>
<li>显示文件最后5行内容</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tail -n 5 test.log</span><br></pre></td></tr></table></figure>
<ul>
<li>实时显示文件内容</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tail -f test.log</span><br><span class="line"></span><br><span class="line">ping baidu.com &gt; 1.txt &amp;</span><br><span class="line">后台以守护进程的方式，将ping命令的返回结果写入 1.txt</span><br></pre></td></tr></table></figure>

<h2 id="五、用户"><a href="#五、用户" class="headerlink" title="五、用户"></a>五、用户</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">w                       查看活动用户</span><br><span class="line">id &lt;用户名&gt;              查看指定用户信息</span><br><span class="line">last                    查看用户登录日志</span><br><span class="line">cut -d: -f1 /etc/passwd    查看系统所有用户</span><br><span class="line">cut -d: -f1 /etc/group     查看系统所有组</span><br><span class="line">crontab -l              查看当前用户的计划任务</span><br></pre></td></tr></table></figure>

<h1 id="六、其它"><a href="#六、其它" class="headerlink" title="六、其它"></a>六、其它</h1><p>1、查看所有安装的软件包</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qa</span><br></pre></td></tr></table></figure>

<p>2、查看环境变量</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">env</span><br></pre></td></tr></table></figure>

<p>3、Mac 删除git文件夹，删除svn文件夹</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span>到该文件夹</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除文件夹下的所有 .svn 文件</span></span><br><span class="line">find . -name <span class="string">".svn"</span> | xargs rm -rf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除文件夹下的所有 .git 文件</span></span><br><span class="line">find . -name <span class="string">".git"</span> | xargs rm -rf</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="更多资料："><a href="#更多资料：" class="headerlink" title="更多资料："></a>更多资料：</h1><p><a href="https://app.yinxiang.com/Home.action#n=b0fcd794-072a-4fab-9ac6-012b7b0ad147&amp;ses=4&amp;sh=2&amp;sds=5&amp;" target="_blank" rel="noopener">https://app.yinxiang.com/Home.action#n=b0fcd794-072a-4fab-9ac6-012b7b0ad147&amp;ses=4&amp;sh=2&amp;sds=5&amp;</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Pod has unbound immediate PersistentVolumeClaims,statefulset挂载不上pv的另一种情况</title>
    <url>/k8s/pod-has-unbound-PersistentVolumeClaims/</url>
    <content><![CDATA[<p>大家都知道当<code>volumeClaimTemplates</code>匹配不上pv时,会出现statefulset挂载不到pv的问题。错误提示如下:</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">error while running &quot;VolumeBinding&quot; filter plugin for pod &quot;web-2&quot;: pod has unbound immediate PersistentVolumeClaims</span><br></pre></td></tr></table></figure>
<p>如果你反复确认了volumeClaimTemplates是正确的，但是始终挂载不上，可以尝试检查以下pvc，看是不是statefulset之前自动创建的错误的pvc没有删除，导致后面statefulset的yaml文件怎么更改也没生效(刷新pvc)。</p>
<p>这种错误产生步骤如下：</p>
<ol>
<li><p>创建一个1G的pv</p>
</li>
<li><p>创建了一个statefulset,但是要求的pv容量为2G</p>
</li>
<li><p>发现statefulset的yaml文件写错了,改成1G,kubectl delete statefulset xx,然后使用新的yaml</p>
</li>
<li><p>然后就发现statefulset的pod无论如何都成为了pending状态</p>
</li>
<li><p>原因就在于第三步删除statefulset的时候,自动创建的pvc没有删除,后面使用新的statefulset,pvc并不会自动刷新</p>
</li>
<li><p>可以使用命令kubectl get pvc 错误的pvc -o yaml查看这个pvc的创建yaml文档</p>
</li>
<li><p>可以使用命令kubectl describe pvc xxx –namespace xxx 查看具体错误信息</p>
</li>
<li><p><strong>kubectl delete -f xxx.yml 时不会自动删除volumeClaimTemplates 创建的错误pvc.<br>需要手动删除kubectls delete pvc pvcname –namespace=kafka</strong></p>
</li>
</ol>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>FastDFS（分布式文件存储系统）</title>
    <url>/middle-software/FastDFS/</url>
    <content><![CDATA[<ul>
<li><p><a href="https://github.com/happyfish100/fastdfs" target="_blank" rel="noopener">server 源代码</a></p>
</li>
<li><p><a href="https://github.com/happyfish100/fastdfs-client-java" target="_blank" rel="noopener">client 源代码</a></p>
</li>
<li><p><a href="https://www.oschina.net/p/fastdfs" target="_blank" rel="noopener">开源文档</a></p>
</li>
<li><p><a href="http://blog.csdn.net/xyang81/article/details/52928230" target="_blank" rel="noopener">FastDFS分布式文件系统集群安装与配置</a></p>
</li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop</title>
    <url>/middle-software/Hadoop/</url>
    <content><![CDATA[<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://hadoop.apache.org/docs/r1.0.4/cn/mapred_tutorial.html" target="_blank" rel="noopener">hadoop r1.0.4文档手册</a></li>
</ul>
<a id="more"></a>
<hr>
<p>Hadoop 集群：</p>
<ul>
<li>本地（单机）模式</li>
<li>伪分布式模式</li>
<li>完全分布式模式</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://waylau.com/about-hadoop/" target="_blank" rel="noopener">Apache Hadoop 入门教程</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink</title>
    <url>/middle-software/Flink/</url>
    <content><![CDATA[<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><ul>
<li><a href="https://github.com/apache/flink" target="_blank" rel="noopener">源代码</a></li>
<li><a href="https://mp.weixin.qq.com/s/IucXK32atxMq1BeQTiHgag" target="_blank" rel="noopener">Flink StreamSQL 原理介绍</a></li>
</ul>
<a id="more"></a>

]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Hbase 笔记</title>
    <url>/middle-software/Hbase-note1/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>HBase是一个开源的非关系型分布式数据库（NoSQL），基于谷歌的BigTable建模，是一个高可靠性、高性能、高伸缩的分布式存储系统，使用HBase技术可在廉价PC Server上搭建起大规模结构化存储集群。</p>
<a id="more"></a>
<p>HBase最初是以Hadoop子项目的形式进行开发建设，底层依赖于HDFS组件作为其存储系统（在 HDFS 中的数据默认会有 3 份），直到2010年5月才正式成为Apache的顶级项目独立发展。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/15.png/w600">

<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ul>
<li>存储大量的数据（PB级别）</li>
<li>写吞吐量大，瞬间写入量很大</li>
<li>优雅数据扩展，动态扩展整个存储系统容量</li>
<li>数据格式无限制，支持半结构化和非结构化的数据</li>
<li>业务场景简单，不需要全部的关系型数据库的特征，如交叉列、交叉表、事务、连接等</li>
</ul>
<h2 id="与关系型数据库的差异"><a href="#与关系型数据库的差异" class="headerlink" title="与关系型数据库的差异"></a>与关系型数据库的差异</h2><ul>
<li>数据按行存储</li>
<li>没有索引的查询使用大量的I/O</li>
<li>建立索引和物化视图需要大量的资源</li>
</ul>
<h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><ul>
<li><p>Rowkey</p>
<p>  Hbase通过行键（Rowkey）检索数据，仅支持单行事务，单表可以有百亿行、百万列，数据矩阵横向和纵向两个维度所支持的数据量级都很有弹性。 RowKey按照字典顺序排序的，且只能存储64K的字节数据。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HBase只能在RowKey上建立索引。非RowKey的访问，只能全表扫描。</span><br><span class="line">RowKey是以字典顺序由小到大的排序。</span><br><span class="line">RowKey尽量散列，可以保证数据都不在一个Region上，从而避免读写的压力集中在个别Region。</span><br><span class="line">RowKey的长度尽量短。</span><br></pre></td></tr></table></figure>

<ul>
<li><p>列族</p>
<p>  Hbase把同一个列族里面的数据存储在同一个目录下，由几个文件保存；权限控制、存储以及调优都是在列族层面进行的。</p>
</li>
<li><p>timestamp时间戳</p>
<p>  每个cell存储单元对同一份数据有多个版本（每个单元格默认有 3 个时间戳的版本数据），根据唯一的时间戳来区分每个版本间的差异，不同版本的数据按时间倒序排序，最新的数据版本在最前面。时间戳类型是64位整型。由Hbase自动赋值。</p>
</li>
<li><p>cell单元格</p>
<p>  由行和列的坐标交叉决定。内容是未解析的字节数组。</p>
</li>
<li><p>HLog</p>
<p>  记录操作动作，以及value值，用于容灾。</p>
</li>
</ul>
<h2 id="组成部分"><a href="#组成部分" class="headerlink" title="组成部分"></a>组成部分</h2><ul>
<li><p>主节点HMaster</p>
<p>  在HBase中可以启动多个HMaster，通过选举机制保证只有一个Master正常运行并提供服务。HMaster主要负责Tabel和Region的管理工作。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">管理用户对Table的增、删、改、查操作</span><br><span class="line">管理RegionServer的负载均衡，调整Region分布</span><br><span class="line">在Region分裂后，负责新Region的分配</span><br><span class="line">在RegionServer死机后，负责失效的RegionServer上的Region迁移</span><br></pre></td></tr></table></figure>

<ul>
<li><p>RegionServer</p>
<p>  负责响应用户的I/O请求，向HDFS文件系统读写数据，是HBase最核心模块。内部管理了一系列Region。<br>  负责切分在运行过程中变得过大的region。</p>
</li>
<li><p>Region</p>
<p>  一个Region由多个store组成，一个store对应了Table中的一个列族的存储。可以看出每个列族其实就是一个存储单元，因为最好将共同I/O特性的列放在一个列族中，保证高效读写。</p>
<p>  Store由两部分组成，MemStore和StoreFile。用户写入的数据首先会放入MemStore，当满了后会缓冲成一个StoreFile，当StoreFile 文件的数量增长到一定的阈值，系统会进行合并。</p>
<p>  Hbase自动把表水平划分成多个区域（region），每个region会保存一个表里面某段连续的数据。每个表开始只有一个region，随着数据不断插入表，region不断增大，当增大到一个阀值时，region会等分成两个新的region（裂变）。当table的行不断增多，就会有越来越多的region。这样一张完整的表被保存在多个Regionserver上。</p>
<p>  客户端检索数据，先在memstore找，找不到再找storefile。</p>
  <img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/14.png/w600">

<p>  <strong>图中示例：表有3个列族，也就对应3个store，组成一个region，表示一个表的某个区间范围rowkey对应的记录。</strong></p>
</li>
</ul>
<ul>
<li><p>客户端client</p>
<p>  客户端使用HBase的RPC机制与HMaster和RegionServer进行通信，客户端支持java接口、Thrift、Rest等多种形式</p>
</li>
<li><p>协调服务组件ZooKeeper</p>
<ul>
<li>负责管理HBase中多个HMaster的选举、服务器之间状态同步，保证任何时候，集群中只有一个master</li>
<li>存储所有的Region的寻址入口</li>
<li>实时监控Region server的上线和下线信息，并实时通知Master</li>
<li>存储Hbase的schema和table元数据</li>
</ul>
</li>
</ul>
<h2 id="Schema设计要点"><a href="#Schema设计要点" class="headerlink" title="Schema设计要点"></a>Schema设计要点</h2><p>行键设计：</p>
<ul>
<li>避免单调递增行键。主要是为了防止数据过于集中在一个Region上。</li>
<li>行键与列族的关系。行键与列族是一对多关系，同一个行键可以在同一个表的每个列族中存在而不会冲突。</li>
<li>行键的长度</li>
<li>行键永远不变</li>
<li>尽量最小化行键长度</li>
</ul>
<p>列族的设计：</p>
<ul>
<li>列族的数量。尽量让你的列族数量少一些，通常只有一个</li>
<li>列族名长度。尽量减少长度，最好是一个字符，比如“d”</li>
<li>列族的基数（即行数）。如果表存在多个列族，列族A有100万行，列族B有10亿行，列族A可能被分散到很多Region中，导致扫描列族A时性能低下。</li>
</ul>
<h2 id="Hbase支持的客户端"><a href="#Hbase支持的客户端" class="headerlink" title="Hbase支持的客户端"></a>Hbase支持的客户端</h2><ul>
<li>HBase提供的原生java客户端。涵盖了增、删、改、查等所有的API。</li>
<li>使用HBase Shell来操作HBase</li>
<li>使用Thrift客户端来访问HBase</li>
<li>通过Rest客户端来访问HBase</li>
</ul>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><ul>
<li><p>Get</p>
<p>  get（）方法默认一次取回该行全部列的数据，我们也可以限定只取回某个列族的列的数据，或者进一步限定只取回某些列的数据</p>
</li>
<li><p>Put</p>
<p>  如果RowKey是新的表示插入，否则表示更新</p>
</li>
<li><p>Scan</p>
<p>  与get方法类似，可以指定startRow参数来定义扫描读取HBase表的起始行键，同时可选stopRow参数来限定读取到何处停止。</p>
</li>
<li><p>Delete</p>
<p>  删除数据。与关系型数据库的delete操作不同，HBase的Delete操作可以指定删除某个列族或者某个列，或者指定某个时间戳，删除比这个时间早的数据。</p>
</li>
<li><p>flush</p>
<p>  强制将memstore中的数据刷到storeFile中。</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 安装hbase后，修改数据存储目录，编辑 conf&#x2F;hbase-site.xml 配置hbase.rootdir 为&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;temp&#x2F;hbase</span><br><span class="line">2. flush &#39;表名&#39;</span><br><span class="line">3. hbase hfile -p -f 74ca443e934c4b4bbf6c7fa4b899d16a 解压查看存储的数据</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h2 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h2><p>过滤器可以根据列族、列、版本等更多的条件来对数据进行过滤，带有过滤条件的RPC查询请求会把过滤器分发到各个RegionServer中，可以降低网络传输的压力。</p>
<ul>
<li><p>比较器：作为过滤器的核心组成之一，用于处理具体的比较逻辑，例如字节级的比较、字符串级的比较。</p>
<ul>
<li>RegexStringComparator（正则表达式的值比较）</li>
<li>SubstringComparator（用于检测一个子串是否存在于值中，不区分大小写）</li>
<li>BinaryPrefixComparator</li>
<li>BinaryComparator</li>
</ul>
</li>
<li><p>列值过滤器</p>
<ul>
<li>SingleColumnValueFilter</li>
<li>SingleColumnValueExcludeFilter</li>
</ul>
</li>
<li><p>键值元数据过滤器</p>
<ul>
<li>FamilyFilter</li>
<li>QualifierFileter</li>
<li>ColumnPrefixFilter</li>
<li>MultipleColumnPrefixFilter</li>
<li>ColumnRangeFilter</li>
<li>DependentColumnFilter</li>
</ul>
</li>
<li><p>行键过滤器</p>
<ul>
<li>RowFilter</li>
<li>RandomRowFilter</li>
</ul>
</li>
<li><p>功能过滤器</p>
<ul>
<li>PageFilter</li>
<li>FirstKeyOnlyFilter</li>
<li>KeyOnlyFilter</li>
<li>InclusiveStopFilter</li>
<li>ColumnPaginationFilter</li>
</ul>
</li>
</ul>
<h2 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a>使用建议</h2><ul>
<li>当客户端需要频繁的写一张表，随机的 RowKey 会获得更好的性能。</li>
<li>当客户端需要频繁的读一张表，有序的 RowKey 则会获得更好的性能。</li>
<li>对于时间连续的数据（例如 log），有序的 RowKey 会很方便查询一段时间的数据（Scan 操作）</li>
<li>大多数的情况下，一个表格不会超过 2 到 3 个 CF，而且很多情况下都是 1 个 CF 就足够了。    </li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>df -h命令卡死解决办法</title>
    <url>/linux/df%E5%91%BD%E4%BB%A4%E5%8D%A1%E6%AD%BB%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    <content><![CDATA[<h1 id="1、现象"><a href="#1、现象" class="headerlink" title="1、现象"></a>1、现象</h1><p>突然有个服务器进入/目录运行 ls  -l 无反应，同时运行df  -h也卡死了。如果你的机器有用到nfs请直接看第四大点。</p>
<a id="more"></a>

<h1 id="2、分析"><a href="#2、分析" class="headerlink" title="2、分析"></a>2、分析</h1><p>运行 mount</p>
<p>[alan@kisee ~]$ mount<br>/dev/mapper/VolGroup-lv_root on / type ext4 (rw)<br>proc on /proc type proc (rw)<br>sysfs on /sys type sysfs (rw)<br>devpts on /dev/pts type devpts (rw,gid=5,mode=620)<br>tmpfs on /dev/shm type tmpfs (rw)<br>/dev/sda1 on /boot type ext4 (rw)<br>/dev/mapper/VolGroup-lv_home on /home type ext4 (rw)<br>/dev/mapper/VolGroup-lv_var on /var type ext4 (rw)<br>none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)<br>sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw)<br>203.116.18.239:/opt/storage-escape on /opt/storage-scms type nfs (rw,addr=203.116.18.239)<br>203.116.18.239:/opt/storage-escape on /opt/storage-escape type nfs (rw,addr=203.116.18.239)<br>203.116.18.239:/test on /test2 type nfs (rw,vers=4,addr=203.116.18.239,clientaddr=203.116.18.233)</p>
<p>发现有三个nfs目录，因此登陆203.116.18.239 查看目录问题 发现/test 这个目录已经被删除了</p>
<p>因此使用umount命令来卸载</p>
<h1 id="3、解决"><a href="#3、解决" class="headerlink" title="3、解决"></a>3、解决</h1><p>运行  <code>umount -l   /test2</code>  来卸载设备。选项 –l 并不是马上umount，而是在该目录空闲后再umount。</p>
<p>以上不行，就运行如下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fuser -m -v /test2</span><br><span class="line"></span><br><span class="line">fuser -m -v -i -k   /test2  <span class="comment">#使用i参数会问你是否kill掉这个某个进程，按y就把它kill了。</span></span><br></pre></td></tr></table></figure>
<h1 id="4、其他情况"><a href="#4、其他情况" class="headerlink" title="4、其他情况"></a>4、其他情况</h1><p>该服务器做了服务端的NFS目录，但是由于服务端所在的服务器重启了机器，导致客户端读不到服务端的目录导致卡死。</p>
<p>解决办法，在服务器重启nfs服务</p>
<p><code>server  restart    nfs</code></p>
<p>客户端也再次重启nfs</p>
<p><code>server  restart    nfs</code>  </p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive</title>
    <url>/middle-software/Hive/</url>
    <content><![CDATA[<p>Hive是Facebook于2008年开源的一个数据仓库框架。Hive定义了一个类似于SQL的查询语言：HQL，能够将用户编写的QL转化为相应的MapReduce程序基于Hadoop执行。</p>
<a id="more"></a>
<p>Hive 适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志。<strong>Hive 不应该用来进行实时的查询（Hive 的设计目的，也不是支持实时的查询）</strong>。因为它需要很长时间才可以返回结果。</p>
<p>Hive 一般只要有 Hadoop 便可以工作。而 HBase 则还需要 Zookeeper 的帮助（Zookeeper，是一个用来进行分布式协调的服务，这些服务包括配置服务，维护元信息和命名空间服务）</p>
<p>Hive的操作可以通过UI界面、命令终端、JDBC（java程序）等方式来操作。</p>
<ul>
<li>创建数据库</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE DATABASE [IF NOT EXISTS] userdb;</span><br></pre></td></tr></table></figure>
<ul>
<li>删除数据库</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DROP DATABASE IF EXISTS userdb;</span><br></pre></td></tr></table></figure>

<ul>
<li>创建表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> employee ( eid <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">String</span>,</span><br><span class="line">  salary <span class="keyword">String</span>, destination <span class="keyword">String</span>)</span><br><span class="line">  <span class="keyword">COMMENT</span> ‘Employee details’</span><br><span class="line">  <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></span><br><span class="line">  <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> ‘\t’</span><br><span class="line">  <span class="keyword">LINES</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> ‘\n’</span><br><span class="line">  <span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE;</span><br></pre></td></tr></table></figure>

<ul>
<li>插入数据 </li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">我们将插入下列数据到表中。在&#x2F;home&#x2F;user目录中名为sample.txt的文件。</span><br><span class="line"></span><br><span class="line">1201  Gopal       45000    Technical manager</span><br><span class="line">1202  Manisha     45000    Proof reader</span><br><span class="line">1203  Masthanvali 40000    Technical writer</span><br><span class="line">1204  Kiran       40000    Hr Admin</span><br><span class="line">1205  Kranthi     30000    Op Admin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hive&gt; LOAD DATA LOCAL INPATH &#39;&#x2F;home&#x2F;user&#x2F;sample.txt&#39;</span><br><span class="line">     OVERWRITE INTO TABLE employee;</span><br></pre></td></tr></table></figure>
<ul>
<li>修改表，包括表结构</li>
</ul>
<p><a href="http://www.yiibai.com/hive/hive_alter_table.html" target="_blank" rel="noopener">http://www.yiibai.com/hive/hive_alter_table.html</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">重命名表，把 employee 修改为 emp。</span><br><span class="line"></span><br><span class="line">hive&gt; ALTER TABLE employee RENAME TO emp;</span><br></pre></td></tr></table></figure>
<ul>
<li>删除表</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; DROP TABLE IF EXISTS employee;</span><br></pre></td></tr></table></figure>
<ul>
<li>各种视图操作（创建、删除、创建索引、删除索引）</li>
</ul>
<h4 id="Hive架构"><a href="#Hive架构" class="headerlink" title="Hive架构"></a>Hive架构</h4><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/20170805_131.png/w600">

<table>
<thead>
<tr>
<th>单元名称</th>
<th>操作</th>
</tr>
</thead>
<tbody><tr>
<td>用户接口/界面</td>
<td>Hive是一个数据仓库基础工具软件，可以创建用户和HDFS之间互动。用户界面，Hive支持是Hive的Web UI，Hive命令行，HiveHD洞察（在Windows服务器）。</td>
</tr>
<tr>
<td>元存储</td>
<td>Hive选择各自的数据库服务器，用以储存表，数据库，列模式或元数据表，它们的数据类型和HDFS映射。</td>
</tr>
<tr>
<td>HiveQL处理引擎</td>
<td>HiveQL类似于SQL的查询上Metastore模式信息。这是传统的方式进行MapReduce程序的替代品之一。相反，使用Java编写的MapReduce程序，可以编写为MapReduce工作，并处理它的查询。</td>
</tr>
<tr>
<td>执行引擎</td>
<td>HiveQL处理引擎和MapReduce的结合部分是由Hive执行引擎。执行引擎处理查询并产生结果和MapReduce的结果一样。它采用MapReduce方法。</td>
</tr>
<tr>
<td>HDFS 或 HBASE</td>
<td>Hadoop的分布式文件系统或者HBASE数据存储技术是用于将数据存储到文件系统。</td>
</tr>
</tbody></table>
<h4 id="Hive工作原理"><a href="#Hive工作原理" class="headerlink" title="Hive工作原理"></a>Hive工作原理</h4><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/20170805_132.png/w600">

<table>
<thead>
<tr>
<th>Step No</th>
<th>操作</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Execute Query， Hive接口，如命令行或Web UI发送查询驱动程序（任何数据库驱动程序，如JDBC，ODBC等）来执行。</td>
</tr>
<tr>
<td>2</td>
<td>Get Plan ，在驱动程序帮助下查询编译器，分析查询检查语法和查询计划或查询的要求。</td>
</tr>
<tr>
<td>3</td>
<td>Get Metadata ，编译器发送元数据请求到Metastore（任何数据库）。</td>
</tr>
<tr>
<td>4</td>
<td>Send Metadata ，Metastore发送元数据，以编译器的响应。</td>
</tr>
<tr>
<td>5</td>
<td>Send Plan，编译器检查要求，并重新发送计划给驱动程序。到此为止，查询解析和编译完成。</td>
</tr>
<tr>
<td>6</td>
<td>Execute Plan，驱动程序发送的执行计划到执行引擎。</td>
</tr>
<tr>
<td>7</td>
<td>Execute Job，在内部，执行作业的过程是一个MapReduce工作。执行引擎发送作业给JobTracker，在名称节点并把它分配作业到TaskTracker，这是在数据节点。在这里，查询执行MapReduce工作。</td>
</tr>
<tr>
<td>7.1</td>
<td>Metadata Ops，与此同时，在执行时，执行引擎可以通过Metastore执行元数据操作。</td>
</tr>
<tr>
<td>8</td>
<td>Fetch Result，执行引擎接收来自数据节点的结果。</td>
</tr>
<tr>
<td>9</td>
<td>Send Results，执行引擎发送这些结果值给驱动程序。</td>
</tr>
<tr>
<td>10</td>
<td>Send Results，驱动程序将结果发送给Hive接口。</td>
</tr>
</tbody></table>
<p>Hive 的安装手册：<a href="http://www.yiibai.com/hive/hive_installation.html" target="_blank" rel="noopener">http://www.yiibai.com/hive/hive_installation.html</a></p>
<h4 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h4><ul>
<li><a href="http://www.yiibai.com/hive/hive_alter_table.html" target="_blank" rel="noopener">http://www.yiibai.com/hive/hive_alter_table.html</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>MogonDB</title>
    <url>/middle-software/MogonDB/</url>
    <content><![CDATA[<h2 id="MogonDB"><a href="#MogonDB" class="headerlink" title="MogonDB"></a>MogonDB</h2><hr>
<a id="more"></a>

]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Hbase</title>
    <url>/middle-software/Hbase/</url>
    <content><![CDATA[<h2 id="一、手册"><a href="#一、手册" class="headerlink" title="一、手册"></a>一、手册</h2><a id="more"></a>
<ul>
<li><a href="Hbase-note1.md">笔记</a></li>
<li><a href="http://blog.csdn.net/itomge/article/details/9970833" target="_blank" rel="noopener">Hbase安装</a></li>
<li>《HBase企业应用开发实战》</li>
<li><a href="https://hbase.apache.org/book.html" target="_blank" rel="noopener">Hbase官网</a></li>
<li><a href="http://abloz.com/hbase/book.html" target="_blank" rel="noopener">Hbase官方文档中文版</a></li>
<li><a href="https://edu.aliyun.com/course/73/learn?spm=0.0.0.0.k89hlH#lesson/978" target="_blank" rel="noopener">Hbase视频课程</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-bigdata-hbase/index.html" target="_blank" rel="noopener">HBase 深入浅出</a></li>
<li><a href="https://mp.weixin.qq.com/s/t6B0qcvq1PzkvXujv8jpUg" target="_blank" rel="noopener">HBase详细概述</a></li>
<li><a href="https://mp.weixin.qq.com/s/-kNKEpsATKgr_66IMS7KEw" target="_blank" rel="noopener">HBase全网学习资料汇总</a></li>
</ul>
<h2 id="二、Phoenix"><a href="#二、Phoenix" class="headerlink" title="二、Phoenix"></a>二、Phoenix</h2><ul>
<li><a href="https://github.com/apache/phoenix" target="_blank" rel="noopener">源代码</a></li>
<li><a href="http://phoenix.apache.org/" target="_blank" rel="noopener">官网地址</a></li>
<li><a href="https://phoenix.apache.org/language/index.html" target="_blank" rel="noopener">官方文档语法</a></li>
<li><a href="http://www.jianshu.com/p/d862337247b1" target="_blank" rel="noopener">Apache Phoenix介绍（SQL on HBase）</a></li>
<li><a href="http://blog.csdn.net/huanggang028/article/details/12563481" target="_blank" rel="noopener">Phoenix使用指南</a></li>
<li><a href="http://www.ixirong.com/2015/06/24/how-hbase-use-apache-phoenix/" target="_blank" rel="noopener">使用Phoenix通过sql语句更新操作hbase数据</a></li>
</ul>
<p>安装：</p>
<ul>
<li><a href="https://yq.aliyun.com/articles/366299?spm=5176.11065265.1996646101.searchclickresult.739544cbDi6KHl" target="_blank" rel="noopener">Apache版Phoenix的安装</a></li>
</ul>
<p>图形客户端：</p>
<ul>
<li>SQuirrel</li>
</ul>
<p>博客：</p>
<ul>
<li><a href="https://yq.aliyun.com/articles/574090?spm=5176.11065265.1996646101.searchclickresult.739544cbDi6KHl#" target="_blank" rel="noopener">Phoenix入门到精通</a></li>
<li><a href="https://yq.aliyun.com/users/1797606532614586/mark?spm=a2c4e.11153940.headeruserinfo.8.216553abfSjHdd" target="_blank" rel="noopener">我的收藏</a></li>
<li><a href="https://blog.csdn.net/u011491148/article/details/45749807" target="_blank" rel="noopener">利用Phoenix为HBase创建二级索引</a></li>
<li><a href="https://blog.csdn.net/mt0803/article/details/38513271" target="_blank" rel="noopener">Phoenix Secondary Index</a></li>
<li><a href="https://yq.aliyun.com/articles/601722?spm=a2c4e.11157919.spm-cont-list.1.146c27aesRwAXc" target="_blank" rel="noopener">高手如何实践HBase？不容错过的滴滴内部技巧</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ</title>
    <url>/middle-software/RabbitMQ/</url>
    <content><![CDATA[<ul>
<li><a href="https://github.com/rabbitmq" target="_blank" rel="noopener">github源码</a></li>
<li><a href="https://github.com/rabbitmq/rabbitmq-tutorials" target="_blank" rel="noopener">官方–多种语言接入示例代码</a></li>
<li><a href="https://github.com/rabbitmq/rabbitmq-java-client" target="_blank" rel="noopener">java-client</a></li>
</ul>
<a id="more"></a>
<p>学习资料</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/GIkzoIBGQJtXB9RXlwlzPQ" target="_blank" rel="noopener">快速入门及应用</a></li>
<li><a href="http://blog.csdn.net/column/details/rabbitmq.html" target="_blank" rel="noopener">从入门到精通</a></li>
<li><a href="http://blog.csdn.net/woogeyu/article/details/51119101" target="_blank" rel="noopener">RabbitMQ分布式集群架构</a></li>
<li><a href="https://mp.weixin.qq.com/s/GC2N1i27eAo8QFuzb6muJw" target="_blank" rel="noopener">有货RabbitMQ双活实践</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty相关</title>
    <url>/middle-software/Netty/</url>
    <content><![CDATA[<h2 id="Netty相关"><a href="#Netty相关" class="headerlink" title="Netty相关"></a>Netty相关</h2><a id="more"></a>
<ul>
<li><a href="https://mp.weixin.qq.com/s/RPTETiULRAkOS-ZTd6xM2A" target="_blank" rel="noopener">Netty入门简介</a></li>
<li><a href="https://mp.weixin.qq.com/s/1zDDoNx4ZabLy7o-scPbsQ" target="_blank" rel="noopener">Netty高性能之道</a></li>
<li><a href="https://mp.weixin.qq.com/s/Klal5868wpEtcJD52DLJ2A" target="_blank" rel="noopener">精尽 Netty 原理与源码专栏</a></li>
<li><a href="http://www.iocoder.cn/Netty/Netty-collection/" target="_blank" rel="noopener">Netty 实现原理与源码解析系统</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ</title>
    <url>/middle-software/RocketMQ/</url>
    <content><![CDATA[<ul>
<li><a href="https://github.com/apache/incubator-rocketmq" target="_blank" rel="noopener">源代码</a></li>
</ul>
<a id="more"></a>
<hr>
<ul>
<li><a href="https://mp.weixin.qq.com/s/HUNuqsjj88vcNA_BzORBcg" target="_blank" rel="noopener">分布式消息队列 RocketMQ 源码分析 —— Message 拉取与消费（上）</a></li>
<li><a href="https://mp.weixin.qq.com/s/J4awuLHrBvSOphsUIAMV4A" target="_blank" rel="noopener">分布式消息队列 RocketMQ 源码分析 —— Message 拉取与消费（下）</a></li>
<li><a href="https://mp.weixin.qq.com/s/hf0ywoRa6A0NKYGEGQL2BQ" target="_blank" rel="noopener">分布式消息队列 RocketMQ 源码分析 —— Message 顺序发送与消费</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark MLlib机器学习笔记</title>
    <url>/middle-software/Spark-MLlib%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="Spark-MLlib机器学习笔记"><a href="#Spark-MLlib机器学习笔记" class="headerlink" title="Spark MLlib机器学习笔记"></a>Spark MLlib机器学习笔记</h2><hr>
<a id="more"></a>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark SQL笔记</title>
    <url>/middle-software/Spark-SQL%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><hr>
<p>Spark SQL API为多种功能提供了函数，比如：选择列、过滤行、聚合列、合并数据以及其他数据处理。只需要寥寥数行代码即可实现功能。</p>
<a id="more"></a>
<p>支持多种数据源：</p>
<ul>
<li><p>文件。文件可以位于HDFS、S3或者本地文件系统上。支持的文件格式，CSV、JSON、ORC、Avro</p>
</li>
<li><p>NoSQL数据库。如：Hbase、Cassandra、Elastics Search、Druid</p>
</li>
<li><p>其他数据库。如：mysql、oracle等</p>
</li>
</ul>
<p>Spark SQL与hive完全兼容。不仅支持HiveSQL，还可以访问Hive meta-store、UDF。Spark SQL不需要Hive环境，无论有没有Hive，都可以运行Spark SQL。它有内置的HiveQL解析器。</p>
<h2 id="性能提升："><a href="#性能提升：" class="headerlink" title="性能提升："></a>性能提升：</h2><ul>
<li>减少磁盘IO。在读数据时，会有所选择，跳过没有被查询到的分区、行、列。</li>
<li>数据分区。把一个已分区的数据集切分成多个水平分片。数据根据单列或多列做分区。在一个已分区的数据集上做过滤条件可以减少浪费在那些从不使用的数据上产生的大量IO操作。</li>
<li>列存储。采用表格形式，可以用行和列来表示。使用列式存储，只读取查询用到的那几列数据。</li>
<li>内存中的列式缓存。</li>
<li>行跳过。比如Parquet和ORC这种序列化格式会存储一个行分组或者多行中每一列的最小值和最大值。根据这一信息，Spark SQL在读取数据时可以跳过某些行。</li>
<li>谓词下推。比如从关系型数据库读取数据，会先借助原生数据库的索引来过滤。因为原生的过滤要比在应用层执行过滤快得多。</li>
<li>查询优化。生成一个优化过的物理查询计划。分成了四个阶段：分析、逻辑优化、物理计划、代码生成。</li>
</ul>
<h2 id="应用范围："><a href="#应用范围：" class="headerlink" title="应用范围："></a>应用范围：</h2><ul>
<li>ETL（Extract 抽取、 Transform 转换、Load 加载）</li>
</ul>
<p>表示从数据源读数据、对数据做转换操作、将数据写到另一个数据源中的过程。</p>
<ul>
<li>数据可视化</li>
</ul>
<p>提供了统一的抽象，屏蔽了底层不同数据源的差异性。比如Spark SQL可以让在Parquet和PostreSQL的表间做连接操作。</p>
<ul>
<li><p>分布式JDBC查询引擎</p>
</li>
<li><p>数据仓库</p>
</li>
</ul>
<p>Spark SQL可用于创建一个开源的数据仓库解决方案。</p>
<h2 id="API："><a href="#API：" class="headerlink" title="API："></a>API：</h2><p>Spark SQL API由SQLContext、HiveContext、DataFrame三个关键抽象组成。</p>
<ul>
<li><p>SQLContext是Spark SQL库的入口点。只有有了SQLContext类实例，才能创建Spark SQL库提供的其他类的类实例。同样，只有有了SQLContext类实例，才能执行SQL查询。</p>
</li>
<li><p>HiveContext是Spark SQL库的另一个入口点，继承自SQLContext，用于处理存储在Hive中的数据。</p>
</li>
<li><p>DataFrame表示若干行的分布式数据，每一行有若干个有名字的列。提供各种方法用于处理、分析结构化数据（选择列、过滤行、聚合列、连接表、抽样数据以及其他一些常见的数据处理任务）。可以被当成一个临时表注册到应用上，在上面可以使用SQL来查询。</p>
</li>
</ul>
<p>如何创建DataFrame：</p>
<ul>
<li><p>toDF。从RDD创建DataFrame，</p>
</li>
<li><p>createDataFrame。SQLContext和HiveContext类都提供了一个名为createDataFrame的方法，用于从一个由行构成的RDD中创建DataFrame。方法有两个参数：行构成的RDD和一个数据格式。</p>
</li>
<li><p>从数据源创建DataFrame。SQLContext和HiveContext类都提供一个名为read的工厂方法，返回一个DataFrameReader类实例。它定义了从数据源读取数据的接口，它使得你可以为读取数据设置不同的选项。</p>
</li>
</ul>
<p>DataFrame常用的API：</p>
<ul>
<li>基本操作<ul>
<li>cache</li>
<li>columns</li>
<li>dtypes</li>
<li>explain</li>
<li>persist</li>
<li>printSchema</li>
<li>registerTempTable</li>
<li>toDF</li>
</ul>
</li>
<li>集成语言的查询所用的方法<ul>
<li>agg</li>
<li>apply</li>
<li>cube</li>
<li>distinct</li>
<li>explode</li>
<li>filter</li>
<li>groupBy</li>
<li>intersect</li>
<li>join</li>
<li>limit</li>
<li>orderBy</li>
<li>sort</li>
<li>randomSplit</li>
<li>rollup</li>
<li>sample</li>
<li>selectExpr</li>
<li>withColumn</li>
</ul>
</li>
<li>RDD操作<ul>
<li>map</li>
<li>flatMap</li>
<li>foreach</li>
<li>mapPartition</li>
<li>coalesce</li>
<li>repartition</li>
<li>等等，常用的RDD操作</li>
<li>如果需要使用DataFrame类中没有但是RDD类中有的方法，可以通过rdd方法</li>
</ul>
</li>
<li>操作<ul>
<li>collect</li>
<li>count</li>
<li>describe</li>
<li>first</li>
<li>show</li>
<li>take</li>
</ul>
</li>
<li>输出操作<ul>
<li>write。返回DataFrameWrite类实例，提供了多种用于将DataFrame内容保存至数据源的方法。</li>
</ul>
</li>
</ul>
<p>保存DataFrame：    </p>
<p>如果将DataFrame保存到关系型数据库、NoSQL数据存储以及其他各种文件格式的文件中，需要借助DataFrameWrite类，其内部定义将数据写入数据源的接口，可以指定存储格式、分区等属性。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">比如：</span><br><span class="line">jdbcDF.write.jdbc(&quot;jdbc:postgresql:dbserver&quot;, &quot;schema.tablename&quot;, connectionProperties)</span><br></pre></td></tr></table></figure>

<p>可以将DataFrame存储至任何Hadoop支持的存储系统中，包括本地文件系统、HDFS、Amazon S3，可以使用的格式包括Parquet、JSON、OCR、CSV。</p>
<p>《Spark大数据分析》P132</p>
<p>保存DataFrame时，如果目的路径和表已经存在，Spark SQL默认会抛出异常。可以能过mode方法来改变这一行为。mode方法只有一个参数。</p>
<ul>
<li>error。默认，如果目的路径或表存在，抛出异常</li>
<li>append。如果目地路径或表存在，将数据追加到已有的数据中</li>
<li>overwrite。如果存在，覆盖已有的数据</li>
<li>ignore。如果存在，忽略此操作</li>
</ul>
<h2 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h2><p>即可用于DataFrame API，也可以用于SQL接口。前提需要引入一行代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import org.apache.spark.sql.functions._</span><br></pre></td></tr></table></figure>
<p>可以分为几类：聚合操作、集合操作、日期/时间、数学、字符串、窗口操作、其他选项。</p>
<ul>
<li>聚合操作</li>
</ul>
<p>内置的聚合操作函数包括approx_count_distinct、avg、count、countDistinct、first、last、max、min、sum、sumDistinct等</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如：</span><br><span class="line">peopleDF.select(min($&quot;price&quot;))</span><br></pre></td></tr></table></figure>

<ul>
<li>集合操作</li>
</ul>
<p>集合操作函数作用于多列上，这些列包含一个多元素的集合，array_contains、explode、size、sort_array</p>
<ul>
<li>日期/时间</li>
</ul>
<p>对时间类型的值的列处理，又可以细分为转换（一种转换成另一种格式）、抽取（提取年、月、日等）、算术（如：加2天）、其他选项。</p>
<ul>
<li>数学</li>
</ul>
<p>提供一些内置的数学函数，比如，abs、sqrt、ceil、pow等</p>
<ul>
<li>字符串</li>
</ul>
<p>对一个字符串进行分割、大小写转换并删除首尾空白。</p>
<ul>
<li>窗口</li>
</ul>
<h2 id="UDF、UDAF"><a href="#UDF、UDAF" class="headerlink" title="UDF、UDAF"></a>UDF、UDAF</h2><p>spark sql允许用户自定义函数（UDF）和用户定义的聚合函数（UDAF）。UDF每次都在一行数据上进行指定的计算，返回一个值。UDAF则在多行构成的分组上进行指定的聚合操作。</p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 安装、启动</title>
    <url>/middle-software/Spark-stream/</url>
    <content><![CDATA[<h2 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><p>下载地址：<a href="http://spark.apache.org/" target="_blank" rel="noopener">http://spark.apache.org/</a></p>
<a id="more"></a>

<p>根据需要选择安装包，spark-2.1.1-bin-hadoop2.7.tgz</p>
<p>然后解压，并在 vi ~/.bash_profile配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SPARK_HOME&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;spark-2.1.1-bin-hadoop2.7</span><br></pre></td></tr></table></figure>

<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><ul>
<li>启动Master，Master会记录并分配系统资源。</li>
</ul>
<p>并提供界面查看系统的运行情况 ： <a href="http://172.16.104.120:8080/" target="_blank" rel="noopener">http://172.16.104.120:8080/</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;sbin&#x2F;start-master.sh</span><br></pre></td></tr></table></figure>

<ul>
<li>启动工作节点，它将会执行Spark作业</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;spark-class org.apache.spark.deploy.worker.Worker spark:&#x2F;&#x2F;onlyonedeMacBook-Pro.local:7077 &amp;</span><br></pre></td></tr></table></figure>
<ul>
<li>如果想停止所有的进程</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;sbin&#x2F;stop-all.sh</span><br></pre></td></tr></table></figure>

<h2 id="运行任务"><a href="#运行任务" class="headerlink" title="运行任务"></a>运行任务</h2><p>将工程导出jar文件，并保存在$SPARK_HOME根目录下</p>
<p>终端执行下面命令，提交任务：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;spark-submit --class com.data.spark.StudentAvgScore  --master spark:&#x2F;&#x2F;onlyonedeMacBook-Pro.local:7077 spark-core-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;若干spark系统日志</span><br><span class="line">。。。。。</span><br><span class="line">zhangsan的平均分：85.5</span><br><span class="line">lihua的平均分：85.0</span><br><span class="line">xiaoming的平均分：93.0</span><br><span class="line">wangwu的平均分：76.5</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>apollo</title>
    <url>/middle-software/apollo/</url>
    <content><![CDATA[<ul>
<li><p><a href="https://github.com/ctripcorp/apollo" target="_blank" rel="noopener">源代码</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/AxqH7UEepzkY1cTWgcz8uA" target="_blank" rel="noopener">开源配置中心Apollo的设计与实现</a></p>
<a id="more"></a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark集群管理员</title>
    <url>/middle-software/Spark-cluster-admin/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>集群管理员管理着整个计算机集群，如cpu、内存、存储空间、端口、以及集群中节点的其他可用资源。</p>
<a id="more"></a>
<p>在Hadoop2.0中，集群管理员与计算引擎分离开了，变成一个独立组件。可以与任意计算引擎（如：MapReduce、Spark、Tez）一起使用。</p>
<p>Spark支持的三种集群管理员：mesos、yarn、独立集群管理员。Spark提供了脚本供它支持的这些集群管理员来部署Spark应用。</p>
<h2 id="一、独立集群管理员"><a href="#一、独立集群管理员" class="headerlink" title="一、独立集群管理员"></a>一、独立集群管理员</h2><p>Spark默认提供的一种方式。由两个组件：master和work。</p>
<p>worker进程管理单个集群节点上的资源。master进程将所有work计算资源聚合起来并将这些资源分配给应用程序。</p>
<p>启动集群：</p>
<p>1.首先启动master进程，默认是7077端口，其中绑定的ip地址和端口都是可配置的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;sbin&#x2F;start-master.sh</span><br></pre></td></tr></table></figure>
<p>2，然后在每个集群节点上启动worker进程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;sbin&#x2F;start-slave.sh  &lt;master-url&gt;</span><br></pre></td></tr></table></figure>

<p>停止集群：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;sbin&#x2F;stop-slave.sh  &#x2F;&#x2F;所有worker节点全部关闭</span><br><span class="line">.&#x2F;sbin&#x2F;stop-master.sh</span><br></pre></td></tr></table></figure>
<p>由于worker数量较多，采用人工方式启停会越来越麻烦，spark还提供了一个批量脚本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">批量启动：</span><br><span class="line"></span><br><span class="line">1.在spark&#x2F;conf目录下创建一个名为slaves的文件。这个文件包含了所有worker的ip地址，每行一个</span><br><span class="line">2.&#x2F;sbin&#x2F;start-all.sh</span><br><span class="line"></span><br><span class="line">批量停止：</span><br><span class="line">.&#x2F;sbin&#x2F;stop-all.sh</span><br></pre></td></tr></table></figure>

<p>在独立集群上运行Spark应用，可以使用spark-submit脚本。支持两种模式：</p>
<ul>
<li>客户端模式（默认）。</li>
</ul>
<p>当客户端设备和Spark集群处于同一个网络中，推荐使用该模式。另外输入和输出都是启动它时所处的控制台。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;spark-submit  --deploy-mode client  --master &lt;master-url&gt; &lt;jar包路径&gt; [参数]</span><br></pre></td></tr></table></figure>
<ul>
<li>集群模式。</li>
</ul>
<p>当部署Spark应用的设备与Spark集群不在同一个网络时，推荐使用集群模式。它是将输出存储成文件或数据库中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;spark-submit  --deploy-mode cluster  --master &lt;master-url&gt; &lt;jar包路径&gt; [参数]</span><br></pre></td></tr></table></figure>

<h2 id="二、Mesos"><a href="#二、Mesos" class="headerlink" title="二、Mesos"></a>二、Mesos</h2><p>Mesos是一个开源的集群管理员，可以把它当成一个集群计算机的操作系统内核。它将集群设备的计算资源汇总到一起，并且让这些资源能被多种应用程序共享。</p>
<p>特性：</p>
<ul>
<li>支持扩展至数万个节点</li>
<li>可容错的master和slave</li>
<li>多种资源（CPU、内存、磁盘、端口）调度</li>
<li>支持Docker容器</li>
<li>任务之间相到独立</li>
</ul>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/19.jpg/w600">

<p>Mesos由四个组件组成，分别是Mesos-master，mesos-slave，framework和executor。<br>Mesos-master是整个系统的核心，负责管理接入mesos的各个framework（由frameworks_manager管理）和slave（由slaves_manager管理），并将slave上的资源按照某种策略分配给framework（由独立插拔模块Allocator管理）。</p>
<p>Mesos-slave负责接收并执行来自mesos-master的命令、管理节点上的mesos-task，并为各个task分配资源。mesos-slave将自己的资源量发送给mesos-master，由mesos-master中的Allocator模块决定将资源分配给哪个framework，当前考虑的资源有CPU和内存两种，也就是说，mesos-slave会将CPU个数和内存量发送给mesos-master，而用户提交作业时，需要指定每个任务需要的CPU个数和内存量，这样，当任务运行时，mesos-slave会将任务放到包含固定资源的linux container中运行，以达到资源隔离的效果。很明显，master存在单点故障问题，为此，mesos采用了zookeeper解决该问题。</p>
<p>Framework是指外部的计算框架，如Hadoop，Spark等，这些计算框架可通过注册的方式接入mesos，以便mesos进行统一管理和资源分配。Mesos要求可接入的框架必须有一个调度器模块，该调度器负责框架内部的任务调度。当一个framework想要接入mesos时，需要修改自己的调度器，以便向mesos注册，并获取mesos分配给自己的资源， 这样再由自己的调度器将这些资源分配给框架中的任务，也就是说，整个mesos系统采用了双层调度框架：第一层，由mesos将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。当前Mesos支持三种语言编写的调度器，分别是C++，java和python，为了向各种调度器提供统一的接入方式，Mesos内部采用C++实现了一个MesosSchedulerDriver（调度器驱动器），framework的调度器可调用该driver中的接口与Mesos-master交互，完成一系列功能（如注册，资源分配等）。</p>
<p>Executor主要用于启动框架内部的task。由于不同的框架，启动task的接口或者方式不同，当一个新的框架要接入mesos时，需要编写一个executor，告诉mesos如何启动该框架中的task。为了向各种框架提供统一的执行器编写方式，Mesos内部采用C++实现了一个MesosExecutorDiver（执行器驱动器），framework可通过该驱动器的相关接口告诉mesos启动task的方法。</p>
<p>在Mesos集群上运行Spark应用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;spark-submit  --master mesos:&#x2F;&#x2F;zk:&#x2F;&#x2F;ip1:2181,ip2:2181,ip3:2181  &lt;jar包地址&gt; [参数]</span><br></pre></td></tr></table></figure>

<ul>
<li><a href="http://www.jianshu.com/p/257f44167c45" target="_blank" rel="noopener">Mesos简介与安装</a></li>
</ul>
<h2 id="三、YARN"><a href="#三、YARN" class="headerlink" title="三、YARN"></a>三、YARN</h2><p>YARN 集群管理员由两个关键组件构成：ResourceManager（相当于mesos的master）和NodeManager（相当于mesos的slave）。NodeManager管理单个节点上可以使用的资源。它将资源使用情况报告给ResourceManager。ResourceManager管理集群中所有节点上的可使用资源，并分配给不同的应用。</p>
<p>客户端应用向ResourceManager提交作业。如：spark-submit脚本就是一个客户端应用。</p>
<p>使用YARN的一个好处就在于Spark应用和MapReduce应用可以共享同一个集群。如果你已有一个Hadoop集群可以轻松地使用YARN来部署Spark应用。</p>
<p>spark-submit脚本也可以用来在YARN集群上部署spark应用。然而，在YARN集群上启动spark应用时，master url的值要么是yarn-cluster要么是yarn-client。Spark将从Hadoop的配置文件中获取ResourceManager的地址。</p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>TCC-Transaction</title>
    <url>/middle-software/TCC-Transaction/</url>
    <content><![CDATA[<ul>
<li><a href="https://mp.weixin.qq.com/s/Cnn19FwpXnZe5fIzGTNJcg" target="_blank" rel="noopener">源码解析合集</a></li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>cobar源码阅读笔记</title>
    <url>/middle-software/cobar-sourcecode/</url>
    <content><![CDATA[<ul>
<li>启动入口</li>
</ul>
<p>com.alibaba.cobar.CobarStartup</p>
<a id="more"></a>
<ul>
<li>CobarServer初始化</li>
</ul>
<p>com.alibaba.cobar.CobarServer.CobarServer()</p>
<ul>
<li><p>CobarConfig初始化</p>
<ul>
<li><p>借助xml解析器，加载schema.xml配置文件转换为XMLSchemaLoader类实例对象</p>
</li>
<li><p>借助xml解析器，加载server.xml配置文件转换为XMLServerLoader类实例对象</p>
</li>
<li><p>将XMLSchemaLoader和XMLServerLoader的全局变量赋值到XMLConfigLoader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">XMLConfigLoader</span><span class="params">(SchemaLoader schemaLoader)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.functions = Collections.unmodifiableMap(schemaLoader.getFunctions());</span><br><span class="line">    <span class="keyword">this</span>.dataSources = schemaLoader.getDataSources();</span><br><span class="line">    <span class="keyword">this</span>.dataNodes = schemaLoader.getDataNodes();</span><br><span class="line">    <span class="keyword">this</span>.schemas = schemaLoader.getSchemas();</span><br><span class="line">    <span class="keyword">this</span>.rules = schemaLoader.listRuleConfig();</span><br><span class="line">    schemaLoader = <span class="keyword">null</span>;</span><br><span class="line">    XMLServerLoader serverLoader = <span class="keyword">new</span> XMLServerLoader();</span><br><span class="line">    <span class="keyword">this</span>.system = serverLoader.getSystem();</span><br><span class="line">    <span class="keyword">this</span>.users = serverLoader.getUsers();</span><br><span class="line">    <span class="keyword">this</span>.quarantine = serverLoader.getQuarantine();</span><br><span class="line">    <span class="keyword">this</span>.cluster = serverLoader.getCluster();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>构造ConfigInitializer对象</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConfigInitializer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       SchemaLoader schemaLoader = <span class="keyword">new</span> XMLSchemaLoader();</span><br><span class="line">       XMLConfigLoader configLoader = <span class="keyword">new</span> XMLConfigLoader(schemaLoader);</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           RouteRuleInitializer.initRouteRule(schemaLoader);</span><br><span class="line">           schemaLoader = <span class="keyword">null</span>;</span><br><span class="line">       &#125; <span class="keyword">catch</span> (SQLSyntaxErrorException e) &#123;</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> ConfigException(e);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">this</span>.system = configLoader.getSystemConfig();</span><br><span class="line">       <span class="keyword">this</span>.users = configLoader.getUserConfigs();</span><br><span class="line">       <span class="keyword">this</span>.schemas = configLoader.getSchemaConfigs();</span><br><span class="line">       <span class="keyword">this</span>.dataSources = configLoader.getDataSources();</span><br><span class="line">       <span class="keyword">this</span>.dataNodes = initDataNodes(configLoader);</span><br><span class="line">       <span class="keyword">this</span>.quarantine = configLoader.getQuarantineConfig();</span><br><span class="line">       <span class="keyword">this</span>.cluster = initCobarCluster(configLoader);</span><br><span class="line"></span><br><span class="line">       <span class="keyword">this</span>.checkConfig();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li>
<li><p>构造CobarConfig对象，最终赋值给CobarServer</p>
</li>
</ul>
</li>
<li><p>cobar服务启动。com.alibaba.cobar.CobarServer.startup()</p>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 初始化数据节点</span></span><br><span class="line">.....省略</span><br><span class="line"><span class="comment">//数据节点连接空闲超时定时检查</span></span><br><span class="line">.....省略</span><br><span class="line"><span class="comment">// 数据节点心跳任务定时检查</span></span><br><span class="line">...省略</span><br><span class="line"><span class="comment">// cobar最核心的服务进程启动</span></span><br><span class="line">ServerConnectionFactory sf = <span class="keyword">new</span> ServerConnectionFactory();</span><br><span class="line">sf.setCharset(system.getCharset());</span><br><span class="line">sf.setIdleTimeout(system.getIdleTimeout());</span><br><span class="line">server = <span class="keyword">new</span> NIOAcceptor(NAME + <span class="string">"Server"</span>, system.getServerPort(), sf);</span><br><span class="line">server.setProcessors(processors);</span><br><span class="line">server.start();</span><br><span class="line"><span class="comment">// 集群节点定时心跳任务</span></span><br><span class="line">timer.schedule(clusterHeartbeat(), <span class="number">0L</span>, system.getClusterHeartbeatPeriod());</span><br></pre></td></tr></table></figure>
</li>
<li><p>com.alibaba.cobar.net.NIOAcceptor.run()，监听端口的线程任务启动，无限循环</p>
<ul>
<li>如果 ServerSocketChannel接收到连接，封装到FrontendConnection，再借助NIOProcessor，注册到NIOReactor.R.BlockingQueue<NIOConnection> </li>
<li>NIOReactor(网络事件反应器)，将NIOConnection的数据读取</li>
</ul>
</li>
<li><p>com.alibaba.cobar.server.ServerConnection.execute(String, int)</p>
<ul>
<li>状态检查</li>
<li>检查当前使用的DB</li>
<li>路由计算</li>
<li>session执行</li>
</ul>
</li>
</ul>
<p>路由算法：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/10.png/w600">


<p>整体流程图：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/8.png/w600">

<p>从上图中可以看到，Cobar的前、后端模块都实现了MySQL协议；当接受到SQL请求时，会依次进行解释（SQL Parser）和路由（SQL Router）工作，然后使用SQL Executor去后端模块获取数据集（后端模块还负责心跳检测功能）；如果数据集来自多个数据源，Cobar则需要把数据集进行组合（Result Merge），最后返回响应。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/9.jpg/w600">

<p>从上图中可以看出，Cobar采用了主流的Reactor设计模式来处理请求，并使用NIO进行底层的数据交换，这大大提升系统的负载能力。其中，NIOAcceptor用于处理前端请求，NIOConnector则用于管理后端的连接，NIOProcessor用于管理多线程事件处理，NIOReactor则用于完成底层的事件驱动机制，就是看起来和Mina和Netty的网络模型比较相似。</p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark Core 笔记</title>
    <url>/middle-software/Spark-core%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="Spark-Core-笔记"><a href="#Spark-Core-笔记" class="headerlink" title="Spark Core 笔记"></a>Spark Core 笔记</h2><p>Spark允许应用程序利用内存缓存数据。这能减少磁盘IO。一个基于MR的数据处理流水线可能包含多个作业，每个作业都需要从磁盘载入数据，处理它，然后再写入磁盘中。</p>
<a id="more"></a>
<p>Spark不会自动将输入的数据缓存在内存中，一个普遍的误解是，一旦无法把输入的数据载入内存，那么spark将无法使用，这不正确，spark可以在集群上处理太字节级的数据，哪怕集群总内存只有100G，在数据处理流水线上何时缓存数据及缓存哪部分数据完全由应用程序决定。</p>
<p>Spark和Hadoop一样都可以将一个作业转化为由若干阶段构成的有向无环图（DAG）。MR对任意一个作业都会创建由map和reduce两个阶段构成的有向无环图。如果是一个复杂的数据处理由MR实现，则需要划分多个作业，而后顺序执行，这样导致Hadoop无法做任何的优化。相反Spark不会迫使开发者实现数据处理算法时将其划分为多个作业，Spark中的DAG可以包含任意个阶段，一次执行包含多阶段的复杂作业，从而减少磁盘IO和数据shuffle操作时间。因为shuffle操作涉及网络数据传输。</p>
<p>Spark是可容错的，能自动处理集群中的节点故障。</p>
<p>Spark本质是一个使用集群节点进行大数据集处理的计算框架。与数据库不同，它并没有存储系统，但可以搭配外部存储系统，如HDFS、Hbase、Cassandra、Amazon S3等。</p>
<h2 id="架构及生态"><a href="#架构及生态" class="headerlink" title="架构及生态"></a>架构及生态</h2><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/16.png/w600">


<ul>
<li><p>RDD(Resilient Distributed Datasets)，弹性分布式数据集。生成只有两种途径：一种来自内存集合或外部存储系统；另一种是通过转换操作来自于其他RDD，比如map、filter、join等。</p>
<p>  Spark中，所有的计算都是通过RDDs的创建、转换，操作完成的。一个RDD内部由许多partitions(分片)组成。</p>
</li>
<li><p>Spark Core：包含任务调度、内存管理、容错机制等，内部定义了RDD,提供了很多API来创建和操作这些RDD，使的Spark能够更加灵活的处理类似MapReduce的批处理作业</p>
</li>
<li><p>Spark SQL/ Shark：兼容Hive的接口HQL，提供比Hive高出数10~100倍的查询速度的分布式SQL引擎</p>
</li>
<li><p>Spark Streaming：提供了API来操作实时流数据，将流式计算分解成一系列的短小的批处理作业。应用场景，企业中接收kafka消息来做实时统计。</p>
</li>
<li><p>MLlib：迭代式运算，MLlib是构建在Spark上的机器学习算法库，目前支持常用的分类算法、聚类算法、推荐算法，模型评估和数据导入。并支持集群上的横向扩展。</p>
</li>
<li><p>GraphX：基于Spark的图计算框架</p>
</li>
</ul>
<p>Spark架构的组成</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/17.png/w600">

<ul>
<li>Cluster Manager：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器</li>
<li>Worker节点：从节点，负责控制计算节点，启动Executor或者Driver。</li>
<li>Driver： 运行Application 的main()函数</li>
<li>Executor：执行器是一个JVM进程，是为某个Application运行在worker node上的一个进程，可以多线程并发执行应用代码。执行器的生命周期和创建它的应用一样，一旦Spark应用结束，那么为它创建的执行者也将回收。</li>
<li>Task：任务，一个任务对应一个数据分区，由Executor并发调用执行，一个执行者可以执行一个或多个任务。任务的数量由分区的数量决定。更多的分区意味着有更多的任务并发处理数据。</li>
</ul>
<h2 id="运行流程"><a href="#运行流程" class="headerlink" title="运行流程"></a>运行流程</h2><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/18.png/w600">

<ul>
<li>构建Spark Application的运行环境，启动SparkContext</li>
<li>SparkContext向资源管理器（可以是Standalone，Mesos，Yarn）申请运行Executor资源，并启动StandaloneExecutorbackend，</li>
<li>Executor向SparkContext申请Task</li>
<li>SparkContext将应用程序分发给Executor</li>
<li>SparkContext构建成DAG图，将DAG图分解成Stage、将Taskset发送给Task Scheduler，最后由Task Scheduler将Task发送给Executor运行</li>
<li>Task在Executor上运行，运行完释放所有资源</li>
</ul>
<p>特点：</p>
<ul>
<li>每个Application获取专属的executor进程，该进程在Application期间一直驻留，并以多线程方式运行Task。这种Application隔离机制是有优势的，无论是从调度角度看（每个Driver调度他自己的任务），还是从运行角度看（来自不同Application的Task运行在不同JVM中），当然这样意味着Spark Application不能跨应用程序共享数据，除非将数据写入外部存储系统</li>
<li>Spark与资源管理器无关，只要能够获取executor进程，并能保持相互通信就可以了</li>
<li>提交SparkContext的Client应该靠近Worker节点（运行Executor的节点），最好是在同一个Rack里，因为Spark Application运行过程中SparkContext和Executor之间有大量的信息交换</li>
<li>Task采用了数据本地性和推测执行的优化机制</li>
</ul>
<h2 id="大数据处理分为三种情况"><a href="#大数据处理分为三种情况" class="headerlink" title="大数据处理分为三种情况"></a>大数据处理分为三种情况</h2><ul>
<li>复杂的批量数据处理，时间跨度为数十分钟到数小时</li>
<li>基于历史数据的交互式查询，时间跨度为数十秒到数分钟</li>
<li>基于实时数据流的数据处理，通常时间跨度为数百毫秒到数秒</li>
</ul>
<h2 id="Spark与Hadoop的区别："><a href="#Spark与Hadoop的区别：" class="headerlink" title="Spark与Hadoop的区别："></a>Spark与Hadoop的区别：</h2><p>1）hadoop：离线处理；对时效性要求不高。</p>
<p>2）spark：对时效性要求很高的场景，由于基于内存操作，大大加快计算速度。另外可应用机器学习领域。但Spark不具有HDFS的存储能力，要借助HDFS等持久化数据。</p>
<p>下载地址：</p>
<p><a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">http://spark.apache.org/downloads.html</a></p>
<p>spark支持多种方式连接，可以从上面的官网下载，解压，进行bin目录，启动对应的客户端脚本（比如scala或者python），然后就可以在终端敲入代码，执行相应的命令。</p>
<p>通过SparkContext对象访问Spark，SparkContext对象代表和一个集群的连接。</p>
<h2 id="RDD-常用的转换函数"><a href="#RDD-常用的转换函数" class="headerlink" title="RDD 常用的转换函数"></a>RDD 常用的转换函数</h2><ul>
<li><p>map  数据转换，输入1个，输出1个。</p>
</li>
<li><p>filter   过滤，满足条件的保留</p>
</li>
<li><p>flatMap</p>
<p>  对每个输入元素，输出多个输出元素。flat压扁的意思，将RDD中元素压扁后返回一个新的RDD。比如对一行文本按空格分割得到多个单词。</p>
</li>
<li><p>distinct  去重</p>
</li>
<li><p>union 两个RDD合并，不会去重</p>
</li>
<li><p>intersection  两个RDD交集</p>
</li>
<li><p>subtract   （返回一个只存在于第一个RDD而不存在于第二个RDD中的所有元素组成的RDD）</p>
</li>
<li><p>reduce</p>
<p>  接收一个函数，作用在RDD两个类型相同的元素上，返回新元素。可以实现，RDD中元素的累加、计数和其它类型的聚集操作。</p>
</li>
<li><p>结果返回</p>
</li>
</ul>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/20170806_134.png/w600">


<h2 id="Key-Value对-RDDs"><a href="#Key-Value对-RDDs" class="headerlink" title="Key Value对 RDDs"></a>Key Value对 RDDs</h2><ul>
<li><p>使用map（）函数，返回key—value 对</p>
</li>
<li><p>reduceByKey 等函数用法</p>
</li>
</ul>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/20170806_138.png/w600">

<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/20170806_137.png/w600">

<ul>
<li><p>combineByKey  </p>
<p>  最常用的基于key的聚合函数，返回类型可以与输入类型不一样。</p>
</li>
</ul>
<h2 id="RDD-缓存"><a href="#RDD-缓存" class="headerlink" title="RDD 缓存"></a>RDD 缓存</h2><ul>
<li>cache：将RDD存储在集群中执行者的内存中</li>
<li>persist：通用版的cache方法 ，将RDD存储在硬盘上或者内存中。persist支持多种选项：MEMORTY_ONLY、Disk_ONLY、MEMORY_AND_DISK等</li>
</ul>
<h2 id="传递给spark的master-url可以有如下几种："><a href="#传递给spark的master-url可以有如下几种：" class="headerlink" title="传递给spark的master url可以有如下几种："></a>传递给spark的master url可以有如下几种：</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local 本地单线程</span><br><span class="line">local[K] 本地多线程（指定K个内核）</span><br><span class="line">local[*] 本地多线程（指定所有可用内核）</span><br><span class="line">spark:&#x2F;&#x2F;HOST:PORT 连接到指定的 Spark standalone cluster master，需要指定端口。</span><br><span class="line">mesos:&#x2F;&#x2F;HOST:PORT 连接到指定的 Mesos 集群，需要指定端口。</span><br><span class="line">yarn-client客户端模式 连接到 YARN 集群。需要配置 HADOOP_CONF_DIR。</span><br><span class="line">yarn-cluster集群模式 连接到 YARN 集群。需要配置 HADOOP_CONF_DIR。</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="http://www.cnblogs.com/zhoudayang/p/5008010.html" target="_blank" rel="noopener">http://www.cnblogs.com/zhoudayang/p/5008010.html</a></li>
<li><a href="http://www.cnblogs.com/tovin/p/3832405.html" target="_blank" rel="noopener">http://www.cnblogs.com/tovin/p/3832405.html</a></li>
<li><a href="https://mp.weixin.qq.com/s/QCtiRWZhy9xlTqUFUAx3EQ" target="_blank" rel="noopener">超实用的Spark数据倾斜解决姿势</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>cobar相关</title>
    <url>/middle-software/cobar/</url>
    <content><![CDATA[<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><ul>
<li><p><a href="https://github.com/alibaba/cobar" target="_blank" rel="noopener">源代码</a></p>
</li>
<li><p><a href="cobar-sourcecode.md">源码阅读笔记</a></p>
</li>
<li><p><a href="https://github.com/alibaba/cobar/wiki/%E5%B8%B8%E8%A7%81%E9%97%AE%E7%AD%94" target="_blank" rel="noopener">常见问题</a></p>
</li>
</ul>
<a id="more"></a>
<hr>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Cobar是关系型数据的分布式处理系统，它可以在分布式的环境下看上去像传统数据库一样为您提供海量数据服务。</p>
<p>Cobar遵循MySQL协议，访问Cobar的方式与访问MySQL数据库完全相同。</p>
<h1 id="Cobar解决的问题"><a href="#Cobar解决的问题" class="headerlink" title="Cobar解决的问题"></a>Cobar解决的问题</h1><ul>
<li><p>分布式:Cobar的分布式主要是通过将表放入不同的库来实现:</p>
<ul>
<li>Cobar支持将一张表水平拆分成多份分别放入不同的库来实现表的水平拆分</li>
<li>Cobar也支持将不同的表放入不同的库</li>
<li>多数情况下,用户会将以上两种方式混合使用 这里需要强调的是,Cobar不支持将一张表,例如test表拆分成test_1, test_2, test_3…..放在同一个库中, 必须将拆分后的表分别放入不同的库来实现分布式。</li>
</ul>
</li>
<li><p>HA: 在用户配置了MySQL心跳的情况下,Cobar可以自动向后端连接的MySQL发送心跳,判断MySQL运行状 况,一旦运行出现异常,Cobar可以自动切换到备机工作。但需要强调的是:</p>
<ul>
<li>Cobar的主备切换有两种触发方式,一种是用户手动触发,一种是Cobar的心跳语句检测到异常后自动触 发。那么,当心跳检测到主机异常,切换到备机,如果主机恢复了,需要用户手动切回主机工作,Cobar不 会在主机恢复时自动切换回主机,除非备机的心跳也返回异常。<br>SQL主备异常,不关心主备之间的数据同步,因此用户需要在使用Cobar之前在MySQL主 备上配置双向同步,详情可以参阅MySQL参考手册。</li>
</ul>
</li>
</ul>
<p>*<em>注意事项 *</em></p>
<p>1.请注意表的拆分方式,一张表水平拆分多份到不同的库中,而不是放入同一个库中。</p>
<p>2.如果使用HA功能,请在MySQL主备之间配置双向同步</p>
<h1 id="逻辑层次图"><a href="#逻辑层次图" class="headerlink" title="逻辑层次图"></a>逻辑层次图</h1><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/7.png/w600">

<ul>
<li>dataSource:数据源,表示一个具体的数据库连接,与一个物理存在的schema一一对应。 </li>
<li>dataNode:数据节点,由主、备数据源,数据源的HA以及连接池共同组成,可以将一个dataNode理解为一 个分库。</li>
<li>table:表,包括拆分表(如tb1,tb2)和非拆分表。 </li>
<li>tableRule:路由规则,用于判断SQL语句被路由到具体哪些 datanode执行。 </li>
<li>schema:cobar可以定义包含拆分表的schema(如schema1),也可以定义无拆分表的schema(如 schema2)。</li>
<li>以上层次关系具有较强的灵活性,用户可以将表自由放置不同的datanode,也可将不同的datasource放置在 同一MySQL实例上。</li>
</ul>
<h1 id="使用手册"><a href="#使用手册" class="headerlink" title="使用手册"></a>使用手册</h1><p>Cobar的主要目录如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin #包含Cobar的启动、重启、停止等脚本文件 </span><br><span class="line">conf #包含Cobar所有配置文件</span><br><span class="line">lib #包含Cobar及其依赖的jar文件</span><br><span class="line">logs #包含Cobar所有日志文件</span><br></pre></td></tr></table></figure>
<p>Cobar的所有配置文件全部放在conf目录中,进入conf目录,可以看到:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server.xml #Cobar系统、用户、集群等相关配置 </span><br><span class="line">schema.xml #schema,dataNode,dataSource相关配置 </span><br><span class="line">rule.xml #分布式规则定义</span><br><span class="line">log4j.xml #日志相关配置</span><br></pre></td></tr></table></figure>

<ul>
<li>dataSource</li>
</ul>
<p>数据源是一个具体的后端数据连接的表示</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dataSource</span> <span class="attr">name</span>=<span class="string">"ds_shard_master"</span>  <span class="attr">type</span>=<span class="string">"mysql"</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"location"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">location</span>&gt;</span>192.168.0.4:3306/shard<span class="tag">&lt;/<span class="name">location</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!--shard$1-3是shard1、shard2、shard3的缩写,在后续介绍的Cobar配 置中,我们也会经常看到类似的缩写形式--&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">location</span>&gt;</span>192.168.0.4:3306/shard$1-3<span class="tag">&lt;/<span class="name">location</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"user"</span>&gt;</span>test<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span> 		   </span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"sqlMode"</span>&gt;</span>STRICT_TRANS_TABLES<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼<span class="tag">&lt;/<span class="name">dataSource</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>上例中配置了4个数据源,数据源名称分别为ds_shard_master[0]、ds_shard_master[1]、 ds_shard_master[2]、ds_shard_master[3],按照用户location中配置的顺序,对应关系如下:</p>
<table>
<thead>
<tr>
<th>数据源名称</th>
<th>数据源地址</th>
</tr>
</thead>
<tbody><tr>
<td>ds_shard_master[0]</td>
<td>192.168.0.4:3306/shard</td>
</tr>
<tr>
<td>ds_shard_master[1]</td>
<td>192.168.0.4:3306/shard1</td>
</tr>
<tr>
<td>ds_shard_master[2]</td>
<td>192.168.0.4:3306/shard2</td>
</tr>
<tr>
<td>ds_shard_master[3]</td>
<td>192.168.0.4:3306/shard3</td>
</tr>
</tbody></table>
<ul>
<li>dataNode</li>
</ul>
<p>数据节点由主、备数据源,心跳,连接池等配置组成</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dataNode</span> <span class="attr">name</span>=<span class="string">"dn_shard"</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!--三个数据节点的主数据源,可用逗号分隔,支持$1-3的缩写形式, 表示ds_shard_master[1],ds_shard_master[2],ds_shard_master[3]--&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dataSourceRef</span>&gt;</span>ds_shard_master[0],ds_shard_master$1-3<span class="tag">&lt;/<span class="name">dataSourceRef</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!--三个数据节点的备数据源,必须与主数据源一一对应(个数,顺序都要 对应)--&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dataSourceRef</span>&gt;</span>ds_shard_slave$0-3<span class="tag">&lt;/<span class="name">dataSourceRef</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"poolSize"</span>&gt;</span>256<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"heartbeatSQL"</span>&gt;</span>update xdual setx=now() where</span><br><span class="line">id=$&#123;(1,10)&#125;<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">dataNode</span>&gt;</span></span><br><span class="line">￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼</span><br></pre></td></tr></table></figure>
<p>数据节点的主备对应关系如下:</p>
<table>
<thead>
<tr>
<th>节点名称</th>
<th>主数据源</th>
<th>备数据源</th>
</tr>
</thead>
<tbody><tr>
<td>dn_shard[0]</td>
<td>ds_shard_master[0]</td>
<td>ds_shard_slave[0]</td>
</tr>
<tr>
<td>dn_shard[1]</td>
<td>ds_shard_master[1]</td>
<td>ds_shard_slave[1]</td>
</tr>
<tr>
<td>dn_shard[2]</td>
<td>ds_shard_master[2]</td>
<td>ds_shard_slave[2]</td>
</tr>
<tr>
<td>dn_shard[3]</td>
<td>ds_shard_master[3]</td>
<td>ds_shard_slave[3]</td>
</tr>
</tbody></table>
<ul>
<li>schema</li>
</ul>
<p>schema定义了Cobar展示给用户的schema，schema由dataNode以及rule.xml中定义的路由规则共同组成。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">// 所有除tb1,tb2,tb3,tb4之外表的访问都路由到dn_shard[0]去执行</span><br><span class="line"><span class="tag">&lt;<span class="name">schema</span> <span class="attr">name</span>=<span class="string">"db_shard"</span> <span class="attr">dataNode</span>=<span class="string">"dn_shard[0]"</span>&gt;</span></span><br><span class="line">	// 对tb1的访问会根据规则tb1Rule路由到dn_shard$0-3的某一个或某几个datanode执行</span><br><span class="line">	<span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">"tb1"</span> <span class="attr">dataNode</span>=<span class="string">"dn_shard$0-3"</span> <span class="attr">rule</span>=<span class="string">"tb1Rule"</span>/&gt;</span></span><br><span class="line">	// 对tb2的访问会根据规则tb2Rule路由到dn_shard[0],dn_shard[3]的某一个或两个datanode执行</span><br><span class="line">	<span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">"tb2"</span> <span class="attr">dataNode</span>=<span class="string">"dn_shard[0],dn_shard[3]"</span> <span class="attr">rule</span>=<span class="string">"tb2Rule"</span> /&gt;</span></span><br><span class="line">	// 对tb3的访问会根据规则tb3Rule路由到dn_shard$0-3的某一个或某几个datanode执行</span><br><span class="line">	<span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">"tb3"</span> <span class="attr">dataNode</span>=<span class="string">"dn_shard$0-3"</span> <span class="attr">rule</span>=<span class="string">"tb3Rule"</span>/&gt;</span></span><br><span class="line">	// 对tb4的访问会直接路由到dn_shard[2]执行,如果datanode中只有一个node,可以不用配置rule</span><br><span class="line">	<span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">"tb4"</span> <span class="attr">dataNode</span>=<span class="string">"dn_shard[2]"</span> <span class="attr">ruleRequired</span>=<span class="string">"false"</span>/&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">schema</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>rule.xml </li>
</ul>
<p>tableRule主要作用是用来判断SQL语句路由到哪些datanode执行,Cobar是通过在SQL中提取一个或 多个字段的值,并根据这些字段的值来决定路由到哪个库执行。</p>
<p>因此，tableRule定义两个要素: </p>
<p>1）按表中的哪个字段路由?——下文中我们称此字段为路由字段 </p>
<p>2）有了字段值，如何路由?——即路由函数</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">// tableRule名称</span><br><span class="line"><span class="tag">&lt;<span class="name">tableRule</span> <span class="attr">name</span>=<span class="string">"tb1Rule"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">		//id为路由字段, id是int型字段</span><br><span class="line">		<span class="tag">&lt;<span class="name">columns</span>&gt;</span>id<span class="tag">&lt;/<span class="name">columns</span>&gt;</span> 	</span><br><span class="line">		//int_4是路由函数，参数为id，int_4在function中定义</span><br><span class="line">		<span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>&lt;![CDATA[int_4($&#123;id&#125;)]]&gt;<span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">rule</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">tableRule</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">tableRule</span> <span class="attr">name</span>=<span class="string">"tb2Rule"</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">		//val为路由字段，val是varchar型字段</span><br><span class="line">		<span class="tag">&lt;<span class="name">columns</span>&gt;</span>val<span class="tag">&lt;/<span class="name">columns</span>&gt;</span> </span><br><span class="line">		//string_2是路由函数,参数为val</span><br><span class="line">		<span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>&lt;![CDATA[string_2($&#123;val&#125;)]]&gt;<span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">rule</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">tableRule</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">tableRulename="tb3Rule"</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">		//id和val共同组成路由字段，id是int型字段，val是varchar型字段</span><br><span class="line">		<span class="tag">&lt;<span class="name">columns</span>&gt;</span>id,val<span class="tag">&lt;/<span class="name">columns</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>&lt;![CDATA[twoDimensionFunc($&#123;id&#125;,$&#123;val&#125;)]]&gt; <span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">rule</span>&gt;</span> </span><br><span class="line">	//按多个字段路由时需要考虑SQL中只有一个字段的情况 </span><br><span class="line">	<span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">		//当SQL语句中只有id,无val字段时,匹配此规则,val参数设置为 null</span><br><span class="line">		<span class="tag">&lt;<span class="name">columns</span>&gt;</span>id<span class="tag">&lt;/<span class="name">columns</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>&lt;![CDATA[twoDimensionFunc($&#123;pid&#125;,null)]]&gt;<span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span> </span><br><span class="line">	<span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line">	//当SQL语句中只有val,无id字段时,匹配此规则,id参数设置为null</span><br><span class="line">	<span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">columns</span>&gt;</span>val<span class="tag">&lt;/<span class="name">columns</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>&lt;![CDATA[twoDimensionFunc(null,$&#123;uid&#125;)]]&gt;<span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	</span><br><span class="line"><span class="tag">&lt;/<span class="name">tableRule</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Cobar支持按1-2个字段做路由，因此路由算法分为单维路由和多维路由(2维)。</p>
<ul>
<li>server.xml</li>
</ul>
<p>system主要是系统参数定义，包括服务端口、管理端口、处理器个数、线程池等</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">system</span>&gt;</span></span><br><span class="line">//Cobar服务端口,通过此端口执行SQL语句,默认值8066</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"serverPort"</span>&gt;</span>8066<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">//Cobar管理端口,通过此端口执行Cobar管理命令, 默认值9066 </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"managerPort"</span>&gt;</span>9066<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">//initExecutor:处理初始化任务的线程 </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"initExecutor"</span>&gt;</span>16<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">//timerExecutor:处理定时任务的线程</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"timerExecutor"</span>&gt;</span>4<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">//managerExecutor:处理来自9066端口任务的线程</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"managerExecutor"</span>&gt;</span>4<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">//processors:Cobar内部处理器个数,默认与系统cpu个数相同</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"processors"</span>&gt;</span>4<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">//processorHandler:前端处理线程,负责处理所有8066端口前端连接</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"processorHandler"</span>&gt;</span>8<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">//processorExcutor:后端处理线程,负责处理Cobar与MySQL之间的连接,</span><br><span class="line">可以适当设置大一些</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"processorExecutor"</span>&gt;</span>8<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">//Cobar与Cobar间心跳的用户名和密码,默认值即是_HEARTBEAT_USER_和 _HEARTBEAT_PASS_</span><br><span class="line">//如果两台Cobar之间需要心跳,这两项配置必须相同,一般不建议自行配 置,使用默认值即可</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"clusterHeartbeatUser"</span>&gt;</span>_HEARTBEAT_USER_<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"clusterHeartbeatPass"</span>&gt;</span>_HEARTBEAT_PASS_<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">system</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://hualong.iteye.com/blog/2102798" target="_blank" rel="noopener">http://hualong.iteye.com/blog/2102798</a></p>
<p><a href="http://www.cnblogs.com/super-d2/p/4276021.html" target="_blank" rel="noopener">http://www.cnblogs.com/super-d2/p/4276021.html</a></p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解Java内存模型</title>
    <url>/java/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>Java内存模型(Java Memory Model，JMM)是java虚拟机规范定义的，用来屏蔽掉java程序在各种不同的硬件和操作系统对内存的访问的差异，这样就可以实现java程序在各种不同的平台上都能达到内存访问的一致性。<a id="more"></a>可以避免像c++等直接使用物理硬件和操作系统的内存模型在不同操作系统和硬件平台下表现不同，比如有些c/c++程序可能在windows平台运行正常，而在linux平台却运行有问题。</p>
<h1 id="物理硬件和内存"><a href="#物理硬件和内存" class="headerlink" title="物理硬件和内存"></a>物理硬件和内存</h1><p>首先，在单核电脑中，处理问题要简单的多。对内存和硬件的要求，各种方面的考虑没有在多核的情况下复杂。电脑中，CPU的运行计算速度是非常快的，而其他硬件比如IO，网络、内存读取等等，跟cpu的速度比起来是差几个数量级的。而不管任何操作，几乎是不可能都在cpu中完成而不借助于任何其他硬件操作。所以协调cpu和各个硬件之间的速度差异是非常重要的，要不然cpu就一直在等待，浪费资源。而在多核中，不仅面临如上问题，还有如果多个核用到了同一个数据，如何保证数据的一致性、正确性等问题，也是必须要解决的。</p>
<p>目前基于高速缓存的存储交互很好的解决了cpu和内存等其他硬件之间的速度矛盾，多核情况下各个处理器(核)都要遵循一定的诸如MSI、MESI等协议来保证内存的各个处理器高速缓存和主内存的数据的一致性。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/4899162-4ef24c0bc6373591.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/826/format/webp" alt=""></p>
<p>除了增加高速缓存，为了使处理器内部运算单元尽可能被充分利用，处理器还会对输入的代码进行乱序执行(Out-Of-Order Execution)优化，处理器会在乱序执行之后的结果进行重组，保证结果的正确性，也就是保证结果与顺序执行的结果一致。但是在真正的执行过程中，代码执行的顺序并不一定按照代码的书写顺序来执行，可能和代码的书写顺序不同。</p>
<h1 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h1><p>虽然java程序所有的运行都是在虚拟机中，涉及到的内存等信息都是虚拟机的一部分，但实际也是物理机的，只不过是虚拟机作为最外层的容器统一做了处理。虚拟机的内存模型，以及多线程的场景下与物理机的情况是很相似的，可以类比参考。<br>Java内存模型的主要目标是定义程序中变量的访问规则。即在虚拟机中将变量存储到主内存或者将变量从主内存取出这样的底层细节。需要注意的是这里的变量跟我们写java程序中的变量不是完全等同的。这里的变量是指实例字段，静态字段，构成数组对象的元素，但是不包括局部变量和方法参数(因为这是线程私有的)。这里可以简单的认为主内存是java虚拟机内存区域中的堆，局部变量和方法参数是在虚拟机栈中定义的。但是在堆中的变量如果在多线程中都使用，就涉及到了堆和不同虚拟机栈中变量的值的一致性问题了。<br>Java内存模型中涉及到的概念有：</p>
<ol>
<li>主内存：java虚拟机规定所有的变量(不是程序中的变量)都必须在主内存中产生，为了方便理解，可以认为是堆区。可以与前面说的物理机的主内存相比，只不过物理机的主内存是整个机器的内存，而虚拟机的主内存是虚拟机内存中的一部分。</li>
<li>工作内存：java虚拟机中每个线程都有自己的工作内存，该内存是线程私有的为了方便理解，可以认为是虚拟机栈。可以与前面说的高速缓存相比。线程的工作内存保存了线程需要的变量在主内存中的副本。虚拟机规定，线程对主内存变量的修改必须在线程的工作内存中进行，不能直接读写主内存中的变量。不同的线程之间也不能相互访问对方的工作内存。如果线程之间需要传递变量的值，必须通过主内存来作为中介进行传递。</li>
</ol>
<p>这里需要说明一下：主内存、工作内存与java内存区域中的java堆、虚拟机栈、方法区并不是一个层次的内存划分。这两者是基本上是没有关系的，上文只是为了便于理解，做的类比<br><img data-src="https://upload-images.jianshu.io/upload_images/4899162-66736384361f6b8b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/812/format/webp" alt=""></p>
<h2 id="工作内存与主内存交互"><a href="#工作内存与主内存交互" class="headerlink" title="工作内存与主内存交互"></a>工作内存与主内存交互</h2><p>物理机高速缓存和主内存之间的交互有协议，同样的，Java内存中线程的工作内存和主内存的交互是由Java虚拟机定义了如下的8种操作来完成的，每种操作必须是原子性的(double和long类型在某些平台有例外，参考volatile详解和非原子性协定)</p>
<p>Java虚拟机中主内存和工作内存交互，就是一个变量如何从主内存传输到工作内存中，如何把修改后的变量从工作内存同步回主内存。</p>
<ul>
<li>lock(锁定):作用于主内存的变量，一个变量在同一时间只能一个线程锁定，该操作表示这条线成独占这个变量</li>
<li>unlock(解锁):作用于主内存的变量，表示这个变量的状态由处于锁定状态被释放，这样其他线程才能对该变量进行锁定</li>
<li>read(读取):作用于主内存变量，表示把一个主内存变量的值传输到线程的工作内存，以便随后的load操作使用</li>
<li>load(载入):作用于线程的工作内存的变量，表示把read操作从主内存中读取的变量的值放到工作内存的变量副本中(副本是相对于主内存的变量而言的)</li>
<li>use(使用):作用于线程的工作内存中的变量，表示把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时就会执行该操作</li>
<li>assign(赋值):作用于线程的工作内存的变量，表示把执行引擎返回的结果赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的字节码指令时就会执行该操作</li>
<li>store(存储):作用于线程的工作内存中的变量，把工作内存中的一个变量的值传递给主内存，以便随后的write操作使用</li>
<li>write(写入):作用于主内存的变量，把store操作从工作内存中得到的变量的值放入主内存的变量中</li>
</ul>
<p>如果要把一个变量从主内存传输到工作内存，那就要顺序的执行read和load操作，如果要把一个变量从工作内存回写到主内存，就要顺序的执行store和write操作。对于普通变量，虚拟机只是要求顺序的执行，并没有要求连续的执行，所以如下也是正确的。对于两个线程，分别从主内存中读取变量a和b的值，并不一样要read a; load a; read b; load b; 也会出现如下执行顺序：read a; read b; load b; load a; (对于volatile修饰的变量会有一些其他规则,后边会详细列出)，对于这8中操作，虚拟机也规定了一系列规则，在执行这8中操作的时候必须遵循如下的规则：</p>
<ul>
<li>不允许read和load、store和write操作之一单独出现，也就是不允许从主内存读取了变量的值但是工作内存不接收的情况，或者不允许从工作内存将变量的值回写到主内存但是主内存不接收的情况</li>
<li>不允许一个线程丢弃最近的assign操作，也就是不允许线程在自己的工作线程中修改了变量的值却不同步/回写到主内存</li>
<li>不允许一个线程回写没有修改的变量到主内存，也就是如果线程工作内存中变量没有发生过任何assign操作，是不允许将该变量的值回写到主内存</li>
<li>变量只能在主内存中产生，不允许在工作内存中直接使用一个未被初始化的变量，也就是没有执行load或者assign操作。也就是说在执行use、store之前必须对相同的变量执行了load、assign操作</li>
<li>一个变量在同一时刻只能被一个线程对其进行lock操作，也就是说一个线程一旦对一个变量加锁后，在该线程没有释放掉锁之前，其他线程是不能对其加锁的，但是同一个线程对一个变量加锁后，可以继续加锁，同时在释放锁的时候释放锁次数必须和加锁次数相同。</li>
<li>对变量执行lock操作，就会清空工作空间该变量的值，执行引擎使用这个变量之前，需要重新load或者assign操作初始化变量的值</li>
<li>不允许对没有lock的变量执行unlock操作，如果一个变量没有被lock操作，那也不能对其执行unlock操作，当然一个线程也不能对被其他线程lock的变量执行unlock操作</li>
<li>对一个变量执行unlock之前，必须先把变量同步回主内存中，也就是执行store和write操作<br>当然，最重要的还是如开始所说，这8个动作必须是原子的，不可分割的。<br>针对volatile修饰的变量，会有一些特殊规定。</li>
</ul>
<h2 id="volatile修饰的变量的特殊规则"><a href="#volatile修饰的变量的特殊规则" class="headerlink" title="volatile修饰的变量的特殊规则"></a>volatile修饰的变量的特殊规则</h2><p>关键字volatile可以说是java虚拟机中提供的最轻量级的同步机制。java内存模型对volatile专门定义了一些特殊的访问规则。这些规则有些晦涩拗口，先列出规则，然后用更加通俗易懂的语言来解释：<br>假定T表示一个线程，V和W分别表示两个volatile修饰的变量，那么在进行read、load、use、assign、store和write操作的时候需要满足如下规则：</p>
<ul>
<li>只有当线程T对变量V执行的前一个动作是load，线程T对变量V才能执行use动作；同时只有当线程T对变量V执行的后一个动作是use的时候线程T对变量V才能执行load操作。所以，线程T对变量V的use动作和线程T对变量V的read、load动作相关联，必须是连续一起出现。也就是在线程T的工作内存中，每次使用变量V之前必须从主内存去重新获取最新的值，用于保证线程T能看得见其他线程对变量V的最新的修改后的值。</li>
<li>只有当线程T对变量V执行的前一个动作是assign的时候，线程T对变量V才能执行store动作；同时只有当线程T对变量V执行的后一个动作是store的时候，线程T对变量V才能执行assign动作。所以，线程T对变量V的assign操作和线程T对变量V的store、write动作相关联，必须一起连续出现。也即是在线程T的工作内存中，每次修改变量V之后必须立刻同步回主内存，用于保证线程T对变量V的修改能立刻被其他线程看到。</li>
<li>假定动作A是线程T对变量V实施的use或assign动作，动作F是和动作A相关联的load或store动作，动作P是和动作F相对应的对变量V的read或write动作；类似的，假定动作B是线程T对变量W实施的use或assign动作，动作G是和动作B相关联的load或store动作，动作Q是和动作G相对应的对变量W的read或write动作。如果动作A先于B，那么P先于Q。也就是说在同一个线程内部，被volatile修饰的变量不会被指令重排序，保证代码的执行顺序和程序的顺序相同。</li>
</ul>
<p>总结上面三条规则，前面两条可以概括为：volatile类型的变量保证对所有线程的可见性。第三条为：volatile类型的变量禁止指令重排序优化。</p>
<ul>
<li>valatile类型的变量保证对所有线程的可见性<br>可见性是指当一个线程修改了这个变量的值，新值（修改后的值）对于其他线程来说是立即可以得知的。正如上面的前两条规则规定，volatile类型的变量每次值被修改了就立即同步回主内存，每次使用时就需要从主内存重新读取值。返回到前面对普通变量的规则中，并没有要求这一点，所以普通变量的值是不会立即对所有线程可见的。</li>
</ul>
<p>误解：volatile变量对所有线程是立即可见的，所以对volatile变量的所有修改(写操作)都立刻能反应到其他线程中。或者换句话说：volatile变量在各个线程中是一致的，所以基于volatile变量的运算在并发下是线程安全的。</p>
<p>这个观点的论据是正确的，但是根据论据得出的结论是错误的，并不能得出这样的结论。volatile的规则，保证了read、load、use的顺序和连续行，同理assign、store、write也是顺序和连续的。也就是这几个动作是原子性的，但是对变量的修改，或者对变量的运算，却不能保证是原子性的。如果对变量的修改是分为多个步骤的，那么多个线程同时从主内存拿到的值是最新的，但是经过多步运算后回写到主内存的值是有可能存在覆盖情况发生的。如下代码的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileTest</span> </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    race++</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> THREADS_COUNT = <span class="number">20</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="keyword">static</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      Thread[] threads = <span class="keyword">new</span> Thread[THREADS_COUNT);</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> = <span class="number">0</span>; i &lt; THREADS_COUNT; i++) &#123;</span><br><span class="line">          threads[i] = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable()&#123;</span><br><span class="line">              <span class="meta">@Override</span></span><br><span class="line">              <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                  <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                     increase();</span><br><span class="line">                  &#125;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;);</span><br><span class="line">          threads[i].start();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">1</span>) &#123;</span><br><span class="line">         Thread.yield();</span><br><span class="line">      &#125;</span><br><span class="line">      System.out.println(race);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码就是对volatile类型的变量启动了20个线程，每个线程对变量执行1w次加1操作，如果volatile变量并发操作没有问题的话，那么结果应该是输出20w，但是结果运行的时候每次都是小于20w，这就是因为race++操作不是原子性的，是分多个步骤完成的。假设两个线程a、b同时取到了主内存的值，是0，这是没有问题的，在进行++操作的时候假设线程a执行到一半，线程b执行完了，这时线程b立即同步给了主内存，主内存的值为1，而线程a此时也执行完了，同步给了主内存，此时的值仍然是1，线程b的结果被覆盖掉了。</p>
<h2 id="volatile变量禁止指令重排序优化"><a href="#volatile变量禁止指令重排序优化" class="headerlink" title="volatile变量禁止指令重排序优化"></a>volatile变量禁止指令重排序优化</h2><p>普通的变量仅仅会保证在该方法执行的过程中，所有依赖赋值结果的地方都能获取到正确的结果，但不能保证变量赋值的操作顺序和程序代码的顺序一致。因为在一个线程的方法执行过程中无法感知到这一点，这也就是java内存模型中描述的所谓的“线程内部表现为串行的语义”。<br>也就是在单线程内部，我们看到的或者感知到的结果和代码顺序是一致的，即使代码的执行顺序和代码顺序不一致，但是在需要赋值的时候结果也是正确的，所以看起来就是串行的。但实际结果有可能代码的执行顺序和代码顺序是不一致的。这在多线程中就会出现问题。<br>看下面的伪代码举例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map configOptions;</span><br><span class="line"><span class="keyword">char</span>[] configText;</span><br><span class="line"><span class="comment">//volatile类型bianliang</span></span><br><span class="line"><span class="keyword">volatile</span> <span class="keyword">boolean</span> initialized = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//假设以下代码在线程A中执行</span></span><br><span class="line"><span class="comment">//模拟读取配置信息，读取完成后认为是初始化完成</span></span><br><span class="line">configOptions = <span class="keyword">new</span> HashMap();</span><br><span class="line">configText = readConfigFile(fileName);</span><br><span class="line">processConfigOptions(configText, configOptions);</span><br><span class="line">initialized = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//假设以下代码在线程B中执行</span></span><br><span class="line"><span class="comment">//等待initialized为true后，读取配置信息进行操作</span></span><br><span class="line"><span class="keyword">while</span> ( !initialized) &#123;</span><br><span class="line">  sleep();</span><br><span class="line">&#125;</span><br><span class="line">doSomethingWithConfig();</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">如果initialiezd是普通变量，没有被<span class="keyword">volatile</span>修饰，那么线程A执行的代码的修改初始化完成的结果initialized = <span class="keyword">true</span>就有可能先于之前的三行代码执行，而此时线程B发现initialized为<span class="keyword">true</span>了，就执行doSomethingWithConfig()方法，但是里面的配置信息都是<span class="keyword">null</span>的，就会出现问题了。</span><br><span class="line">现在initialized是<span class="keyword">volatile</span>类型变量，保证禁止代码重排序优化，那么就可以保证initialized = <span class="keyword">true</span>执行的时候，前边的三行代码一定执行完成了，那么线程B读取的配置文件信息就是正确的。</span><br><span class="line"></span><br><span class="line">跟其他保证并发安全的工具相比，<span class="keyword">volatile</span>的性能确实会好一些。在某些情况下，<span class="keyword">volatile</span>的同步机制性能要优于锁(使用<span class="keyword">synchronized</span>关键字或者java.util.concurrent包中的锁)。但是现在由于虚拟机对锁的不断优化和实行的许多消除动作，很难有一个量化的比较。</span><br><span class="line">与自己相比，就可以确定一个原则：<span class="keyword">volatile</span>变量的读操作和普通变量的读操作几乎没有差异，但是写操作会性能差一些，慢一些，因为要在本地代码中插入许多内存屏障指令来禁止指令重排序，保证处理器不发生代码乱序执行行为。</span><br><span class="line"></span><br><span class="line">## long和double变量的特殊规则</span><br><span class="line">Java内存模型要求对主内存和工作内存交换的八个动作是原子的，正如章节开头所讲，对<span class="keyword">long</span>和<span class="keyword">double</span>有一些特殊规则。八个动作中lock、unlock、read、load、use、assign、store、write对待<span class="number">32</span>位的基本数据类型都是原子操作，对待<span class="keyword">long</span>和<span class="keyword">double</span>这两个<span class="number">64</span>位的数据，java虚拟机规范对java内存模型的规定中特别定义了一条相对宽松的规则：允许虚拟机将没有被<span class="keyword">volatile</span>修饰的<span class="number">64</span>位数据的读写操作划分为两次<span class="number">32</span>位的操作来进行，也就是允许虚拟机不保证对<span class="number">64</span>位数据的read、load、store和write这<span class="number">4</span>个动作的操作是原子的。这也就是我们常说的<span class="keyword">long</span>和<span class="keyword">double</span>的非原子性协定(Nonautomic Treatment of <span class="keyword">double</span> and <span class="keyword">long</span> Variables)。</span><br><span class="line"></span><br><span class="line">## 并发内存模型的实质</span><br><span class="line">Java内存模型围绕着并发过程中如何处理原子性、可见性和顺序性这三个特征来设计的。</span><br><span class="line"></span><br><span class="line">- 原子性(Automicity)</span><br><span class="line">由Java内存模型来直接保证原子性的变量操作包括read、load、use、assign、store、write这<span class="number">6</span>个动作，虽然存在<span class="keyword">long</span>和<span class="keyword">double</span>的特例，但基本可以忽律不计，目前虚拟机基本都对其实现了原子性。如果需要更大范围的控制，lock和unlock也可以满足需求。lock和unlock虽然没有被虚拟机直接开给用户使用，但是提供了字节码层次的指令monitorenter和monitorexit对应这两个操作，对应到java代码就是<span class="keyword">synchronized</span>关键字，因此在<span class="keyword">synchronized</span>块之间的代码都具有原子性。</span><br><span class="line"></span><br><span class="line">- 可见性</span><br><span class="line">可见性是指一个线程修改了一个变量的值后，其他线程立即可以感知到这个值的修改。正如前面所说，<span class="keyword">volatile</span>类型的变量在修改后会立即同步给主内存，在使用的时候会从主内存重新读取，是依赖主内存为中介来保证多线程下变量对其他线程的可见性的。</span><br><span class="line"></span><br><span class="line">除了<span class="keyword">volatile</span>，<span class="keyword">synchronized</span>和<span class="keyword">final</span>也可以实现可见性。<span class="keyword">synchronized</span>关键字是通过unlock之前必须把变量同步回主内存来实现的，<span class="keyword">final</span>则是在初始化后就不会更改，所以只要在初始化过程中没有把<span class="keyword">this</span>指针传递出去也能保证对其他线程的可见性。</span><br><span class="line"></span><br><span class="line">- 有序性</span><br><span class="line">有序性从不同的角度来看是不同的。单纯单线程来看都是有序的，但到了多线程就会跟我们预想的不一样。可以这么说：如果在本线程内部观察，所有操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句说的就是“线程内表现为串行的语义”，后半句值得是“指令重排序”现象和主内存与工作内存之间同步存在延迟的现象。</span><br><span class="line"></span><br><span class="line">保证有序性的关键字有<span class="keyword">volatile</span>和<span class="keyword">synchronized</span>，<span class="keyword">volatile</span>禁止了指令重排序，而<span class="keyword">synchronized</span>则由“一个变量在同一时刻只能被一个线程对其进行lock操作”来保证。</span><br><span class="line"></span><br><span class="line">总体来看，<span class="keyword">synchronized</span>对三种特性都有支持，虽然简单，但是如果无控制的滥用对性能就会产生较大影响。</span><br><span class="line"></span><br><span class="line">## 先行发生原则</span><br><span class="line">如果Java内存模型中所有的有序性都要依靠<span class="keyword">volatile</span>和<span class="keyword">synchronized</span>来实现，那是不是非常繁琐。Java语言中有一个“先行发生原则”，是判断数据是否存在竞争、线程是否安全的主要依据。</span><br><span class="line"></span><br><span class="line">### 什么是先行发生原则</span><br><span class="line">先行发生原则是Java内存模型中定义的两个操作之间的偏序关系。比如说操作A先行发生于操作B，那么在B操作发生之前，A操作产生的“影响”都会被操作B感知到。这里的影响是指修改了内存中的共享变量、发送了消息、调用了方法等。个人觉得更直白一些就是有可能对操作B的结果有影响的都会被B感知到，对B操作的结果没有影响的是否感知到没有太大关系。</span><br><span class="line"></span><br><span class="line">### Java内存模型自带先行发生原则有哪些</span><br><span class="line">- 程序次序原则</span><br><span class="line">在一个线程内部，按照代码的顺序，书写在前面的先行发生与后边的。或者更准确的说是在控制流顺序前面的先行发生与控制流后面的，而不是代码顺序，因为会有分支、跳转、循环等。</span><br><span class="line">- 管程锁定规则</span><br><span class="line">一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须注意的是对同一个锁，后面是指时间上的后面</span><br><span class="line">- <span class="keyword">volatile</span>变量规则</span><br><span class="line">对一个<span class="keyword">volatile</span>变量的写操作先行发生与后面对这个变量的读操作，这里的后面是指时间上的先后顺序</span><br><span class="line">- 线程启动规则</span><br><span class="line">Thread对象的start()方法先行发生与该线程的每个动作。当然如果你错误的使用了线程，创建线程后没有执行start方法，而是执行run方法，那此句话是不成立的，但是如果这样其实也不是线程了</span><br><span class="line">- 线程终止规则</span><br><span class="line">线程中的所有操作都先行发生与对此线程的终止检测，可以通过Thread.join()和Thread.isAlive()的返回值等手段检测线程是否已经终止执行</span><br><span class="line">- 线程中断规则</span><br><span class="line">对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。</span><br><span class="line">- 对象终结规则</span><br><span class="line">一个对象的初始化完成先行发生于他的finalize方法的执行，也就是初始化方法先行发生于finalize方法</span><br><span class="line">- 传递性</span><br><span class="line">如果操作A先行发生于操作B，操作B先行发生于操作C，那么操作A先行发生于操作C。</span><br><span class="line">看一个例子:</span><br><span class="line">```java</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> value = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setValue</span><span class="params">(<span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.value = value;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getValue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">this</span>.value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果有两个线程A和B，A先调用setValue方法，然后B调用getValue方法，那么B线程执行方法返回的结果是什么？</p>
<p>我们去对照先行发生原则一个一个对比。首先是程序次序规则，这里是多线程，不在一个线程中，不适用；然后是管程锁定规则，这里没有synchronized，自然不会发生lock和unlock，不适用；后面对于线程启动规则、线程终止规则、线程中断规则也不适用，这里与对象终结规则、传递性规则也没有关系。所以说B返回的结果是不确定的，也就是说在多线程环境下该操作不是线程安全的。</p>
<p>如何修改呢，一个是对get/set方法加入synchronized 关键字，可以使用管程锁定规则；要么对value加volatile修饰，可以使用volatile变量规则。</p>
<p>通过上面的例子可知，一个操作时间上先发生并不代表这个操作先行发生，那么一个操作先行发生是不是代表这个操作在时间上先发生？也不是，如下面的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> j = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>在同一个线程内，对i的赋值先行发生于对j赋值的操作，但是代码重排序优化，也有可能是j的赋值先发生，我们无法感知到这一变化。</p>
<p>所以，综上所述，时间先后顺序与先行发生原则之间基本没有太大关系。我们衡量并发安全的问题的时候不要受到时间先后顺序的干扰，一切以先行发生原则为准。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java的JIT知识整理</title>
    <url>/java/Java%E7%9A%84JIT%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h2 id="1-什么是JIT："><a href="#1-什么是JIT：" class="headerlink" title="1. 什么是JIT："></a>1. 什么是JIT：</h2><p>JIT编译器（just in time 即时编译器），当虚拟机发现某个方法或代码块运行特别频繁时，就会把这些代码认定为(Hot Spot Code 热点代码，为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各层次的优化，完成这项任务的正是JIT编译器。</p>
<a id="more"></a>
<h2 id="2-JIT的工作原理"><a href="#2-JIT的工作原理" class="headerlink" title="2. JIT的工作原理"></a>2. JIT的工作原理</h2><p><img data-src="https://upload-images.jianshu.io/upload_images/1917623-2624a58354221aed.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/330/format/webp" alt="JIT的工作原理图"></p>
<h2 id="3-JIT编译"><a href="#3-JIT编译" class="headerlink" title="3. JIT编译"></a>3. JIT编译</h2><p>对于 Java 代码，刚开始都是被编译器编译成字节码文件，然后字节码文件会被交由 JVM 解释执行，所以可以说 Java 本身是一种半编译半解释执行的语言。</p>
<p>当JIT编译启用时（默认是启用的），JVM读入.class文件解释后，将其发给JIT编译器。JIT编译器将字节码编译成本机机器代码。</p>
<p>通常Javac将程序源码编译，转换成java字节码，JVM通过解释字节码将其翻译成相应的机器指令，逐条读入，逐条解释翻译。<br>经过解释运行，其运行速度必定会比可运行的二进制字节码程序慢。为了提高运行速度，引入了JIT技术。</p>
<p>在执行时JIT会把翻译过的机器码保存起来，已备下次使用，因此从理论上来说，采用该JIT技术能够，能够接近曾经纯编译技术。</p>
<p>现在主流的商用虚拟机（如Sun HotSpot、IBM J9 如 # 各大主流的虚拟机比较<br>）中几乎都同时包含``解释器和编译器（三大商用虚拟机之一的JRockit是个例外，它内部没有解释器，因此会有启动相应时间长之类的缺点，但它主要是面向服务端的应用，这类应用一般不会重点关注启动时间）。<br>二者各有优势：当程序需要迅速启动和执行时，解释器可以首先发挥作用，省去编译的时间，立即执行；当程序运行后，随着时间的推移，编译器逐渐会返回作用，把越来越多的代码编译成本地代码后，可以获取更高的执行效率。解释执行可以节约内存，而编译执行可以提升效率。</p>
<p>HotSpot虚拟机中内置了两个JIT编译器：Client Complier和Server Complier，分别用在客户端和服务端，目前主流的HotSpot虚拟机中默认是采用解释器与其中一个编译器直接配合的方式工作。</p>
<p>运行过程中会被即时编译器编译的热点代码有两类：被多次调用的方法。``被多次调用的循环体。<br>这两种情况，编译器都是以整个方法作为编译对象，这种编译也是虚拟机中标准的编译方式。要知道一段代码或方法是不是热点代码，是不是需要触发即时编译，需要进行Hot Spot Detection（热点探测）。</p>
<p>目前主要的热点 判定方式有以下两种：</p>
<ol>
<li>基于采样的热点探测：<br>采用这种方法的虚拟机会周期性地检查各个线程的栈顶，如果发现某些方法经常出现在栈顶，那这段方法代码就是“热点代码”。这种探测方法的好处是实现简单高效，还可以很容易地获取方法调用关系，缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。</li>
<li>基于计数器的热点探测：<br>采用这种方法的虚拟机会为每个方法，甚至是代码块建立计数器，统计方法的执行次数，如果执行次数超过一定的阀值，就认为它是“热点方法”。这种统计方法实现复杂一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是它的统计结果相对更加精确严谨。</li>
</ol>
<p>HotSpot虚拟机中使用的是第二种:基于计数器的热点探测方法，因此它为每个方法准备了两个计数器：方法调用计数器和回边计数器。</p>
<ol>
<li><p>方法调用计数器<br>方法调用计数器用来统计方法调用的次数，在默认设置下，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间内方法被调用的次数。</p>
</li>
<li><p>回边计数器<br>用于统计一个方法中循环体代码执行的次数（准确地说，应该是回边的次数，因为并非所有的循环都是回边），在字节码中遇到控制流向后跳转的指令就称为“回边”。</p>
</li>
</ol>
<p>JIT编译。触发了JIT编译后，在默认设置下，执行引擎并不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成为止（编译工作在后台线程中进行）。当编译工作完成后，下一次调用该方法或代码时，就会使用已编译的版本。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/1917623-1068b27cb819b4db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/545/format/webp" alt="方法调用计数器触发即时编译的流程(回边计数器触发即时编译的过程类似)"></p>
<p>注: Javac字节码编译器与虚拟机内的JIT编译器的执行过程合起来其实就等同于一个传统的编译器所执行的编译过程。</p>
<h2 id="Java和C-C-的编译器对比"><a href="#Java和C-C-的编译器对比" class="headerlink" title="Java和C/C++的编译器对比"></a>Java和C/C++的编译器对比</h2><p>这里不是比Java和C/C++谁快这种大坑问题，只是比较编译器（我个人认为开发效率上Java快，执行效率上C/C++快）</p>
<p>这种对比代表了经典的即时编译器与静态编译期的对比，其实总体来说Java编译器有优有劣。主要就是动态编译时间压力大能做的优化少，还要做一些动态校验。而静态编译器无法实现一些开发上很有用的动态特性。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>dubbo 源代码笔记整理</title>
    <url>/middle-software/dubbo-sourcecode/</url>
    <content><![CDATA[<h1 id="框架总体介绍"><a href="#框架总体介绍" class="headerlink" title="框架总体介绍"></a>框架总体介绍</h1><p>模块关系</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-2.png/w600">

<p>模块说明</p>
<ul>
<li>dubbo-common 公共逻辑模块，包括Util类和通用模型。</li>
<li>dubbo-remoting 远程通讯模块，相当于Dubbo协议的实现，如果RPC用RMI协议则不需要使用此包。</li>
<li>dubbo-rpc 远程调用模块，抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。</li>
<li>dubbo-cluster 集群模块，将多个服务提供方伪装为一个提供方，包括：负载均衡, 容错，路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发。</li>
<li>dubbo-registry 注册中心模块，基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。</li>
<li>dubbo-monitor 监控模块，统计服务调用次数，调用时间的，调用链跟踪的服务。</li>
<li>dubbo-config 配置模块，是Dubbo对外的API，用户通过Config使用Dubbo，隐藏Dubbo所有细节。</li>
<li>dubbo-container 容器模块，是一个Standlone的容器，以简单的Main加载Spring启动，因为服务通常不需要Tomcat/JBoss等Web容器的特性，没必要用Web容器去加载服务。</li>
</ul>
<p>整体上按照分层结构进行分包，与分层的不同点在于：</p>
<ul>
<li>container为服务容器，用于部署运行服务，没有在层中画出。</li>
<li>protocol层和proxy层都放在rpc模块中，这两层是rpc的核心，在不需要集群时(只有一个提供者)，可以只使用这两层完成rpc调用。</li>
<li>transport层和exchange层都放在remoting模块中，为rpc调用的通讯基础。</li>
<li>serialize层放在common模块中，以便更大程度复用。</li>
</ul>
<p>各层说明</p>
<ul>
<li>config，配置层，对外配置接口，以ServiceConfig, ReferenceConfig为中心，可以直接new配置类，也可以通过spring解析配置生成配置类</li>
<li>proxy，服务代理层，服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory</li>
<li>registry，注册中心层，封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory, Registry, RegistryService</li>
<li>cluster，路由层，封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster, Directory, Router, LoadBalance</li>
<li>monitor，监控层，RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory, Monitor, MonitorService</li>
<li>protocol，远程调用层，封将RPC调用，以Invocation, Result为中心，扩展接口为Protocol, Invoker, Exporter</li>
<li>exchange，信息交换层，封装请求响应模式，同步转异步，以Request, Response为中心，扩展接口为Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer</li>
<li>transport，网络传输层，抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel, Transporter, Client, Server, Codec</li>
<li>serialize，数据序列化层，可复用的一些工具，扩展接口为Serialization, ObjectInput, ObjectOutput, ThreadPool</li>
</ul>
<p>关系说明：</p>
<ul>
<li>在RPC中，Protocol是核心层，也就是只要有Protocol + Invoker + Exporter就可以完成非透明的RPC调用，然后在Invoker的主过程上Filter拦截点。</li>
<li>图中的Consumer和Provider是抽象概念，只是想让看图者更直观的了解哪些类分属于客户端与服务器端，不用Client和Server的原因是Dubbo在很多场景下都使用Provider, Consumer, Registry, Monitor划分逻辑拓普节点，保持统一概念。</li>
<li>而Cluster是外围概念，所以Cluster的目的是将多个Invoker伪装成一个Invoker，这样其它人只要关注Protocol层Invoker即可，加上Cluster或者去掉Cluster对其它层都不会造成影响，因为只有一个提供者时，是不需要Cluster的。</li>
<li>Proxy层封装了所有接口的透明化代理，而在其它层都以Invoker为中心，只有到了暴露给用户使用时，才用Proxy将Invoker转成接口，或将接口实现转成Invoker，也就是去掉Proxy层RPC是可以Run的，只是不那么透明，不那么看起来像调本地服务一样调远程服务。</li>
<li>而Remoting实现是Dubbo协议的实现，如果你选择RMI协议，整个Remoting都不会用上，Remoting内部再划为Transport传输层和Exchange信息交换层，Transport层只负责单向消息传输，是对Mina,Netty,Grizzly的抽象，它也可以扩展UDP传输，而Exchange层是在传输层之上封装了Request-Response语义。</li>
<li>Registry和Monitor实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在一起。</li>
</ul>
<p>依赖关系：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-3.png/w600">

<h1 id="全局调用链"><a href="#全局调用链" class="headerlink" title="全局调用链"></a>全局调用链</h1><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-4.png/w600">

<h1 id="Spring识别并加载dubbo的xml配置"><a href="#Spring识别并加载dubbo的xml配置" class="headerlink" title="Spring识别并加载dubbo的xml配置"></a>Spring识别并加载dubbo的xml配置</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot;</span><br><span class="line">       xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">       xmlns:dubbo&#x3D;&quot;http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&quot;</span><br><span class="line">       xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans</span><br><span class="line">        http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd</span><br><span class="line">        http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo</span><br><span class="line">        http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&#x2F;dubbo.xsd&quot;&gt;</span><br><span class="line"></span><br><span class="line">&lt;dubbo:monitor address&#x3D;&quot;$&#123;dubbo.monitor.address&#125;&quot;&#x2F;&gt;</span><br><span class="line"></span><br><span class="line">&lt;dubbo:application name&#x3D;&quot;应用名&quot; owner&#x3D;&quot;&quot;&#x2F;&gt;</span><br><span class="line"></span><br><span class="line">&lt;dubbo:registry protocol&#x3D;&quot;zookeeper&quot; address&#x3D;&quot;$&#123;dubbo.zk.servers&#125;&quot; client&#x3D;&quot;zkclient&quot; group&#x3D;&quot;$&#123;dubbo.zk.group&#125;&quot;   file&#x3D;&quot;dubbo-reg-zk.cache&quot;&#x2F;&gt;</span><br><span class="line"> </span><br><span class="line">&lt;dubbo:protocol name&#x3D;&quot;dubbo&quot; port&#x3D;&quot;$&#123;dubbo.service.provider.port&#125;&quot; threadpool&#x3D;&quot;cached&quot; threads&#x3D;&quot;$&#123;dubbo.service.provider.threads:200&#125;&quot;&#x2F;&gt;</span><br><span class="line"></span><br><span class="line">&lt;dubbo:service interface&#x3D;&quot;com.alibaba.dubbo.demo.DemoService&quot; ref&#x3D;&quot;demoService&quot; &#x2F;&gt;</span><br><span class="line"></span><br><span class="line">&lt;bean id&#x3D;&quot;demoService&quot; class&#x3D;&quot;com.alibaba.dubbo.demo.provider.DemoServiceImpl&quot; &#x2F;&gt;</span><br><span class="line">            </span><br><span class="line">&lt;&#x2F;beans&gt;</span><br></pre></td></tr></table></figure>

<p>Spring提供了可扩展Schema的支持，解析自定义的xml文件，然后转化为配置对象。主要步骤：</p>
<ul>
<li>设计配置属性和JavaBean</li>
<li>编写xsd文件</li>
<li>编写NamespaceHandler和BeanDefinitionParser完成解析工作</li>
<li>编写spring.handlers和spring.schemas串联起所有部件</li>
<li>开始使用bean实例对象</li>
</ul>
<p>dubbo框架实现的子类分别是<br>com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler和com.alibaba.dubbo.config.spring.schema.DubboBeanDefinitionParser将xml配置转换为类实例对象。</p>
<p>参考例子：<a href="http://blog.csdn.net/cutesource/article/details/5864562" target="_blank" rel="noopener">http://blog.csdn.net/cutesource/article/details/5864562</a></p>
<p>dubbo的xml配置与对应业务类的映射关系：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler</span><br><span class="line"></span><br><span class="line">registerBeanDefinitionParser(&quot;application&quot;, new DubboBeanDefinitionParser(ApplicationConfig.class, true));</span><br><span class="line">registerBeanDefinitionParser(&quot;module&quot;, new DubboBeanDefinitionParser(ModuleConfig.class, true));</span><br><span class="line">registerBeanDefinitionParser(&quot;registry&quot;, new DubboBeanDefinitionParser(RegistryConfig.class, true));</span><br><span class="line">registerBeanDefinitionParser(&quot;monitor&quot;, new DubboBeanDefinitionParser(MonitorConfig.class, true));</span><br><span class="line">registerBeanDefinitionParser(&quot;provider&quot;, new DubboBeanDefinitionParser(ProviderConfig.class, true));</span><br><span class="line">registerBeanDefinitionParser(&quot;consumer&quot;, new DubboBeanDefinitionParser(ConsumerConfig.class, true));</span><br><span class="line">registerBeanDefinitionParser(&quot;protocol&quot;, new DubboBeanDefinitionParser(ProtocolConfig.class, true));</span><br><span class="line">registerBeanDefinitionParser(&quot;service&quot;, new DubboBeanDefinitionParser(ServiceBean.class, true));</span><br><span class="line">registerBeanDefinitionParser(&quot;reference&quot;, new DubboBeanDefinitionParser(ReferenceBean.class, false));</span><br><span class="line">registerBeanDefinitionParser(&quot;annotation&quot;, new DubboBeanDefinitionParser(AnnotationBean.class, true));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>说明：</p>
<p>org.springframework.beans.factory.xml.NamespaceHandlerSupport.registerBeanDefinitionParser(String, BeanDefinitionParser)</p>
<p>a）第一个参数，表示子节点名，比如“<a href="dubbo:service/">dubbo:service/</a>” 中的service</p>
<p>b) 第二个参数，表示节点的解析器</p>
<h1 id="核心配置组件"><a href="#核心配置组件" class="headerlink" title="核心配置组件"></a>核心配置组件</h1><table>
<thead>
<tr>
<th>schema格式</th>
<th>类模板</th>
<th>内部属性</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><a href="dubbo:service/">dubbo:service/</a></td>
<td>com.alibaba.dubbo.config.ServiceConfig</td>
<td><a href="https://github.com/alibaba/dubbo/wiki/user-guide-configuration-ref" target="_blank" rel="noopener">链接</a></td>
<td>服务配置，用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心</td>
</tr>
<tr>
<td><a href="dubbo:reference/">dubbo:reference/</a></td>
<td>com.alibaba.dubbo.config.ReferenceConfig</td>
<td>同上</td>
<td>引用配置，用于创建一个远程服务代理，一个引用可以指向多个注册中心。</td>
</tr>
<tr>
<td><a href="dubbo:protocol/">dubbo:protocol/</a></td>
<td>com.alibaba.dubbo.config.ProtocolConfig</td>
<td>同上</td>
<td>协议配置，用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受</td>
</tr>
<tr>
<td><a href="dubbo:application/">dubbo:application/</a></td>
<td>com.alibaba.dubbo.config.ApplicationConfig</td>
<td>同上</td>
<td>应用配置，用于配置当前应用信息，不管该应用是提供者还是消费者</td>
</tr>
<tr>
<td><a href="dubbo:module/">dubbo:module/</a></td>
<td>com.alibaba.dubbo.config.ModuleConfig</td>
<td>同上</td>
<td>模块配置，用于配置当前模块信息，可选。</td>
</tr>
<tr>
<td><a href="dubbo:registry/">dubbo:registry/</a></td>
<td>com.alibaba.dubbo.config.RegistryConfig</td>
<td>同上</td>
<td>注册中心配置，用于配置连接注册中心相关信息</td>
</tr>
<tr>
<td><a href="dubbo:monitor/">dubbo:monitor/</a></td>
<td>com.alibaba.dubbo.config.MonitorConfig</td>
<td>同上</td>
<td>监控中心配置，用于配置连接监控中心相关信息，可选。</td>
</tr>
<tr>
<td><a href="dubbo:provider/">dubbo:provider/</a></td>
<td>com.alibaba.dubbo.config.ProviderConfig</td>
<td>同上</td>
<td>提供方的缺省值，当ProtocolConfig和ServiceConfig某属性没有配置时，采用此缺省值，可选。</td>
</tr>
<tr>
<td><a href="dubbo:consumer/">dubbo:consumer/</a></td>
<td>com.alibaba.dubbo.config.ConsumerConfig</td>
<td>同上</td>
<td>消费方缺省配置，当ReferenceConfig某属性没有配置时，采用此缺省值，可选。</td>
</tr>
<tr>
<td><a href="dubbo:method/">dubbo:method/</a></td>
<td>com.alibaba.dubbo.config.MethodConfig</td>
<td>同上</td>
<td>方法配置，用于ServiceConfig和ReferenceConfig指定方法级的配置信息</td>
</tr>
<tr>
<td><a href="dubbo:argument/">dubbo:argument/</a></td>
<td>com.alibaba.dubbo.config.ArgumentConfig</td>
<td>同上</td>
<td>用于指定方法参数配置。</td>
</tr>
</tbody></table>
<p>类依赖关系：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-config.jpg/w600">

<p>注意：只有group，interface，version是服务的匹配条件，三者决定是不是同一个服务，其它配置项均为调优和治理参数。</p>
<p>所有配置最终都将转换为URL表示，并由服务提供方生成，经注册中心传递给消费方，各属性对应URL的参数，参见配置项一览表中的”对应URL参数”列。</p>
<p>URL格式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dubbo:&#x2F;&#x2F;192.168.21.58:20130&#x2F;com.alibaba.dubbo.demo.DemoService?anyhost&#x3D;true&amp;application&#x3D;bbs-service&amp;dubbo&#x3D;2.5.3&amp;interface&#x3D;com.alibaba.dubbo.demo.DemoService&amp;methods&#x3D;getSimpleMemberByUids,getMasterMemberInfo,getUidsByWcuids,getUserInfoListByWcuids,getForumModeratorByUidAndFid,getMemberInfoByUsernames,clearMemberCache,getMemberCountByUids,addDav,updateBio,updateMemberCount,getLastTidsByUids,batchGetMemberProfileModel,getWcuidsByUids,isDav,getUidByWcuid,updateLastTid,saveName,getMemberDetailModelListByUids,register&amp;pid&#x3D;4481&amp;revision&#x3D;0.0.1&amp;side&#x3D;provider&amp;threadpool&#x3D;cached&amp;threads&#x3D;200&amp;timestamp&#x3D;1490614869341</span><br></pre></td></tr></table></figure>


<h1 id="lt-dubbo-service-gt-内部实现"><a href="#lt-dubbo-service-gt-内部实现" class="headerlink" title="&lt;dubbo:service/&gt; 内部实现"></a>&lt;dubbo:service/&gt; 内部实现</h1><p>服务提供方暴露服务的初始化链，时序图如下：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-5.png/w600">

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、Protocol是服务域，它是Invoker暴露和引用的主功能入口，它负责Invoker的生命周期管理。</span><br><span class="line">2、Invoker是实体域，它是Dubbo的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起invoke调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。</span><br><span class="line">3、Invocation是会话域，它持有调用过程中的变量，比如方法名，参数等。</span><br></pre></td></tr></table></figure>
<p>服务提供者暴露一个服务的详细过程</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-7.jpg/w600">

<p>上图是服务提供者暴露服务的主过程：</p>
<p>首先ServiceConfig类拿到对外提供服务的实际类ref(如：HelloWorldImpl),然后通过ProxyFactory类的getInvoker方法使用ref生成一个AbstractProxyInvoker实例，到这一步就完成具体服务到Invoker的转化。接下来就是Invoker转换到Exporter的过程。</p>
<p>Dubbo处理服务暴露的关键就在Invoker转换到Exporter的过程(如上图中的红色部分)，下面我们以Dubbo和RMI这两种典型协议的实现来进行说明：</p>
<p>1、Dubbo的实现<br>Dubbo协议的Invoker转为Exporter发生在DubboProtocol类的export方法，它主要是打开socket侦听服务，并接收客户端发来的各种请求，通讯细节由Dubbo自己实现。</p>
<p>2、RMI的实现<br>RMI协议的Invoker转为Exporter发生在RmiProtocol类的export方法，<br>它通过Spring或Dubbo或JDK来实现RMI服务，通讯细节这一块由JDK底层来实现，这就省了不少工作量。</p>
<p>代码调用细节：</p>
<ul>
<li>public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener, BeanNameAware {<br>}</li>
</ul>
<p>入口在afterPropertiesSet（）方法，从spring容器中查找这些bean（ProviderConfig、ApplicationConfig、ModuleConfig、List&lt;RegistryConfig&gt;、MonitorConfig、 List&lt;ProtocolConfig&gt;、），并set到ServiceBean</p>
<ul>
<li>com.alibaba.dubbo.config.ServiceConfig.export()。支持延时暴露服务（启动了一个Thread来实现）</li>
<li>com.alibaba.dubbo.rpc.proxy.jdk.JdkProxyFactory.getInvoker(T, Class<T>, URL)，生成AbstractProxyInvoker代理类</li>
<li>com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol.export(Invoker<T>)，生成一个<br>Exporter实例。这样当网络通讯层收到一个请求后，会找到对应的Exporter实例，并调用它所对应的AbstractProxyInvoker实例，从而真正调用了服务提供者的代码。</li>
</ul>
<h1 id="lt-dubbo-reference-gt-内部实现"><a href="#lt-dubbo-reference-gt-内部实现" class="headerlink" title="&lt;dubbo:reference/&gt; 内部实现"></a>&lt;dubbo:reference/&gt; 内部实现</h1><p>服务消费方引用服务的初始化链，时序图如下：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-6.jpg/w600">

<p>服务消费者消费一个服务的详细过程</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-8.jpg/w600">

<p>首先ReferenceConfig类的init方法调用Protocol的refer方法生成Invoker实例(如上图中的红色部分)，这是服务消费的关键，Invoker实现了真正的远程服务调用。接下来把Invoker转换为客户端需要的接口(如：HelloWorld)。</p>
<p>由于Invoker是Dubbo领域模型中非常重要的一个概念，很多设计思路都是向它靠拢。这就使得Invoker渗透在整个实现代码里，对于刚开始接触Dubbo的人，确实容易给搞混了。<br>下面我们用一个精简的图来说明最重要的两种Invoker：服务提供Invoker和服务消费Invoker：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-9.jpg/w600">


<h1 id="服务节点路由选择"><a href="#服务节点路由选择" class="headerlink" title="服务节点路由选择"></a>服务节点路由选择</h1><p>位于【dubbo-cluster】模块</p>
<ul>
<li>com.alibaba.dubbo.rpc.cluster.loadbalance.RandomLoadBalance：随机（默认方式）</li>
<li>com.alibaba.dubbo.rpc.cluster.loadbalance.RoundRobinLoadBalance：轮询</li>
<li>com.alibaba.dubbo.rpc.cluster.loadbalance.LeastActiveLoadBalance：最少连接数</li>
<li>com.alibaba.dubbo.rpc.cluster.loadbalance.ConsistentHashLoadBalance：一致性hash</li>
</ul>
<p>核心思想：</p>
<p>protected <T> Invoker<T> doSelect(List&lt;Invoker<T>&gt; invokers, URL url, Invocation invocation)；从invokers列表中，根据算法选择一个合适Invoker来执行具体业务。</p>
<h1 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h1><p>com.alibaba.dubbo.registry.RegistryService：注册服务。提供以下方法：</p>
<ul>
<li>void register(URL url);注册数据，比如：提供者地址，消费者地址，路由规则，覆盖规则，等数据。</li>
<li>void unregister(URL url);取消注册</li>
<li>void subscribe(URL url, NotifyListener listener);订阅符合条件的已注册数据，当有注册数据变更时自动推送</li>
<li>void unsubscribe(URL url, NotifyListener listener);取消订阅</li>
<li>List<URL> lookup(URL url);查询符合条件的已注册数据，与订阅的推模式相对应，这里为拉模式，只返回一次结果</li>
</ul>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-11.png/w600">

<p>实现子类：</p>
<ul>
<li>com.alibaba.dubbo.registry.redis.RedisRegistry，负责维护redis缓存存储的注册中心数据</li>
<li>com.alibaba.dubbo.registry.zookeeper.ZookeeperRegistry，负责维护zk存储的注册中心数据<ul>
<li>提供了注册、取消注册、订阅等一系列功能的具体实现</li>
<li>ZookeeperRegistry.toUrlPath(URL)，通过“/”拼接的路径节点，与zk的树型结构非常匹配，每个接口服务下分别提供了providers和consumers两个中间节点，存储服务节点和消费节点的配置信息。</li>
</ul>
</li>
</ul>
<p>com.alibaba.dubbo.registry.NotifyListener。当收到服务变更通知时触发</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">通知需处理契约：</span><br><span class="line">1. 总是以服务接口和数据类型为维度全量通知，即不会通知一个服务的同类型的部分数据，用户不需要对比上一次通知结果。</span><br><span class="line">2. 订阅时的第一次通知，必须是一个服务的所有类型数据的全量通知。&lt;br&gt;</span><br><span class="line">3. 中途变更时，允许不同类型的数据分开通知，比如：providers, consumers, routers, overrides，允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。&lt;br&gt;</span><br><span class="line">4. 如果一种类型的数据为空，需通知一个empty协议并带category参数的标识性URL数据。&lt;br&gt;</span><br><span class="line">5. 通知者(即注册中心实现)需保证通知的顺序，比如：单线程推送，队列串行化，带版本对比。&lt;br&gt;</span><br></pre></td></tr></table></figure>
<h1 id="心跳中心"><a href="#心跳中心" class="headerlink" title="心跳中心"></a>心跳中心</h1><p>com.alibaba.dubbo.monitor.simple.RegistryContainer，取到RegistryService，实现subscribe节点数据变更方法。</p>
<h1 id="网络数据传输"><a href="#网络数据传输" class="headerlink" title="网络数据传输"></a>网络数据传输</h1><p>负责客户端与服务端、客户端与注册中心、服务端与注册中心等服务器间的数据通信。底层接口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">com.alibaba.dubbo.remoting.Transporter</span><br><span class="line">com.alibaba.dubbo.remoting.Server</span><br><span class="line">com.alibaba.dubbo.remoting.Client</span><br></pre></td></tr></table></figure>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-10.png/w600">

<p>支持多种通信框架：</p>
<ul>
<li>com.alibaba.dubbo.remoting.transport.transporter.netty.NettyTransporter</li>
<li>com.alibaba.dubbo.remoting.transport.transporter.mina.MinaTransporter</li>
<li>com.alibaba.dubbo.remoting.transport.transporter.grizzly.GrizzlyTransporter</li>
</ul>
<h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h1><p><a href="https://github.com/alibaba/dubbo/wiki/user-guide-sample#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1" target="_blank" rel="noopener">https://github.com/alibaba/dubbo/wiki/user-guide-sample#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1</a></p>
<p><a href="http://dubbo.io/Developer+Guide-zh.htm#DeveloperGuide-zh-%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B%E7%BB%86%E8%8A%82" target="_blank" rel="noopener">http://dubbo.io/Developer+Guide-zh.htm#DeveloperGuide-zh-%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B%E7%BB%86%E8%8A%82</a></p>
<p><a href="https://mp.weixin.qq.com/s/pN39RfZ4qKRLRScJ7LVfGQ" target="_blank" rel="noopener">Dubbo 源码解析 —— 简单原理、与spring融合</a></p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据相关的其它框架</title>
    <url>/middle-software/big-data/</url>
    <content><![CDATA[<ul>
<li><a href="presto.md">presto</a></li>
<li><a href="Flink.md">Flink</a></li>
<li><a href="https://github.com/apache/flume" target="_blank" rel="noopener">Flume</a></li>
</ul>
<a id="more"></a>
<ul>
<li><a href="">Sqoop</a></li>
<li><a href="">Pig</a></li>
<li><a href="MogonDB.md">MogonDB</a></li>
<li><a href="Storm.md">Storm</a></li>
<li><a href="https://github.com/alibaba/oceanbase/tree/master/oceanbase_0.4" target="_blank" rel="noopener">Oceanbase</a></li>
<li><a href="">Oozie</a></li>
<li><a href="">kettle</a></li>
<li><a href="http://blog.csdn.net/dashenghuahua/article/details/53462604" target="_blank" rel="noopener">ApacheBeam</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>swagger</title>
    <url>/java-other/swagger/</url>
    <content><![CDATA[<ul>
<li><a href="http://swagger.io/" target="_blank" rel="noopener">官方文档</a></li>
<li><a href="http://www.cnblogs.com/java-zhao/p/5348113.html" target="_blank" rel="noopener">springboot + swagger</a></li>
<li><a href="https://my.oschina.net/zzuqiang/blog/793606" target="_blank" rel="noopener">swagger注解类使用说明</a></li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>apollo</title>
    <url>/middle-software/dubbo/</url>
    <content><![CDATA[<h2 id="dubbo相关"><a href="#dubbo相关" class="headerlink" title="dubbo相关"></a>dubbo相关</h2><hr>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><ul>
<li><p><a href="https://github.com/alibaba/dubbo" target="_blank" rel="noopener">源码</a></p>
</li>
<li><p><a href="dubbo-sourcecode.md">源码阅读笔记</a></p>
</li>
<li><p><a href="https://github.com/aalansehaiyang/dubbo" target="_blank" rel="noopener">fork分支</a></p>
</li>
<li><p><a href="https://dubbo.gitbooks.io/dubbo-user-book/" target="_blank" rel="noopener">dubbo用户手册</a></p>
</li>
<li><p><a href="https://dubbo.gitbooks.io/dubbo-admin-book/install/zookeeper.html" target="_blank" rel="noopener">dubbo管理员手册</a></p>
</li>
<li><p><a href="https://dubbo.gitbooks.io/dubbo-dev-book/" target="_blank" rel="noopener">dubbo开发者手册</a></p>
</li>
<li><p><a href="http://dubbo.wangxingrong.com/FAQ.htm" target="_blank" rel="noopener">Dubbo FAQ</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/xbq8080/p/6813579.html" target="_blank" rel="noopener">dubbo monitor</a></p>
</li>
</ul>
<h3 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h3><ul>
<li><a href="http://www.oschina.net/search?q=dubbo&scope=project&fromerr=OSwWxF3l" target="_blank" rel="noopener">http://www.oschina.net/search?q=dubbo&amp;scope=project&amp;fromerr=OSwWxF3l</a></li>
<li><a href="http://dubbo.io/User+Guide-zh.htm" target="_blank" rel="noopener">http://dubbo.io/User+Guide-zh.htm</a></li>
<li><a href="">《可伸缩服务架构–框架与中间件》（第8章 Dubbo实战及源码分析）</a></li>
</ul>
<h3 id="前沿"><a href="#前沿" class="headerlink" title="前沿"></a>前沿</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/2AQMrV7hFTJt3SpXONT_uQ" target="_blank" rel="noopener">独家专访阿里高级技术专家北纬：Dubbo开源重启半年来的快意江湖</a></li>
</ul>
<hr>
<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/dubbo-1.jpg/w600">


<ul>
<li><p>单一应用架构</p>
<p>  当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。<br>此时，用于简化增删改查工作量的 数据访问框架(ORM) 是关键。</p>
</li>
<li><p>垂直应用架构<br>  当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。<br>此时，用于加速前端页面开发的 Web框架(MVC) 是关键。</p>
</li>
<li><p>分布式服务架构 </p>
<p>  当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。<br>此时，用于提高业务复用及整合的 分布式服务框架(RPC) 是关键。</p>
</li>
<li><p>流动计算架构</p>
<p>  当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。<br>此时，用于提高机器利用率的 资源调度和治理中心(SOA) 是关键。</p>
</li>
</ul>
<h4 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h4><ul>
<li>远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。</li>
<li>集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。</li>
<li>自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。</li>
</ul>
<h4 id="常见问题："><a href="#常见问题：" class="headerlink" title="常见问题："></a>常见问题：</h4><p>1、dubbo默认有重试机制（2次），结合自己的业务是否需要重试，不必要的重试可能会导致脏数据。<br>如果服务提供方响应速度慢，不断的重试，会额外加重系统负担。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dubbo:reference id&#x3D;&quot;privateMessageService&quot; interface&#x3D;&quot;com.onlyone.bbs.service.PrivateMessageService&quot;  retries&#x3D;&quot;0&quot; &#x2F;&gt;</span><br></pre></td></tr></table></figure>

<p>2.启动时服务是否注册检查，这种情况一般在预发环境遇到，有些业务部门的服务没有布预发环境，会导致我们的应用在预发环境启动不了。启动时需要取消检查</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;单个服务维度</span><br><span class="line"> &lt;dubbo:reference id&#x3D;&quot;stockService&quot; interface&#x3D;&quot;com.onlyone.stock.service.StockService&quot; check&#x3D;&quot;false&quot;  &#x2F;&gt;</span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F;全局维度</span><br><span class="line">&lt;dubbo:consumer check&#x3D;&quot;false&quot; &#x2F;&gt;</span><br></pre></td></tr></table></figure>

<p>3.调用远程接口，如果因为非正常原因而响应慢会阻塞业务线程，此时需要及早结束。<br>可以配置超时时间</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dubbo:reference id&#x3D;&quot;memberService&quot; interface&#x3D;&quot;com.onlyone.bbs.service.MemberService&quot; timeout&#x3D;&quot;5000&quot;  &#x2F;&gt;</span><br></pre></td></tr></table></figure>

<p>4.dubbo默认是随机路由方式，如果消费方只有一台机器，服务提供方有多台，1对多关系，可能会产生负载不均衡，导致大量请求压到一台机器，把一台机器压死，进而引发雪崩效应。可以调整路由策略，改为轮询方式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dubbo:reference id&#x3D;&quot;***&quot; interface&#x3D;&quot;******&quot; loadbalance&#x3D;&quot;roundrobin&quot; &#x2F;&gt;</span><br></pre></td></tr></table></figure>

<p>5.<a href="https://dubbo.gitbooks.io/dubbo-user-book/best-practice.html" target="_blank" rel="noopener">项目中使用注意事项</a></p>
<ul>
<li>分包</li>
<li>粒度</li>
<li>版本</li>
<li>兼容性</li>
<li>枚举值</li>
<li>序列化</li>
<li>异常</li>
<li>调用 </li>
</ul>
<p>6.服务注册不上怎么办？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">检查暴露服务的 Spring 配置有没有加载</span><br><span class="line">查看有没有错误日志</span><br><span class="line">在服务提供者机器上测试与注册中心的网络是否通畅(telnet 172.22.3.94 20880)</span><br><span class="line">检查与注册中心的连接是否存在(netstat -anp | grep 172.22.3.94)</span><br></pre></td></tr></table></figure>

<p>7.RpcException: No provider available for the service 异常怎么办？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">表示没有可用的服务提供者：</span><br><span class="line"></span><br><span class="line">检查连接的注册中心地址是否正确(若是 Zookeeper 注册中心，根节点(registry.group)是否一样)</span><br><span class="line">到监控中心&#x2F;注册中心查看相应的服务提供者是否存在</span><br><span class="line">检查服务提供者是否正常运行</span><br></pre></td></tr></table></figure>

<p>8.出现调用超时 TimeoutException 异常怎么办？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">通常是业务(提供方)处理太慢，也可能是网络抖动引起。 如果一直超时，可在服务提供方执行：jstack PID &gt; jstack.log 分析线程都卡在哪个方法调用上，这里就是慢的原因。 如果不能调优性能，请将 timeout 设大</span><br></pre></td></tr></table></figure>
<p>9.出现 RpcException: Forbid consumer xxx access service XxxService from registry 异常怎么办？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">该异常表示有服务提供者注册到注册中心，但服务提供者与消费者未匹配。那服务的路由规则是什么？ 默认的路由规则是 服务名&#x3D;[group&#x2F;]serviceName[:version]。</span><br><span class="line"></span><br><span class="line">检查两边应用的注册中心与服务相关配置是否完全一样：</span><br><span class="line"></span><br><span class="line">注册中心：dubbo.registry.address、dubbo.registry.group</span><br><span class="line">服务：ServiceInterface、group、version</span><br></pre></td></tr></table></figure>

<p>10.Dubbo 服务注册的地址与实际部署的机器地址不一样</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">某业务同学反馈，在 172.16.47.59 上面部署了一个应用，部署完结果在注册中心显示这个服务的IP不是在实际部署的机器上。 之前没清理dubbo的cache文件显示在 172.16.50.196，清理缓存以后显示在 172.16.47.53 上面。(dubbo-2.5.3)</span><br><span class="line"></span><br><span class="line">问题根源：NetUtils.getLocalHost() 调用的 InetAddress.getLocalHost() 返回了一个错误的IP地址。 其原理是通过获取本机的 hostname，然后对此 hostname 做解析，从而获取IP地址。 即机器的 hostname 映射的IP地址不是机器实际的IP地址。</span><br><span class="line"></span><br><span class="line">解决方案：</span><br><span class="line"></span><br><span class="line">修改 hostname</span><br><span class="line">在 &#x2F;etc&#x2F;hosts 中配置 hostname -&gt; 本机IP地址</span><br></pre></td></tr></table></figure>

<p>11.zookeeper.KeeperException$UnimplementedException: KeeperErrorCode = Unimplemented for {root.path}</p>
<p>Dubbo 应用使用 ZooKeeper 作为注册中心，启动时报该异常。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">问题根源：Curator&#x2F;ZooKeeper的JAR版本不匹配ZooKeeper服务器安装的版本</span><br></pre></td></tr></table></figure>

<p>12.Curator 报 NoSuchMethodError: org.apache.zookeeper.server.quorum.flexible.QuorumMaj.(Ljava/util/Map;)V</p>
<p>Dubbo 应用使用 ZooKeeper 作为注册中心，启动时发生该异常。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">问题根源：QuorumMaj类未定义单个Map参数的构造函数，而EnsembleTracker类却引用了它</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>ehcache</title>
    <url>/middle-software/ehcache/</url>
    <content><![CDATA[<ul>
<li><a href="http://raychase.iteye.com/blog/1545906" target="_blank" rel="noopener">本地缓存、磁盘存储 — Ehcache</a></li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>ElasticSearch应用场景</title>
    <url>/middle-software/elasticsearch-application/</url>
    <content><![CDATA[<h1 id="基本查询"><a href="#基本查询" class="headerlink" title="基本查询"></a>基本查询</h1><ul>
<li>词条查询。仅匹配在给定字段中含有该词条的文档，而且是确切的、未经分析的词条。</li>
<li>多词条查询。匹配那些在内容中含有某些词条的文档。可以通过设置minimum_match的值来说明想至少保证有多少个词同时被匹配上。</li>
</ul>
<a id="more"></a>
<ul>
<li><p>match_all查询。匹配索引中的所有的文件。</p>
</li>
<li><p>常用词查询。考虑到查询条件的词越多，查询性能越低。所以将词分为两类：一类，是重要的词，出现的频率较低；另一类，是出现频率较高，如：”的”，但不那么重要的词。</p>
</li>
<li><p>match查询</p>
</li>
<li><p>multi_match查询。基本与match一样，不同的是它不是针对单个字段，而是针对多个字段执行相同的 match 查询。</p>
</li>
<li><p>match_phrase。精确匹配一系列单词或者短语 。 比如， 我们想执行这样一个查询，仅匹配同时包含 “rock” 和 “climbing” ，并且二者以短语 “rock climbing” 的形式紧挨着的雇员记录。</p>
</li>
<li><p>query_string查询</p>
</li>
<li><p>simple_query_string查询</p>
</li>
<li><p>标识符查询</p>
</li>
<li><p>前缀查询。配置与词条查询类似。如：查询所有的name字段以tom开始的文档。</p>
</li>
<li><p>fuzzy_like_this查询</p>
</li>
<li><p>fuzzy_like_this_field查询</p>
</li>
<li><p>fuzzy查询</p>
</li>
<li><p>通配符查询。允许我们在查询值中使用<em>和？等通配符。如“cr\</em>me”，表示字段里以cr开头me结尾的文档。</p>
</li>
<li><p>more_like_this查询</p>
</li>
<li><p>more_like_this_field查询</p>
</li>
<li><p>range 范围查询</p>
<p>  查询某一个字段值在某一个范围里的文档，字段可以是数值型，也可以是基于字符串的。比如找到年龄在20到30之间的学生。</p>
</li>
<li><p>最大分查询</p>
</li>
<li><p>正则表达式查询</p>
</li>
<li><p>term 查询。</p>
<p>  查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些 not_analyzed 的字符串。而无需对查询结果进行评分计算。</p>
</li>
<li><p>exists 查询和 missing 查询。</p>
<p>  用于查找那些指定字段中有值 (exists) 或无值 (missing) 的文档。这与SQL中的 IS_NULL (missing) 和 NOT IS_NULL (exists) 在本质上是相同的。</p>
</li>
</ul>
<h1 id="复合查询"><a href="#复合查询" class="headerlink" title="复合查询"></a>复合查询</h1><ul>
<li>布尔查询</li>
</ul>
<p>在多个字段上查询多种多样的文本，并且根据一系列的标准来过滤，将多查询组合成单一查询。可以用 bool 查询来实现你的需求。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">must 文档 必须 匹配这些条件才能被包含进来。</span><br><span class="line">must_not 文档 必须不 匹配这些条件才能被包含进来。</span><br><span class="line">should 如果满足这些语句中的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。</span><br><span class="line">filter 必须 匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。</span><br></pre></td></tr></table></figure>

<ul>
<li>加权查询</li>
<li>constant_score查询</li>
<li>索引查询</li>
</ul>
<h1 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h1><p>filter 过滤器不影响评分，只是选择索引中的某个子集。过滤器很容易被缓存，从而进一步提高过滤查询的性能。另外过滤器提供了十几种不同类型，如：范围过滤器、脚本过滤器等等，可以根据不同场景选择合适的。</p>
<h1 id="深入搜索"><a href="#深入搜索" class="headerlink" title="深入搜索"></a>深入搜索</h1><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/search-in-depth.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/search-in-depth.html</a><br>里面提供了多维度、更灵活的搜索场景以及案例。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/13.png/w600">


<h1 id="排序与相关性"><a href="#排序与相关性" class="headerlink" title="排序与相关性"></a>排序与相关性</h1><p>相关性得分由一个浮点数进行表示，并在搜索结果中通过 _score 参数返回， 默认排序是 _score 降序。</p>
<ul>
<li><p>按单个字段的值排序</p>
</li>
<li><p>多级排序</p>
<p>  比如我们想要结合使用 date 和 _score 进行查询，并且匹配的结果首先按照日期排序，然后按照相关性排序。<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/_Sorting.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/_Sorting.html</a><br>。多级排序并不一定包含 _score 。你可以根据一些不同的字段进行排序， 如地理距离或是脚本计算的特定值。</p>
</li>
</ul>
<h1 id="基于poi经纬度地理位置的查询"><a href="#基于poi经纬度地理位置的查询" class="headerlink" title="基于poi经纬度地理位置的查询"></a>基于poi经纬度地理位置的查询</h1><ul>
<li>基于距离的排序。按照与给定地点的距离来对结果排序。</li>
<li>边界框过滤。搜索条件提供左上及右下的坐标，搜索被矩形框住的选定区域。</li>
<li>距离的限制。把结果限定为离基准点一个选定的距离之内，比如把结果限定为离巴黎半径500公里以内。</li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark Streaming 笔记</title>
    <url>/middle-software/Spark-stream%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>Spark Streaming是一个库，它使得Spark能够处理实时数据流。它运行在Spark之上，并提供了用于处理数据流的高阶API。它将Spark变成了一个分布式流数据处理框架。</p>
<a id="more"></a>
<p>StreamingContext是Spark Streaming库的入口。</p>
<p>var ssc = new StreamingContext(sparkConf, Seconds(5))，其中第二个参数指定每一批的大小，以时间为单位。数据流根据这个时间间隔分割成批，每一批数据都被当成一个RDD来处理。每一批的大小可以低至500毫秒。</p>
<p>ssc.checkpoint(“path-to-checkpoint-directory”)，会让Spark Streaming定期创建检查点数据，生产环境，最好是HDFS存储系统，有很好的容错。</p>
<p>ssc.start() ，开始启动流式计算</p>
<p>ssc.awaitTermination()，如果应用是多线程的，并且调用start方法的是其他线程，而不是主线程，必须使用awaitTermination方法，以避免主线程过早退出。start方法是一个阻塞方法，直到流式计算结束或停止，这个方法才返回。</p>
<p>DStream（离散数据流）是处理数据流的主要抽象。其本质还是RDD，Spark Streaming将在DStream上的操作转换成底层RDD上的操作。所以它具有RDD的关键特征：不可变，分区并且容错。</p>
<p>创建Dstream，可以从一个数据流来源创建，也可以通过现有的DStream执行转换操作得到。</p>
<ul>
<li>socketTextStream：从TCP套接字连接接收数据流的DStream</li>
<li>textFileStream：监控hadoop的文件系统上是否有新文件创建，如果有，就作为文本文件读取新文件内容。必须是mv命令移动过来。</li>
<li>actorStream：创建一个使用用户自己实现的Akka actor接收器的DStream</li>
<li>高级源：一些外部三方库提供的工具类方法</li>
</ul>
<p>处理数据流，包含两类：转换和输出。转换细分为：基本转换、聚合转换、键值对转换、特殊转换。DStream也是惰性操作。如果一个DStream上没有任何输出操作，即使调用了转换操作，Spark Streaming也不会对数据做任何处理。</p>
<ul>
<li>基本转换<ul>
<li>map</li>
<li>flatMap</li>
<li>filter</li>
<li>repartition</li>
<li>union</li>
</ul>
</li>
<li>聚合转换<ul>
<li>count</li>
<li>reduce</li>
<li>countByValue</li>
</ul>
</li>
<li>键值对转换<ul>
<li>cogroup</li>
<li>join</li>
<li>groupByKey    </li>
<li>reduceByKey</li>
</ul>
</li>
<li>特殊转换<ul>
<li>transform</li>
<li>updateStateByKey</li>
</ul>
</li>
</ul>
<p>输出操作</p>
<ul>
<li>saveAsTestFiles</li>
<li>saveAsObjectFiles</li>
<li>saveAsHadoopFiles</li>
<li>saveAsNewAPIHadoopFiles</li>
<li>print，在控制台上显示</li>
<li>foreachRDD，逐个遍历元素，保存至数据库中</li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark汇总</title>
    <url>/middle-software/Spark/</url>
    <content><![CDATA[<h2 id="一、Spark-Core"><a href="#一、Spark-Core" class="headerlink" title="一、Spark Core"></a>一、Spark Core</h2><ul>
<li><a href="../Spark-core笔记">读书笔记</a></li>
<li><a href="../Spark-stream">Spark 安装、启动</a></li>
<li><a href="../Spark-cluster-admin">集群管理员</a></li>
<li><a href="https://github.com/aalansehaiyang/spark-example" target="_blank" rel="noopener">一些Spark demo程序</a></li>
<li><a href="http://blog.csdn.net/T1DMzks/article/category/7062215" target="_blank" rel="noopener">Spark常用案例</a></li>
<li><a href="http://www.cnblogs.com/shishanyuan/p/4699644.html" target="_blank" rel="noopener">Spark入门实战系列</a></li>
<li><a href="http://www.cnblogs.com/tgzhu/p/5818374.html" target="_blank" rel="noopener">基本架构及原理</a></li>
<li><a href="https://mp.weixin.qq.com/s/6dCZrPi9sI-BRX0L3F5z3g" target="_blank" rel="noopener">Spark从入门到调优，是否有捷径可走？</a></li>
</ul>
<h2 id="二、Spark-Streaming"><a href="#二、Spark-Streaming" class="headerlink" title="二、Spark Streaming"></a>二、Spark Streaming</h2><ul>
<li><a href="../Spark-stream笔记">读书笔记</a></li>
<li><a href="https://github.com/allwefantasy/my-life" target="_blank" rel="noopener">github上的一些资料</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA5NzkxMzg1Nw==&mid=2653159189&idx=1&sn=ae87942269773e8ef9bc39c344d6c5fa&scene=27#wechat_redirect" target="_blank" rel="noopener">Spark Straming 实例讲解</a></li>
<li><a href="https://mp.weixin.qq.com/s/_pZ5U-UlZvhPeXuOepO9_w" target="_blank" rel="noopener">Spark Streaming笔记——技术点汇总</a></li>
<li><a href="http://mp.weixin.qq.com/s/URJg23Pz0rkFFAjWCdYB1w" target="_blank" rel="noopener">Spark Streaming中流式计算的困境与解决之道</a></li>
<li><a href="https://mp.weixin.qq.com/s/Mdcupaqfni_qPeZWUHxNVA" target="_blank" rel="noopener">以Flink为例，消除流处理常见的六大谬见</a></li>
</ul>
<h2 id="三、Spark-SQL"><a href="#三、Spark-SQL" class="headerlink" title="三、Spark SQL"></a>三、Spark SQL</h2><ul>
<li><a href="../Spark-SQL笔记">读书笔记</a></li>
</ul>
<h2 id="四、MLlib"><a href="#四、MLlib" class="headerlink" title="四、MLlib"></a>四、MLlib</h2><ul>
<li><a href="../Spark-MLlib笔记">读书笔记</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch Restful命令</title>
    <url>/middle-software/elasticsearch-rest/</url>
    <content><![CDATA[<h1 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h1><ul>
<li>索引统计</li>
</ul>
<a id="more"></a>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Storm</title>
    <url>/middle-software/Storm/</url>
    <content><![CDATA[<h2 id="Storm"><a href="#Storm" class="headerlink" title="Storm"></a>Storm</h2><hr>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>ElasticSearch入门及安装</title>
    <url>/middle-software/elasticsearch-setup/</url>
    <content><![CDATA[<hr>
<p>Elasticsearch 是用 Java 编写的，它的内部使用 Lucene 做索引与搜索，但是它的目的是使全文检索变得简单， 通过隐藏 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。</p>
<a id="more"></a>
<p><strong>一个 Elasticsearch 集群可以包含多个索引 ，相应的每个索引可以包含多个类型 。 这些不同的类型存储着多个文档 ，每个文档又有多个属性 。</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">你也许已经注意到 索引 这个词在 Elasticsearch 语境中包含多重意思， 所以有必要做一点儿说明：</span><br><span class="line"></span><br><span class="line">索引（名词）：</span><br><span class="line"></span><br><span class="line">如前所述，一个 索引 类似于传统关系数据库中的一个 数据库 ，是一个存储关系型文档的地方。 索引 (index) 的复数词为 indices 或 indexes 。</span><br><span class="line"></span><br><span class="line">索引（动词）：</span><br><span class="line"></span><br><span class="line">索引一个文档 就是存储一个文档到一个 索引 （名词）中以便它可以被检索和查询到。这非常类似于 SQL 语句中的 INSERT 关键词，除了文档已存在时新文档会替换旧文档情况之外。</span><br><span class="line"></span><br><span class="line">倒排索引：</span><br><span class="line"></span><br><span class="line">关系型数据库通过增加一个 索引 比如一个 B树（B-tree）索引 到指定的列上，以便提升数据检索速度。Elasticsearch 和 Lucene 使用了一个叫做 倒排索引 的结构来达到相同的目的。</span><br><span class="line"></span><br><span class="line">+ 默认的，一个文档中的每一个属性都是被索引的（有一个倒排索引）和可搜索的。一个没有倒排索引的属性是不能被搜索到的。</span><br></pre></td></tr></table></figure>


<p><strong>特性</strong></p>
<ul>
<li>分布式的实时文件存储，每个字段都被索引并可被搜索</li>
<li>分布式的实时分析搜索引擎</li>
<li>可以扩展到上百台服务器，处理PB级结构化或非结构化数据</li>
</ul>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>安装非常简单，<a href="http://www.elasticsearch.org/download/" target="_blank" rel="noopener">http://www.elasticsearch.org/download/</a> 下载最新版本的Elasticsearch，其中zip包可直接解压使用。</p>
<h1 id="如何启动"><a href="#如何启动" class="headerlink" title="如何启动"></a>如何启动</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;elasticsearch</span><br><span class="line"></span><br><span class="line">如果想在后台以守护进程模式运行，添加-d参数</span><br><span class="line"></span><br><span class="line">curl &#39;http:&#x2F;&#x2F;localhost:9200&#x2F;?pretty&#39; 输出status为200表示启动成功。</span><br></pre></td></tr></table></figure>

<p>查询索引结构：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl <span class="string">'http://192.168.3.216:9200/forum/user_member/_mapping'</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"forum"</span>: &#123;</span><br><span class="line">    <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">      <span class="attr">"user_member"</span>: &#123;</span><br><span class="line">        <span class="attr">"_all"</span>: &#123;</span><br><span class="line">          <span class="attr">"analyzer"</span>: <span class="string">"ik_max_word"</span>,</span><br><span class="line">          <span class="attr">"search_analyzer"</span>: <span class="string">"ik_smart"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">          <span class="attr">"follower"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"long"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"id"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"string"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"threads"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"long"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"uid"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"long"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"username"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"string"</span>,</span><br><span class="line">            <span class="attr">"index"</span>: <span class="string">"not_analyzed"</span>,</span><br><span class="line">            <span class="attr">"term_vector"</span>: <span class="string">"with_positions_offsets"</span>,</span><br><span class="line">            <span class="attr">"include_in_all"</span>: <span class="literal">false</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"verify"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"long"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"wcuid"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"long"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h1><p>Elasticsearch 提供了官方客户端，支持市面上象java、javaScript、Groovy、Python等主流语言，下载地址：<a href="https://www.elastic.co/guide/en/elasticsearch/client/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/client/index.html</a></p>
<ul>
<li>创建索引结构</li>
<li>源数据导入，build索引（可以采用api接口形式）</li>
<li>多维度组合查询条件，搜索查询（可以采用api接口形式）</li>
</ul>
<h1 id="入门级案例"><a href="#入门级案例" class="headerlink" title="入门级案例"></a>入门级案例</h1><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/running-elasticsearch.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/running-elasticsearch.html</a></p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/12.png/w600">

]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>ElasticSearch进阶型原理</title>
    <url>/middle-software/elasticsearch-theory/</url>
    <content><![CDATA[<p>传统关系型数据库的行和列存储，这相当于是把一个表现力丰富的对象挤压到一个非常大的电子表格中：你必须将这个对象扁平化来适应表结构–通常一个字段&gt;对应一列–而且又不得不在每次查询时重新构造对象。</p>
<a id="more"></a>
<p>Elasticsearch 是 面向文档 的，意味着它存储整个对象或 文档_。Elasticsearch 不仅存储文档，而且 _索引 每个文档的内容使之可以被检索。在 Elasticsearch 中，你 对文档进行索引、检索、排序和过滤–而不是对行列数据。这是一种完全不同的思考数据的方式，也是 Elasticsearch 能支持复杂全文检索的原因。</p>
<h1 id="集群相关"><a href="#集群相关" class="headerlink" title="集群相关"></a>集群相关</h1><ul>
<li>节点、主节点、主分片、副本分片</li>
</ul>
<p>一个运行中的 Elasticsearch 实例称为一个 节点，而集群是由一个或者多个拥有相同 cluster.name 配置的节点组成， 它们共同承担数据和负载的压力。<strong>当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。</strong> </p>
<p>当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。集群状态存在于集群中的每个节点，包括客户端节点。但只有主节点被允许更新集群状态，然后向所有集群中的所有节点发布一个新的版本。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">集群状态 是一种数据结构，贮存下列集群级别的信息：</span><br><span class="line">1.集群级别的设置</span><br><span class="line">2.集群中的节点</span><br><span class="line">3.索引以及它们的设置、映射、分析器、预热器（Warmers）和别名</span><br><span class="line">4.与每个索引关联的分片以及它们分配到的节点</span><br></pre></td></tr></table></figure>

<p><strong>每个节点上都有若干分片（即可以有主分片也可以有副分片）。</strong></p>
<p>作为用户，我们可以将请求发送到集群中的任何节点，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。</p>
<ul>
<li>集群健康命令：</li>
</ul>
<p>curl -XGET ‘localhost:9200/_cluster/health?pretty’</p>
<p>Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。</p>
<p><strong>在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。</strong></p>
<ul>
<li>水平扩容</li>
</ul>
<p>创建更多的副本分片，提供服务（读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理），提高系统的吞吐量。</p>
<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/_scale_horizontally.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/_scale_horizontally.html</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;blogs&#x2F;_settings</span><br><span class="line">&#123;</span><br><span class="line">   &quot;number_of_replicas&quot; : 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="分布式文档存储"><a href="#分布式文档存储" class="headerlink" title="分布式文档存储"></a>分布式文档存储</h1><p>当我们创建文档时，被存储到哪一个主分片？有一个公式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shard &#x3D; hash(routing) % number_of_primary_shards</span><br><span class="line"></span><br><span class="line">注：routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。number_of_primary_shards 是主分片的个数。</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>新建、更新和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片。</strong><br><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/distrib-write.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/distrib-write.html</a></p>
</li>
<li><p>**当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。</p>
</li>
<li><ul>
<li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/_partial_updates_to_a_document.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/_partial_updates_to_a_document.html</a></li>
</ul>
</li>
<li><p><strong>读取请求，协调节点在每次请求的时候将选择不同的副本分片来达到负载均衡；通过轮询所有的副本分片。</strong><br><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/distrib-read.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/distrib-read.html</a></p>
</li>
</ul>
<p>注：在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因。</p>
<h1 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h1><p>Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。<br><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/inverted-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/inverted-index.html</a></p>
<h1 id="分布式检索"><a href="#分布式检索" class="headerlink" title="分布式检索"></a>分布式检索</h1><p>当一个节点接收搜索请求时，这个节点就变成了协调节点。 这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端。<br><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/_query_phase.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/_query_phase.html</a></p>
<p>对于楼梯式的翻页，随着页号越大，效率越差。每个分片在本地执行查询请求并且创建一个长度为 from + size 的优先队列，也就是说，每个分片创建的结果集足够大，均可以满足全局的搜索请求。 分片返回一个轻量级的结果列表到协调节点，它仅包含文档 ID 集合以及任何排序需要用到的值，例如 _score 。协调节点将这些分片级的结果合并到自己的有序优先队列里，它代表了全局排序结果集合。至此查询过程结束。</p>
<h1 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h1><p>例子：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/_finding_exact_values.html#_internal_filter_operation" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/current/_finding_exact_values.html#_internal_filter_operation</a></p>
<p>在内部，Elasticsearch 会在运行非评分查询的时执行多个操作：</p>
<ul>
<li><p>查找匹配文档.</p>
<p>  term 查询在倒排索引中查找 XHDK-A-1293-#fJ3 然后获取包含该 term 的所有文档。本例中，只有文档 1 满足我们要求。</p>
</li>
<li><p>创建 bitset.</p>
<p>  过滤器会创建一个 bitset （一个包含 0 和 1 的数组），它描述了哪个文档会包含该 term 。每一个文档都会有一个二进制数字。匹配上的文档的标志位是 1 。本例中，bitset 的值为 [1,0,0,0] ，因为只有4个文档。在内部，它表示成一个 “roaring bitmap”，可以同时对稀疏或密集的集合进行高效编码。</p>
<p>  bitset是一个标志位数组，表示有或没有，猜测应该有一个对应的文档id号的数组，数组的下标可以做关联。</p>
</li>
<li><p>迭代 bitset(s)</p>
<p>  一旦为每个查询生成了 bitsets ，Elasticsearch 就会循环迭代 bitsets 从而找到满足所有过滤条件的匹配文档的集合。执行顺序是启发式的，但一般来说先迭代稀疏的 bitset （因为它可以排除掉大量的文档）。</p>
</li>
</ul>
<p><strong>理论上非评分查询先于评分查询执行。非评分查询任务旨在降低那些将对评分查询计算带来更高成本的文档数量，从而达到快速搜索的目的。从概念上记住非评分计算是首先执行的，这将有助于写出高效又快速的搜索请求。</strong></p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch相关</title>
    <url>/middle-software/elasticsearch/</url>
    <content><![CDATA[<h1 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h1><ul>
<li><a href="elasticsearch-setup.md">入门及安装</a></li>
<li><a href="elasticsearch-application.md">应用场景</a></li>
<li><a href="elasticsearch-theory.md">进阶型原理</a></li>
<li><a href="elasticsearch-rest.md">Restful命令</a></li>
</ul>
<h1 id="社区资料"><a href="#社区资料" class="headerlink" title="社区资料"></a>社区资料</h1><ul>
<li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html" target="_blank" rel="noopener">Elasticsearch: 权威指南</a>（中文翻译版，主要讲一些基础知识）</li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-ngram-tokenizer.html" target="_blank" rel="noopener">Elasticsearch Reference</a>（英文版，内容比较全）</li>
<li><a href="https://github.com/elasticsearch-cn" target="_blank" rel="noopener">Elastic中文社区</a></li>
<li><a href="http://es.xiaoleilu.com/010_Intro/10_Installing_ES.html" target="_blank" rel="noopener">http://es.xiaoleilu.com/010_Intro/10_Installing_ES.html</a></li>
<li><a href="http://www.sojson.com/blog/91" target="_blank" rel="noopener">http://www.sojson.com/blog/91</a></li>
<li>《Elasticssearch服务器开发（第二版）》</li>
<li><a href="solr和elasticsearch.md">solr和elasticsearch的区别</a></li>
<li><a href="http://www.cnblogs.com/xing901022/p/4704319.html" target="_blank" rel="noopener">http://www.cnblogs.com/xing901022/p/4704319.html</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Guava</title>
    <url>/middle-software/guava/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如果服务上要使用本地缓存，可以考虑使用guava框架。Guava Cache与ConcurrentMap很相似，但也不完全一样。最基本的区别是ConcurrentMap会一直保存所有添加的元素，直到显式地移除。相对地，Guava Cache为了限制内存占用，通常都设定为自动回收元素。在某些场景下，尽管LoadingCache 不回收元素，它也是很有用的，因为它会自动加载缓存。</p>
<a id="more"></a>
<h2 id="Guava-Cache适用于："><a href="#Guava-Cache适用于：" class="headerlink" title="Guava Cache适用于："></a>Guava Cache适用于：</h2><ul>
<li>你愿意消耗一些内存空间来提升速度。</li>
<li>你预料到某些键会被查询一次以上。</li>
<li>缓存中存放的数据总量不会超出内存容量。</li>
</ul>
<p>代码示例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.google.common.cache.CacheBuilder;</span><br><span class="line"><span class="keyword">import</span> com.google.common.cache.CacheLoader;</span><br><span class="line"><span class="keyword">import</span> com.google.common.cache.LoadingCache;</span><br><span class="line"><span class="keyword">import</span> com.google.common.cache.RemovalListener;</span><br><span class="line"><span class="keyword">import</span> com.google.common.cache.RemovalNotification;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> onlyone</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TT</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        LoadingCache&lt;Integer, String&gt; localCache = CacheBuilder.newBuilder()</span><br><span class="line">        <span class="comment">// 设置并发级别为8，并发级别是指可以同时写缓存的线程数</span></span><br><span class="line">        .concurrencyLevel(<span class="number">8</span>)</span><br><span class="line">        <span class="comment">// 最大容量</span></span><br><span class="line">        .maximumSize(<span class="number">200000</span>)</span><br><span class="line">        <span class="comment">// 初始容量</span></span><br><span class="line">        .initialCapacity(<span class="number">100000</span>)</span><br><span class="line">        <span class="comment">// 写入后5秒过期</span></span><br><span class="line">        .expireAfterWrite(<span class="number">5</span>, TimeUnit.SECONDS)</span><br><span class="line">        <span class="comment">// 统计缓存的命中率</span></span><br><span class="line">        .recordStats()</span><br><span class="line">        <span class="comment">// 设置缓存移除通知</span></span><br><span class="line">        .removalListener(<span class="keyword">new</span> RemovalListener&lt;Integer, String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onRemoval</span><span class="params">(RemovalNotification&lt;Integer, String&gt; notification)</span> </span>&#123;</span><br><span class="line">                System.out.println(notification.getKey() + <span class="string">" was removed,cause is "</span> + notification.getCause());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).build(<span class="keyword">new</span> CacheLoader&lt;Integer, String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 在缓存不存在时，通过CacheLoader自动加载缓存</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> String <span class="title">load</span><span class="params">(Integer key)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"load data:"</span> + key);</span><br><span class="line">                <span class="keyword">return</span> key + <span class="string">"对应的 value"</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ------------</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++) &#123;</span><br><span class="line">            System.out.println(<span class="string">"key:"</span> + i + <span class="string">",value:"</span> + localCache.get(i));</span><br><span class="line">            System.out.println(<span class="string">"key:"</span> + i + <span class="string">",value:"</span> + localCache.get(i));</span><br><span class="line">            <span class="comment">// 休眠2s</span></span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 打印缓存中的命中情况</span></span><br><span class="line">            System.out.println(<span class="string">"cache status:"</span>);</span><br><span class="line">            System.out.println(localCache.stats().toString());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>响应结果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">load data:<span class="number">1</span></span><br><span class="line">key:<span class="number">1</span>,value:<span class="number">1</span>对应的 value</span><br><span class="line">key:<span class="number">1</span>,value:<span class="number">1</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">1</span>, missCount=<span class="number">1</span>, loadSuccessCount=<span class="number">1</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1061305</span>, evictionCount=<span class="number">0</span>&#125;</span><br><span class="line">load data:<span class="number">2</span></span><br><span class="line">key:<span class="number">2</span>,value:<span class="number">2</span>对应的 value</span><br><span class="line">key:<span class="number">2</span>,value:<span class="number">2</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">2</span>, missCount=<span class="number">2</span>, loadSuccessCount=<span class="number">2</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1125724</span>, evictionCount=<span class="number">0</span>&#125;</span><br><span class="line">load data:<span class="number">3</span></span><br><span class="line">key:<span class="number">3</span>,value:<span class="number">3</span>对应的 value</span><br><span class="line">key:<span class="number">3</span>,value:<span class="number">3</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">3</span>, missCount=<span class="number">3</span>, loadSuccessCount=<span class="number">3</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1184002</span>, evictionCount=<span class="number">0</span>&#125;</span><br><span class="line">load data:<span class="number">4</span></span><br><span class="line">key:<span class="number">4</span>,value:<span class="number">4</span>对应的 value</span><br><span class="line">key:<span class="number">4</span>,value:<span class="number">4</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">4</span>, missCount=<span class="number">4</span>, loadSuccessCount=<span class="number">4</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1288529</span>, evictionCount=<span class="number">0</span>&#125;</span><br><span class="line">load data:<span class="number">5</span></span><br><span class="line">key:<span class="number">5</span>,value:<span class="number">5</span>对应的 value</span><br><span class="line">key:<span class="number">5</span>,value:<span class="number">5</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">5</span>, missCount=<span class="number">5</span>, loadSuccessCount=<span class="number">5</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1340360</span>, evictionCount=<span class="number">0</span>&#125;</span><br><span class="line">load data:<span class="number">6</span></span><br><span class="line">key:<span class="number">6</span>,value:<span class="number">6</span>对应的 value</span><br><span class="line">key:<span class="number">6</span>,value:<span class="number">6</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">6</span>, missCount=<span class="number">6</span>, loadSuccessCount=<span class="number">6</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1395073</span>, evictionCount=<span class="number">0</span>&#125;</span><br><span class="line">load data:<span class="number">7</span></span><br><span class="line">key:<span class="number">7</span>,value:<span class="number">7</span>对应的 value</span><br><span class="line">key:<span class="number">7</span>,value:<span class="number">7</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">7</span>, missCount=<span class="number">7</span>, loadSuccessCount=<span class="number">7</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1446730</span>, evictionCount=<span class="number">0</span>&#125;</span><br><span class="line">load data:<span class="number">8</span></span><br><span class="line">key:<span class="number">8</span>,value:<span class="number">8</span>对应的 value</span><br><span class="line">key:<span class="number">8</span>,value:<span class="number">8</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">8</span>, missCount=<span class="number">8</span>, loadSuccessCount=<span class="number">8</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1498473</span>, evictionCount=<span class="number">0</span>&#125;</span><br><span class="line"><span class="number">2</span> was removed,cause is EXPIRED</span><br><span class="line">load data:<span class="number">9</span></span><br><span class="line">key:<span class="number">9</span>,value:<span class="number">9</span>对应的 value</span><br><span class="line">key:<span class="number">9</span>,value:<span class="number">9</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">9</span>, missCount=<span class="number">9</span>, loadSuccessCount=<span class="number">9</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1553158</span>, evictionCount=<span class="number">1</span>&#125;</span><br><span class="line"><span class="number">1</span> was removed,cause is EXPIRED</span><br><span class="line">load data:<span class="number">10</span></span><br><span class="line">key:<span class="number">10</span>,value:<span class="number">10</span>对应的 value</span><br><span class="line">key:<span class="number">10</span>,value:<span class="number">10</span>对应的 value</span><br><span class="line">cache status:</span><br><span class="line">CacheStats&#123;hitCount=<span class="number">10</span>, missCount=<span class="number">10</span>, loadSuccessCount=<span class="number">10</span>, loadExceptionCount=<span class="number">0</span>, totalLoadTime=<span class="number">1599422</span>, evictionCount=<span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure>

<h3 id="缓存回收"><a href="#缓存回收" class="headerlink" title="缓存回收"></a>缓存回收</h3><h2 id="被动删除"><a href="#被动删除" class="headerlink" title="被动删除"></a>被动删除</h2><ul>
<li><h3 id="基本容量的回收"><a href="#基本容量的回收" class="headerlink" title="基本容量的回收"></a>基本容量的回收</h3><p>1）设置了初始值和最大容量上限，如果逼近容量上限，就会触发回收机制。</p>
</li>
<li><h3 id="定时回收"><a href="#定时回收" class="headerlink" title="定时回收"></a>定时回收</h3><p>  1）expireAfterAccess(long, TimeUnit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于大小回收一样。</p>
<p>  2）expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。</p>
</li>
<li><h3 id="基于引用的回收"><a href="#基于引用的回收" class="headerlink" title="基于引用的回收"></a>基于引用的回收</h3><p>  基于java的垃圾回收机制，判断缓存的数据引用的关系，如果没有被引用，则将该数据删除</p>
</li>
</ul>
<h2 id="主动删除"><a href="#主动删除" class="headerlink" title="主动删除"></a>主动删除</h2><ul>
<li>单个清除：Cache.invalidate(key)</li>
<li>批量清除：Cache.invalidateAll(keys)</li>
<li>清除所有缓存项：Cache.invalidateAll()</li>
</ul>
<h2 id="更多资料："><a href="#更多资料：" class="headerlink" title="更多资料："></a>更多资料：</h2><p><a href="https://www.cnblogs.com/gaojy/p/7245319.html" target="_blank" rel="noopener">https://www.cnblogs.com/gaojy/p/7245319.html</a></p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka-manager 安装</title>
    <url>/middle-software/kafka-manager-setup/</url>
    <content><![CDATA[<ul>
<li>源码</li>
</ul>
<p><a href="https://github.com/yahoo/kafka-manager" target="_blank" rel="noopener">https://github.com/yahoo/kafka-manager</a></p>
<a id="more"></a>
<ul>
<li>参考：</li>
</ul>
<p><a href="https://www.cnblogs.com/dadonggg/p/8205302.html" target="_blank" rel="noopener">https://www.cnblogs.com/dadonggg/p/8205302.html</a></p>
<ul>
<li>启动：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;kafka&#x2F;kafka-manager-1.3.3.7</span><br><span class="line"></span><br><span class="line">bin&#x2F;kafka-manager -Dconfig.file&#x3D;conf&#x2F;application.conf -Dhttp.port&#x3D;9000 &amp;</span><br><span class="line"></span><br><span class="line">注意：刚下载的可能没有执行权限</span><br></pre></td></tr></table></figure>

<ul>
<li>访问地址：</li>
</ul>
<p><a href="http://localhost:9000/" target="_blank" rel="noopener">http://localhost:9000/</a></p>
<ul>
<li>本机截图</li>
</ul>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/22.png/w600">
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka安装</title>
    <url>/middle-software/kafka-setup/</url>
    <content><![CDATA[<p>1、首先安装 zookeeper</p>
<p>2、下载kafka</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;mirrors.cnnic.cn&#x2F;apache&#x2F;kafka&#x2F;2.1.0&#x2F;kafka_2.11-2.1.0.tgz</span><br><span class="line">&#96;&#96;&#96;	</span><br><span class="line"></span><br><span class="line">解压：</span><br><span class="line"></span><br><span class="line">tar zxf kafka_2.11-2.1.0.tgz</span><br><span class="line"></span><br><span class="line">3、修改配置</span><br></pre></td></tr></table></figure>
<p>cd kafka_2.11-2.1.0/config/<br>vim server.properties</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">kafka最为重要三个配置依次为：broker.id、log.dir、zookeeper.connect</span><br><span class="line"></span><br><span class="line">参数详细说明：</span><br><span class="line"></span><br><span class="line">https:&#x2F;&#x2F;blog.csdn.net&#x2F;lizhitao&#x2F;article&#x2F;details&#x2F;25667831 </span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">4、启动</span><br></pre></td></tr></table></figure>
<p>cd /Users/onlyone/software/kafka/kafka_2.11-2.1.0<br>bin/kafka-server-start.sh config/server.properties &amp;</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">停止kafka</span><br></pre></td></tr></table></figure>
<p>bin/kafka-server-stop.sh  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">5、检测</span><br></pre></td></tr></table></figure>
<p>➜  jps<br>41505 QuorumPeerMain<br>66244 Jps<br>64472 Kafka<br>252 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">* QuorumPeerMain为对应的zookeeper实例</span><br><span class="line">* Kafka的进程ID为64472</span><br><span class="line"></span><br><span class="line">6、测试</span><br><span class="line"></span><br><span class="line">* 创建topic</span><br></pre></td></tr></table></figure>
<p>bin/kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic test1</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">* 查看topic创建情况</span><br></pre></td></tr></table></figure>
<p>bin/kafka-topics.sh –list –zookeeper localhost:2181</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>bin/kafka-topics.sh –describe –zookeeper localhost:2181</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">运行结果：</span><br></pre></td></tr></table></figure>
<p>Topic:test1    PartitionCount:1    ReplicationFactor:1    Configs:<br>    Topic: test1    Partition: 0    Leader: 1    Replicas: 1    Isr: 1</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">参数解析：https:&#x2F;&#x2F;www.cnblogs.com&#x2F;shengulong&#x2F;p&#x2F;9013282.html</span><br><span class="line"></span><br><span class="line">* 启动生产端 producer，并发送消息</span><br></pre></td></tr></table></figure>
<p>bin/kafka-console-producer.sh –broker-list 192.168.0.14:9092 –topic test1</p>
<p>注意：首次，topic不存在时，会自动创建</p>
<p>上面命令是在控制台输入要发送的消息，“回车”单条消息结束。</p>
<p>echo ‘{“name”:”Steve”, “title”:”Captain America”}’ | bin/kafka-console-producer.sh –broker-list 192.168.0.14:9092 –topic test1</p>
<p>将发送的消息放在执行命令中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">* 启动消费端 consumer，可以看到刚才发送的消息列表</span><br></pre></td></tr></table></figure>
<p>bin/kafka-console-consumer.sh –bootstrap-server 192.168.0.14:9092 –topic test1 –from-beginning  </p>
<pre><code>
</code></pre>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Emqx部署问题</title>
    <url>/middle-software/emqx%E9%83%A8%E7%BD%B2%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="1、centos-安装mqtt"><a href="#1、centos-安装mqtt" class="headerlink" title="1、centos 安装mqtt"></a>1、centos 安装mqtt</h1><p>安装所需要的依赖包</p>
<p>$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2</p>
<p>使用以下命令设置稳定存储库，以 CentOS7 为例</p>
<p>$ sudo yum-config-manager –add-repo <a href="https://repos.emqx.io/emqx-ce/redhat/centos/7/emqx-ce.repo" target="_blank" rel="noopener">https://repos.emqx.io/emqx-ce/redhat/centos/7/emqx-ce.repo</a></p>
<p>安装最新版本的 EMQ X</p>
<p>$ sudo yum install emqx</p>
<h1 id="2、dashboard登录后提示URL-not-Found"><a href="#2、dashboard登录后提示URL-not-Found" class="headerlink" title="2、dashboard登录后提示URL not Found"></a>2、dashboard登录后提示URL not Found</h1><p>原因是http默认端口8080被占用，</p>
<p>查看端口占用进程</p>
<p>netstat -tnlp | grep :8080</p>
<p>一种方式：找到占用改端口的程序，使用kill -9 进程号 杀掉该进程</p>
<p>另外一种方式：修改emqx http为其他端口：</p>
<p>找到插件plugin中的emqx_management.conf。</p>
<p>修改</p>
<p>management.listener.http = 8090 这一行</p>
<p>保存，然后重启</p>
<h1 id="3、emqx-ctl-linsteners-提示命令不存在"><a href="#3、emqx-ctl-linsteners-提示命令不存在" class="headerlink" title="3、emqx_ctl linsteners 提示命令不存在"></a>3、emqx_ctl linsteners 提示命令不存在</h1><p>列出的emqx_ctl使用方法列表明显表较少</p>
<p>正常的大概有77个命令。</p>
<p>此时很可能是8080端口占用，跟第二个问题解决方法一样，最好给emqx_management换一个端口</p>
<h1 id="4、使用emqx-auth-mysql插件进行用户名和访问权限控制："><a href="#4、使用emqx-auth-mysql插件进行用户名和访问权限控制：" class="headerlink" title="4、使用emqx_auth_mysql插件进行用户名和访问权限控制："></a>4、使用emqx_auth_mysql插件进行用户名和访问权限控制：</h1><p>（1）首先安装数据库，建议使用docker安装mariadb。</p>
<p>（2）设置数据库的用户名和密码。</p>
<p>（3）启动数据库。</p>
<p>（4）创建mqtt数据库</p>
<p>（5）创建用户表和ACL表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`mqtt_user`</span> ( <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT, <span class="string">`username`</span> <span class="built_in">varchar</span>(<span class="number">100</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>, <span class="string">`password`</span> <span class="built_in">varchar</span>(<span class="number">100</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>, <span class="string">`salt`</span> <span class="built_in">varchar</span>(<span class="number">35</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>, <span class="string">`is_superuser`</span> <span class="built_in">tinyint</span>(<span class="number">1</span>) <span class="keyword">DEFAULT</span> <span class="number">0</span>, <span class="string">`created`</span> datetime <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>, PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>), <span class="keyword">UNIQUE</span> <span class="keyword">KEY</span> <span class="string">`mqtt_username`</span> (<span class="string">`username`</span>) ) <span class="keyword">ENGINE</span>=MyISAM <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`mqtt_acl`</span> ( <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT, <span class="string">`allow`</span> <span class="built_in">int</span>(<span class="number">1</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'0: deny, 1: allow'</span>, <span class="string">`ipaddr`</span> <span class="built_in">varchar</span>(<span class="number">60</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'IpAddress'</span>, <span class="string">`username`</span> <span class="built_in">varchar</span>(<span class="number">100</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'Username'</span>, <span class="string">`clientid`</span> <span class="built_in">varchar</span>(<span class="number">100</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'ClientId'</span>, <span class="string">`access`</span> <span class="built_in">int</span>(<span class="number">2</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'1: subscribe, 2: publish, 3: pubsub'</span>, <span class="string">`topic`</span> <span class="built_in">varchar</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">''</span> <span class="keyword">COMMENT</span> <span class="string">'Topic Filter'</span>, PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>) ) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8;</span><br></pre></td></tr></table></figure>

<p>配置etc/plugins/emqx_auth_mysql.conf</p>
<p>将数据库的用户名、密码填入</p>
<p>其他配置信息参考官方说明文档</p>
<p><a href="https://docs.emqx.io/edge/v3/cn/plugins.html#emqx-auth-http-http" target="_blank" rel="noopener">https://docs.emqx.io/edge/v3/cn/plugins.html#emqx-auth-http-http</a></p>
<p>其中在配置密码规则时要注意的一点：</p>
<p>auth.mysql.password_hash = sha256</p>
<p>官方配置默认是sha256加密，那么在数据库中的password字段不能用明文</p>
<p>上面的方式是不行的</p>
<p>要将密码通过sha256加密后将加密串写入数据库才行</p>
<p>另外要注意的是数据库字段salt是密码加盐后再进行加密。说白了就是密码加上一段一段字符串（上图中是crodigy），然后经过加密算法计算的密文。这样更安全</p>
<p>如果要采用密码加盐的方式则配置文件字段修改如下</p>
<p>auth.mysql.password_hash = salt,sha256</p>
<p>意思是 字符串+密码后经过sha256计算后的密文填入数据库</p>
<p>示例：</p>
<p>python代码实现sha256+盐算法代码如下：其中string是密码，crodigy是盐字符串</p>
<p>最终将输出的res字段放入数据库的password中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="comment"># ######## sha256 ########</span></span><br><span class="line"></span><br><span class="line">string = <span class="string">"test"</span></span><br><span class="line"></span><br><span class="line">sha256 = hashlib.sha256(<span class="string">b'crodigy'</span>)</span><br><span class="line"></span><br><span class="line">sha256.update(string.encode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">res = sha256.hexdigest()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"sha256加密结果:"</span>,res)</span><br></pre></td></tr></table></figure>

<p>ACL批量校验：</p>
<p>在实际项目中一般要限制用户订阅的主题和发布的主题。比如采用 /username/set 来订阅主题</p>
<p>/username/get 来发布主题。 如果连接的客户端比较多，那么简历的ACL规则也比较多</p>
<p>比如连接十万个客户端，那么就要有至少20万个（发布+订阅）主题，数据库中就要写20万个ACL规则，这样规则匹配也非常耗时。</p>
<p>可以使用通配符替换的形式来解决问题.</p>
<p>先上解决方案：</p>
<p>在数据库配置文件emqx_auth_mysql.conf中修改如下字段：</p>
<p>auth.mysql.acl_query = select allow, ipaddr, username, clientid, access, REPLACE(topic,’$devTopic’,’%u’) from mqtt_acl where ipaddr = ‘%a’ or username = ‘%u’ or username = ‘$all’ or clientid = ‘%c’ order by id desc</p>
<p>数据库语句主要修改了1、REPLACE(topic,’$devTopic’,’%u’)和2、order by id desc</p>
<p>第一条的作用是将主题中的通配符$devTopic替换成当前需要匹配的用户名。</p>
<p>第二条是将查询出来的规则以id降序排列，进行验证。因为ACL规则是按照规则顺序进行一一校验，所以顺序不同校验结果可能不同。</p>
<p>数据库填写如下内容</p>
<p>这样就可以实现用户test1只能订阅/test1/get主题，只能发布/test1/set主题。</p>
<p>制定这样规则的好处在于每个用户只能订阅和发布自己的主题，不能订阅发布别人的主题。</p>
<p>另外数据库中的用户名和ACL规则添加后，emqx是动态加载，不需要重启emqx就能实现校验。这个可能是比较新的版本修改过。之前看到git上有人提问类似的问题：说添加了ACL规则后要重启emqx才能生效。目前我测试的3.2.7版本不需要重启就能生效。</p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>apollo</title>
    <url>/middle-software/kafka-sourcecode/</url>
    <content><![CDATA[<h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><hr>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ul>
<li><p>消息</p>
<p>  最基本的数据单元</p>
</li>
<li><p>Topic、分区、Log</p>
</li>
<li><p>保留策略</p>
<ul>
<li>根据消息保留的时间，超过指定时间，就可以被删除</li>
<li>根据Topic存储的数据大小</li>
</ul>
</li>
<li><p>Broker</p>
</li>
<li><p>副本</p>
<p>   每个分区至少有一个副本，对消息进行了冗余备份，灾备</p>
</li>
</ul>
<ul>
<li><p>ISR集合</p>
<p>  副本集合，表示的是目前“可用”且消息量与Leader相差不多的副本集合，这是整个副本集合的一个子集。</p>
</li>
<li><p>Cluster、Controller</p>
</li>
<li><p>生产者</p>
</li>
<li><p>消费者</p>
<p>  从Topic中拉取消息，并对消息进行消费。某个消费者消费到Partition的哪个位置（offset）的相关信息，由Consumer自己维护的。</p>
</li>
<li><p>Consumer Group    </p>
<p>  多个Consumer可以组成一个Group，保证其订阅的Topic的每个分区可以被分配给此Consumer Group中的一个消费者处理。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>apollo</title>
    <url>/middle-software/kafka/</url>
    <content><![CDATA[<h2 id="kafka相关"><a href="#kafka相关" class="headerlink" title="kafka相关"></a>kafka相关</h2><hr>
<ul>
<li><a href="kafka-setup.md">安装</a></li>
<li><a href="kafka-sourcecode.md">Apache Kafaka源码剖析</a></li>
<li><a href="https://gitee.com/robertleepeak/kclient" target="_blank" rel="noopener">Kafka Java客户端—KClient</a></li>
</ul>
<p>管理工具：</p>
<ul>
<li><a href="kafka-manager-setup.md">kafka-manager</a></li>
</ul>
<hr>
<p>Kafka是由LinkedIn开发的一个开源分布式基于发布/订阅的消息系统，Scala编写。<br>Producer向broker push消息；Consumer从broker pull消息（pull模式则可以根据Consumer的消费能力以适当的速率消费消息）</p>
<h3 id="目标："><a href="#目标：" class="headerlink" title="目标："></a>目标：</h3><ul>
<li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。</li>
<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输。</li>
<li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输（注意：非整体有序，如果有顺序要求，可以只配置一个partition）。</li>
<li>同时支持离线数据处理和实时数据处理。</li>
</ul>
<h3 id="核心组件："><a href="#核心组件：" class="headerlink" title="核心组件："></a>核心组件：</h3><ul>
<li><p>Broker</p>
<p>Kafka集群包含一个或多个服务器，这种服务器被称为broker</p>
</li>
<li><p>Topic</p>
<p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic，逻辑上可称之为队列（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>
</li>
<li><p>Partition</p>
<p>Partition是物理上的概念，每个Topic包含一个或多个Partition，每个Partition对应一个逻辑log，由多个segment组成。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/1.png/w600">

<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/2.png/w600">
</li>
<li><p>Producer</p>
<p>负责发布消息到Kafka broker</p>
</li>
<li><p>Consumer</p>
<p>消息消费者，向Kafka broker读取消息的客户端。</p>
</li>
<li><p>Consumer Group</p>
<p>每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group），会维护一个索引，用于标识一个消费集群的消费位置。为了对减小一个consumer group中不同consumer之间的分布式协调开销，指定partition为最小的并行消费单位，即一个group内的consumer只能消费不同的partition。</p>
</li>
</ul>
<hr>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/20160702_54.png/w600">

<p>发到某个topic的消息会被均匀的分布到多个Partition上（随机或根据用户指定的回调函数进行分布），broker收到发布消息往对应Partition的最后一个segment上添加该消息，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。</p>
<p>每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p>
<p>Kafka集群会保留所有的消息，无论其被消费与否。两种策略删除旧数据：</p>
<ul>
<li>一基于时间的SLA(服务水平保证)，消息保存一定时间（通常为7天）后会被删除</li>
<li>二是基于Partition文件大小，可以通过配置$KAFKA_HOME/config/server.properties</li>
</ul>
<h3 id="消息的有序性"><a href="#消息的有序性" class="headerlink" title="消息的有序性"></a>消息的有序性</h3><ul>
<li><p><a href="https://github.com/chenryn/logstash-best-practice-cn/blob/master/contrib_plugins/kafka.md" target="_blank" rel="noopener">https://github.com/chenryn/logstash-best-practice-cn/blob/master/contrib_plugins/kafka.md</a></p>
</li>
<li><p><a href="https://github.com/chenryn/ELKstack-guide-cn/blob/master/logstash/scale/kafka.md" target="_blank" rel="noopener">https://github.com/chenryn/ELKstack-guide-cn/blob/master/logstash/scale/kafka.md</a></p>
</li>
<li><p><a href="http://blog.csdn.net/chunlongyu/article/details/53977819" target="_blank" rel="noopener">http://blog.csdn.net/chunlongyu/article/details/53977819</a></p>
</li>
<li><p><a href="http://www.cnblogs.com/intsmaze/p/6386616.html" target="_blank" rel="noopener">http://www.cnblogs.com/intsmaze/p/6386616.html</a></p>
</li>
<li><p><a href="http://zqhxuyuan.github.io/2016/02/20/Kafka-Consumer-New/" target="_blank" rel="noopener">http://zqhxuyuan.github.io/2016/02/20/Kafka-Consumer-New/</a></p>
</li>
<li><p><a href="http://zqhxuyuan.github.io/2016/10/27/Kafka-Definitive-Guide-cn-04/" target="_blank" rel="noopener">http://zqhxuyuan.github.io/2016/10/27/Kafka-Definitive-Guide-cn-04/</a></p>
<p>kafka 的消息模型是对 topic 分区以达到分布式效果。每个 topic 下的不同的 partitions (区)只能有一个 Owner 去消费。所以只有多个分区后才能启动多个消费者，对应不同的区去消费。其中协调消费部分是由 server 端协调而成。使用者不必考虑太多。只是消息的消费是无序的。</p>
</li>
</ul>
<p>总结：如果想保证消息的顺序，那就用一个 partition。 kafka 的每个 partition 只能同时被同一个 group 中的一个 consumer 消费。</p>
<h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><ul>
<li><a href="">源码分析笔记</a></li>
</ul>
<h3 id="其它资料"><a href="#其它资料" class="headerlink" title="其它资料"></a>其它资料</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/3i51S1jDXbqvi6fv1cuQSg" target="_blank" rel="noopener">Kafka高性能架构之道——Kafka设计解析</a></li>
<li><a href="http://www.infoq.com/cn/articles/kafka-analysis-part-1" target="_blank" rel="noopener">Kafka背景及架构介绍</a></li>
<li><a href="http://blog.csdn.net/stark_summer/article/details/50203133" target="_blank" rel="noopener">kafka性能参数和压力测试揭秘</a></li>
<li><a href="http://zqhxuyuan.github.io/2017/12/31/Kafka-Book-Resources/" target="_blank" rel="noopener">Kafka技术内幕拾遗</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>apollo</title>
    <url>/middle-software/mq-compare/</url>
    <content><![CDATA[<h2 id="MQ框架性能比较"><a href="#MQ框架性能比较" class="headerlink" title="MQ框架性能比较"></a>MQ框架性能比较</h2><hr>
<ul>
<li><a href="https://mp.weixin.qq.com/s/ad7jibTb5nTzh3nDQYKFeg" target="_blank" rel="noopener">消息中间件选型分析</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>apollo</title>
    <url>/middle-software/mycat/</url>
    <content><![CDATA[<h2 id="mycat"><a href="#mycat" class="headerlink" title="mycat"></a>mycat</h2><hr>
<p><code>Mycat是java编写的！！！</code></p>
<h3 id="一、问题"><a href="#一、问题" class="headerlink" title="一、问题"></a>一、问题</h3><ul>
<li>目前有哪些好的开源分布式数据框架？</li>
<li>引入成本如何？</li>
<li>是否支持分布式事务？</li>
<li>是否支持动态修改配置项？</li>
<li>集群性能如何?</li>
<li>社区是否活跃？内部源码？</li>
<li>mycat如何搭建读写分离？</li>
<li>mycat如何做到主从切换？</li>
<li>支持哪些分片算法？</li>
<li>查询多张分表，支持结果集合并，如果涉及翻页或排序，需要对合并后的结果做二次加工处理。</li>
</ul>
<h3 id="二、数据相关"><a href="#二、数据相关" class="headerlink" title="二、数据相关"></a>二、数据相关</h3><p>分布式数据库特性：</p>
<ul>
<li>透明性。用户不需要了解内部结构，表现就象一个传统的单处理机系统。</li>
<li>扩展性。通过横向扩展使集群的整体性能提升。</li>
<li>可靠性。不允许单点，如果一台机器坏了，则其他机器能接替它进行工作。</li>
</ul>
<p>数据分片：</p>
<ul>
<li>水平切分。按分表键，将表的行数据拆分到多个节点库中。逻辑上单表，物理上多表。</li>
<li>垂直切分。一个数据库由很多表组成，每个表对应不同的业务。垂直切分，将表进行分类分布到不同的节点上。类似电商按商品线、交易线、会员线、店铺线等拆分到不同的DB。</li>
</ul>
<p>技术点：</p>
<ul>
<li>支持多数据源</li>
<li>主库、备库切换</li>
<li>分库</li>
<li>分表</li>
<li>支持千亿级别大表</li>
<li>事务、分布式事务</li>
<li>读写分离</li>
<li>数据合并</li>
<li>在线扩容</li>
<li>数据迁移</li>
<li>系统监控</li>
</ul>
<h3 id="三、Mycat核心组件及配置"><a href="#三、Mycat核心组件及配置" class="headerlink" title="三、Mycat核心组件及配置"></a>三、Mycat核心组件及配置</h3><h4 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h4><ul>
<li>逻辑库（Schema）</li>
</ul>
<p>数据库中间件被当成作一个或多个数据库集群构成的逻辑库。</p>
<ul>
<li>逻辑表（table）</li>
</ul>
<p>逻辑表可以分布在一个或多个分片库中，也可以不分片。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;table name&#x3D;&quot;t_user&quot; dataNode&#x3D;&quot;dn1,dn2&quot; rule&#x3D;&quot;sharding-by-mod2&quot;&#x2F;&gt;</span><br></pre></td></tr></table></figure>
<p>t_user分片表，数据按照规则被切分到dn1、dn2两个节点。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;table name&#x3D;&quot;t_node&quot; primaryKey&#x3D;&quot;id&quot; autoIncrement&#x3D;&quot;true&quot; dataNode&#x3D;&quot;dn1&quot; &#x2F;&gt;</span><br></pre></td></tr></table></figure>
<p>t_node表，非分片表，只存在于节点dn1。</p>
<p><code>primaryKey：逻辑表对应真实表的主键。对于分片规则使用非主键进行分表，如果使用主键查询会，会扫描所有分表，配置了该属性，mycat会缓存主键与dn的信息，避免所有表扫描，提升性能。但如果缓存没有命中，还是会把SQL发给所有的dn执行来获取数据。</code></p>
<ul>
<li>分片节点（dataNode）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dataNode name&#x3D;&quot;dn1&quot; dataHost&#x3D;&quot;localhost1&quot; database&#x3D;&quot;mycat_node1&quot;&#x2F;&gt;</span><br><span class="line">&lt;dataNode name&#x3D;&quot;dn2&quot; dataHost&#x3D;&quot;localhost1&quot; database&#x3D;&quot;mycat_node2&quot;&#x2F;&gt;</span><br></pre></td></tr></table></figure>
<p>一个大表被分到不同的分片数据库上，每个表分片所在的数据库就是分片节点</p>
<ul>
<li>节点主机（dataHost）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dataHost name&#x3D;&quot;localhost1&quot; writeType&#x3D;&quot;0&quot; switchType&#x3D;&quot;1&quot; slaveThreshold&#x3D;&quot;100&quot; balance&#x3D;&quot;1&quot; dbType&#x3D;&quot;mysql&quot; maxCon&#x3D;&quot;10&quot; minCon&#x3D;&quot;1&quot; dbDriver&#x3D;&quot;native&quot;&gt;</span><br><span class="line">    &lt;heartbeat&gt;show status like &#39;wsrep%&#39;&lt;&#x2F;heartbeat&gt;</span><br><span class="line">    &lt;writeHost host&#x3D;&quot;hostM1&quot; url&#x3D;&quot;127.0.0.1:3306&quot; user&#x3D;&quot;root&quot; password&#x3D;&quot;root&quot; &gt;</span><br><span class="line">    &lt;&#x2F;writeHost&gt;  </span><br><span class="line">&lt;&#x2F;dataHost&gt;</span><br></pre></td></tr></table></figure>
<p>同一台机器上可以有多个分片数据库。为了避免单节点主机并发数量的限制，尽量将读写压力高的分片节点均匀地放在不同的节点主机上。</p>
<p><code>上面只列了几个核心参数，更多参数详细说明可参考《基于mycat中间件P22》</code></p>
<h4 id="配置文件："><a href="#配置文件：" class="headerlink" title="配置文件："></a>配置文件：</h4><ul>
<li>server.xml</li>
</ul>
<p>主要是配置系统信息，有两个重要标签 user、system</p>
<ul>
<li>schema.xml</li>
</ul>
<p>主要是逻辑库、逻辑表、分片规则 、分片节点、数据源</p>
<ul>
<li>sequence</li>
</ul>
<p>在分库分表的情况下，数据库的自增主键无法保证在集群中是全局唯一的主键，因此mycat提供了全局的sequence，并支持本地配置、数据库配置等多种实现方式。</p>
<ul>
<li>rule.xml </li>
</ul>
<p>分片规则的配置文件，分片规则的具体一些参数信息单独存放为文件，也在这个目录下，配置文件修改需要重启MyCAT。</p>
<ul>
<li>log4j.xml</li>
</ul>
<p>日志存放在logs/log中，每天一个文件，日志的配置是在conf/log4j.xml中，根据自己的需要可以调整输出级别为debug，debug级别下，会输出更多的信息，方便排查问题。</p>
<p>autopartition-long.txt,partition-hash-int.txt,sequence_conf.properties， sequence_db_conf.properties 分片相关的id分片规则配置文件</p>
<ul>
<li>lib</li>
</ul>
<p>MyCAT自身的jar包或依赖的jar包的存放目录。</p>
<ul>
<li>logs    </li>
</ul>
<p>MyCAT日志的存放目录。日志存放在logs/log中，每天一个文件</p>
<h4 id="分片规则"><a href="#分片规则" class="headerlink" title="分片规则"></a>分片规则</h4><ul>
<li>取模分片（常用的方式）</li>
</ul>
<p>对分表键id按总的分表数求模计算，比如模为0，放在第1张表，模为1，放在第2张表。</p>
<ul>
<li>枚举分片</li>
</ul>
<p>配置文件中配置可能的枚举id，指定数据分布到不同的物理节点上。本规则适用于按省份或县区来拆分数据。</p>
<ul>
<li>范围分片</li>
</ul>
<p>按分片字段的某个范围放入对应分片。比如0<del>1kw，放在第1张表，1kw</del>2kw，放在第2张表</p>
<ul>
<li>范围求模算法</li>
</ul>
<p>范围分片+取模分片的组合。先根据id找到对应的分片组，分片组内使用求模可以保证组内的数据分布比较均匀。事先规定好分片的数量，数据扩容时按分片组扩容，原有的分片组的数据不需要迁移。由于分片组的数据分布比较均匀，所以分片组内可以避免热点数据问题。<br>0~1kw=5 //表示该组有5个分片节点</p>
<ul>
<li><p>固定分片hash算法</p>
</li>
<li><p>取模范围算法</p>
</li>
<li><p>字符串hash求模范围算法</p>
</li>
</ul>
<p>与取模算法类似，该算法支持数字、符号、字母取模。截取长度为prefixLength的子串，再对子串中每个字符的ascii码求和得出sum，然后对sum进行求模运算。</p>
<ul>
<li>一致性hash算法</li>
</ul>
<p>有效解决分布式数据的扩容问题。<code>每个真实的数据库节点会被映射为N倍虚拟节点，默认是160倍</code></p>
<ul>
<li>按日期（天）分片</li>
</ul>
<p>从开始时间算起，每隔sPartionDay天，对应一个数据分区。</p>
<ul>
<li>按月单小时算法</li>
<li>自然月分片算法</li>
<li>日期范围hash算法</li>
</ul>
<p>先根据日期的范围分组，再根据时间hash分到每组下对应的分片。</p>
<h3 id="四、mycat优势"><a href="#四、mycat优势" class="headerlink" title="四、mycat优势"></a>四、mycat优势</h3><ul>
<li>对Cobar代码进行了重构，使用NIO重构了网络模块，并优化了Buffer内核，增强了聚合、join等基本特性</li>
<li>支持绝大部分数据库，如oracle、mysql、sqlserver、db2、MongoDB 等，成为通用数据库中间件</li>
<li>支持透明的读写分离机制，减轻写库压力，提高数据库的并发查询能力</li>
<li>大表水平分片方式支持100亿级的数据存储</li>
<li>内建数据库集群故障切换机制，实现了自动切换</li>
<li>提供reload命令，例如更新了schema.xml文件后，不用重启即可进行配置文件更新。</li>
</ul>
<h3 id="五、源码分析"><a href="#五、源码分析" class="headerlink" title="五、源码分析"></a>五、源码分析</h3><p>mycat前身Amoeba、Cobar。</p>
<p><a href="https://github.com/MyCATApache/Mycat-Server" target="_blank" rel="noopener">github 源码</a></p>
<p>Mycat核心是拦截用户发过来SQL语句，做一些分析，例如SQL解析、分片分析、路由分析、读写分离分析、缓存分析等，然后将SQL语句发往后端的真实数据库，并将返回的结果做适当处理，最终返回给用户。</p>
<p><strong>架构剖析</strong></p>
<ul>
<li>NIO架构</li>
</ul>
<p>NIOAcceptor负责处理Accept事件，服务端接收客户端的连接事件，NIOAcceptor调用NIOReactor.postRegister进行注册</p>
<table>
<thead>
<tr>
<th>事件名</th>
<th>对应值</th>
</tr>
</thead>
<tbody><tr>
<td>服务端接收客户端连接事件</td>
<td>Selection.OP_ACCEPT</td>
</tr>
<tr>
<td>客户端连接服务端事件</td>
<td>Selection.OP_CONNECT</td>
</tr>
<tr>
<td>读事件</td>
<td>Selection.OP_READ</td>
</tr>
<tr>
<td>写事件</td>
<td>Selection.OP_WRITE</td>
</tr>
</tbody></table>
<ul>
<li>多线程架构</li>
</ul>
<p>维护一个线程池 NameableExecutor，继承自ThreadPoolExecutor。mycat内部有两大线程池：timerExectuor和businessExecutor。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timerExectuor：</span><br><span class="line">定时更新任务、处理器定时检查任务，数据节点定时心跳检测，主要是后勤工作。</span><br><span class="line"></span><br><span class="line">businessExecutor:</span><br><span class="line">处理业务请求，比如执行SQL语句，SQL拦截，数据合并，查询结果</span><br></pre></td></tr></table></figure>
<ul>
<li>内存管理及缓存架构</li>
</ul>
<p>缓冲区采用java.io.ByteBuffer，缓冲区分为直接缓冲区（操作系统内存）和非直接缓冲区（JVM内存）。</p>
<ul>
<li><p>连接池</p>
</li>
<li><p>分布式事务</p>
</li>
<li><p>sql路由实现</p>
</li>
<li><p>跨库join实现</p>
</li>
<li><p>数据汇聚、数据排序</p>
</li>
</ul>
<h3 id="六、Mycat安装"><a href="#六、Mycat安装" class="headerlink" title="六、Mycat安装"></a>六、Mycat安装</h3><p>如何安装？</p>
<p><a href="https://github.com/MyCATApache/Mycat-Server" target="_blank" rel="noopener">https://github.com/MyCATApache/Mycat-Server</a></p>
<p><code>下载文件直接解压。执行./mycat start 启动</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;mycat start 启动</span><br><span class="line">.&#x2F;mycat stop 停止</span><br><span class="line">.&#x2F;mycat console 前台运行</span><br><span class="line">.&#x2F;mycat restart 重启服务</span><br><span class="line">.&#x2F;mycat pause 暂停</span><br><span class="line">.&#x2F;mycat status 查看启动状态</span><br></pre></td></tr></table></figure>

<h3 id="七、Mycat实战"><a href="#七、Mycat实战" class="headerlink" title="七、Mycat实战"></a>七、Mycat实战</h3><ul>
<li><a href="https://github.com/MyCATApache/Mycat-doc" target="_blank" rel="noopener">入门指南、开发指南、生产部署、设计文档</a></li>
</ul>
<h4 id="1-搭建读写分离"><a href="#1-搭建读写分离" class="headerlink" title="1.搭建读写分离"></a>1.搭建读写分离</h4><p>主数据提供写操作，从数据库提供读操作，有效减轻单台数据库的压力，主数据库进行写操作后，数据及时同步到所读的数据库，尽可能保证两边数据一致。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">主（M1）&lt;----&gt; 备(M2)</span><br><span class="line">|</span><br><span class="line">|</span><br><span class="line">从(S1)</span><br></pre></td></tr></table></figure>

<ul>
<li>balance为0。不开启读写分离，所有的读全发送到M1</li>
<li>balance为1。所有的读发送到S1和M2</li>
<li>balance为2。所有的读发送到M1、M2和S1</li>
<li>balance为3。所有的读发送到S1</li>
</ul>
<h4 id="2-搭建主备切换"><a href="#2-搭建主备切换" class="headerlink" title="2.搭建主备切换"></a>2.搭建主备切换</h4><h4 id="3-mycat-percona-haproxy-keepalived"><a href="#3-mycat-percona-haproxy-keepalived" class="headerlink" title="3.mycat+percona+haproxy+keepalived"></a>3.mycat+percona+haproxy+keepalived</h4><h4 id="4-mha-keepalived"><a href="#4-mha-keepalived" class="headerlink" title="4.mha+keepalived"></a>4.mha+keepalived</h4>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Openresty安装</title>
    <url>/middle-software/openresty-setup/</url>
    <content><![CDATA[<h2 id="openresty安装"><a href="#openresty安装" class="headerlink" title="openresty安装"></a>openresty安装</h2><hr>
<h4 id="官方安装地址"><a href="#官方安装地址" class="headerlink" title="官方安装地址"></a>官方安装地址</h4><p><a href="http://openresty.org/cn/installation.html" target="_blank" rel="noopener">http://openresty.org/cn/installation.html</a></p>
<p>其中最简单的方式是通过brew命令安装</p>
<h4 id="Mac-OS下包管理器Homebrew的安装与使用"><a href="#Mac-OS下包管理器Homebrew的安装与使用" class="headerlink" title="Mac OS下包管理器Homebrew的安装与使用"></a>Mac OS下包管理器Homebrew的安装与使用</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;d229ac7fe77d</span><br></pre></td></tr></table></figure>

<h4 id="安装openresty"><a href="#安装openresty" class="headerlink" title="安装openresty"></a>安装openresty</h4><p>一键命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install openresty&#x2F;brew&#x2F;openresty</span><br></pre></td></tr></table></figure>

<p>默认安装目录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;openresty&#x2F;1.13.6.2</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rw-r--r--   1 onlyone  admin    22K  5 15 04:24 COPYRIGHT</span><br><span class="line">-rw-r--r--   1 onlyone  admin   792B  7  4 19:22 INSTALL_RECEIPT.json</span><br><span class="line">-rw-r--r--   1 onlyone  admin   4.6K  5 15 04:24 README.markdown</span><br><span class="line">drwxr-xr-x   9 onlyone  admin   306B  7  4 19:22 bin</span><br><span class="line">-rw-r--r--   1 onlyone  admin   583B  7  4 19:22 homebrew.mxcl.openresty.plist</span><br><span class="line">drwxr-xr-x   6 onlyone  admin   204B  7  4 19:22 luajit</span><br><span class="line">drwxr-xr-x   6 onlyone  admin   204B  7  4 19:22 lualib</span><br><span class="line">drwxr-xr-x  10 onlyone  admin   340B  7  4 19:55 nginx</span><br><span class="line">drwxr-xr-x  44 onlyone  admin   1.5K  7  4 19:22 pod</span><br><span class="line">-rw-r--r--   1 onlyone  admin   219K  7  4 19:22 resty.index</span><br><span class="line">drwxr-xr-x   5 onlyone  admin   170B  7  4 19:22 site</span><br></pre></td></tr></table></figure>
<p>nginx的配置文件地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;local&#x2F;etc&#x2F;openresty</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rw-r--r--  1 onlyone  admin   1.1K  7  4 19:22 fastcgi.conf</span><br><span class="line">-rw-r--r--  1 onlyone  admin   1.1K  7  4 19:22 fastcgi.conf.default</span><br><span class="line">-rw-r--r--  1 onlyone  admin   1.0K  7  4 19:22 fastcgi_params</span><br><span class="line">-rw-r--r--  1 onlyone  admin   1.0K  7  4 19:22 fastcgi_params.default</span><br><span class="line">-rw-r--r--  1 onlyone  admin   2.8K  7  4 19:22 koi-utf</span><br><span class="line">-rw-r--r--  1 onlyone  admin   2.2K  7  4 19:22 koi-win</span><br><span class="line">-rw-r--r--  1 onlyone  admin   171B  7  4 20:09 lua.conf</span><br><span class="line">-rw-r--r--  1 onlyone  admin   5.0K  7  4 19:22 mime.types</span><br><span class="line">-rw-r--r--  1 onlyone  admin   5.0K  7  4 19:22 mime.types.default</span><br><span class="line">-rw-r--r--  1 onlyone  admin   518B  7  4 19:48 nginx.conf</span><br><span class="line">-rw-r--r--  1 onlyone  admin   2.6K  7  4 19:22 nginx.conf.default</span><br><span class="line">-rw-r--r--  1 onlyone  admin   2.6K  7  4 19:22 nginx.conf_1</span><br><span class="line">-rw-r--r--  1 onlyone  admin   636B  7  4 19:22 scgi_params</span><br><span class="line">-rw-r--r--  1 onlyone  admin   636B  7  4 19:22 scgi_params.default</span><br><span class="line">-rw-r--r--  1 onlyone  admin   664B  7  4 19:22 uwsgi_params</span><br><span class="line">-rw-r--r--  1 onlyone  admin   664B  7  4 19:22 uwsgi_params.default</span><br><span class="line">-rw-r--r--  1 onlyone  admin   3.5K  7  4 19:22 win-utf</span><br></pre></td></tr></table></figure>

<h4 id="nginx配置lua脚本"><a href="#nginx配置lua脚本" class="headerlink" title="nginx配置lua脚本"></a>nginx配置lua脚本</h4><p>将系统默认的nginx.conf备份nginx.conf_1</p>
<p>新建nginx.conf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> #user  nobody;</span><br><span class="line">worker_processes  2;</span><br><span class="line"></span><br><span class="line">error_log  logs&#x2F;error.log;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  text&#x2F;html;</span><br><span class="line"></span><br><span class="line">    #lua模块路径，其中”;;”表示默认搜索路径，默认到&#x2F;usr&#x2F;servers&#x2F;nginx下找</span><br><span class="line">    lua_package_path &quot;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;openresty&#x2F;1.13.6.2&#x2F;lualib&#x2F;?.lua;;&quot;;  #lua 模块  </span><br><span class="line">    lua_package_cpath &quot;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;openresty&#x2F;1.13.6.2&#x2F;lualib&#x2F;?.so;;&quot;;  #c模块   </span><br><span class="line">    </span><br><span class="line">    include &#x2F;usr&#x2F;local&#x2F;etc&#x2F;openresty&#x2F;lua.conf;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>lua.conf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       8081;</span><br><span class="line">    server_name  _;</span><br><span class="line"></span><br><span class="line">    location &#x2F;lua &#123;</span><br><span class="line">        default_type &#39;text&#x2F;html&#39;;</span><br><span class="line">          content_by_lua  &#39;ngx.say(&quot;hello world&quot;)&#39;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意：1024以下的端口需要以root权限来启动，这里设定为8081</p>
<p><a href="http://blog.sina.com.cn/s/blog_4adc4b090102vxpz.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_4adc4b090102vxpz.html</a></p>
<h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;openresty&#x2F;1.13.6.2</span><br><span class="line"></span><br><span class="line">--启动</span><br><span class="line">sudo nginx&#x2F;sbin&#x2F;nginx</span><br><span class="line"></span><br><span class="line">-- 停止</span><br><span class="line">sudo nginx&#x2F;sbin&#x2F;nginx -s stop</span><br><span class="line"></span><br><span class="line">-- 重启</span><br><span class="line">sudo nginx&#x2F;sbin&#x2F;nginx -s reload</span><br><span class="line"></span><br><span class="line">-- 检验nginx配置是否正确</span><br><span class="line">sudo nginx&#x2F;sbin&#x2F;nginx -t</span><br></pre></td></tr></table></figure>

<p>浏览器访问：<a href="http://localhost:8081/lua" target="_blank" rel="noopener">http://localhost:8081/lua</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hello world</span><br></pre></td></tr></table></figure>

<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ul>
<li><a href="http://jinnianshilongnian.iteye.com/blog/2186270" target="_blank" rel="noopener">http://jinnianshilongnian.iteye.com/blog/2186270</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenResty（nginx+lua）</title>
    <url>/middle-software/openresty/</url>
    <content><![CDATA[<h2 id="OpenResty（nginx-lua）"><a href="#OpenResty（nginx-lua）" class="headerlink" title="OpenResty（nginx+lua）"></a>OpenResty（nginx+lua）</h2><hr>
<ul>
<li><a href="openresty-setup.md">安装</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>presto相关</title>
    <url>/middle-software/presto/</url>
    <content><![CDATA[<p>Presto是一个开源的分布式SQL查询引擎，适用于交互式分析查询，数据量支持GB到PB字节。</p>
<p>Presto支持在线数据查询，包括Hive, Cassandra, 关系数据库以及专有数据存储。 一条Presto查询可以将多个数据源的数据进行合并，可以跨越整个组织进行分析。</p>
<p>Presto以分析师的需求作为目标，他们期望响应时间小于1秒到几分钟。 Presto终结了数据分析的两难选择，要么使用速度快的昂贵的商业方案，要么使用消耗大量硬件的慢速的“免费”方案。</p>
<ul>
<li><a href="https://github.com/prestodb/presto" target="_blank" rel="noopener">源码</a></li>
<li><a href="http://prestodb-china.com/" target="_blank" rel="noopener">文档</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>RPC框架性能比较</title>
    <url>/middle-software/rpc-compare/</url>
    <content><![CDATA[<ul>
<li><a href="http://mp.weixin.qq.com/s/iw9-UaZZl3gCqKAw2Mxz6A" target="_blank" rel="noopener">RPC框架性能比较</a></li>
<li><a href="https://mp.weixin.qq.com/s/TTcQJM9s5OhyY7dmpJlcfQ" target="_blank" rel="noopener">一个针对所有RPC框架的性能测试，Dubbo排名居然垫底？</a></li>
<li><a href="https://mp.weixin.qq.com/s/PegpzyGT57pVaF1WLDuiLQ" target="_blank" rel="noopener">Dubbo将积极适配Spring Cloud生态，Spring Cloud体系或将成为微服务的不二选择！</a></li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper适用场景</title>
    <url>/middle-software/zookeeper-application-scene/</url>
    <content><![CDATA[<h1 id="dubbo（注册中心）"><a href="#dubbo（注册中心）" class="headerlink" title="dubbo（注册中心）"></a>dubbo（注册中心）</h1><p>网上资料比较多，就不多描述，可自行baidu。</p>
<a id="more"></a>
<h1 id="canal（主要用于主备切换）"><a href="#canal（主要用于主备切换）" class="headerlink" title="canal（主要用于主备切换）"></a>canal（主要用于主备切换）</h1><p>出于容灾考虑，往往会配置两个Canal Server负责一个mysql数据库实例的数据增量复制。为了减少Canal Server 的dump请求对mysql master带来的性能影响，要求不同的Canal Server上的instance在同一时刻只能有一个处于Running状态，其他的instance处于Standby状态。具体步骤：</p>
<p>a）尝试启动。所有Canal Server上的instance都会向zk尝试创建一个临时节点，哪个Canal Server创建成功了，那么就让哪个Server启动</p>
<p>b）启动instance。将自己的信息写入该节点。其它的Canal Server对该节点注册Watch监听。</p>
<p>c）主备切换。如果服务节点与zk的会话失效，临时节点会被删除，从而所有的实例会重新竞争上岗，从而实现主备切换。但有一个问题，服务节点可能存在假死情况，网络出现闪断，导致zk认为其会话失效，从而释放Running节点，但此时Cannal Server对应的JVM并没未退出。解决策略：</p>
<p>状态为Standby的Cannal Sever在收到Running节点释放通知后，会延迟一段时间（通常5秒）抢占Running节点，而原本处于Running状态的instance可以不需要等待延迟，直接重新取得Running节点。</p>
<p>更多资料可参考《从Paxos到ZooKeeper》P219</p>
<h1 id="otter"><a href="#otter" class="headerlink" title="otter"></a>otter</h1><h1 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h1><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p>分布式程序分布在不同主机上的进程对互斥资源进行访问的时候需要加锁。这样理解：很多分布式系统有多个服务窗口，但是某个时刻只让一个服务去干活，当这台服务器出问题的时候锁释放，立即fail over到其它的服务。</p>
<h1 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h1><p>分布式集群中，经常会由于各种原因，比如硬件故障，网络问题，有些节点挂掉、有些节点加进来。这个时候机器需要感知到变化，然后根据变化做出对应的决策，那么zk就实现了类似这种集群的管理。</p>
<h1 id="master选举"><a href="#master选举" class="headerlink" title="master选举"></a>master选举</h1><p>分布式高并发情况下创建节点一定是全局唯一性，zk会保证客户端无法重复创建一个已经存在的数据节点。</p>
<p>客户端集群每天定时往zk上创建一个临时节点，例如 /master-selection/2017-10-20/binding，抢节点时，只有一个客户端创建成功，那么创建节点的客户端就成了master。其他客户端在/master-selection/2017-10-20上注册一个Watcher事件，用于监控Master机器是否存活，一旦发现当前Master挂了，其余的客户端会重新进行Master选举。</p>
<h1 id="配置中心"><a href="#配置中心" class="headerlink" title="配置中心"></a>配置中心</h1><p>在分布式系统中，一般会把服务部署到n台机器上，服务配置文件都是相同的，如果配置文件的配置选项发生了改变，那我们就得一台一台的去改动。这时候zookeeper就起作用了，可以把zk当成一个高可用的配置存储器，把这样配置的事情交给zk去进行管理，将集群的配置文件拷贝到zookeeper的文件系统的某个节点上，然后用zk监控所有分布式系统里的配置文件状态，一旦发现有配置文件发生了变化，那么每台服务器同步zk的配置文件，zk同时保证同步操作的原子性，确保每个服务器的配置文件都能被更新。</p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper leader选举、数据同步</title>
    <url>/middle-software/zookeeper-leader-election-and-data-synchronous/</url>
    <content><![CDATA[<p>zk的核心是原子广播，这个机制保证了各个Server之间的同步，实现这个机制的协议叫做Zab协议。Zab协议有两种模式，分别是恢复模式（选主）和广播模式（同步）。当服务启动或者leader崩溃后，Zab进入恢复模式，当leader被选举出来，然后进行同步模式，同步完成以后，恢复模式结束。</p>
<a id="more"></a>
<p>为了保证事务的顺序一致性。实现中zxid是一个64位的数字，它高32位是用epoch用来标志leader关系是否改变，每次一个新的leader选举出来，都会拥有一个新的epoch。低32位用来递增计数。</p>
<p>（1）Serverid：在配置server时，给定的服务器的标识id，也就是myid</p>
<p>（2）Zxid：事务id，用来唯一标识一次服务器状态的变更，在某一时刻，集群中的每台机器的zxid值不一定全都一致，zxid越大，表示数据越新。</p>
<p>（3）Epoch：选举的轮数，即逻辑时钟。随着选举的轮数++</p>
<p>什么场景触发选举？</p>
<ul>
<li>服务器集群初始化启动</li>
<li>服务器运行期间无法和Leader保持连接</li>
<li>leader挂了</li>
</ul>
<h1 id="一、选主流程"><a href="#一、选主流程" class="headerlink" title="一、选主流程"></a>一、选主流程</h1><p>当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，然后需要重新选举出一个leader。让所有的Server都恢复到一个正确的状态。Zk选举算法有两种，一种是基于basic paxos实现，一种是基于fast paxos算法实现。系统默认的是fast paxos。</p>
<p>每个Server在工作过程中有三种状态：</p>
<p>LOOKING：当前Server不知道Leader是谁，正在投票、选举。</p>
<p>LEADING：领导者状态。</p>
<p>FOLLOWING：跟随者状态。</p>
<h2 id="首先介绍basic-paxos"><a href="#首先介绍basic-paxos" class="headerlink" title="首先介绍basic paxos"></a>首先介绍basic paxos</h2><p>1、 选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server。</p>
<p>2、 选举线程首先向所有Server发起一次询问（包括自己），投票信息（myid，zxid）</p>
<p>3、 收到所有Server回复以后，计算出zxid较大的那个Server，并将这个Server相关信息设置成下一次投票的Server。如果zxid相同，取myid较大那个。</p>
<p>4、 如果获胜的Server获得n/2+1的Server票数，设置当前推荐的leader为获胜的Server，将根据获胜的Server信息设置自己的状态（LEADING或FOLLOWING），否则，继续这个过程，直到leader被选举出来。</p>
<p>备注：要使Leader获得多数的Server支持，则Server总数必须是奇数2n+1，且存活的Server的数据不得少于n+1。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/20.png/w600">

<p>参考例子可参考《从Paxos到ZooKeeper》P325页</p>
<h2 id="fast-paxos："><a href="#fast-paxos：" class="headerlink" title="fast paxos："></a>fast paxos：</h2><p>1、 server启动、恢复准备加入集群，此时都会读取本身的zxid等信息。</p>
<p>2、 所有server加入集群时都会推荐自己成为leader，然后将（leader id,zxid,epoch）作为广播信息到集群中所有的server，等待集群中的server返回信息。</p>
<p>3、 收到集群中其他服务器返回的信息，分为两类，服务器处于looking状态，或者其他状态。</p>
<p>（1） 服务器处于looking状态</p>
<p>说先判断逻辑时钟Epoch：</p>
<p>（a） 如果接受到Epoch大于自己目前的逻辑时钟，那么更新本机的Epoch，同时clear其他服务器发送来的选举数据。然后判断是否需要更新当前自己的选举情况（开始选择的leader id是自己）。</p>
<p>判断规则：保存的zxid最大值和leader id来进行判断。先看数据zxid，zxid大的胜出；其次判断leader id，leader id大的胜出；然后再将自身最新的选举结果广播给其他server。</p>
<p>（b） 如果接受到的Epoch小于目前的逻辑时钟，说明对方处于一个比较低一轮的选举轮数，这时需要将自己的选举情况发送给它即可。</p>
<p>（c） 如果接收到的Epoch等于目前的逻辑时钟，再根据（a）中的判断规则，将自身的最新选举结果广播给其他server。</p>
<p>同时server还要处理两种情况：</p>
<p>（a） 如果server接收到了其他所有服务器的选举信息，那么则根据这些选举信息确定自己的状态（Following，Leading），结束Looking，退出选举。</p>
<p>（b） 即时没有收到所有服务器的选举信息，也可以判断一下根据以上过程之后最新的选举leader是不是得到了超过半数以上服务器的支持，如果是则尝试接受最新数据，如果没有最新数据，说明都接受了这个结果，同样也退出选举过程。</p>
<p>（2） 服务器处于其他状态（Following，Leading）</p>
<p>（a） 若果逻辑时钟Epoch相同，将该数据保存到recvset，若果所接受服务器宣称自己是leader，那么将判断是不是有半数以上的服务器选举他，若果是则设置选举状态退出选举过程。</p>
<p>（b） 若果Epoch不相同，那么说明另一个选举过程中已经有了选举结果，于是将选举结果加入到outofelection集合中，再根据outofelection来判断是否可以结束选举，保存逻辑时钟，设置选举状态，并退出选举过程。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/21.png/w600">


<h1 id="二、同步流程"><a href="#二、同步流程" class="headerlink" title="二、同步流程"></a>二、同步流程</h1><p>1、 leader等待server连接。</p>
<p>2、 follower连接到leader，将最大的zxid发送给leader。</p>
<p>3、 leader根据zxid确定同步点。</p>
<p>4、 同步完成之后，通知follower成为uptodate状态。</p>
<p>5、 follower收到uptodate消息后，开始接受client请求服务。</p>
<h1 id="三、主要功能"><a href="#三、主要功能" class="headerlink" title="三、主要功能"></a>三、主要功能</h1><h2 id="1、-Leader主要功能"><a href="#1、-Leader主要功能" class="headerlink" title="1、 Leader主要功能"></a>1、 Leader主要功能</h2><p>（a） 恢复数据。</p>
<p>（b） 维持与Learner的心跳，接受Learner请求并判断Learner的请求消息类型。</p>
<p>备注：Learner的消息类型主要是ping、request、ack、revalidate。</p>
<p>ping消息：是指Learner的心跳信息。</p>
<p>request消息：follower发送的提议信息，包括写请求和同步请求。</p>
<p>ack消息：是follower对提议的回复，超过半数follower通过，则commit提议。</p>
<p>revalidate消息：用来延长session有效时间。</p>
<h2 id="2、-Follower主要功能"><a href="#2、-Follower主要功能" class="headerlink" title="2、 Follower主要功能"></a>2、 Follower主要功能</h2><p>（a） 向Leader发送请求。</p>
<p>（b） 接受Leader消息并进行处理。</p>
<p>（c） 接受Client的请求，如果是写请求，发送给Leader进行投票。</p>
<p>（d） 返回结果给Client。</p>
<p>备注：follower处理Leader的如下几个消息：</p>
<p>ping：心跳信息。</p>
<p>proposal消息：leader发起提案，要求follower投票。</p>
<p>commit消息：服务器端最新一次提案的消息。</p>
<p>uptodate消息：表明同步完成。</p>
<p>revalidate消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；</p>
<p> sync消息：返回sync信息到client客户端。</p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper安装</title>
    <url>/middle-software/zookeeper-setup/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>ZooKeeper是Apache基金会的一个开源、分布式应用程序协调服务，是Google的Chubby一个开源的实现。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。它的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
<a id="more"></a>
<h2 id="一、集群模式（首选推荐，一般用于生产环境）"><a href="#一、集群模式（首选推荐，一般用于生产环境）" class="headerlink" title="一、集群模式（首选推荐，一般用于生产环境）"></a>一、集群模式（首选推荐，一般用于生产环境）</h2><h2 id="1-下载"><a href="#1-下载" class="headerlink" title="1.下载"></a>1.下载</h2><p>ZooKeeper安装包可以在其官网下载页面下载，下载地址如下，为加快下载速度可以选择中国境内的镜像，选择稳定版本zookeeper-3.4.8.tar.gz安装包。</p>
<p><a href="http://zookeeper.apache.org/releases.html#download" target="_blank" rel="noopener">http://zookeeper.apache.org/releases.html#download</a></p>
<h2 id="2-解压并配置环境变量"><a href="#2-解压并配置环境变量" class="headerlink" title="2.解压并配置环境变量"></a>2.解压并配置环境变量</h2><p>下载后把安装包方放在目录/Users/onlyone/software/zookeeper目录下，并解压</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$cd &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper</span><br><span class="line">$tar -zxvf zookeeper-3.4.8.tar.gz</span><br></pre></td></tr></table></figure>
<p>将ZooKeeper的bin路径加入到/Users/onlyone/.bash_profile中，设置如下内容（分发到各节点后，在各节点上做同样设置）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export ZOOKEEPER_HOME&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8</span><br><span class="line">export PATH&#x3D;$PATH:$ZOOKEEPER_HOME&#x2F;bin</span><br></pre></td></tr></table></figure>

<p>设置完毕后使用如下命令使配置生效：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$source .bash_profile</span><br></pre></td></tr></table></figure>

<h2 id="3-修改ZooKeeper的配置文件"><a href="#3-修改ZooKeeper的配置文件" class="headerlink" title="3.修改ZooKeeper的配置文件"></a>3.修改ZooKeeper的配置文件</h2><p>在ZooKeeper的根目录下建立data和log目录用于存放工作数据和日志文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$mkdir &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;data&#x2F;</span><br><span class="line">$mkdir &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;log&#x2F;</span><br></pre></td></tr></table></figure>
<p>在ZooKeeper配置目录下默认情况下，不存在在zoo.cfg文件，需要复制一份，然后进行修改，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$cd &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;conf&#x2F;</span><br><span class="line">$cp zoo_sample.cfg zoo.cfg</span><br><span class="line">$sudo vi zoo.cfg</span><br></pre></td></tr></table></figure>
<p>修改zoo.cfg配置文件内容（仅列出重要配置）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;用于存放ZooKeeper的数据和日志</span><br><span class="line">dataDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;data</span><br><span class="line">dataLogDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;log</span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F;外部客户端连接端口号，在Kafka中将使用该端口号</span><br><span class="line">clientPort&#x3D;2181</span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F;ZooKeeper集群相关配置信息</span><br><span class="line">server.1&#x3D;ip1:2888:3888</span><br><span class="line">server.2&#x3D;ip2:2888:3888</span><br><span class="line">server.3&#x3D;ip3:2888:3888</span><br><span class="line">配置中server.A&#x3D;B：C：D含义如下</span><br><span class="line"></span><br><span class="line">* A为数字，表示这个是第几号服务器；</span><br><span class="line">* B 表示该服务器的 ip 地址；</span><br><span class="line">* C 表示该服务器与集群中的 Leader 服务器交换信息的端口；</span><br><span class="line">* D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</span><br><span class="line"></span><br><span class="line">如果是伪集群的配置方式，由于 B 都是一样，所以不同的 ZooKeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。</span><br></pre></td></tr></table></figure>

<h2 id="4-分发ZooKeeper到各节点"><a href="#4-分发ZooKeeper到各节点" class="headerlink" title="4.分发ZooKeeper到各节点"></a>4.分发ZooKeeper到各节点</h2><p>使用scp命令到ZooKeeper分发到slave1和slave2节点上：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$cd &#x2F;app&#x2F;soft&#x2F;</span><br><span class="line">$scp -r zookeeper-3.4.8 spark@slave1:&#x2F;app&#x2F;soft</span><br><span class="line">$scp -r zookeeper-3.4.8 spark@slave2:&#x2F;app&#x2F;soft</span><br><span class="line">在dataDir目录下创建一个myid文件，然后分别在myid文件中按照zoo.cfg文件的server.A中A的数值，在不同机器上的该文件中填写相应的值，如master节点该值为1、slave1节点该值为2、slave2节点该值为3。</span><br><span class="line"></span><br><span class="line">$cd &#x2F;app&#x2F;soft&#x2F;zookeeper-3.4.8&#x2F;data</span><br><span class="line">$vi myid</span><br></pre></td></tr></table></figure>

<h2 id="5-启动并验证"><a href="#5-启动并验证" class="headerlink" title="5.启动并验证"></a>5.启动并验证</h2><p>执行命令“zkServer.sh start”将会启动ZooKeeper。在此大家需要注意的是，不同节点上的ZooKeeper需要单独启动。</p>
<p>而执行命令“zkServer.sh stop”将会停止ZooKeeper。</p>
<p>使用命令“JPS”查看ZooKeeper是否成功启动，或执行命令“zkServer.sh status”查看ZooKeeper集群状态：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$zkServer.sh start</span><br><span class="line">$zkServer.sh status</span><br></pre></td></tr></table></figure>
<p>当第一个节点启动ZooKeeper时由于集群的其他节点未启动ZooKeeper，使用zkServer.sh status命令查看当前状态时会提示错误。但是随着后续节点的ZooKeeper的陆续启动，使用status查看状态时会显示当前节点的状态，本次master作为了follower。</p>
<h2 id="二、单机模式"><a href="#二、单机模式" class="headerlink" title="二、单机模式"></a>二、单机模式</h2><p>zk支持单机部署，只要启动一台zk机器，就可以提供正常服务</p>
<p>单机模式的部署步骤和集群模式的部署步骤基本一致，只是在zoo.cfg文件的配置上有些差异。</p>
<p>进入目录中的conf目录，有一个zoo_sample.cfg文件，将其重命名为zoo.cfg，然后打开，在最后添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dataDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;data</span><br><span class="line">dataLogDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;log</span><br><span class="line">clientPort&#x3D;2181</span><br></pre></td></tr></table></figure>

<p>启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;bin&#x2F;zkServer.sh start</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  zookeeper-3.4.8 telnet 127.0.0.1 2181                </span><br><span class="line">Trying 127.0.0.1...</span><br><span class="line">Connected to localhost.</span><br><span class="line">Escape character is &#39;^]&#39;.</span><br><span class="line">stat</span><br><span class="line">Zookeeper version: 3.4.8--1, built on 02&#x2F;06&#x2F;2016 03:18 GMT</span><br><span class="line">Clients:</span><br><span class="line"> &#x2F;127.0.0.1:50446[0](queued&#x3D;0,recved&#x3D;1,sent&#x3D;0)</span><br><span class="line"></span><br><span class="line">Latency min&#x2F;avg&#x2F;max: 0&#x2F;0&#x2F;0</span><br><span class="line">Received: 2</span><br><span class="line">Sent: 1</span><br><span class="line">Connections: 1</span><br><span class="line">Outstanding: 0</span><br><span class="line">Zxid: 0x0</span><br><span class="line">Mode: standalone</span><br><span class="line">Node count: 4</span><br><span class="line">Connection closed by foreign host.</span><br></pre></td></tr></table></figure>

<p>集群模式和单机模式下输出的服务器验证信息基本一致，只有Mode属性不一样。</p>
<h2 id="三、伪集群模式（一般用于测试环境）"><a href="#三、伪集群模式（一般用于测试环境）" class="headerlink" title="三、伪集群模式（一般用于测试环境）"></a>三、伪集群模式（一般用于测试环境）</h2><p>比如有一台物理机（10核16G内存），如果做为单机模式有点浪费，如果按照集群模式，需要借助硬件的虚拟化技术，把一台物理机转换成几台虚拟机。</p>
<p>伪集群，集群所有的机器都在一台机器上，但是还是以集群的特性对外提供服务。</p>
<p>创建环境目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk1</span><br><span class="line">mkdir &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk2</span><br><span class="line">mkdir &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo &quot;1&quot; &gt; &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk1&#x2F;data&#x2F;myid</span><br><span class="line">echo &quot;2&quot; &gt; &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk2&#x2F;data&#x2F;myid</span><br><span class="line">echo &quot;3&quot; &gt; &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk3&#x2F;data&#x2F;myid</span><br></pre></td></tr></table></figure>
<p>分别修改配置文件</p>
<p>修改：dataDir、dataLogDir、clientPort</p>
<p>增加：集群的实例，server.X，”X”表示每个目录中的myid的值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk1&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line"></span><br><span class="line">tickTime&#x3D;2000</span><br><span class="line">initLimit&#x3D;10</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line">dataDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk1&#x2F;data</span><br><span class="line">dataLogDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk1&#x2F;log</span><br><span class="line">clientPort&#x3D;2181</span><br><span class="line">server.1&#x3D;192.168.0.14:2888:3888</span><br><span class="line">server.2&#x3D;192.168.0.14:2889:3889</span><br><span class="line">server.3&#x3D;192.168.0.14:2890:3890</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vi &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk2&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line"></span><br><span class="line">tickTime&#x3D;2000</span><br><span class="line">initLimit&#x3D;10</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line">dataDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk2&#x2F;data</span><br><span class="line">dataLogDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk2&#x2F;log</span><br><span class="line">clientPort&#x3D;2182</span><br><span class="line">server.1&#x3D;192.168.0.14:2888:3888</span><br><span class="line">server.2&#x3D;192.168.0.14:2889:3889</span><br><span class="line">server.3&#x3D;192.168.0.14:2890:3890</span><br><span class="line"></span><br><span class="line">vi &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk3&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line"></span><br><span class="line">tickTime&#x3D;2000</span><br><span class="line">initLimit&#x3D;10</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line">dataDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk3&#x2F;data</span><br><span class="line">dataLogDir&#x3D;&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk3&#x2F;log</span><br><span class="line">clientPort&#x3D;2183</span><br><span class="line">server.1&#x3D;192.168.0.14:2888:3888</span><br><span class="line">server.2&#x3D;192.168.0.14:2889:3889</span><br><span class="line">server.3&#x3D;192.168.0.14:2890:3890</span><br></pre></td></tr></table></figure>
<p>注意：本地启动，要注意更改ip</p>
<p>3个节点配置完成，然后启动集群</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;bin&#x2F;zkServer.sh start &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk1&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line"></span><br><span class="line">&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;bin&#x2F;zkServer.sh start &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk2&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line"></span><br><span class="line">&#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;bin&#x2F;zkServer.sh start &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk3&#x2F;conf&#x2F;zoo.cfg</span><br></pre></td></tr></table></figure>
<p>查看节点状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  bin &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;bin&#x2F;zkServer.sh status &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk1&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk1&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line">➜  bin &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;bin&#x2F;zkServer.sh status &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk2&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk2&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line">➜  bin &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zookeeper-3.4.8&#x2F;bin&#x2F;zkServer.sh status &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk3&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;zookeeper&#x2F;zk-cluster&#x2F;zk3&#x2F;conf&#x2F;zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure>
<p>可以看出zk2是leader，zk1和zk3是follower</p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Solr和Elasticsearch的区别</title>
    <url>/middle-software/solr%E5%92%8Celasticsearch/</url>
    <content><![CDATA[<h2 id="一、关于搜索引擎"><a href="#一、关于搜索引擎" class="headerlink" title="一、关于搜索引擎"></a>一、关于搜索引擎</h2><p>搜索引擎（Search Engine）是指根据一定的策略、运用特定的计算机程序从互联网上搜集信息，在对信息进行组织和处理后，为用户提供检索服务，将用户检索相关的信息展示给用户的系统。搜索引擎包括全文索引、目录索引、元搜索引擎、垂直搜索引擎、集合式搜索引擎、门户搜索引擎与免费链接列表等。</p>
<a id="more"></a>
<p>一个搜索引擎由搜索器 、索引器 、检索器 和用户接口 四个部分组成。搜索器的功能是在互联网中漫游，发现和搜集信息。索引器的功能是理解搜索器所搜索的信息，从中抽取出索引项，用于表示文档 以及生成文档库的索引表。检索器的功能是根据用户的查询在索引库中快速检出文档，进行文档与查询的相关度评价，对将要输出的结果进行排序，并实现某种用户相关性反馈机制。用户接口的作用是输入用户查询、显示查询结果、提供用户相关性反馈机制。</p>
<h2 id="二、Lucene"><a href="#二、Lucene" class="headerlink" title="二、Lucene"></a>二、Lucene</h2><p>solr和elasticsearch都是基于Lucene实现的，因此这里有必要对Lucene进行介绍。</p>
<p>Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。Lucene是一套用于全文检索和搜寻的开源程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。在Java开发环境里Lucene是一个成熟的免费开源工具。就其本身而言，Lucene是当前以及最近几年最受欢迎的免费Java信息检索程序库。人们经常提到信息检索程序库，虽然与搜索引擎有关，但不应该将信息检索程序库与搜索引擎相混淆。</p>
<p>Lucene是一个全文检索引擎的架构。那什么是全文搜索引擎？</p>
<p>全文搜索引擎是名副其实的搜索引擎，国外具代表性的有Google、Fast/AllTheWeb、AltaVista、Inktomi、Teoma、WiseNut等，国内著名的有百度（Baidu）。它们都是通过从互联网上提取的各个网站的信息（以网页文字为主）而建立的数据库中，检索与用户查询条件匹配的相关记录，然后按一定的排列顺序将结果返回给用户，因此他们是真正的搜索引擎。</p>
<p>从搜索结果来源的角度，全文搜索引擎又可细分为两种，一种是拥有自己的检索程序（Indexer），俗称“蜘蛛”（Spider）程序或“机器人”（Robot）程序，并自建网页数据库，搜索结果直接从自身的数据库中调用，如上面提到的7家引擎；另一种则是租用其他引擎的数据库，并按自定的格式排列搜索结果，如Lycos引擎。</p>
<h2 id="三、solr"><a href="#三、solr" class="headerlink" title="三、solr"></a>三、solr</h2><p>Solr是一个基于Lucene的Java搜索引擎服务器。Solr 提供了层面搜索、命中醒目显示并且支持多种输出格式（包括 XML/XSLT 和 JSON 格式）。它易于安装和配置，而且附带了一个基于 HTTP 的管理界面。Solr已经在众多大型的网站中使用，较为成熟和稳定。Solr 包装并扩展了 Lucene，所以Solr的基本上沿用了Lucene的相关术语。更重要的是，Solr 创建的索引与 Lucene 搜索引擎库完全兼容。通过对Solr 进行适当的配置，某些情况下可能需要进行编码，Solr 可以阅读和使用构建到其他 Lucene 应用程序中的索引。此外，很多 Lucene 工具（如Nutch、 Luke）也可以使用Solr 创建的索引。</p>
<p>推荐一本不错的书籍：《Lucene In Action》</p>
<h2 id="四、elasticsearch"><a href="#四、elasticsearch" class="headerlink" title="四、elasticsearch"></a>四、elasticsearch</h2><p>Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。</p>
<p>但是，Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。</p>
<p>Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。</p>
<h2 id="五、solr和elasticsearch比较"><a href="#五、solr和elasticsearch比较" class="headerlink" title="五、solr和elasticsearch比较"></a>五、solr和elasticsearch比较</h2><p>Elasticsearch 与 Solr 的比较总结</p>
<p>二者安装都很简单；</p>
<p>Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能;</p>
<p>Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式；</p>
<p>Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供；</p>
<p>Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。</p>
<p>Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。</p>
<p>两者对比更详细介绍请看如下文章：</p>
<p><a href="http://www.cnblogs.com/chowmin/articles/4629220.html" target="_blank" rel="noopener">http://www.cnblogs.com/chowmin/articles/4629220.html</a></p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>sharding-jdbc</title>
    <url>/middle-software/sharding-jdbc/</url>
    <content><![CDATA[<ul>
<li><a href="https://github.com/shardingjdbc" target="_blank" rel="noopener">源代码</a></li>
<li><a href="https://www.slahser.com/2016/06/25/%E5%BD%93%E5%BD%93%E7%9A%84sharding-jdbc%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/" target="_blank" rel="noopener">当当的sharding Jdbc源码解读</a></li>
<li><a href="http://www.iocoder.cn/categories/Sharding-JDBC/" target="_blank" rel="noopener">Sharding-JDBC 源码解析合集</a></li>
<li><a href="https://mp.weixin.qq.com/s/6mwfMAioa59ThwqGDNCp1A" target="_blank" rel="noopener">Sharding-JDBC 源码解析合集</a></li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper命令行操作</title>
    <url>/middle-software/zookeeper-command-operation/</url>
    <content><![CDATA[<h1 id="通过客户端连接ZooKeeper的集群"><a href="#通过客户端连接ZooKeeper的集群" class="headerlink" title="通过客户端连接ZooKeeper的集群"></a>通过客户端连接ZooKeeper的集群</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/Users/onlyone/software/zookeeper/zookeeper-3.4.8/bin/zkCli.sh -server 192.168.0.14:2181</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h1 id="help-打印命令行帮助"><a href="#help-打印命令行帮助" class="headerlink" title="help 打印命令行帮助"></a>help 打印命令行帮助</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 0] help</span><br><span class="line">ZooKeeper -server host:port cmd args</span><br><span class="line">	stat path [watch]</span><br><span class="line">	set path data [version]</span><br><span class="line">	ls path [watch]</span><br><span class="line">	delquota [-n|-b] path</span><br><span class="line">	ls2 path [watch]</span><br><span class="line">	setAcl path acl</span><br><span class="line">	setquota -n|-b val path</span><br><span class="line">	history </span><br><span class="line">	redo cmdno</span><br><span class="line">	printwatches on|off</span><br><span class="line">	delete path [version]</span><br><span class="line">	sync path</span><br><span class="line">	listquota path</span><br><span class="line">	rmr path</span><br><span class="line">	get path [watch]</span><br><span class="line">	create [-s] [-e] path data acl</span><br><span class="line">	addauth scheme auth</span><br><span class="line">	quit </span><br><span class="line">	getAcl path</span><br><span class="line">	close </span><br><span class="line">	connect host:port</span><br><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 1]</span><br></pre></td></tr></table></figure>

<h1 id="创建一个节点"><a href="#创建一个节点" class="headerlink" title="创建一个节点"></a>创建一个节点</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create &#x2F;node &#39;node value&#39;</span><br></pre></td></tr></table></figure>

<h1 id="ls，查看-目录内容"><a href="#ls，查看-目录内容" class="headerlink" title="ls，查看/目录内容"></a>ls，查看/目录内容</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 3] ls &#x2F;</span><br><span class="line">[node, zookeeper]</span><br></pre></td></tr></table></figure>


<h1 id="查看-node节点的数据信息"><a href="#查看-node节点的数据信息" class="headerlink" title="查看/node节点的数据信息"></a>查看/node节点的数据信息</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 4] get &#x2F;node</span><br><span class="line">node value</span><br><span class="line">cZxid &#x3D; 0x100000002</span><br><span class="line">ctime &#x3D; Wed Oct 25 09:22:10 CST 2017</span><br><span class="line">mZxid &#x3D; 0x100000002</span><br><span class="line">mtime &#x3D; Wed Oct 25 09:22:10 CST 2017</span><br><span class="line">pZxid &#x3D; 0x100000002</span><br><span class="line">cversion &#x3D; 0</span><br><span class="line">dataVersion &#x3D; 0</span><br><span class="line">aclVersion &#x3D; 0</span><br><span class="line">ephemeralOwner &#x3D; 0x0</span><br><span class="line">dataLength &#x3D; 10</span><br><span class="line">numChildren &#x3D; 0</span><br><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 5]</span><br></pre></td></tr></table></figure>

<h1 id="修改-node节点的数据"><a href="#修改-node节点的数据" class="headerlink" title="修改/node节点的数据"></a>修改/node节点的数据</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 23] set &#x2F;node &#39;new value 1&#39;</span><br><span class="line">cZxid &#x3D; 0x100000002</span><br><span class="line">ctime &#x3D; Wed Oct 25 09:22:10 CST 2017</span><br><span class="line">mZxid &#x3D; 0x100000003</span><br><span class="line">mtime &#x3D; Wed Oct 25 09:26:50 CST 2017</span><br><span class="line">pZxid &#x3D; 0x100000002</span><br><span class="line">cversion &#x3D; 0</span><br><span class="line">dataVersion &#x3D; 1</span><br><span class="line">aclVersion &#x3D; 0</span><br><span class="line">ephemeralOwner &#x3D; 0x0</span><br><span class="line">dataLength &#x3D; 11</span><br><span class="line">numChildren &#x3D; 0</span><br><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 24]</span><br></pre></td></tr></table></figure>


<h1 id="删除-node-节点"><a href="#删除-node-节点" class="headerlink" title="删除 /node 节点"></a>删除 /node 节点</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 25] delete &#x2F;node</span><br><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 26]</span><br></pre></td></tr></table></figure>

<h1 id="quit-退出客户端连接"><a href="#quit-退出客户端连接" class="headerlink" title="quit,退出客户端连接"></a>quit,退出客户端连接</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.0.24:2181(CONNECTED) 28] quit</span><br><span class="line">Quitting...</span><br><span class="line">2017-10-25 09:29:12,234 [myid:] - INFO  [main:ZooKeeper@684] - Session: 0x15f51069cb20000 closed</span><br><span class="line">2017-10-25 09:29:12,237 [myid:] - INFO  [main-EventThread:ClientCnxn$EventThread@519] - EventThread shut down for session: 0x15f51069cb20000</span><br><span class="line">➜  bin</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper汇总</title>
    <url>/middle-software/zookeeper/</url>
    <content><![CDATA[<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="../zookeeper-setup">安装</a></li>
<li><a href="../zookeeper-command-operation">命令行操作</a></li>
<li><a href="../zookeeper-application-scene">适用场景</a></li>
<li><a href="../zookeeper-leader-election-and-data-synchronous">leader选举、数据同步</a></li>
</ul>
<hr>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>zk为分布式应用提供了高效且可靠的分布式协调服务。用于解决数据同步、数据发布/订阅、集群管理、配置管理、分布式锁、命名服务、负载均衡等问题。最早由雅虎创建，具有以下特性：</p>
<ul>
<li>顺序一致性</li>
</ul>
<p>包括全局有序和偏序两种：全局有序是指如果再一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。</p>
<ul>
<li>原子性</li>
</ul>
<p>更新只能成功或者失败，没有其他中间信息</p>
<ul>
<li>单一视图</li>
</ul>
<p>不管连接到zk集群的哪台机器，客户端看到的视图都是一致的</p>
<ul>
<li>可靠性</li>
</ul>
<p>消息message被到一台服务器接受，那么它到任何服务器都被接受。</p>
<ul>
<li>实时性</li>
</ul>
<p>zk保证在一个时间间隔范围内获得服务器的更新信息，或者服务器失效信息。但是由于网络延时等一些其他原因，zk不能保证两个客户端同事得到更新或者失效信息。</p>
<ul>
<li>强一致性</li>
</ul>
<p>分布式高并发情况下创建节点一定是全局唯一性，zk会保证客户端无法重复创建一个已经存在的数据节点。</p>
<p>zk采用树型结构的名字空间，类似于一个文件系统的目录结构，全量数据存储在内存中。当节点发生变化时（创建、删除、数据变更），可以通知各个客户端。</p>
<p><strong>zk的数据节点有两种：持久性节点、临时节点</strong>。对于临时节点，一旦创建znode的客户端与服务器失去联系，这个znode就会自动删除，ZooKeeper的客户端与服务器通信采用长连接的方式（这种连接状态称为session），如果znode是临时节点，这个session失效，znode也就被删除了。</p>
<p>zk以集群形式对外提供服务，集群只要有一半的机器能正常工作，就可以正常运转。默认端口号2181。</p>
<p>zk支持单机、集群两种模式。</p>
<p>常用于一些大型的分布式系统的应用，比如：Hadoop、Kafka、Hbase、dubbo</p>
<p><strong>常用命令：</strong></p>
<ul>
<li>创建节点（create）</li>
<li>读取（get）</li>
<li>更新节点的数据内容（set）</li>
<li>删除（delete）</li>
</ul>
<p><strong>开源的客户端：</strong></p>
<ul>
<li>ZkClient</li>
<li><a href="http://blog.csdn.net/dc_726/article/details/46475633" target="_blank" rel="noopener">Curator</a></li>
</ul>
<p><strong>监控：</strong></p>
<ul>
<li><a href="https://blog.csdn.net/liubowin/article/details/77966868?locationNum=6&fps=1" target="_blank" rel="noopener">ZooInspector</a> </li>
</ul>
<h2 id="ZkClient-介绍"><a href="#ZkClient-介绍" class="headerlink" title="ZkClient 介绍"></a>ZkClient 介绍</h2><p>ZkClient是github上一个开源的ZK客户端，在zookeeper原生API接口之上进行了包装，是一个更易用的ZK客户端。实现了如session超时重连、Watcher反复注册等功能，使得zookeeper客户端的繁琐细节工作对开发人员透明。</p>
<p>pom依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>jline<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jline<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.github.sgroschupf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zkclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="代码示例："><a href="#代码示例：" class="headerlink" title="代码示例："></a>代码示例：</h2><h2 id="1-建立客户端连接"><a href="#1-建立客户端连接" class="headerlink" title="1.建立客户端连接"></a>1.建立客户端连接</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 使用ZKClient来创建一个Zookeeper客户端</span><br><span class="line"> * </span><br><span class="line"> * @author onlyone</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class CreateSession &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        &#x2F;&#x2F; 建立连接</span><br><span class="line">        ZkClient zkClient &#x3D; new ZkClient(&quot;192.168.1.1:2188,192.168.1.2:2188;192.168.1.3:2188&quot;, 5000);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ZkClient 构造方法参数说明：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>zkServers</td>
<td>用英文状态的逗号分开的host:port字符串组成，比如 192.168.1.1:2188,192.168.1.2:2188;192.168.1.3:2188</td>
</tr>
<tr>
<td>connectionTimeout</td>
<td>创建连接超时时间，单位毫秒，超时无法与ZooKeeper建立连接，抛出异常</td>
</tr>
<tr>
<td>sessionTimeout</td>
<td>会话超时时间，单位毫秒，默认 30000</td>
</tr>
<tr>
<td>ZkSerializer</td>
<td>自定义序列化器</td>
</tr>
<tr>
<td>zkConnection</td>
<td>IZkConnection接口实现类，包含了增、删、改、查等一系列方法</td>
</tr>
</tbody></table>
<h2 id="2-创建节点"><a href="#2-创建节点" class="headerlink" title="2.创建节点"></a>2.创建节点</h2><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/3.png/w600">

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>path</td>
<td>指定数据节点的节点路径</td>
</tr>
<tr>
<td>data</td>
<td>节点的初始数据内容，可以为null</td>
</tr>
<tr>
<td>mode</td>
<td>节点类型，可以为一个枚举类型，有4种</td>
</tr>
<tr>
<td>createParents</td>
<td>是否创建父节点</td>
</tr>
</tbody></table>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 创建provier子节点，如果父节点root不存在，会先创建父节点</span><br><span class="line">zkClient.createPersistent(&quot;&#x2F;root&#x2F;provier&quot;, true);</span><br></pre></td></tr></table></figure>

<h2 id="3-删除节点"><a href="#3-删除节点" class="headerlink" title="3.删除节点"></a>3.删除节点</h2><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/4.png/w600">

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>path</td>
<td>数据节点的完整节点路径</td>
</tr>
</tbody></table>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; zk只允许叶子节点，如果下面还有子节点的话，无法直接删除，deleteRecursive方法自动逐层遍历删除节点</span><br><span class="line">zkClient.deleteRecursive(&quot;&#x2F;root&#x2F;provier&quot;);</span><br></pre></td></tr></table></figure>

<h2 id="4-读取数据"><a href="#4-读取数据" class="headerlink" title="4.读取数据"></a>4.读取数据</h2><ul>
<li>getChildren</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;获取指定节点的子节点列表，返回值为子节点的相对路径，结果 [provider,consumer]</span><br><span class="line">List&lt;String&gt; subNode &#x3D; zkClient.getChildren(&quot;&#x2F;dubbo&#x2F;interface_1.0.0&quot;);</span><br></pre></td></tr></table></figure>

<ul>
<li><p>subscribeChildChanges</p>
<p>与原生的Watcher不同的是，zkclient的Listener不是一次性的，客户端只需要注册一次就会一直生效。</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 订阅子节点列表变更的监听，一旦子节点列表发生变更，zk服务端会向客户端发出事件通知，由Listener来处理</span></span><br><span class="line">zkClient.subscribeChildChanges(<span class="string">"/root"</span>, <span class="keyword">new</span> IZkChildListener() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleChildChange</span><span class="params">(String parentPath, List&lt;String&gt; currentChilds)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"parentPath="</span> + parentPath + <span class="string">",currentChilds="</span> + currentChilds);</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<ul>
<li><p>readData</p>
<p>获取指定节点的数据内容。</p>
</li>
</ul>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/5.png/w600">

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>returnNullIfPathNotExists</td>
<td>如果节点不存在，返回null，而不是抛出异常</td>
</tr>
<tr>
<td>stat</td>
<td>指定数据节点的节点状态信息</td>
</tr>
</tbody></table>
<ul>
<li><p>subscribeDataChanges</p>
<p>“节点内容变更”和“节点删除”事件监听。</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">zkClient.subscribeDataChanges(<span class="string">"/root"</span>, <span class="keyword">new</span> IZkDataListener() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleDataDeleted</span><span class="params">(String dataPath)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">// 指定节点被删除，dataPath为全路径</span></span><br><span class="line">                System.out.println(<span class="string">"Node: "</span> + dataPath + <span class="string">" deleted!"</span>);</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定节点的数据内容或数据版本发生变更，会触发这个事件。</span></span><br><span class="line">            <span class="comment">// dataPath为全路径;data最新的数据节点内容</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleDataChange</span><span class="params">(String dataPath, Object data)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"Node:  "</span> + dataPath + <span class="string">" changed!, new data:"</span> + data);</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>


<h2 id="5-更新数据"><a href="#5-更新数据" class="headerlink" title="5.更新数据"></a>5.更新数据</h2><img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/6.png/w600">

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>path</td>
<td>数据节点的完整路径</td>
</tr>
<tr>
<td>object</td>
<td>数据内容，可以是null</td>
</tr>
<tr>
<td>expectedVersion</td>
<td>预期的数据版本，实现类似CAS的原子操作</td>
</tr>
</tbody></table>
<h2 id="6-检测节点是否存在"><a href="#6-检测节点是否存在" class="headerlink" title="6.检测节点是否存在"></a>6.检测节点是否存在</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean isNodeExist &#x3D; zkClient.exists(&quot;&#x2F;root&quot;);</span><br></pre></td></tr></table></figure>

<h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><ul>
<li><a href="https://github.com/apache/zookeeper" target="_blank" rel="noopener">https://github.com/apache/zookeeper</a></li>
<li><a href="https://github.com/llohellohe/zookeeper" target="_blank" rel="noopener">https://github.com/llohellohe/zookeeper</a></li>
<li><a href="http://mp.weixin.qq.com/s/pTXUAMgGpafhNNWfW2R_Cw" target="_blank" rel="noopener">zookeeper 入门系列 : 概述</a></li>
<li><a href="http://mp.weixin.qq.com/s/a17RBmGABt8j_mmxgBN94w" target="_blank" rel="noopener">paxos 协议</a></li>
</ul>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring事务传播机制与隔离级别</title>
    <url>/spring/Spring%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E6%9C%BA%E5%88%B6%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
    <content><![CDATA[<h1 id="Spring事务传播性机制"><a href="#Spring事务传播性机制" class="headerlink" title="Spring事务传播性机制"></a>Spring事务传播性机制</h1><h2 id="什么是事务的传播机制"><a href="#什么是事务的传播机制" class="headerlink" title="什么是事务的传播机制"></a>什么是事务的传播机制</h2><p>事务的传播性一般在事务嵌套时候使用，比如在事务A里面调用了另外一个使用事务的方法，那么这俩个事务是各自作为独立的事务执行提交，还是内层的事务合并到外层的事务一块提交那，这就是事务传播性要确定的问题。下面一一介绍比较常用的事务传播机制。</p>
<p>首先奉上事务拦截器TransactionInterceptor事务处理流程图：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/spring/SpringTransactionInterceptor/1.png/w600">

<h1 id="Spring事务的7种传播机制"><a href="#Spring事务的7种传播机制" class="headerlink" title="Spring事务的7种传播机制"></a>Spring事务的7种传播机制</h1><h2 id="1-PROPAGATION-REQUIRED"><a href="#1-PROPAGATION-REQUIRED" class="headerlink" title="1. PROPAGATION_REQUIRED"></a>1. PROPAGATION_REQUIRED</h2><p>Spring默认的事务传播机制，如果外层有事务则当前事务<strong>加入</strong>到外层事务，一块提交一块回滚，如果外层没有事务则当前开启一个新事务。这个机制可以满足大多数业务场景。</p>
<p>若当前存在事务，则加入该事务，若不存在事务，则新建一个事务。<br>试验：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C1</span>()</span>&#123;</span><br><span class="line">    <span class="meta">@Transactional</span>(propagation = Propagation.REQUIRED)</span><br><span class="line">    <span class="function">function <span class="title">A</span><span class="params">()</span></span>&#123;</span><br><span class="line">        C2.B();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C2</span>()</span>&#123;</span><br><span class="line">    <span class="meta">@Transactional</span>(propagation = Propagation.REQUIRED)</span><br><span class="line">    <span class="function">function <span class="title">B</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">do</span> something;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>若B方法抛出异常，A方法进行捕获，A会抛出异常，因为C2标志回滚，C1标志提交，产生冲突。</p>
</li>
<li><p>若B方法抛出异常，B方法内部捕获，A、B都不会回滚。</p>
</li>
<li><p>若A或B抛出异常，但没有捕获，则A、B都回滚。</p>
</li>
<li><p>A、B可操作同一条记录，因为处于同一个事务中。</p>
</li>
</ul>
<p>平时我们都是在bo里面调用数据库操作，在rpc和screen调用bo,所以bo层不应该catch掉异常，而应该抛出来，在rpc和screen层catch异常。</p>
<h2 id="2-PROPAGATION-REQUIRES-NEW"><a href="#2-PROPAGATION-REQUIRES-NEW" class="headerlink" title="2. PROPAGATION_REQUIRES_NEW"></a>2. PROPAGATION_REQUIRES_NEW</h2><p>每次都新开启一个事务，同时把外层的事务挂起，当前新事务执行完毕后在恢复上层事务的执行。</p>
<p>新老事务相互独立。外部事务抛出异常回滚不会影响内部事务的正常提交。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C1</span>()</span>&#123;</span><br><span class="line">    <span class="meta">@Transactional</span>(propagation = Propagation.REQUIRED)</span><br><span class="line">    <span class="function">function <span class="title">A</span><span class="params">()</span></span>&#123;</span><br><span class="line">        C2.B();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C2</span>()</span>&#123;</span><br><span class="line">    <span class="meta">@Transactional</span>(propagation = Propagation.REQUIRE_NEW)</span><br><span class="line">    <span class="function">function <span class="title">B</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">do</span> something;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>若B方法抛出异常，A方法进行捕获，B方法回滚，A方法不受B异常影响。</p>
</li>
<li><p>若B方法抛出异常，B方法内部捕获，A、B都不会回滚。</p>
</li>
<li><p>若A方法抛出异常，不会影响B正常执行。</p>
</li>
<li><p>若B方法抛出异常，A、B方法都没有处理，则A、B都会回滚。</p>
</li>
<li><p>A、B不可操作同一条记录，因为处于不同事务中，会产生死锁。</p>
</li>
</ul>
<h2 id="3-PROPAGATION-SUPPORTS"><a href="#3-PROPAGATION-SUPPORTS" class="headerlink" title="3. PROPAGATION_SUPPORTS"></a>3. PROPAGATION_SUPPORTS</h2><p>如果外层有事务则<strong>加入</strong>该事务，如果不存在也不会创建新事务，直接使用非事务方式执行。</p>
<h2 id="4-PROPAGATION-NOT-SUPPORTED"><a href="#4-PROPAGATION-NOT-SUPPORTED" class="headerlink" title="4. PROPAGATION_NOT_SUPPORTED"></a>4. PROPAGATION_NOT_SUPPORTED</h2><p>不支持事务，如果外层存在事务则挂起外层事务 ，然后执行当前逻辑，执行完毕后，恢复外层事务。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C1</span>()</span>&#123;</span><br><span class="line">    <span class="meta">@Transactional</span>(propagation = Propagation.REQUIRED)</span><br><span class="line">    <span class="function">function <span class="title">A</span><span class="params">()</span></span>&#123;</span><br><span class="line">        C2.B();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C2</span>()</span>&#123;</span><br><span class="line">    <span class="meta">@Transactional</span>(propagation = Propagation.NOT_SUPPORTED)</span><br><span class="line">    <span class="function">function <span class="title">B</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">do</span> something;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>A、B不可操作同一条记录，因为A是事务执行，B在A尚未提交前再操作同一条记录，会产生死锁。</li>
</ul>
<h2 id="5-PROPAGATION-NEVER"><a href="#5-PROPAGATION-NEVER" class="headerlink" title="5. PROPAGATION_NEVER"></a>5. PROPAGATION_NEVER</h2><p>不支持事务，以非事务的方式执行，如果外层存在事务，则直接抛出异常。 </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">IllegalTransactionStateException( “Existing transaction found <span class="keyword">for</span> transaction marked with propagation ‘never<span class="string">'”)</span></span><br></pre></td></tr></table></figure>

<h2 id="6-PROPAGATION-MANDATORY"><a href="#6-PROPAGATION-MANDATORY" class="headerlink" title="6. PROPAGATION_MANDATORY"></a>6. PROPAGATION_MANDATORY</h2><p>强制事务执行，只能在已经存在事务的方法中被调用，如果在不存在事务的方法中被调用，直接抛出异常。 </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">IllegalTransactionStateException( “No existing transaction found <span class="keyword">for</span> transaction marked with propagation ‘mandatory<span class="string">'”);</span></span><br></pre></td></tr></table></figure>

<h2 id="7-PROPAGATION-NESTED"><a href="#7-PROPAGATION-NESTED" class="headerlink" title="7. PROPAGATION_NESTED"></a>7. PROPAGATION_NESTED</h2><p>如果外层存在事务，则<strong>嵌套</strong>在外层事务中执行。如果外层没有事务，则新建一个事务，类似于REQUIRED_NEW。<br>该传播机制特点是可以保存状态保存点，当事务回滚后会回滚到某一个保存点上，从而避免所有嵌套事务都回滚。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C1</span>()</span>&#123;</span><br><span class="line">    <span class="meta">@Transactional</span>(propagation = Propagation.REQUIRED)</span><br><span class="line">    <span class="function">function <span class="title">A</span><span class="params">()</span></span>&#123;</span><br><span class="line">        C2.B();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C2</span>()</span>&#123;</span><br><span class="line">    <span class="meta">@Transactional</span>(propagation = Propagation.NESTED)</span><br><span class="line">    <span class="function">function <span class="title">B</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">do</span> something;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>若B方法抛出异常，A方法进行捕获，B方法回滚，A方法正常执行。</p>
</li>
<li><p>若A或者B抛出异常，不做任何处理的话，A、B都要回滚。</p>
</li>
<li><p>A、B可操作同一条记录，因为处于同一个事务中。</p>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结:"></a>总结:</h2><p>只有为PROPAGATION_REQUIRED||PROPAGATION_REQUIRES_NEW||PROPAGATION_NESTED时候才可能开启一个新事务。</p>
<div class="note primary">
            <ul><li>PROPAGATION_REQUIRED – 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。</li><li>PROPAGATION_SUPPORTS – 支持当前事务，如果当前没有事务，就以非事务方式执行。</li><li>PROPAGATION_MANDATORY – 支持当前事务，如果当前没有事务，就抛出异常。</li><li>PROPAGATION_REQUIRES_NEW – 新建事务，如果当前存在事务，把当前事务挂起。</li><li>PROPAGATION_NOT_SUPPORTED – 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</li><li>PROPAGATION_NEVER – 以非事务方式执行，如果当前存在事务，则抛出异常。</li><li>PROPAGATION_NESTED – 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。</li></ul>
          </div>

<h3 id="NESTED和REQUIRED-NEW的区别"><a href="#NESTED和REQUIRED-NEW的区别" class="headerlink" title="NESTED和REQUIRED_NEW的区别:"></a><strong>NESTED和REQUIRED_NEW的区别:</strong></h3><div class="note primary">
            <ul><li><p>PROPAGATION_REQUIRES_NEW 启动一个新的, 不依赖于环境的 “内部” 事务. 这个事务将被完全 commited 或 rolled back 而不依赖于外部事务, 它拥有自己的隔离范围, 自己的锁, 等等. 当内部事务开始执行时, 外部事务将被挂起, 内务事务结束时, 外部事务将继续执行. </p></li><li><p>PROPAGATION_NESTED 开始一个 “嵌套的” 事务,  它是已经存在事务的一个真正的子事务. 潜套事务开始执行时, 它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交. </p></li></ul>
          </div>

<p>那么绘制一个表格来表现他们的差异</p>
<ol>
<li>定义serviceA.methodA()以PROPAGATION_REQUIRED修饰；</li>
<li>定义serviceB.methodB()以表格中三种方式修饰；</li>
<li>methodA中调用methodB</li>
</ol>
<table>
<thead>
<tr>
<th align="center">异常状态</th>
<th align="center">PROPAGATION_REQUIRES_NEW（两个独立事务）</th>
<th align="center">PROPAGATION_NESTED (B的事务嵌套在A的事务中)</th>
<th align="center">PROPAGATION_REQUIRED(同一个事务)</th>
</tr>
</thead>
<tbody><tr>
<td align="center">methodA抛异常 methodB正常</td>
<td align="center">A回滚，B正常提交</td>
<td align="center">A与B一起回滚</td>
<td align="center">A与B一起回滚</td>
</tr>
<tr>
<td align="center">methodA正常 methodB抛异常</td>
<td align="center">1.如果A中捕获B的异常，并没有继续向上抛异常，则B先回滚，A再正常提交；2.如果A未捕获B的异常，默认则会将B的异常向上抛，则B先回滚，A再回滚</td>
<td align="center">B先回滚，A再正常提交</td>
<td align="center">A与B一起回滚</td>
</tr>
<tr>
<td align="center">methodA抛异常 methodB抛异常</td>
<td align="center">B先回滚，A再回滚</td>
<td align="center">A与B一起回滚</td>
<td align="center">A与B一起回滚</td>
</tr>
<tr>
<td align="center">methodA正常 methodB正常</td>
<td align="center">B先提交，A再提交</td>
<td align="center">A与B一起提交</td>
<td align="center">A与B一起提交</td>
</tr>
</tbody></table>
<h1 id="二、事务隔离性"><a href="#二、事务隔离性" class="headerlink" title="二、事务隔离性"></a>二、事务隔离性</h1><h2 id="2-1-什么是事务的隔离性"><a href="#2-1-什么是事务的隔离性" class="headerlink" title="2.1 什么是事务的隔离性"></a>2.1 什么是事务的隔离性</h2><p>事务的隔离性是指多个事务并发执行的时候相互之间不受到彼此的干扰，是事务acid中i，根据隔离程度对隔离性有会分类。在具体介绍事务隔离性前有必要介绍几个名词说明数据库并发操作存在的问题。</p>
<h3 id="2-1-1-脏读"><a href="#2-1-1-脏读" class="headerlink" title="2.1.1 脏读"></a>2.1.1 脏读</h3><p>所谓脏读是指一个事务中访问到了另外一个事务未提交的数据，具体来说假如有两个事务A和B同时更新一个数据d=1，事务B先执行了select获取到d=1,然后更新d=2但是没有提交，这时候事务A在B没有提交的情况下执行搜索结果d=2，这就是脏读。</p>
<h3 id="2-1-2-不可重复读"><a href="#2-1-2-不可重复读" class="headerlink" title="2.1.2 不可重复读"></a>2.1.2 不可重复读</h3><p>所谓不可重复读是指一个事务内在未提交的前提下多次搜索一个数据，搜出来的结果不一致。发生不可重复读的原因是在多次搜索期间这个数据被其他事务更新了。</p>
<h3 id="2-1-3-幻读"><a href="#2-1-3-幻读" class="headerlink" title="2.1.3 幻读"></a>2.1.3 幻读</h3><p>所谓幻读是指同一个事务内多次查询(注意查询的sql不一定一样)返回的结果集的不一样（比如新增或者少了一条数据），比如同一个事务A内第一次查询时候有n条记录，但是第二次同等条件下查询却又n+1条记录，这就好像产生了幻觉，为啥两次结果不一样那。其实和不可重复读一样，发生幻读的原因也是另外一个事务新增或者删除或者修改了第一个事务结果集里面的数据。不同在于不可重复读是数据内容被修改了，幻读是数据变多了或者少了。</p>
<h2 id="2-2、事务隔离级别"><a href="#2-2、事务隔离级别" class="headerlink" title="2.2、事务隔离级别"></a>2.2、事务隔离级别</h2><p>为了解决事务并发带来的问题，才有了sql规范中的四个事务隔离级别，不同隔离级别对上面三个问题部分或者全部做了避免。注意：下面试验用的两个终端都是同时执行了begin为了模拟事务并发。</p>
<h3 id="2-2-1-Read-Uncommitted"><a href="#2-2-1-Read-Uncommitted" class="headerlink" title="2.2.1 Read Uncommitted"></a>2.2.1 Read Uncommitted</h3><p>读未提交隔离级别，就是指一个事务中可以读取其他事务未提交的数据，这个级别会导致脏读。 本文都是以mysql为例引擎InnoDB，mysql默认事务隔离级别为Repeatable_Read：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; show global variables like '%isolation%';</span><br><span class="line">+<span class="comment">-----------------------+-----------------+</span></span><br><span class="line">| Variable_name         | Value           |</span><br><span class="line">+<span class="comment">-----------------------+-----------------+</span></span><br><span class="line">| transaction_isolation | REPEATABLE-READ |</span><br><span class="line">+<span class="comment">-----------------------+-----------------+</span></span><br></pre></td></tr></table></figure>
<p>下面我们更改隔离级别为Read Uncommitted ：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; set global transaction_isolation='read-uncommitted';</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set session transaction_isolation='read-uncommitted';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select @@global.transaction_isolation,@@transaction_isolation;</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| @@global.transaction_isolation | @@transaction_isolation |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| READ-UNCOMMITTED               | READ-UNCOMMITTED        |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br></pre></td></tr></table></figure>

<p>试验： 下面我们打开两个mysql终端，并且关闭自动提交.<br>终端一：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; show variables like '%autocommit%';</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line">| autocommit    | ON    |</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line"></span><br><span class="line">mysql&gt; set autocommit=0;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show variables like '%autocommit%';</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line">| autocommit    | OFF   |</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line"></span><br><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into test_user values(2,'2');</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>终端二：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; set autocommit = 0;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show variables like 'autocommit';</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line">| autocommit    | OFF   |</span><br><span class="line">+<span class="comment">---------------+-------+</span></span><br><span class="line"></span><br><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>终端一我们开启了一个事务，并且插入了一条数据但是没有提交事务，但是终端二却查询出来了。</p>
<p>终端一执行rollback：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; rollback;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure>
<p>终端二查询：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>在终端1回滚后，终端二有搜不到了，所以有可能在终端一没有回滚时候终端二已经获取并使用终端一的数据，而终端一回滚后，数据已经被使用过了，所以导致了脏读。</p>
<p>总结：该隔离级别会导致 脏读，不可重复读，幻读，是最低级的隔离级别，一般不用的。</p>
<h3 id="2-2-2-Read-Committed"><a href="#2-2-2-Read-Committed" class="headerlink" title="2.2.2 Read Committed"></a>2.2.2 Read Committed</h3><p>读已提交隔离级别，一个事务只能读取到其他事务已经提交的数据，可能导致同一个事务中多次搜查结果不一样。</p>
<p>试验：修改事务隔离级别为Read Committed，</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; set global transaction_isolation='read-committed';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set session transaction_isolation='read-committed';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select @@global.transaction_isolation,@@transaction_isolation;</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| @@global.transaction_isolation | @@transaction_isolation |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| READ-COMMITTED                 | READ-COMMITTED          |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br></pre></td></tr></table></figure>
<p>终端一：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into test_user values(2,'2');</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br></pre></td></tr></table></figure>
<p>终端二：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br></pre></td></tr></table></figure>

<p>由于终端一执行后没有commit,所以终端二查询不到。</p>
<p>下面终端一执行commit:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>终端二再次执行查询：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>

<p>终端一提交后，终端二就可以搜查出来了。</p>
<p>总结：该隔离级别会导致不可重复读和幻读，避免了脏读，oracle默认是该隔离级别。实际项目使用mybaits时候虽然隔离级别是read committed,但是在一个事务中多次搜索还是会是同一个结果，这是因为mybatis一级缓存的原因</p>
<h3 id="2-2-3-Repeatable-Read"><a href="#2-2-3-Repeatable-Read" class="headerlink" title="2.2.3 Repeatable Read"></a>2.2.3 Repeatable Read</h3><p>可重复读隔离级别，一个事务内多次查询数据时候查询的数据内容和第一次查询的一致也就是说第一次查询出来的数据没有被修改，而不管其他事务有没有对这些数据新修改。但是可能其他事务新增一条数据，导致一个事务内查询的结果集里面多了一条记录。mysql默认隔离级别就是这个。<br>试验： 首先修改事务隔离级别为可重复读：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; set global transaction_isolation='repeatable-read';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set session transaction_isolation='repeatable-read';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select @@global.transaction_isolation,@@transaction_isolation;</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| @@global.transaction_isolation | @@transaction_isolation |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| REPEATABLE-READ                | REPEATABLE-READ         |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br></pre></td></tr></table></figure>

<p>模拟修改数据情况： 终端一：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; select @@global.transaction_isolation,@@transaction_isolation;</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| @@global.transaction_isolation | @@transaction_isolation |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| REPEATABLE-READ                | REPEATABLE-READ         |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line"></span><br><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">update</span> test_user <span class="keyword">set</span> <span class="keyword">name</span>=<span class="string">'3'</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">2</span>;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 3    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br></pre></td></tr></table></figure>

<p>终端二：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; select @@global.transaction_isolation,@@transaction_isolation;;</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| @@global.transaction_isolation | @@transaction_isolation |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| REPEATABLE-READ                | REPEATABLE-READ         |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">begin</span>;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br></pre></td></tr></table></figure>
<p>可以知道终端一已经提交的数据在终端二的事务中还是查不到（注意终端二执行begin要在终端一执行commit前，因为我们要模拟并发事务）。</p>
<p>下面在模拟下新增数据情况 终端一：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">2 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">insert</span> <span class="keyword">into</span> test_user <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">'3'</span>);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">|    3 | 3    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br></pre></td></tr></table></figure>

<p>终端二：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br></pre></td></tr></table></figure>

<p>终端一插入了一条记录并且提交，但是终端二还是查询不到新增的记录<br>总结：这里有点奇怪，按照其他资料显示该隔离级别应该是避免了 脏读，不可重复读，但是还存在幻读</p>
<h3 id="2-2-4-Serializable"><a href="#2-2-4-Serializable" class="headerlink" title="2.2.4 Serializable"></a>2.2.4 Serializable</h3><p>串行化隔离级别，就是多个事务串行化一个个按照顺序执行，这种不存在并发情况，所以可以避免所有事务并发问题。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; set global transaction_isolation='serializable';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set session transaction_isolation='serializable';</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select @@global.transaction_isolation,@@transaction_isolation;</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| @@global.transaction_isolation | @@transaction_isolation |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| SERIALIZABLE                   | SERIALIZABLE            |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br></pre></td></tr></table></figure>
<p>终端一：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; select @@global.transaction_isolation,@@transaction_isolation;</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| @@global.transaction_isolation | @@transaction_isolation |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line">| SERIALIZABLE                   | SERIALIZABLE            |</span><br><span class="line">+<span class="comment">--------------------------------+-------------------------+</span></span><br><span class="line"></span><br><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_user;</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">| id   | name |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">|    1 | 1    |</span><br><span class="line">|    2 | 2    |</span><br><span class="line">|    3 | 3    |</span><br><span class="line">|    4 | 4    |</span><br><span class="line">+<span class="comment">------+------+</span></span><br><span class="line">4 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>终端二：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into test_user values(5,5);</span><br></pre></td></tr></table></figure>
<p>可以看到终端一打开一个事务后，事务二的insert语句会等待直到事务一提交或者超时。<br>超时：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into test_user values(5,5);</span><br><span class="line">ERROR 1205 (HY000): <span class="keyword">Lock</span> <span class="keyword">wait</span> <span class="keyword">timeout</span> exceeded; try restarting transaction</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring注解原理的详细剖析与实现</title>
    <url>/spring/Spring%E6%B3%A8%E8%A7%A3%E5%8E%9F%E7%90%86%E7%9A%84%E8%AF%A6%E7%BB%86%E5%89%96%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="一、注解的基本概念和原理及其简单实用"><a href="#一、注解的基本概念和原理及其简单实用" class="headerlink" title="一、注解的基本概念和原理及其简单实用"></a>一、<strong>注解的基本概念和原理及其简单实用</strong></h1><p>注解（Annotation）提供了一种安全的类似注释的机制，为我们在代码中添加信息提供了一种形式化得方法，使我们可以在稍后某个时刻方便的使用这些数据（通过解析注解来使用这些数据），用来将任何的信息或者元数据与程序元素（类、方法、成员变量等）进行关联。其实就是更加直观更加明了的说明，这些说明信息与程序业务逻辑没有关系，并且是供指定的工具或框架使用的。Annotation像一种修饰符一样，应用于包、类型、构造方法、方法、成员变量、参数及本地变量的申明语句中。</p>
<p>Annotation其实是一种接口。通过[Java]的反射机制相关的API来访问Annotation信息。相关类（框架或工具中的类）根据这些信息来决定如何使用该程序元素或改变它们的行为。Java语言解释器在工作时会忽略这些Annotation，因此在JVM中这些Annotation是“不起作用”的，只能通过配套的工具才能对这些Annotation类型的信息进行访问和处理。</p>
<p>Annotation和interface的异同：</p>
<ul>
<li><p>1、 annotition的类型使用关键字@interface而不是interface。它继承了java.lang.annotition.Annotition接口，并非申明了一个interface。</p>
</li>
<li><p>2、 Annotation类型、方法定义是独特的、受限制的。Annotation类型的方法必须申明为无参数、无异常抛出的。这些方法定义了Annotation的成员：方法名称为了成员名，而方法返回值称为了成员的类型。而方法返回值必须为primitive类型、Class类型、枚举类型、Annotation类型或者由前面类型之一作为元素的一位数组。方法的后面可以使用default和一个默认数值来申明成员的默认值，null不能作为成员的默认值，这与我们在非Annotation类型中定义方法有很大不同。Annotation类型和他的方法不能使用Annotation类型的参数，成员不能是generic。只有返回值类型是Class的方法可以在Annotation类型中使用generic，因为此方法能够用类转换将各种类型转换为Class。</p>
</li>
<li><p>3、 Annotation类型又与接口有着近似之处。它们可以定义常量、静态成员类型（比如枚举类型定义）。Annotation类型也可以如接口一般被实现或者继承。</p>
</li>
</ul>
<p><strong>元注解@Target,@Retention,@Documented,@Inherited</strong> </p>
<ul>
<li><p>@Target 表示该注解用于什么地方，可能的 ElemenetType 参数包括： </p>
</li>
<li><p>ElemenetType.CONSTRUCTOR 构造器声明 </p>
</li>
<li><p>ElemenetType.FIELD 域声明（包括 enum 实例） </p>
</li>
<li><p>ElemenetType.LOCAL_VARIABLE 局部变量声明 </p>
</li>
<li><p>ElemenetType.METHOD 方法声明 </p>
</li>
<li><p>ElemenetType.PACKAGE 包声明 </p>
</li>
<li><p>ElemenetType.PARAMETER 参数声明 </p>
</li>
<li><p>ElemenetType.TYPE 类，接口（包括注解类型）或enum声明 </p>
</li>
<li><p>@Retention 表示在什么级别保存该注解信息。可选的 RetentionPolicy 参数包括： </p>
</li>
<li><p>RetentionPolicy.SOURCE 注解将被编译器丢弃 </p>
</li>
<li><p>RetentionPolicy.CLASS 注解在class文件中可用，但会被VM丢弃 </p>
</li>
<li><p>RetentionPolicy.RUNTIME VM将在运行期也保留注释，因此可以通过反射机制读取注解的信息。 </p>
</li>
<li><p>@Documented 将此注解包含在 javadoc 中 </p>
</li>
<li><p>@Inherited 允许子类继承父类中的注解</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Target</span>(ElementType.METHOD) </span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME) </span><br><span class="line"><span class="meta">@Documented</span> </span><br><span class="line"><span class="meta">@Inherited</span></span><br></pre></td></tr></table></figure>

<h2 id="二、下面的示例来简单的讲述-spring-注解原理："><a href="#二、下面的示例来简单的讲述-spring-注解原理：" class="headerlink" title="二、下面的示例来简单的讲述[spring]注解原理："></a>二、下面的示例来简单的讲述[spring]注解原理：</h2><p>本例实现了在set方法上和在字段属性上注解的处理解析。</p>
<h3 id="1、定义注解"><a href="#1、定义注解" class="headerlink" title="1、定义注解"></a>1、定义注解</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.yt.annotation;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.ElementType;  </span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.Retention;  </span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.RetentionPolicy;  </span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.Target;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>:定义注解 </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span>: ZxfResource </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Project</span>: spring-aop </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span>: zxf </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2011-6-7 </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="comment">// 在运行时执行  </span></span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)  </span><br><span class="line"><span class="comment">// 注解适用地方(字段和方法)  </span></span><br><span class="line"><span class="meta">@Target</span>(&#123; ElementType.FIELD, ElementType.METHOD &#125;)  </span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> ZxfResource &#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//注解的name属性  </span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">name</span><span class="params">()</span> <span class="keyword">default</span> ""</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2、带有注解的服务类"><a href="#2、带有注解的服务类" class="headerlink" title="2、带有注解的服务类"></a>2、带有注解的服务类</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.yt.annotation;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 带有注解的服务 </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span>: UserDaoImpl </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Project</span>: spring-aop </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span>: zxf </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2011-6-7 </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> UserDaoImpl userDao;  </span><br><span class="line">    <span class="keyword">public</span> User1DaoImpl user1Dao;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 字段上的注解,可以配置name属性  </span></span><br><span class="line">    <span class="meta">@ZxfResource</span>  </span><br><span class="line">    <span class="keyword">public</span> User2DaoImpl user2Dao;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// set方法上的注解，带有name属性  </span></span><br><span class="line">    <span class="meta">@ZxfResource</span>(name = <span class="string">"userDao"</span>)  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserDao</span><span class="params">(UserDaoImpl userDao)</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">this</span>.userDao = userDao;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// set方法上的注解，没有配置name属性  </span></span><br><span class="line">    <span class="meta">@ZxfResource</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUser1Dao</span><span class="params">(User1DaoImpl user1Dao)</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">this</span>.user1Dao = user1Dao;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        userDao.show();  </span><br><span class="line">        user1Dao.show1();  </span><br><span class="line">        user2Dao.show2();  </span><br><span class="line">        System.out.println(<span class="string">"这里是Service方法........"</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3、要注入的DAO"><a href="#3、要注入的DAO" class="headerlink" title="3、要注入的DAO"></a>3、要注入的DAO</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.yt.annotation;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 要注入的DAo类 </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span>: UserDaoImpl </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Project</span>: spring-aop </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span>: zxf </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2011-6-7 </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDaoImpl</span> </span>&#123;  </span><br><span class="line">      </span><br><span class="line">    String name ;  </span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>&#123;  </span><br><span class="line">        System.out.println(<span class="string">"这里是dao方法........"</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span> = <span class="string">"userDao"</span> <span class="attr">class</span>=<span class="string">"com.yt.annotation.UserDaoImpl"</span> /&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span> = <span class="string">"user1Dao"</span> <span class="attr">class</span>=<span class="string">"com.yt.annotation.User1DaoImpl"</span> /&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span> = <span class="string">"user2Dao"</span> <span class="attr">class</span>=<span class="string">"com.yt.annotation.User2DaoImpl"</span> /&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span> = <span class="string">"userService"</span> <span class="attr">class</span> = <span class="string">"com.yt.annotation.UserServiceImpl"</span> /&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="4、注解处理器"><a href="#4、注解处理器" class="headerlink" title="4、注解处理器"></a>4、注解处理器</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.yt.annotation;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.beans.Introspector;  </span><br><span class="line"><span class="keyword">import</span> java.beans.PropertyDescriptor;  </span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;  </span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;  </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;  </span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;  </span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;  </span><br><span class="line"><span class="keyword">import</span> java.util.List;  </span><br><span class="line"><span class="keyword">import</span> java.util.Map;  </span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;  </span><br><span class="line"><span class="keyword">import</span> org.dom4j.Document;  </span><br><span class="line"><span class="keyword">import</span> org.dom4j.DocumentException;  </span><br><span class="line"><span class="keyword">import</span> org.dom4j.Element;  </span><br><span class="line"><span class="keyword">import</span> org.dom4j.io.SAXReader;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: spring中的注解原理 </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span>: ClassPathXMLApplicationContext </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Project</span>: spring-aop </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span>: zxf </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2011-6-3 </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassPathXMLApplicationContext</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    Logger log = Logger.getLogger(ClassPathXMLApplicationContext<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">  </span><br><span class="line">    List&lt;BeanDefine&gt; beanList = <span class="keyword">new</span> ArrayList&lt;BeanDefine&gt;();  </span><br><span class="line">    Map&lt;String, Object&gt; sigletions = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ClassPathXMLApplicationContext</span><span class="params">(String fileName)</span> </span>&#123;  </span><br><span class="line">        <span class="comment">//读取配置文件中管理的bean  </span></span><br><span class="line">        <span class="keyword">this</span>.readXML(fileName);  </span><br><span class="line">        <span class="comment">//实例化bean  </span></span><br><span class="line">        <span class="keyword">this</span>.instancesBean();  </span><br><span class="line">        <span class="comment">//注解处理器  </span></span><br><span class="line">        <span class="keyword">this</span>.annotationInject();  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 读取Bean配置文件 </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readXML</span><span class="params">(String fileName)</span> </span>&#123;  </span><br><span class="line">        Document document = <span class="keyword">null</span>;  </span><br><span class="line">        SAXReader saxReader = <span class="keyword">new</span> SAXReader();  </span><br><span class="line">        <span class="keyword">try</span> &#123;  </span><br><span class="line">            ClassLoader classLoader =   </span><br><span class="line">                Thread.currentThread().getContextClassLoader();  </span><br><span class="line">            document = saxReader.read(classLoader.getResourceAsStream(fileName));  </span><br><span class="line">            Element beans = document.getRootElement();  </span><br><span class="line">            <span class="keyword">for</span> (Iterator&lt;Element&gt; beansList = beans.elementIterator();   </span><br><span class="line">                beansList.hasNext();) &#123;  </span><br><span class="line">                Element element = beansList.next();  </span><br><span class="line">                BeanDefine bean = <span class="keyword">new</span> BeanDefine(  </span><br><span class="line">                        element.attributeValue(<span class="string">"id"</span>),  </span><br><span class="line">                        element.attributeValue(<span class="string">"class"</span>));  </span><br><span class="line">                beanList.add(bean);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (DocumentException e) &#123;  </span><br><span class="line">            log.info(<span class="string">"读取配置文件出错...."</span>);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">      </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 实例化Bean </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">instancesBean</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">for</span> (BeanDefine bean : beanList) &#123;  </span><br><span class="line">            <span class="keyword">try</span> &#123;  </span><br><span class="line">                sigletions.put(bean.getId(),   </span><br><span class="line">                        Class.forName(bean.getClassName()).newInstance());  </span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;  </span><br><span class="line">                log.info(<span class="string">"实例化Bean出错..."</span>);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">      </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 注解处理器 </span></span><br><span class="line"><span class="comment">     * 如果注解ZxfResource配置了name属性，则根据name所指定的名称获取要注入的实例引用， </span></span><br><span class="line"><span class="comment">     * 如果注解ZxfResource;没有配置name属性，则根据属性所属类型来扫描配置文件获取要 </span></span><br><span class="line"><span class="comment">     * 注入的实例引用 </span></span><br><span class="line"><span class="comment">     *  </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">annotationInject</span><span class="params">()</span></span>&#123;  </span><br><span class="line">        <span class="keyword">for</span>(String beanName:sigletions.keySet())&#123;  </span><br><span class="line">            Object bean = sigletions.get(beanName);  </span><br><span class="line">            <span class="keyword">if</span>(bean!=<span class="keyword">null</span>)&#123;  </span><br><span class="line">                <span class="keyword">this</span>.propertyAnnotation(bean);  </span><br><span class="line">                <span class="keyword">this</span>.fieldAnnotation(bean);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">      </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 处理在set方法加入的注解 </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> bean 处理的bean </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">propertyAnnotation</span><span class="params">(Object bean)</span></span>&#123;  </span><br><span class="line">        <span class="keyword">try</span> &#123;  </span><br><span class="line">            <span class="comment">//获取其属性的描述  </span></span><br><span class="line">            PropertyDescriptor[] ps =   </span><br><span class="line">                Introspector.getBeanInfo(bean.getClass()).getPropertyDescriptors();  </span><br><span class="line">            <span class="keyword">for</span>(PropertyDescriptor proderdesc : ps)&#123;  </span><br><span class="line">                <span class="comment">//获取所有set方法  </span></span><br><span class="line">                Method setter = proderdesc.getWriteMethod();  </span><br><span class="line">                <span class="comment">//判断set方法是否定义了注解  </span></span><br><span class="line">                <span class="keyword">if</span>(setter!=<span class="keyword">null</span> &amp;&amp; setter.isAnnotationPresent(ZxfResource<span class="class">.<span class="keyword">class</span>))</span>&#123;  </span><br><span class="line">                    <span class="comment">//获取当前注解，并判断name属性是否为空  </span></span><br><span class="line">                    ZxfResource resource = setter.getAnnotation(ZxfResource<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">                    String name =<span class="string">""</span>;  </span><br><span class="line">                    Object value = <span class="keyword">null</span>;  </span><br><span class="line">                    <span class="keyword">if</span>(resource.name()!=<span class="keyword">null</span>&amp;&amp;!<span class="string">""</span>.equals(resource.name()))&#123;  </span><br><span class="line">                        <span class="comment">//获取注解的name属性的内容  </span></span><br><span class="line">                        name = resource.name();  </span><br><span class="line">                        value = sigletions.get(name);  </span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123; <span class="comment">//如果当前注解没有指定name属性,则根据类型进行匹配  </span></span><br><span class="line">                        <span class="keyword">for</span>(String key : sigletions.keySet())&#123;  </span><br><span class="line">                            <span class="comment">//判断当前属性所属的类型是否在配置文件中存在  </span></span><br><span class="line">                            <span class="keyword">if</span>(proderdesc.getPropertyType().isAssignableFrom(sigletions.get(key).getClass()))&#123;  </span><br><span class="line">                                <span class="comment">//获取类型匹配的实例对象  </span></span><br><span class="line">                                value = sigletions.get(key);  </span><br><span class="line">                                <span class="keyword">break</span>;  </span><br><span class="line">                            &#125;  </span><br><span class="line">                        &#125;  </span><br><span class="line">                    &#125;  </span><br><span class="line">                    <span class="comment">//允许访问private方法  </span></span><br><span class="line">                    setter.setAccessible(<span class="keyword">true</span>);  </span><br><span class="line">                    <span class="comment">//把引用对象注入属性  </span></span><br><span class="line">                    setter.invoke(bean, value);   </span><br><span class="line">                &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;  </span><br><span class="line">            log.info(<span class="string">"set方法注解解析异常.........."</span>);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">      </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 处理在字段上的注解 </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> bean 处理的bean </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fieldAnnotation</span><span class="params">(Object bean)</span></span>&#123;  </span><br><span class="line">        <span class="keyword">try</span> &#123;  </span><br><span class="line">            <span class="comment">//获取其全部的字段描述  </span></span><br><span class="line">            Field[] fields = bean.getClass().getFields();  </span><br><span class="line">            <span class="keyword">for</span>(Field f : fields)&#123;  </span><br><span class="line">                <span class="keyword">if</span>(f!=<span class="keyword">null</span> &amp;&amp; f.isAnnotationPresent(ZxfResource<span class="class">.<span class="keyword">class</span>))</span>&#123;  </span><br><span class="line">                    ZxfResource resource = f.getAnnotation(ZxfResource<span class="class">.<span class="keyword">class</span>)</span>;  </span><br><span class="line">                    String name =<span class="string">""</span>;  </span><br><span class="line">                    Object value = <span class="keyword">null</span>;  </span><br><span class="line">                    <span class="keyword">if</span>(resource.name()!=<span class="keyword">null</span>&amp;&amp;!<span class="string">""</span>.equals(resource.name()))&#123;  </span><br><span class="line">                        name = resource.name();  </span><br><span class="line">                        value = sigletions.get(name);  </span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123;  </span><br><span class="line">                        <span class="keyword">for</span>(String key : sigletions.keySet())&#123;  </span><br><span class="line">                            <span class="comment">//判断当前属性所属的类型是否在配置文件中存在  </span></span><br><span class="line">                            <span class="keyword">if</span>(f.getType().isAssignableFrom(sigletions.get(key).getClass()))&#123;  </span><br><span class="line">                                <span class="comment">//获取类型匹配的实例对象  </span></span><br><span class="line">                                value = sigletions.get(key);  </span><br><span class="line">                                <span class="keyword">break</span>;  </span><br><span class="line">                            &#125;  </span><br><span class="line">                        &#125;  </span><br><span class="line">                    &#125;  </span><br><span class="line">                    <span class="comment">//允许访问private字段  </span></span><br><span class="line">                    f.setAccessible(<span class="keyword">true</span>);  </span><br><span class="line">                    <span class="comment">//把引用对象注入属性  </span></span><br><span class="line">                    f.set(bean, value);  </span><br><span class="line">                &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;  </span><br><span class="line">            log.info(<span class="string">"字段注解解析异常.........."</span>);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">      </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 获取Map中的对应的bean实例 </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> beanId </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">getBean</span><span class="params">(String beanId)</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">return</span> sigletions.get(beanId);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </span><br><span class="line">        ClassPathXMLApplicationContext path = <span class="keyword">new</span> ClassPathXMLApplicationContext(  </span><br><span class="line">                <span class="string">"configAnnotation.xml"</span>);  </span><br><span class="line">        UserServiceImpl userService =(UserServiceImpl)path.getBean(<span class="string">"userService"</span>);  </span><br><span class="line">        userService.show();  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring aop面向切面原理，用处和实力讲解</title>
    <url>/spring/spring-aop%E9%9D%A2%E5%90%91%E5%88%87%E9%9D%A2%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>先实例对比说说什么面向切面，看下面代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">savePerson</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//现在我想把每个保存数据库的语句前后都打印一句话，如下：</span></span><br><span class="line">    System.out.println(<span class="string">"开始保存到数据库....."</span>);</span><br><span class="line">    save(person);     <span class="comment">//请把这句看做是保存数据库的语句</span></span><br><span class="line">    System.out.println(<span class="string">"...保存成功"</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面打印的语句，其实就相当于日志，监控我有没有保存成功，这里我保存的是person对象，如果我还有student，teacher，dog等等很多对象都需要做增删改查操作，是不是在每个增删改查的语句前后都加上这两句话呢？这样不是很繁琐。那么有没有办法让每有执行save操作时就自动前后打印日志呢？这里就应运而生了面向切面AOP</p>
<p>下面再看看面向切面的例子吧！</p>
<p>maven工程加jar包依赖：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- spring aop --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.aspectj<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>aspectjweaver<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.6.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>applicationContext.xml配置：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:context</span>=<span class="string">"http://www.springframework.org/schema/context"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:tx</span>=<span class="string">"http://www.springframework.org/schema/tx"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:aop</span>=<span class="string">"http://www.springframework.org/schema/aop"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">        http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">        http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd </span></span></span><br><span class="line"><span class="tag"><span class="string">        http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd"</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment">&lt;!-- 配置扫描的包 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">"redisCache.service"</span>/&gt;</span></span><br><span class="line">   <span class="comment">&lt;!-- 切面的声明 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"transaction"</span> <span class="attr">class</span>=<span class="string">"aop.Transaction"</span>/&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--aop配置  --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:config</span>&gt;</span></span><br><span class="line">    	 <span class="comment">&lt;!-- 切点， 配置aop的切入点id; 是切入点的标识 ;expression 为切入点的表达式 --&gt;</span></span><br><span class="line">    	 <span class="tag">&lt;<span class="name">aop:pointcut</span> <span class="attr">expression</span>=<span class="string">"execution(* redisCache.service.impl.PersonDaoImpl.*(..))"</span> <span class="attr">id</span>=<span class="string">"perform"</span>/&gt;</span></span><br><span class="line">    	 <span class="comment">&lt;!-- 切面，配置切面(切面里面配置通知)—— ref 指向声明切面的类 --&gt;</span></span><br><span class="line">    	 <span class="tag">&lt;<span class="name">aop:aspect</span> <span class="attr">ref</span>=<span class="string">"transaction"</span>&gt;</span></span><br><span class="line">    	 <span class="comment">&lt;!-- 	前置通知pointcut-ref 引用一个切入点 --&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">aop:before</span> <span class="attr">method</span>=<span class="string">"beginTransaction"</span> <span class="attr">pointcut-ref</span>=<span class="string">"perform"</span>/&gt;</span></span><br><span class="line">         <span class="comment">&lt;!-- 后置通知   </span></span><br><span class="line"><span class="comment">         &lt;aop:after-returning method="commit" pointcut-ref="perform" returning="val"/&gt; --&gt;</span></span><br><span class="line">         </span><br><span class="line">    	 <span class="tag">&lt;/<span class="name">aop:aspect</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">aop:config</span>&gt;</span></span><br><span class="line">  </span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>切面工具类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> aop;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.JoinPoint;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.ProceedingJoinPoint;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> redisCache.entity.Person;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 切面(spring aop 就不需要拦截器啦)</span></span><br><span class="line"><span class="comment"> * (模拟hibernate里面保存数据要打开事物，然后各种增删改之后，再提交事物。)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Transaction</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">beginTransaction</span><span class="params">()</span> </span>&#123;<span class="comment">//前置通知</span></span><br><span class="line">        <span class="comment">//打开事物</span></span><br><span class="line">        System.out.println(<span class="string">"begin Transaction"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> joinPoint 通过joinPoint可以得到目标类和目标方法的一些信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> val       目标方法的返回值</span></span><br><span class="line"><span class="comment">     *                  和&lt;aop:after-returning returning="val"/&gt;中returning的值保质一致</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">(JoinPoint joinPoint, Object val)</span> </span>&#123;<span class="comment">//后置通知</span></span><br><span class="line">        String methodName = joinPoint.getSignature().getName();</span><br><span class="line">        System.out.println(methodName);</span><br><span class="line">        System.out.println(joinPoint.getTarget().getClass().getName());</span><br><span class="line">        <span class="comment">//提交事物</span></span><br><span class="line">        System.out.println(<span class="string">"commit"</span>);</span><br><span class="line">        List&lt;Person&gt; personList = (ArrayList&lt;Person&gt;) val;</span><br><span class="line">        <span class="keyword">for</span> (Person person : personList) &#123;</span><br><span class="line">            System.out.println(person.getPname());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">finalMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"最终通知"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">aroundMethod</span><span class="params">(ProceedingJoinPoint joinPoint)</span> </span>&#123;<span class="comment">//环绕通知</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"around method"</span>);</span><br><span class="line">            joinPoint.proceed();<span class="comment">//调用目标类的目标方法</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">            <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 异常通知</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">throwingMethod</span><span class="params">(Throwable except)</span> </span>&#123;</span><br><span class="line">        System.out.println(except.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>person实体类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> redisCache.entity;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">	 <span class="keyword">private</span> Long pid;</span><br><span class="line">	    <span class="keyword">private</span> String pname;</span><br><span class="line"> </span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Long <span class="title">getPid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	        <span class="keyword">return</span> pid;</span><br><span class="line">	    &#125;</span><br><span class="line"> </span><br><span class="line">	    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPid</span><span class="params">(Long pid)</span> </span>&#123;</span><br><span class="line">	        <span class="keyword">this</span>.pid = pid;</span><br><span class="line">	    &#125;</span><br><span class="line"> </span><br><span class="line">	    <span class="function"><span class="keyword">public</span> String <span class="title">getPname</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	        <span class="keyword">return</span> pname;</span><br><span class="line">	    &#125;</span><br><span class="line"> </span><br><span class="line">	    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPname</span><span class="params">(String pname)</span> </span>&#123;</span><br><span class="line">	        <span class="keyword">this</span>.pname = pname;</span><br><span class="line">	    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>personDao接口类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> redisCache.service;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> redisCache.entity.Person;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 目标对象和代理对象都实现的接口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">PersonDao</span> </span>&#123;</span><br><span class="line">	 	<span class="function"><span class="keyword">void</span> <span class="title">deletePerson</span><span class="params">()</span></span>;</span><br><span class="line">	    <span class="function">List&lt;Person&gt; <span class="title">getPerson</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">	    <span class="function"><span class="keyword">void</span> <span class="title">savePerson</span><span class="params">()</span></span>;</span><br><span class="line">	    <span class="function"><span class="keyword">void</span> <span class="title">updatePerson</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>personDaoImpl接口实现类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> redisCache.service.impl;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> redisCache.entity.Person;</span><br><span class="line"><span class="keyword">import</span> redisCache.service.PersonDao;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 目标对象:实现目标接口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Service</span>(<span class="string">"personDao"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonDaoImpl</span> <span class="keyword">implements</span> <span class="title">PersonDao</span></span>&#123;</span><br><span class="line">	 <span class="meta">@Override</span></span><br><span class="line">	    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deletePerson</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	        System.out.println(<span class="string">"delete perosn"</span>);</span><br><span class="line">	    &#125;</span><br><span class="line"> </span><br><span class="line">	    <span class="meta">@Override</span></span><br><span class="line">	    <span class="function"><span class="keyword">public</span> List&lt;Person&gt; <span class="title">getPerson</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	        List&lt;Person&gt; personList = <span class="keyword">new</span> ArrayList&lt;Person&gt;();</span><br><span class="line">	        Person person1 = <span class="keyword">new</span> Person();</span><br><span class="line">	        person1.setPid(<span class="number">1L</span>);</span><br><span class="line">	        person1.setPname(<span class="string">"person1"</span>);</span><br><span class="line">	        System.out.println(<span class="string">"get person"</span>);</span><br><span class="line">	        personList.add(person1);</span><br><span class="line">	        Person person2 = <span class="keyword">new</span> Person();</span><br><span class="line">	        person2.setPid(<span class="number">2L</span>);</span><br><span class="line">	        person2.setPname(<span class="string">"person2"</span>);</span><br><span class="line">	        personList.add(person2);</span><br><span class="line">	        <span class="keyword">return</span> personList;</span><br><span class="line">	    &#125;</span><br><span class="line"> </span><br><span class="line">	    <span class="meta">@Override</span></span><br><span class="line">	    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">savePerson</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	        System.out.println(<span class="string">"delete perosn"</span>);</span><br><span class="line">	    &#125;</span><br><span class="line"> </span><br><span class="line">	    <span class="meta">@Override</span></span><br><span class="line">	    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updatePerson</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	        System.out.println(<span class="string">"delete perosn"</span>);</span><br><span class="line">	    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>TestAop测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> redisCache;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ApplicationContext;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.ClassPathXmlApplicationContext;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> redisCache.service.PersonDao;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestAop</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		ApplicationContext context = <span class="keyword">new</span> ClassPathXmlApplicationContext(<span class="string">"applicationContext.xml"</span>);</span><br><span class="line">    	PersonDao personDao=(PersonDao) context.getBean(<span class="string">"personDao"</span>);</span><br><span class="line">    	<span class="keyword">try</span> &#123;</span><br><span class="line">			personDao.getPerson();</span><br><span class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">			<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>允许测试类的结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log4j:WARN No appenders could be found for logger (org.springframework.core.env.StandardEnvironment).</span><br><span class="line">log4j:WARN Please initialize the log4j system properly.</span><br><span class="line">log4j:WARN See http:&#x2F;&#x2F;logging.apache.org&#x2F;log4j&#x2F;1.2&#x2F;faq.html#noconfig for more info.</span><br><span class="line">begin Transaction</span><br><span class="line">get person</span><br><span class="line">begin Transaction</span><br><span class="line">delete perosn</span><br></pre></td></tr></table></figure>
<p>从打印结果中可以看出personDaoImpl实现类的所有方法只要执行就会先打印“begin Transcation” .</p>
<p>上面我们在执行方法前打印的方式称为前置通知，当然在面向切面的术语中还有其他诸如：后置通知，环绕通知，最终通知，异常通知。这里我们都在配置文件中加上，如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">aop:config</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 切点， 配置aop的切入点id; 是切入点的标识 ;expression 为切入点的表达式 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:pointcut</span> <span class="attr">expression</span>=<span class="string">"execution(* redisCache.service.impl.PersonDaoImpl.*(..))"</span> <span class="attr">id</span>=<span class="string">"perform"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 切面，配置切面(切面里面配置通知)—— ref 指向声明切面的类 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:aspect</span> <span class="attr">ref</span>=<span class="string">"transaction"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 	前置通知pointcut-ref 引用一个切入点 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:before</span> <span class="attr">method</span>=<span class="string">"beginTransaction"</span> <span class="attr">pointcut-ref</span>=<span class="string">"perform"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 后置通知   </span></span><br><span class="line"><span class="comment">    &lt;aop:after-returning method="commit" pointcut-ref="perform" returning="val"/&gt; --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">            最终通知</span></span><br><span class="line"><span class="comment">            *   不能得到目标方法的返回值</span></span><br><span class="line"><span class="comment">            *   无论目标方法是否有异常，最终通知都将执行</span></span><br><span class="line"><span class="comment">            *   资源的关闭、连接的释放写在最终通知里</span></span><br><span class="line"><span class="comment">        --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;aop:after pointcut-ref="perform" method="finalMethod"/&gt;--&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">                环绕通知</span></span><br><span class="line"><span class="comment">                *  ProceedingJoinPoint的proceed方法就是目标对象的目标方法</span></span><br><span class="line"><span class="comment">                *  环绕通知可以控制目标对象目标方法执行</span></span><br><span class="line"><span class="comment">        --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">    &lt;aop:around method="aroundMethod" pointcut-ref="perform"/&gt;</span></span><br><span class="line"><span class="comment">        --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">                异常通知</span></span><br><span class="line"><span class="comment">                *  在异常通知中获取目标方法抛出的异常</span></span><br><span class="line"><span class="comment">        --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;aop:after-throwing method="throwingMethod" pointcut-ref="perform" throwing="except"/&gt;--&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">aop:aspect</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">aop:config</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>总结一句话就是：AOP 在不修改源代码的情况下给程序动态统一添加功能。  这样就能够在一个项目及时要在中途需要这么一个功能，那也就只需修改配置文件和加一个类，而没有该已经写好的类的代码。aop明显增加了代码的复用性，也省去了重新测试的时间。</p>
<p>通过实例大概了解aop的用途和优势后我们再结合上面的实例理解aop的原理和各种术语。</p>
<p>先上图：</p>
<img alt="" class="has" data-src="https://img-blog.csdn.net/20161126151759472" />

<p>上面的三条红色的竖向框就是经常说的切面，在这个切面里面有很多的方法，你大可以吧a()看做上面的说道的前置通知，b（）看做后置通知，c()看做最终通知等等。总而言之，这些方法都不需要我们去写的，而是aop自动帮我们做好的。我们只要触动了我们的比如“保存方法”就会执行切面里的一系列方法。这样就省去了很多开发时间，也精简了代码。</p>
<p>因为这个AOP–面向切面编程是基于动态代理模式的，所以，要想搞清楚这个AOP，就必须得先了解下，<strong>什么是代理模式</strong>，<strong>什么又是动态代理模式</strong>。<strong>动态代理模式的2种实现方式。</strong></p>
<p><strong>在小编的这篇博文中有简单解释代理：</strong><a href="https://blog.csdn.net/csdnliuxin123524/article/details/81236007" target="_blank" rel="noopener">https://blog.csdn.net/csdnliuxin123524/article/details/81236007</a></p>
<p>下面重新写一下动态代理的实例步骤，代码转自一位很强的博主的博文：<a href="https://blog.csdn.net/qq_27093465/article/details/53351403" target="_blank" rel="noopener">https://blog.csdn.net/qq_27093465/article/details/53351403</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> proxy1;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.springframework.cglib.proxy.Enhancer;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cglib.proxy.MethodInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cglib.proxy.MethodProxy;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyInterceptor</span> <span class="keyword">implements</span> <span class="title">MethodInterceptor</span></span>&#123;</span><br><span class="line">	<span class="keyword">private</span> Object target;<span class="comment">//通用目标类</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">//有参构造器</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">MyInterceptor</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.target=o;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Object <span class="title">intercept</span><span class="params">(Object o, Method method, Object[] objects, MethodProxy methodProxy)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">		<span class="keyword">if</span>(method.getName().equals(<span class="string">"getPerson"</span>))&#123;<span class="comment">//切入点，因为传入的object类中的方法不是都需要做打印通知的，所以只有满足我们条件的方法才行，这里我以方法名做判断。</span></span><br><span class="line">            System.out.println(<span class="string">"aaaaa"</span>);<span class="comment">//切面方法a();</span></span><br><span class="line">            <span class="comment">//。。。</span></span><br><span class="line">            method.invoke(<span class="keyword">this</span>.target, objects);<span class="comment">//调用目标类的目标方法</span></span><br><span class="line">            <span class="comment">//。。。</span></span><br><span class="line">            System.out.println(<span class="string">"bbbbb"</span>);<span class="comment">//切面方法f();</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 返回代理对象</span></span><br><span class="line"><span class="comment">     * 具体实现，暂时先不追究。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">createProxy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Enhancer enhancer = <span class="keyword">new</span> Enhancer();</span><br><span class="line">        enhancer.setCallback(<span class="keyword">this</span>);<span class="comment">//回调函数  拦截器</span></span><br><span class="line">        <span class="comment">//设置代理对象的父类,可以看到代理对象是目标对象的子类。所以这个接口类就可以省略了。</span></span><br><span class="line">        enhancer.setSuperclass(<span class="keyword">this</span>.target.getClass());</span><br><span class="line">        <span class="keyword">return</span> enhancer.create();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类 </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> redisCache;</span><br><span class="line"><span class="keyword">import</span> redisCache.service.impl.PersonDaoImpl;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestAop2</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		PersonDaoImpl personDaoImpl=<span class="keyword">new</span>  PersonDaoImpl();</span><br><span class="line">		MyInterceptor myInterceptor=<span class="keyword">new</span> MyInterceptor(personDaoImpl);</span><br><span class="line">		PersonDaoImpl personDaoImpl2=(PersonDaoImpl) myInterceptor.createProxy();</span><br><span class="line">		personDaoImpl2.getPerson();</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">aaaaa</span><br><span class="line">get person</span><br><span class="line">bbbbb</span><br></pre></td></tr></table></figure>
<p>上面代码，看完之后，就来<strong>对应AOP里面的各个概念到实际代码里面去</strong>。</p>
<img alt="" class="has" height="234" data-src="https://img-blog.csdn.net/20180727162335751?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NzZG5saXV4aW4xMjM1MjQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="718" />

<img alt="" class="has" height="312" data-src="https://img-blog.csdn.net/20180727162655235?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NzZG5saXV4aW4xMjM1MjQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="847" />

<img alt="" class="has" height="103" data-src="https://img-blog.csdn.net/20180727162844384?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NzZG5saXV4aW4xMjM1MjQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="831" />

<p>图上说了5个术语。加上下面的<strong>织入</strong>，也就是6个啦。</p>
<p>再加上<strong>代理对象</strong>，这个就比较简单了，测试代码有写注释啦。那么就是一共7个啦。</p>
<p>唯一漏掉的就是<strong>“引入”</strong>，这个是系统自己实现的，我们就没必要去深究了。</p>
<p>注意理解以下几个概念：</p>
<ul>
<li>代理对象的方法 = 目标对象的目标方法 + 所有切面的通知。</li>
<li>织入：形成代理对象的方法的过程</li>
<li>通知：实际上就是切面中的方法。</li>
<li><strong>切入点</strong>的理解：只有符合切入点的目标方法，才能加载通知。也就是调用切面的通知（方法）啦，看代码也就是说，切入点是控制代理对象内部的切面方法和目标对象的目标方法是否执行的条件。切面可以不止是一个。每个切面里面的通知即切面方法也是可以有很多的。</li>
<li><strong>连接点</strong>的理解：所谓连接点，也就是目标对象或者代理对象之中的方法。为什么说2个都 可以呢？因为如果是jdk实现的动态代理的话，那么目标对象和代理对象要实现共同的接口，如果是cglib实现的动态代理的话，那么代理对象类是目标对象类的子类。都是一个方法啦。所以这么理解就OK的啦。</li>
</ul>
<p>上面的过程就可以理解为@Transcational注解所起的作用，因为spring事务的管理使用的就是aop动态代理的功能。</p>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring汇总</title>
    <url>/spring/spring-summary/</url>
    <content><![CDATA[<p>Spring的IOC原理[通俗解释一下]<br><a href="https://www.cnblogs.com/superjt/p/4311577.html" target="_blank" rel="noopener">https://www.cnblogs.com/superjt/p/4311577.html</a></p>
<p>Spring aop的实现原理<br><a href="https://www.cnblogs.com/liantdev/p/10132680.html" target="_blank" rel="noopener">https://www.cnblogs.com/liantdev/p/10132680.html</a></p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><ul>
<li><p><a href="https://github.com/spring-projects/spring-framework" target="_blank" rel="noopener">源码</a></p>
</li>
<li><p><a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/html/scheduling.html" target="_blank" rel="noopener">定时任务（复杂的场景还是要借助Quartz框架）</a> </p>
<a id="more"></a>

</li>
</ul>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>一个应用非常广泛的java开源框架。主要分为两大块：IOC和AOP。</p>
<p><code>无论是技术类书籍或者网上资料、学习手册，非常多，此处就不详细列举</code></p>
<h1 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h1><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><ul>
<li><a href="http://www.codeceo.com/article/spring-transactions.html" target="_blank" rel="noopener">深入理解 Spring 事务原理</a></li>
<li><a href="https://mp.weixin.qq.com/s/u4NLJ3I2vkeZHWBpgHsdEA" target="_blank" rel="noopener">Spring事务传播性与隔离性</a></li>
</ul>
<h2 id="annotation-重试配置"><a href="#annotation-重试配置" class="headerlink" title="annotation 重试配置"></a>annotation 重试配置</h2><ul>
<li><a href="http://blog.csdn.net/jiesa/article/details/76549381" target="_blank" rel="noopener">Spring重试支持Spring Retry</a></li>
<li><a href="https://stackoverflow.com/questions/38212471/springboot-retryable-not-retrying" target="_blank" rel="noopener">https://stackoverflow.com/questions/38212471/springboot-retryable-not-retrying</a></li>
</ul>
<h2 id="框架配置"><a href="#框架配置" class="headerlink" title="框架配置"></a>框架配置</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/8-XvEOA4WzrZwytOXpHHyw" target="_blank" rel="noopener">Spring、Spring MVC、MyBatis 整合文件配置详解</a></li>
</ul>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><ul>
<li><a href="https://jingyan.baidu.com/article/11c17a2c353e20f446e39d38.html" target="_blank" rel="noopener">利用StopWatch监控Java代码运行时间和分析性能</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot 使用 druid-spring-boot-starter 整合druid</title>
    <url>/springboot/druid-spring-boot-starter/</url>
    <content><![CDATA[<h1 id="pom文件"><a href="#pom文件" class="headerlink" title="pom文件"></a>pom文件</h1><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="yml文件"><a href="#yml文件" class="headerlink" title="yml文件"></a>yml文件</h1><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="comment"># 配置数据库信息</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">druid:</span></span><br><span class="line">      <span class="comment"># 数据源配置</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">      <span class="attr">password:</span> <span class="number">123456</span></span><br><span class="line">      <span class="attr">url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/springboot?serverTimezone=GMT%2B8&amp;characterEncoding=UTF-8&amp;useSSL=false</span>  <span class="comment"># 设置时区</span></span><br><span class="line">      <span class="attr">driver-class-name:</span> <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">      <span class="comment"># 初始化 最小 最大</span></span><br><span class="line">      <span class="attr">initial-size:</span> <span class="number">5</span></span><br><span class="line">      <span class="attr">min-idle:</span> <span class="number">5</span></span><br><span class="line">      <span class="attr">max-active:</span> <span class="number">20</span></span><br><span class="line">      <span class="comment"># 配置获取连接等待超时的时间</span></span><br><span class="line">      <span class="attr">max-wait:</span> <span class="number">120000</span></span><br><span class="line">      <span class="comment"># 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒</span></span><br><span class="line">      <span class="attr">time-between-eviction-runs-millis:</span> <span class="number">60000</span></span><br><span class="line">      <span class="comment"># 配置一个连接在池中最小生存的时间，单位是毫秒</span></span><br><span class="line">      <span class="attr">min-evictable-idle-time-millis:</span> <span class="number">300000</span></span><br><span class="line">      <span class="attr">validation-query:</span> <span class="string">SELECT</span> <span class="string">'x'</span></span><br><span class="line">      <span class="attr">test-while-idle:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">test-on-borrow:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">test-on-return:</span> <span class="literal">false</span></span><br><span class="line">      <span class="comment"># 打开PSCache，并且指定每个连接上PSCache的大小</span></span><br><span class="line">      <span class="attr">poolPreparedStatements:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">maxPoolPreparedStatementPerConnectionSize:</span> <span class="number">20</span></span><br><span class="line">      <span class="comment"># 配置多个英文逗号分隔</span></span><br><span class="line">      <span class="comment"># filters: stat,wall</span></span><br><span class="line">      <span class="attr">filter:</span></span><br><span class="line">        <span class="attr">stat:</span></span><br><span class="line">          <span class="attr">log-slow-sql:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">slow-sql-millis:</span> <span class="number">2000</span></span><br><span class="line">          <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">wall:</span></span><br><span class="line">          <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="comment"># WebStatFilter配置，说明请参考Druid Wiki，配置_配置WebStatFilter</span></span><br><span class="line">      <span class="comment"># 是否启用StatFilter默认值true</span></span><br><span class="line">      <span class="attr">web-stat-filter:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">url-pattern:</span> <span class="string">/*</span></span><br><span class="line">        <span class="attr">exclusions:</span> <span class="string">"*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*"</span></span><br><span class="line">        <span class="attr">session-stat-enable:</span> <span class="literal">false</span></span><br><span class="line">        <span class="attr">session-stat-max-count:</span> <span class="number">1000</span></span><br><span class="line">        <span class="attr">principal-cookie-name:</span> <span class="string">admin</span></span><br><span class="line">        <span class="attr">principal-session-name:</span> <span class="string">admin</span></span><br><span class="line">        <span class="attr">profile-enable:</span> <span class="literal">true</span></span><br><span class="line">      <span class="comment"># 根据配置中的url-pattern来访问内置监控页面，如果是上面的配置，内置监控页面的首页是/druid/index.html</span></span><br><span class="line">      <span class="comment"># http://loacalhsot:8081/druid</span></span><br><span class="line">      <span class="attr">stat-view-servlet:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">true</span> <span class="comment">#设置为true，默认为false,看不到监控页面</span></span><br><span class="line">        <span class="attr">url-pattern:</span> <span class="string">/druid/*</span>  <span class="comment"># 监控页面访问路径</span></span><br><span class="line">        <span class="comment"># 允许清空统计数据</span></span><br><span class="line">        <span class="attr">reset-enable:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">login-username:</span> <span class="string">admin</span></span><br><span class="line">        <span class="attr">login-password:</span> <span class="number">123456</span></span><br><span class="line">        <span class="comment"># StatViewSerlvet展示出来的监控信息比较敏感，是系统运行的内部情况，如果你需要做访问控制，可以配置allow和deny这两个参数</span></span><br><span class="line">        <span class="comment"># deny优先于allow，如果在deny列表中，就算在allow列表中，也会被拒绝。如果allow没有配置或者为空，则允许所有访问</span></span><br><span class="line">        <span class="comment"># 配置的格式</span></span><br><span class="line">          <span class="comment"># &lt;IP&gt;,&lt;IP&gt;</span></span><br><span class="line">          <span class="comment"># 或者&lt;IP&gt;/&lt;SUB_NET_MASK_size&gt;其中128.242.127.1/24</span></span><br><span class="line">          <span class="comment"># 24表示，前面24位是子网掩码，比对的时候，前面24位相同就匹配,不支持IPV6。</span></span><br><span class="line">        <span class="attr">allow:</span></span><br><span class="line">        <span class="attr">deny:</span></span><br></pre></td></tr></table></figure>
<p>编写以上配置后，监控页面一直报：（*）property for user to setup，后面才发现，数据源根本没有注入成功</p>
<p>在yml中添加以下代码，即可解决</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="comment"># 配置数据库信息</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">com.alibaba.druid.pool.DruidDataSource</span>   <span class="comment"># 指定数据源为druid</span></span><br></pre></td></tr></table></figure>

<p>参考:<br><a href="https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter" target="_blank" rel="noopener">https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter</a></p>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>Springboot 热部署</title>
    <url>/springboot/hot-reload/</url>
    <content><![CDATA[<p>右键—》Run As—》Run Configurations—》在Arguments的tab里面设置VM参数如下</p>
<a id="more"></a>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">-javaagent:/Users/onlyone/M2/org/springframework/springloaded/<span class="number">1.2</span><span class="number">.6</span>.RELEASE/springloaded-<span class="number">1.2</span><span class="number">.6</span>.RELEASE.jar  -noverify</span><br></pre></td></tr></table></figure>



<p>** 即可支持在编码过程中代码热部署！！！ **</p>
<p>** 另外支持 debug 模式！！！ Dubug As –》Java Application  **</p>
<p>其它方式可参考：</p>
<p><a href="http://blog.csdn.net/l1028386804/article/details/69940574" target="_blank" rel="noopener">http://blog.csdn.net/l1028386804/article/details/69940574</a></p>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot javaConfig</title>
    <url>/springboot/javaconfig/</url>
    <content><![CDATA[<h2 id="SpringBootApplication"><a href="#SpringBootApplication" class="headerlink" title="@SpringBootApplication"></a>@SpringBootApplication</h2><a id="more"></a>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Target</span>(ElementType.TYPE)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Inherited</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableAutoConfiguration</span></span><br><span class="line"><span class="meta">@ComponentScan</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> SpringBootApplication &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Exclude specific auto-configuration classes such that they will never be applied.</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span> the classes to exclude</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	Class&lt;?&gt;[] exclude() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义在main方法入口类处，用于启动sping boot应用项目</p>
<ul>
<li>@EnableAutoConfiguration</li>
</ul>
<p>让spring boot根据类路径中的jar包依赖当前项目进行自动配置</p>
<p>在src/main/resources的META-INF/spring.factories</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\</span><br><span class="line">org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\</span><br><span class="line">org.springframework.boot.autoconfigure.aop.AopAutoConfiguration</span><br><span class="line"></span><br><span class="line">若有多个自动配置，用“，”隔开</span><br></pre></td></tr></table></figure>

<h2 id="ImportResource"><a href="#ImportResource" class="headerlink" title="@ImportResource"></a>@ImportResource</h2><p>加载xml配置，一般是放在启动main类上</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ImportResource</span>(<span class="string">"classpath*:/spring/*.xml"</span>)  单个</span><br><span class="line"></span><br><span class="line"><span class="meta">@ImportResource</span>(&#123;<span class="string">"classpath*:/spring/1.xml"</span>,<span class="string">"classpath*:/spring/2.xml"</span>&#125;)   多个</span><br></pre></td></tr></table></figure>

<h2 id="Value"><a href="#Value" class="headerlink" title="@Value"></a>@Value</h2><p>application.properties定义属性，直接使用@Value注入即可</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span>&#123;</span><br><span class="line">	 <span class="meta">@Value</span>(<span class="string">"$&#123;push.start:0&#125;"</span>)    如果缺失，默认值为<span class="number">0</span></span><br><span class="line">     <span class="keyword">private</span> Long  id;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="ConfigurationProperties-prefix-”person”"><a href="#ConfigurationProperties-prefix-”person”" class="headerlink" title="@ConfigurationProperties(prefix=”person”)"></a>@ConfigurationProperties(prefix=”person”)</h2><p>可以新建一个properties文件，ConfigurationProperties的属性prefix指定properties的配置的前缀，通过location指定properties文件的位置</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ConfigurationProperties</span>(prefix=<span class="string">"person"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonProperties</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">private</span> String name ;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="EnableConfigurationProperties"><a href="#EnableConfigurationProperties" class="headerlink" title="@EnableConfigurationProperties"></a>@EnableConfigurationProperties</h2><p>用 @EnableConfigurationProperties注解使 @ConfigurationProperties生效，并从IOC容器中获取bean。</p>
<p><a href="https://blog.csdn.net/u010502101/article/details/78758330" target="_blank" rel="noopener">https://blog.csdn.net/u010502101/article/details/78758330</a></p>
<h2 id="RestController"><a href="#RestController" class="headerlink" title="@RestController"></a>@RestController</h2><p>组合@Controller和@ResponseBody，当你开发一个和页面交互数据的控制时，比如bbs-web的api接口需要此注解</p>
<h2 id="RequestMapping-“-api2-copper”"><a href="#RequestMapping-“-api2-copper”" class="headerlink" title="@RequestMapping(“/api2/copper”)"></a>@RequestMapping(“/api2/copper”)</h2><p>用来映射web请求（访问路径和参数）、处理类和方法，可以注解在类或方法上。注解在方法上的路径会继承注解在类上的路径。</p>
<p>produces属性：定制返回的response的媒体类型和字符集，或需返回值是json对象</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(value=<span class="string">"/api2/copper"</span>,produces=<span class="string">"application/json;charset=UTF-8"</span>,method = RequestMethod.POST)</span><br></pre></td></tr></table></figure>

<h2 id="RequestParam"><a href="#RequestParam" class="headerlink" title="@RequestParam"></a>@RequestParam</h2><p>获取request请求的参数值</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;CopperVO&gt; <span class="title">getOpList</span><span class="params">(HttpServletRequest request,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   @RequestParam(value = <span class="string">"pageIndex"</span>, required = <span class="keyword">false</span>)</span> Integer pageIndex,</span></span><br><span class="line"><span class="function">                                   @<span class="title">RequestParam</span><span class="params">(value = <span class="string">"pageSize"</span>, required = <span class="keyword">false</span>)</span> Integer pageSize) </span>&#123;</span><br><span class="line"></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<h2 id="ResponseBody"><a href="#ResponseBody" class="headerlink" title="@ResponseBody"></a>@ResponseBody</h2><p>支持将返回值放在response体内，而不是返回一个页面。比如Ajax接口，可以用此注解返回数据而不是页面。此注解可以放置在返回值前或方法前。</p>
<p>另一个玩法，可以不用@ResponseBody。<br>继承FastJsonHttpMessageConverter类并对writeInternal方法扩展，在spring响应结果时，再次拦截、加工结果</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// stringResult：json返回结果</span></span><br><span class="line"><span class="comment">//HttpOutputMessage outputMessage</span></span><br><span class="line"> <span class="keyword">byte</span>[] payload = stringResult.getBytes();</span><br><span class="line"> outputMessage.getHeaders().setContentType(META_TYPE);</span><br><span class="line"> outputMessage.getHeaders().setContentLength(payload.length);</span><br><span class="line"> outputMessage.getBody().write(payload);</span><br><span class="line"> outputMessage.getBody().flush();</span><br></pre></td></tr></table></figure>

<h2 id="Bean-name-”bean的名字”-initMethod-”初始化时调用方法名字”-destroyMethod-”close”"><a href="#Bean-name-”bean的名字”-initMethod-”初始化时调用方法名字”-destroyMethod-”close”" class="headerlink" title="@Bean(name=”bean的名字”,initMethod=”初始化时调用方法名字”,destroyMethod=”close”)"></a>@Bean(name=”bean的名字”,initMethod=”初始化时调用方法名字”,destroyMethod=”close”)</h2><p>定义在方法上，在容器内初始化一个bean实例类。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span>(destroyMethod=<span class="string">"close"</span>)</span><br><span class="line"><span class="meta">@ConditionalOnMissingBean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> PersonService <span class="title">registryService</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> PersonService();</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Service-用于标注业务层组件"><a href="#Service-用于标注业务层组件" class="headerlink" title="@Service  用于标注业务层组件"></a>@Service  用于标注业务层组件</h2><h2 id="Controller用于标注控制层组件（如struts中的action）"><a href="#Controller用于标注控制层组件（如struts中的action）" class="headerlink" title="@Controller用于标注控制层组件（如struts中的action）"></a>@Controller用于标注控制层组件（如struts中的action）</h2><h2 id="Repository用于标注数据访问组件，即DAO组件"><a href="#Repository用于标注数据访问组件，即DAO组件" class="headerlink" title="@Repository用于标注数据访问组件，即DAO组件"></a>@Repository用于标注数据访问组件，即DAO组件</h2><h2 id="Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。"><a href="#Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。" class="headerlink" title="@Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。"></a>@Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。</h2><h2 id="PostConstruct"><a href="#PostConstruct" class="headerlink" title="@PostConstruct"></a>@PostConstruct</h2><p>spring容器初始化时，要执行该方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PostConstruct</span>  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="PathVariable-用来获得请求url中的动态参数"><a href="#PathVariable-用来获得请求url中的动态参数" class="headerlink" title="@PathVariable  用来获得请求url中的动态参数"></a>@PathVariable  用来获得请求url中的动态参数</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Controller</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;  </span><br><span class="line"></span><br><span class="line">     <span class="meta">@RequestMapping</span>(value=<span class="string">"/user/&#123;userId&#125;/roles/&#123;roleId&#125;"</span>,method = RequestMethod.GET)  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getLogin</span><span class="params">(@PathVariable(<span class="string">"userId"</span>)</span> String userId,  </span></span><br><span class="line"><span class="function">         @<span class="title">PathVariable</span><span class="params">(<span class="string">"roleId"</span>)</span> String roleId)</span>&#123;</span><br><span class="line">           </span><br><span class="line">         System.out.println(<span class="string">"User Id : "</span> + userId);  </span><br><span class="line">         System.out.println(<span class="string">"Role Id : "</span> + roleId);  </span><br><span class="line">         <span class="keyword">return</span> <span class="string">"hello"</span>;  </span><br><span class="line">     </span><br><span class="line">     &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="ComponentScan-注解会告知Spring扫描指定的包来初始化Spring"><a href="#ComponentScan-注解会告知Spring扫描指定的包来初始化Spring" class="headerlink" title="@ComponentScan  注解会告知Spring扫描指定的包来初始化Spring"></a>@ComponentScan  注解会告知Spring扫描指定的包来初始化Spring</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ComponentScan</span>(basePackages = <span class="string">"com.bbs.xx"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="EnableZuulProxy"><a href="#EnableZuulProxy" class="headerlink" title="@EnableZuulProxy"></a>@EnableZuulProxy</h2><p>路由网关的主要目的是为了让所有的微服务对外只有一个接口，我们只需访问一个网关地址，即可由网关将所有的请求代理到不同的服务中。Spring Cloud是通过Zuul来实现的，支持自动路由映射到在Eureka Server上注册的服务。Spring Cloud提供了注解@EnableZuulProxy来启用路由代理。</p>
<h2 id="Autowired"><a href="#Autowired" class="headerlink" title="Autowired"></a>Autowired</h2><p>在默认情况下使用 @Autowired 注释进行自动注入时，Spring 容器中匹配的候选 Bean 数目必须有且仅有一个。当找不到一个匹配的 Bean 时，Spring 容器将抛出 BeanCreationException 异常，并指出必须至少拥有一个匹配的 Bean。</p>
<p>当不能确定 Spring 容器中一定拥有某个类的 Bean 时，可以在需要自动注入该类 Bean 的地方可以使用 @Autowired(required = false)，这等于告诉 Spring：在找不到匹配 Bean 时也不报错</p>
<p><a href="https://blog.csdn.net/ethunsex/article/details/66475792" target="_blank" rel="noopener">@Autowired注解注入map、list与@Qualifier</a></p>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="@Configuration"></a>@Configuration</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span>(<span class="string">"name"</span>)<span class="comment">//表示这是一个配置信息类,可以给这个配置类也起一个名称</span></span><br><span class="line"><span class="meta">@ComponentScan</span>(<span class="string">"spring4"</span>)<span class="comment">//类似于xml中的&lt;context:component-scan base-package="spring4"/&gt;</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Config</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span><span class="comment">//自动注入，如果容器中有多个符合的bean时，需要进一步明确</span></span><br><span class="line">    <span class="meta">@Qualifier</span>(<span class="string">"compent"</span>)<span class="comment">//进一步指明注入bean名称为compent的bean</span></span><br><span class="line">    <span class="keyword">private</span> Compent compent;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span><span class="comment">//类似于xml中的&lt;bean id="newbean" class="spring4.Compent"/&gt;</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Compent <span class="title">newbean</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Compent();</span><br><span class="line">    &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Import-Config1-class"><a href="#Import-Config1-class" class="headerlink" title="@Import(Config1.class)"></a>@Import(Config1.class)</h2><p>导入Config1配置类里实例化的bean</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CDConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span>   <span class="comment">// 将SgtPeppers注册为 SpringContext中的bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> CompactDisc <span class="title">compactDisc</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CompactDisc();  <span class="comment">// CompactDisc类型的</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@Import</span>(CDConfig<span class="class">.<span class="keyword">class</span>)  //导入<span class="title">CDConfig</span>的配置</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">class</span> <span class="title">CDPlayerConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span>(name = <span class="string">"cDPlayer"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> CDPlayer <span class="title">cdPlayer</span><span class="params">(CompactDisc compactDisc)</span> </span>&#123;  </span><br><span class="line">         <span class="comment">// 这里会注入CompactDisc类型的bean</span></span><br><span class="line">         <span class="comment">// 这里注入的这个bean是CDConfig.class中的CompactDisc类型的那个bean</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CDPlayer(compactDisc);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Order"><a href="#Order" class="headerlink" title="@Order"></a>@Order</h2><p>@Order(1)，值越小优先级超高，越先运行</p>
<ul>
<li>@ConditionalOnExpression</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@ConditionalOnExpression</span>(<span class="string">"$&#123;enabled:false&#125;"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BigpipeConfiguration</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> OrderMessageMonitor <span class="title">orderMessageMonitor</span><span class="params">(ConfigContext configContext)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> OrderMessageMonitor(configContext);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>开关为true的时候才实例化bean，后面是默认值</p>
<h2 id="ConditionalOnWebApplication"><a href="#ConditionalOnWebApplication" class="headerlink" title="ConditionalOnWebApplication"></a>ConditionalOnWebApplication</h2><p>当前项目是WEB项目的条件下</p>
<p><a href="https://www.jianshu.com/p/23f504713b94" target="_blank" rel="noopener">https://www.jianshu.com/p/23f504713b94</a></p>
<h2 id="ConditionalOnProperty"><a href="#ConditionalOnProperty" class="headerlink" title="@ConditionalOnProperty"></a>@ConditionalOnProperty</h2><p>这个注解能够控制某个 @Configuration 是否生效。具体操作是通过其两个属性name以及havingValue来实现的，其中name用来从application.properties中读取某个属性值，如果该值为空，则返回false;如果值不为空，则将该值与havingValue指定的值进行比较，如果一样则返回true;否则返回false。如果返回值为false，则该configuration不生效；为true则生效。</p>
<p><a href="https://blog.csdn.net/dalangzhonghangxing/article/details/78420057" target="_blank" rel="noopener">https://blog.csdn.net/dalangzhonghangxing/article/details/78420057</a></p>
<h2 id="ConditionalOnClass"><a href="#ConditionalOnClass" class="headerlink" title="@ConditionalOnClass"></a>@ConditionalOnClass</h2><p>该注解的参数对应的类在class path中，否则不解析该注解修饰的配置类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">@ConditionalOnClass(&#123;Gson.class&#125;)</span><br><span class="line">public class GsonAutoConfiguration &#123;</span><br><span class="line">    public GsonAutoConfiguration() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    @ConditionalOnMissingBean</span><br><span class="line">    public Gson gson() &#123;</span><br><span class="line">        return new Gson();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="ConditionalOnBean"><a href="#ConditionalOnBean" class="headerlink" title="@ConditionalOnBean"></a>@ConditionalOnBean</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@ConditionalOnBean</span>(&#123;LoadBalancerClient<span class="class">.<span class="keyword">class</span>&#125;)</span></span><br><span class="line"><span class="class">@<span class="title">EnableConfigurationProperties</span>(</span>&#123;LoadBalancerRetryProperties<span class="class">.<span class="keyword">class</span>&#125;)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">class</span> <span class="title">LoadBalancerAutoConfiguration</span> </span>&#123;</span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只有 LoadBalancerClient类创建的bean对象在容器中存在时，才会执行LoadBalancerAutoConfiguration中的配置类</p>
<h2 id="ConditionalOnMisssingClass-ApplicationManager-class"><a href="#ConditionalOnMisssingClass-ApplicationManager-class" class="headerlink" title="@ConditionalOnMisssingClass({ApplicationManager.class})"></a>@ConditionalOnMisssingClass({ApplicationManager.class})</h2><p>如果存在它修饰的类的bean，则不需要再创建这个bean；</p>
<h2 id="ConditionOnMissingBean-name-“example”"><a href="#ConditionOnMissingBean-name-“example”" class="headerlink" title="@ConditionOnMissingBean(name = “example”)"></a>@ConditionOnMissingBean(name = “example”)</h2><p>表示如果name为“example”的bean存在，该注解修饰的代码块不执行。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot笔记</title>
    <url>/springboot/note/</url>
    <content><![CDATA[<h1 id="框架—模块—体系—生态"><a href="#框架—模块—体系—生态" class="headerlink" title="框架—模块—体系—生态"></a>框架—模块—体系—生态</h1><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>springboot是基于spring+java+web容器，微服务框架的杰出代表。微服务其实就是将服务粒度做小，使之可以独立承担对外服务的的职责。</p>
<a id="more"></a>

<h2 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h2><ul>
<li>遵循“约定胜于配置”的原则，使用spring boot只需要很少的配置，大部分时候可以使用默认配置</li>
<li>项目快速搭建，可以配置整合第三方框架</li>
<li>可完全不使用xml配置，借助java config</li>
<li>内嵌Servlet（如 Tomcat）容器，可以jar包运行</li>
<li>运行中的应用状态监控</li>
</ul>
<h3 id="微服务优势："><a href="#微服务优势：" class="headerlink" title="微服务优势："></a><strong>微服务优势：</strong></h3><ul>
<li>独立性。每个微服务都是一个独立的项目。可以独立对外提供服务，可以将研发人力资源很好的分摊，避免人力资源密集带来的沟通、协作成本。（低耦合原则）</li>
<li>稳定性。任何一个微服务的失败都将只影响自己或少量其他微服务，不会影响整个服务运行体系。</li>
</ul>
<p>SpringApplication将一个典型的spring应用启动的流程“模板化”，默认模板化后执行流程就可以满足需求了，如果有特殊需求，SpringApplication在合适的流程节点开放了一系列不同类型的扩展点，我们可以通过这些扩展点对SpringBoot程序的启动和关闭过程进行扩展。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span>(exclude = &#123; DataSourceAutoConfiguration<span class="class">.<span class="keyword">class</span>,</span></span><br><span class="line"><span class="class">                                  <span class="title">DataSourceTransactionManagerAutoConfiguration</span>.<span class="title">class</span> &#125;)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">class</span> <span class="title">Main</span> <span class="keyword">extends</span> <span class="title">WebMvcConfigurationSupport</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication app = new SpringApplication(Main.class, "classpath*:/spring/*.xml");</span><br><span class="line">        app.setShowBanner(<span class="keyword">false</span>);</span><br><span class="line">        app.run(args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="执行流程："><a href="#执行流程：" class="headerlink" title="执行流程："></a><strong>执行流程：</strong></h3><ol>
<li>如果我们使用的是SpringApplication的静态run方法，首先需要创建一个SpringApplication对象实例。</li>
</ol>
<ul>
<li><p>使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationContextInitialize</p>
</li>
<li><p>使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationListener</p>
</li>
<li><p>设置main方法的定义类</p>
</li>
</ul>
<ol start="2">
<li><p>开始执行run方法的逻辑，首先遍历执行所有通过SpringFactoriesLoader加载到的SpringApplicationRunListener，调用它们的started()方法，告诉这些SpringApplicationRunListener，SpringBoot应用要开始执行了。</p>
</li>
<li><p>创建并配置当前SpringBoot应用将要使用的Environment</p>
</li>
<li><p>遍历并调用所有的SpringApplicationRunListener的environmentPrepared()方法，告诉它们，Springboot应用使用的Environment准备好了</p>
</li>
<li><p>确定SpringBoot应用创建什么类型的ApplicationContext，并创建完成，然后根据条件决定是否使用自定义的ShutdownHook，是否使用自定义的BeanNameGenerator，是否使用自定义的ResourceLoader，然后将准备好的Environment设置给创建好的ApplicationContext使用</p>
</li>
<li><p>ApplicationContext创建完成，SpringApplication调用之前加载的ApplicationContextInitialize的initialize方法对创建好的ApplicationContext进行进一步的处理</p>
</li>
<li><p>遍历所有SpringApplicationRunListener的contextPrepared()方法，通知它们，SpringBoot应用使用的ApplicationContext准备好了</p>
</li>
<li><p>将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的Ioc容器配置加载到已经你准备完毕的ApplicationContext</p>
</li>
<li><p>遍历所有的SpringApplicationRunListener的contextLoader()方法，告知ApplicationContext已装载完毕</p>
</li>
<li><p>调用ApplicationContext的refresh()方法，完成Ioc容器可用的最后一道工序</p>
</li>
<li><p>查找当前ApplicationContext中是否注册有CommandLineRunner，如果有，则遍历执行它们</p>
</li>
<li><p>遍历所有的SpringApplicationRunListener的finished()方法，告知，“初始化完成”</p>
</li>
</ol>
<hr>
<h2 id="spring-boot提供了很多“开箱即用”的依赖模块-以”spring-boot-starter-“开头，以解决不同场景问题。"><a href="#spring-boot提供了很多“开箱即用”的依赖模块-以”spring-boot-starter-“开头，以解决不同场景问题。" class="headerlink" title="spring boot提供了很多“开箱即用”的依赖模块,以”spring-boot-starter-“开头，以解决不同场景问题。"></a>spring boot提供了很多“开箱即用”的依赖模块,以”spring-boot-starter-“开头，以解决不同场景问题。</h2><ol>
<li><p>SpringBoot应用将自动使用logback作为应用日志框架，</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>得到一个直接可执行的web应用，当前项目下直接运行mvn spring-boot:run 就可以直接启动一个嵌入tomcat服务请求的web应用。</p>
</li>
</ol>
<p>默认访问地址：<a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>如果想使用其它容器，可引入spring-boot-starter-jetty</p>
<p>另外可以修改server.port使用自己指定的端口</p>
<ol start="3">
<li>访问数据库依赖此模块。</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol start="4">
<li><p>负责web应用安全，配合spring-boot-starter-web使用</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-security<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>监控，了解应用的运行状态</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>上面只是介绍一些常用的组件，sping社区还有很多其它优秀的组件，可以根据自己的业务情况研究自取。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot项目设置为开机启动</title>
    <url>/springboot/start/</url>
    <content><![CDATA[<p>关于开机启动，其实有很多办法，例如：<span class="label success">chkconfig</span>、<span class="label warning">systemctl</span>、<span class="label danger">supervisord</span> 等.</p>
<a id="more"></a>
<h2 id="1-创建启动脚本"><a href="#1-创建启动脚本" class="headerlink" title="1.创建启动脚本"></a>1.创建启动脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ vim start.sh  </span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/sh  </span></span><br><span class="line"><span class="built_in">cd</span> /web/target &amp;&amp; java -jar myboot-0.0.1-SNAPSHOT.jar &gt; /web/logs/web.log &amp;  </span><br><span class="line"><span class="built_in">echo</span> $! &gt; /web/myboot.pid</span><br></pre></td></tr></table></figure>

<h2 id="2-创建停止脚本"><a href="#2-创建停止脚本" class="headerlink" title="2.创建停止脚本"></a>2.创建停止脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ vim stop.sh  </span><br><span class="line"><span class="meta">#!/bin/sh  </span></span><br><span class="line">PID=$(cat /web/myboot.pid)  </span><br><span class="line"><span class="built_in">kill</span> -9 <span class="variable">$PID</span>  </span><br><span class="line">  </span><br><span class="line">$ chmod +x ./*.sh</span><br></pre></td></tr></table></figure>
<h2 id="3-系统启动脚本"><a href="#3-系统启动脚本" class="headerlink" title="3.系统启动脚本"></a>3.系统启动脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ vim /usr/lib/systemd/system/myboot.service  </span><br><span class="line">  </span><br><span class="line">[Unit]  </span><br><span class="line">Description=myboot  </span><br><span class="line">After=syslog.target network.target remote-fs.target nss-lookup.target  </span><br><span class="line">  </span><br><span class="line">[Service]  </span><br><span class="line">Type=forking  </span><br><span class="line">ExecStart=/web/start/start.sh  </span><br><span class="line">ExecStop=/web/start/stop.sh  </span><br><span class="line">PrivateTmp=<span class="literal">true</span>  </span><br><span class="line">  </span><br><span class="line">[Install]  </span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<h2 id="4-启动，设置开机启动"><a href="#4-启动，设置开机启动" class="headerlink" title="4.启动，设置开机启动"></a>4.启动，设置开机启动</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ systemctl start myboot  </span><br><span class="line">$ systemctl <span class="built_in">enable</span> myboot</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>Springboot汇总</title>
    <url>/springboot/summary/</url>
    <content><![CDATA[<h1 id="一、手册"><a href="#一、手册" class="headerlink" title="一、手册"></a>一、手册</h1><ul>
<li><a href="https://github.com/spring-projects/spring-boot" target="_blank" rel="noopener">源码</a></li>
<li><a href="../note">spring boot 笔记</a><a id="more"></a></li>
<li><a href="https://github.com/aalansehaiyang/SpringBoot-Learning" target="_blank" rel="noopener">SpringBoot 组件接入示例</a></li>
<li><a href="../javaConfig">java autoConfig配置</a></li>
<li><a href="../hot-reload">代码热部署</a></li>
<li><a href="../unit">eclipse中如何跑spring boot的单元测试</a></li>
<li><a href="https://blog.csdn.net/v2sking/article/details/72795742" target="_blank" rel="noopener">异步调用Async</a></li>
</ul>
<h2 id="接口扩展"><a href="#接口扩展" class="headerlink" title="接口扩展"></a>接口扩展</h2><ul>
<li><a href="https://my.oschina.net/spinachgit/blog/1635218?nocache=1522203306031" target="_blank" rel="noopener">ApplicationListener</a></li>
<li><a href="https://blog.csdn.net/huangbo_embed/article/details/50342669" target="_blank" rel="noopener">ApplicationObjectSupport</a></li>
<li><a href="">FactoryBean</a></li>
<li><a href="">InitializingBean</a></li>
<li>拦截器<ul>
<li><a href="https://blog.csdn.net/qq_27905183/article/details/79079762" target="_blank" rel="noopener">HandlerInterceptor、WebMvcConfigurerAdapter</a></li>
<li><a href="https://www.jianshu.com/p/deb5e5efb724" target="_blank" rel="noopener">ClientHttpRequestInterceptor、RestTemplate</a></li>
</ul>
</li>
<li>AOP<ul>
<li><a href="https://www.cnblogs.com/ssslinppp/p/5845659.html" target="_blank" rel="noopener">@Around增强处理简单示例</a></li>
</ul>
</li>
</ul>
<h1 id="二、资料集"><a href="#二、资料集" class="headerlink" title="二、资料集"></a>二、资料集</h1><ul>
<li><a href="http://www.ityouknow.com/spring-boot.html" target="_blank" rel="noopener">Spring Boot 系列文章</a></li>
<li><a href="https://github.com/ityouknow/awesome-spring-boot" target="_blank" rel="noopener">【github】awesome-spring-boot，收集各种Spring Boot 学习资源 </a> </li>
<li><a href="https://mp.weixin.qq.com/s/iwYVhvNgfi0VTkl2tqMbNw" target="_blank" rel="noopener">基于spring Boot 的开源软件</a></li>
<li>系列<ul>
<li><a href="https://github.com/JeffLi1993/springboot-learning-example" target="_blank" rel="noopener">springboot-learning-example</a></li>
<li><a href="http://www.jianshu.com/collection/f0cf6eae1754" target="_blank" rel="noopener">Spring Boot 简书</a></li>
<li><a href="https://mp.weixin.qq.com/s/VFHmOIp-H4lgh4gQE-cj5A" target="_blank" rel="noopener">Spring干货汇总</a></li>
<li>《SpringBoot揭秘–快速构建微服务体系》</li>
</ul>
</li>
<li><a href="https://mp.weixin.qq.com/s/weh1bwsxBXQC1sbBo7_nwQ" target="_blank" rel="noopener">给你一份SpringBoot知识清单</a></li>
</ul>
<h1 id="三、前沿"><a href="#三、前沿" class="headerlink" title="三、前沿"></a>三、前沿</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/lsJU_XFmI3dPpkWndrsAuw" target="_blank" rel="noopener">Spring Boot 2.0正式发布，新特性解读</a></li>
<li><a href="https://mp.weixin.qq.com/s/aSzZYsYux9iRHJOcbpvSWg" target="_blank" rel="noopener">Spring Boot 2.0权威发布</a></li>
<li><a href="https://mp.weixin.qq.com/s/7Fck8qYDZiYqsHE7qjbV1Q" target="_blank" rel="noopener">Spring Boot 2.1.0 权威发布</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>Springboot单元测试</title>
    <url>/springboot/unit/</url>
    <content><![CDATA[<h2 id="eclipse中如何跑springboot的单元测试"><a href="#eclipse中如何跑springboot的单元测试" class="headerlink" title="eclipse中如何跑springboot的单元测试"></a>eclipse中如何跑springboot的单元测试</h2><a id="more"></a>

<p>1、首先引入对应的pom依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-configuration-processor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RunWith</span>(SpringJUnit4ClassRunner<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">@<span class="title">ContextConfiguration</span>(<span class="title">locations</span> </span>= &#123;<span class="string">"classpath*:spring/bbs*.xml"</span>&#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AdServiceTest</span> <span class="keyword">extends</span> <span class="title">AbstractTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    AdService adService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        AdParam adParam = <span class="keyword">new</span> AdParam();</span><br><span class="line">        adParam.setAdPositionId(<span class="number">16005</span>);</span><br><span class="line">        adParam.setNum(<span class="number">20</span>);</span><br><span class="line">        List&lt;AdModel&gt; adModels = adService.queryAdList(adParam);</span><br><span class="line">        System.out.println(JSON.toJSONString(adModels));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>参考资料：</strong></p>
<p><a href="http://412887952-qq-com.iteye.com/blog/2307104" target="_blank" rel="noopener">http://412887952-qq-com.iteye.com/blog/2307104</a></p>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>spring cloud gateway之过滤器</title>
    <url>/springcloud/spring-cloud-gateway-filter/</url>
    <content><![CDATA[<p>在上一篇文章详细的介绍了Gateway的Predict，Predict决定了请求由哪一个路由处理，在路由处理之前，需要经过“pre”类型的过滤器处理，处理返回响应之后，可以由“post”类型的过滤器处理。</p>
<h2 id="filter的作用和生命周期"><a href="#filter的作用和生命周期" class="headerlink" title="filter的作用和生命周期"></a>filter的作用和生命周期</h2><p>由filter工作流程点，可以知道filter有着非常重要的作用，在“pre”类型的过滤器可以做参数校验、权限校验、流量监控、日志输出、协议转换等，在“post”类型的过滤器中可以做响应内容、响应头的修改，日志的输出，流量监控等。首先需要弄清一点为什么需要网关这一层，这就不得不说下filter的作用了。</p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>当我们有很多个服务时，比如下图中的user-service、goods-service、sales-service等服务，客户端请求各个服务的Api时，每个服务都需要做相同的事情，比如鉴权、限流、日志输出等。</p>
<img data-src="https://img-blog.csdnimg.cn/20190601011017456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9mb3JlenAuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70">

<p>对于这样重复的工作，有没有办法做的更好，答案是肯定的。在微服务的上一层加一个全局的权限控制、限流、日志输出的Api Gatewat服务，然后再将请求转发到具体的业务服务层。这个Api Gateway服务就是起到一个服务边界的作用，外接的请求访问系统，必须先通过网关层。</p>
<img data-src="https://img-blog.csdnimg.cn/20190601011045154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9mb3JlenAuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" >

<h3 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h3><p>Spring Cloud Gateway同zuul类似，有“pre”和“post”两种方式的filter。客户端的请求先经过“pre”类型的filter，然后将请求转发到具体的业务服务，比如上图中的user-service，收到业务服务的响应之后，再经过“post”类型的filter处理，最后返回响应到客户端。</p>
<img data-src="https://img-blog.csdnimg.cn/20190601011115924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9mb3JlenAuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" >

<p>与zuul不同的是，filter除了分为“pre”和“post”两种方式的filter外，在Spring Cloud Gateway中，filter从作用范围可分为另外两种，一种是针对于单个路由的gateway filter，它在配置文件中的写法同predict类似；另外一种是针对于所有路由的global gateway filer。现在从作用范围划分的维度来讲解这两种filter。</p>
<h2 id="gateway-filter"><a href="#gateway-filter" class="headerlink" title="gateway filter"></a>gateway filter</h2><p>过滤器允许以某种方式修改传入的HTTP请求或传出的HTTP响应。过滤器可以限定作用在某些特定请求路径上。  Spring Cloud Gateway包含许多内置的GatewayFilter工厂。</p>
<p>GatewayFilter工厂同上一篇介绍的Predicate工厂类似，都是在配置文件application.yml中配置，遵循了约定大于配置的思想，只需要在配置文件配置GatewayFilter Factory的名称，而不需要写全部的类名，比如AddRequestHeaderGatewayFilterFactory只需要在配置文件中写AddRequestHeader，而不是全部类名。在配置文件中配置的GatewayFilter Factory最终都会相应的过滤器工厂类处理。</p>
<p>Spring Cloud Gateway 内置的过滤器工厂一览表如下：</p>
<img data-src="https://img-blog.csdnimg.cn/20190601011143809.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9mb3JlenAuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" >

<p>现在挑几个常见的过滤器工厂来讲解，每一个过滤器工厂在官方文档都给出了详细的使用案例，如果不清楚的还可以在org.springframework.cloud.gateway.filter.factory看每一个过滤器工厂的源码。</p>
<h3 id="AddRequestHeader-GatewayFilter-Factory"><a href="#AddRequestHeader-GatewayFilter-Factory" class="headerlink" title="AddRequestHeader GatewayFilter Factory"></a>AddRequestHeader GatewayFilter Factory</h3><p>创建工程，引入相关的依赖,包括spring boot 版本2.0.5，spring Cloud版本Finchley，gateway依赖如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-gateway<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>在工程的配置文件中，加入以下的配置：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">profiles:</span></span><br><span class="line">    <span class="attr">active:</span> <span class="string">add_request_header_route</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">gateway:</span></span><br><span class="line">      <span class="attr">routes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">id:</span> <span class="string">add_request_header_route</span></span><br><span class="line">        <span class="attr">uri:</span> <span class="string">http://httpbin.org:80/get</span></span><br><span class="line">        <span class="attr">filters:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">AddRequestHeader=X-Request-Foo,</span> <span class="string">Bar</span></span><br><span class="line">        <span class="attr">predicates:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">After=2017-01-20T17:42:47.789-07:00[America/Denver]</span></span><br><span class="line">  <span class="attr">profiles:</span> <span class="string">add_request_header_route</span></span><br></pre></td></tr></table></figure>

<p>在上述的配置中，工程的启动端口为8081，配置文件为add_request_header_route，在add_request_header_route配置中，配置了roter的id为add_request_header_route，路由地址为<a href="http://httpbin.org:80/get，该router有AfterPredictFactory，有一个filter为AddRequestHeaderGatewayFilterFactory(约定写成AddRequestHeader)，AddRequestHeader过滤器工厂会在请求头加上一对请求头，名称为X-Request-Foo，值为Bar。为了验证AddRequestHeaderGatewayFilterFactory是怎么样工作的，查看它的源码，AddRequestHeaderGatewayFilterFactory的源码如下：" target="_blank" rel="noopener">http://httpbin.org:80/get，该router有AfterPredictFactory，有一个filter为AddRequestHeaderGatewayFilterFactory(约定写成AddRequestHeader)，AddRequestHeader过滤器工厂会在请求头加上一对请求头，名称为X-Request-Foo，值为Bar。为了验证AddRequestHeaderGatewayFilterFactory是怎么样工作的，查看它的源码，AddRequestHeaderGatewayFilterFactory的源码如下：</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AddRequestHeaderGatewayFilterFactory</span> <span class="keyword">extends</span> <span class="title">AbstractNameValueGatewayFilterFactory</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> GatewayFilter <span class="title">apply</span><span class="params">(NameValueConfig config)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> (exchange, chain) -&amp;gt; &#123;</span><br><span class="line">			ServerHttpRequest request = exchange.getRequest().mutate()</span><br><span class="line">					.header(config.getName(), config.getValue())</span><br><span class="line">					.build();</span><br><span class="line"></span><br><span class="line">			<span class="keyword">return</span> chain.filter(exchange.mutate().request(request).build());</span><br><span class="line">		&#125;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由上面的代码可知，根据旧的ServerHttpRequest创建新的 ServerHttpRequest ，在新的ServerHttpRequest加了一个请求头，然后创建新的 ServerWebExchange ，提交过滤器链继续过滤。</p>
<p>启动工程，通过curl命令来模拟请求：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl localhost:8081</span><br></pre></td></tr></table></figure>

<p>最终显示了从 <a href="http://httpbin.org:80/get得到了请求，响应如下：" target="_blank" rel="noopener">http://httpbin.org:80/get得到了请求，响应如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"args"</span>: &#123;&#125;,</span><br><span class="line">  <span class="attr">"headers"</span>: &#123;</span><br><span class="line">    <span class="attr">"Accept"</span>: <span class="string">"*/*"</span>,</span><br><span class="line">    <span class="attr">"Connection"</span>: <span class="string">"close"</span>,</span><br><span class="line">    <span class="attr">"Forwarded"</span>: <span class="string">"proto=http;host=\"localhost:8081\";for=\"0:0:0:0:0:0:0:1:56248\""</span>,</span><br><span class="line">    <span class="attr">"Host"</span>: <span class="string">"httpbin.org"</span>,</span><br><span class="line">    <span class="attr">"User-Agent"</span>: <span class="string">"curl/7.58.0"</span>,</span><br><span class="line">    <span class="attr">"X-Forwarded-Host"</span>: <span class="string">"localhost:8081"</span>,</span><br><span class="line">    <span class="attr">"X-Request-Foo"</span>: <span class="string">"Bar"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"origin"</span>: <span class="string">"0:0:0:0:0:0:0:1, 210.22.21.66"</span>,</span><br><span class="line">  <span class="attr">"url"</span>: <span class="string">"http://localhost:8081/get"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以上面的响应可知，确实在请求头中加入了X-Request-Foo这样的一个请求头，在配置文件中配置的AddRequestHeader过滤器工厂生效。</p>
<p>跟AddRequestHeader过滤器工厂类似的还有AddResponseHeader过滤器工厂，在此就不再重复。</p>
<h3 id="RewritePath-GatewayFilter-Factory"><a href="#RewritePath-GatewayFilter-Factory" class="headerlink" title="RewritePath GatewayFilter Factory"></a>RewritePath GatewayFilter Factory</h3><p>在Nginx服务启中有一个非常强大的功能就是重写路径，Spring Cloud Gateway默认也提供了这样的功能，这个功能是Zuul没有的。在配置文件中加上以下的配置：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">profiles:</span></span><br><span class="line">    <span class="attr">active:</span> <span class="string">rewritepath_route</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">gateway:</span></span><br><span class="line">      <span class="attr">routes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">id:</span> <span class="string">rewritepath_route</span></span><br><span class="line">        <span class="attr">uri:</span> <span class="string">https://blog.csdn.net</span></span><br><span class="line">        <span class="attr">predicates:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">Path=/foo/**</span></span><br><span class="line">        <span class="attr">filters:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">RewritePath=/foo/(?&amp;lt;segment&amp;gt;.*),</span> <span class="string">/$\&#123;segment&#125;</span></span><br><span class="line">  <span class="attr">profiles:</span> <span class="string">rewritepath_route</span></span><br></pre></td></tr></table></figure>
<p>上面的配置中，所有的/foo/<em>*开始的路径都会命中配置的router，并执行过滤器的逻辑，在本案例中配置了RewritePath过滤器工厂，此工厂将/foo/(?.</em>)重写为{segment}，然后转发到<a href="https://blog.csdn.net。比如在网页上请求localhost:8081/foo/forezp，此时会将请求转发到https://blog.csdn.net/forezp的页面，比如在网页上请求localhost:8081/foo/forezp/1，页面显示404，就是因为不存在https://blog.csdn.net/forezp/1这个页面。" target="_blank" rel="noopener">https://blog.csdn.net。比如在网页上请求localhost:8081/foo/forezp，此时会将请求转发到https://blog.csdn.net/forezp的页面，比如在网页上请求localhost:8081/foo/forezp/1，页面显示404，就是因为不存在https://blog.csdn.net/forezp/1这个页面。</a></p>
<h3 id="自定义过滤器"><a href="#自定义过滤器" class="headerlink" title="自定义过滤器"></a>自定义过滤器</h3><p>Spring Cloud Gateway内置了19种强大的过滤器工厂，能够满足很多场景的需求，那么能不能自定义自己的过滤器呢，当然是可以的。在spring Cloud Gateway中，过滤器需要实现GatewayFilter和Ordered2个接口。写一个RequestTimeFilter，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RequestTimeFilter</span> <span class="keyword">implements</span> <span class="title">GatewayFilter</span>, <span class="title">Ordered</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Log log = LogFactory.getLog(GatewayFilter<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String REQUEST_TIME_BEGIN = <span class="string">"requestTimeBegin"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Mono&amp;lt;Void&amp;gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;</span><br><span class="line"></span><br><span class="line">        exchange.getAttributes().put(REQUEST_TIME_BEGIN, System.currentTimeMillis());</span><br><span class="line">        <span class="keyword">return</span> chain.filter(exchange).then(</span><br><span class="line">                Mono.fromRunnable(() -&amp;gt; &#123;</span><br><span class="line">                    Long startTime = exchange.getAttribute(REQUEST_TIME_BEGIN);</span><br><span class="line">                    <span class="keyword">if</span> (startTime != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        log.info(exchange.getRequest().getURI().getRawPath() + <span class="string">": "</span> + (System.currentTimeMillis() - startTime) + <span class="string">"ms"</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面的代码中，Ordered中的int getOrder()方法是来给过滤器设定优先级别的，值越大则优先级越低。还有有一个filterI(exchange,chain)方法，在该方法中，先记录了请求的开始时间，并保存在ServerWebExchange中，此处是一个“pre”类型的过滤器，然后再chain.filter的内部类中的run()方法中相当于”post”过滤器，在此处打印了请求所消耗的时间。然后将该过滤器注册到router中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RouteLocator <span class="title">customerRouteLocator</span><span class="params">(RouteLocatorBuilder builder)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// @formatter:off</span></span><br><span class="line">    <span class="keyword">return</span> builder.routes()</span><br><span class="line">            .route(r -&amp;gt; r.path(<span class="string">"/customer/**"</span>)</span><br><span class="line">                    .filters(f -&amp;gt; f.filter(<span class="keyword">new</span> RequestTimeFilter())</span><br><span class="line">                            .addResponseHeader(<span class="string">"X-Response-Default-Foo"</span>, <span class="string">"Default-Bar"</span>))</span><br><span class="line">                    .uri(<span class="string">"http://httpbin.org:80/get"</span>)</span><br><span class="line">                    .order(<span class="number">0</span>)</span><br><span class="line">                    .id(<span class="string">"customer_filter_router"</span>)</span><br><span class="line">            )</span><br><span class="line">            .build();</span><br><span class="line">    <span class="comment">// @formatter:on</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>重启程序，通过curl命令模拟请求：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl localhost:8081/customer/123</span><br></pre></td></tr></table></figure>

<p>在程序的控制台输出一下的请求信息的日志：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2018-11-16 15:02:20.177  INFO 20488 --- [ctor-http-nio-3] o.s.cloud.gateway.filter.GatewayFilter   : &#x2F;customer&#x2F;123: 152ms</span><br></pre></td></tr></table></figure>

<h2 id="自定义过滤器工厂"><a href="#自定义过滤器工厂" class="headerlink" title="自定义过滤器工厂"></a>自定义过滤器工厂</h2><p>在上面的自定义过滤器中，有没有办法自定义过滤器工厂类呢?这样就可以在配置文件中配置过滤器了。现在需要实现一个过滤器工厂，在打印时间的时候，可以设置参数来决定是否打印请参数。查看GatewayFilterFactory的源码，可以发现GatewayFilterfactory的层级如下：</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuZmFuZ3poaXBlbmcuY29tL2ltZy9qaWFuc2h1LzIyNzk1OTQtZjk3ZTEwNDVjZWJjOTU0Yy5wbmc?x-oss-process=image/format,png" >

<p>过滤器工厂的顶级接口是GatewayFilterFactory，我们可以直接继承它的两个抽象类来简化开发AbstractGatewayFilterFactory和AbstractNameValueGatewayFilterFactory，这两个抽象类的区别就是前者接收一个参数（像StripPrefix和我们创建的这种），后者接收两个参数（像AddResponseHeader）。</p>
<p>过滤器工厂的顶级接口是GatewayFilterFactory，有2个两个较接近具体实现的抽象类，分别为AbstractGatewayFilterFactory和AbstractNameValueGatewayFilterFactory，这2个类前者接收一个参数，比如它的实现类RedirectToGatewayFilterFactory；后者接收2个参数，比如它的实现类AddRequestHeaderGatewayFilterFactory类。现在需要将请求的日志打印出来，需要使用一个参数，这时可以参照RedirectToGatewayFilterFactory的写法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RequestTimeGatewayFilterFactory</span> <span class="keyword">extends</span> <span class="title">AbstractGatewayFilterFactory</span>&lt;<span class="title">RequestTimeGatewayFilterFactory</span>.<span class="title">Config</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Log log = LogFactory.getLog(GatewayFilter<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String REQUEST_TIME_BEGIN = <span class="string">"requestTimeBegin"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KEY = <span class="string">"withParams"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">shortcutFieldOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(KEY);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RequestTimeGatewayFilterFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(Config<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> GatewayFilter <span class="title">apply</span><span class="params">(Config config)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (exchange, chain) -&gt; &#123;</span><br><span class="line">            exchange.getAttributes().put(REQUEST_TIME_BEGIN, System.currentTimeMillis());</span><br><span class="line">            <span class="keyword">return</span> chain.filter(exchange).then(</span><br><span class="line">                    Mono.fromRunnable(() -&gt; &#123;</span><br><span class="line">                        Long startTime = exchange.getAttribute(REQUEST_TIME_BEGIN);</span><br><span class="line">                        <span class="keyword">if</span> (startTime != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            StringBuilder sb = <span class="keyword">new</span> StringBuilder(exchange.getRequest().getURI().getRawPath())</span><br><span class="line">                                    .append(<span class="string">": "</span>)</span><br><span class="line">                                    .append(System.currentTimeMillis() - startTime)</span><br><span class="line">                                    .append(<span class="string">"ms"</span>);</span><br><span class="line">                            <span class="keyword">if</span> (config.isWithParams()) &#123;</span><br><span class="line">                                sb.append(<span class="string">" params:"</span>).append(exchange.getRequest().getQueryParams());</span><br><span class="line">                            &#125;</span><br><span class="line">                            log.info(sb.toString());</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;)</span><br><span class="line">            );</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Config</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">boolean</span> withParams;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isWithParams</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> withParams;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setWithParams</span><span class="params">(<span class="keyword">boolean</span> withParams)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.withParams = withParams;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的代码中 apply(Config config)方法内创建了一个GatewayFilter的匿名类，具体的实现逻辑跟之前一样，只不过加了是否打印请求参数的逻辑，而这个逻辑的开关是config.isWithParams()。静态内部类类Config就是为了接收那个boolean类型的参数服务的，里边的变量名可以随意写，但是要重写List shortcutFieldOrder()这个方法。</p>
<p>需要注意的是，在类的构造器中一定要调用下父类的构造器把Config类型传过去，否则会报ClassCastException</p>
<p>最后，需要在工程的启动文件Application类中，向Srping Ioc容器注册RequestTimeGatewayFilterFactory类的Bean。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RequestTimeGatewayFilterFactory <span class="title">elapsedGatewayFilterFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> RequestTimeGatewayFilterFactory();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后可以在配置文件中配置如下：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">profiles:</span></span><br><span class="line">    <span class="attr">active:</span> <span class="string">elapse_route</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">gateway:</span></span><br><span class="line">      <span class="attr">routes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">id:</span> <span class="string">elapse_route</span></span><br><span class="line">        <span class="attr">uri:</span> <span class="string">http://httpbin.org:80/get</span></span><br><span class="line">        <span class="attr">filters:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">RequestTime=false</span></span><br><span class="line">        <span class="attr">predicates:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">After=2017-01-20T17:42:47.789-07:00[America/Denver]</span></span><br><span class="line">  <span class="attr">profiles:</span> <span class="string">elapse_route</span></span><br></pre></td></tr></table></figure>

<p>启动工程，在浏览器上访问localhost:8081?name=forezp，可以在控制台上看到，日志输出了请求消耗的时间和请求参数。</p>
<h2 id="global-filter"><a href="#global-filter" class="headerlink" title="global filter"></a>global filter</h2><p>Spring Cloud Gateway根据作用范围划分为GatewayFilter和GlobalFilter，二者区别如下：</p>
<ul>
<li><p>GatewayFilter : 需要通过spring.cloud.routes.filters 配置在具体路由下，只作用在当前路由上或通过spring.cloud.default-filters配置在全局，作用在所有路由上</p>
</li>
<li><p>GlobalFilter : 全局过滤器，不需要在配置文件中配置，作用在所有的路由上，最终通过GatewayFilterAdapter包装成GatewayFilterChain可识别的过滤器，它为请求业务以及路由的URI转换为真实业务服务的请求地址的核心过滤器，不需要配置，系统初始化时加载，并作用在每个路由上。</p>
</li>
</ul>
<p>Spring Cloud Gateway框架内置的GlobalFilter如下：</p>
<img data-src="https://img-blog.csdnimg.cn/20190601011412503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9mb3JlenAuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70" >

<p>上图中每一个GlobalFilter都作用在每一个router上，能够满足大多数的需求。但是如果遇到业务上的定制，可能需要编写满足自己需求的GlobalFilter。在下面的案例中将讲述如何编写自己GlobalFilter，该GlobalFilter会校验请求中是否包含了请求参数“token”，如何不包含请求参数“token”则不转发路由，否则执行正常的逻辑。代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenFilter</span> <span class="keyword">implements</span> <span class="title">GlobalFilter</span>, <span class="title">Ordered</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Logger logger=LoggerFactory.getLogger( TokenFilter<span class="class">.<span class="keyword">class</span> )</span>;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Mono&lt;Void&gt; <span class="title">filter</span><span class="params">(ServerWebExchange exchange, GatewayFilterChain chain)</span> </span>&#123;</span><br><span class="line">        String token = exchange.getRequest().getQueryParams().getFirst(<span class="string">"token"</span>);</span><br><span class="line">        <span class="keyword">if</span> (token == <span class="keyword">null</span> || token.isEmpty()) &#123;</span><br><span class="line">            logger.info( <span class="string">"token is empty..."</span> );</span><br><span class="line">            exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);</span><br><span class="line">            <span class="keyword">return</span> exchange.getResponse().setComplete();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> chain.filter(exchange);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">100</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的TokenFilter需要实现GlobalFilter和Ordered接口，这和实现GatewayFilter很类似。然后根据ServerWebExchange获取ServerHttpRequest，然后根据ServerHttpRequest中是否含有参数token，如果没有则完成请求，终止转发，否则执行正常的逻辑。</p>
<p>然后需要将TokenFilter在工程的启动类中注入到Spring Ioc容器中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> TokenFilter <span class="title">tokenFilter</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> TokenFilter();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启动工程，使用curl命令请求：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl localhost:8081/customer/123</span><br></pre></td></tr></table></figure>

<p>可以看到请没有被转发，请求被终止，并在控制台打印了如下日志：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2018-11-16 15:30:13.543  INFO 19372 --- [ctor-http-nio-2] gateway.TokenFilter                      : token is empty...</span><br></pre></td></tr></table></figure>

<p>上面的日志显示了请求进入了没有传“token”的逻辑。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇文章讲述了Spring Cloud Gateway中的过滤器，包括GatewayFilter和GlobalFilter。从官方文档的内置过滤器讲起，然后讲解自定义GatewayFilter、GatewayFilterFactory以及自定义的GlobalFilter。有很多内置的过滤器并没有讲述到，比如限流过滤器，这个我觉得是比较重要和大家关注的过滤器，将在之后的文章讲述。</p>
<h2 id="更多阅读"><a href="#更多阅读" class="headerlink" title="更多阅读"></a>更多阅读</h2><p><a href="https://blog.csdn.net/forezp/article/details/70148833" target="_blank" rel="noopener">史上最简单的 SpringCloud 教程汇总</a></p>
<p><a href="https://blog.csdn.net/forezp/article/details/70341818" target="_blank" rel="noopener">SpringBoot教程汇总</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Zuul网关过滤器</title>
    <url>/springcloud/Zuul%E7%BD%91%E5%85%B3%E8%BF%87%E6%BB%A4%E5%99%A8/</url>
    <content><![CDATA[<h1 id="一、zuul网关过滤器"><a href="#一、zuul网关过滤器" class="headerlink" title="一、zuul网关过滤器"></a>一、zuul网关过滤器</h1><p>Zuul中提供了过滤器定义，可以用来过滤代理请求，提供额外功能逻辑。如：权限验证，日志记录等。<br> <a id="more"></a><br>Zuul提供的过滤器是一个父类。父类是ZuulFilter。通过父类中定义的抽象方法filterType，来决定当前的Filter种类是什么。有前置过滤、路由后过滤、后置过滤、异常过滤。</p>
<ul>
<li>前置过滤：是请求进入Zuul之后，立刻执行的过滤逻辑。</li>
<li>路由后过滤：是请求进入Zuul之后，并Zuul实现了请求路由后执行的过滤逻辑，路由后过滤，是在远程服务调用之前过滤的逻辑。</li>
<li>后置过滤：远程服务调用结束后执行的过滤逻辑。</li>
<li>异常过滤：是任意一个过滤器发生异常或远程服务调用无结果反馈的时候执行的过滤逻辑。无结果反馈，就是远程服务调用超时</li>
</ul>
<p>编写网关过滤器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.netflix.zuul.ZuulFilter;</span><br><span class="line"><span class="keyword">import</span> com.netflix.zuul.context.RequestContext;</span><br><span class="line"><span class="keyword">import</span> com.netflix.zuul.exception.ZuulException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestFilter</span> <span class="keyword">extends</span> <span class="title">ZuulFilter</span> </span>&#123;</span><br><span class="line">    <span class="comment">//四种类型：pre,routing,error,post</span></span><br><span class="line">    <span class="comment">//pre：主要用在路由映射的阶段是寻找路由映射表的</span></span><br><span class="line">    <span class="comment">//routing:具体的路由转发过滤器是在routing路由器，具体的请求转发的时候会调用</span></span><br><span class="line">    <span class="comment">//error:一旦前面的过滤器出错了，会调用error过滤器。</span></span><br><span class="line">    <span class="comment">//post:当routing，error运行完后才会调用该过滤器，是在最后阶段的</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">filterType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"pre"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//自定义过滤器执行的顺序，数值越大越靠后执行，越小就越先执行</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">filterOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//控制过滤器生效不生效，可以在里面写一串逻辑来控制</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">shouldFilter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//执行过滤逻辑</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> ZuulException </span>&#123;</span><br><span class="line">        RequestContext context = RequestContext.getCurrentContext();</span><br><span class="line">        HttpServletRequest request = context.getRequest();</span><br><span class="line">        String token = request.getParameter(<span class="string">"token"</span>);</span><br><span class="line">        <span class="keyword">if</span> (token == <span class="keyword">null</span>) &#123;</span><br><span class="line">            context.setSendZuulResponse(<span class="keyword">false</span>);</span><br><span class="line">            context.setResponseStatusCode(<span class="number">401</span>);</span><br><span class="line">            context.setResponseBody(<span class="string">"unAuthrized"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在main方法中添加过滤器的bean, 交给spring管理</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.netflix.zuul.EnableZuulProxy;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableZuulProxy</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(Application<span class="class">.<span class="keyword">class</span>, <span class="title">args</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TestFilter <span class="title">tokenFilter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> TestFilter();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="二、过滤器的生命周期"><a href="#二、过滤器的生命周期" class="headerlink" title="二、过滤器的生命周期"></a>二、过滤器的生命周期</h1><p><img data-src="https://img-blog.csdnimg.cn/20190813154638825.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nbmluZ2tpZA==,size_16,color_FFFFFF,t_70" alt=""></p>
]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Springcloud Netflix</title>
    <url>/springcloud/springcloud-netflix/</url>
    <content><![CDATA[<p>几大模块：服务发现（Eureka），断路器（Hystrix），智能路由（Zuul），客户端负载均衡（Ribbon）</p>
<p>spring –&gt; spring boot –&gt; spring cloud</p>
<a id="more"></a>

<h3 id="一、手册"><a href="#一、手册" class="headerlink" title="一、手册"></a>一、手册</h3><ul>
<li><p><a href="https://github.com/spring-cloud/spring-cloud-netflix" target="_blank" rel="noopener">源码</a></p>
</li>
<li><p><a href="http://bbs.springcloud.com.cn/" target="_blank" rel="noopener">中文社区</a></p>
</li>
<li><p><a href="http://www.jianshu.com/u/6a622d516e32" target="_blank" rel="noopener">源码分析</a></p>
</li>
<li><p><a href="http://www.ityouknow.com/springcloud/2016/12/30/springcloud-collect.html" target="_blank" rel="noopener">推荐博客</a></p>
</li>
<li><p><a href="https://github.com/aalansehaiyang/SpringCloud-Learning" target="_blank" rel="noopener">Spring Cloud 构建微服务示例</a></p>
</li>
<li><p><a href="https://github.com/ityouknow/spring-cloud-examples" target="_blank" rel="noopener">spring Cloud 核心组件</a></p>
<ul>
<li><a href="http://www.ityouknow.com/springcloud/2017/05/10/springcloud-eureka.html" target="_blank" rel="noopener">注册中心 Eureka</a><ul>
<li>生产中我们可能需要三台或者大于三台的注册中心来保证服务的稳定性，配置的原理其实都一样，将注册中心分别指向其它的注册中心。</li>
<li>不同的服务器之间通过异步模式互相复制各自的状态。</li>
</ul>
</li>
<li><a href="http://blog.didispace.com/springcloud6/" target="_blank" rel="noopener">服务注册与发现</a><ul>
<li>client初始时为java提供的，如果是Node.js、Net等语言，也有其对应的client，按规范将接口的自定义协议注册到注册中心即可。</li>
<li>客户端向注册中心注册自身提供的服务，并周期性地发送心跳来更新它的服务租约。当服务关闭时，向Eureka Server取消租约。</li>
</ul>
</li>
<li><a href="http://www.ityouknow.com/springcloud/2017/05/16/springcloud-hystrix.html" target="_blank" rel="noopener">熔断器 Hystrix</a><ul>
<li>容错管理组件。帮助服务依赖中出现延迟或故障时，提供强大的容错能力。</li>
</ul>
</li>
<li><a href="https://mp.weixin.qq.com/s/5PQ9iyPfYCEcJ5W7q0T2oQ" target="_blank" rel="noopener">服务网关 Zuul</a><ul>
<li>通过一个API网关根据请求的url，路由到相应的服务</li>
<li><a href="http://www.ityouknow.com/springcloud/2017/06/01/gateway-service-zuul.html" target="_blank" rel="noopener">服务网关zuul初级篇</a></li>
<li><a href="https://mp.weixin.qq.com/s/wh_7duo4God8_9awPJBJbQ" target="_blank" rel="noopener">Netflix正式开源其API网关Zuul 2</a></li>
</ul>
</li>
<li><a href="http://blog.didispace.com/spring-cloud-starter-dalston-2-2/" target="_blank" rel="noopener">客户端负载均衡 Ribbon</a><ul>
<li>通过在客户端中配置ribbonServerList来设置服务端列表去轮询访问以达到均衡负载的作用。</li>
</ul>
</li>
<li><a href="http://blog.didispace.com/spring-cloud-starter-dalston-2-3/" target="_blank" rel="noopener">客户端负载均衡 Feign</a>    <ul>
<li>Feign是基于Ribbon实现的，所以它自带了客户端负载均衡功能，也可以通过Ribbon的IRule进行策略扩展。</li>
<li>创建接口并用注解来配置它即可完成对Web服务接口的绑定。它具备可插拔的注解支持，包括Feign注解、JAX-RS注解。它也支持可插拔的编码器和解码器。Spring Cloud Feign还扩展了对Spring MVC注解的支持，同时还整合了Ribbon和Eureka来提供均衡负载的HTTP客户端实现。</li>
</ul>
</li>
<li>config<ul>
<li>分布式配置管理</li>
<li><a href="https://mp.weixin.qq.com/s/cQ7iSBv9YZZMH95Zot7JLg" target="_blank" rel="noopener">Spring Cloud Config采用数据库存储配置内容</a></li>
</ul>
</li>
</ul>
</li>
<li><p>配置参数</p>
<ul>
<li><a href="http://www.cnblogs.com/chry/p/7992885.html" target="_blank" rel="noopener">SpringCloud Eureka参数配置项详解</a></li>
</ul>
</li>
</ul>
<h3 id="二、博客"><a href="#二、博客" class="headerlink" title="二、博客"></a>二、博客</h3><ul>
<li><a href="https://github.com/dyc87112/SpringCloud-Learning" target="_blank" rel="noopener">【github】SpringCloud-Learning</a></li>
<li><a href="https://github.com/dyc87112/SpringBoot-Learning" target="_blank" rel="noopener">【github】SpringBoot-Learning</a></li>
<li><a href="https://github.com/forezp/SpringCloudLearning" target="_blank" rel="noopener">【github】SpringCloudLearning</a></li>
<li><a href="https://blog.csdn.net/column/details/15197.html" target="_blank" rel="noopener">【CSDN】史上最简单的 Spring Cloud 教程</a>    </li>
<li><a href="https://springcloud.cc/spring-cloud-dalston.html" target="_blank" rel="noopener">【文档】SpringCloud.cc</a></li>
<li><a href="https://github.com/aalansehaiyang/SpringCloud-Learning" target="_blank" rel="noopener">【github】SpringCloud-Learning</a></li>
</ul>
<h3 id="三、闲谈"><a href="#三、闲谈" class="headerlink" title="三、闲谈"></a>三、闲谈</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/vnWXpH5pv-FAzLZfbgTGvg" target="_blank" rel="noopener">Spring Cloud在国内中小型公司能用起来吗？</a></li>
</ul>
<h4 id="四、坑"><a href="#四、坑" class="headerlink" title="四、坑"></a>四、坑</h4><ul>
<li><a href="http://www.ccblog.cn/95.htm" target="_blank" rel="noopener">注册中心备份节点 unavailable-replicas问题</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud目录</title>
    <url>/springcloud/summary/</url>
    <content><![CDATA[<ul>
<li><p><a href="https://blog.csdn.net/kangswx/article/details/89633779" target="_blank" rel="noopener">SpringCloud各组件的主要功能及底层实现原理</a></p>
</li>
<li><p><a href="https://blog.csdn.net/shida_hu/article/details/89450177" target="_blank" rel="noopener">zipkin的工作原理浅析</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务设计、拆分原则</title>
    <url>/springcloud/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1-%E6%8B%86%E5%88%86%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<h1 id="一、AKF拆分原则"><a href="#一、AKF拆分原则" class="headerlink" title="一、AKF拆分原则"></a>一、AKF拆分原则</h1><p>业界对于可扩展系统架构设计有一个朴素的理念：通过加机器就可以解决容量和可用性问题。</p>
<a id="more"></a>
<p>这一理念在云计算概念疯狂流行的今天，得到了广泛的认可，对于一个规模迅速增长的系统而言，容量和性能问题当然是首当其冲的。但随着时间的向前，系统规模的增长，除了面对性能与容量的问题外，还要面对功能与模块数量上的增长带来的系统复杂性问题以及业务的变化带来的提供差异化服务的问题。</p>
<p>然而许多系统在架构设计时为充分考虑这些问题，导致系统重构成为常态，而影响业务交付能力，还浪费人力财力。对此《可扩展艺术》一书提出了一个系统可扩展模型–AKF可扩展立方（Scalability Cube）。</p>
<img data-src="https://img2018.cnblogs.com/blog/955092/201906/955092-20190605094248873-1093446045.jpg" alt="" />

<h2 id="1-Y轴（功能）关注应用中功能划分，基于不同的业务拆分"><a href="#1-Y轴（功能）关注应用中功能划分，基于不同的业务拆分" class="headerlink" title="1. Y轴（功能）关注应用中功能划分，基于不同的业务拆分"></a>1. Y轴（功能）关注应用中功能划分，基于不同的业务拆分</h2><p>Y轴扩展会将庞大的整体应用拆分为多个服务，每个服务实现一组相关的功能，如订单管理、客户管理等。在工程上常见的方案是服务化架构（SOA），比如对于一个电子商务平台，我们可以拆分成不同的服务，组成类似下面的架构：</p>
<img data-src="https://img2018.cnblogs.com/blog/955092/201906/955092-20190605102858869-1192849060.jpg" alt="" />

<p>但通过上图可以发现，当服务数量增多时，服务调用关系变得复杂，为系统添加一个新功能，要调用的服务数变得不可控，由此引发了服务管理上的混乱，所以一般情况下，需要采用服务注册的机制形成服务网关来进行服务治理</p>
<img data-src="https://img2018.cnblogs.com/blog/955092/201906/955092-20190605103156172-1648161249.jpg" alt="" />

<h2 id="2-X轴（水平扩展）关注水平扩展，也就是-ldquo-加速器解决问题-rdquo"><a href="#2-X轴（水平扩展）关注水平扩展，也就是-ldquo-加速器解决问题-rdquo" class="headerlink" title="2. X轴（水平扩展）关注水平扩展，也就是&ldquo;加速器解决问题&rdquo;"></a>2. X轴（水平扩展）关注水平扩展，也就是&ldquo;加速器解决问题&rdquo;</h2><p>X轴扩展与我们前面朴素理念是一致的，通过绝对平等的复制服务与数据，以解决容量与可用性的问题，其实就是将微服务运行多个实例，做集群加负载均衡的模式。</p>
<p>为了提升单个服务的可用性与容量，对每一个服务进行X轴扩展划分。</p>
<img data-src="https://img2018.cnblogs.com/blog/955092/201906/955092-20190605103435174-274644802.jpg" alt="" />

<h2 id="3-Z轴（数据分区）关注服务与数据的优先级划分，如按地域划分"><a href="#3-Z轴（数据分区）关注服务与数据的优先级划分，如按地域划分" class="headerlink" title="3. Z轴（数据分区）关注服务与数据的优先级划分，如按地域划分"></a>3. Z轴（数据分区）关注服务与数据的优先级划分，如按地域划分</h2><p>Z轴扩展通常是指基于请求者或用户独特的需求，进行系统划分，并使得划分出来的子系统相互隔离但又是完整的。以生产汽车的工厂来举例：福特公司为了发展在中国的业务，或者利用中国的廉价劳动力，在中国建立一个完整的子工厂，与美国工厂一样，负责完整的汽车生产。这就是一种Z 轴扩展。</p>
<p>工程领域常见的Z轴扩展有以下两种方案</p>
<ol>
<li>单元化架构</li>
</ol>
<p>在分布式服务设计领域，一个单元Cell就是满足某个分区所有业务操作的自包含闭环。如上面我们说到的Y轴扩展的SOA架构。客户端对服务端节点的选择一般是随机的，但是，如果在此上加Z轴扩展，那服务节点的选择将不再是随机的，而是每个单元自成一体。</p>
<img data-src="https://img2018.cnblogs.com/blog/955092/201906/955092-20190605105401192-849866805.jpg" alt="" />

<ol start="2">
<li>数据分区</li>
</ol>
<p>为了性能数据安全上的考虑，我们将一个完整的数据集按一定维度划分出不同的子集。一个分区（Shard），就是整体数据集的一个子集。比如用尾号来划分用户，那同样尾号的那部分用户就可以认为是同一个分区，数据分区一般包括以下几种数据划分形式：</p>
<ul>
<li><p>数据类型：如业务类型</p>
</li>
<li><p>数据范围：如时间段、用户ID</p>
</li>
<li><p>数据热度：如用户活跃度、商品热度</p>
</li>
<li><p>按读写分：如商品描述、商品库存</p>
</li>
</ul>
<h1 id="二、前后端分离原则"><a href="#二、前后端分离原则" class="headerlink" title="二、前后端分离原则"></a>二、前后端分离原则</h1><img data-src="https://img2018.cnblogs.com/blog/955092/201906/955092-20190605100416748-2107900661.jpg" alt="" />

<p>何为前后端分离？前后端本来不就是分离的吗？这要从jsp开始讲起。分工精细化从来都是蛋糕做大的原则，多个领域工程师最好在不需要接触其他领域知识的情况下合作，才能使效率越来越高，维护也会变得简单。jsp的模板技术融合了html和java代码，使得传统MVC开发中的前后端如胶似漆，前端做好页面，后端转成模板，发现问题再找前端，前端又看不懂java代码，前后端分离的目的就是打破这尴尬的局面，我们需要的是一个全能的团队，而不是一个个全能的人。</p>
<p>前后端分离原则，简单的将就是前端和后端的代码分离，我们推荐的模式是最好采用物理分离的方式部署，进一步促使更彻底的分离。如果继续使用服务端模板技术，如jsp，把java、js、css、html都堆到一个页面里，稍微复杂一点的页面就无法维护了。</p>
<p>这种前后端分离有几个好处：</p>
<ol>
<li><p>前后端技术分离，可以由各自的专家来对各自的领域进行优化，这样前端的用户体验会更好。</p>
</li>
<li><p>分离模式下，前后端交互界面更清晰，就剩下接口模型，后端接口简介明了，更易于维护。</p>
</li>
<li><p>前端多渠道继承场景更容易实现，后端服务无需变更，采用统一的数据和模型，可以支持多个前端，例如：微信h5前端、PC前端、安卓前端、IOS前端。</p>
</li>
</ol>
<h1 id="三、无状态服务"><a href="#三、无状态服务" class="headerlink" title="三、无状态服务"></a>三、无状态服务</h1><img data-src="https://img2018.cnblogs.com/blog/955092/201906/955092-20190605095519283-724193985.jpg" alt="" />

<p>对于无状态服务，首先说一下什么是状态：如果一个数据需要被多个服务共享，才能完成一笔交易，那么这个数据被称为状态。进而依赖这个状态的服务被称为有状态的服务，反之成为无状态服务。</p>
<p>这个无状态服务原则并不是说在微服务架构里不允许存在状态，表达的真实意思就是要把有状态的业务服务改变为无状态的计算类服务，那么状态数据也就相应的迁移到对应的&ldquo;有状态数据服务&rdquo;中。</p>
<p>场景说明：例如我们从前在本地内存中建立的数据缓存、Session缓存，到现在微服务架构中就应该把数据迁移到分布式缓存中存储，让业务服务变成一个无状态的计算节点。迁移后，就可以做到按需动态伸缩，微服务应用在运行时动态增删节点，就不再需要考虑缓存数据如何同步的问题。</p>
<h1 id="四、RestFul通讯风格"><a href="#四、RestFul通讯风格" class="headerlink" title="四、RestFul通讯风格"></a>四、RestFul通讯风格</h1><img data-src="https://img2018.cnblogs.com/blog/955092/201906/955092-20190605094944373-1205632199.jpg" alt="" />

<p>这里介绍一个&ldquo;无状态通讯原则&rdquo;-Restful通讯风格，它有许多优点：</p>
<ol>
<li><p>无状态协议HTTP，具备先天优势，扩展能力强，例如安全加密有成熟的https。</p>
</li>
<li><p>JSON报文序列化，轻量简单，人与机均可读，学习成本低，搜索引擎友好。</p>
</li>
<li><p>语言无关，各大热门语言都提供成熟的Restful API框架，相对一些其他RPC框架生态更加完善。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Springcloud微服务——基于security和jwt实现认证及鉴权服务</title>
    <url>/springcloud/%E5%9F%BA%E4%BA%8Esecurity%E5%92%8Cjwt%E5%AE%9E%E7%8E%B0%E8%AE%A4%E8%AF%81%E5%8F%8A%E9%89%B4%E6%9D%83%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<h1 id="一、需求"><a href="#一、需求" class="headerlink" title="一、需求"></a>一、需求</h1><ul>
<li>1、RESTfull风格的鉴权服务（路线相同的情况下根据请求方式鉴别访问权限）</li>
<li>2、包含用户、角色、权限</li>
<li>3、使用JWT最为token认证方式</li>
</ul>
<a id="more"></a>

<h1 id="二、知识点讲解"><a href="#二、知识点讲解" class="headerlink" title="二、知识点讲解"></a>二、知识点讲解</h1><h2 id="2-1-方案"><a href="#2-1-方案" class="headerlink" title="2.1 方案"></a>2.1 方案</h2><p>传统的单体应用体系下，应用是一个整体，一般针对所有的请求都会进行权限校验。请求一般会通过一个权限的拦截器进行权限的校验，在登录时将用户信息缓存到 session 中，后续访问则从缓存中获取用户信息</p>
<p>但在微服务架构下，一个应用会被拆分成若干个微应用，每个微应用都需要对访问进行鉴权，每个微应用都需要明确当前访问用户以及其权限。尤其当访问来源不只是浏览器，还包括其他服务的调用时，单体应用架构下的鉴权方式就不是特别合适了。因此在设计架构中，要考虑外部应用接入的场景、用户与服务的鉴权、服务与服务的鉴权等多种鉴权场景。</p>
<p>目前主流的方案由四种</p>
<h3 id="2-1-1-单点登录（SSO）"><a href="#2-1-1-单点登录（SSO）" class="headerlink" title="2.1.1 单点登录（SSO）"></a>2.1.1 单点登录（SSO）</h3><p>一次登入，多地使用。这种方案意味着每个面向用户的服务都必须与认证服务交互，进而产生大量琐碎的网络流量和重复的工作，当动辄数十个微应用时，这种方案的弊端会更加明显。</p>
<h3 id="2-1-2-分布式-Session-方案"><a href="#2-1-2-分布式-Session-方案" class="headerlink" title="2.1.2 分布式 Session 方案"></a>2.1.2 分布式 Session 方案</h3><p>借助reids或其他共享存储中，将用户认证的信息存储在其中，通常使用用户会话作为 key 来实现的简单分布式哈希映射。当用户访问微服务时，用户数据可以从共享存储中获取。在某些场景下，这种方案很不错，用户登录状态是不透明的。同时也是一个高可用且可扩展的解决方案。这种方案的缺点在于共享存储需要一定保护机制，因此需要通过安全链接来访问，这时解决方案的实现就通常具有相当高的复杂性了。</p>
<h3 id="2-1-3-客户端-Token-方案"><a href="#2-1-3-客户端-Token-方案" class="headerlink" title="2.1.3 客户端 Token 方案"></a>2.1.3 客户端 Token 方案</h3><p>令牌在客户端生成，由身份验证服务进行签名，并且必须包含足够的信息，以便可以在所有微服务中建立用户身份。令牌会附加到每个请求上，为微服务提供用户身份验证，这种解决方案的安全性相对较好，但身份验证注销是一个大问题，缓解这种情况的方法可以使用短期令牌和频繁检查认证服务等。对于客户端令牌的编码方案，Borsos 更喜欢使用 JSON Web Tokens（JWT），它足够简单且库支持程度也比较好。</p>
<h3 id="2-1-4-客户端-Token-与-API-网关结合"><a href="#2-1-4-客户端-Token-与-API-网关结合" class="headerlink" title="2.1.4 客户端 Token 与 API 网关结合"></a>2.1.4 客户端 Token 与 API 网关结合</h3><p>这个方案意味着所有请求都通过网关，从而有效地隐藏了微服务。 在请求时，网关将原始用户令牌转换为内部会话 ID 令牌。在这种情况下，注销就不是问题，因为网关可以在注销时撤销用户的令牌。</p>
<p>本文就采用方案4，实现微服务体系中用户鉴权及认证服务。</p>
<p>Token的实现方案业界有多套成熟的方案，这其中最主流的是JWT 和 Oauth2.0 两种方式。<br>下面就基于JWT的方式具体实现。</p>
<h1 id="SpringSecurity"><a href="#SpringSecurity" class="headerlink" title="SpringSecurity"></a>SpringSecurity</h1><ul>
<li><p>AuthenticationManager, 用户认证的管理类，所有的认证请求（比如login）都会通过提交一个token给AuthenticationManager的authenticate()方法来实现。当然事情肯定不是它来做，具体校验动作会由AuthenticationManager将请求转发给具体的实现类来做。根据实现反馈的结果再调用具体的Handler来给用户以反馈。</p>
</li>
<li><p>AuthenticationProvider, 认证的具体实现类，一个provider是一种认证方式的实现，比如提交的用户名密码我是通过和DB中查出的user记录做比对实现的，那就有一个DaoProvider；如果我是通过CAS请求单点登录系统实现，那就有一个CASProvider。按照Spring一贯的作风，主流的认证方式它都已经提供了默认实现，比如DAO、LDAP、CAS、OAuth2等。<br>前面讲了AuthenticationManager只是一个代理接口，真正的认证就是由AuthenticationProvider来做的。一个AuthenticationManager可以包含多个Provider，每个provider通过实现一个support方法来表示自己支持那种Token的认证。AuthenticationManager默认的实现类是ProviderManager。</p>
</li>
<li><p>UserDetailService, 用户认证通过Provider来做，所以Provider需要拿到系统已经保存的认证信息，获取用户信息的接口spring-security抽象成UserDetailService。虽然叫Service,但是我更愿意把它认为是我们系统里经常有的UserDao。</p>
</li>
<li><p>AuthenticationToken, 所有提交给AuthenticationManager的认证请求都会被封装成一个Token的实现，比如最容易理解的UsernamePasswordAuthenticationToken。</p>
</li>
<li><p>SecurityContext，当用户通过认证之后，就会为这个用户生成一个唯一的SecurityContext，里面包含用户的认证信息Authentication。通过SecurityContext我们可以获取到用户的标识Principle和授权信息GrantedAuthrity。在系统的任何地方只要通过SecurityHolder.getSecruityContext()就可以获取到SecurityContext。在Shiro中通过SecurityUtils.getSubject()到达同样的目的。</p>
</li>
</ul>
<h1 id="三、具体实现"><a href="#三、具体实现" class="headerlink" title="三、具体实现"></a>三、具体实现</h1><h2 id="3-1-业务流程"><a href="#3-1-业务流程" class="headerlink" title="3.1 业务流程"></a>3.1 业务流程</h2><ul>
<li>客户端调用登录接口，传入用户名密码。</li>
<li>服务端请求身份认证中心，确认用户名密码正确。</li>
<li>服务端创建JWT，返回给客户端。</li>
<li>客户端拿到 JWT，进行存储（可以存储在缓存中，也可以存储在数据库中，如果是浏览器，可以存储在 Cookie中）在后续请求中，在 HTTP 请求头中加上 JWT。</li>
<li>服务端校验 JWT，校验通过后，返回相关资源和数据。<h2 id="3-2-代码"><a href="#3-2-代码" class="headerlink" title="3.2 代码"></a>3.2 代码</h2>完整pom文件（项目结构为多模块）<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springcloud<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lhm<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>security<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--web 服务--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--security--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-security<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.jsonwebtoken<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jjwt<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--mybatis-plus--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--mybatis-plus日志--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>p6spy<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>p6spy<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- druid的starter --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- redis --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-pool2<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-redis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--JSON--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.38<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- StringUtils相关工具类jar包 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-lang3<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--  lombok  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="3-3-认证服务"><a href="#3-3-认证服务" class="headerlink" title="3.3 认证服务"></a>3.3 认证服务</h2><p><img data-src="https://img-blog.csdnimg.cn/20190522113953804.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JlY2F1c2VTeQ==,size_16,color_FFFFFF,t_70" alt=""><br>在登入方面，本次使用了security默认提供的表单登陆方式，因此直接从实现<br>UserDetailsService开始</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.exception.CommonException;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.AuthUserDetails;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.AuthUserPoJo;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.service.IUsersService;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.StringRedisTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UserDetails;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UserDetailsService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UsernameNotFoundException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> UserDetailsServiceImpl</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>  实现security提供的 用户信息获取接口  并按照业务增加redis 登陆限制</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2018/5/6 10:26</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDetailsServiceImpl</span> <span class="keyword">implements</span> <span class="title">UserDetailsService</span> </span>&#123;</span><br><span class="line">    <span class="comment">//登入重试时间</span></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;security.loginAfterTime&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> Integer loginAfterTime;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> StringRedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IUsersService iUsersService;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 实现用户信息查询方法 让DaoAuthenticationProvider 获取到数据库获中用户数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Date</span> 11:21 2019/5/6</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Param</span> [username]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> org.springframework.security.core.userdetails.UserDetails</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> UserDetails <span class="title">loadUserByUsername</span><span class="params">(String username)</span> <span class="keyword">throws</span> UsernameNotFoundException </span>&#123;</span><br><span class="line">        String flagKey = <span class="string">"loginFailFlag:"</span>+username;</span><br><span class="line">        String value = redisTemplate.opsForValue().get(flagKey);</span><br><span class="line">        <span class="keyword">if</span>(StringUtils.isNotBlank(value))&#123;</span><br><span class="line">            <span class="comment">//超过限制次数</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UsernameNotFoundException(<span class="string">"登录错误次数超过限制，请"</span>+loginAfterTime+<span class="string">"分钟后再试"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//查询用户信息</span></span><br><span class="line">        AuthUserPoJo authUserPoJo=iUsersService.findAuthUserByUsername(username);</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">null</span>==authUserPoJo)&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UsernameNotFoundException(<span class="string">"当前用户不存在"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(authUserPoJo.getRoleInfos()==<span class="keyword">null</span> || authUserPoJo.getRoleInfos().isEmpty())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UsernameNotFoundException(<span class="string">"当前用户无角色"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> AuthUserDetails(authUserPoJo);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>UserDetailsServiceImpl 最后返回一个拼装好的security用户对象，但为了实现自定义角色与权限管理需要对UserDetails进行重写。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.pojo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.UserConstant;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.entity.PermissionInfo;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.GrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.authority.SimpleGrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UserDetails;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Collection;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Exrickx</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AuthUserDetails</span> <span class="keyword">extends</span> <span class="title">AuthUserPoJo</span> <span class="keyword">implements</span> <span class="title">UserDetails</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">AuthUserDetails</span><span class="params">(AuthUserPoJo user)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (user != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.setUserName(user.getUserName());</span><br><span class="line">            <span class="keyword">this</span>.setPassWord(user.getPassWord());</span><br><span class="line">            <span class="keyword">this</span>.setStatus(user.getStatus());</span><br><span class="line">            <span class="keyword">this</span>.setRoleInfos(user.getRoleInfos());</span><br><span class="line">            <span class="keyword">this</span>.setPermissionInfos(user.getPermissionInfos());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将角色权限 放入GrantedAuthorit的自定义实现类MyGrantedAuthority中  为权限判定提供数据</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123;</span><br><span class="line"></span><br><span class="line">        List&lt;GrantedAuthority&gt; authorityList = <span class="keyword">new</span> ArrayList&lt;GrantedAuthority&gt;();</span><br><span class="line">        List&lt;PermissionInfo&gt; permissions = <span class="keyword">this</span>.getPermissionInfos();</span><br><span class="line">        <span class="keyword">if</span> (permissions != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (PermissionInfo permission : permissions) &#123;</span><br><span class="line">                GrantedAuthority grantedAuthority = <span class="keyword">new</span> MyGrantedAuthority(permission.getPath(), permission.getMethod());</span><br><span class="line">                authorityList.add(grantedAuthority);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> authorityList;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPassword</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getPassWord();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getUsername</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getUserName();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 账户是否过期</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isAccountNonExpired</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否禁用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isAccountNonLocked</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 密码是否过期</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isCredentialsNonExpired</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否启用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEnabled</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> UserConstant.USER_STATUS_NORMAL.equals(<span class="keyword">this</span>.getStatus()) ? <span class="keyword">true</span> : <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后DaoProvider会对比校验并执行相应的结果处理器</p>
<p>登入成功处理器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.handler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.AuthUserDetails;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResponseUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.TokenUtil;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.Authentication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.AuthenticationSuccessHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> LoginSuccessHandlerFilter</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 登陆认证成功处理过滤器</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2019/5/6 16:27</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginSuccessHandler</span> <span class="keyword">implements</span> <span class="title">AuthenticationSuccessHandler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> TokenUtil tokenUtil;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 用户认证成功后 生成token并返回</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Date</span> 8:50 2019/5/7</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Param</span> [request, response, authentication]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> void</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAuthenticationSuccess</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Authentication authentication)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">       AuthUserDetails authUserDetails=(AuthUserDetails)authentication.getPrincipal();<span class="comment">//从内存中获取当前认证用户信息</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建token</span></span><br><span class="line">        String accessToken = tokenUtil.createAccessJwtToken(authUserDetails);</span><br><span class="line">        String refreshToken = tokenUtil.createRefreshToken(authUserDetails);</span><br><span class="line"></span><br><span class="line">        HashMap&lt;String,String&gt; map=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(<span class="string">"accessToken"</span>,accessToken);</span><br><span class="line">        map.put(<span class="string">"refreshToken"</span>,refreshToken);</span><br><span class="line"></span><br><span class="line">        ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.OK,<span class="string">"登录成功"</span>,map));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>登入失败处理器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.handler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResponseUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.StringRedisTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.BadCredentialsException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.DisabledException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.AuthenticationException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UsernameNotFoundException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.AuthenticationFailureHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> LoginFailureHandler</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 登陆失败处理过滤器</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2019/5/7 9:05</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginFailureHandler</span> <span class="keyword">implements</span> <span class="title">AuthenticationFailureHandler</span> </span>&#123;</span><br><span class="line">    <span class="comment">//#限制用户登陆错误次数（次）</span></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;security.loginTimeLimit&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> Integer loginTimeLimit;</span><br><span class="line">    <span class="comment">//#错误超过次数后多少分钟后才能继续登录（分钟）</span></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;security.loginAfterTime&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> Integer loginAfterTime;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> StringRedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 用户登陆失败处理类  记录用户登陆错误次数</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Date</span> 9:12 2019/5/7</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Param</span> [request, response, e]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> void</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAuthenticationFailure</span><span class="params">(HttpServletRequest request, HttpServletResponse response, AuthenticationException e)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (e <span class="keyword">instanceof</span> UsernameNotFoundException || e <span class="keyword">instanceof</span> BadCredentialsException) &#123;</span><br><span class="line">            String username = request.getParameter(<span class="string">"username"</span>);</span><br><span class="line">            recordLoginTime(username);</span><br><span class="line">            String key = <span class="string">"loginTimeLimit:"</span> + username;</span><br><span class="line">            String value = redisTemplate.opsForValue().get(key);</span><br><span class="line">            <span class="keyword">if</span> (StringUtils.isBlank(value)) &#123;</span><br><span class="line">                value = <span class="string">"0"</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//获取已登录错误次数</span></span><br><span class="line">            <span class="keyword">int</span> loginFailTime = Integer.parseInt(value);</span><br><span class="line">            <span class="keyword">int</span> restLoginTime = loginTimeLimit - loginFailTime;</span><br><span class="line">            ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.BAD_REQUEST, <span class="string">"用户名或密码错误"</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> DisabledException) &#123;</span><br><span class="line">            ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.BAD_REQUEST, <span class="string">"账户被禁用，请联系管理员"</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.BAD_REQUEST, <span class="string">"登录失败"</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断用户登陆错误次数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">recordLoginTime</span><span class="params">(String username)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        String key = <span class="string">"loginTimeLimit:"</span> + username;</span><br><span class="line">        String flagKey = <span class="string">"loginFailFlag:"</span> + username;</span><br><span class="line">        String value = redisTemplate.opsForValue().get(key);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(value)) &#123;</span><br><span class="line">            value = <span class="string">"0"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//获取已登录错误次数</span></span><br><span class="line">        <span class="keyword">int</span> loginFailTime = Integer.parseInt(value) + <span class="number">1</span>;</span><br><span class="line">        redisTemplate.opsForValue().set(key, String.valueOf(loginFailTime), loginAfterTime, TimeUnit.MINUTES);</span><br><span class="line">        <span class="keyword">if</span> (loginFailTime &gt;= loginTimeLimit) &#123;</span><br><span class="line"></span><br><span class="line">            redisTemplate.opsForValue().set(flagKey, <span class="string">"fail"</span>, loginAfterTime, TimeUnit.MINUTES);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在登入的过程中会对用户的请求间隔时间及失败次数做记录。</p>
<h2 id="3-4-鉴权服务"><a href="#3-4-鉴权服务" class="headerlink" title="3.4 鉴权服务"></a>3.4 鉴权服务</h2><p>鉴权的过程分成了两个大的步骤</p>
<ul>
<li>第一对请求的路径、方法、头部信息进行判断，确认该请求是否需要鉴权<br>JWTAuthenticationFilter</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.filter;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONArray;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.IgnoredUrlsProperties;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.SecurityConstant;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.exception.CommonException;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.MyGrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResponseUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.SpringUtil;</span><br><span class="line"><span class="keyword">import</span> io.jsonwebtoken.Claims;</span><br><span class="line"><span class="keyword">import</span> io.jsonwebtoken.ExpiredJwtException;</span><br><span class="line"><span class="keyword">import</span> io.jsonwebtoken.Jwts;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.AuthenticationManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.UsernamePasswordAuthenticationToken;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.context.SecurityContextHolder;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.User;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.AuthenticationEntryPoint;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.www.BasicAuthenticationFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.AntPathMatcher;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.PathMatcher;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.FilterChain;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * JWT过滤器1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JWTAuthenticationFilter</span> <span class="keyword">extends</span> <span class="title">BasicAuthenticationFilter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JWTAuthenticationFilter</span><span class="params">(AuthenticationManager authenticationManager)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(authenticationManager);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JWTAuthenticationFilter</span><span class="params">(AuthenticationManager authenticationManager, AuthenticationEntryPoint authenticationEntryPoint)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(authenticationManager, authenticationEntryPoint);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doFilterInternal</span><span class="params">(HttpServletRequest request, HttpServletResponse response, FilterChain chain)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">        IgnoredUrlsProperties ignoredUrlsProperties= SpringUtil.getBean(<span class="string">"ignoredUrlsProperties"</span>, IgnoredUrlsProperties<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        String Requesturl=request.getRequestURI();</span><br><span class="line">        PathMatcher pathMatcher = <span class="keyword">new</span> AntPathMatcher();</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">null</span> != ignoredUrlsProperties)&#123;</span><br><span class="line">            <span class="keyword">for</span>(String url:ignoredUrlsProperties.getUrls())&#123;</span><br><span class="line">                <span class="keyword">if</span>(pathMatcher.match(url,Requesturl))&#123;</span><br><span class="line">                    chain.doFilter(request, response);</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取请求头</span></span><br><span class="line">        String header = request.getHeader(SecurityConstant.HEADER);</span><br><span class="line">        <span class="comment">//如果请求头中不存在 或  格式不对  则进入下个过滤器</span></span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(header) || !header.startsWith(SecurityConstant.TOKEN_SPLIT)) &#123;</span><br><span class="line">            chain.doFilter(request, response);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            UsernamePasswordAuthenticationToken authentication = getAuthentication(request, response);</span><br><span class="line">            SecurityContextHolder.getContext().setAuthentication(authentication);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.BAD_REQUEST, e.getMessage()));</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        chain.doFilter(request, response);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 对token进行解析认证</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Date</span> 11:11 2019/5/7</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Param</span> [request, response]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> org.springframework.security.authentication.UsernamePasswordAuthenticationToken</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> UsernamePasswordAuthenticationToken <span class="title">getAuthentication</span><span class="params">(HttpServletRequest request, HttpServletResponse response)</span> <span class="keyword">throws</span> CommonException </span>&#123;</span><br><span class="line"></span><br><span class="line">        String token = request.getHeader(SecurityConstant.HEADER);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isNotBlank(token)) &#123;</span><br><span class="line">            <span class="comment">// 解析token</span></span><br><span class="line">            Claims claims = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                claims = Jwts.parser()</span><br><span class="line">                        .setSigningKey(SecurityConstant.tokenSigningKey)</span><br><span class="line">                        .parseClaimsJws(token.replace(SecurityConstant.TOKEN_SPLIT, <span class="string">""</span>))</span><br><span class="line">                        .getBody();</span><br><span class="line"></span><br><span class="line">                <span class="comment">//获取用户名</span></span><br><span class="line">                String username = claims.getSubject();</span><br><span class="line"></span><br><span class="line">                <span class="comment">//获取权限</span></span><br><span class="line">                List&lt;MyGrantedAuthority&gt; authorities = <span class="keyword">new</span> ArrayList&lt;MyGrantedAuthority&gt;();</span><br><span class="line">                String authority = claims.get(SecurityConstant.AUTHORITIES).toString();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (StringUtils.isNotBlank(authority)) &#123;</span><br><span class="line">                    JSONArray list=JSONArray.parseArray(authority);</span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;list.size();i++)&#123;</span><br><span class="line">                        JSONObject jsonObject=list.getJSONObject(i);</span><br><span class="line">                        authorities.add(<span class="keyword">new</span> MyGrantedAuthority(jsonObject.getString(<span class="string">"path"</span>),jsonObject.getString(<span class="string">"method"</span>)));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (StringUtils.isNotBlank(username)) &#123;</span><br><span class="line">                    <span class="comment">//此处password不能为null</span></span><br><span class="line">                    User principal = <span class="keyword">new</span> User(username, <span class="string">""</span>, authorities);</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> UsernamePasswordAuthenticationToken(principal, <span class="keyword">null</span>, authorities);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ExpiredJwtException e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> CommonException(ResultCode.BAD_REQUEST, <span class="string">"登录已失效，请重新登录"</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> CommonException(ResultCode.BAD_REQUEST, <span class="string">"解析token错误"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>第二判断当前请求token是否有权访问当前请求地址<br>MyFilterSecurityInterceptor</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.filter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.manager.MyAccessDecisionManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.SecurityMetadataSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.intercept.AbstractSecurityInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.intercept.InterceptorStatusToken;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.FilterInvocation;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.access.intercept.FilterInvocationSecurityMetadataSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.*;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 权限管理过滤器2</span></span><br><span class="line"><span class="comment"> * 监控用户行为</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Exrickx</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFilterSecurityInterceptor</span> <span class="keyword">extends</span> <span class="title">AbstractSecurityInterceptor</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> FilterInvocationSecurityMetadataSource securityMetadataSource;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMyAccessDecisionManager</span><span class="params">(MyAccessDecisionManager myAccessDecisionManager)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.setAccessDecisionManager(myAccessDecisionManager);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig filterConfig)</span> <span class="keyword">throws</span> ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest request, ServletResponse response, FilterChain chain)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">        FilterInvocation fi = <span class="keyword">new</span> FilterInvocation(request, response, chain);</span><br><span class="line">        invoke(fi);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//fi里面有一个被拦截的url</span></span><br><span class="line">    <span class="comment">//里面调用MyInvocationSecurityMetadataSource的getAttributes(Object object)这个方法获取fi对应的所有权限</span></span><br><span class="line">    <span class="comment">//再调用MyAccessDecisionManager的decide方法来校验用户的权限是否足够</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(FilterInvocation fi)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">        InterceptorStatusToken token = <span class="keyword">super</span>.beforeInvocation(fi);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fi.getChain().doFilter(fi.getRequest(), fi.getResponse());</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">super</span>.afterInvocation(token, <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Class&lt;?&gt; getSecureObjectClass() &#123;</span><br><span class="line">        <span class="keyword">return</span> FilterInvocation<span class="class">.<span class="keyword">class</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SecurityMetadataSource <span class="title">obtainSecurityMetadataSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.securityMetadataSource;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>具体的处理会放到MySecurityMetadataSource中去判断，不过我这里做了个小优化，将处理权限的业务统一放到了MyAccessDecisionManager下，减少点性能开销</p>
<p>MySecurityMetadataSource</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.manager;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.ConfigAttribute;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.SecurityConfig;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.access.intercept.FilterInvocationSecurityMetadataSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Collection;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 权限资源管理器</span></span><br><span class="line"><span class="comment"> * 为权限决断器提供支持</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Exrickx</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySecurityMetadataSource</span> <span class="keyword">implements</span> <span class="title">FilterInvocationSecurityMetadataSource</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 此方法是为了判定用户请求的url 是否在权限表中，如果在权限表中，则返回给 decide 方法，用来判定用户是否有此权限。如果不在权限表中则放行。</span></span><br><span class="line"><span class="comment">     * 因为每一次来了请求，都先要匹配一下权限表中的信息是不是包含此url，</span></span><br><span class="line"><span class="comment">     * 因此优化一下，对url直接拦截，不管请求的url 是什么都直接拦截，然后在MyAccessDecisionManager的decide 方法中做拦截还是放行的决策。</span></span><br><span class="line"><span class="comment">     * 所以此方法的返回值不能返回 null 此处随便返回一下。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> o</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IllegalArgumentException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Collection&lt;ConfigAttribute&gt; <span class="title">getAttributes</span><span class="params">(Object o)</span> <span class="keyword">throws</span> IllegalArgumentException </span>&#123;</span><br><span class="line"></span><br><span class="line">        Collection&lt;ConfigAttribute&gt; co = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        co.add(<span class="keyword">new</span> SecurityConfig(<span class="string">"null"</span>));</span><br><span class="line">        <span class="keyword">return</span> co;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Collection&lt;ConfigAttribute&gt; <span class="title">getAllConfigAttributes</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">supports</span><span class="params">(Class&lt;?&gt; aClass)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>MyAccessDecisionManager</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.manager;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.MyGrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.AccessDecisionManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.AccessDeniedException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.ConfigAttribute;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.InsufficientAuthenticationException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.Authentication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.GrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.FilterInvocation;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.util.matcher.AntPathRequestMatcher;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> java.util.Collection;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> MyAccessDecisionManager</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 权限最终判断器</span></span><br><span class="line"><span class="comment"> *  * 判断用户拥有的角色是否有资源访问权限</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2019/5/7 10:44</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyAccessDecisionManager</span> <span class="keyword">implements</span> <span class="title">AccessDecisionManager</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//decide 方法是判定是否拥有权限的决策方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">decide</span><span class="params">(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; configAttributes)</span> <span class="keyword">throws</span> AccessDeniedException, InsufficientAuthenticationException </span>&#123;</span><br><span class="line">        HttpServletRequest request = ((FilterInvocation) object).getHttpRequest();</span><br><span class="line">        String url, method;</span><br><span class="line">        AntPathRequestMatcher matcher;</span><br><span class="line">        <span class="keyword">for</span> (GrantedAuthority ga : authentication.getAuthorities()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (ga <span class="keyword">instanceof</span> MyGrantedAuthority) &#123;</span><br><span class="line">                MyGrantedAuthority urlGrantedAuthority = (MyGrantedAuthority) ga;</span><br><span class="line">                url = urlGrantedAuthority.getPermissionUrl();</span><br><span class="line">                method = urlGrantedAuthority.getMethod();</span><br><span class="line">                matcher = <span class="keyword">new</span> AntPathRequestMatcher(url);</span><br><span class="line">                <span class="keyword">if</span> (matcher.matches(request)) &#123;</span><br><span class="line">                    <span class="comment">//当权限表权限的method为ALL时表示拥有此路径的所有请求方式权利。</span></span><br><span class="line">                    <span class="keyword">if</span> (method.equals(request.getMethod()) || <span class="string">"ALL"</span>.equals(method)) &#123;</span><br><span class="line">                        <span class="keyword">return</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> AccessDeniedException(<span class="string">"您没有访问权限"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> AccessDeniedException(<span class="string">"鉴权出错"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">supports</span><span class="params">(ConfigAttribute attribute)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">supports</span><span class="params">(Class&lt;?&gt; clazz)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>decide（）方法中的MyGrantedAuthority是我自定义的权限对象 因为原有的SimpleGrantedAuthority类只有一个属性，无法完成RESTfull风格的请求。<br>MyGrantedAuthority</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.pojo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.GrantedAuthority;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> MyGrantedAuthority</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2018/5/7 10:39</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyGrantedAuthority</span> <span class="keyword">implements</span> <span class="title">GrantedAuthority</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String url;</span><br><span class="line">    <span class="keyword">private</span> String method;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPermissionUrl</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> url;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPermissionUrl</span><span class="params">(String permissionUrl)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.url = permissionUrl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> method;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMethod</span><span class="params">(String method)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.method = method;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyGrantedAuthority</span><span class="params">(String url, String method)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.url = url;</span><br><span class="line">        <span class="keyword">this</span>.method = method;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getAuthority</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.url + <span class="string">";"</span> + <span class="keyword">this</span>.method;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>最后将我们自定义的类全部注入到security提供的配置文件类中，具体的配置我都用注解表明了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.IgnoredUrlsProperties;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.filter.JWTAuthenticationFilter;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.filter.MyFilterSecurityInterceptor;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.filter.WebSecurityCorsFilter;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.handler.RestAccessDeniedHandler;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.service.impl.UserDetailsServiceImpl;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.HttpMethod;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.annotation.web.builders.HttpSecurity;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.annotation.web.configurers.ExpressionUrlAuthorizationConfigurer;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.http.SessionCreationPolicy;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.access.channel.ChannelProcessingFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.access.intercept.FilterSecurityInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.AuthenticationFailureHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.AuthenticationSuccessHandler;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Security 核心配置类</span></span><br><span class="line"><span class="comment"> * 开启控制权限至Controller</span></span><br><span class="line"><span class="comment"> * @author Exrickx</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WebSecurityConfig</span> <span class="keyword">extends</span> <span class="title">WebSecurityConfigurerAdapter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IgnoredUrlsProperties ignoredUrlsProperties;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserDetailsServiceImpl userDetailsService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> AuthenticationSuccessHandler successHandler;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> AuthenticationFailureHandler failHandler;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RestAccessDeniedHandler accessDeniedHandler;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> MyFilterSecurityInterceptor myFilterSecurityInterceptor;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(AuthenticationManagerBuilder auth)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        auth.userDetailsService(userDetailsService).passwordEncoder(<span class="keyword">new</span> BCryptPasswordEncoder());</span><br><span class="line">        <span class="comment">//密码加密使用 Spring Security 提供的BCryptPasswordEncoder.encode(user.getRawPassword().trim())</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(HttpSecurity http)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ExpressionUrlAuthorizationConfigurer&lt;HttpSecurity&gt;.ExpressionInterceptUrlRegistry registry = http</span><br><span class="line">                .authorizeRequests();</span><br><span class="line">        <span class="comment">//除配置文件忽略路径其它所有请求都需经过认证和授权</span></span><br><span class="line">        <span class="keyword">for</span>(String url:ignoredUrlsProperties.getUrls())&#123;</span><br><span class="line">            registry.antMatchers(url).permitAll();</span><br><span class="line">        &#125;</span><br><span class="line">        registry.antMatchers(HttpMethod.OPTIONS).permitAll()</span><br><span class="line">                .and()</span><br><span class="line">                <span class="comment">//表单登录方式</span></span><br><span class="line">                .formLogin()</span><br><span class="line">                .loginPage(<span class="string">"/login/needLogin"</span>)</span><br><span class="line">                <span class="comment">//登录需要经过的url请求</span></span><br><span class="line">                .loginProcessingUrl(<span class="string">"/api/v1/auth/login"</span>)</span><br><span class="line">                .usernameParameter(<span class="string">"username"</span>)</span><br><span class="line">                .passwordParameter(<span class="string">"password"</span>)</span><br><span class="line">                .permitAll()</span><br><span class="line">                <span class="comment">//成功处理类</span></span><br><span class="line">                .successHandler(successHandler)</span><br><span class="line">                <span class="comment">//失败</span></span><br><span class="line">                .failureHandler(failHandler)</span><br><span class="line">                .and()</span><br><span class="line">                .logout()</span><br><span class="line">                .permitAll()</span><br><span class="line">                .and()</span><br><span class="line">                .authorizeRequests()</span><br><span class="line">                <span class="comment">//任何请求</span></span><br><span class="line">                .anyRequest()</span><br><span class="line">                <span class="comment">//需要身份认证</span></span><br><span class="line">                .authenticated()</span><br><span class="line">                .and()</span><br><span class="line">                <span class="comment">//关闭跨站请求防护</span></span><br><span class="line">                .csrf().disable()</span><br><span class="line">                <span class="comment">//前后端分离采用JWT 不需要session</span></span><br><span class="line">                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)</span><br><span class="line">                .and()</span><br><span class="line">                <span class="comment">//自定义权限拒绝处理类</span></span><br><span class="line">                .exceptionHandling().accessDeniedHandler(accessDeniedHandler)</span><br><span class="line">                .and()</span><br><span class="line">                <span class="comment">//添加自定义权限过滤器</span></span><br><span class="line">                .addFilterBefore(<span class="keyword">new</span> WebSecurityCorsFilter(), ChannelProcessingFilter<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">                .<span class="title">addFilterBefore</span>(<span class="title">myFilterSecurityInterceptor</span>, <span class="title">FilterSecurityInterceptor</span>.<span class="title">class</span>)</span></span><br><span class="line"><span class="class">                //添加<span class="title">JWT</span>过滤器 除/<span class="title">login</span>其它请求都需经过此过滤器</span></span><br><span class="line"><span class="class">                .<span class="title">addFilter</span>(<span class="title">new</span> <span class="title">JWTAuthenticationFilter</span>(<span class="title">authenticationManager</span>()))</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>双网卡路由设置</title>
    <url>/system/%E5%8F%8C%E7%BD%91%E5%8D%A1%E8%B7%AF%E7%94%B1%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="windows"><a href="#windows" class="headerlink" title="windows"></a>windows</h1><h2 id="1-查看路由"><a href="#1-查看路由" class="headerlink" title="1. 查看路由"></a>1. 查看路由</h2><p>如果按正常的设置方法设置每块网卡的ip地址和网关，再cmd下使用route print查看时会看到<br>即指向0.0.0.0的有两个网关，这样就会出现路由冲突，两个网络都不能访问。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ route <span class="built_in">print</span></span><br><span class="line">永久路由:</span><br><span class="line">  网络地址          网络掩码  网关地址  跃点数</span><br><span class="line">          0.0.0.0          0.0.0.0     192.168.31.1     默认</span><br><span class="line">          0.0.0.0          0.0.0.0      192.168.0.1     默认</span><br></pre></td></tr></table></figure>
<h2 id="2-修改路由策略"><a href="#2-修改路由策略" class="headerlink" title="2. 修改路由策略"></a>2. 修改路由策略</h2><p>如何实现同时访问两个网络？那要用到route命令</p>
<ul>
<li><p>第一步：route delete 0.0.0.0     “删除所有0.0.0.0的路由”</p>
</li>
<li><p>第二步：route add -p 0.0.0.0 mask 0.0.0.0 192.168.1.1     “添加0.0.0.0网络路由”这个是主要的,意思就是你可以上外网.</p>
</li>
<li><p>第三步：route add -p 172.23.0.0 mask 255.0.0.0 172.23.1.1    “添加172.23.0.0网络路由”，注意mask为255.0.0.0   ，而不是255.255.255.0 ，这样内部的多网段才可用。</p>
</li>
</ul>
<p>route add -p 添加静态路由,即重启后，路由不会丢失</p>
<h1 id="Linux-Deepin"><a href="#Linux-Deepin" class="headerlink" title="Linux(Deepin)"></a>Linux(Deepin)</h1><h2 id="1-查看"><a href="#1-查看" class="headerlink" title="1. 查看"></a>1. 查看</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ route</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">default         XiaoQiang       0.0.0.0         UG    600    0        0 wlp3s0</span><br><span class="line">default         192.168.0.1     0.0.0.0         UG    20100  0        0 enp0s31f6</span><br><span class="line">192.168.0.0     0.0.0.0         255.255.255.0   U     100    0        0 enp0s31f6</span><br><span class="line">192.168.31.0    0.0.0.0         255.255.255.0   U     600    0        0 wlp3s0</span><br></pre></td></tr></table></figure>
<h2 id="2-修改路由"><a href="#2-修改路由" class="headerlink" title="2. 修改路由"></a>2. 修改路由</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除有线网卡路由</span></span><br><span class="line">route del -net default netmask 0.0.0.0 dev enp0s31f6</span><br><span class="line">route del -net 192.168.0.0 netmask 0.0.0.0 dev enp0s31f6</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添一条路由</span></span><br><span class="line"></span><br><span class="line">route add -net 192.168.0.0 netmask 255.255.255.0 gw 192.168.0.1 dev enp0s31f6</span><br><span class="line"></span><br><span class="line"><span class="comment">#只要访问192.168.0.0  都从192.168.0.1走.</span></span><br></pre></td></tr></table></figure>
<p>补充：由于重启之后路由会恢复，所以我们把它放配置文件中：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/NetworkManager/dispatcher.d/02-myroutes</span><br></pre></td></tr></table></figure>
<p>里面写：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#！/bin/bash</span></span><br><span class="line"></span><br><span class="line">route del -net default netmask 0.0.0.0 dev enp0s31f6</span><br><span class="line"></span><br><span class="line">route add -net 192.168.0.0 netmask 255.255.255.0 gw 192.168.0.1 dev enp0s31f6</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>Google Guava</title>
    <url>/third-tools/Goole-Guava/</url>
    <content><![CDATA[<ul>
<li><a href="https://github.com/google/guava/wiki/CachesExplained#population" target="_blank" rel="noopener">Guava 源码</a></li>
</ul>
<a id="more"></a>
<hr>
<h2 id="pom依赖"><a href="#pom依赖" class="headerlink" title="pom依赖"></a>pom依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.guava<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">version</span>&gt;</span>13.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="一、缓存相关"><a href="#一、缓存相关" class="headerlink" title="一、缓存相关"></a>一、缓存相关</h2><p>如果服务上要使用本地缓存，可以考虑使用guava框架。Guava Cache与ConcurrentMap很相似，但也不完全一样。最基本的区别是ConcurrentMap会一直保存所有添加的元素，直到显式地移除。相对地，Guava Cache为了限制内存占用，通常都设定为自动回收元素。在某些场景下，尽管LoadingCache 不回收元素，它也是很有用的，因为它会自动加载缓存。</p>
<h3 id="Guava-Cache适用于："><a href="#Guava-Cache适用于：" class="headerlink" title="Guava Cache适用于："></a>Guava Cache适用于：</h3><ul>
<li>你愿意消耗一些内存空间来提升速度。</li>
<li>你预料到某些键会被查询一次以上。</li>
<li>缓存中存放的数据总量不会超出内存容量。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private Cache&lt;String, UserAuthTokenRecord&gt; localCache &#x3D; CacheBuilder.newBuilder().maximumSize(200000)</span><br><span class="line">           .initialCapacity(100000).expireAfterWrite(30, TimeUnit.SECONDS).&lt;String, UserAuthTokenRecord&gt;build();</span><br></pre></td></tr></table></figure>

<h2 id="缓存回收"><a href="#缓存回收" class="headerlink" title="缓存回收"></a>缓存回收</h2><ul>
<li><h3 id="基本容量的回收"><a href="#基本容量的回收" class="headerlink" title="基本容量的回收"></a>基本容量的回收</h3><p>1）设置了初始值和最大容量上限，如果逼近容量上限，就会触发回收机制。</p>
</li>
<li><h3 id="定时回收"><a href="#定时回收" class="headerlink" title="定时回收"></a>定时回收</h3><p>  1）expireAfterAccess(long, TimeUnit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于大小回收一样。</p>
<p>  2）expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。</p>
</li>
<li><h3 id="基于引用的回收"><a href="#基于引用的回收" class="headerlink" title="基于引用的回收"></a>基于引用的回收</h3></li>
</ul>
<h2 id="二、常用的工具类"><a href="#二、常用的工具类" class="headerlink" title="二、常用的工具类"></a>二、常用的工具类</h2><h3 id="1-创建一个集合"><a href="#1-创建一个集合" class="headerlink" title="1.创建一个集合"></a>1.创建一个集合</h3><p>com.google.common.collect.Lists.newArrayList(E… elements)</p>
<h3 id="2-创建指定容量大小的集合"><a href="#2-创建指定容量大小的集合" class="headerlink" title="2.创建指定容量大小的集合"></a>2.创建指定容量大小的集合</h3><p>注：避免使用过程中，容量不足引发的扩容带来的性能损耗。</p>
<p>com.google.common.collect.Lists.newArrayListWithCapacity(int)</p>
<p>创建指定大小的的List；</p>
<p>com.google.common.collect.Maps.newHashMapWithExpectedSize(int)</p>
<p>创建指定大小的的Map；</p>
<h3 id="3-连接器-Joiner"><a href="#3-连接器-Joiner" class="headerlink" title="3.连接器[Joiner]"></a>3.连接器[Joiner]</h3><p>用分隔符把字符串序列连接起来也可能会遇上不必要的麻烦。如果字符串序列中含有null，那连接操作会更难。Fluent风格的Joiner让连接字符串更简单。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Joiner joiner &#x3D; Joiner.on(&quot;; &quot;).skipNulls();</span><br><span class="line">return joiner.join(&quot;Harry&quot;, null, &quot;Ron&quot;, &quot;Hermione&quot;);</span><br></pre></td></tr></table></figure>

<p>上述代码返回”Harry; Ron; Hermione”。另外，useForNull(String)方法可以给定某个字符串来替换null，而不像skipNulls()方法是直接忽略null。</p>
<p>Joiner也可以用来连接对象类型，在这种情况下，它会把对象的toString()值连接起来。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Joiner.on(&quot;,&quot;).join(Arrays.asList(1, 5, 7)); &#x2F;&#x2F; returns &quot;1,5,7&quot;</span><br></pre></td></tr></table></figure>

<p>警告：joiner实例总是不可变的。用来定义joiner目标语义的配置方法总会返回一个新的joiner实例。这使得joiner实例都是线程安全的，你可以将其定义为static final常量。</p>
<h3 id="4-拆分器-Splitter"><a href="#4-拆分器-Splitter" class="headerlink" title="4.拆分器[Splitter]"></a>4.拆分器[Splitter]</h3><p>JDK内建的字符串拆分工具有一些古怪的特性。比如，String.split悄悄丢弃了尾部的分隔符。 问题：”,a,,b,”.split(“,”)返回？</p>
<p>“”, “a”, “”, “b”, “”</p>
<p>null, “a”, null, “b”, null</p>
<p>“a”, null, “b”</p>
<p>“a”, “b”</p>
<p>以上都不对，””, “a”, “”, “b”。只有尾部的空字符串被忽略了。 Splitter使用令人放心的、直白的流畅API模式对这些混乱的特性作了完全的掌控。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Splitter.on(&#39;,&#39;)</span><br><span class="line">        .trimResults()</span><br><span class="line">        .omitEmptyStrings()</span><br><span class="line">        .split(&quot;foo,bar,,   qux&quot;);</span><br></pre></td></tr></table></figure>

<p>上述代码返回Iterable<String>，其中包含”foo”、”bar”和”qux”。Splitter可以被设置为按照任何模式、字符、字符串或字符匹配器拆分。</p>
<p><strong>拆分器工厂</strong></p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
<th>范例</th>
</tr>
</thead>
<tbody><tr>
<td>Splitter.on(char)</td>
<td>按单个字符拆分</td>
<td>Splitter.on(‘;’)</td>
</tr>
<tr>
<td>Splitter.on(CharMatcher)</td>
<td>按字符匹配器拆分</td>
<td>Splitter.on(CharMatcher.BREAKING_WHITESPACE)</td>
</tr>
<tr>
<td>Splitter.on(String)</td>
<td>按字符串拆分</td>
<td>Splitter.on(“,   “)</td>
</tr>
<tr>
<td>Splitter.on(Pattern)Splitter.onPattern(String)</td>
<td>按正则表达式拆分</td>
<td>Splitter.onPattern(“\r?\n”)</td>
</tr>
<tr>
<td>Splitter.fixedLength(int)</td>
<td>按固定长度拆分；最后一段可能比给定长度短，但不会为空。</td>
<td>Splitter.fixedLength(3)</td>
</tr>
</tbody></table>
<p><strong>拆分器修饰符</strong></p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>omitEmptyStrings()</td>
<td>从结果中自动忽略空字符串</td>
</tr>
<tr>
<td>trimResults()</td>
<td>移除结果字符串的前导空白和尾部空白</td>
</tr>
<tr>
<td>trimResults(CharMatcher)</td>
<td>给定匹配器，移除结果字符串的前导匹配字符和尾部匹配字符</td>
</tr>
<tr>
<td>limit(int)</td>
<td>限制拆分出的字符串数量</td>
</tr>
</tbody></table>
<p>如果你想要拆分器返回List，只要使用Lists.newArrayList(splitter.split(string))或类似方法。 警告：splitter实例总是不可变的。用来定义splitter目标语义的配置方法总会返回一个新的splitter实例。这使得splitter实例都是线程安全的，你可以将其定义为static final常量。</p>
<p><br><br></p>
<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p><a href="http://ifeve.com/google-guava-cachesexplained" target="_blank" rel="noopener">http://ifeve.com/google-guava-cachesexplained/</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>HttpClient</title>
    <url>/third-tools/HttpClient/</url>
    <content><![CDATA[<ul>
<li><a href="http://hc.apache.org/httpcomponents-client-4.5.x/index.html" target="_blank" rel="noopener">apache官网</a></li>
<li><a href="http://hc.apache.org/httpcomponents-client-4.5.x/httpclient/apidocs/index.html" target="_blank" rel="noopener">httpcomponents-client-4.5.x的接口文档</a></li>
<li><a href="https://github.com/aalansehaiyang/httpclient-example" target="_blank" rel="noopener">一些github代码案例</a></li>
</ul>
<a id="more"></a>
<p><strong>简介：</strong></p>
<p>HttpClient是Apache Jakarta Common下的子项目，用来提供高效的、最新的、功能丰富的支持HTTP协议的客户端编程工具包，并且它支持HTTP协议最新的版本和建议</p>
<p><strong>特性：</strong></p>
<ul>
<li>基于标准的java语言。实现了Http1.0和Http1.1</li>
<li>以可扩展的面向对象的结构实现了Http全部的方法（GET, POST, PUT, DELETE, HEAD, OPTIONS, and TRACE）。</li>
<li>支持HTTPS协议</li>
<li>连接管理器支持多线程应用。支持设置最大连接数，同时支持设置每个主机的最大连接数，发现并关闭过期的连接。</li>
<li>自动处理Set-Cookie中的Cookie。</li>
<li>Request的输出流可以避免流中内容直接缓冲到socket服务器。</li>
<li>Response的输入流可以有效的从socket服务器直接读取相应内容。</li>
<li>在http1.0和http1.1中利用KeepAlive保持持久连接。</li>
<li>直接获取服务器发送的response 响应状态和 headers。</li>
<li>设置连接超时的能力。</li>
</ul>
<p><strong>pom依赖：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.squareup.okhttp<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>okhttp<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	 <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.httpcomponents<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	 <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>httpclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	 <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.5.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>


<p><strong>代码案例：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// http协议通讯工具类</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.Charset;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.NameValuePair;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.HttpClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.config.RequestConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.entity.UrlEncodedFormEntity;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.methods.CloseableHttpResponse;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.methods.HttpPost;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.client.CloseableHttpClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.client.HttpClients;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.conn.PoolingHttpClientConnectionManager;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.message.BasicNameValuePair;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.util.EntityUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HttpServer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> HttpClient <span class="title">createHttpClient</span><span class="params">(<span class="keyword">int</span> maxTotal, <span class="keyword">int</span> maxPerRoute, <span class="keyword">int</span> socketTimeout, <span class="keyword">int</span> connectTimeout,</span></span></span><br><span class="line"><span class="function"><span class="params">                                              <span class="keyword">int</span> connectionRequestTimeout)</span> </span>&#123;</span><br><span class="line">        RequestConfig defaultRequestConfig = RequestConfig.custom().setSocketTimeout(socketTimeout).setConnectTimeout(connectTimeout).setConnectionRequestTimeout(connectionRequestTimeout).build();</span><br><span class="line">        PoolingHttpClientConnectionManager cm = <span class="keyword">new</span> PoolingHttpClientConnectionManager();</span><br><span class="line">        cm.setMaxTotal(maxTotal);</span><br><span class="line">        cm.setDefaultMaxPerRoute(maxPerRoute);</span><br><span class="line">        CloseableHttpClient httpClient = HttpClients.custom().setConnectionManager(cm).setDefaultRequestConfig(defaultRequestConfig).build();</span><br><span class="line">        <span class="keyword">return</span> httpClient;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 发送post请求</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> url 请求地址</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> params 请求参数</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> encoding 编码</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">sendPost</span><span class="params">(HttpClient httpClient, String url, Map&lt;String, String&gt; params, String cookie,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  Charset encoding)</span> </span>&#123;</span><br><span class="line">        String resp = <span class="string">""</span>;</span><br><span class="line">        HttpPost httpPost = <span class="keyword">new</span> HttpPost(url);</span><br><span class="line">        <span class="keyword">if</span> (params != <span class="keyword">null</span> &amp;&amp; params.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            List&lt;NameValuePair&gt; formParams = <span class="keyword">new</span> ArrayList&lt;NameValuePair&gt;();</span><br><span class="line">            Iterator&lt;Map.Entry&lt;String, String&gt;&gt; itr = params.entrySet().iterator();</span><br><span class="line">            <span class="keyword">while</span> (itr.hasNext()) &#123;</span><br><span class="line">                Map.Entry&lt;String, String&gt; entry = itr.next();</span><br><span class="line">                formParams.add(<span class="keyword">new</span> BasicNameValuePair(entry.getKey(), entry.getValue()));</span><br><span class="line">            &#125;</span><br><span class="line">            UrlEncodedFormEntity postEntity = <span class="keyword">new</span> UrlEncodedFormEntity(formParams, encoding);</span><br><span class="line">            httpPost.setEntity(postEntity);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        httpPost.setHeader(<span class="string">"Cookie"</span>, cookie);</span><br><span class="line">        CloseableHttpResponse response = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            response = (CloseableHttpResponse) httpClient.execute(httpPost);</span><br><span class="line">            resp = EntityUtils.toString(response.getEntity(), encoding);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// String setCookie = response.getFirstHeader("Set-Cookie").getValue();</span></span><br><span class="line">            <span class="comment">// System.out.println("setCookie=" + setCookie);</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (response != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    response.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                    <span class="comment">// log</span></span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//测试类，访问HZ某网站</span></span><br><span class="line"></span><br><span class="line">HttpClient httpClient = HttpServer.createHttpClient(<span class="number">10</span>, <span class="number">10</span>, <span class="number">4000</span>, <span class="number">4000</span>, <span class="number">4000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//请求cookie,为了与验证码绑定（注意：分号要是英文格式）</span></span><br><span class="line">String cookie = <span class="string">"cust_type=2;JSESSIONID=1042CD46231F265585CE3D8D105741CD;_gscu_1827457641=573266013u4vos16"</span>;</span><br><span class="line"><span class="comment">//验证码</span></span><br><span class="line">String code = <span class="string">"1674"</span>; </span><br><span class="line"></span><br><span class="line">String url = <span class="string">"http://www.hzgjj.gov.cn:8080/WebAccounts/userLogin.do"</span>;</span><br><span class="line">Map&lt;String, String&gt; params = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">params.put(<span class="string">"cust_no"</span>, <span class="string">"用户名"</span>);</span><br><span class="line">params.put(<span class="string">"password"</span>, <span class="string">"密码"</span>);</span><br><span class="line">params.put(<span class="string">"validate_code"</span>, code);</span><br><span class="line">params.put(<span class="string">"user_type"</span>, <span class="string">"3"</span>);</span><br><span class="line">params.put(<span class="string">"cust_type"</span>, <span class="string">"2"</span>);</span><br><span class="line"></span><br><span class="line">String result = HttpServer.sendPost(httpClient, url, params, cookie, <span class="keyword">null</span>);</span><br></pre></td></tr></table></figure>


<p>参考资料：</p>
<p><a href="http://hc.apache.org/status.html" target="_blank" rel="noopener">http://hc.apache.org/status.html</a></p>
<p><a href="http://blog.csdn.net/wangpeng047/article/details/19624529" target="_blank" rel="noopener">http://blog.csdn.net/wangpeng047/article/details/19624529</a></p>
<p><a href="https://www.ibm.com/developerworks/cn/opensource/os-httpclient/" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/opensource/os-httpclient/</a></p>
<p><a href="https://hc.apache.org/httpcomponents-client-ga/" target="_blank" rel="noopener">https://hc.apache.org/httpcomponents-client-ga/</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Javassist</title>
    <url>/third-tools/Javassist/</url>
    <content><![CDATA[<ul>
<li><a href="https://github.com/jboss-javassist/javassist/" target="_blank" rel="noopener">源代码</a></li>
<li><a href="http://www.javassist.org/" target="_blank" rel="noopener">官网</a></li>
</ul>
<a id="more"></a>
<ul>
<li><a href="https://blog.csdn.net/itomge/article/details/7671294" target="_blank" rel="noopener">webx—javassist动态创建class文件</a></li>
<li><a href="https://www.jianshu.com/p/43424242846b" target="_blank" rel="noopener">Javassist 使用指南（一）</a></li>
<li><a href="https://www.jianshu.com/p/b9b3ff0e1bf8" target="_blank" rel="noopener">Javassist 使用指南（二）</a></li>
<li><a href="https://www.jianshu.com/p/7803ffcc81c8" target="_blank" rel="noopener">Javassist 使用指南（三）</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Quartz</title>
    <url>/third-tools/Quartz/</url>
    <content><![CDATA[<h2 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h2><ul>
<li>开源的任务调度框架，提供了强大的调度机制</li>
<li>接口扩展性好，接入简单</li>
<li>支持调度运行环境的持久化机制</li>
</ul>
<h2 id="基础结构："><a href="#基础结构：" class="headerlink" title="基础结构："></a>基础结构：</h2><ul>
<li><p>Job</p>
<p> 是一个接口，内部只有一个方法  public void execute(JobExecutionContext context) throws JobExecutionException，开发者在方法体内实现自己的业务逻辑，JobExecutionContext提供了调度上下文的各种信息。</p>
</li>
<li><p>JobDetail</p>
<p>描述Job的实现类及其他静态信息，如Job名称、描述、关联监听器等信息，运行时通过newInstance()的反射机制实例化Job</p>
</li>
<li><p>Trigger</p>
<p>描述触发Job执行的时间规则，主要有SimpleTrigger和CronTrigger两个子类。当仅需触发一次或以固定时间间隔周期执行，SimpleTrigger是最合适的。如果是定义各种复杂的时间规则，CronTrigger比较合适。</p>
</li>
<li><p>Scheduler</p>
<p>表示Quartz的独立运行容器，Trigger和JobDetail可以注册到Scheduler中，两者在Scheduler中有各自的组和名称。一个Job可以对应多个Trigger，而一个Trigger只能对应一个Job。</p>
</li>
</ul>
<p><strong>常用的时间表达式：</strong></p>
<table>
<thead>
<tr>
<th>表达式</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>0 0 12 * * ？</td>
<td>每天12：00运行</td>
</tr>
<tr>
<td>0 15 10 ？ * *</td>
<td>每天10：15运行</td>
</tr>
<tr>
<td>0 15 10 * * ？</td>
<td>每天10：15运行</td>
</tr>
<tr>
<td>0 15 10 * * ？ *</td>
<td>每天10：15运行</td>
</tr>
<tr>
<td>0 15 10 * * ? 2016</td>
<td>在2016年每天10：15</td>
</tr>
<tr>
<td>0 * 14 * * ？</td>
<td>每天14点到15点之间每分钟运行一次，开始14：00，结束于14：59</td>
</tr>
<tr>
<td>0 0/5 14 * * ?</td>
<td>每天14点到15点之间每5分钟运行一次，开始于14：00，结束于14：55</td>
</tr>
<tr>
<td>0 0/5 14,18 * * ？</td>
<td>每天14点到15点之前每5分钟运行一次，另外每天18点到19点每5分钟也运行一次</td>
</tr>
<tr>
<td>0 0-5 14 * * ？</td>
<td>每天14：00到14：05，每分钟运行一次</td>
</tr>
<tr>
<td>0 15 10 ？ * MON-FRI</td>
<td>每周一、二、三、四、五的10：15分运行</td>
</tr>
<tr>
<td>0 15 10 15 * ？</td>
<td>每月15日10：15运行</td>
</tr>
<tr>
<td>0 15 10 L * ?</td>
<td>每月最后一天的10：15运行</td>
</tr>
</tbody></table>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">说明：</span><br><span class="line"></span><br><span class="line">第一位：秒</span><br><span class="line">第二位：分</span><br><span class="line">第三位：时</span><br><span class="line">第四位：日</span><br><span class="line">第五位：月</span><br><span class="line">第六位：星期</span><br><span class="line">第七位：年（可选）</span><br><span class="line"></span><br><span class="line">符号：</span><br><span class="line">（*） 表示对应时间域的每一个时刻，比如* 在分钟字段时，表示每一分钟</span><br><span class="line">（？）只有在日期和星期字段中使用，无特殊含义，相当于点位符</span><br><span class="line">（-） 表示范围，比如小时字段中使用9-11，表示9点到11点，即9、10、11</span><br><span class="line">（，）表示一个列表值，比如星期字段中使用“MON,WEN,FRI”表示星期一、星期三和星期五</span><br><span class="line">（&#x2F;）x&#x2F;y表示一个等步长序列，x为起始值，y为步长，比如0&#x2F;15表示0、15、30、45</span><br><span class="line">（L）只在日期和星期字段中使用，L在日期字段，表示这个月份的最后一天，比如一月的31号；如果用在星期中，表示星期六。</span><br></pre></td></tr></table></figure>

<h2 id="pom依赖"><a href="#pom依赖" class="headerlink" title="pom依赖"></a>pom依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.quartz-scheduler<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>quartz<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="代码示例："><a href="#代码示例：" class="headerlink" title="代码示例："></a>代码示例：</h2><h2 id="1-调度工厂配置，里面注册了所有的trigger触发器"><a href="#1-调度工厂配置，里面注册了所有的trigger触发器" class="headerlink" title="1. 调度工厂配置，里面注册了所有的trigger触发器"></a>1. 调度工厂配置，里面注册了所有的trigger触发器</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"org.springframework.scheduling.quartz.SchedulerFactoryBean"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"triggers"</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">list</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">ref</span> <span class="attr">bean</span>=<span class="string">"hotPostsCollectTrigger"</span> /&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">list</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>SchedulerFactoryBean特点：</strong></p>
<ul>
<li>以Bean风格的方式为Scheduler提供配置信息</li>
<li>让Scheduler与Spring容器的生命周期建立关联</li>
<li>通过属性配置部分或全部代替Quartz自身的配置文件</li>
</ul>
<h2 id="2-trigger触发器，包含具体的任务和触发时间规则"><a href="#2-trigger触发器，包含具体的任务和触发时间规则" class="headerlink" title="2. trigger触发器，包含具体的任务和触发时间规则"></a>2. trigger触发器，包含具体的任务和触发时间规则</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"hotPostsCollectTrigger"</span></span></span><br><span class="line"><span class="tag">		<span class="attr">class</span>=<span class="string">"org.springframework.scheduling.quartz.CronTriggerFactoryBean"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jobDetail"</span> <span class="attr">ref</span>=<span class="string">"hotPostsCollectJobDetail"</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"cronExpression"</span> <span class="attr">value</span>=<span class="string">"0 30 23 * * ?"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="3-编写自己业务的jobdetail类，实现job接口"><a href="#3-编写自己业务的jobdetail类，实现job接口" class="headerlink" title="3. 编写自己业务的jobdetail类，实现job接口"></a>3. 编写自己业务的jobdetail类，实现job接口</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;bean id&#x3D;&quot;hotPostsCollectJob&quot; class&#x3D;&quot;com.onlyone.bbs.task.job.HotPostsCollectJob&quot; &#x2F;&gt;</span><br><span class="line">&lt;bean id&#x3D;&quot;hotPostsCollectJobDetail&quot;	class&#x3D;&quot;org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean&quot;&gt;</span><br><span class="line">		&lt;property name&#x3D;&quot;targetObject&quot; ref&#x3D;&quot;hotPostsCollectJob&quot; &#x2F;&gt;</span><br><span class="line">		&lt;property name&#x3D;&quot;targetMethod&quot; value&#x3D;&quot;doHandle&quot; &#x2F;&gt;</span><br><span class="line">		&lt;property name&#x3D;&quot;concurrent&quot; value&#x3D;&quot;false&quot; &#x2F;&gt;</span><br><span class="line">&lt;&#x2F;bean&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class HotPostsCollectJob implements Job &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void execute(JobExecutionContext context) throws JobExecutionException &#123;</span><br><span class="line">        &#x2F;&#x2F; 框架默认的接口</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F;也可以自己定义方法，此时需要在JobDetail调用时用targetMethod指定</span><br><span class="line">    public void doHandle() &#123;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>commons-codec</title>
    <url>/third-tools/commons-codec/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>commons-codec是Apache下面的用来处理常用的编码方法的工具类包，例如DES、SHA1、MD5、Base64，URL，Soundx等等。 不仅是编码，也可用于解码。</p>
<a id="more"></a>

<h2 id="pom依赖"><a href="#pom依赖" class="headerlink" title="pom依赖"></a>pom依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-codec<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-codec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h2 id="常用工具类："><a href="#常用工具类：" class="headerlink" title="常用工具类："></a>常用工具类：</h2><ul>
<li><p>DigestUtils工具类</p>
<p>提供了多种编码方式的静态方法，用于对String、byte[]、InputStream等类型的数据编码。</p>
</li>
</ul>
<p><strong>案例场景：</strong></p>
<p>电子商务平台，买家对一件商品下单后，为了便于后面的纠纷处理，需要对下单那一时刻的商品信息备份（因为卖家随时会修改自己的宝贝信息），命名为快照。如果为每一个订单都保存一次商品详情显然不现实，DigestUtils可以很好解决这个问题。每次对整个商品详情数据编码得到一个32字符摘要，作为唯一id并关联到用户订单，并保存到数据库中。可以有效对快照去重，节省资源空间。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.commons.codec.digest.DigestUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DigestTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">encodeStr</span><span class="params">(String data)</span> </span>&#123;</span><br><span class="line">        String encodeS = DigestUtils.md5Hex(data);</span><br><span class="line">        System.out.println(encodeS);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String data = <span class="string">"网销投连险是保险公司的一款保险产品，在互联网金融上还是很常见的。"</span> + <span class="string">"比如京东天天盈，网易有钱零钱++。这些保险削弱了保险的保障功能，降低成本，从而提高保险的理财功能提高理财收益。"</span></span><br><span class="line">                      + <span class="string">"投连险基本和银行结构性理财产品一样，信息披露度不高，但是有保险公司兜底，不至于整个平台跑路。"</span></span><br><span class="line">                      + <span class="string">"投资投连险可以想象为投资一个起点低的银行理财产品吧。网销投连险一般都受益在4-6%，不承诺保本。"</span></span><br><span class="line">                      + <span class="string">"经常爆出保险公司的保障型长期投连险出现投资亏损新闻，但是网销短期投连险投资型投连险目前没有出现亏损，基本也能按照预期收益兑付。"</span></span><br><span class="line">                      + <span class="string">"网销投连险安全性和收益性都比较居中，短期产品危险系数不高，但是在债券违约的大环境下，长期产品安全性没有太大保障。"</span> + <span class="string">"不过好在保险公司没有跑路风险，至少不会把本金损失殆尽啊。"</span>;</span><br><span class="line"></span><br><span class="line">        encodeStr(data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">9901d04398f5b2adc0049c8c751e7411</span><br></pre></td></tr></table></figure>

<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p><a href="http://commons.apache.org/proper/commons-codec/userguide.html" target="_blank" rel="noopener">http://commons.apache.org/proper/commons-codec/userguide.html</a></p>
<p><a href="https://commons.apache.org/proper/commons-codec/apidocs/index.html" target="_blank" rel="noopener">https://commons.apache.org/proper/commons-codec/apidocs/index.html</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>commons-io</title>
    <url>/third-tools/commons-io/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h2 id="封装了一些常用工具类方法，用于IO的各种操作"><a href="#封装了一些常用工具类方法，用于IO的各种操作" class="headerlink" title="封装了一些常用工具类方法，用于IO的各种操作:"></a>封装了一些常用工具类方法，用于IO的各种操作:</h2><ul>
<li>Utility class ，提供一些静态方法来满足一些常用的业务场景</li>
<li>Input ， InputStream 和 Reader 实现</li>
</ul>
<a id="more"></a>
<ul>
<li>Output ， OutputStream 和 Writer 实现</li>
<li>Filters ， 多种文件过滤器实现（定义了 IOFileFilter接口，同时继承了 FileFilter 和 FilenameFilter 接口）</li>
<li>comparator包， 文件比较，提供了多种 java.util.Comparator<File> 实现</li>
</ul>
<h2 id="pom依赖"><a href="#pom依赖" class="headerlink" title="pom依赖"></a>pom依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="常用工具类"><a href="#常用工具类" class="headerlink" title="常用工具类"></a>常用工具类</h2><ul>
<li><p>IOUtils </p>
<p>提供各种静态方法，用于处理读，写和、拷贝，这些方法基于InputStream、OutputStream、Reader 和 Writer</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">  InputStream in = <span class="keyword">new</span> URL( <span class="string">"http://commons.apache.org"</span> ).openStream();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    System.out.println( IOUtils.toString( in ) );</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    IOUtils.closeQuietly(in);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>FileUtils</p>
<p>提供各种静态方法，基于File对象工作，包括读、写、拷贝、比较文件</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File file = <span class="keyword">new</span> File(<span class="string">"/commons/io/project.properties"</span>);</span><br><span class="line">List lines = FileUtils.readLines(file, <span class="string">"UTF-8"</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li><p>LineIterator</p>
<p>提供灵活的方式操作基于行的文件。通过FileUtils 或 IOUtils中的静态方法，可以直接创建一个实例</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">LineIterator it = FileUtils.lineIterator(file, <span class="string">"UTF-8"</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">        String line = it.nextLine();</span><br><span class="line">        <span class="comment">/// do something with line</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    LineIterator.closeQuietly(it);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p><a href="http://ifeve.com/commons-io/" target="_blank" rel="noopener">http://ifeve.com/commons-io/</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>commons-lang3</title>
    <url>/third-tools/commons-lang3/</url>
    <content><![CDATA[<p><strong>主要是提供一些基础的操作和处理，归为以下几类：</strong></p>
<ul>
<li><p>org.apache.commons.lang3（高度重用的Util类，常用的工具类静态方法；重点）</p>
</li>
<li><p>org.apache.commons.lang3.builder（忽略）</p>
</li>
<li><p>org.apache.commons.lang3.concurrent（忽略）</p>
</li>
<li><p>org.apache.commons.lang3.event（忽略）</p>
</li>
<li><p>org.apache.commons.lang3.exception（忽略）</p>
</li>
<li><p>org.apache.commons.lang3.math（数字类型转换、大小比较、是否数字 等相关工具类；重点）</p>
</li>
<li><p>org.apache.commons.lang3.mutable（包装值型变量，为基础数据类型扩展了更多方法）</p>
</li>
<li><p>org.apache.commons.lang3.reflect（反射相关，忽略）</p>
</li>
<li><p>org.apache.commons.lang3.text（文本相关）</p>
</li>
<li><p>org.apache.commons.lang3.time（处理日期和时间的功能；重点）</p>
</li>
<li><p>org.apache.commons.lang3.tuple（忽略）</p>
</li>
</ul>
<h2 id="pom依赖"><a href="#pom依赖" class="headerlink" title="pom依赖"></a>pom依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-lang3<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="常用工具类："><a href="#常用工具类：" class="headerlink" title="常用工具类："></a>常用工具类：</h2><p>内容虽然有点多，但我们使用最多还是一些有用的包含static方法的Util类。</p>
<ul>
<li><p>StringUtils – 处理String的核心类，提供了相当多的功能；</p>
</li>
<li><p>NumberUtils - 类型转换（String-&gt;Long）；取最大最小值；比较大小。所有操作都不会抛出异常，如果转换不成功返回0,0.0d,0.0f等形式，转换操作也可以指定默认值。</p>
</li>
<li><p>DateUtils -日期相关；是否同一天；时间+x；字符串转换成Date</p>
</li>
<li><p>ArrayUtils – 用于对数组的操作，如添加、查找、删除、子数组、倒序、元素类型转换等；</p>
</li>
<li><p>SystemUtils – 在java.lang.System基础上提供更方便的访问，如用户路径、Java版本、时区、操作系统等判断；</p>
</li>
<li><p>WordUtils – 用于处理单词大小写、换行等。</p>
</li>
<li><p>StringEscapeUtils – 用于正确处理转义字符，产生正确的Java、JavaScript、HTML、XML和SQL代码；</p>
</li>
<li><p>CharRange – 用于设定字符范围并做相应检查；</p>
</li>
<li><p>ClassUtils – 用于对Java类的操作，不使用反射；</p>
</li>
<li><p>Validate – 提供验证的操作，有点类似assert断言；</p>
</li>
</ul>
<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p><a href="https://commons.apache.org/proper/commons-lang/javadocs/api-release/" target="_blank" rel="noopener">https://commons.apache.org/proper/commons-lang/javadocs/api-release/</a></p>
<p><a href="http://zhoualine.iteye.com/blog/1770014" target="_blank" rel="noopener">http://zhoualine.iteye.com/blog/1770014</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>tsharding相关</title>
    <url>/middle-software/tsharding/</url>
    <content><![CDATA[<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="https://github.com/baihui212/tsharding" target="_blank" rel="noopener">源代码</a></li>
</ul>
<hr>
<a id="more"></a>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>分库分表业界方案</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/middle-software/11.png/w600">

<p>TSharding组件目标：</p>
<ul>
<li>很少的资源投入即可开发完成</li>
<li>支持交易订单表的Sharding需求，分库又分表</li>
<li>支持数据源路由</li>
<li>支持事务</li>
<li>支持结果集合并</li>
<li>支持读写分离</li>
</ul>
<p>TSharding组件接入过程：</p>
<ul>
<li>引入TSharding JAR包</li>
<li>配置所有分库的JDBC连接信息</li>
<li>Mybatis Mapper方法参数增加ShardingOrderPara/ShardingBuyerPara/ShardingSellerPara注解</li>
<li>批量查询增加结果集合并逻辑</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.oschina.net/p/TSharding-Client" target="_blank" rel="noopener">https://www.oschina.net/p/TSharding-Client</a></p>
]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>fastJson相关</title>
    <url>/third-tools/fastJson/</url>
    <content><![CDATA[<h2 id="pom依赖"><a href="#pom依赖" class="headerlink" title="pom依赖"></a>pom依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.41<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h2><p>fastjson是阿里的一个开源二方库，用于对象和json串之间的转换，是目前Java语言中最快的JSON库。接口简单易用，已经被广泛使用在缓存序列化、协议交互、Web输出、Android客户端等多种应用场景。</p>
<h2 id="二、常用的工具类"><a href="#二、常用的工具类" class="headerlink" title="二、常用的工具类"></a>二、常用的工具类</h2><ul>
<li>对象转换为字符串</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">com.alibaba.fastjson.JSON.toJSONString(Object)</span><br></pre></td></tr></table></figure>

<ul>
<li>字符串反序列化为Object</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">com.alibaba.fastjson.JSON.parseObject(String, Class&lt;ForumCache&gt;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例子：https://github.com/alibaba/fastjson/wiki/Samples-DataBind</span></span><br></pre></td></tr></table></figure>

<ul>
<li>将字符串反序化为List &lt;T&gt;</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;ForumCache&gt; List&lt;ForumCache&gt; com.alibaba.fastjson.JSONArray.parseArray(String text, Class&lt;ForumCache&gt; clazz)</span><br></pre></td></tr></table></figure>

<h2 id="三、手册"><a href="#三、手册" class="headerlink" title="三、手册"></a>三、手册</h2><ul>
<li><a href="https://www.w3cschool.cn/fastjson/fastjson-jsonpath.html" target="_blank" rel="noopener">Fastjson的常用API使用例子</a></li>
<li><a href="https://github.com/aalansehaiyang/fastjson" target="_blank" rel="noopener">源码 Fork分支</a></li>
<li><a href="https://blog.csdn.net/u010246789/article/details/52539576" target="_blank" rel="noopener">SerializerFeature详解</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>lombok</title>
    <url>/third-tools/lombok/</url>
    <content><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul>
<li><a href="http://www.blogjava.net/fancydeepin/archive/2012/07/12/382933.html" target="_blank" rel="noopener">Lombok安装</a></li>
</ul>
<a id="more"></a>
<h2 id="API-手册"><a href="#API-手册" class="headerlink" title="API 手册"></a>API 手册</h2><ul>
<li><a href="https://blog.csdn.net/54powerman/article/details/72624987" target="_blank" rel="noopener">lombok注解详解</a></li>
<li><a href="https://blog.csdn.net/cc_smile0702/article/details/73521878" target="_blank" rel="noopener">@Accessors注解</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>okhttp</title>
    <url>/third-tools/okhttp/</url>
    <content><![CDATA[<ul>
<li><a href="https://github.com/square/okhttp" target="_blank" rel="noopener">源代码</a></li>
</ul>
<a id="more"></a>
<h2 id="OKHttp的配置Cookie持久化"><a href="#OKHttp的配置Cookie持久化" class="headerlink" title="OKHttp的配置Cookie持久化"></a>OKHttp的配置Cookie持久化</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span>  <span class="keyword">static</span> String <span class="title">httpPost</span><span class="params">(String url,String json)</span> </span>&#123;</span><br><span class="line">    String res = <span class="string">""</span>;</span><br><span class="line">    OkHttpClient okHttpClient = <span class="keyword">new</span> OkHttpClient().newBuilder().cookieJar(<span class="keyword">new</span> CookieJar() &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> HashMap&lt;String, List&lt;Cookie&gt;&gt; cookieStore = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">saveFromResponse</span><span class="params">(HttpUrl httpUrl, List&lt;Cookie&gt; cookies)</span> </span>&#123;</span><br><span class="line">            cookieStore.put(httpUrl.host(), cookies);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> List&lt;Cookie&gt; <span class="title">loadForRequest</span><span class="params">(HttpUrl httpUrl)</span> </span>&#123;</span><br><span class="line">            List&lt;Cookie&gt; cookies = cookieStore.get(httpUrl.host());</span><br><span class="line">            <span class="keyword">return</span> cookies != <span class="keyword">null</span> ? cookies : <span class="keyword">new</span> ArrayList&lt;Cookie&gt;();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;).connectTimeout(<span class="number">5</span>, TimeUnit.SECONDS)</span><br><span class="line">            .readTimeout(<span class="number">5</span>, TimeUnit.SECONDS).writeTimeout(<span class="number">5</span>, TimeUnit.SECONDS).build();         </span><br><span class="line">    RequestBody requestBody = RequestBody.create(JSON, json);</span><br><span class="line">    <span class="comment">//创建一个请求对象</span></span><br><span class="line">    Request request = <span class="keyword">new</span> Request.Builder()</span><br><span class="line">            .url(url)</span><br><span class="line">            .post(requestBody)</span><br><span class="line">            .build();</span><br><span class="line">    <span class="comment">//发送请求获取响应</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Response response=okHttpClient.newCall(request).execute();</span><br><span class="line">        res = response.body().string();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis安装及主从复制</title>
    <url>/third-tools/redis-master-slave/</url>
    <content><![CDATA[<h1 id="一、安装"><a href="#一、安装" class="headerlink" title="一、安装"></a>一、安装</h1><h2 id="下载安装包"><a href="#下载安装包" class="headerlink" title="下载安装包"></a>下载安装包</h2><p><a href="https://redis.io/download" target="_blank" rel="noopener">https://redis.io/download</a></p>
<a id="more"></a>
<h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf redis-4.0.2.tar.gz</span><br></pre></td></tr></table></figure>
<h2 id="编译源程序"><a href="#编译源程序" class="headerlink" title="编译源程序"></a>编译源程序</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd redis-4.0.2-6379</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<h2 id="服务启动"><a href="#服务启动" class="headerlink" title="服务启动"></a>服务启动</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd src</span><br><span class="line">.&#x2F;redis-server &amp;</span><br></pre></td></tr></table></figure>

<h2 id="查看一下启动的Redis实例"><a href="#查看一下启动的Redis实例" class="headerlink" title="查看一下启动的Redis实例"></a>查看一下启动的Redis实例</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -ef|grep redis</span><br></pre></td></tr></table></figure>

<h2 id="客户端shell"><a href="#客户端shell" class="headerlink" title="客户端shell"></a>客户端shell</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd src</span><br><span class="line">.&#x2F;redis-cli</span><br></pre></td></tr></table></figure>

<h2 id="配置参数-redis-conf"><a href="#配置参数-redis-conf" class="headerlink" title="配置参数(redis.conf)"></a>配置参数(redis.conf)</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">daemonize：如需要在后台运行，把该项的值改为yes</span><br><span class="line"></span><br><span class="line">　　pdifile：把pid文件放在&#x2F;var&#x2F;run&#x2F;redis.pid，可以配置到其他地址</span><br><span class="line"></span><br><span class="line">　　bind：指定redis只接收来自该IP的请求，如果不设置，那么将处理所有请求，在生产环节中最好设置该项</span><br><span class="line"></span><br><span class="line">　　port：监听端口，默认为6379</span><br><span class="line"></span><br><span class="line">　　timeout：设置客户端连接时的超时时间，单位为秒</span><br><span class="line"></span><br><span class="line">　　loglevel：等级分为4级，debug，revbose，notice和warning。生产环境下一般开启notice</span><br><span class="line"></span><br><span class="line">　　logfile：配置log文件地址，默认使用标准输出，即打印在命令行终端的端口上</span><br><span class="line"></span><br><span class="line">　　database：设置数据库的个数，默认使用的数据库是0</span><br><span class="line"></span><br><span class="line">　　save：设置redis进行数据库镜像的频率</span><br><span class="line"></span><br><span class="line">　　rdbcompression：在进行镜像备份时，是否进行压缩</span><br><span class="line"></span><br><span class="line">　　dbfilename：镜像备份文件的文件名</span><br><span class="line"></span><br><span class="line">　　dir：数据库镜像备份的文件放置的路径</span><br><span class="line"></span><br><span class="line">　　slaveof：设置该数据库为其他数据库的从数据库</span><br><span class="line"></span><br><span class="line">　　masterauth：当主数据库连接需要密码验证时，在这里设定</span><br><span class="line"></span><br><span class="line">　　requirepass：设置客户端连接后进行任何其他指定前需要使用的密码</span><br><span class="line"></span><br><span class="line">　　maxclients：限制同时连接的客户端数量</span><br><span class="line"></span><br><span class="line">　　maxmemory：设置redis能够使用的最大内存</span><br><span class="line"></span><br><span class="line">　　appendonly：开启appendonly模式后，redis会把每一次所接收到的写操作都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态</span><br><span class="line"></span><br><span class="line">　　appendfsync：设置appendonly.aof文件进行同步的频率</span><br><span class="line"></span><br><span class="line">　　vm_enabled：是否开启虚拟内存支持</span><br><span class="line"></span><br><span class="line">　　vm_swap_file：设置虚拟内存的交换文件的路径</span><br><span class="line"></span><br><span class="line">　　vm_max_momery：设置开启虚拟内存后，redis将使用的最大物理内存的大小，默认为0</span><br><span class="line"></span><br><span class="line">　　vm_page_size：设置虚拟内存页的大小</span><br><span class="line"></span><br><span class="line">　　vm_pages：设置交换文件的总的page数量</span><br><span class="line"></span><br><span class="line">　　vm_max_thrrads：设置vm IO同时使用的线程数量</span><br></pre></td></tr></table></figure>


<h1 id="二、主从复制"><a href="#二、主从复制" class="headerlink" title="二、主从复制"></a>二、主从复制</h1><ul>
<li><a href="https://yq.aliyun.com/articles/79223?spm=5176.8091938.0.0.TKdCyN" target="_blank" rel="noopener">主从复制原理</a></li>
</ul>
<blockquote>
<p>单机启动三个实例，一主两从。创建三个目录，分别是6379、6380、6381，创建conf、log、db三个目录，并拷贝redis.conf到对应的conf目录下</p>
</blockquote>
<ul>
<li>（master）修改6379/conf 目录下的redis.conf 配置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">daemonize yes　　　　　　　　　　　　　　　　　　　　 &lt;&#x3D;&#x3D; daemon进程运行</span><br><span class="line">pidfile &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6379&#x2F;redis.pid   &lt;&#x3D;&#x3D; 进程id存放文件</span><br><span class="line">port 6379                                　　　　&lt;&#x3D;&#x3D; 端口</span><br><span class="line">logfile &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6379&#x2F;log&#x2F;redis.log   　　　　&lt;&#x3D;&#x3D; 日志目录</span><br><span class="line">dir &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6379&#x2F;db&#x2F;                 　　　　&lt;&#x3D;&#x3D; db目录</span><br></pre></td></tr></table></figure>

<ul>
<li>（slave） 修改6380/conf 目录下的redis.conf 配置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">daemonize yes　　　　　　　　　　　　　　　　　　　　 &lt;&#x3D;&#x3D; daemon进程运行</span><br><span class="line">pidfile &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6380&#x2F;redis.pid     &lt;&#x3D;&#x3D; 进程id存放文件</span><br><span class="line">port 6380                               　　　　&lt;&#x3D;&#x3D; 端口</span><br><span class="line">logfile &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6380&#x2F;log&#x2F;redis.log   　　　　&lt;&#x3D;&#x3D; 日志目录</span><br><span class="line">dir &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6380&#x2F;db&#x2F;                 　　　　&lt;&#x3D;&#x3D; db目录</span><br><span class="line">slaveof 127.0.0.1 6379      &lt;&#x3D;&#x3D; master机器</span><br></pre></td></tr></table></figure>

<ul>
<li>（slave） 修改6381/conf 目录下的redis.conf 配置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">daemonize yes　　　　　　　　　　　　　　　　　　　　 &lt;&#x3D;&#x3D; daemon进程运行</span><br><span class="line">pidfile &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6381&#x2F;redis.pid   &lt;&#x3D;&#x3D; 进程id存放文件</span><br><span class="line">port 6381                               　　　　&lt;&#x3D;&#x3D; 端口</span><br><span class="line">logfile &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6381&#x2F;log&#x2F;redis.log   　　　　&lt;&#x3D;&#x3D; 日志目录</span><br><span class="line">dir &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6381&#x2F;db&#x2F;                 　　　　&lt;&#x3D;&#x3D; db目录</span><br><span class="line">slaveof 127.0.0.1 6379      &lt;&#x3D;&#x3D; master机器</span><br></pre></td></tr></table></figure>



<p>启动实例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;redis-server  &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6379&#x2F;conf&#x2F;redis.conf &amp; </span><br><span class="line">.&#x2F;redis-server  &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6380&#x2F;conf&#x2F;redis.conf &amp; </span><br><span class="line">.&#x2F;redis-server  &#x2F;Users&#x2F;onlyone&#x2F;software&#x2F;redis&#x2F;6381&#x2F;conf&#x2F;redis.conf &amp;</span><br></pre></td></tr></table></figure>

<p>查看进程信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -ef|grep redis</span><br><span class="line"></span><br><span class="line">501 32933     1   0 10:24上午 ??         0:00.25 .&#x2F;redis-server 127.0.0.1:6380 </span><br><span class="line">501 32986     1   0 10:27上午 ??         0:00.09 .&#x2F;redis-server 127.0.0.1:6381 </span><br><span class="line">501 32880 12633   0 10:22上午 ttys000    0:00.43 .&#x2F;redis-server *:6379</span><br></pre></td></tr></table></figure>

<p>查看master节点信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;redis-cli -p 6379 &quot;info&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">。。。省略。。。</span><br><span class="line">\# Replication</span><br><span class="line">role:master</span><br><span class="line">connected_slaves:2</span><br><span class="line">slave0:ip&#x3D;127.0.0.1,port&#x3D;6380,state&#x3D;online,offset&#x3D;518,lag&#x3D;1</span><br><span class="line">slave1:ip&#x3D;127.0.0.1,port&#x3D;6381,state&#x3D;online,offset&#x3D;518,lag&#x3D;1</span><br><span class="line">master_replid:38605ae9c8d326685b9d114b31efffc405b54129</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:518</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:1</span><br><span class="line">repl_backlog_histlen:518</span><br><span class="line">。。。省略。。。</span><br></pre></td></tr></table></figure>

<p>查看slave（6380）节点信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;redis-cli -p 6380 &quot;info&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">。。。省略。。。</span><br><span class="line">\# Replication</span><br><span class="line">role:slave</span><br><span class="line">master_host:127.0.0.1</span><br><span class="line">master_port:6379</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:10</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:658</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">master_replid:38605ae9c8d326685b9d114b31efffc405b54129</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:658</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:1</span><br><span class="line">repl_backlog_histlen:658</span><br><span class="line">。。。省略。。。</span><br></pre></td></tr></table></figure>

<p>主库写数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  src .&#x2F;redis-cli -p 6379</span><br><span class="line">127.0.0.1:6379&gt; set name tom</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">&quot;tom&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>查看从库同步数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  src .&#x2F;redis-cli -p 6380</span><br><span class="line">127.0.0.1:6380&gt; get name</span><br><span class="line">&quot;tom&quot;</span><br><span class="line">127.0.0.1:6380&gt;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>redis不同版本新特性</title>
    <url>/third-tools/redis-new-feature/</url>
    <content><![CDATA[<h2 id="Redis-3-0"><a href="#Redis-3-0" class="headerlink" title="Redis 3.0"></a>Redis 3.0</h2><ul>
<li>实现了Cluster的功能，增删集群节点后会自动的进行数据迁移</li>
<li>Redis 集群在线重配置的核心就是将槽从一个节点移动到另一个节点的能力。因为一个哈希槽实际上就是一些键的集合， 所以 Redis 集群在重哈希（rehash）时真正要做的，就是将一些键从一个节点移动到另一个节点。</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>redis网上资料</title>
    <url>/third-tools/redis-online-information/</url>
    <content><![CDATA[<p>* </p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>redis汇总</title>
    <url>/third-tools/redis/</url>
    <content><![CDATA[<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="../redis-master-slave">安装、主从复制</a></li>
<li><a href="../redis缓存与memcache的区别">redis缓存与memcache的区别</a></li>
<li><a href="http://www.runoob.com/redis/redis-sorted-sets.html" target="_blank" rel="noopener">redis原生命令api</a></li>
</ul>
<a id="more"></a>
<ul>
<li><a href="http://doc.redisfans.com/index.html" target="_blank" rel="noopener">redis 命令参考</a></li>
<li><a href="http://www.runoob.com/redis/redis-pub-sub.html" target="_blank" rel="noopener">Redis 教程</a></li>
<li>redis cluster<ul>
<li><a href="http://www.redis.cn/topics/cluster-tutorial.html" target="_blank" rel="noopener">Redis 集群教程</a></li>
<li><a href="https://www.cnblogs.com/lykxqhh/p/5690923.html" target="_blank" rel="noopener">Redis Cluster集群搭建</a></li>
</ul>
</li>
</ul>
<p>客户端：</p>
<ul>
<li>Jedis<ul>
<li><a href="https://github.com/xetorthio/jedis" target="_blank" rel="noopener">github源码</a></li>
</ul>
</li>
<li>Redic<ul>
<li>Redis缓存客户端，支持读写分离和分片。</li>
<li><a href="https://gitee.com/robertleepeak/redic" target="_blank" rel="noopener">源码</a></li>
</ul>
</li>
<li>Codis<ul>
<li>在应用层和缓存服务器中间增加一个代理层，根据分片规则来路由请求。</li>
<li><a href="http://www.cnblogs.com/xuanzhi201111/p/4425194.html" target="_blank" rel="noopener">Codis集群的搭建与使用</a></li>
</ul>
</li>
</ul>
<p>资料收集：</p>
<ul>
<li><a href="http://blog.csdn.net/world6/article/details/79381682" target="_blank" rel="noopener">redis为什么是单线程？</a></li>
<li><a href="https://mp.weixin.qq.com/s/m-RdJQdG-qW-BLquorhMlQ" target="_blank" rel="noopener">Redis为什么这么快？一文深入了解Redis内存模型！</a></li>
<li><a href="https://mp.weixin.qq.com/s/vxJCG0Nk4csbZ1axLy0bfQ" target="_blank" rel="noopener">3台机器轻松搭建一个高可用Redis服务架构</a></li>
<li><a href="https://mp.weixin.qq.com/s/fpupqLp-wjR8fQvYSQhVLg" target="_blank" rel="noopener">Redis 内存为什么不宜过大</a></li>
<li><a href="https://mp.weixin.qq.com/s/BoLsVKYyu8yRXZbxd1uuQw" target="_blank" rel="noopener">史上最全Redis高可用技术解决方案大全</a></li>
</ul>
<p>业务应用：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/2FEbkas_m1WnYUqjVpMkWw" target="_blank" rel="noopener">同程凤凰缓存系统基于Redis的设计与实践</a></li>
<li><a href="http://mp.weixin.qq.com/s/YhrJprLWjoZa2tU3qY8XZw" target="_blank" rel="noopener">携程开源其Redis多数据中心解决方案XPipe</a></li>
</ul>
<p>前沿：</p>
<ul>
<li><a href="redis-new-feature.md">redis不同版本新特性</a></li>
</ul>
<hr>
<p>redis采用C编写，redis服务器是核心业务采用单线程模式，无锁竞争且基于内存操作，执行效率非常高。</p>
<p>如果开启备份机制，会fork子线程来处理。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用的比较多的redis客户端jedis：</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;xetorthio&#x2F;jedis</span><br></pre></td></tr></table></figure>

<h2 id="核心逻辑："><a href="#核心逻辑：" class="headerlink" title="核心逻辑："></a>核心逻辑：</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Connection <span class="title">sendCommand</span><span class="params">(<span class="keyword">final</span> Command cmd, <span class="keyword">final</span> <span class="keyword">byte</span>[]... args)</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	<span class="comment">//建立连接，包装RedisOutputStream和RedisInputStream</span></span><br><span class="line">    connect();</span><br><span class="line">    <span class="comment">//发送执行命令</span></span><br><span class="line">    Protocol.sendCommand(outputStream, cmd, args);</span><br><span class="line">    lastAccessTime = System.currentTimeMillis();</span><br><span class="line">    pipelinedCommands++;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125; <span class="keyword">catch</span> (JedisConnectionException ex) &#123;</span><br><span class="line">	System.err.println(ex.getMessage());</span><br><span class="line">    <span class="comment">// Any other exceptions related to connection?</span></span><br><span class="line">    broken = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">throw</span> ex;</span><br><span class="line">&#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>Command内提供了多种redis操作命令。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">enum</span> Command &#123;</span><br><span class="line">PING, SET, GET, QUIT, EXISTS, DEL, TYPE, FLUSHDB, KEYS, RANDOMKEY, RENAME, RENAMENX, RENAMEX, DBSIZE, EXPIRE, EXPIREAT, TTL, SELECT, MOVE, FLUSHALL, GETSET, MGET, SETNX, SETEX, MSET, MSETNX, DECRBY, DECR, INCRBY, INCR, APPEND, SUBSTR, HSET, HGET, HSETNX, HMSET, HMGET, HINCRBY, HEXISTS, HDEL, HLEN, HKEYS, HVALS, HGETALL, RPUSH, LPUSH, LLEN, LRANGE, LTRIM, LINDEX, LSET, LREM, LPOP, RPOP, RPOPLPUSH, SADD, SMEMBERS, SREM, SPOP, SMOVE, SCARD, SISMEMBER, SINTER, SINTERSTORE, SUNION, SUNIONSTORE, SDIFF, SDIFFSTORE, SRANDMEMBER, ZADD, ZRANGE, ZREM, ZINCRBY, ZRANK, ZREVRANK, ZREVRANGE, ZCARD, ZSCORE, MULTI, DISCARD, EXEC, WATCH, UNWATCH, SORT, BLPOP, BRPOP, AUTH, SUBSCRIBE, PUBLISH, UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBSUB, ZCOUNT, ZRANGEBYSCORE, ZREVRANGEBYSCORE, ZREMRANGEBYRANK, ZREMRANGEBYSCORE, ZUNIONSTORE, ZINTERSTORE, ZLEXCOUNT, ZRANGEBYLEX, ZREMRANGEBYLEX, SAVE, BGSAVE, BGREWRITEAOF, LASTSAVE, SHUTDOWN, INFO, MONITOR, SLAVEOF, CONFIG, STRLEN, SYNC, LPUSHX, PERSIST, RPUSHX, ECHO, LINSERT, DEBUG, BRPOPLPUSH, SETBIT, GETBIT, BITPOS, SETRANGE, GETRANGE, EVAL, EVALSHA, SCRIPT, SLOWLOG, OBJECT, BITCOUNT, BITOP, SENTINEL, DUMP, RESTORE, PEXPIRE, PEXPIREAT, PTTL, INCRBYFLOAT, PSETEX, CLIENT, TIME, MIGRATE, HINCRBYFLOAT, SCAN, HSCAN, SSCAN, ZSCAN, WAIT, CLUSTER, ASKING, PFADD, PFCOUNT, PFMERGE;</span><br></pre></td></tr></table></figure>


<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">set</span><span class="params">(<span class="keyword">final</span> String key, <span class="keyword">final</span> String value, <span class="keyword">final</span> String nxxx,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> String expx, <span class="keyword">final</span> <span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">checkIsInMulti();</span><br><span class="line">client.set(key, value, nxxx, expx, time);</span><br><span class="line"><span class="comment">//返回结果</span></span><br><span class="line"><span class="keyword">return</span> client.getStatusCodeReply();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>


<h2 id="不同类型长度限制："><a href="#不同类型长度限制：" class="headerlink" title="不同类型长度限制："></a>不同类型长度限制：</h2><ul>
<li>string 最大512M</li>
<li>List 最大长度 （2的32次方-1）,有序可重复</li>
<li>Sets 最大长度 （2的32次方-1），不允许重复，自动去重</li>
<li>Sorted sets，同上，支持按score排序</li>
<li>Hashes kv对数（2的32次方-1）</li>
</ul>
<h2 id="内部方法详解："><a href="#内部方法详解：" class="headerlink" title="内部方法详解："></a>内部方法详解：</h2><h3 id="1-String"><a href="#1-String" class="headerlink" title="1.String"></a>1.String</h3><ul>
<li><p>String setBin(String key, byte[] value) </p>
<p>按字节数组关联到key下</p>
</li>
<li><p>byte[] getBin(String key) </p>
<p>根据key查找对应下的字节数组</p>
</li>
<li><p>String set(String key, String value)  </p>
<p>将字符串值value关联到key</p>
</li>
<li><p>String get(String key)</p>
<p>返回key所关联的字符串值,如果key不存在则返回null</p>
</li>
<li><p>long setnx(String key, String value)</p>
<p>将字符串值value关联到key，如果key已存在则不做任何改变。返回1表示key不存在，第一次设置；返回0表示key已经存在</p>
</li>
<li><p>String setex(String key, int seconds, String value)</p>
<p>将值value关联到key，并将key的生命周期设为seconds(以秒为单位)。如果key 已经存在，SETEX命令将覆写旧值。 </p>
</li>
<li><p>long append(String key, String value)</p>
<p>如果key已经存在并且是一个字符串，APPEND命令将value追加到key原来的值之后<BR><br>如果key不存在，APPEND就简单地将给定key设为value，同 SET key value</p>
</li>
<li><p>long strlen(String key) throws RedisException;</p>
<p>获取key所对应的value字符串长度</p>
</li>
<li><p>long incr(String key) </p>
<p>将key中储存的数字值加1,如果key不存在,以0为key的初始值,然后执行INCR操作。线程安全</p>
</li>
<li><p>long incrBy(String key, long n)</p>
<p>将key中储存的数字值加n,如果key不存在,以0为key的初始值,然后执行INCRBY操作</p>
</li>
<li><p>long decr(String key)</p>
<p>将key中储存的数字值减1,如果key不存在,以0为key的初始值,然后执行DECR操作。</p>
</li>
<li><p>long decrBy(String key, long n)</p>
<p>将key中储存的数字值减n,如果key不存在,以0为key的初始值,然后执行DECRBY操        </p>
</li>
<li><p>String getSet(String key, String value) </p>
<p>设置key为当前值，并返回旧的值</p>
</li>
<li><p>String set(String key, String value, String nxxx, String expx, long time) throws RedisException;</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">将字符串值value关联到key:</span><br><span class="line">nxxx：必须是NX或者XX，NX表示不存在则设置否则不做操作；XX表示存在才设置否则不做操作</span><br><span class="line">expx：过期时间单位必须是EX或PX，EX表示单位是“秒”，PX表示单位是“毫秒”</span><br><span class="line">time：过期时间，前一个参数是&quot;EX&quot;的话单位为“秒”，是&quot;PX&quot;的话单位为“毫秒”</span><br><span class="line"></span><br><span class="line">@return 操作成功的话返回字符串OK，否则返回null</span><br><span class="line"></span><br><span class="line">ps：从Redis 2.6.12 版本开始支持</span><br></pre></td></tr></table></figure>


<h2 id="2-List"><a href="#2-List" class="headerlink" title="2.List"></a>2.List</h2><p>Redis lists基于Linked Lists实现。这意味着即使在一个list中有数百万个元素，在头部或尾部添加一个元素的操作，其时间复杂度也是常数级别的。用LPUSH 命令在十个元素的list头部添加新元素，和在千万元素list头部添加新元素的速度相同</p>
<ul>
<li><p>long lpush(String key, String value) </p>
<p>将值value插入到列表key的表头。 如果key不存在，一个空列表会被创建并执行LPUSH操作</p>
</li>
<li><p>long lpushBin(String key, byte[] value)</p>
<p>同上</p>
</li>
<li><p>long rpush(String key, String value) </p>
<p>将值value插入到列表key的表尾。 如果key不存在，一个空列表会被创建并执行RPUSH操作</p>
</li>
<li><p>long rpushBin(String key, byte[] value) </p>
<p>同上</p>
</li>
<li><p>String lpop(String key)</p>
<p>移除并返回列表key的头元素</p>
</li>
<li><p>byte[] lpopBin(String key)</p>
<p>同上</p>
</li>
<li><p>String rpop(String key)</p>
<p>移除并返回列表key的尾元素</p>
</li>
<li><p>byte[] rpopBin(String key)</p>
<p>同上</p>
</li>
<li><p>long llen(String key) </p>
<p>计算列表长度</p>
</li>
<li><p>List<String> lrange(String key, long start, long end) </p>
<p>返回列表key中指定区间内的元素，[start,end]，区间为0开始</p>
</li>
<li><p>String ltrim(String key, int start, int end)</p>
<p>列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除</p>
</li>
<li><p>long lrem(final String key, final long count, final String value)</p>
<p>根据参数count的值，移除列表中与参数value相等的元素<BR><br>count的值可以是以下几种：<BR><br>count &gt; 0: 从表头开始向表尾搜索，移除与value相等的元素，数量为count <BR><br>count &lt; 0: 从表尾开始向表头搜索，移除与value相等的元素，数量为count的绝对值 <BR><br>count = 0: 移除表中所有与value相等的值 <BR></p>
</li>
</ul>
<h3 id="3-Set"><a href="#3-Set" class="headerlink" title="3.Set"></a>3.Set</h3><ul>
<li><p>long sadd(String key, String member)</p>
<p>将member单个元素加入到集合key当中</p>
</li>
<li><p>long sadd(String key, String… members)</p>
<p>将members元素数组加入到集合key当中</p>
</li>
<li><p>long srem(String key, String member)</p>
<p>移除集合中的member元素</p>
</li>
<li><p>long scard(String key)</p>
<p>集合中元素的数量</p>
</li>
<li><p>Set<String> smembers(String key)</p>
<p>返回set中的所有元素</p>
</li>
</ul>
<h3 id="4-sorted-set"><a href="#4-sorted-set" class="headerlink" title="4.sorted set"></a>4.sorted set</h3><ul>
<li><p>long zadd(String key, double score, String member)</p>
<p>将member元素及其score值加入到有序集key当中</p>
</li>
<li><p>double zincrby(String key, double score, String member)</p>
<p>对member元素增加score值</p>
</li>
<li><p>long zrem(String key, String member)</p>
<p>移除有序集合key中的成员member，如果member不是有序集中的成员，不做任何操作</p>
</li>
<li><p>long zremrangeByScore(String key, double start, double end)</p>
<p>删除的有序集合保存在key的最小值和最大值(含)之间的分数的所有元素</p>
</li>
<li><p>long zcard(String key)</p>
<p>集合长度</p>
</li>
<li><p>long zcount(String key, double min, double max)</p>
<p>有序集key中，score值在min和max之间的成员数量</p>
</li>
<li><p>double zscore(String key, String member)</p>
<p>有序集key中，成员member的score值</p>
</li>
<li><p>long zrank(String key, String member)</p>
<p>返回有序集key中成员member的排名。其中有序集成员按score值递增(从小到大)顺序排列<BR><br>排名以0为底，也就是说，score值最小的成员排名为0</p>
</li>
</ul>
<ul>
<li><p>Set&lt;String&gt; zrange(String key, int start, int end)</p>
<p>返回索引区间之间的元素，最小元素索引号为0，[start,end]</p>
</li>
<li><p>Set&lt;String&gt; zrangeByScore(String key, double min, double max)</p>
<p>返回分数之间的元素,[min,max]</p>
</li>
<li><p>Set&lt;String&gt; zrangeByScore(String key, double min, double max, int offset, int count)</p>
<p>分数由小到大的顺序，取[min,max]之间的数据，offset表示取数据的开始位置（O：表示最小分数的那个位置），最多返回count个结果</p>
</li>
</ul>
<ul>
<li><p>long zrevrank(String key, String member) </p>
<p>返回有序集key中成员member的排名。其中有序集成员按score值递减(从大到小)排序<BR><br>排名以0为底，也就是说，score值最大的成员排名为0</p>
</li>
<li><p>Set&lt;String&gt; zrevrange(String key, int start, int end)</p>
<p>返回索引区间之间的元素，最大元素索引号为0,[start,end]</p>
</li>
<li><p>Set&lt;Tuple&gt; zrevrangeByScoreWithScores(String key, double max,</p>
<pre><code>double min, int offset, int count)</code></pre><p>分数按大到小的顺序，取[min,max]之间的数据，offset表示取数据的开始位置（O：表示最大分数的那个位置），最多返回count个结果，Tuple包含分数、value值等信息。                       </p>
</li>
</ul>
<h3 id="5-Hash"><a href="#5-Hash" class="headerlink" title="5.Hash"></a>5.Hash</h3><ul>
<li><p>long hset(String key, String field, String value)</p>
<p>将哈希表key中的域field的值设为value,如果key不存在，一个新的哈希表被创建并进行HSET操作。</p>
</li>
<li><p>long hsetBin(String key, String field, byte[] value)</p>
<p>同上</p>
</li>
<li><p>long hsetnx(String key, String field, String value)</p>
<p>将哈希表key中的域field的值设为value，如果key已经存在，不做任何处理</p>
</li>
<li><p>String hmset(String key, Map&lt;String, String&gt; hash)</p>
<p>同时将多个field - value(域-值)对设置到哈希表key中</p>
</li>
<li><p>String hget(String key, String field)</p>
<p>返回哈希表key中给定域field的值</p>
</li>
<li><p>byte[] hgetBin(String key, String field) </p>
<p>同上</p>
</li>
<li><p>Map&lt;String, String&gt; hgetAll(String key)</p>
<p>返回哈希表key中，所有的域和值</p>
</li>
<li><p>List<String> hmget(String key, String… fields)</p>
<p>返回哈希表key中，一个或多个给定域的值，一一对应的<BR><br>如果给定的域不存在于哈希表，那么返回一个null.</p>
</li>
<li><p>long hlen(String key)</p>
<p>返回Hash表中的元素个数</p>
</li>
<li><p>Set<String> hkeys(String key)</p>
<p>返回Hash表中的keys</p>
</li>
<li><p>List<String> hvals(String key)</p>
<p>返回Hash表中的values</p>
</li>
<li><p>boolean hexists(String key, String field) </p>
<p>哈希表key中，给定域field是否存在</p>
</li>
<li><p>long hdel(String key, String field)</p>
<p>删除哈希表key中的一个指定域</p>
</li>
<li><p>long hincrBy(String key, String field, long value)</p>
<p>对哈希中的某个key对应的值增加计数，线程安全。<br><br>如果field不存在，初始值为0<br></p>
</li>
</ul>
<h2 id="lua-脚本"><a href="#lua-脚本" class="headerlink" title="lua 脚本"></a>lua 脚本</h2><p>如果一次业务请求需要执行多条命令，可以借助lua脚本批量提交执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; key：缓存键值； seconds：过期时间</span><br><span class="line">public static String luaScript(String key, long seconds) &#123;</span><br><span class="line">	return &quot;local currIncr &#x3D; redis.call(&#39;INCR&#39;, &#39;&quot; + key + &quot;&#39;) &quot;</span><br><span class="line">			+ &quot;if tonumber(currIncr) &#x3D;&#x3D; 1 &quot;</span><br><span class="line">			+ &quot;then &quot;</span><br><span class="line">			+ &quot;redis.call(&#39;EXPIRE&#39;, &#39;&quot; + key + &quot;&#39;, &quot; + seconds + &quot;) &quot;</span><br><span class="line">			+ &quot;end &quot;</span><br><span class="line">			+ &quot;return currIncr&quot;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;寻找目标节点</span><br><span class="line">Node target &#x3D; redisClient.getNodeByKey(key);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;执行lua脚本命令</span><br><span class="line">Long count &#x3D; (Long) redisClient.eval(target, luaScript方法返回的字符串命令);</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://zhangtielei.com/posts/server.html" target="_blank" rel="noopener">http://zhangtielei.com/posts/server.html</a></p>
<p><a href="https://www.zhihu.com/question/19764056" target="_blank" rel="noopener">https://www.zhihu.com/question/19764056</a></p>
<p><a href="http://www.redis.cn/" target="_blank" rel="noopener">http://www.redis.cn/</a></p>
<p><a href="http://ifeve.com/category/redis/" target="_blank" rel="noopener">http://ifeve.com/category/redis/</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>redis缓存与memcache的区别</title>
    <url>/third-tools/redis%E7%BC%93%E5%AD%98%E4%B8%8Ememcache%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<ul>
<li><p>数据结构方面</p>
<p>  redis有更丰富的数据结构，可以满足不同的业务需求。而memcache需要客户端将数据获取再修改再set回去，增加网络io和系统开销。</p>
<a id="more"></a></li>
<li><p>内存使用方面</p>
<p>  使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。</p>
</li>
<li><p>性能对比</p>
<p>  由于Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。</p>
</li>
</ul>
<h2 id="数据类型支持不同"><a href="#数据类型支持不同" class="headerlink" title="数据类型支持不同"></a>数据类型支持不同</h2><p>Redis支持的数据类型有：String、Hash、List、Set和Sorted Set。Redis内部使用一个redisObject对象来表示所有的key和value。</p>
<p>redisObject最主要的信息如图所示：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/third-tools/1.jpg/w600">

<p>type代表一个value对象具体是什么数据类型，encoding表示不同数据类型在redis内部的存储方式，比如：type=String代表value存储的是一个普通字符串，那么对应的encoding可以是raw或者是int，如果是int则代表实际redis内部是按数值类型存储和表示这个字符串的，当然前提是这个字符串本身可以用数值表示，比如:”123″ “456”这样的字符串。只有打开了Redis的虚拟内存功能，vm字段才会真正的分配内存，该功能默认是关闭状态的。</p>
<p>1）String</p>
<p>常用命令：set/get/decr/incr/mget等；</p>
<p>应用场景：String是最常用的一种数据类型，普通的key/value存储都可以归为此类；</p>
<p>实现方式：String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr、decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。</p>
<p>2）Hash</p>
<p>常用命令：hget/hset/hgetall等</p>
<p>应用场景：我们要存储一个用户信息对象数据，其中包括用户ID、用户姓名、年龄和生日，通过用户ID我们希望获取该用户的姓名或者年龄或者生日；</p>
<p>实现方式：Redis的Hash实际是内部存储的Value为一个HashMap，并提供了直接存取这个Map成员的接口。如图所示，Key是用户ID, value是一个Map。这个Map的key是成员的属性名，value是属性值。这样对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field), 也就是通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据。当前HashMap的实现有两种方式：当HashMap的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，这时对应的value的redisObject的encoding为zipmap，当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/third-tools/2.jpg/w600">

<p>3）List</p>
<p>常用命令：lpush/rpush/lpop/rpop/lrange等；</p>
<p>应用场景：Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现；</p>
<p>实现方式：Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。</p>
<p>4）Set</p>
<p>常用命令：sadd/spop/smembers/sunion等；</p>
<p>应用场景：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以去重，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的；</p>
<p>实现方式：set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速去重，这也是set能提供判断一个成员是否在集合内的原因。</p>
<p>5）Sorted Set</p>
<p>常用命令：zadd/zrange/zrem/zcard等；</p>
<p>应用场景：Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。</p>
<p>实现方式：Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。</p>
<h2 id="内存管理机制不同"><a href="#内存管理机制不同" class="headerlink" title="内存管理机制不同"></a>内存管理机制不同</h2><p>对于像Redis和Memcached这种基于内存的数据库系统来说，内存管理的效率高低是影响系统性能的关键因素。传统C语言中的malloc/free函数是最常用的分配和释放内存的方法，但是这种方法存在着很大的缺陷：首先，对于开发人员来说不匹配的malloc和free容易造成内存泄露；其次频繁调用会造成大量内存碎片无法回收重新利用，降低内存利用率；最后作为系统调用，其系统开销远远大于一般函数调用。所以，为了提高内存的管理效率，高效的内存管理方案都不会直接使用malloc/free调用。Redis和Memcached均使用了自身设计的内存管理机制，但是实现方法存在很大的差异，下面将会对两者的内存管理机制分别进行介绍。</p>
<p>Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。Slab Allocation机制只为存储外部数据而设计，也就是说所有的key-value数据都存储在Slab Allocation系统里，而Memcached的其它内存请求则通过普通的malloc/free来申请，因为这些请求的数量和频率决定了它们不会对整个系统的性能造成影响Slab Allocation的原理相当简单。 如图所示，它首先从操作系统申请一大块内存，并将其分割成各种尺寸的块Chunk，并把尺寸相同的块分成组Slab Class。其中，Chunk就是用来存储key-value数据的最小单位。每个Slab Class的大小，可以在Memcached启动的时候通过制定Growth Factor来控制。假定图中Growth Factor的取值为1.25，如果第一组Chunk的大小为88个字节，第二组Chunk的大小就为112个字节，依此类推。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/third-tools/3.jpg/w600">

<p>当Memcached接收到客户端发送过来的数据时首先会根据收到数据的大小选择一个最合适的Slab Class，然后通过查询Memcached保存着的该Slab Class内空闲Chunk的列表就可以找到一个可用于存储数据的Chunk。当一条数据库过期或者丢弃时，该记录所占用的Chunk就可以回收，重新添加到空闲列表中。从以上过程我们可以看出Memcached的内存管理制效率高，而且不会造成内存碎片，但是它最大的缺点就是会导致空间浪费。如下图所示，将100个字节的数据存到128个字节的Chunk中，剩余的28个字节就浪费掉了。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/third-tools/4.png/w600">

<p>Redis的内存管理主要通过源码中zmalloc.h和zmalloc.c两个文件来实现的。Redis为了方便内存的管理，在分配一块内存之后，会将这块内存的大小存入内存块的头部。如图所示，real_ptr是redis调用malloc后返回的指针。redis将内存块的大小size存入头部，size所占据的内存大小是已知的，为size_t类型的长度，然后返回ret_ptr。当需要释放内存的时候，ret_ptr被传给内存管理程序。通过ret_ptr，程序可以很容易的算出real_ptr的值，然后将real_ptr传给free释放内存。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/third-tools/5.png/w600">


<p>Redis通过定义一个数组来记录所有的内存分配情况，这个数组的长度为ZMALLOC_MAX_ALLOC_STAT。数组的每一个元素代表当前程序所分配的内存块的个数，且内存块的大小为该元素的下标。在源码中，这个数组为zmalloc_allocations。zmalloc_allocations[16]代表已经分配的长度为16bytes的内存块的个数。zmalloc.c中有一个静态变量used_memory用来记录当前分配的内存总大小。所以，总的来看，Redis采用的是包装的mallc/free，相较于Memcached的内存管理方法来说，要简单很多。</p>
<h2 id="数据持久化支持"><a href="#数据持久化支持" class="headerlink" title="数据持久化支持"></a>数据持久化支持</h2><p>Redis提供两种持久化策略：RDB快照和AOF日志。而memcached不支持数据持久化。</p>
<p>1）RDB快照</p>
<p>Redis支持将当前数据的快照存成一个数据文件的持久化机制，即RDB快照。但是一个持续写入的数据库如何生成快照呢？RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他IO操作。在生成快照时，将当前进程fork出一个子进程，然后在子进程中循环所有的数据，将数据写成为RDB文件。</p>
<p>可以通过Redis的save指令来配置RDB快照生成的时机，比如配置10分钟就生成快照，也可以配置有1000次写入就生成快照，也可以多个规则一起实施。这些规则的定义就在Redis的配置文件中，你也可以通过Redis的CONFIG SET命令在Redis运行时设置规则，不需要重启Redis。</p>
<p>Redis的RDB文件不会坏掉，因为其写操作是在一个新进程中进行的，当生成一个新的RDB文件时，Redis生成的子进程会先将数据写到一个临时文件中，然后通过原子性rename系统调用将临时文件重命名为RDB文件，这样在任何时候出现故障，Redis的RDB文件都总是可用的。RDB的缺点，就是一旦数据库出现问题，我们的RDB文件中保存的数据并不是全新的，从上次RDB文件生成到Redis停机这段时间的数据全部丢失。</p>
<p>2）AOF日志</p>
<p><strong>AOF 优点：</strong></p>
<p>使用AOF 会让你的Redis更加耐久: 你可以使用不同的fsync策略：无fsync,每秒fsync,每次写的时候fsync.使用默认的每秒fsync策略,Redis的性能依然很好(fsync是由后台线程进行处理的,主线程会尽力处理客户端请求),一旦出现故障，你最多丢失1秒的数据。</p>
<p>AOF文件是一个只进行追加的日志文件,所以不需要写入seek,即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令,你也也可使用redis-check-aof工具修复这些问题。</p>
<p>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</p>
<p>AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。</p>
<p><strong>AOF 缺点</strong></p>
<p>对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积。</p>
<p>根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。</p>
<h2 id="集群管理的不同"><a href="#集群管理的不同" class="headerlink" title="集群管理的不同"></a>集群管理的不同</h2><p>Memcached是全内存的数据缓冲系统，Redis虽然支持数据的持久化，但是全内存毕竟才是其高性能的本质。作为基于内存的存储系统来说，机器物理内存的大小就是系统能够容纳的最大数据量。如果需要处理的数据量超过了单台机器的物理内存大小，就需要构建分布式集群来扩展存储能力。</p>
<p>Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。下图给出了Memcached的分布式存储实现架构。当客户端向Memcached集群发送数据之前，首先会通过内置的分布式算法计算出该条数据的目标节点，然后数据会直接发送到该节点上存储。但客户端查询数据时，同样要计算出查询数据所在的节点，然后直接向该节点发送查询请求以获取数据。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/third-tools/6.jpg/w600">

<p>相较于Memcached只能采用客户端实现分布式存储，Redis更偏向于在服务器端构建分布式存储。最新版本的Redis已经支持了分布式存储功能。Redis Cluster是一个实现了分布式且允许单点故障的Redis高级版本，它没有中心节点，具有线性可伸缩的功能。下图给出Redis Cluster的分布式存储架构，其中节点与节点之间通过二进制协议进行通信，节点与客户端之间通过ascii协议进行通信。在数据的放置策略上，Redis Cluster将整个key的数值域分成4096个哈希槽，每个节点上可以存储一个或多个哈希槽，也就是说当前Redis Cluster支持的最大节点数就是4096。Redis Cluster使用的分布式算法也很简单：crc16( key ) % HASH_SLOTS_NUMBER。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/third-tools/7.jpg/w600">


<p>为了保证单点故障下的数据可用性，Redis Cluster引入了Master节点和Slave节点。在Redis Cluster中，每个Master节点都会有对应的两个冗余的Slave节点。这样在整个集群中，任意两个节点的宕机都不会导致数据的不可用。当Master节点退出后，集群会自动选择一个Slave节点成为新的Master节点。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/third-tools/8.jpg/w600">

]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>解决GitHub的raw.githubusercontent.com无法连接问题</title>
    <url>/vue/%E8%A7%A3%E5%86%B3GitHub%E7%9A%84raw.githubusercontent.com/</url>
    <content><![CDATA[<p><a href="https://site.ip138.com/raw.Githubusercontent.com/" target="_blank" rel="noopener">https://site.ip138.com/raw.Githubusercontent.com/</a></p>
<p>输入raw.githubusercontent.com</p>
<p>查询IP地址</p>
<p>修改hosts Ubuntu，CentOS及macOS直接在终端输入</p>
<p><code>sudo vi /etc/hosts</code></p>
<p>添加以下内容保存即可 （IP地址查询后相应修改，可以ping不同IP的延时 选择最佳IP地址）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># GitHub Start</span></span><br><span class="line">52.74.223.119 github.com</span><br><span class="line">192.30.253.119 gist.github.com</span><br><span class="line">54.169.195.247 api.github.com</span><br><span class="line">185.199.111.153 assets-cdn.github.com</span><br><span class="line">151.101.76.133 raw.githubusercontent.com</span><br><span class="line">151.101.108.133 user-images.githubusercontent.com</span><br><span class="line">151.101.76.133 gist.githubusercontent.com</span><br><span class="line">151.101.76.133 cloud.githubusercontent.com</span><br><span class="line">151.101.76.133 camo.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars0.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars1.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars2.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars3.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars4.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars5.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars6.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars7.githubusercontent.com</span><br><span class="line">151.101.76.133 avatars8.githubusercontent.com</span><br><span class="line"><span class="comment"># GitHub End</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title>Vue.js介绍以及优缺点</title>
    <url>/vue/Vue%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E4%BC%98%E7%BC%BA%E7%82%B9/</url>
    <content><![CDATA[<h1 id="一-MVX框架模式了解"><a href="#一-MVX框架模式了解" class="headerlink" title="一.MVX框架模式了解"></a>一.MVX框架模式了解</h1><p>MVX框架模式：MVC+MVP+MVVM</p>
<a id="more"></a>
<ol>
<li>MVC：Model(模型)+View(视图)+controller(控制器)，主要是基于分层的目的，让彼此的职责分开。<br>View通过Controller来和Model联系，Controller是View和Model的协调者，View和Model不直接联系，基本联系都是单向的。<br>用户User通过控制器Controller来操作模板Model从而达到视图View的变化。</li>
</ol>
<ol start="2">
<li>MVP：是从MVC模式演变而来的，都是通过Controller/Presenter负责逻辑的处理+Model提供数据+View负责显示。</li>
</ol>
<p>在MVP中，Presenter完全把View和Model进行了分离，主要的程序逻辑在Presenter里实现。<br>并且，Presenter和View是没有直接关联的，是通过定义好的接口进行交互，从而使得在变更View的时候可以保持Presenter不变。</p>
<p>MVP模式的框架：Riot,js。</p>
<ol start="3">
<li>MVVM：MVVM是把MVC里的Controller和MVP里的Presenter改成了ViewModel。Model+View+ViewModel。</li>
</ol>
<p>View的变化会自动更新到ViewModel,ViewModel的变化也会自动同步到View上显示。这种自动同步是因为ViewModel中的属性实现了Observer，当属性变更时都能触发对应的操作。</p>
<p>MVVM模式的框架有：AngularJS+Vue.js和Knockout+Ember.js后两种知名度较低以及是早起的框架模式。</p>
<ul>
<li>View 是HTML文本的js模板</li>
<li>ViewModel是业务逻辑层（一切js可视业务逻辑，比如表单按钮提交，自定义事件的注册和处理逻辑都在viewmodel里面负责监控俩边的数据）</li>
<li>Model 数据层 对数据的处理（比如增删改查）<br><img data-src="https://img-blog.csdn.net/20170802093304107" alt=""></li>
</ul>
<h1 id="二-Vue-js-是什么"><a href="#二-Vue-js-是什么" class="headerlink" title="二.Vue.js 是什么"></a>二.Vue.js 是什么</h1><p>Vue.js是一个轻巧、高性能、可组件化的MVVM库，同时拥有非常容易上手的API；</p>
<p>Vue.js是一个构建数据驱动的Web界面的库。</p>
<p>Vue.js是一套构建用户界面的 渐进式框架。与其他重量级框架不同的是，Vue 采用自底向上增量开发的设计。Vue 的核心库只关注视图层，并且非常容易学习，非常容易与其它库或已有项目整合。另一方面，Vue 完全有能力驱动采用单文件组件和 Vue 生态系统支持的库开发的复杂单页应用。数据驱动+组件化的前端开发。</p>
<p>简而言之：Vue.js是一个构建数据驱动的 web 界面的渐进式框架。Vue.js 的目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件。核心是一个响应式的数据绑定系统。</p>
<p>Vue.js的特性如下：</p>
<ol>
<li><p>轻量级的框架</p>
</li>
<li><p>双向数据绑定</p>
</li>
<li><p>指令</p>
</li>
<li><p>插件化</p>
</li>
</ol>
<div class="note primary">
            <p>渐进式的理解:<br>申明式渲染  &gt;&gt;  组件系统  &gt;&gt;  客户端路由  &gt;&gt;  大规模状态管理  &gt;&gt;  构建工具</p><ol><li>不管是单页面还是多页面。首先都是通过声明式渲染声明每个字段，这是基本的要求。因为我们需要展现一些功能一些信息，那么就要通过渲染才可以。</li><li>通常我们会把公共的头部和尾部抽出来，做成组件。这时候就需要使用组件系统。</li><li>单页面应用程序时往往是需要路由，这时候需要把vue的插件（vue-router）拉进来做路由</li><li>如果我们的项目足够复杂，大量的使用组件而且难以去管理组件的状态，这个时候我们使用vue-resource,vue-resource是集中来管理我们的状态的。</li><li>项目完成后需要构建工具来build我们的系统，来提高我们的效果，最后形成完成的项目。</li></ol>
          </div>

<h1 id="三-Vue-js与其他框架的区别？"><a href="#三-Vue-js与其他框架的区别？" class="headerlink" title="三.Vue.js与其他框架的区别？"></a>三.Vue.js与其他框架的区别？</h1><h2 id="1-与angularjs的区别"><a href="#1-与angularjs的区别" class="headerlink" title="1.与angularjs的区别"></a>1.与angularjs的区别</h2><p>相同点：</p>
<ol>
<li><p>都支持指令：内置指令和自定义指令。</p>
</li>
<li><p>都支持过滤器：内置过滤器和自定义过滤器。</p>
</li>
<li><p>都支持双向数据绑定。</p>
</li>
<li><p>都不支持低端浏览器。</p>
</li>
</ol>
<p>不同点：</p>
<ol>
<li><p>AngularJS的学习成本高，比如增加了Dependency Injection特性，而Vue.js本身提供的API都比较简单、直观。</p>
</li>
<li><p>在性能上，AngularJS依赖对数据做脏检查，所以Watcher越多越慢。<br>Vue.js使用基于依赖追踪的观察并且使用异步队列更新。所有的数据都是独立触发的。<br>对于庞大的应用来说，这个优化差异还是比较明显的。</p>
</li>
</ol>
<h2 id="2-与React的区别"><a href="#2-与React的区别" class="headerlink" title="2. 与React的区别"></a>2. 与React的区别</h2><p>相同点：</p>
<ol>
<li>都使用 Virtual DOM</li>
<li>提供了响应式 (Reactive) 和组件化 (Composable) 的视图组件。</li>
<li>将注意力集中保持在核心库，而将其他功能如路由和全局状态管理交给相关的库。</li>
<li>react采用特殊的JSX语法，Vue.js在组件开发中也推崇编写.vue特殊文件格式，对文件内容都有一些约定，两者都需要编译后使用。</li>
<li>中心思想相同：一切都是组件，组件实例之间可以嵌套。</li>
<li>都提供合理的钩子函数，可以让开发者定制化地去处理需求。</li>
<li>都不内置列数AJAX，Route等功能到核心包，而是以插件的方式加载。</li>
<li>在组件开发中都支持mixins的特性。</li>
</ol>
<p>不同点：</p>
<ol>
<li><p>在 React 应用中，当某个组件的状态发生变化时，它会以该组件为根，重新渲染整个组件子树。<br>在 Vue 应用中，组件的依赖是在渲染过程中自动追踪的，所以系统能精确知晓哪个组件确实需要被重渲染。你可以理解为每一个组件都已经自动获得了 shouldComponentUpdate。</p>
</li>
<li><p>在 React 中，一切都是 JavaScript。不仅仅是 HTML 可以用 JSX 来表达，现在的潮流也越来越多地将 CSS 也纳入到 JavaScript 中来处理。这类方案有其优点，但也存在一些不是每个开发者都能接受的取舍。<br>Vue 的整体思想是拥抱经典的 Web(HTML) 技术，并在其上进行扩展。</p>
</li>
</ol>
<p>即 JSX vs Templates</p>
<ul>
<li><p>在 React 中，所有的组件的渲染功能都依靠 JSX。JSX 是使用 XML 语法编写 JavaScript 的一种语法糖。</p>
<p>使用 JSX 的渲染函数有下面这些优势：</p>
<ol>
<li><p>你可以使用完整的编程语言 JavaScript 功能来构建你的视图页面。比如你可以使用临时变量、JS 自带的流程控制、以及直接引用当前 JS 作用域中的值等等。</p>
</li>
<li><p>开发工具对 JSX 的支持相比于现有可用的其他 Vue 模板还是比较先进的 (比如，linting、类型检查、编辑器的自动完成)。</p>
</li>
</ol>
</li>
<li><p>事实上 Vue 也提供了渲染函数，甚至支持 JSX。然而，默认推荐的还是模板。任何合乎规范的 HTML 都是合法的 Vue 模板，这也带来了一些特有的优势：</p>
<ol>
<li><p>对于很多习惯了 HTML 的开发者来说，模板比起 JSX 读写起来更自然。这里当然有主观偏好的成分，但如果这种区别会导致开发效率的提升，那么它就有客观的价值存在。</p>
</li>
<li><p>基于 HTML 的模板使得将已有的应用逐步迁移到 Vue 更为容易。</p>
</li>
<li><p>这也使得设计师和新人开发者更容易理解和参与到项目中。</p>
</li>
<li><p>你甚至可以使用其他模板预处理器，比如 Pug 来书写 Vue 的模板。</p>
</li>
<li><p>Vue.js在模板中提供了指令，过滤器等，可以非常方便，快捷地操作DOM。</p>
</li>
</ol>
</li>
</ul>
<h1 id="四-应用场景："><a href="#四-应用场景：" class="headerlink" title="四.应用场景："></a>四.应用场景：</h1><p>针对具有复杂交互逻辑的前端应用；</p>
<ol>
<li><p>它可以提供基础的架构抽象；</p>
</li>
<li><p>可以通过AJAX数据持久化，保证前端用户体验</p>
</li>
</ol>
<p>好处：<br>当前端和数据做一些操作的时候，可以通过AJAX请求对后端做数据持久化，不需要刷新整个页面，只需要改动DOM里需要改动的那部分数据。特别是移动端应用场景，刷新页面太昂贵，会重新加载很多资源，虽然有些会被缓存，但是页面的DOM,JS,CSS都会被页面重新解析一遍，因此移动端页面通常会做出SPA单页应用。</p>
<p>Vue.js的特点：MVVM框架、数据驱动、组件化、轻量、简洁、高效、快速、模块友好</p>
<h1 id="Vue生命周期图示"><a href="#Vue生命周期图示" class="headerlink" title="Vue生命周期图示"></a>Vue生命周期图示</h1><p><img data-src="https://cn.vuejs.org/images/lifecycle.png" alt=""></p>
<h1 id="Vue的双向数据绑定原理是什么"><a href="#Vue的双向数据绑定原理是什么" class="headerlink" title="Vue的双向数据绑定原理是什么"></a>Vue的双向数据绑定原理是什么</h1><p>vue是采用数据劫持，并且使用发布-订阅者的开发模式。原理是观察者observer通过Object.defineProperty()来劫持到各个属性的getter setter，在数据变动的时候，会被observer观察到，会通过Dep通知数据的订阅者watcher，之后进行相应的视图上面的变化。</p>
<p>具体实现步骤：</p>
<ul>
<li><p>第一步：需要observe的数据对象进行递归遍历，包括子属性对象的属性，都加上 setter和getter<br>这样的话，给这个对象的某个值赋值，就会触发setter，那么就能监听到了数据变化</p>
</li>
<li><p>第二步：compile解析模板指令，将模板中的变量替换成数据，然后初始化渲染页面视图，并将每个指令对应的节点绑定更新函数，添加监听数据的订阅者，一旦数据有变动，收到通知，更新视图</p>
</li>
<li><p>第三步：Watcher订阅者是Observer和Compile之间通信的桥梁，主要做的事情是: </p>
<ol>
<li>在自身实例化时往属性订阅器(dep)里面添加自己 </li>
<li>自身必须有一个update()方法 </li>
<li>待属性变动dep.notice()通知时，能调用自身的update()方法，并触发Compile中绑定的回调，则功成身退。</li>
</ol>
</li>
<li><p>第四步：MVVM作为数据绑定的入口，整合Observer、Compile和Watcher三者，通过Observer来监听自己的model数据变化，通过Compile来解析编译模板指令，最终利用Watcher搭起Observer和Compile之间的通信桥梁，达到数据变化 -&gt; 视图更新；视图交互变化(input) -&gt; 数据model变更的双向绑定效果</p>
</li>
</ul>
<p>参考：<br><a href="https://cn.vuejs.org/v2/guide/comparison.html" target="_blank" rel="noopener">https://cn.vuejs.org/v2/guide/comparison.html</a></p>
]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title>Git使用规范</title>
    <url>/pm/Git%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>本人在实际工作中总结出的Git使用规范，比较简单，容易落地。</p>
<h1 id="1-分支管理"><a href="#1-分支管理" class="headerlink" title="1. 分支管理"></a>1. 分支管理</h1><p>开发过程主要存在以下分支：</p>
<ul>
<li>master</li>
<li>develop</li>
<li>release</li>
<li>hotfix-[问题名称 | bug编号]</li>
<li>feature-[功能名称]</li>
<li>bugfix-[bug编号]</li>
<li>refactor-[重构名称]</li>
</ul>
<h2 id="1-1-master-主分支"><a href="#1-1-master-主分支" class="headerlink" title="1.1 master 主分支"></a>1.1 master 主分支</h2><ul>
<li>master主分支 用于部署生产环境的分支,确保master分支稳定性,始终保持稳定的可发布版本</li>
<li>master 分支一般由release以及hotfix分支合并，任何时间都不能直接修改代码</li>
<li>只有项目组主程才拥有master主分支的管理权限（例如其他分支合并到master必须由主程操作）</li>
</ul>
<h2 id="1-2-develop-开发分支"><a href="#1-2-develop-开发分支" class="headerlink" title="1.2 develop 开发分支"></a>1.2 develop 开发分支</h2><ul>
<li>develop开发分支为不稳定版本，但已有的功能必须是完整的</li>
<li>始终保持最新完成以及bug修复后的代码</li>
<li>原则上不允许直接在develop分支上进行功能开发，必须新建feature分支进行开发</li>
</ul>
<h2 id="1-3-release分支-预上线分支"><a href="#1-3-release分支-预上线分支" class="headerlink" title="1.3 release分支 预上线分支"></a>1.3 release分支 预上线分支</h2><ul>
<li>release 为预上线分支，发布提测阶段，会release分支代码为基准提测</li>
<li>当有一组feature开发完成，首先会合并到develop分支，进入提测时，会创建release分支。<br>如果测试过程中若存在bug需要修复，则直接由开发者在release分支修复并提交。<br>当测试完成之后，合并release分支到master和develop分支，此时master为最新代码，用作上线。</li>
</ul>
<h2 id="1-4-hotfix-问题名称-bug编号-紧急热修复分支"><a href="#1-4-hotfix-问题名称-bug编号-紧急热修复分支" class="headerlink" title="1.4 hotfix-[问题名称 | bug编号] 紧急热修复分支"></a>1.4 hotfix-[问题名称 | bug编号] 紧急热修复分支</h2><ul>
<li>线上出现紧急问题时，需要及时修复，以master分支为基线，创建hotfix分支，横线后面跟上问题名称或者对应的bug编号，仅仅适用于<strong>生产线问题紧急修复</strong>！！</li>
<li>修复完成，测试通过，合并到master和develop分支上，然后将此分支删除</li>
</ul>
<h2 id="1-5-feature-功能名称-功能开发分支"><a href="#1-5-feature-功能名称-功能开发分支" class="headerlink" title="1.5 feature-[功能名称] 功能开发分支"></a>1.5 feature-[功能名称] 功能开发分支</h2><ul>
<li>从develop分支创建，横线后跟功能名称，用于新功能开发，每天下班前push提交到远程</li>
<li>开发完成以后，在远程发起向develop分支的合并请求，由指定的CodeReview人员审查通过以后进行合并，并删除该分支</li>
<li>命名规则: feature-user_module、 feature-cart_module</li>
</ul>
<h2 id="1-6-bugfix-bug编号-问题修复分支"><a href="#1-6-bugfix-bug编号-问题修复分支" class="headerlink" title="1.6 bugfix-[bug编号] 问题修复分支"></a>1.6 bugfix-[bug编号] 问题修复分支</h2><ul>
<li>从develop分支创建，用于修改测试提出的bug，横线后跟bug编号</li>
<li>修复以后，在远程发起向develop分支的合并请求，并指定提交者自身（或其他人）作为CodeReview，合并以后删除该分支</li>
</ul>
<h2 id="1-7-refactor-重构名称-重构分支"><a href="#1-7-refactor-重构名称-重构分支" class="headerlink" title="1.7 refactor-[重构名称] 重构分支"></a>1.7 refactor-[重构名称] 重构分支</h2><ul>
<li>从develop分支创建，用于代码的<strong>重大规模重构</strong>（小规模重构创建feature分支即可）</li>
<li>重构以后，必须经过严格测试通过，才能向develop分支合并。</li>
</ul>
<h2 id="常见任务"><a href="#常见任务" class="headerlink" title="常见任务"></a>常见任务</h2><h3 id="增加新功能"><a href="#增加新功能" class="headerlink" title="增加新功能"></a>增加新功能</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(develop)$: git checkout -b feature/xxx            <span class="comment"># 从develop建立特性分支</span></span><br><span class="line">(feature/xxx)$: blabla                         <span class="comment"># 开发</span></span><br><span class="line">(feature/xxx)$: git add xxx</span><br><span class="line">(feature/xxx)$: git commit -m <span class="string">'commit comment'</span></span><br><span class="line">(develop)$: git merge feature/xxx --no-ff          <span class="comment"># 把特性分支合并到develop</span></span><br></pre></td></tr></table></figure>
<h3 id="修复紧急bug"><a href="#修复紧急bug" class="headerlink" title="修复紧急bug"></a>修复紧急bug</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(master)$: git checkout -b hotfix/xxx         <span class="comment"># 从master建立hotfix分支</span></span><br><span class="line">(hotfix/xxx)$: blabla                         <span class="comment"># 开发</span></span><br><span class="line">(hotfix/xxx)$: git add xxx</span><br><span class="line">(hotfix/xxx)$: git commit -m <span class="string">'commit comment'</span></span><br><span class="line">(master)$: git merge hotfix/xxx --no-ff       <span class="comment"># 把hotfix分支合并到master，并上线到生产环境</span></span><br><span class="line">(develop)$: git merge hotfix/xxx --no-ff          <span class="comment"># 把hotfix分支合并到develop，同步代码</span></span><br></pre></td></tr></table></figure>

<h3 id="预发布环境代码"><a href="#预发布环境代码" class="headerlink" title="预发布环境代码"></a>预发布环境代码</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(release)$: git merge develop --no-ff     <span class="comment"># 把develop分支合并到release，然后在测试环境拉取并测试</span></span><br></pre></td></tr></table></figure>

<h3 id="生产环境上线"><a href="#生产环境上线" class="headerlink" title="生产环境上线"></a>生产环境上线</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(master)$: git merge release --no-ff      <span class="comment"># 把testing测试好的代码合并到master</span></span><br><span class="line">(master)$: git tag -a v0.1 -m <span class="string">'部署包版本名'</span>  <span class="comment">#给版本命名，打Tag</span></span><br></pre></td></tr></table></figure>

<h1 id="2-Commit-提交规范"><a href="#2-Commit-提交规范" class="headerlink" title="2. Commit 提交规范"></a>2. Commit 提交规范</h1><h2 id="2-1-commit提交的日志格式"><a href="#2-1-commit提交的日志格式" class="headerlink" title="2.1 commit提交的日志格式"></a>2.1 commit提交的日志格式</h2><p><type>: <subject><br><BLANK LINE></p>
<body>
<BLANK LINE>
<footer>

<ul>
<li>type: 本次 commit 的类型，如feat fix doc refactor 等</li>
<li>subject: 简明扼要的阐述下本次 commit 的主旨，在原文中特意强调了几点 1. 使用祈使句，是不是很熟悉又陌生的一个词，来传送门在此 祈使句 2. 首字母不要大写 3. 结尾无需添加标点</li>
<li>body: 同样使用祈使句，在主体内容中我们需要把本次 commit 详细的描述一下，比如此次变更的动机，如需换行，则使用 |</li>
<li>footer: 描述下与之关联的 issue 或 break change，详见案例</li>
</ul>
<table>
<thead>
<tr>
<th align="left">类型</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">feat</td>
<td align="left">feature，即新开发的功能</td>
</tr>
<tr>
<td align="left">fix</td>
<td align="left">问题修复</td>
</tr>
<tr>
<td align="left">refactor</td>
<td align="left">重构代码</td>
</tr>
<tr>
<td align="left">doc</td>
<td align="left">增加文档（如readme），注释等</td>
</tr>
</tbody></table>
<p>例如：</p>
<p>fix:修复身份证含字母X的用户无法注册问题<br>fix: 紧急修复生产线用户积分不显示的问题<br>feat:商品详情页功能<br>doc:增加项目readme文档，修改结算条款结算逻辑的注释</p>
<h2 id="2-2-Commit提交频率"><a href="#2-2-Commit提交频率" class="headerlink" title="2.2 Commit提交频率"></a>2.2 Commit提交频率</h2><p>每天下班前必须提交feature分支，并push到远程<br>hotfix、feature、bugfix、refactor分支尽量按照功能点或修复重构的问题及时commit（不要求push）</p>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>ab性能压测</title>
    <url>/pm/ab%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<h2 id="ab命令原理"><a href="#ab命令原理" class="headerlink" title="ab命令原理"></a>ab命令原理</h2><p>Apache的ab命令模拟多线程并发请求，测试服务器负载压力，也可以测试nginx、lighthttp、IIS等其它Web服务器的压力。 </p>
<a id="more"></a>
<p>ab命令对发出负载的计算机要求很低，既不会占用很多CPU，也不会占用太多的内存，但却会给目标服务器造成巨大的负载，因此是某些DDOS攻击之必备良药，老少皆宜。自己使用也须谨慎。否则一次上太多的负载，造成目标服务器直接因内存耗光死机，而不得不硬重启，得不偿失。</p>
<h2 id="采用linux的ab命令执行web接口性能测试"><a href="#采用linux的ab命令执行web接口性能测试" class="headerlink" title="采用linux的ab命令执行web接口性能测试"></a>采用linux的ab命令执行web接口性能测试</h2><p>Mac OS X中配置Apache</p>
<p>参考 <a href="http://www.cnblogs.com/snandy/archive/2012/11/13/2765381.html" target="_blank" rel="noopener">http://www.cnblogs.com/snandy/archive/2012/11/13/2765381.html</a></p>
<h2 id="mac中应该是自带了Apache"><a href="#mac中应该是自带了Apache" class="headerlink" title="mac中应该是自带了Apache"></a>mac中应该是自带了Apache</h2><p>终端查看mac版本</p>
<p>more /System/Library/CoreServices/SystemVersion.plist</p>
<p>显示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;key&gt;ProductVersion&lt;&#x2F;key&gt;</span><br><span class="line">&lt;string&gt;10.9.3&lt;&#x2F;string&gt;</span><br></pre></td></tr></table></figure>
<p>Apache启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apachectl start</span><br></pre></td></tr></table></figure>
<p>打开Safari浏览器地址栏输入 “<a href="http://localhost”，可以看到内容为“It" target="_blank" rel="noopener">http://localhost”，可以看到内容为“It</a> works!”的页面。表示启动成功。</p>
<h2 id="下载安装httpd-2-4-10"><a href="#下载安装httpd-2-4-10" class="headerlink" title="下载安装httpd-2.4.10"></a>下载安装httpd-2.4.10</h2><p>下载链接：<a href="http://httpd.apache.org/download.cgi" target="_blank" rel="noopener">http://httpd.apache.org/download.cgi</a></p>
<h2 id="使用ab进行web接口性能测试"><a href="#使用ab进行web接口性能测试" class="headerlink" title="使用ab进行web接口性能测试"></a>使用ab进行web接口性能测试</h2><p>终端进入到httpd-2.4.10/support目录</p>
<p>cd /Users/onlyone/software/httpd-2.4.27</p>
<p>ab -r -n 200 -c 10 <a href="http://localhost:8092/data/get1" target="_blank" rel="noopener">http://localhost:8092/data/get1</a></p>
<p>-n：请求数</p>
<p>-c：并发数</p>
<p>注意：压测时如果报错：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Benchmarking localhost (be patient)</span><br><span class="line">socket: Too many open files in system (23)</span><br><span class="line">Total of 327 requests completed</span><br></pre></td></tr></table></figure>
<p>mac或linux系统有文件限制，结果文件数超过最大限制，导致程序异常。</p>
<p> ulimit -a  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-t: cpu time (seconds)              unlimited</span><br><span class="line">-f: file size (blocks)              unlimited</span><br><span class="line">-d: data seg size (kbytes)          unlimited</span><br><span class="line">-s: stack size (kbytes)             8192</span><br><span class="line">-c: core file size (blocks)         0</span><br><span class="line">-v: address space (kbytes)          unlimited</span><br><span class="line">-l: locked-in-memory size (kbytes)  unlimited</span><br><span class="line">-u: processes                       709</span><br><span class="line">-n: file descriptors                327  (文件数)</span><br></pre></td></tr></table></figure>

<p> 调整文件系统值</p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ulimit -n 8192</span><br></pre></td></tr></table></figure>

<h2 id="ab压测结果分析"><a href="#ab压测结果分析" class="headerlink" title="ab压测结果分析"></a>ab压测结果分析</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">This is ApacheBench, Version 2.3 &lt;$Revision: 655654 $&gt; </span><br><span class="line">Copyright 1996 Adam Twiss, Zeus Technology Ltd, http:&#x2F;&#x2F;www.zeustech.net&#x2F; </span><br><span class="line">Licensed to The Apache Software Foundation, http:&#x2F;&#x2F;www.apache.org&#x2F;</span><br><span class="line"></span><br><span class="line">Benchmarking 192.168.0.10 (be patient) </span><br><span class="line">Completed 100 requests </span><br><span class="line">Completed 200 requests </span><br><span class="line">Completed 300 requests </span><br><span class="line">Completed 400 requests </span><br><span class="line">Completed 500 requests </span><br><span class="line">Completed 600 requests </span><br><span class="line">Completed 700 requests </span><br><span class="line">Completed 800 requests </span><br><span class="line">Finished 800 requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Server Software:        Microsoft-HTTPAPI&#x2F;2.0 </span><br><span class="line">Server Hostname:        192.168.0.10 </span><br><span class="line">Server Port:            80</span><br><span class="line"></span><br><span class="line">Document Path:          &#x2F; </span><br><span class="line">Document Length:        315 bytes       HTTP响应数据的正文长度</span><br><span class="line"></span><br><span class="line">Concurrency Level:      800 </span><br><span class="line">Time taken for tests:   0.914 seconds    所有这些请求处理完成所花费的时间 </span><br><span class="line">Complete requests:      800             完成请求数 </span><br><span class="line">Failed requests:        0                失败请求数 </span><br><span class="line">Write errors:           0                </span><br><span class="line">Non-2xx responses:      800 </span><br><span class="line">Total transferred:      393600 bytes     网络总传输量 </span><br><span class="line">HTML transferred:       252000 bytes     HTML内容传输量 </span><br><span class="line">Requests per second:    875.22 [#&#x2F;sec] (mean) 吞吐量-每秒请求数 </span><br><span class="line">Time per request:       914.052 [ms] (mean)  服务器收到请求，响应页面要花费的时间 </span><br><span class="line">Time per request:       1.143 [ms] (mean, across all concurrent requests) 并发的每个请求平均消耗时间 </span><br><span class="line">Transfer rate:          420.52 [Kbytes&#x2F;sec] received 平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">网络上消耗的时间的分解： </span><br><span class="line">Connection Times (ms) </span><br><span class="line">              min  mean[+&#x2F;-sd] median   max </span><br><span class="line">Connect:        0    1   0.5      1       3 </span><br><span class="line">Processing:   245  534 125.2    570     682 </span><br><span class="line">Waiting:       11  386 189.1    409     669 </span><br><span class="line">Total:        246  535 125.0    571     684</span><br><span class="line"></span><br><span class="line">整个场景中所有请求的响应情况。在场景中每个请求都有一个响应时间 </span><br><span class="line">其中 50％ 的用户响应时间小于 571 毫秒 </span><br><span class="line">80 ％ 的用户响应时间小于 652 毫秒 </span><br><span class="line">最大的响应时间小于 684 毫秒 </span><br><span class="line">Percentage of the requests served within a certain time (ms) </span><br><span class="line">  50%    571 </span><br><span class="line">  66%    627 </span><br><span class="line">  75%    646 </span><br><span class="line">  80%    652 </span><br><span class="line">  90%    666 </span><br><span class="line">  95%    677 </span><br><span class="line">  98%    681 </span><br><span class="line">  99%    682 </span><br><span class="line">100%    684 (longest request)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>互联网产品生命周期</title>
    <url>/pm/product-lifecycle/</url>
    <content><![CDATA[<img data-src="http://f.ngall-in.com/alan87/static/images/pm/7.png/w600">
<a id="more"></a>]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>项目管理</title>
    <url>/pm/project-management/</url>
    <content><![CDATA[<h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><ul>
<li><a href="项目生命周期.md">项目生命周期</a></li>
<li><a href="product-lifecycle.md">互联网产品生命周期</a></li>
</ul>
<a id="more"></a>
<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/jqi2PUKwr8N44bpCLPdnyQ" target="_blank" rel="noopener">CIO:如何建立高效的IT架构</a></li>
</ul>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>测试相关</title>
    <url>/pm/test/</url>
    <content><![CDATA[<h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><ul>
<li><a href="/ab测试">ab性能压测</a></li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>从技术转型做管理总结</title>
    <url>/pm/%E4%BB%8E%E6%8A%80%E6%9C%AF%E8%BD%AC%E5%9E%8B%E5%81%9A%E7%AE%A1%E7%90%86%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>中国互联网经过过去十多年野蛮式的发展似乎这两年开始慢下来了，程序员 35 岁的退休年龄虽然只是贩卖焦虑的一种说法，但是整个行业对人的要求越来越高是不争的事实，要求我们的成长速度必须跟上。</p>
<a id="more"></a>
<p>2020 年，希望自己在技术、管理、业务这三个维度再做更深层次的学习，体系化个人的认知，做一个有特点的 IT 人。</p>
<p>下文的主题是关于『工程师如何从技术转型做管理』，这是我在团队管理上第一篇系统性的总结。</p>
<p>之所以选择这个主题：</p>
<ul>
<li><p>一方面，个人觉得转型做管理是当前环境下大部分程序员会选择的职业路径。</p>
</li>
<li><p>另一方面，自己亲身经历了比较漫长的转型过程，应该能写出点心得体会。</p>
</li>
</ul>
<p>希望下面的内容对于『正在转型挣扎期』或者『后续有规划往管理转型』的同学，让你们有所启发。</p>
<p>内容大概分成以下四个部分：</p>
<ul>
<li>什么样的工程师会被提拔做管理？</li>
<li>你选择做管理的初衷是什么？</li>
<li>转型期你会遇到哪些困惑或者挑战？</li>
<li>转型期应该具备哪些心智？</li>
</ul>
<h2 id="什么样的工程师会被提拔做管理？"><a href="#什么样的工程师会被提拔做管理？" class="headerlink" title="什么样的工程师会被提拔做管理？"></a>什么样的工程师会被提拔做管理？</h2><p>一般来说，满足这三个条件的工程师会被提拔做管理：技术能力强、业务熟练、软性素质达标。（当然还要看公司是否有管理岗位的空缺以及你个人的意愿），下面分别展开说下重点。</p>
<ul>
<li>①技术方面：常用技术的深度和宽度缺一不可，架构能力非常关键。否则技术方向都把握不好，技术决策也容易出问题。</li>
</ul>
<p>如果技术能力没达到一定水平，不建议太早转管理（个人感觉能力至少要接近阿里的 P7，腾讯的 T3-1，百度的 T6）。</p>
<ul>
<li><p>②业务方面：不了解业务，技术没法落地，不仅要求熟悉业务而且应该具备比较强的业务意识，（如果能从技术维度提出好想法，帮助业务拿到更好的结果，这种 Leader 是非常受欢迎的）。</p>
</li>
<li><p>③软性素质达标：软性素质这个词有些泛，我个人觉得最核心的两点，沟通协调能力和做事靠不靠谱。软性都是可以锻炼的，但是一定要有意识去提升。</p>
</li>
</ul>
<p>著名管理学家陈春花老师说，“一个人被组织提拔，其实不是因为能力，而是因为信任”，聪明的人很多，但是靠谱的人很少，比能力更重要的是工作的投入感和靠谱的态度。</p>
<p>如果你觉得上述三个方面都达到要求了，我觉得只是差一个机会，否则好好提升自己吧。</p>
<h2 id="你选择做管理的初衷是什么？"><a href="#你选择做管理的初衷是什么？" class="headerlink" title="你选择做管理的初衷是什么？"></a>你选择做管理的初衷是什么？</h2><p>之前有人问过我一个问题，“你觉得我适合做管理吗？能给我些建议吗？”，我当时没有正面回答他，而是反过来问他，“你能先告诉我，做管理对你意味着什么？它能给你带来什么呢？”。</p>
<p>当然我不是在质疑他，而是想让他反思他做管理的初衷。我觉得『最原始的动机』会决定你在管理路上能扛多大的压力以及能走多远。</p>
<p>关于初衷，我见过最普遍的说法有这么几种：</p>
<p>技术不能做一辈子，很多前辈在能力达到一定水平后都转管理了，自己也这么想。在技术路线上遇到了晋升瓶颈，想尝试下管理方向，看自己是否合适。公司发展太快了，老板让我带团队，自己也没办法。管理者工资高，在别人眼中是优秀的代表。指挥做事即可，可以脱离执行层面，越往上走越轻松。</p>
<p>上面这几类都属于『外部因素』驱动，说实话，都很难在管理路上走得很远。</p>
<p>因为技术管理是极其复杂和琐碎的工作，它远没有你想象中的轻松和风光，而在这些外力下，你做出决策后的结果很多时候跟你的预期是不一致的，这个时候你的怨气和转型痛苦就会出现，你开始质疑你选择的这条路是不是错了？</p>
<p>再来看另外一个问题，作为技术管理者，对于公司、团队以及你个人，你觉得它的价值分别是什么？</p>
<p>我个人的解读是这样的：</p>
<div class="note primary">
            <ul><li><p>对于公司：能带领技术团队支撑好业务，帮助业务实现公司定的战略目标。</p></li><li><p>对于团队：规划好方向，别让组员瞎忙，同时能帮助他们成长。</p></li><li><p>对于个人：提升自身的技术和管理能力。</p></li></ul>
          </div>

<p>这是对于技术管理岗位的基本认知，你的初衷必须建立在这个认知基础之上。然后试问你自己：是否认可这个岗位的价值？</p>
<p>如果你觉得全是牺牲自己来成就公司和团队，那你不可能做得开心，也不可能做好。</p>
<p>第二个问题，你是否对管理者的工作充满热情？并且享受这个过程呢？比如项目协调，比如制定流程并推动落地执行，比如招聘。</p>
<p>如果你说我只喜欢做技术相关的工作（比如架构设计、技术评审等），那么你还是走技术路线吧。</p>
<p>认可技术管理岗位的价值所在，并且能激发你的投入意愿。这些就是底层最好的动力，你的成长和回报都是付出后水到渠成的东西。所以这个初衷很重要，三观一定要正。</p>
<h2 id="转型期你会遇到哪些困惑或者挑战？"><a href="#转型期你会遇到哪些困惑或者挑战？" class="headerlink" title="转型期你会遇到哪些困惑或者挑战？"></a>转型期你会遇到哪些困惑或者挑战？</h2><p>转型期会经历心态、工作方式的转变，很多事情会刷新你的认知。</p>
<p>下面几点，我认为是绝大部分人在转型过程中会遇到的困惑或者挑战：</p>
<ol>
<li><p>时间不够用：成为团队 Leader 后有很多日常事务要处理，要参加各种会议，有时候还需要分出一部分精力在一线 Coding 上，时间完全被碎片化，根本不够用。</p>
</li>
<li><p>嫌组员效率低：一个你认为简单的需求或者技术问题，交给团队成员后，他们的处理时间远超出你的预期，当外界施压时，你忍不住抱怨和责怪，并开始自己动手处理，久而久之，习惯自己冲在一线，觉得这样效率最高。</p>
</li>
<li><p>恨人际关系复杂：对内对外、对上对下，每天需要和不同职位、不同level的人打交道，有靠谱的，有不靠谱的，某些你认为很简单的事情推动起来却很难，感觉情商不够用。</p>
</li>
<li><p>成就感不强：偶尔会收到上级、平级、甚至下级的负面反馈，你开始质疑自己的管理能力，不像做工程师那样经常被认可，落差感强。</p>
</li>
<li><p>不敢放弃一线：担心自己不合适做管理，如果脱离一线执行，感觉技术能力会停滞不前。不放弃一线，精力又跟不上，这个度把握不好。</p>
</li>
</ol>
<p>上述疑惑是我个人转型过程中体会最深的几点，我在后文中会分别给出自己的看法和建议。</p>
<h2 id="转型期应该具备哪些心智？"><a href="#转型期应该具备哪些心智？" class="headerlink" title="转型期应该具备哪些心智？"></a>转型期应该具备哪些心智？</h2><p>从技术转型做管理，更多的不是能力的变化，而是思维方式和行为的改变。</p>
<p>很多刚转型的 Leader 管理做不好，绝大部分不是因为能力不行，而是出现在了认知上。</p>
<p>以下几点，我认为是转型期 Leader 一定要具备的心智：</p>
<div class="note primary">
            <ol><li>学会从团队的角度考虑问题</li><li>注重执行细节</li><li>学会用人所长具备包容心</li><li>重视情商，做好自我情绪控制</li><li>做好时间管理</li></ol>
          </div>

<h3 id="1-学会从团队角度考虑问题"><a href="#1-学会从团队角度考虑问题" class="headerlink" title="1. 学会从团队角度考虑问题"></a>1. 学会从团队角度考虑问题</h3><p>以前作为工程师，更多是从事情本身或者从个人角度出发，成为 Leader 后，转变成团队思维是最最重要的，因为你的 KPI 取决于你整个团队的完成情况，你要权衡的是团队整体的利益和效能。</p>
<p><img data-src="https://pics6.baidu.com/feed/6a600c338744ebf81d7f02874473832c6159a788.png?token=c4cb62630a5c3063db21643e6e1c29a1&s=2DD6E8124F705A8A5C6984CB030060B7" alt=""></p>
<p>上面四项对比，是我个人认为比较典型的 Case，比如上一节提到的一种情况：Leader 觉得某个问题很简单，嫌员工处理效率低，然后自己跳出来三下五除二给解决了，这种就属于很典型的员工思维。</p>
<p>单从搞定这件事情来看，这也许是很好的处理方式，业务方也会很满意，但是带团队是长远的事情，上述做法紧急情况可行，但是变成常态就是非常大的问题。</p>
<p>团队能力不提高，Leader 永远不会解放，这是作为 Leader 应该具备的意识。</p>
<p>如果通过这个问题能够提升组员某方面的能力，Leader 应该扮演好教练的角色，放手让组员自己去做，你要做的仅仅是观察、给一些指点、适当给予时间上的支持。</p>
<p>这次处理也许效率不高，但是下次碰到类似的问题，团队是不需要依靠你来解决的，另外组员也有自己的发挥空间，觉得团队在帮助他成长。</p>
<h3 id="2-注重执行细节"><a href="#2-注重执行细节" class="headerlink" title="2. 注重执行细节"></a>2. 注重执行细节</h3><p>对于刚转型做管理的一线 Leader，切忌被放权式的管理方式洗脑。</p>
<p>放权式管理对于对管理者的经验要求很高，它比较适用于工作流程清晰，团队骨干目标认知以及自驱力很强的团队。</p>
<p>当你个人的管理水平还处于菜鸟期时，一定要从细节抓起，通过手把手带员工，教会他们如何正确的做事，怎么才能达到你的要求，以及如何培养出团队骨干，搭建出团队的核心组织架构。</p>
<p>所有这些都经历过了，你在管理上才会有自己的心得体会，才会走得更扎实。</p>
<p>通过观察执行细节，你能非常清楚团队每个人的优劣势，深入感受自己的管理方式是否存在问题，然后再辅以 Leader 思维去思考和解决问题，管理上才能真正获得成长。</p>
<p>这个过程，你可能会收到上级、平级、下级的很多反馈，清楚细节后其实你就有了自己的判断，知道是否是自身的问题，是否要调整，而不是沮丧抓瞎。</p>
<h3 id="3-学会用人所长，具备包容心"><a href="#3-学会用人所长，具备包容心" class="headerlink" title="3. 学会用人所长，具备包容心"></a>3. 学会用人所长，具备包容心</h3><p>知人善任、人尽其才，是每个管理者都懂的道理，但是能做到的不多。</p>
<p>尤其在技术管理岗上，我见过有些 Leader 在技术上非常强势，技术权威不容有任何挑战，当组员提出更合理的技术方案时，他会用职级强制要求按自己说的执行，根本不做任何解释。</p>
<p>对于新晋 Leader，团队对你的信任感还在磨合期，上述做法很容易打击组员的积极性，消灭他们的创造力，这对你带团队来说是非常致命的。</p>
<p>如果组员的方案更合理，Leader 应该倍感欣慰，包容并鼓励这种行为，因为组员某方面的专业能力超过你了，你不再是团队各方面最强的人，你需要做的是调整自己的心智，学会用人所长。</p>
<p>另外，还有一种情况是：组员和 Leader 的技术方案都可行，我个人倾向将选择权交给组员，毕竟他们是真正的执行者，应该给他们自由发挥的空间，最后就算出问题对他们来说也是很好的经验积累。</p>
<h3 id="4-重视情商，做好自我情绪控制"><a href="#4-重视情商，做好自我情绪控制" class="headerlink" title="4.重视情商，做好自我情绪控制"></a>4.重视情商，做好自我情绪控制</h3><p>管理上能做多大事情，真的和情商有非常大的关系。IT 界的技术人员由于工作性质的原因，普遍注重技术上的提升，而忽略情商的培养和维护，作为新晋 Leader 必须从一开始就意识到情商的重要性。</p>
<p>管理是一个复合型的岗位，当你的专业技能和处理问题的方法论已经形成后，越往上发展，为人处事的软技能占比会越来越重。</p>
<p>每天和不同的人打交道，这个是管理者的日常工作，因为你需要调动所有可能的资源去解决团队的困难。</p>
<p>面对不同职位、不同 Level、不同性格的人，你要反复琢磨采取何种沟通方式和沟通技巧。</p>
<p>上一节提到一种情况：一件你认为很简单的事情，推动起来却很困难。</p>
<p>可能是因为你对外的沟通方式太生硬，别人不想配合你，或者别人确实有其他更重要的事情，但是如果私下关系建立好，你再当面软磨硬泡，多半也是可以解决的。</p>
<p>人际关系上，难免会有碰壁的时候，不要气馁，这跟技术同学写出 1 个 Bug 一样，是家常便饭的事情，但是一定要注意积累经验。</p>
<p>线下和关键的配合方维护好私人关系，多吃饭喝酒，别人有困难能及时伸出援手等等，套路有很多。</p>
<p>情绪控制，是一个比较难的事情。情绪很容易传递，如果 Leader 碰到不爽的事情，把组员当做出气筒，这是非常伤士气的，之前建立的信任感很容易消失，受不了的组员也可能就离职了。</p>
<p>另外，对外沟通上，如果 Leader 控制不好情绪，不将重点放在解决问题上，只是抱怨或者发火，也非常容易引起配合方的不满，认为你不专业，久而久之，你的团队也会被打上这种标签。</p>
<p>个人在情商方面目前做得也很差，踩过很多坑。提供三点建议：</p>
<p>保持积极乐观的心态，同时提高自己面对问题时的承受能力，想清楚情绪化是解决不了问题的，只会加大解决问题的难度。能够自我反省并吸收别人的反馈，做得不好的地方要勇于正视并且持续改进。培养亲和力，不要觉得自己是 Leader 就带着架子，要有一种鞠着的姿态，能够尊重人并且真诚待人。</p>
<h3 id="5-做好时间管理"><a href="#5-做好时间管理" class="headerlink" title="5.做好时间管理"></a>5.做好时间管理</h3><p>时间管理的 4 象限理论可以百度一下。重点说下我个人遇到时间管理问题是怎么解决的，以及技术和管理两个维度如何分配时间。</p>
<p>第一步，可以拿过去一周或者一个月的时间跨度为例，详细列一下你的时间花在哪些具体事情上了，以及每类事情大概的时间占比。</p>
<p>对于技术 Leader 可能的事情包括：需求评审，资源规划和项目排期，技术评审，团队周例会，研发规范制定和落地，项目管理，技术调研，架构设计，Coding，紧急任务协调和处理，业务以及新技术充电等等。</p>
<p>第二步，针对第一步列举的每类事情，考虑下哪些是非必须的，哪些是可以授权给团队骨干去做的，哪些是可以优化提高效率的。</p>
<p>比如一些简单的需求评审或者技术方案评审让骨干把关即可，项目管理制定好流程规范同时培养一些 Scrum Master 或者项目经理下放给他们来做。</p>
<p>不用凡事都事必躬亲，Leader 应该把时间聚焦在对团队最关键的事情上，学会授权和放权。</p>
<p>对于一线 Leader，技术和管理两个维度如何分配时间，个人的建议是：</p>
<p>大部分时间 Leader 是不需要亲自写代码的，但是如果有需要，Leader 要能够随时顶上，所以不能长期远离一线，纸上谈兵。长此以往，技术判断可能容易出现失误，而且如果管理不合适再转型回去代价太高。</p>
<p>技术维度：可以将重点放在架构设计、代码审查、技术调研、以及一些框架性的代码开发上，这些事情对于维持技术优势是足够的。</p>
<p>如果管理维度的时间占比超过 60%，个人觉得比例是有些失衡的，要么团队太大了（比如超过了 10 人），要么自身的管理存在问题或者时间管理存在问题，需要关注并考虑做出调整。</p>
<p>上面这些内容，就是关于工程师转型管理的个人心得。关于管理，后续我会将更多实用的技巧以及方法论结合具体 Case 进行总结和分享！</p>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>代码规范</title>
    <url>/pm/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><a href="https://m.aliyun.com/yunqi//articles/215726?from=groupmessage&isappinstalled=0&utm_content=m_23665" target="_blank" rel="noopener">阿里巴巴java开发手册终极版</a></p>
<p>下文是对里面常用的一些案例及规范的抽取。</p>
<a id="more"></a>
<h1 id="无规矩不成方圆，无规范不能协作"><a href="#无规矩不成方圆，无规范不能协作" class="headerlink" title="无规矩不成方圆，无规范不能协作"></a>无规矩不成方圆，无规范不能协作</h1><p>对软件来说，适当的规范和标准绝不是消灭代码内容的创造性、优雅性，而是限制过度个性化，以一种普遍认可的方式一起做事，降低故障率，提升协作效率。</p>
<p>开发手册详细列举如何开发更加高效，更加容错，更加有协作性，力求知其然，更知其不然，结合正反例，提高代码质量。比如，异常日志处理时的各种不规范行为；集合转换的各种坑；创建线程池出现的等待队列OOM等。</p>
<p>简单，适用的代码规约背后所传递的是技术上的追求卓越、协同合作的精神，是每个技术团队不可缺失的重要利器。<br>代码是软件工程里面的产品设计、系统架构设计等工作的最后承载体，代码的质量决定了一切工作的成败。</p>
<hr>
<h1 id="一、编程规约"><a href="#一、编程规约" class="headerlink" title="一、编程规约"></a>一、编程规约</h1><p>1、所有编程相关命名均不能以下划线或美元符号开始,也不能以下划线或美元符号结束。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">反例: _name &#x2F; __name &#x2F; $Object &#x2F; name_ &#x2F; name$ &#x2F; Object$</span><br></pre></td></tr></table></figure>

<p>2、所有编程相关的命名严禁使用拼音与英文混合的方式,更不允许直接使用中文的方式。 </p>
<p>3、类名使用 UpperCamelCase 风格,必须遵从<strong>驼峰形式</strong>,但以下情形例外:(领域模型的相关命名)DO / DTO / VO / DAO 等。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:MarcoPolo &#x2F; UserDO &#x2F; XmlService &#x2F; TcpUdpDeal &#x2F; TaPromotion</span><br><span class="line">反例:macroPolo &#x2F; UserDo &#x2F; XMLService &#x2F; TCPUDPDeal &#x2F; TAPromotion</span><br></pre></td></tr></table></figure>

<p>4、方法名、参数名、成员变量、局部变量都统一使用 lowerCamelCase 风格,必须遵从 驼峰形式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例: localValue &#x2F; getHttpMessage() &#x2F; inputUserId</span><br></pre></td></tr></table></figure>

<p>5、常量命名全部大写,单词间用下划线隔开,力求语义表达完整清楚,不要嫌名字长。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例: MAX_STOCK_COUNT</span><br><span class="line">反例: MAX_COUNT</span><br></pre></td></tr></table></figure>
<p>6、抽象类命名使用 Abstract 或 Base 开头；异常类命名使用 Exception 结尾；测试类命名以它要测试的类的名称开始，以 Test 结尾</p>
<p>7、中括号是数组类型的一部分,数组定义如下:String[] args; </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">反例:请勿使用 String args[]的方式来定义</span><br></pre></td></tr></table></figure>

<p>8、POJO 类中的任何布尔类型的变量,都不要加 is,否则部分框架解析会引起序列化错误。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">反例：定义为基本数据类型 boolean isSuccess;的属性,它的方法也是 isSuccess(),RPC 框架在反向解析的时候,“以为”对应的属性名称是 success，导致属性获取不到，进而抛出异常。</span><br></pre></td></tr></table></figure>

<p>9、包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用<br>单数形式,但是类名如果有复数含义,类名可以使用复数形式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例: 应用工具类包名为com.alibaba.mpp.util、类名为MessageUtils(此规则参考spring 的框架结构)</span><br></pre></td></tr></table></figure>

<p>10、如果使用到了设计模式，建议在类名中体现出具体模式。 </p>
<p>说明：将设计模式体现在名字中， 有利于阅读者快速理解架构设计思想。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:</span><br><span class="line">public class OrderFactory;</span><br><span class="line">public class LoginProxy;</span><br><span class="line">public class ResourceObserver;</span><br></pre></td></tr></table></figure>
<p>11、对于 Service 和 DAO 类，基于 SOA 的理念，暴露出来的服务一定是接口，内部<br>的实现类用 Impl 的后缀与接口区别。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:CacheServiceImpl 实现 CacheService 接口。</span><br></pre></td></tr></table></figure>

<p>12、枚举类名建议带上 Enum 后缀,枚举成员名称需要全大写,单词间用下划线隔开。 </p>
<p>说明:枚举其实就是特殊的常量类,且构造方法被默认强制是私有。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:枚举名字:DealStatusEnum;成员名称:SUCCESS &#x2F; UNKOWN_REASON。</span><br></pre></td></tr></table></figure>

<p>13、各层命名规约</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Service&#x2F;DAO 层方法命名规约:</span><br><span class="line">1) 获取单个对象的方法用 get 做前缀。</span><br><span class="line">2) 获取多个对象的方法用 list 做前缀。</span><br><span class="line">3) 获取统计值的方法用 count 做前缀。</span><br><span class="line">4) 插入的方法用 insert 做前缀。 </span><br><span class="line">5) 删除的方法用 delete 做前缀。 </span><br><span class="line">6) 修改的方法用 update 做前缀。</span><br><span class="line"></span><br><span class="line">领域模型命名规约:</span><br><span class="line">1) 数据对象:xxxDO,xxx 即为数据表名。</span><br><span class="line">2) 数据传输对象:xxxDTO,xxx 为业务领域相关的名称。 </span><br><span class="line">3) 展示对象:xxxVO,xxx 一般为网页名称。</span><br><span class="line">4) POJO 是 DO&#x2F;DTO&#x2F;BO&#x2F;VO 的统称,禁止命名成 xxxPOJO。</span><br></pre></td></tr></table></figure>

<p>14、long 或者 Long 初始赋值时,必须使用大写的 L，不能是小写的 l，小写容易跟数字 1 混淆，造成误解。</p>
<p>说明:Long a = 2l; 写的是数字的 21,还是 Long 型的 2?</p>
<p>15、不要使用一个常量类维护所有常量，应该按常量功能进行归类，分开维护。</p>
<p>如：缓存相关的常量放在类:CacheConsts 下；系统配置相关的常量放在类:ConfigConsts 下。</p>
<p>16、对外暴露的接口签名，原则上不允许修改方法签名，避免对接口调用方产生影响。</p>
<p>接口过时必须加@Deprecated 注解，并清晰地说明采用的新接口或者新服务是什么</p>
<p>17、当一个类有多个构造器方法，或者多个同名方法（重载），这些方法应该按顺序放置在一起，便于阅读。</p>
<p>18、推荐尽量少用 else。if-else 的方式可以改写成:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if(condition)&#123; </span><br><span class="line">	...</span><br><span class="line">	return obj; </span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; 接着写 else 的业务逻辑代码;</span><br></pre></td></tr></table></figure>

<p>说明：如果使用要 if-else if-else 方式表达逻辑，最好不要超过 3 层</p>
<p>19、所有的类都必须添加作者信息。方法前要加注释。</p>
<p>代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑 等的修改。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">说明:代码与注释更新不同步,就像路网与导航软件更新不同步一样,如果导航软件严重滞后, 就失去了导航的意义。</span><br></pre></td></tr></table></figure>

<p>20、接口返回值不允许使用枚举类型或者包含枚举类型的 POJO 对象（建议用字符串代替）。容易引发反序列化失败。</p>
<p>21、依赖于一个二方库群时，必须定义一个统一版本变量，避免版本号不一致。</p>
<p>说明:依赖 springframework-core、-context、-beans，它们都是同一个版本，可以定义一个变量来保存版本:${spring.version}，定义依赖的时候，引用该版本。</p>
<h1 id="二、编码误区"><a href="#二、编码误区" class="headerlink" title="二、编码误区"></a>二、编码误区</h1><p>1、Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例: &quot;test&quot;.equals(object);</span><br><span class="line">反例: object.equals(&quot;test&quot;);</span><br><span class="line">说明:推荐使用 java.util.Objects#equals (JDK7 引入的工具类)</span><br></pre></td></tr></table></figure>

<p>2、所有的相同类型的包装类对象之间值的比较,全部使用 equals 方法比较。</p>
<p>3、序列化类新增属性时,请不要修改 serialVersionUID 字段,避免反序列失败;如果完全不兼容升级,避免反序列化混乱,那么请修改 serialVersionUID 值。</p>
<p>4、使用索引访问用 String 的 split 方法得到的数组时,需做最后一个分隔符后有无内 容的检查,否则会有抛 IndexOutOfBoundsException 的风险。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">String str &#x3D; &quot;a,b,c,,&quot;; </span><br><span class="line">String[] ary &#x3D; str.split(&quot;,&quot;);</span><br><span class="line">&#x2F;&#x2F;预期大于 3,结果是 3</span><br><span class="line">System.out.println(ary.length);</span><br></pre></td></tr></table></figure>

<p>5、字符串的联接方式，使用 StringBuilder 的 append 方法进行扩展。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">反例:</span><br><span class="line">String str &#x3D; &quot;start&quot;;</span><br><span class="line">for(int i&#x3D;0; i&lt;100; i++)&#123;</span><br><span class="line">    str &#x3D; str + &quot;hello&quot;;</span><br><span class="line">&#125;</span><br><span class="line">说明:反编译出的字节码文件显示每次循环都会 new 出一个 StringBuilder 对象,然后进行 append 操作,最后通过 toString 方法返回 String 对象,造成内存资源浪费。</span><br></pre></td></tr></table></figure>

<p>6、final 可提高程序响应效率，声明成 final 的情况：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1) 不需要重新赋值的变量,包括类属性、局部变量。 </span><br><span class="line">2) 对象参数前加 final,表示不允许修改引用的指向。 </span><br><span class="line">3) 类方法确定不允许被重写。</span><br><span class="line">4) 类不能被继承</span><br></pre></td></tr></table></figure>

<p>7、Map/Set 的 key 为自定义对象时，必须重写 hashCode 和 equals。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:String 重写了 hashCode 和 equals 方法,所以我们可以非常愉快地使用 String 对象作 为 key 来使用。</span><br></pre></td></tr></table></figure>

<p>8、使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一样的数组，大小就是 list.size()</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">反例:</span><br><span class="line">直接使用 toArray 无参方法存在问题,此方法返回值只能是 Object[]类,若强转其它类型数组将出现 ClassCastException 错误。</span><br><span class="line"></span><br><span class="line">正例:</span><br><span class="line">List&lt;String&gt; list &#x3D; new ArrayList&lt;String&gt;(2);</span><br><span class="line">list.add(&quot;guan&quot;);</span><br><span class="line">list.add(&quot;bao&quot;);</span><br><span class="line">String[] array &#x3D; new String[list.size()];</span><br><span class="line">array &#x3D; list.toArray(array);</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">注：ArrayList 源码：</span><br><span class="line"></span><br><span class="line"> public &lt;T&gt; T[] toArray(T[] a) &#123;</span><br><span class="line">        if (a.length &lt; size)</span><br><span class="line">            &#x2F;&#x2F; Make a new array of a&#39;s runtime type, but my contents:</span><br><span class="line">            return (T[]) Arrays.copyOf(elementData, size, a.getClass());</span><br><span class="line">        System.arraycopy(elementData, 0, a, 0, size);</span><br><span class="line">        if (a.length &gt; size)</span><br><span class="line">            a[size] &#x3D; null;</span><br><span class="line">        return a;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>9、使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法, 它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">说明：asList 的返回对象是一个 Arrays 内部类,并没有实现集合的修改方法。Arrays.asList 体现的是适配器模式,只是转换接口,后台的数据仍是数组。</span><br><span class="line"></span><br><span class="line">String[] str &#x3D; new String[] &#123; &quot;a&quot;, &quot;b&quot; &#125;;</span><br><span class="line">List list &#x3D; Arrays.asList(str);</span><br><span class="line"></span><br><span class="line">第一种情况:list.add(&quot;c&quot;); 运行时异常。 </span><br><span class="line">第二种情况:str[0]&#x3D; &quot;gujin&quot;; 那么 list.get(0)也会随之修改。</span><br></pre></td></tr></table></figure>

<p>10、不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式,如果并发操作,需要对 Iterator 对象加锁。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">反例:</span><br><span class="line">List&lt;String&gt; a &#x3D; new ArrayList&lt;String&gt;();</span><br><span class="line">a.add(&quot;1&quot;);</span><br><span class="line">a.add(&quot;2&quot;);</span><br><span class="line">for (String temp : a) &#123;</span><br><span class="line">    if(&quot;1&quot;.equals(temp))&#123;</span><br><span class="line">       a.remove(temp);</span><br><span class="line">	&#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Iterator&lt;String&gt; it &#x3D; a.iterator(); </span><br><span class="line">while(it.hasNext())&#123;</span><br><span class="line">	String temp &#x3D; it.next(); </span><br><span class="line">	if(删除元素的条件)&#123;</span><br><span class="line">        it.remove();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>11、集合初始化时，尽量指定集合初始值大小。</p>
<p>说明：ArrayList 尽量使用 ArrayList(int initialCapacity) 初始化</p>
<p>12、使用 entrySet 遍历 Map 类集合 KV,而不是 keySet 方式进行遍历。</p>
<p>说明：keySet 其实是遍历了 2 次,一次是转为 Iterator 对象,另一次是从 hashMap 中取出 key 所对应的 value。而 entrySet 只是遍历了一次就把 key 和 value 都放到了 entry 中，效率更高。如果是 JDK8,使用 Map.foreach 方法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:</span><br><span class="line">values()返回的是 V 值集合,是一个 list 集合对象;</span><br><span class="line">keySet()返回的是 K 值集合,是 一个 Set 集合对象;</span><br><span class="line">entrySet()返回的是 K-V 值组合集合。</span><br></pre></td></tr></table></figure>

<p>13、Map 类集合 K/V 能不能存储 null 值的情况</p>
<table>
<thead>
<tr>
<th>集合类</th>
<th>Key</th>
<th>Value</th>
<th>Super</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>￼￼￼￼Hashtable</td>
<td>不允许为 null</td>
<td>不允许为 null</td>
<td>Dictionary</td>
<td>线程安全</td>
</tr>
<tr>
<td>ConcurrentHashMap</td>
<td>不允许为 null</td>
<td>不允许为 null</td>
<td>AbstractMap</td>
<td>线程局部安全</td>
</tr>
<tr>
<td>TreeMap</td>
<td>不允许为 null</td>
<td>允许为 null</td>
<td>AbstractMap</td>
<td>线程不安全</td>
</tr>
<tr>
<td>HashMap</td>
<td>允许为 null</td>
<td>允许为 null</td>
<td>AbstractMap</td>
<td>线程不安全</td>
</tr>
</tbody></table>
<p>14、利用 Set 元素唯一的特性,可以快速对另一个集合进行去重操作,避免使用 List 的 contains 方法进行遍历去重操作。</p>
<p>15、获取单例对象要线程安全(双重空判断)。在单例对象里面做操作也要保证线程安全。</p>
<p>16、<strong>线程资源必须通过线程池提供</strong>，不允许在应用中自行显式创建线程。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">说明：使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者 “过度切换”的问题。</span><br></pre></td></tr></table></figure>

<p>17、多线程并行处理定时任务时，Timer 运行多个 TimeTask 时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@param</span><br><span class="line">command the task to execute</span><br><span class="line">delay the time from now to delay execution</span><br><span class="line">unit the time unit of the delay parameter</span><br><span class="line"></span><br><span class="line">@method</span><br><span class="line">ScheduledFuture&lt;?&gt; java.util.concurrent.ScheduledExecutorService.schedule(Runnable command, long delay, TimeUnit unit)</span><br></pre></td></tr></table></figure>

<p>18、线程池不允许使用 Executors 去创建,而是通过 ThreadPoolExecutor 的方式,这样的处理方式让写的同学更加明确线程池的运行规则,规避资源耗尽的风险。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">说明:Executors 各个方法的弊端:</span><br><span class="line"></span><br><span class="line">newFixedThreadPool 、newSingleThreadExecutor 和 newScheduledThreadPool:</span><br><span class="line">主要问题是堆积的请求处理队列可能会耗费非常大的内存,甚至 OOM。</span><br></pre></td></tr></table></figure>

<p>19、创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:</span><br><span class="line">public class TimerTaskThread extends Thread &#123;</span><br><span class="line">	public TimerTaskThread()&#123;</span><br><span class="line">		super.setName(&quot;TimerTaskThread&quot;); </span><br><span class="line">	... </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>20、避免 Random 实例被多线程使用,虽然共享该实例是线程安全的,但会因竞争同一 seed 导致的性能下降。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">说明:Random 实例包括 java.util.Random 的实例或者 Math.random()实例。</span><br><span class="line">正例:在 JDK7 之后,可以直接使用 API ThreadLocalRandom,在 JDK7 之前,可以做到每个线程一个实例。</span><br></pre></td></tr></table></figure>

<p>21、volatile 解决多线程内存不可见问题。对于一写多读,是可以解决变量同步问题, 但是如果多写,同样无法解决线程安全问题。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如果想取回 count++数据,使用如下类实现: </span><br><span class="line">AtomicInteger count &#x3D; new AtomicInteger(); </span><br><span class="line">count.addAndGet(1); </span><br><span class="line"></span><br><span class="line">count++操作如果是JDK8,推荐使用 LongAdder 对象,比 AtomicLong 性能更好(减少乐观锁的重试次数)。</span><br></pre></td></tr></table></figure>

<p>22、在一个 switch 块内,每个 case 要么通过 break/return 来终止,要么注释说明程序 将继续执行到哪一个 case 为止;在一个 switch 块内,都必须包含一个 default 语句并且放在 最后,即使它什么代码也没有。</p>
<p>23、在使用正则表达式时,利用好其预编译功能,可以有效加快正则匹配速度。 </p>
<p>说明:不要在方法体内定义:Pattern pattern = Pattern.compile(规则);</p>
<p>24、获取当前毫秒数:System.currentTimeMillis(); 而不是 new Date().getTime(); </p>
<p>如果想获取更加精确的纳秒级时间值，用 System.nanoTime。</p>
<p>25、日志输出最好使用占位符的方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">logger.debug(&quot;Processing trade with id: &#123;&#125; and symbol : &#123;&#125; &quot;, id, symbol);</span><br></pre></td></tr></table></figure>

<p>26、避免重复打印日志,浪费磁盘空间,务必在 log4j.xml 中设置 additivity=false。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:&lt;logger name&#x3D;&quot;com.taobao.ecrm.member.config&quot; additivity&#x3D;&quot;false&quot;&gt;</span><br></pre></td></tr></table></figure>

<p>27、输出的 POJO 类必须重写 toString 方法，否则只输出此对象的 hashCode 值(地址值)，没啥<br>参考意义。</p>
<h1 id="三、MYSQL-规约"><a href="#三、MYSQL-规约" class="headerlink" title="三、MYSQL 规约"></a>三、MYSQL 规约</h1><p>1、任何字段如果为非负数，必须是 unsigned。</p>
<p>2、表名、字段名必须使用小写字母或数字</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">正例:getter_admin,task_config,level3_name</span><br></pre></td></tr></table></figure>

<p>3、禁用保留字,如 desc、range、match、delayed 等,参考官方保留字。</p>
<p>4、唯一索引名为 uk_字段名；普通索引名则为 idx_字段名</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">说明:uk_ 即 unique key;idx_ 即 index 的简称。</span><br></pre></td></tr></table></figure>
<p>5、如果存储的字符串长度几乎相等，使用 CHAR 定长字符串类型。</p>
<p>varchar 是可变长字符串，不预先分配存储空间,长度不要超过 5000，如果存储长度大于此值，定义字段类型为 TEXT，独立出来一张表，用主键来对应，避免影响其它字段索引效率。</p>
<p>6、表必备三字段：id, gmt_create, gmt_modified</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 说明:其中 id 必为主键,类型为 unsigned bigint、单表时自增、步长为 1;分表时改为从 TDDL Sequence 取值,确保分表之间的全局唯一。</span></span><br><span class="line">gmt_create, gmt_modified 的类型均为 date_time 类型。</span><br><span class="line"></span><br><span class="line">`id` int(10) unsigned NOT NULL AUTO_INCREMENT <span class="keyword">COMMENT</span> <span class="string">'自增主键'</span>,</span><br><span class="line"><span class="string">`created_time`</span> <span class="built_in">timestamp</span>(<span class="number">3</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">CURRENT_TIMESTAMP</span>(<span class="number">3</span>) <span class="keyword">COMMENT</span> <span class="string">'创建时间'</span>,</span><br><span class="line"><span class="string">`updated_time`</span> <span class="built_in">timestamp</span>(<span class="number">3</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="keyword">CURRENT_TIMESTAMP</span>(<span class="number">3</span>) <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="keyword">CURRENT_TIMESTAMP</span>(<span class="number">3</span>) <span class="keyword">COMMENT</span> <span class="string">'更新时间'</span>,</span><br><span class="line">PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>),</span><br></pre></td></tr></table></figure>

<p>7、如果修改字段含义或对字段表示的状态追加时,需要及时更新字段注释。</p>
<p>8、单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。 </p>
<p>说明:如果预计三年后的数据量根本达不到这个级别,请不要在创建表时就分库分表。 </p>
<p>反例:某业务三年总数据量才 2 万行,却分成 1024 张表。<br>问:你为什么这么设计?答:分 1024 张表,不是标配吗?</p>
<p>9、合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。</p>
<p>正例:</p>
<p>人的年龄用 unsigned tinyint(表示范围 0-255,人的寿命不会超过 255 岁);<br>海龟就 必须是 smallint,<br>太阳的年龄,就必须是 int;<br>所有恒星的年龄都加起来，那么就必须使用 bigint。</p>
<p>10、业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引</p>
<p>说明:不要以为唯一索引影响了 insert 速度,这个速度损耗可以忽略,但提高查找速度是明<br>显的;另外，即使在应用层做了非常完善的校验和控制,只要没有唯一索引,根据墨菲定律, 必然有脏数据产生。</p>
<p>11、严禁多个表间join操作</p>
<p>12、页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。</p>
<p>说明：索引文件具有 B-Tree 的最左前缀匹配特性,如果左边的值未确定,那么无法使用此索<br>引。</p>
<p>13、如果有 order by 的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现 file_sort 的情况，影响查询性能。 </p>
<p>正例:<br>where a=? and b=? order by c; 索引:a_b_c</p>
<p>反例:<br>索引中有范围查找,那么索引有序性无法利用,如:WHERE a&gt;10 ORDER BY b; 索引 a_b 无法排序。</p>
<p>14、建组合索引的时候，区分度最高的在最左边</p>
<p>正例:<br>如果 where a=? and b=? ,a 列的几乎接近于唯一值,那么只需要单建 idx_a 索引即可。</p>
<p>说明:存在非等号和等号混合判断条件时,在建索引时,请把等号条件的列前置。如:where a&gt;?<br>and b=? 那么即使 a 的区分度更高,也必须把 b 放在索引的最前列。</p>
<p>15、创建索引时避免有如下极端误解：</p>
<p>1)误认为一个查询就需要建一个索引。<br>2)误认为索引会消耗空间、严重拖慢更新和新增速度。<br>3)误认为唯一索引一律需要在应用层通过“先查后插”方式解决。</p>
<p>16、不得使用外键与级联，一切外键概念必须在应用层解决。 </p>
<p>说明:(概念解释)学生表中的 student_id 是主键,那么成绩表中的 student_id 则为外键。 如果更新学生表中的 student_id,同时触发成绩表中的 student_id 更新,则为级联更新。外键与级联更新适用于单机低并发,不适合分布式、高并发集群;级联更新是强阻塞,存在数据库更新风暴的风险;外键影响数据库的插入速度。</p>
<p>17、IDB 数据订正时，删除和修改记录时，要先 select，避免出现误删除，确认无误才能提交执行。</p>
<p>18、in 操作能避免则避免，若实在避免不了，需要仔细评估 in 后边的集合元素数量，控制在 1000 个之内</p>
<p>19、所有的字符存储与表示，均以 utf-8 编码，那么字符计数方法注意:</p>
<p>说明:<br>SELECT LENGTH(“阿里巴巴”); 返回为 12<br>SELECT CHARACTER_LENGTH(“阿里巴巴”); 返回为 4<br>如果要使用表情，那么使用 utfmb4 来进行存储，注意它与 utf-8 编码。</p>
<p>20、在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。</p>
<p>说明:<br>1)增加查询分析器解析成本。<br>2)增减字段容易与 resultMap 配置不一致。</p>
<p>21、不要用 resultClass 当返回参数,即使所有类属性名与数据库字段一一对应,也需要定义;反过来,每一个表也必然有一个与之对应。</p>
<p>说明：配置映射关系，使字段与 DO 类解耦，方便维护</p>
<p>22、xml 配置中参数注意使用:#{},#param# 不要使用${} 此种方式容易出现 SQL 注入</p>
<p>23、更新数据表记录时，必须同时更新记录对应的 gmt_modified 字段值为当前时间。</p>
<p>24、不要写一个大而全的数据更新接口,传入为 POJO 类，不管是不是自己的目标更新字段，都进行 update table set c1=value1,c2=value2,c3=value3; 这是不对的。</p>
<p>执行 SQL 时，尽量不要更新无改动的字段，一是易出错；二是效率低；三是 binlog 增加存储。</p>
<h1 id="四、工程规约"><a href="#四、工程规约" class="headerlink" title="四、工程规约"></a>四、工程规约</h1><p>1、默认上层依赖于下层，箭头关系表示可直接依赖，如:开放接口层可以依赖于 Web 层,也可以直接依赖于 Service 层,依此类推:</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/pm/1.png/w600">

<ul>
<li>开放接口层：可直接封装 Service 接口暴露成 RPC 接口；通过 Web 封装成 http 接口；网关控制层等。</li>
<li>终端显示层：各个端的模板渲染并执行显示层。当前主要是 velocity 渲染,JS 渲染,JSP 渲 染,移动端展示层等。</li>
<li>Web 层：主要是对访问控制进行转发,各类基本参数校验,或者不复用的业务简单处理等。</li>
<li>Service层：相对具体的业务逻辑服务层。</li>
<li>Manager层：通用业务处理层,它有如下特征:<ul>
<li>1) 对第三方平台封装的层,预处理返回结果及转化异常信息;</li>
<li>2) 对 Service 层通用能力的下沉,如缓存方案、中间件通用处理; </li>
<li>3) 与 DAO 层交互,对 DAO 的业务通用能力的封装。</li>
</ul>
</li>
<li>DAO 层：数据访问层,与底层 Mysql、Oracle、Hbase 进行数据交互。</li>
<li>外部接口或第三方平台：包括其它部门 RPC 开放接口，基础平台，其它公司的 HTTP 接口。</li>
</ul>
<p>2、分层领域模型规约：</p>
<ul>
<li>DO(Data Object)：与数据库表结构一一对应,通过 DAO 层向上传输数据源对象。</li>
<li>DTO(Data Transfer Object)：数据传输对象,Service 和 Manager 向外传输的对象。</li>
<li>BO(Business Object)：业务对象。可以由 Service 层输出的封装业务逻辑的对象。</li>
<li>QUERY：数据查询对象,各层接收上层的查询请求。注:超过 2 个参数的查询封装,禁止使 用 Map 类来传输。</li>
<li>VO(View Object)：显示层对象，通常是 Web 向模板渲染引擎层传输的对象。</li>
</ul>
<h1 id="五、服务器"><a href="#五、服务器" class="headerlink" title="五、服务器"></a>五、服务器</h1><p>1、高并发服务器建议调小 TCP 协议的 time_wait 超时时间。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">说明：操作系统默认 240 秒后，才会关闭处于 time_wait 状态的连接,在高并发访问下,服务</span><br><span class="line">器端会因为处于 time_wait 的连接数太多,可能无法建立新的连接,所以需要在服务器上调小此等待值。</span><br><span class="line"></span><br><span class="line">正例:</span><br><span class="line">在linux 服务器上请通过变更&#x2F;etc&#x2F;sysctl.conf 文件去修改该缺省值(秒):</span><br><span class="line">net.ipv4.tcp_fin_timeout &#x3D; 30</span><br></pre></td></tr></table></figure>

<p>2、调大服务器所支持的最大文件句柄数(File Descriptor,简写为 fd)。 </p>
<p>说明：主流操作系统的设计是将 TCP/UDP 连接采用与文件一样的方式去管理，即一个连接对应于一个 fd。主流的 linux 服务器默认所支持最大fd 数量为 1024，当并发连接数很大时很容易因为 fd 不足而出现“open too many files”错误，导致新的连接无法建立。 </p>
<p>建议将linux服务器所支持的最大句柄数调高数倍(与服务器的内存数量相关)。</p>
<h1 id="六、性能规范"><a href="#六、性能规范" class="headerlink" title="六、性能规范"></a>六、性能规范</h1><ul>
<li><p>常见OOM预防</p>
</li>
<li><p>禁止应用中显示创建线程，避免不可控出现unable to create new native thread；</p>
</li>
<li><p>控制select/update/delete/insert的数据级和可变集合的size，避免随着业务增加内存数据量不可控；</p>
</li>
<li><p>页面查询不推荐全表查询，查询通过查询条件限制查询条数；</p>
</li>
<li><p>页面下载条数和下载次数做限制，避免请求过多导致OOM；</p>
</li>
<li><p>SQL优化目标必须满足range、ref或者consts，不可以是all类型，避免慢SQL导致连接数耗尽影响业务功能；</p>
</li>
<li><p>代码书写中考虑MySQL中共享锁和排它锁场景，预防产生死锁；</p>
</li>
<li><p>代码中不建议使用@Transactional，因为一般业务场景中用不到，它影响数据库性能并且多个操作可能在并发下导致数据库死锁；</p>
</li>
<li><p>数据库单表达到一定数据量级需要做分库分表或者冷热数据隔离，避免业务增加带来的性能问题；</p>
</li>
<li><p>避免系统中出现单点故障，包括中间件和应用程序等所有的节点；</p>
</li>
<li><p>能异步处理的别同步处理，异步可以释放线程资源，避免阻塞，提高响应效率；</p>
</li>
<li><p>随着业务量的增加，考虑功能拆分和数据库表拆分，除此支付系统建议按照通道拆分，不同的通道指定独立的work线程，分而治之，避免相互之间影响；提高并发的一个思路就是拆分，拆分后通过异步提高并发效率。</p>
</li>
</ul>
<h1 id="七、安全规范"><a href="#七、安全规范" class="headerlink" title="七、安全规范"></a>七、安全规范</h1><ul>
<li><p>页面请求参数严格限制或者校验处理，防止SQL注入；</p>
</li>
<li><p>页面URL请求做细粒度的权限拦截，防止访问权限过大；</p>
</li>
<li><p>部署在公网的应用做好防止XSS攻击的防范措施；</p>
</li>
<li><p>和第三方系统交互需要互加白名单确保安全；</p>
</li>
<li><p>系统全站提供HTTPS服务；</p>
</li>
<li><p>和第三方系统交互报文需要加密传输；</p>
</li>
<li><p>用户敏感数据做数据脱敏（如：用户手机号nick）；</p>
</li>
<li><p>预防页面被频繁请求，占用系统资源；</p>
</li>
<li><p>预防API被频繁请求，占用系统资源；</p>
</li>
</ul>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>代码管理</title>
    <url>/pm/code/</url>
    <content><![CDATA[<ul>
<li><a href="代码规范.md">代码规范</a></li>
<li><a href="git-commands.md">Git常用命令</a></li>
<li><a href="http://www.mvnrepository.com/open-source/http-clients" target="_blank" rel="noopener">maven仓库</a></li>
</ul>
<a id="more"></a>]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>Git常用命令</title>
    <url>/pm/git-commands/</url>
    <content><![CDATA[<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><ul>
<li><p>git branch -a      </p>
<p>查看所有的分支，包括本地和远程</p>
<a id="more"></a></li>
<li><p>git checkout -b develop remotes/origin/develop   </p>
<p>切换远程开发分支在本地创建影像</p>
</li>
<li><p>git status </p>
<p>查看文件的修改状态 </p>
</li>
<li><p>git add src/main/java/com/onlyone/csw/controllers/Test.java </p>
<p>标记需要提交的文件，支持*通配符</p>
</li>
<li><p>git commit -m “备注”  </p>
<p>将本地修改保存到本地仓库中，并添加备注</p>
</li>
<li><p>git push</p>
<p>将本地仓库修改推送到服务器上的仓库中</p>
</li>
<li><p>git pull </p>
<p>同步服务器最新内容到本地</p>
</li>
<li><p>git checkout 分支名        </p>
<p>在分支之间切换 </p>
</li>
<li><p>git merge 分支a   </p>
<p>将分支a内容合到当前分支上，最后要执行git commit 和 git push</p>
</li>
<li><p>git branch -d 分支名      </p>
<p>删除本地分支（删之前需要切换非当前分支）</p>
</li>
<li><p>git branch 分支名       </p>
<p>在本地库创建新的分支</p>
</li>
<li><p>git push -u origin 分支名     </p>
<p>提交本地创建的分支到远程服务器    </p>
</li>
<li><p>git diff  topic  maste    </p>
<p>直接将两个分支上最新的提交做diff    </p>
</li>
<li><p>git diff</p>
<p>查看当前未提交的文件的改动点</p>
</li>
<li><p>git branch -v -v     </p>
<p>有【】的表示和服务器关联</p>
</li>
<li><p>git reset –hard HEAD~3  | git reset –hard commit-id</p>
<p>会将最新的3次提交全部重置，只在本地生效 （<a href="http://www.cnblogs.com/mliudong/archive/2013/04/08/3007303.html）" target="_blank" rel="noopener">http://www.cnblogs.com/mliudong/archive/2013/04/08/3007303.html）</a></p>
<p>git push -f origin 分支名 </p>
<p>强制提交到远程服务器，此时回退了3个版本，git服务器的提交log也会清掉。</p>
</li>
</ul>
<ul>
<li>已经commit 了N次，需要退回到某一版本</li>
</ul>
<pre><code>git reset &lt;commit-id&gt;  #默认就是-mixed参数。
修改代码 或者  git checkout 撤销修改
git push -f 强制提交

ps：查看git log，会发现原来已经提交过的log也会被删除
</code></pre><ul>
<li><p>git stash</p>
<p>多分支开发，本地缓存。<a href="https://www.cnblogs.com/tocy/p/git-stash-reference.html" target="_blank" rel="noopener">https://www.cnblogs.com/tocy/p/git-stash-reference.html</a></p>
</li>
<li><p>git branch </p>
<p>查看所有本地分支，带*为当前分支    </p>
</li>
<li><p>git log  </p>
<p>查看当前分支的提交记录</p>
</li>
<li><p>git log -p   </p>
<p>查看代码改动点（所有）</p>
</li>
</ul>
<h1 id="git-reset"><a href="#git-reset" class="headerlink" title="git reset"></a>git reset</h1><h2 id="git-reset-参数"><a href="#git-reset-参数" class="headerlink" title="git reset 参数"></a>git reset 参数</h2><ol>
<li><p>–soft<br>仅仅移动当前Head指针，不会改变工作区和暂存区的内容 </p>
</li>
<li><p>–mixed 默认<br>是reset的默认参数,移动head指针，改变暂存区内容，但不会改变工作区 </p>
</li>
<li><p>–hard<br>当前head指针、工作区和暂存区内容全部改变  </p>
</li>
</ol>
<h2 id="如何回滚文件"><a href="#如何回滚文件" class="headerlink" title="如何回滚文件"></a>如何回滚文件</h2><ul>
<li><ol>
<li>修改完，还未执行git add<br>git checkout .<br>使用暂存区的文件覆盖工作区，所以执行完git add .之后，再执行该命令是无效的<br>git checkout .和git add .是一对反义词</li>
</ol>
</li>
<li><p>2.使用git add 提交到暂存区，还未commit之前<br>git reset  先用Head指针覆盖当前的暂存区内容<br>git checkout . 再用暂存区内容覆盖工作区内容<br>或者使用  git reset –hard 直接使用head覆盖当前暂存区和工作区</p>
</li>
<li><p>3.已经git commit，还未git push<br>git reset –hard origin/master<br>从远程仓库把代码取回来，然后覆盖本地仓库、本地暂存区和工作区  </p>
</li>
</ul>
<p>或者使用 git reset –hard last_commit_id，覆盖本地仓库、暂存区和工作区，</p>
<p>其中查看 last_commit_id 命令为 git log<br>或者使用 git reset –mixed last_commit_id  覆盖本地的暂存区，<br>再执行 git checkout . 覆盖本地工作区</p>
<ul>
<li>4.已经git push</li>
</ul>
<ol>
<li>git reset –hard commit_id :当前head指针、工作区和暂存区内容全部改变为之前的commit_id版本 </li>
<li>git reset 最新的版本号 :移动HEAD指针改变暂存区,不改变工作区，工作区为之前commit_id版本，（直接push会报错，提示我当前的分支落后于线上分支，这步目的主要是移动HEAD指针） 或者 git push -f origin develop.</li>
</ol>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>论需求调研的重要性</title>
    <url>/pm/%E8%AE%BA%E9%9C%80%E6%B1%82%E8%B0%83%E7%A0%94%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7/</url>
    <content><![CDATA[<p>有国外开发者在 Quora 提了这个问题：“为什么软件开发周期通常是预期的两三倍？” 并补充问：“这是开发人员的错误？ 是管理失误？ 是因为做事方法不对， 或者说缺乏好的方法？还是说这就是软件开发流程的特点？” Michael Wolfe 在2012年1月28日给的回复，非常经典，截至我们发布时已有8016个赞。以下是译文。</p>
<a id="more"></a>

<p>让我们先沿着海岸线，从旧金山（SF）走路去洛杉矶（LA），去拜访我们住在Newport Beach的朋友，我拿出地图在上面画出了行进路线。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/pm/2.jpg/w600">

<p>全程大约有400英里，如果我们每天走10小时每小时4公里的话，只用10天就可以到达目的地。立刻打电话给我们的朋友预定下周六的晚餐，告诉他们下周六晚上六点我们一定会准时出现，朋友们已经等不及了！</p>
<p>第二天清晨，我们带着准备冒险的兴奋起床，背起行囊，拿出地图，准备计划我们冒险的第一天，看一眼地图，噢，不！</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/pm/3.jpg/w600">


<p>哇，海岸线上有这么多迂回曲折的线路。每天行进40英里的话，10天后只能勉强到达Half Moon Bay（半月湾？）。这趟旅行至少有500英里，而不是400。赶紧打电话给我们的朋友，将晚餐顺延至下下周周二。人还是应该现实一点。朋友们有点失望，不过仍然盼望见到我们，况且花 12 天从 SF 到 LA 也不赖。</p>
<p>把不开心的事丢到一边，准备出发。两小时过后，我们才刚刚走出动物园。出了什么事？我们低头看了一下脚下的路：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/pm/4.jpg/w600">

<p>天哪，这样走路也太慢了！有沙子、海水、阶梯、溪流，还有海边愤怒的海狮！这样我们只能按每小时2公里的速度前进，只有我们预估一般的速度。要么我们现在每天走20小时，要么再把晚餐推迟一个星期。好吧，让我们各退一步：每天走12个小时，把晚餐安排到下下周的周末。只好再打电话给朋友告诉他们这个情况。朋友们有些不高兴，但还是表示可以，到时候见。</p>
<p>在辛苦走了12小时后，我们准备在 Moss Beach 扎营休息。靠，要把帐篷在风中立起来根本不可能。直到半夜才开始休息。不过没什么大不了：明天在加快点速度就可以了。</p>
<p>第二天早上睡过头了，早上10点才醒，起来浑身酸痛精疲力尽。艹，今天没法走12个小时了，先走10个小时，明天可以走14个小时。收拾东西出发。</p>
<p>再缓慢行进了几个小时之后，我发现伙伴脚有点跛。妈的，是水泡。必须现在解决它，在这些问题开始减慢我们的速度前，必须将它们扼杀在萌芽状态。我慢跑了45分钟到达内陆3英里远的Pescadero，买了一些创可贴再快速跑回去给朋友包扎了一下。我快累坏了，太阳也快下山了，又浪费了一天的时间。到我们准备休息前今天只走了6英里。但是我们确实需要补充一下供给。一切都很好，明天我们就能赶上。</p>
<p>第二天醒来，扎紧脚上的绷带准备出发。转角之后突然发现，靠！这是个啥？</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/pm/5.jpg/w600">

<p>你妹的地图上怎么没标出它！现在我们只能往内陆走3英里，绕过这些被联邦政府用栅栏保护起来的区域，中途迷路了两次，在中午前才好不容易又回到了海岸线。今天的时间过了一大半，而我们才前进了差不多1英里。好吧，不过我们不会再打电话给朋友推迟了，今天我们会一直走到午夜试着赶上进度。</p>
<p>晚上在大雾里断断续续地睡了一夜。一大早被我的伙伴叫醒，他一阵阵的头疼，还有点发烧，我问他能不能坚持一下。“你在想什么呢，混蛋，我已经连续三天在这么冷的雾中赶路，没有休息过了。“好吧，今天看来只能黄了，只能在原地好好恢复了。现在我们已经有经验了，今天好好休息明天再走14个小时，还有几天的时间，我们一定能够做到！</p>
<p>第二天我们昏昏沉沉地起来了。我看了一眼随身的地图：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/pm/6.jpg/w600">

<p>天啊！我们已经走了10天旅程里的第5天还没有离开海湾区域！太荒唐了！我们要重新估计一下准确的时间再打给朋友，搞不好会被骂，但至少得找一个现实一点的目标。</p>
<p>同伴说，我们在四天里走了40英里，这趟旅程至少又600英里，那就至少要60天，安全一点的说法说不定要70天，“没门…是，以前我是没走路从SF去过LA，但肯定不会要70天的时间，如果告诉他们我们要到复活节才能到，那要被他们笑死的“，我说。</p>
<p>我接着说，“如果你能保证每天走16个小时，我们就能把落下的时间补回来！我知道很困难，但现在是最关键的时刻，别抱怨了！”伙伴对我吼道 “一开始又不是我告诉别人下周日我们就能到的！因为你犯的这个错差点要我的命！”</p>
<p>两个人就这样不说话了。我还是没打出电话，等我的伙伴明天冷静一点我再决定，我也愿意做一些更合理的承诺。</p>
<p>第二天上午，我们一直待在各自的帐篷中直到一场暴风雨袭来。我们赶紧收拾好东西直到10点才摆脱危险。浑身酸痛，又长了好多新水泡。之前发生的事谁也没提，直到发现我那愚蠢的伙伴把水壶落下了，又被我指责了一顿，我们不得不再花30分钟回去取它。</p>
<p>我心里记得我们的厕纸已经快用完了，下次到一个小镇的时候应该囤一点。在我们又转个弯后，才发现一条湍急的河流挡住了去路，这时我突然感到肚子一阵难受……</p>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>敏捷开发核心思想</title>
    <url>/pm/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3/</url>
    <content><![CDATA[<h2 id="一、四句敏捷宣言"><a href="#一、四句敏捷宣言" class="headerlink" title="一、四句敏捷宣言"></a><strong>一、四句敏捷宣言</strong></h2><ol>
<li><p>个体与交互 胜过 过程与工具</p>
</li>
<li><p>可以工作的软件  胜过 面面俱到的文档</p>
</li>
<li><p>客户协作  胜过 合同谈判</p>
</li>
<li><p>响应变化 胜过 遵循计划</p>
</li>
</ol>
<h2 id="二、12条敏捷原则"><a href="#二、12条敏捷原则" class="headerlink" title="二、12条敏捷原则"></a><strong>二、12条敏捷原则</strong></h2><p> 四句敏捷宣言中讲了敏捷开发的价值观, 从这些价值观中可以引出下面的12条原则， 它们是敏捷实践区别于重型过程的特征所在。<br> 在Agile Software Development － Principles,Patterns,and Practices（中文书名： 敏捷软件开发－原则、模式与实践）中对这12条原则分别进行了阐述。</p>
<h2 id="1-我们最优先要做的是通过尽早的、持续的交付有价值的软件来使客户满意。"><a href="#1-我们最优先要做的是通过尽早的、持续的交付有价值的软件来使客户满意。" class="headerlink" title="1. 我们最优先要做的是通过尽早的、持续的交付有价值的软件来使客户满意。"></a><strong>1. 我们最优先要做的是通过尽早的、持续的交付有价值的软件来使客户满意。</strong></h2><p>规划迭代故事时必须按照优先级安排，为客户先提供最有价值的功能。通过频繁迭代能与客户形成早期的良好合作，及时反馈提高产品质量。敏捷小组关注完成和交 付具有用户价值的功能，而不是孤立的任务。以前我们都用需求规格说明书或者用例来编写详细的需求，敏捷使用用户故事来罗列需求。用户故事是一种表示需求的 轻量级技术，它没有</p>
<p>固定的形式和强制性的语法。但是有一些固定的形式可以用来参考还是比较有益的。敏捷估算中使用了这个模板：&ldquo;作为【用户的类型】，我希 望可以【能力】以便【业务价值】&ldquo;。使用基于用户故事的需求分析方法时，仍可能需要原型和编写文档，只是工作重点更多的转移到了口头交流。</p>
<h2 id="2-即使到了开发的后期，也欢迎改变需求。敏捷过程利用变化来为客户创造竞争优势。"><a href="#2-即使到了开发的后期，也欢迎改变需求。敏捷过程利用变化来为客户创造竞争优势。" class="headerlink" title="2. 即使到了开发的后期，也欢迎改变需求。敏捷过程利用变化来为客户创造竞争优势。"></a><strong>2. 即使到了开发的后期，也欢迎改变需求。敏捷过程利用变化来为客户创造竞争优势。</strong></h2><p>敏捷过程参与者不怕变化，他们认为改变需求是好事情，因为这些改变意味着我们更了解市场需求。 </p>
<h2 id="3-经常性的交付可以工作的软件，交付的间隔可以从几周到几个月，交付的时间间隔越短越好"><a href="#3-经常性的交付可以工作的软件，交付的间隔可以从几周到几个月，交付的时间间隔越短越好" class="headerlink" title="*3. 经常性的交付可以工作的软件，交付的间隔可以从几周到几个月，交付的时间间隔越短越好. *"></a>*<em>3. 经常性的交付可以工作的软件，交付的间隔可以从几周到几个月，交付的时间间隔越短越好. *</em></h2><p>迭代是受实践框限制的，意味着即使放弃一些功能也必须按时结束迭代。只要我们可以保证交付的软件可以很好的工作，那么交付时间越短，我们和客户协作就越 紧密，对产品质量就更有益。虽然我们多次迭代，但并不是每次迭代的结果都需要交付给用户，敏捷开发的目标是让他们可以交付。这意味着开发小组在每次迭代中 都会增加一些功能，增加的每个功能都是经过编码、测试，达到了可发布的质量标准的。　　</p>
<p>另外敏捷开发项目中对开发阶段没有什么重要的分割，没有先期的需求阶段，然后是分析阶段，架构设计阶段，编码测试阶段等，在项目真正开始后，每次迭代中都会同时进行所有的上述阶段工作。</p>
<h2 id="4-在整个项目开发期间，业务人员和开发人员必须天天都在一起工作。"><a href="#4-在整个项目开发期间，业务人员和开发人员必须天天都在一起工作。" class="headerlink" title="4. 在整个项目开发期间，业务人员和开发人员必须天天都在一起工作。"></a><strong>4. 在整个项目开发期间，业务人员和开发人员必须天天都在一起工作。</strong></h2><p>软件项目不会依照之前设定的计划原路执行，中间对业务的理解、软件的解决方案肯定会存在偏差，所以客户、需求人员、开发人员以及涉众之间必须进行有意义的、频繁的交互，这样就可以在早期及时的发现并解决问题。</p>
<h2 id="5-围绕被激励起来的人个来构建项目。给他们提供所需要的环境和支持，并且信任他们能够完成工作。"><a href="#5-围绕被激励起来的人个来构建项目。给他们提供所需要的环境和支持，并且信任他们能够完成工作。" class="headerlink" title="5. 围绕被激励起来的人个来构建项目。给他们提供所需要的环境和支持，并且信任他们能够完成工作。"></a><strong>5. 围绕被激励起来的人个来构建项目。给他们提供所需要的环境和支持，并且信任他们能够完成工作。</strong></h2><p>业务和技术是引起不确定的二个主要方面，人是第三个方面。而业务和技术又必须由人来执行，所以能够激励人来解决这些问题是解决不确定性的关键。只要个人的目标和团队的目标一致，我们就需要鼓舞起每个人的积极性，以个人为中心构建项目，提供所需的环境、支持与信任。 </p>
<h2 id="6-在团队内部，最具有效果并且富有效率的传递信息的方法，就是面对面的交谈。"><a href="#6-在团队内部，最具有效果并且富有效率的传递信息的方法，就是面对面的交谈。" class="headerlink" title="6. 在团队内部，最具有效果并且富有效率的传递信息的方法，就是面对面的交谈。"></a><strong>6. 在团队内部，最具有效果并且富有效率的传递信息的方法，就是面对面的交谈。</strong></h2><p>在十几或者二十几个人组成的大团队中，文档是一种比较合适的传递知识和交流的途径。而敏捷团队一般不会很多人（大团队实施敏捷时也会分成多个小的敏捷团队），所以大量的文档交流其实并不是很经济的做法。此时面对面的交谈反而更快速有效。</p>
<h2 id="7、可工作的软件是首要进度度量标准。"><a href="#7、可工作的软件是首要进度度量标准。" class="headerlink" title="7、可工作的软件是首要进度度量标准。"></a><strong>7、可工作的软件是首要进度度量标准。</strong></h2><p>一般的工作都比较容易衡量任务进展，比如让你去搬运1吨的石头，我只要去称一下你已经搬运的石头重量就知道你完成多少了。而对于软件来说，在软件没有编 码、测试完成之前，我们都不能因为代码编写了多少行，测试用例跑了多少个就去度量这个功能是否完成了。</p>
<p>衡量这个功能是否完成的首要标准就是这个功能可以工 作了，对用户来说已经可以应用了. </p>
<h2 id="8-敏捷过程提可持续的开发速度。责任人、开发者和用户应该能够保持一个长期的、恒定的开发速度。"><a href="#8-敏捷过程提可持续的开发速度。责任人、开发者和用户应该能够保持一个长期的、恒定的开发速度。" class="headerlink" title="8. 敏捷过程提可持续的开发速度。责任人、开发者和用户应该能够保持一个长期的、恒定的开发速度。"></a><strong>8. 敏捷过程提可持续的开发速度。责任人、开发者和用户应该能够保持一个长期的、恒定的开发速度。</strong></h2><p>很多人都认为软件开发中加班是很正常的，不加班反而不正常，我对此有点不理解，这个可能是国情所致吧。敏捷过程希望能够可持续的进行开发，开发速度不会 随着迭代的任务不同而不同，不欣赏所谓的拼一拼也能完成的态度，开发工作不应该是突击行为。</p>
<p>我们不能指望说突击这个项目后就可以轻松了，因为完成一个项目 后会接踵而来下一个项目，而只要还是拼拼的态度，下一个项目依旧会让你的组员再次突击。这时不知道有人会不会说，那我们就一直加班，也是&ldquo;持续的开发速 度&rdquo;啊，这时可要注意了，持续加班智慧导致人疲劳、厌倦，保持长期恒定的速度也只是一种理想而已。</p>
<h2 id="9-不断地关注优秀的技能和好的设计会增强敏捷能力。"><a href="#9-不断地关注优秀的技能和好的设计会增强敏捷能力。" class="headerlink" title="9. 不断地关注优秀的技能和好的设计会增强敏捷能力。"></a><strong>9. 不断地关注优秀的技能和好的设计会增强敏捷能力。</strong></h2><p>敏捷过程有很多好的技术实践可以加强产品敏捷能力，很多原则、模式和实践也可以增强敏捷开发能力。 《敏捷软件开发－原则、模式与实践》一书中介绍了很多设计，感兴趣的可以去仔细看看。</p>
<h2 id="10-简单—-使未完成的工作最大化的艺术—-是根本的。"><a href="#10-简单—-使未完成的工作最大化的艺术—-是根本的。" class="headerlink" title="10. 简单—-使未完成的工作最大化的艺术—-是根本的。"></a><strong>10. 简单—-使未完成的工作最大化的艺术—-是根本的。</strong></h2><p>我们不可能预期后面需求会如何变化，所以不可能一开始就构建一个完美的架构来适应以后的所有变化。敏捷团队不会去构建明天的软件，而把注意力放在如何通 过最简单的方法完成现在需要解决的问题。这时有人会说，我已经预计到了肯定存在哪些需求扩展点，我们在一开始是否需要考虑呢？这时团队需要根据自己的理解 去决定是否考虑，如果深信在明天发生了这个问题也可以轻易处理的话，那么就最好先不考虑。</p>
<h2 id="11-最好的构架、需求和设计出自与自组织的团队。"><a href="#11-最好的构架、需求和设计出自与自组织的团队。" class="headerlink" title="11. 最好的构架、需求和设计出自与自组织的团队。"></a><strong>11. 最好的构架、需求和设计出自与自组织的团队。</strong></h2><p> 敏捷中有很多种实践，大家都知道，迭代式开发是主要的实践方法，而自组织团队也是主要的实践之一。在自组织团队中，管理者不再发号施令，而是让团队自身寻找最佳的工作方式来完成工作。要形成一个自组织团队其实比较难。CSDN采访Mishkin Berteig中说到 自组织团队的第一个要素就是必须有一个团队，而不仅仅是一群人。一群人是一帮在一起工作的人，他们彼此之间并没有太多的沟通，他们也并不视彼此为一体。</p>
<p> 项目一开始，我们就会组建&ldquo;团队&rdquo;，但很多时候由构架师、需求人员、开发人员和测试人员组成的是一群人而已。他还认为，团队的形成必须经历几个时期。在 经历了初期的磨合后，成员才会开始对团队共同的工作理念与文化形成一个基本的认识和理解。团队内会逐渐形成规矩，而且这些规矩是不言而喻的。比如，每个人 都知道上午九点来上班，都会主动询问别人是否需要帮助，也都会去主动和别人探讨问题。</p>
<p> 如果团队成员之间能够达成这样的默契，那么这个团队将成为一个真正高 效的工作团队。在这样团队中，成员之间相互理解，工作效率非常高。在自组织团队中，团队成员不需要遵从别人的详细指令。他们需要更高层次的指导，这种指 导更像是一个目标，一个致力于开发出更好的软件的目标。总之，自组织团队是一个自动自发、有着共同目标和工作文化的团队，这样的团队总是在向它的组织做出 承诺。但是，实现这些承诺对于自组织团队来说非常重要。否则，一旦出现问题，团队成员之间就会出现信任危机。</p>
<p>虽然敏捷开发小组是以小组为整体 来工作的，但是还是有必要指明一些承担一定任务的角色。第一个角色是产品所有者（Product Owner）。产品所有者的主要职责包括：确认小组所有成员都在追求一个共同的项目前景，确定功能的优先级以便总是在处理最具有价值的功能，以及作出决定 使得对项目的投入可以产生良好的回报。可以对应为以前开发中的&ldquo;产品经理&rdquo;。另一角色是开发团队（developer），这里的开发人员包括了架构师、设计师、程序员、需求人员、测试人员、文档编写者等，有时产品所有者也可以被看作是</p>
<p>开发人员。还有一个重要角色就是项目经理（project manager）。敏捷开发的项目经理会更多的关注领导而不是管理。在某些项目中，项目经理可能同时也是开发人员，少数时候也会担任产品所有者。　
　</p>
<h2 id="12-每隔一定时间，团队会在如何才能更有效地工作方面进行反省，然后相应地对自己的行为进行调整。"><a href="#12-每隔一定时间，团队会在如何才能更有效地工作方面进行反省，然后相应地对自己的行为进行调整。" class="headerlink" title="12. 每隔一定时间，团队会在如何才能更有效地工作方面进行反省，然后相应地对自己的行为进行调整。"></a><strong>12. 每隔一定时间，团队会在如何才能更有效地工作方面进行反省，然后相应地对自己的行为进行调整。</strong></h2><p>　　由于很多不确定性因素会导致计划失效，比如项目成员增减、技术应用效果、用户需求的改变、竞争者对我们的影响等都会让我们作出不同的反应。　敏捷不是基于预定义的工作方式，而是基于经验性的方式，对以上这些变化，小组通过不断的反省调整来保持团队的敏捷性。</p>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>项目生命周期</title>
    <url>/pm/%E9%A1%B9%E7%9B%AE%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
    <content><![CDATA[<p>项目生命周期大致可以分为：初创阶段（协调）-&gt;普通成长阶段（质量）-&gt;实时监控阶段（预警）-&gt;高速发展阶段（高速扩张）-&gt;成熟运行阶段（稳定）</p>
<a id="more"></a>
<p>下面会分别来分析这几个阶段可能遇到的问题，希望帮助到正在创业的或者中小项目团队提前避免，因为团队初期一定会遇到这些问题，成熟的团队都已经历过了这个阵痛期。</p>
<ul>
<li><p>初创阶段：项目初创阶段，人员刚刚组成，团队属于磨合期，初期沟通低效，时间成本高。这个阶段作为技术团队首先要提高对外和对内的协作效率，对外主要沟通对象是产品和测试，对内就是技术团队内部合作问题。因为每个人考虑问题的角度不一样，这个阶段很有可能花费大量时间沟通，这个阶段各个团队的leader一定要精选，这样统一的入口和出口对接人会解决很多问题。</p>
</li>
<li><p>普通成长阶段：项目/系统开始迭代开发，业务正常发展，线上有商户/用户使用，但是偶发发现有商户或用户投诉系统产品功能不完善，开发人员开发的功能有bug，其实这个时候进入了质量问题暴漏阶段，问题主要体现在产品设计有漏掉、开发代码质量不高、测试场景不充分等，所以这个时候建议有一定项目管理流程和机制，并不是一味地提倡快速迭代，因为步子迈得太大一定会容易摔跤。同时，另外一个问题发生了，如果每次都是用户先发现问题，这个场景很尴尬，并且会导致用户流失，所以系统迫切地需要一个实时监控系统，所有的问题早于用户发现，早发现早解决。</p>
</li>
<li><p>实时监控阶段：如果系统没有监控和裸奔没有什么区别，就好比你驾驶着一辆没有仪表盘的车辆，每天都提心吊胆，担心系统出问题后用户投诉。实时监控系统是所有项目人员的眼睛，有了实时监控相当于给系统撒了一张网，让系统所有的点都是可控的、预期的，给人安全感。实时监控主要监控分为业务监控和非业务监控</p>
</li>
</ul>
<ul>
<li>高速发展阶段：随着业务的前期的发展和积累，监控系统也能帮助我们看住系统，这时候业务发展稳定，可能就悄悄来到了高速发展阶段。业务量骤增导致系统并发响应慢、数据库数据量增长过快、单点故障等现象，这个时候其实遇到的问题是性能问题。对于一个初创团队一开始一定是业务核心，不可能过度设计性能问题，好的架构也不是一次设计出来的，一定是演变过来的。这个阶段最需要解决的就是高可用问题，如何建设高可用系统有很多这方面的书籍。</li>
</ul>
<ul>
<li>成熟运行阶段：经历了以上阶段之后，就是成熟运行阶段了。从系统来说，成熟运行阶段只关心一个问题就是线上偶发事故的响应机制。任务系统都一定会发生事故，像最近的发生的GitLab和AWS事件，事故发生了不可怕，如何快速恢复是最重要。生产事故响应机制是如果事故发生了第一时间不是去解决问题、定位问题，而是如何快速恢复交易、减少影响范围、通知商户/用户。为什么这样说？因为技术人员的特点是发生事故后不自然地就去想分析问题和定位问题，这个思路是不对的，增加了事故影响时间。成熟运行阶段，从项目来说，这个时候可能开发任务不那么紧急了，这个时候还需要注重如何提高团队的积极性、如何做好技术分享、如何归纳总结历史问题和知识等。</li>
</ul>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>如何管理好技术团队自我总结</title>
    <url>/pm/%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E5%A5%BD%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E8%87%AA%E6%88%91%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>带了一年15人的技术团队，以下是我对技术团队日常的管理、学习交流会、管理书籍学习，总结出的技术团队管理的建议和看法，希望对大家有所帮助。</p>
<a id="more"></a>
<h2 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h2><ul>
<li><p>1、尊重你的成员，不要觉得自己技术很牛逼，其他人都是傻子，尊重别人的同时，别人也尊重你</p>
</li>
<li><p>2、信任你的成员，给予他们鼓励，帮助他们成长</p>
</li>
<li><p>3、培养你的成员，了解他们的兴趣，帮助规划职业方向，为他们铺路</p>
</li>
<li><p>4、认同你的成员，赞扬他的工作，激励他们成长，指导他们把工作做的更好，给他提出更高的要求</p>
</li>
<li><p>5、技术团队管理不能太技术化，不能只有true or false，要学会变通和交流</p>
</li>
<li><p>6、合理分配团队成员工作，知人善任，人尽其用</p>
</li>
<li><p>7、提高团队执行力，团队驱动靠的是目标</p>
</li>
<li><p>8、工作安排，不能告诉他们怎么做，而是清楚表达自己的需求，要做的是什么，并委婉的进行确认，培养他们需求理解和动手能力</p>
</li>
<li><p>9、定期的和成员间进行沟通，了解他们的状态和内心对环境的看法</p>
</li>
<li><p>10、任何时候都不能替成员完成工作，要培养他们的责任心和执行力</p>
</li>
<li><p>11、项目进展缓慢，不是人的问题，而是项目管理工作分配的问题</p>
</li>
<li><p>12、对于团队中慢性子的人，不要去约束，而是要锻炼他们自我管理能力</p>
</li>
<li><p>13、不要觉得团队管理就要抛弃技术路线，重复工作可以指导队员去完成，自己多花时间加强平台的优化监控和研究新的一些技术</p>
</li>
<li><p>14、适当加班可以锻炼团队战斗力，抵制无意义的加班，营造高效、愉快的工作环境</p>
</li>
<li><p>15、团队的负责人起着带头作用，上行下效，要规范自己的言行，在约束管理团队成员不好言行时，自己也一定不要去做相同的事情</p>
</li>
<li><p>16、每天自省下自己团队管理中的不足，认可自己的成绩，承认自己的不足并相信自己下次能做好</p>
</li>
</ul>
<h2 id="团队、团队建设"><a href="#团队、团队建设" class="headerlink" title="团队、团队建设"></a>团队、团队建设</h2><p>团队是由基层和管理层人员组成的一个共同体，它合理利用每一个成员的知识和技能协同工作，解决问题，达到共同的目标。</p>
<p>团队的构成要素为目标、人、定位、权限、计划。</p>
<p>团队建设就是通过各种活动，组织团队成员优质高效的完成目标。</p>
<p>团队建设的特点是统一的目标、统一的思想、统一的规则、统一的行动、统一的声音。</p>
<ul>
<li><p>统一的目标：先有目标才会有团队。有了团队目标只是团队目标管理的第一步，更重要 的是第二步统一团队的目标，就是要让团队的每个人都认同团队的目标，并为达成目标而努力的工作。</p>
</li>
<li><p>统一的思想：如果团队的思想不统一，你说东他说西，就像人在做思想斗争时会降低行动效率一样，团队思想不统一也会降低效率。</p>
</li>
<li><p>统一的规则：一个团队必须有它的规则，规则是告诉团队成员该做什么，不该做什么。不能做什么是团队行事的底线，如果没有设定底线，大家就会不断的突破底线，一个不断突破行为底线的组织是不能称其为团队的。</p>
</li>
<li><p>统一的行动：一个团队在行动的时候要相互的沟通与协调，让行动统一有序，使整个流程合理的衔接，每个细节都能环环紧扣。</p>
</li>
<li><p>统一的声音：团队在做出决策后声音一定要相同，不能开会不说，会后乱说，当面一套，背后一套。</p>
</li>
</ul>
<p>高效团队是团队建设的目的与努力方向。高效团队强调了协作、配合、有效的沟通及强有力的执行力。高效团队具有以下特性：</p>
<ul>
<li><p>有共同的目标，有约束团队成员朝着这个目标不断努力的机制或制度。</p>
</li>
<li><p>角色定位明晰。各角色职责明确，各岗位不可或缺。</p>
</li>
<li><p>互补的技能。全员参与，注重配合与协调。</p>
</li>
<li><p>共同的工作方法。强调服务，强调实效，强调沟通交流。</p>
</li>
<li><p>工作任务分解(WBS)，执行力度，工作检查。</p>
</li>
<li><p>相互依赖并共同承担责任。</p>
</li>
<li><p>领头的作用明显，指引方向，给成员信心，适当激励。</p>
</li>
</ul>
<p>为做好工程项目，在组建团队时，需要作多方面的努力：</p>
<ul>
<li><p>首先，项目管理者应做到知人善用，各尽所长。尽可能安排合适的人在合适的岗位，充分发挥出他的优势与特长。</p>
</li>
<li><p>其次，在配合上给力。项目成员必须有团队协作精神，通过协同作战来发挥团队的整体战斗力，即形成合力。从而使整个团队达到最佳状态。古人云：“打虎亲兄弟，上阵父子兵”，强调的就是默契的配合，以及密切的协作。</p>
</li>
<li><p>第三，在工作计划与任务安排上考虑更加全面、到位;如有变动，要及时将变动信息传达到相应的人员，以免造成信息脱节。</p>
</li>
</ul>
<h2 id="团队中存在的问题："><a href="#团队中存在的问题：" class="headerlink" title="团队中存在的问题："></a>团队中存在的问题：</h2><ul>
<li><p>一是人员分工不明确，岗位职责不清晰。项目部成员没有相对明确的分工，岗位职责也不明确，几个人凑在一起，今天你干这个，明天我做那个，没有计划性和考核评价，办事效率低下。</p>
</li>
<li><p>二是执行力差，缺乏积极性和主动性。主要表现：没有养成加班做事的习惯。凡事等着上级安排，推一推，动一动，不推不动。</p>
</li>
</ul>
<p>上级不安排工作就坐等，上级不指示就不执行，上级不询问就不汇报，上级不检查就拖着办。很多工作的完成，都是在多次检查、催办下完成的，执行力很差；</p>
<p>再就是等待外单位的回复。抱着“我已与你联系过了，静待回音，什么时候回复不是我能决定的，延误工作的责任应该由对方负责，我只能等”这样的心态，不积极、不主动靠前。</p>
<p>再就是等待其他部门或其他人的联系。你不找我协助，我就躲避，总有原因可以找，就说情况不清楚。对其他相关工作不关心，没兴趣，多一事不如少一事；等待下级的汇报。</p>
<p>任务虽已布置，但是没有检查，没有监督。不主动去深入实际调查研究，掌握第一手资料，只是被动地听下级的汇报，没有核实，然后作决定或向上级汇报，贻误战机，影响效率。</p>
<ul>
<li><p>三是缺乏专业知识和工作经验，工作效率不高。比如说**库和尾矿库建设的问题，为如何立项获得批准经历了很多反复，耽误了很多时间，一直是在摸索；黄金文化产业园项目，因为坐标出现偏差，导致重新申报；涌积水与边坡综合治理及防沙绿化生态农业项目，开始是承办公司变更，再加上项目合并，耽误了时间，影响了工作效率；这些问题的出现，其实最根本的问题还是专业能力不足，缺少工作经验。</p>
</li>
<li><p>四是动力不足，工作进展缓慢。团队人员不多，但没有凝聚力，一盘散沙，你干你的，我干我的，缺乏协调和沟通，没有目标和使命感；缺少责任心和监督考评制度。上述现象的出现，主要原因是负责人缺乏<strong>责任心和使命感</strong>，懒惰，自私造成的，这样的后果就是出现了不学无术、沟通不畅、缺乏责任和担当，履行职责没有痕迹，作而无为等现象。造成的结果就是吃大锅饭，绩效考核指标，动力不足，积极性不高，办事效率低下。</p>
</li>
</ul>
<h2 id="如何搞好团队建设"><a href="#如何搞好团队建设" class="headerlink" title="如何搞好团队建设"></a>如何搞好团队建设</h2><p>团队建设，简单讲就是：给你一拨人，你得能把他们拢在一起，朝着一个方向走。</p>
<p>彼得.德鲁克说过：现代企业不仅是老板和下属的企业，而应该是一个团队。</p>
<p>团队需要建设!</p>
<h3 id="1、强化项目经理的领导力"><a href="#1、强化项目经理的领导力" class="headerlink" title="1、强化项目经理的领导力"></a>1、强化项目经理的领导力</h3><p>项目经理既是管理者，又是执行者;既是工作计划的制订者，又是实施计划的领头人，作为团队的”头”，其个人素质起着至关重要的作用。要做好这支团队的领头羊，不仅要用平和之心客观公正地对待营业处的每件事和每个人，更重要的是全面提高自身素质。</p>
<p>项目经理在团队管理中相当于搅拌机，通过组织会议、讨论、学习、攻关等活动，与成员之间形成良好的沟通，最终形成明智的决策。项目经理不但要有计划、领导、沟通、交际、应变的能力，还必须具备较强的组织能力。如何将项目成员组织起来，如何发挥他们的工作效率，如何增强团队的凝聚力等，是项目经理必须考虑的问题。</p>
<p>在团队建设中，项目经理要做到以下几点：</p>
<ul>
<li><p>一、是建立明确共同的目标，项目管理培训，打造团队精神，抓好目标管理，没有目标，团队就失去了方向。因此，建立一个明确的目标并对目标进行分解，同时通过组织讨论、学习，使每一个单位、每一个人都知道本单位或自己所应承担的责任、应该努力的方向，这是团队形成合力、劲往一处使的前提。</p>
</li>
<li><p>二、是抓规范，抓执行，营造积极进取团结向上的工作氛围。衡量一个公司管理是否走上正轨的一个重要标志就是制度、流程是否被公司员工了解、熟悉、掌握和执行，是否有监督和保障措施。让员工熟悉、掌握各类制度、流程，不但是保证工作质量的需要，也是满足公司长远发展和员工快速成长的需要。事实证明，没有一套科学完整、切合实际的制度体系，管理工作和员工的行为就不能做到制度化、规范化、程序化，就会出现无序和混乱，就不会产生井然有序、纪律严明的团队。所以，要从我们的小团队做起，要运用各种形式，加大学习力度，抓执行力，抓落实兑现。</p>
</li>
<li><p>三、是用有效的沟通激活团队建设，建立良好的工作氛围。把情况了解上来，把影响施加下去。</p>
</li>
</ul>
<p>沟通的手段多种多样：</p>
<p>比如：聊天就是很好的方式之一。聊天那不是乱聊的意思，尤其在时机和话题的选择上。目的只有一个：拉近距离，融洽气氛，了解情况，施加影响。再如：还有比较喜欢用的就是娱乐，尤其是下棋、打牌、喝酒，这三项活动最能体现人的性格，想藏都藏不住。</p>
<p>性格无所谓优劣，最重要的是因人而异，善加利用。通过合理的组合，减少冲突，增强合力。</p>
<p>沟通是维护团队建设整体性的一项十分重要的工作，也可以说是一门艺术。如果说纪律是维护团队完整的硬性手段的话，那么沟通则是维护团队完整的软性措施，它是团队的无形纽带和润滑剂。</p>
<p>沟通可以使团队建设中上情下达、下情上达，促进彼此间的了解;可以消除员工内心的紧张和隔阂，使大家精神舒畅，从而形成良好的工作氛围。</p>
<p>因此，作为各单位负责人必须要保持团队内部上下、左右各种沟通渠道的畅通，以利于提高团队内部的士气，为各项工作的开展创造”人和”的环境。</p>
<ul>
<li><p>四、是树立服务意识。服务，这是团队建设的核心内容。</p>
<ul>
<li><p>1.压制自己是头、有权发号施令的念头。</p>
</li>
<li><p>2.多地想的是对这个团体的责任，目的是要把工作做好。</p>
</li>
<li><p>3.要立足于服务，给团队成员创造出一个良好的工作环境。</p>
</li>
<li><p>4.要让团队成员放手工作，“错了，责任是我的，对了，功劳是你们的”</p>
</li>
</ul>
<p>需要注意：</p>
<ul>
<li><p>1.服务不等于迁就，是有原则的，也是在自己能力范围内的。</p>
</li>
<li><p>2.过程中，难免会有不少误解、委屈，也会很“吃亏”。如果你想把工作做好，这些你都得认喽，吃这些小“亏”占“工作做好”这个大“便宜”。等成绩出来的时候，那些误解、委屈也就没了，你收获得将是一帮多少年后都还彼此眷顾、相互信任的朋友和一段美好的回忆。</p>
</li>
</ul>
</li>
<li><p>五、是用好考核激励机制，不断激发员工进步。绩效考核是一种激励和检验。它不仅检验每个团队成员的工作成果，也是向团队成员宣示公司的价值取向，倡导什么，反对什么，所以它同样关系到团队的生存和发展。PgMp.mypm.net激励。</p>
</li>
</ul>
<p>物质奖励是必要的，但一定要慎用、少用。</p>
<p>弊端：</p>
<ul>
<li><p>1.造成不必要的麻烦，增加攀比、猜忌等矛盾，破坏气氛。</p>
</li>
<li><p>2.说明组织、薪酬体系有问题。</p>
</li>
</ul>
<p>多使用精神层面的激励;最有效的就是对人真诚的尊重和信任、对成绩及时有效的肯定。</p>
<h3 id="2、实行多样性的管理方法。"><a href="#2、实行多样性的管理方法。" class="headerlink" title="2、实行多样性的管理方法。"></a>2、实行多样性的管理方法。</h3><p>推行制度化管理，建立相应的管理体系和支撑体系，从机构和制度上建立保障机制;项目管理者通过立规矩、建标准来实现制度管人。通过制度和规范来保障项目的稳定运作。结合通信工程的特点，工作中必须保证安全、质量，操作上必须严谨、规范。通过制度来保证行动的高效性和团队的执行力，实现项目的安全、进度、质量目标。</p>
<p>将法、儒、道家的管理哲学应用到团队管理中。以孔子为代表的儒家主张礼治;以秦孝公的商鞅变法为代表的法家主张以法治国，通过建立法规法律去约束人的行为，从而达到管理的目的;道家的理论奠定于老子，提倡无为而治。</p>
<p>结合团队发展阶段，在形成期和磨合期，采用法家的多一些，强调制度化管理方法，以规范为主。在表现期团队稳定有秩序的状况下，则采用儒家的多一些，或者阴法阳儒——红脸白脸的做法。当然，项目管理者的领导风格也应由影响型转变为授权型。</p>
<h3 id="3、过程管控贯穿于整个项目实施周期。"><a href="#3、过程管控贯穿于整个项目实施周期。" class="headerlink" title="3、过程管控贯穿于整个项目实施周期。"></a>3、过程管控贯穿于整个项目实施周期。</h3><p>由于很多时候施工任务迭代进行，因此需要有人定期跟踪进度和现场情况，将问题或风险反馈汇报，对安全、工艺和质量把关，阶段性检查与纠偏等，做到全程监控，持续跟进。使得计划有落实、任务有执行、进度有跟踪、问题有反馈、问责可追溯，从而形成工作的PDCA闭环。</p>
<p>在做好全过程细节的划分和量化的同时，重点强调“凡事”两个字，即必须要落实“凡事有人负责、凡事有章可循、凡事有人监督、凡事有据可查”的要求。</p>
<ol>
<li><p>凡事有人负责。即要求每一项工作、每一个环节和每一个细节都必须有人负责，这是实施精细化管理的第一要务。</p>
</li>
<li><p>凡事有章可循。即要求每一项工作、每一个环节和每一个细节都必须有制度可循、有标准可查，这是“细”的主要内容、“精”的本质要求。</p>
</li>
<li><p>凡事有人监督。即要求每一项工作、每一个环节和每一个细节都必须有人检查、有人监督，这是精细化目标得以实现的必要保证。</p>
</li>
<li><p>凡事有据可查。即要求每一项工作、每一个环节和每一个细节都必须有必要的过程记录和数据留存，这是“事故后”进行问题反查和闭环管理、持续改进的基本要求。如果达不到凡事有据可查，一旦出现工作质量问题，将无法进行原因分析和问题整改;同时，必要的过程记录和数据留存也是总结经验、持续改进的基础。</p>
</li>
</ol>
<h3 id="4、加强沟通与配合。"><a href="#4、加强沟通与配合。" class="headerlink" title="4、加强沟通与配合。"></a>4、加强沟通与配合。</h3><p>沟通交流是做好团队管理的关键环节之一。由于工程项目涉及众多合作单位，需要与外单位协调、配合的事务很多，因此需要掌握沟通技巧，注意沟通的方式方法。同时，又要求团队成员间协同作战，高度配合。</p>
<p>从龙舟比赛可以看出，一支参赛队伍想要拥有强劲的战斗力，既要项目经理掌握好队伍的整体节奏、比赛策略，又需要赛手密切配合，动作高度一致。只有合力发挥出所有人的能量，才能最终赢得比赛。</p>
<h3 id="5、组织学习、培训与个人提升。"><a href="#5、组织学习、培训与个人提升。" class="headerlink" title="5、组织学习、培训与个人提升。"></a>5、组织学习、培训与个人提升。</h3><p>“火车跑得快，全凭车头带”。传统的团队管理方法，突显了项目经理的领头羊作用。但车头——项目管理者会很累。现今的动车跑得更快了，靠的是项目管理者正确的指挥与引导，激发所有成员的动力，加上所有成员目标一致性、工作方法相同、密切配合、协同作战，从而形成强大的合力。再加上外部环境的改进，激励机制的优化，这样团队才能真正高效。带队伍就应该像动车那样。</p>
<p>要善于营造学习氛围，形成良好的学习环境。当今社会普遍存在一个误区，以为在员工学习上，发些资料、文档给员工看，或者把学习材料共享到指定网站，规定员工学习范围就行了。其实不然，作者认为这还不够，正确的指导是必须的，定期跟进其学习状态，了解成员近期在学习什么，周末时间如何安排的等。</p>
<p>团队建设不能忽视工员的个人提升。通过培训学习，使员工工作技能到得提升，促进员工成长，形成“传—帮—带”的机制和团队互助作风。员工的成长离不开项目经理的培养，员工也希望能从他的上司或主管那里学到一些知识，或得到建议。正如卡拉·哈里斯在《我在摩根士丹利做高管》一书中提到，一些人希望与他的上司或领导建立起“导师关系”，从而能够从岁导师身上获得知识、建议或如何更好地处理事情的启示等等。换言之，帮助员工规划职业生涯，也是主管的一种担当。</p>
<h3 id="6、认同公司的企业文化、核心价值观，通过企业文化的渗透，保证团队的稳定性。"><a href="#6、认同公司的企业文化、核心价值观，通过企业文化的渗透，保证团队的稳定性。" class="headerlink" title="6、认同公司的企业文化、核心价值观，通过企业文化的渗透，保证团队的稳定性。"></a>6、认同公司的企业文化、核心价值观，通过企业文化的渗透，保证团队的稳定性。</h3><p>在此基础上，建立起真诚友善，互助互惠的工作环境。史蒂芬·柯维在《高能效人士的七个习惯》中强调双赢思维。彼此相互信任，以双赢思维解决冲突，从而达到和谐、健康、平衡发展的良好局面。</p>
<h3 id="7、团队建设活动必不可少。"><a href="#7、团队建设活动必不可少。" class="headerlink" title="7、团队建设活动必不可少。"></a>7、团队建设活动必不可少。</h3><p>团队活动是团队长期稳定必要的润滑剂。在日常生活中，项目经理应经常与项目成员进行面谈，听取他们在工作中存在的困难和困惑，帮助他们减轻思想压力;并且定期组织一些业余活动等。在关键里程碑项目管理者联完成的时候，进行总结和庆祝，对项目成员的士气起到很大的鼓舞作用，对下一阶段工作有序的开展也提供帮助。要将员工关怀体现在生活中，8小时之外的时间里，举行一些活动，如座谈聊天，喝茶等，关心员工的健康，关爱员工感受与内心诉求，让员工感受到公司是重视员工的，自身价值能够得到体现的，从而形成团队凝聚力。</p>
<h3 id="8、发掘潜能，发挥到极致。"><a href="#8、发掘潜能，发挥到极致。" class="headerlink" title="8、发掘潜能，发挥到极致。"></a>8、发掘潜能，发挥到极致。</h3><p>例如，通过某个活动或任务的授权，委以重任，挖掘员工的优势与潜能，发现员工的特长技能。那么，项目管理者需要创造必要的条件，并营造一个平台，使得这些潜能能够充分发挥出来。当整个团队的能量都发挥出后，整体团队的能量才能彰显出来。也就是说，项目团队成长过程达到了“表现期”，那么，整个团队的工作绩效和团队士气将升级到很高的状态。</p>
<p>当然，潜能发掘是一个循序渐进的过程，不能一蹴而就。而且有些人不善于表达，羞于主动表现，那么，项目经理在平时就要多留心观察，多些引导和沟通。项目经理最重要的不是自己如何能干，而是怎么样把你项目中的人员的能力发挥到极致。</p>
<h2 id="团队"><a href="#团队" class="headerlink" title="团队"></a>团队</h2><p>团队建设、团队培养、领导力、沟通</p>
<h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><p>目标计划、任务分解、过程管控（全程监控、持续跟进）</p>
]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title>架构经验</title>
    <url>/sa/architecture-experience/</url>
    <content><![CDATA[<h1 id="架构相关"><a href="#架构相关" class="headerlink" title="架构相关"></a>架构相关</h1><a id="more"></a>
<ul>
<li><a href="../架构思想">架构思想</a></li>
<li><a href="../大型网站技术架构">大型网站技术架构</a></li>
<li><a href="http://blog.fulin.org/2016/03/summary-of-architectures/" target="_blank" rel="noopener">各大互联网公司架构演进之路汇总</a></li>
<li><a href="https://mp.weixin.qq.com/s/AbUGOWN27FEUPWgDQkF_Dw" target="_blank" rel="noopener">中小型研发团队架构落地实践18篇，含案例、代码</a></li>
<li><a href="https://mp.weixin.qq.com/s/5vVXBXkd-Ilh7zk5G6Wxcg" target="_blank" rel="noopener">高可用系统架构</a></li>
<li><a href="https://mp.weixin.qq.com/s/-wIC6yPifSEfT_Yybi4pTg" target="_blank" rel="noopener">看京东系统架构师如何让笨重的架构变得灵巧</a></li>
<li>前后端分离<ul>
<li><a href="https://mp.weixin.qq.com/s/Nhyo969WnEwyCWpr34ECcA" target="_blank" rel="noopener">互联网分层架构，为啥要前后端分离</a></li>
<li><a href="https://mp.weixin.qq.com/s/On98tXDEpnx1n7sqgZYWzA" target="_blank" rel="noopener">前后端API交互如何保证数据安全性？</a></li>
</ul>
</li>
<li>网关    <ul>
<li><a href="Gateway.md">Gateway</a></li>
<li><a href="https://mp.weixin.qq.com/s/Qnxec7w26AX6jRl0KRHVHg" target="_blank" rel="noopener">微服务网关Zuul迁移到Spring Cloud Gateway</a></li>
<li><a href="https://mp.weixin.qq.com/s/qySjzQ8f-pYwWKPE_8BhVg" target="_blank" rel="noopener">Spring Cloud 终于按捺不住推出了自己的服务网关 Gateway</a></li>
</ul>
</li>
<li>分布式事务<ul>
<li><a href="https://github.com/aalansehaiyang/technology-talk/blob/master/data-base/transaction.md" target="_blank" rel="noopener">technology-talk</a></li>
</ul>
</li>
<li>注册中心<ul>
<li><a href="https://mp.weixin.qq.com/s/Kawfps7C1pGRMq1eBgiZKw" target="_blank" rel="noopener">几种服务注册与发现组件的原理与比较</a></li>
</ul>
</li>
<li>负载均衡<ul>
<li><a href="../load-balance">常用算法</a></li>
</ul>
</li>
<li>Spring Cloud<ul>
<li><a href="https://mp.weixin.qq.com/s/Xh-C79U35lsIsow_TL41dQ" target="_blank" rel="noopener">苏宁数据中台基于Spring Cloud微服务架构实践</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h1><ul>
<li><a href="../microservice-introduce">微服务介绍</a></li>
<li><a href="../SOA与微服务">SOA与微服务</a></li>
<li><a href="https://mp.weixin.qq.com/s/W3Vn0EgCjWpjJ365Pv30iw" target="_blank" rel="noopener">如何设计高可用的微服务架构？</a></li>
<li><a href="https://mp.weixin.qq.com/s/YfXjkMX-eQFmEzjG6Lwvrw" target="_blank" rel="noopener">微服务的4大设计原则和19个解决方案</a></li>
<li><a href="https://mp.weixin.qq.com/s/ZxVQ7PvK89XVBYhNUoMnMg" target="_blank" rel="noopener">微服务后如何做一次系统梳理</a></li>
<li><a href="https://mp.weixin.qq.com/s/zFJokAv8lSQejGFTGJTJeQ" target="_blank" rel="noopener">微服务架构技术栈选型手册</a></li>
<li><a href="https://mp.weixin.qq.com/s/OloZhn2pwfIrOQit_8jefA" target="_blank" rel="noopener">微服务2.0技术栈选型手册</a></li>
<li><a href="https://mp.weixin.qq.com/s/fqOOkMMPwXTNG8PHJ_yUAw" target="_blank" rel="noopener">微服务架构在千万级别日调用量、亿级别海量数据场景下的应用实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/dY2xmz3J735Etb7DtX-9hQ" target="_blank" rel="noopener">微服务架构设计基础之立方体模型</a></li>
<li>Service Mesh    <ul>
<li><a href="https://mp.weixin.qq.com/s/XCUg4nVXJ9Q-mccYAyvc5Q" target="_blank" rel="noopener">Service Mesh：重塑微服务市场</a></li>
<li><a href="https://mp.weixin.qq.com/s/fdByrlbKmA0H1ccEBL0NAw" target="_blank" rel="noopener">Service Mesh 及其主流开源实现解析</a></li>
<li><a href="https://skyao.io/#about" target="_blank" rel="noopener">蚂蚁金服 Service Mesh</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h1><ul>
<li><a href="../cache-summary">cache经验总结</a></li>
<li><a href="../cache-talk">缓存杂谈</a></li>
<li><a href="../缓存架构之防雪崩设计">缓存架构之防雪崩设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/Imn4FuXv2hw3uocgZsBlOg" target="_blank" rel="noopener">大型web系统数据缓存设计</a></li>
<li><a href="https://github.com/oldratlee/cache-practice" target="_blank" rel="noopener">cache常见的陷阱与坑</a></li>
<li><a href="https://mp.weixin.qq.com/s/62KJ2mSTGoUTPsq0RjU7lg" target="_blank" rel="noopener">缓存穿透、缓存并发、热点缓存之最佳招式</a></li>
<li><a href="https://mp.weixin.qq.com/s/kYXabyZhVthF-9rR0Uv4lQ" target="_blank" rel="noopener">再谈缓存的穿透、数据一致性和最终一致性问题</a></li>
<li><a href="https://mp.weixin.qq.com/s/foQZSZ0xx0YYPHGawshc3g" target="_blank" rel="noopener">分布式缓存的25个优秀实践与线上案例</a></li>
<li><a href="https://mp.weixin.qq.com/s/f-K0lPjBPcYFK0hbZJF99Q" target="_blank" rel="noopener">缓存在大型分布式系统中的最佳应用</a></li>
<li>数据迁移    <ul>
<li><a href="https://mp.weixin.qq.com/s/8WtbAaNRdaJvRWcVG5K5rQ" target="_blank" rel="noopener">分布式缓存的迁移方案</a></li>
</ul>
</li>
<li><a href="https://mp.weixin.qq.com/s/xHOZ5Nr4LQwpQoRwoTDxZA" target="_blank" rel="noopener">数据库和缓存双写一致性方案解析</a></li>
<li><a href="https://mp.weixin.qq.com/s/4J3oM1j5hcLq4w4TdSEMPg" target="_blank" rel="noopener">缓存架构，一篇足够？</a></li>
<li><a href="https://mp.weixin.qq.com/s/DV5eSZtShs2twGe0UwzPuA" target="_blank" rel="noopener">你应该知道的Java缓存进化史</a></li>
<li><a href="../cache相关">cache相关</a>    </li>
</ul>
<hr>
<h1 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h1><ul>
<li><a href="../数据库架构">数据库架构</a></li>
<li><a href="https://mp.weixin.qq.com/s/ad4tpM6cdi9r6vgfbaTzxg" target="_blank" rel="noopener">无限容量数据库架构设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/3O3kPSwV-tAeYdy2ZRACpg" target="_blank" rel="noopener">100亿数据1万属性数据架构设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/ezD0CWHAr0RteC9yrwqyZA" target="_blank" rel="noopener">数据库表垂直拆分</a></li>
<li><a href="https://mp.weixin.qq.com/s/2G5z9Ra8DJOP_1Co3cHcqA" target="_blank" rel="noopener">分布式MySQL集群方案的探索与思考</a></li>
<li>中间件<ul>
<li><a href="https://mp.weixin.qq.com/s/lHrMS-GdKsZYhaOf59magQ" target="_blank" rel="noopener">为什么要引入数据库中间件</a></li>
</ul>
</li>
<li>分库分表<ul>
<li><a href="https://mp.weixin.qq.com/s/eOaVRyCTKHeAWG4UXcGjQQ" target="_blank" rel="noopener">关于分库分表</a></li>
<li><a href="https://mp.weixin.qq.com/s/Wn_Ox3617uUkzIJJJoUrjw" target="_blank" rel="noopener">也谈分库分表在实际应用的实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/oK94W71MAdNKXLxHl5dpPQ" target="_blank" rel="noopener">不停机分库分表迁移</a></li>
<li><a href="split-table.md">如何不停机完成单表拆分</a></li>
</ul>
</li>
<li><a href="https://mp.weixin.qq.com/s/JEJcgD36dpKgbUi7xo6DzA" target="_blank" rel="noopener">InnoDB，5项最佳实践，知其所以然？</a></li>
</ul>
<hr>
<h1 id="MQ消息"><a href="#MQ消息" class="headerlink" title="MQ消息"></a>MQ消息</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/Zwd1USlOCkQvsG96eSwvpg" target="_blank" rel="noopener">消息中间件选型分析</a></li>
<li><a href="https://mp.weixin.qq.com/s/8oX7u8XcLL80_nNdN-UkvQ" target="_blank" rel="noopener">MQ消息可达性+幂等性+延时性架构设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/Kpkr-vGUC9Po19iRPKfLfA" target="_blank" rel="noopener">一网打尽消息队列在大型分布式系统中的实战精髓</a></li>
</ul>
<hr>
<h1 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/MI_vtOo4EFAWm_e379uPUg?from=groupmessage&isappinstalled=0" target="_blank" rel="noopener">分布式配置中心</a></li>
</ul>
<hr>
<h1 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h1><ul>
<li>系统容量<ul>
<li><a href="https://mp.weixin.qq.com/s/wxSN47UNtEG_4vEl5lw31g" target="_blank" rel="noopener">如何进行容量设计</a></li>
</ul>
</li>
<li>限流<ul>
<li><a href="../如何设计API的限流">如何设计API的限流</a></li>
<li><a href="https://mp.weixin.qq.com/s/VXu82MgWwn993n8fSlaNtg" target="_blank" rel="noopener">分布式限流</a></li>
<li><a href="https://mp.weixin.qq.com/s/GEu7UVO7s_HX88T_DmBmnQ" target="_blank" rel="noopener">探索常见的几种限流策略和实现</a></li>
<li><a href="https://mp.weixin.qq.com/s/s-4JeeATl9NpkxUIeBHvSw?utm_source=tuicool&utm_medium=referral" target="_blank" rel="noopener">阿里巴巴宣布开源限流降级中间件——Sentinel</a> </li>
<li><a href="https://mp.weixin.qq.com/s/q3QUySAw4owaXYlfgQ15SA" target="_blank" rel="noopener">限流降级神器，带你解读阿里巴巴开源 Sentinel （二）资源调用链</a></li>
<li><a href="https://mp.weixin.qq.com/s/g2hyp9CquEAvTe8QmPO-3g" target="_blank" rel="noopener">限流降级神器-哨兵(sentinel)原理分析</a></li>
<li><a href="https://blog.52itstyle.com/archives/2982/" target="_blank" rel="noopener">从构建分布式秒杀系统聊聊限流特技</a></li>
<li><a href="https://mp.weixin.qq.com/s/wRKiEKT_Qe05Ie8XWgkaXQ" target="_blank" rel="noopener">限流系统如何发现系统的热点</a></li>
<li><a href="https://mp.weixin.qq.com/s/EpDh2j8eKaObVcE7a1F4jg" target="_blank" rel="noopener">想通关「限流」？只要这一篇</a></li>
</ul>
</li>
<li>降级<ul>
<li><a href="../demotion">降级</a></li>
</ul>
</li>
<li>熔断<ul>
<li><a href="../fusing">熔断器</a></li>
<li><a href="https://mp.weixin.qq.com/s/txh8-N_VEVh11Rc4oQGfqw" target="_blank" rel="noopener">如何在到处是“雷”的系统中「明哲保身」</a></li>
</ul>
</li>
<li>隔离<ul>
<li><a href="../isolate">隔离设计</a></li>
</ul>
</li>
<li>幂等<ul>
<li><a href="../idempotent">幂等性设计</a></li>
<li><a href="https://my.oschina.net/wangen2009/blog/1560975" target="_blank" rel="noopener">并发与幂等性</a></li>
</ul>
</li>
<li>重试<ul>
<li><a href="../re-try">重试设计</a></li>
</ul>
</li>
<li>异地双活</li>
</ul>
<hr>
<h1 id="流量相关"><a href="#流量相关" class="headerlink" title="流量相关"></a>流量相关</h1><ul>
<li><a href="../flow-dispatch">流量调度</a></li>
</ul>
<hr>
<h1 id="高并发"><a href="#高并发" class="headerlink" title="高并发"></a>高并发</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/th2PyARAdLOLElieQjNSSA" target="_blank" rel="noopener">究竟啥才是互联网架构“高并发”</a></li>
</ul>
<hr>
<h1 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h1><ul>
<li><a href="../数字签名">接口鉴权（数字签名）</a></li>
</ul>
<hr>
<h1 id="锁相关"><a href="#锁相关" class="headerlink" title="锁相关"></a>锁相关</h1><ul>
<li><a href="../锁机制">乐观锁&amp;悲观锁</a></li>
<li>分布式锁<ul>
<li><a href="../分布式锁">基于 redis分布式锁（推荐）</a></li>
<li><a href="https://mp.weixin.qq.com/s/ctbcwV4hzdB2MwGqQAA0_A" target="_blank" rel="noopener">基于 redis 的分布式锁到底安全吗?</a></li>
<li><a href="../lock-zk">基于 zookeeper实现的分布式锁</a></li>
<li><a href="../lock-db">基于数据库实现分布式锁（不推荐）</a></li>
</ul>
</li>
<li><a href="https://mp.weixin.qq.com/s/0wmVSfrkFq7BfpUvydr-ug" target="_blank" rel="noopener">我们该使用哪种分布式锁？</a></li>
<li><a href="https://mp.weixin.qq.com/s/-mziYuTMjECKpTLKZBumbw" target="_blank" rel="noopener">从构建分布式秒杀系统聊聊分布式锁</a></li>
</ul>
<hr>
<h1 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h1><ul>
<li><a href="../性能优化之Qps">性能优化之QPS</a></li>
<li><a href="http://blog.csdn.net/itomge/article/details/21649489" target="_blank" rel="noopener">系统性能优化常用手段</a></li>
<li><a href="http://blog.csdn.net/itomge/article/details/8712102" target="_blank" rel="noopener">web性能优化14法则</a></li>
<li><a href="https://mp.weixin.qq.com/s/gtxDbgo_esY4kD_LNoyfPQ" target="_blank" rel="noopener">从代码层面优化系统性能的解决方案</a></li>
</ul>
<hr>
<h1 id="WEB-系统"><a href="#WEB-系统" class="headerlink" title="WEB 系统"></a>WEB 系统</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/iTdHyODJ12RvTbe6MILg6Q" target="_blank" rel="noopener">分布式 session</a></li>
</ul>
<hr>
<h1 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/KUiHS4Jg7pqunEA3X6RQPw" target="_blank" rel="noopener">技术选型时的思考及注意事项</a></li>
</ul>
<hr>
<h1 id="开源"><a href="#开源" class="headerlink" title="开源"></a>开源</h1><ul>
<li><a href="https://yq.aliyun.com/articles/676140" target="_blank" rel="noopener">2018年阿里巴巴重要开源项目汇总</a></li>
</ul>
<hr>
<h1 id="架构汇总"><a href="#架构汇总" class="headerlink" title="架构汇总"></a>架构汇总</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/OlFKpcnBOgcPZmjvdzCCiA" target="_blank" rel="noopener">架构师之路2016年精选50篇</a></li>
<li><a href="https://mp.weixin.qq.com/s/8RM6U8UqWTDp29DB_hiYVQ" target="_blank" rel="noopener">架构师之路2017半年精选40篇</a></li>
<li><a href="https://mp.weixin.qq.com/s/vLebPT-58Jw-Q7afhkgHSg" target="_blank" rel="noopener">架构师之路，季度精选40篇</a></li>
<li><a href="https://mp.weixin.qq.com/s/CIPosICgva9haqstMDIHag" target="_blank" rel="noopener">架构师之路17年精选80篇</a></li>
<li><a href="https://maimai.cn/article/detail?fid=282107496&from=headline&share_user=http://i9.taou.com/maimai/p/3621/990_45_u1AK5tPDEjhwhh-a160" target="_blank" rel="noopener">阿里巴巴十年Java架构师分享</a></li>
<li><a href="https://mp.weixin.qq.com/s/VlJjfJHcedO5sIdGaHCoxg" target="_blank" rel="noopener">芋道源码的周八（2018.03.04）</a></li>
<li><a href="https://mp.weixin.qq.com/s/QqcY-9Y7miheTcu65ZEY4A?from=groupmessage&isappinstalled=0" target="_blank" rel="noopener">芋道源码的周八（2018.03.18）</a></li>
</ul>
<hr>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><ul>
<li><a href="../架构师的职责与思考">架构师的职责与思考</a></li>
<li><a href="http://mp.weixin.qq.com/s/KsFVTqDhYcO3Jws6oOoa4g" target="_blank" rel="noopener">好的架构是逐步演化过来的</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&mid=2650993402&idx=1&sn=f79a2e2cd75bf7ca539149addb6e7c21" target="_blank" rel="noopener">技术不应成为业务的工具</a></li>
<li><a href="http://mp.weixin.qq.com/s/iGTJy98Fj_qT0gBMHxzH1g" target="_blank" rel="noopener">创业公司如何打造高效的研发体系？</a></li>
<li><a href="https://mp.weixin.qq.com/s/pf-2pw0W4vKch7IDGTyzBw" target="_blank" rel="noopener">那么贵的技术会议，真的能学到东西吗？</a></li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>经典案例</title>
    <url>/sa/architecture-good-case/</url>
    <content><![CDATA[<h1 id="电商"><a href="#电商" class="headerlink" title="电商"></a>电商</h1><a id="more"></a>
<ul>
<li><h3 id="淘宝"><a href="#淘宝" class="headerlink" title="淘宝"></a>淘宝</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/WkBavHJyfCQCo_P1Vmm03A" target="_blank" rel="noopener">淘宝网系统架构分享</a></li>
<li><a href="http://mp.weixin.qq.com/s/kbAwChFavgfhyUZLEXea2w" target="_blank" rel="noopener">阿里巴巴系统架构</a></li>
<li><a href="http://mp.weixin.qq.com/s/1BJ5SA0q4mkjxiLt0Sbq_w" target="_blank" rel="noopener">淘宝双11高可用架构演进之路</a></li>
<li><a href="http://mp.weixin.qq.com/s/m6rlPeB46JbF3Dl49FE1xQ" target="_blank" rel="noopener">历经8年双11流量洗礼，淘宝开放平台如何攻克技术难关？</a></li>
<li><a href="http://mp.weixin.qq.com/s/_n1zSJ0uv9gNctXD9tyGsg" target="_blank" rel="noopener">从淘宝到云端的高可用架构演进</a></li>
<li><a href="http://mp.weixin.qq.com/s/WBdSWR9N6sp-UooewzVa3Q" target="_blank" rel="noopener">阿里研究员玄难：如何做电商业务中台</a></li>
<li><a href="http://mp.weixin.qq.com/s/Osggn2PFSySsrqCyW2Dtmw" target="_blank" rel="noopener">解密阿里巴巴高可用架构技术——“异地多活”</a></li>
<li><a href="https://mp.weixin.qq.com/s/BDLPoresSJJ_uv2PBvYsYA" target="_blank" rel="noopener">揭秘2017双11背后的网络－双11的网络产品和技术概览</a></li>
</ul>
</li>
<li><h3 id="1号店"><a href="#1号店" class="headerlink" title="1号店"></a>1号店</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/_2Rw-4h4F4843c89tz-Z2Q" target="_blank" rel="noopener">1号店大型电商微服务实践</a></li>
<li><a href="http://mp.weixin.qq.com/s/lzRZNWMx2KxeIyKXggl58w" target="_blank" rel="noopener">1号店交易系统架构如何向「高并发高可用」演进</a></li>
</ul>
</li>
<li><h3 id="蘑菇街"><a href="#蘑菇街" class="headerlink" title="蘑菇街"></a>蘑菇街</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/wQH7Zz6o88pj-v1E2rGJEw" target="_blank" rel="noopener">蘑菇街电商交易平台服务架构及改造优化历程</a></li>
</ul>
</li>
<li><h3 id="有赞"><a href="#有赞" class="headerlink" title="有赞"></a>有赞</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/XLWq01U0mOWpGEmXeri2TQ" target="_blank" rel="noopener">交易系统架构困局以及破局之道</a></li>
<li><a href="https://mp.weixin.qq.com/s/4W3WVssWXu4ViXFhBPc_SQ" target="_blank" rel="noopener">团队和工程管理取舍的经验之谈</a></li>
<li><a href="https://mp.weixin.qq.com/s/enawjPibzmwXJ9MTVLSPxQ" target="_blank" rel="noopener">订单导出的配置化实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/pkPVYmrUTywSiswZz_YqKw" target="_blank" rel="noopener">订单管理的三生三世与“十面埋伏”</a></li>
</ul>
</li>
<li><h3 id="O2O外卖"><a href="#O2O外卖" class="headerlink" title="O2O外卖"></a>O2O外卖</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/nmRG5tyj28-pS_dho2NOqg" target="_blank" rel="noopener">美团外卖订单中心的演进</a></li>
<li><a href="https://mp.weixin.qq.com/s/DvQszWAr89XjWodJUjVTjw" target="_blank" rel="noopener">饿了么：日订单量超900万的架构设计及演进之路</a></li>
</ul>
</li>
<li><h3 id="苏宁"><a href="#苏宁" class="headerlink" title="苏宁"></a>苏宁</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/kBblUtVUvWDFDy9cqrUH5Q" target="_blank" rel="noopener">苏宁六年企业IT架构的演进之路</a></li>
</ul>
</li>
<li><h3 id="京东到家"><a href="#京东到家" class="headerlink" title="京东到家"></a>京东到家</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/aIzdMG1y0a5cWOS4lx6IuQ" target="_blank" rel="noopener">库存系统难破题？京东到家来分享</a></li>
<li><a href="https://mp.weixin.qq.com/s/-9fvfJ6KT3xSRQZnlTBBhA" target="_blank" rel="noopener">京东到家库存系统架构设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/TrCJJtvhjB2m29fOOa3Rzg" target="_blank" rel="noopener">京东到家订单中心 Elasticsearch 演进历程</a></li>
</ul>
</li>
<li><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/kauO45XNQaV40hxmSc3BpA" target="_blank" rel="noopener">订单系统分库分表实践</a></li>
<li><a href="http://mp.weixin.qq.com/s/01rmXXkEz-cQaLBe7eGeQA" target="_blank" rel="noopener">盘点电商大战背后的技术力量支撑</a></li>
<li><a href="http://mp.weixin.qq.com/s/gbVMGGneiSD7mhXtTH6QOg" target="_blank" rel="noopener">乐视电商云的整体架构与技术实现</a></li>
<li><a href="http://mp.weixin.qq.com/s/DMee9gp70ReIR8jRRhLYCA" target="_blank" rel="noopener">海淘平台架构实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/cV-iDCkrTx86TKbHA3U2Sw" target="_blank" rel="noopener">电商系统之订单系统</a></li>
<li><a href="https://mp.weixin.qq.com/s/CJmOaxTv0Ksll3CvCIXcnA" target="_blank" rel="noopener">交易系统 - 领域驱动设计浅析</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="支付"><a href="#支付" class="headerlink" title="支付"></a>支付</h1><ul>
<li><h3 id="支付宝"><a href="#支付宝" class="headerlink" title="支付宝"></a>支付宝</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/wVjmK4Qh8LJIJ23toXdB6g" target="_blank" rel="noopener">支付宝钱包系统架构内部剖析</a></li>
<li><a href="http://mp.weixin.qq.com/s/D3MAYfr4BpX8dONUfJ7LhQ" target="_blank" rel="noopener">余额宝技术架构及演进</a></li>
<li><a href="http://mp.weixin.qq.com/s/RFkYydSU_IuAIbNqcMIoRw" target="_blank" rel="noopener">蚂蚁金服CTO程立：金融级分布式交易的技术路径</a></li>
<li><a href="http://mp.weixin.qq.com/s/UgOmJ2R82D9xTcISAFbxtg" target="_blank" rel="noopener">蚂蚁金服11.11：支付宝和蚂蚁花呗的技术架构及实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/O1akcIZ9ZMngQr-UzJ22Fg" target="_blank" rel="noopener">完整的支付系统整体架构！</a></li>
</ul>
</li>
<li><h3 id="去哪"><a href="#去哪" class="headerlink" title="去哪"></a>去哪</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/9V1VC2Fe9HdGzdvQ2A7wiA" target="_blank" rel="noopener">去哪儿网支付系统架构演进全历程</a></li>
<li><a href="https://mp.weixin.qq.com/s/JT_hkmY8HcIF8UUvPa228A" target="_blank" rel="noopener">基于文档模型的交易系统</a></li>
</ul>
</li>
<li><h3 id="微博"><a href="#微博" class="headerlink" title="微博"></a>微博</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/a1iM8m0smLF9mqK4jqRf2Q" target="_blank" rel="noopener">微博付费打赏架构：一个社交场景下准金融项目开发和实践</a></li>
</ul>
</li>
<li><h3 id="其它-1"><a href="#其它-1" class="headerlink" title="其它"></a>其它</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/LjxMFyG4K4301bNoH74ZWA" target="_blank" rel="noopener">支付系统整体架构</a></li>
<li><a href="http://mp.weixin.qq.com/s/jDC__stAnICyPTgezfj8Og" target="_blank" rel="noopener">可用性高达五个9！支付系统高可用架构设计实战</a></li>
<li><a href="https://mp.weixin.qq.com/s/823bGuLkU0uX-vHUYkr5jg" target="_blank" rel="noopener">点融支付系统架构的演进</a></li>
<li><a href="https://mp.weixin.qq.com/s/Lsw_Ygyp50IJnqjzHxpGWg" target="_blank" rel="noopener">易宝支付日志中心平台建设</a></li>
<li><a href="https://mp.weixin.qq.com/s/syKnlmu_noyp0C4LeGp9Tw" target="_blank" rel="noopener">高并发支付场景分析及设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/rfeFWOq--0FXRa6r1eritQ" target="_blank" rel="noopener">中小型研发团队架构实践之企业支付网关</a></li>
<li><a href="https://mp.weixin.qq.com/s/c-jlnScSTLSGNFLlNBWeow" target="_blank" rel="noopener">支付平台架构设计评审核心要点与最佳实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/G_unHPP6P3q0guZR8x0UMg" target="_blank" rel="noopener">解密支付平台建设资金底线防火墙的杀手级设计方案</a></li>
</ul>
</li>
<li><h3 id="结算"><a href="#结算" class="headerlink" title="结算"></a>结算</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/FHTB8eKwIWnMxNraXghqvA" target="_blank" rel="noopener">联营结算平台建设之路</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="物流、外卖"><a href="#物流、外卖" class="headerlink" title="物流、外卖"></a>物流、外卖</h1><ul>
<li><h3 id="菜鸟"><a href="#菜鸟" class="headerlink" title="菜鸟"></a>菜鸟</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/igH0UwkvP9WiVTkFX-IrLA" target="_blank" rel="noopener">谈笔1000亿的生意：揭秘菜鸟全球智能仓配技术实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/1NhflDbO6CKYNSQcdM9ekg" target="_blank" rel="noopener">菜鸟下一代分布式体系架构的设计理念</a></li>
</ul>
</li>
<li><h3 id="京东"><a href="#京东" class="headerlink" title="京东"></a>京东</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/2HVkQCaXQQEQIqTrJZ01wA" target="_blank" rel="noopener">京东物流系统架构演进中的最佳实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/G1l3lRZezV6_h-4CpdofvA" target="_blank" rel="noopener">大数据构建京东智慧物流</a></li>
</ul>
</li>
<li><h3 id="顺丰"><a href="#顺丰" class="headerlink" title="顺丰"></a>顺丰</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/vK2VRyLtcH1qYtO1VbllOw" target="_blank" rel="noopener">顺丰IT基础架构运维的焦虑与进化</a></li>
</ul>
</li>
<li><h3 id="达达配送"><a href="#达达配送" class="headerlink" title="达达配送"></a>达达配送</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/0lMiU_rZpoT3wqwVHyCpDw" target="_blank" rel="noopener">高性能服务端优化之路</a></li>
</ul>
</li>
<li><h3 id="外卖"><a href="#外卖" class="headerlink" title="外卖"></a>外卖</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/vdxhbPTlYFftAQkNhfFufA" target="_blank" rel="noopener">从下单到享用，外卖背后的分布式架构设计</a></li>
</ul>
</li>
<li><h3 id="其它-2"><a href="#其它-2" class="headerlink" title="其它"></a>其它</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/X-0qIcxnGhV_PTnXTR1IuA" target="_blank" rel="noopener">大数据在物流企业中的应用</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="秒杀、抽奖"><a href="#秒杀、抽奖" class="headerlink" title="秒杀、抽奖"></a>秒杀、抽奖</h1><ul>
<li><h3 id="微信"><a href="#微信" class="headerlink" title="微信"></a>微信</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/oQN31DA6VZiurNOX2yxI-w" target="_blank" rel="noopener">微信红包系统架构的设计和优化分享</a></li>
<li><a href="https://mp.weixin.qq.com/s/l9Gqlj_QjoPQJ2Z_yqsbcQ" target="_blank" rel="noopener">从技术角度谈一谈，我参与设计开发的手Q春节红包项目</a></li>
</ul>
</li>
<li><h3 id="一号店"><a href="#一号店" class="headerlink" title="一号店"></a>一号店</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/0vkLqt-zwXLAJTe6GBPlaw" target="_blank" rel="noopener">1号店的抽奖系统架构实践</a></li>
</ul>
</li>
<li><h3 id="京东-1"><a href="#京东-1" class="headerlink" title="京东"></a>京东</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/40GHwueY8T3ji3DZ8yoxhQ" target="_blank" rel="noopener">京东抢购服务高并发实践</a></li>
</ul>
</li>
<li><h3 id="其它-3"><a href="#其它-3" class="headerlink" title="其它"></a>其它</h3><ul>
<li><a href="案例-秒杀小结.md">秒杀小结</a></li>
<li><a href="http://mp.weixin.qq.com/s/1BnygFm6ukEZcpakyEi9-Q" target="_blank" rel="noopener">秒杀系统架构分析与实战</a></li>
<li><a href="http://mp.weixin.qq.com/s/58y6YE2tQnQCugNJu9xOGA" target="_blank" rel="noopener">秒杀系统的架构解决之道</a></li>
<li><a href="http://mp.weixin.qq.com/s/N9Eha8lsy0N7PeXQxOgqAA" target="_blank" rel="noopener">揭秘红包场景下的高性能本地存储架构设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/OAN9DXmdYaxCUbt6cOn9cw" target="_blank" rel="noopener">秒杀架构实践</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><ul>
<li><h3 id="阿里"><a href="#阿里" class="headerlink" title="阿里"></a>阿里</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/S3FfkHYTr3kICFngA_Htpg" target="_blank" rel="noopener">阿里新一代实时计算引擎 Blink，每秒支持数十亿次计算</a></li>
</ul>
</li>
<li><h3 id="腾讯"><a href="#腾讯" class="headerlink" title="腾讯"></a>腾讯</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/avPzDxtSIsqUqzOKurZBQw" target="_blank" rel="noopener">华为狼VS腾讯企鹅，解读两大巨头的大数据体系</a></li>
</ul>
</li>
<li><h3 id="微博-1"><a href="#微博-1" class="headerlink" title="微博"></a>微博</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/sNHi05PTh4goOUMh68wr6g" target="_blank" rel="noopener">微博广告架构解密</a></li>
<li><a href="http://mp.weixin.qq.com/s/UrrVxnK4UicXcCs1FPsr1A" target="_blank" rel="noopener">微博广告分层实验平台(Faraday)架构实践</a></li>
</ul>
</li>
<li><h3 id="京东-2"><a href="#京东-2" class="headerlink" title="京东"></a>京东</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/35c06LQHVsyG-dy4FgJZnA" target="_blank" rel="noopener">Spark技术在京东智能供应链预测的应用</a></li>
<li><a href="https://mp.weixin.qq.com/s/ygo7ErbFd12yn-wR8-6Yjw" target="_blank" rel="noopener">京东基于Spark的风控系统架构实践和技术细节</a></li>
</ul>
</li>
<li><h3 id="携程"><a href="#携程" class="headerlink" title="携程"></a>携程</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/eNOAU8DxvsnV-OdFns23mw" target="_blank" rel="noopener">携程大数据实时计算平台建设实践</a></li>
<li><a href="http://mp.weixin.qq.com/s/OJdlpP62YWGmVnBWsfpVZw" target="_blank" rel="noopener">携程实时用户行为系统实践</a></li>
</ul>
</li>
<li><h3 id="网易"><a href="#网易" class="headerlink" title="网易"></a>网易</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/swIuD0N9_stqi2EWKKXzDQ" target="_blank" rel="noopener">奇硕基于网易云的微服务与大数据实战</a></li>
</ul>
</li>
<li><h3 id="小米"><a href="#小米" class="headerlink" title="小米"></a>小米</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/VjRWHEKqursOg6ekzBMsBw" target="_blank" rel="noopener">小米品牌广告引擎与算法实践</a></li>
</ul>
</li>
<li><h3 id="有赞-1"><a href="#有赞-1" class="headerlink" title="有赞"></a>有赞</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/M9yxvoDAbzCzjRMritB1Sw" target="_blank" rel="noopener">有赞大数据实践: 敏捷型数据仓库的构建及其应用</a></li>
</ul>
</li>
<li><h3 id="蘑菇街-1"><a href="#蘑菇街-1" class="headerlink" title="蘑菇街"></a>蘑菇街</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/O-pWwLJGMyYK1IN-yd7Kuw" target="_blank" rel="noopener">蘑菇街搜索与推荐架构，从 0 到 1 再到 100</a></li>
</ul>
</li>
<li><h3 id="唯品会"><a href="#唯品会" class="headerlink" title="唯品会"></a>唯品会</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/efFi45ng7_CPRSmDrAx7Ww" target="_blank" rel="noopener">实时离线融合在唯品会的进展：在实时技术、数据、业务中寻找平衡</a></li>
<li><a href="https://mp.weixin.qq.com/s/BFMTvQXXFjwgDKjeu7CUtw" target="_blank" rel="noopener">Spark在唯品会财务系统重构中的实践总结</a></li>
</ul>
</li>
<li><h3 id="58同城"><a href="#58同城" class="headerlink" title="58同城"></a>58同城</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/BWDbcNUaFf6LpGwQdK4emQ" target="_blank" rel="noopener">58大数据平台的技术演进与实践</a></li>
</ul>
</li>
<li><h3 id="其它-4"><a href="#其它-4" class="headerlink" title="其它"></a>其它</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/Tmi13LzpkIYNoek1iFDyew" target="_blank" rel="noopener">挖财基于大数据的信贷审批系统实践</a></li>
<li><a href="http://mp.weixin.qq.com/s/F84Q25OgJ2qv-N7u9zfxvw" target="_blank" rel="noopener">数据开发常用的几种数据预处理和数据整理方法</a></li>
<li><a href="http://mp.weixin.qq.com/s/F7Srnf0aEIW-OetVNh_q9A" target="_blank" rel="noopener">以客户流失预测为例，谈谈机器学习在市场营销中的应用</a></li>
<li><a href="https://mp.weixin.qq.com/s/A_eyUjm4fbr2kMEym6bJbw" target="_blank" rel="noopener">日处理20亿数据，实时用户行为服务系统架构实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/9-NUxtVsQeIeJwaR8Oh3kg" target="_blank" rel="noopener">漫谈千亿级数据优化实践：一次数据优化实录</a></li>
<li><a href="https://mp.weixin.qq.com/s/yrbVO1nrHfSv8xtLjlyjSw" target="_blank" rel="noopener">时序数据库如何支持秒级上亿数据的查询分组和聚合运算</a></li>
<li><a href="https://mp.weixin.qq.com/s/LF8kem9bTVlMpGbpmhWtUA" target="_blank" rel="noopener">从分布式管理到多租户实现，企业级大数据系统如何利用开源生态构建？</a></li>
<li><a href="https://mp.weixin.qq.com/s/UiOIP7eOEQ-o9F8ej3Lb9g" target="_blank" rel="noopener">spark sql 在饿了么的应用实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/mZkivs8_BHEbHny3SG0vFA" target="_blank" rel="noopener">蚂蜂窝大数据多维分析 DRUID 引擎实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/unbRSelVZBBAoz2d8SdZYQ" target="_blank" rel="noopener">Flume+Kafka+Storm+Redis构建大数据实时处理系统</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="社区、社交互动"><a href="#社区、社交互动" class="headerlink" title="社区、社交互动"></a>社区、社交互动</h1><ul>
<li><h3 id="微博-2"><a href="#微博-2" class="headerlink" title="微博"></a>微博</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/wi3XqgEn7iCKhVhXAwlyJg" target="_blank" rel="noopener">微博推荐架构的演进</a></li>
<li><a href="http://mp.weixin.qq.com/s/JI3xmM0eYjfJpObOcUSnPA" target="_blank" rel="noopener">新浪微博技术架构分析</a></li>
<li><a href="案例-微博与理财社区cache分析.md">新浪微博与理财社区cache对比分析</a></li>
</ul>
</li>
<li><h3 id="QQ"><a href="#QQ" class="headerlink" title="QQ"></a>QQ</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/4tStRbQalbCPUwkrUxkG3A" target="_blank" rel="noopener">QQ空间平台百亿级流量的社交广告系统实践</a></li>
</ul>
</li>
<li><h3 id="今日头条"><a href="#今日头条" class="headerlink" title="今日头条"></a>今日头条</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/_dfVM8Ix0sqHeyn1xnqjfw" target="_blank" rel="noopener">今日头条的核心架构解析</a></li>
<li><a href="https://mp.weixin.qq.com/s/t_uRBG53o3ve8tFZNGz0NA" target="_blank" rel="noopener">今日头条推荐系统架构演进之路</a></li>
</ul>
</li>
<li><h3 id="淘宝-1"><a href="#淘宝-1" class="headerlink" title="淘宝"></a>淘宝</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/r_4SahpX9nAKf9OsPFQMQg" target="_blank" rel="noopener">闲鱼社区技术架构演进</a></li>
</ul>
</li>
<li><h3 id="BBS社区"><a href="#BBS社区" class="headerlink" title="BBS社区"></a>BBS社区</h3><ul>
<li><a href="案例-公众号增量消息同步改造.md">公众号增量消息同步改造</a></li>
<li><a href="社区稳定性之降级.md">社区稳定性之降级</a></li>
<li><a href="案例-计数器.md">社区计数器</a></li>
<li><a href="案例-贴子楼层号.md">回复的楼层号如何控制并发？</a></li>
</ul>
</li>
<li><h3 id="timeline"><a href="#timeline" class="headerlink" title="timeline"></a>timeline</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/MFFJtRixz9Cr3WFh33h__Q" target="_blank" rel="noopener">几个大型网站的Feeds(Timeline)设计简单对比</a></li>
<li><a href="">《深入分布式缓存—第12章，社交场景架构进化：从数据库到缓存》</a></li>
<li><a href="">《深入分布式缓存—第13章，缓存在社交网络Feed系统中的架构实践》</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="互联网金融"><a href="#互联网金融" class="headerlink" title="互联网金融"></a>互联网金融</h1><ul>
<li><h3 id="区块链"><a href="#区块链" class="headerlink" title="区块链"></a>区块链</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/9aFoptoI88n7hgZtxOe4Aw" target="_blank" rel="noopener">区块链技术与微服务架构之间有什么关系</a></li>
<li><a href="https://mp.weixin.qq.com/s/BRrrhe1xFpDTp2DG6Khpkg" target="_blank" rel="noopener">《区块链》都火了两年多了，你还不知道它是什么？</a></li>
<li><a href="http://mp.weixin.qq.com/s/cqi6mNVh2ZFZdNFIAQynjw" target="_blank" rel="noopener">200 行代码实现一个简单的区块链</a></li>
<li><a href="https://mp.weixin.qq.com/s/-2jXpGcZEF37ex0jiIe3DA" target="_blank" rel="noopener">通俗讲解比特币的原理及运作机制</a></li>
<li><a href="https://mp.weixin.qq.com/s/9kgxbjntTJiWDsmc856V-A" target="_blank" rel="noopener">什么是区块链？</a></li>
</ul>
</li>
<li><h3 id="宜人贷"><a href="#宜人贷" class="headerlink" title="宜人贷"></a>宜人贷</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/GZsFhq7-3ZhRiyNodbv0lg" target="_blank" rel="noopener">从宜人贷系统架构看互联网高并发对金融系统架构的挑战</a></li>
</ul>
</li>
<li><a href="http://mp.weixin.qq.com/s/aMQ6gpbkMn57WNKDL0OlOQ" target="_blank" rel="noopener">如何构建用于检测信用卡诈骗的机器学习模型？</a></li>
<li><a href="http://mp.weixin.qq.com/s/4a8hGw-E73FVoGsAW0UWHQ" target="_blank" rel="noopener">智能问答在金融领域中的实践与应用</a></li>
<li><a href="http://mp.weixin.qq.com/s/3GZaaLHsMSDFTJ0n7hzw1A" target="_blank" rel="noopener">微博众筹的架构设计</a></li>
<li><a href="http://mp.weixin.qq.com/s/Qir5SwHoLNdILruYdFmEsw" target="_blank" rel="noopener">互联网金融系统技术沙龙:小米风控实践</a></li>
<li><a href="http://mp.weixin.qq.com/s/ZX2lbry5fTq65LEo17YdBg" target="_blank" rel="noopener">雪球在股市风暴下的高可用架构改造分享</a></li>
</ul>
<hr>
<h1 id="开放平台-网关"><a href="#开放平台-网关" class="headerlink" title="开放平台/网关"></a>开放平台/网关</h1><ul>
<li><h3 id="淘宝-2"><a href="#淘宝-2" class="headerlink" title="淘宝"></a>淘宝</h3><ul>
<li><a href="http://www.infoq.com/cn/articles/taobao-open-platform-overcome-technical-difficulties" target="_blank" rel="noopener">历经8年双11流量洗礼，淘宝开放平台如何攻克技术难关？</a></li>
<li><a href="http://www.infoq.com/cn/articles/open-api-practice" target="_blank" rel="noopener">Open API分析、实践和思索</a></li>
<li><a href="http://www.infoq.com/cn/articles/open-platform-review-prospect" target="_blank" rel="noopener">开放平台回顾与前景展望</a></li>
</ul>
</li>
<li><h3 id="京东-3"><a href="#京东-3" class="headerlink" title="京东"></a>京东</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/vZqzVfWq4zX_bWrZZJdlLw" target="_blank" rel="noopener">京东京麦开放平台的高可用架构之路</a></li>
<li><a href="https://mp.weixin.qq.com/s/jX1Xr9GlqOm2uaGmyJX2RQ" target="_blank" rel="noopener">京东双十一大促网关承载十亿调用量背后的架构实践</a></li>
</ul>
</li>
<li><h3 id="其它-5"><a href="#其它-5" class="headerlink" title="其它"></a>其它</h3><ul>
<li><a href="http://www.infoq.com/cn/news/2011/11/znx-tencent-open-platform" target="_blank" rel="noopener">专家观点：QCon专访朱念洋，谈腾讯开放平台关键技术</a></li>
<li><a href="http://www.infoq.com/cn/news/2017/03/Startups-API-practice" target="_blank" rel="noopener">一个创业公司的API网关落地实践</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="直播-Live、客服"><a href="#直播-Live、客服" class="headerlink" title="直播 Live、客服"></a>直播 Live、客服</h1><ul>
<li><h3 id="IM"><a href="#IM" class="headerlink" title="IM"></a>IM</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/sYRchf1-8ZpD7Q3UYx_KLQ" target="_blank" rel="noopener">现代IM系统中消息推送和存储架构的实现（Timeline）</a></li>
</ul>
</li>
<li><h3 id="答题"><a href="#答题" class="headerlink" title="答题"></a>答题</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/Tp7K4g3DxmEiU0iYrmR8Mw" target="_blank" rel="noopener">直播答题系统在技术上难实现吗？挑战有多大？</a></li>
</ul>
</li>
<li><h3 id="智能客服"><a href="#智能客服" class="headerlink" title="智能客服"></a>智能客服</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/tiGxIeY9sDRdbMvKxcOS7w" target="_blank" rel="noopener">阿里千亿级购物节背后，淘宝智能客服架构演进之路</a></li>
</ul>
</li>
<li><h3 id="其它-6"><a href="#其它-6" class="headerlink" title="其它"></a>其它</h3><ul>
<li><a href="http://mp.weixin.qq.com/s/WcHvukClRSLA4KczRjDVaw" target="_blank" rel="noopener">淘宝直播在双11的互动实践</a></li>
<li><a href="http://mp.weixin.qq.com/s/Ej4QHRvF7e0i5d78hETrwg" target="_blank" rel="noopener">常见的几种直播连麦方案</a></li>
<li><a href="http://mp.weixin.qq.com/s/U4SKJbXSkd6JOx0R7yK-5g" target="_blank" rel="noopener">如何开发10万在线级别的直播弹幕技术？</a></li>
<li><a href="http://mp.weixin.qq.com/s/OXzYMM14ag2k9sh9WidV2w" target="_blank" rel="noopener">视频私有云实战：基于 Docker 构建点播私有云平台</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="共享单车"><a href="#共享单车" class="headerlink" title="共享单车"></a>共享单车</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/IIJcFdku41Z6NYQSV-dk5A" target="_blank" rel="noopener">摩拜单车类的共享行业应如何在不可靠远程网络下进行分布式MQTT设计</a></li>
</ul>
<hr>
<h1 id="移动端相关"><a href="#移动端相关" class="headerlink" title="移动端相关"></a>移动端相关</h1><ul>
<li><a href="http://mp.weixin.qq.com/s/mMMsuCMX27T1-ynVeJntUw" target="_blank" rel="noopener">蘑菇街移动端混合开发体系的研发与实践</a></li>
<li><a href="http://mp.weixin.qq.com/s/h9UNSqnKjzFnXY2gMNAQ-g" target="_blank" rel="noopener">人人车Android客户端架构演进实录</a></li>
</ul>
<hr>
<h1 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h1><ul>
<li><a href="http://mp.weixin.qq.com/s/HErVN8x-s6MzgW-3XMvvAA" target="_blank" rel="noopener">去哪儿网机票搜索系统的高并发架构设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/uIlNuutCRVPrZeJ_u1AtnA" target="_blank" rel="noopener">聊聊基于Lucene的搜索引擎核心技术实践</a></li>
</ul>
<hr>
<h1 id="系统稳定性"><a href="#系统稳定性" class="headerlink" title="系统稳定性"></a>系统稳定性</h1><ul>
<li><h3 id="阿里-1"><a href="#阿里-1" class="headerlink" title="阿里"></a>阿里</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/9qaxFINcTsmy01OP1D3UOQ" target="_blank" rel="noopener">史上最复杂业务场景，逼出阿里高可用三大法宝</a></li>
<li><a href="https://mp.weixin.qq.com/s/xyJ4GB955PoOXk7UOMqGBw" target="_blank" rel="noopener">鹰眼技术解密</a></li>
<li><a href="http://mp.weixin.qq.com/s/tP9it4Cbv_SUr-qFHkzHPw" target="_blank" rel="noopener">阿里如何应对电商故障？神秘演练细节曝光</a></li>
<li><a href="https://mp.weixin.qq.com/s/q5qiYGhCGUxKJYjm1kXuTA" target="_blank" rel="noopener">阿里SRE体系如何支撑24小时峰值压力、220+个国家“剁手党”？</a></li>
<li><a href="https://mp.weixin.qq.com/s/GVrmSsEa1VogcPOzbXF_QA" target="_blank" rel="noopener">阿里巴巴AliExpress数百微服务的治理之策</a></li>
</ul>
</li>
<li><h3 id="滴滴"><a href="#滴滴" class="headerlink" title="滴滴"></a>滴滴</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/wy-BC_RShqO5KbarHDzCQQ" target="_blank" rel="noopener">滴滴业务实时监控系统架构及实践</a></li>
</ul>
</li>
<li><h3 id="微博-3"><a href="#微博-3" class="headerlink" title="微博"></a>微博</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/6tSbQFgSff07VIZRHpfTQg" target="_blank" rel="noopener">新浪微博混合云架构如何轻松应对热点事件的高峰值流量</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="风控"><a href="#风控" class="headerlink" title="风控"></a>风控</h1><ul>
<li><h3 id="金融"><a href="#金融" class="headerlink" title="金融"></a>金融</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/X634-KXzwBLkrmrT_OTxbQ" target="_blank" rel="noopener">互联网小贷：一个从繁盛到衰退，又在管制中蜕变成长的类金融机构</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="日志系统"><a href="#日志系统" class="headerlink" title="日志系统"></a>日志系统</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/AZ_ucwyF1v7KelhfxQRLkQ" target="_blank" rel="noopener">百亿级日志系统架构设计及优化</a></li>
</ul>
<hr>
<h1 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/E0xEqPSbi5IEYV-IFfn5vw" target="_blank" rel="noopener">搭建一个基于Java的分布式爬虫系统</a></li>
<li><a href="https://mp.weixin.qq.com/s/-3AmP_yMFY75Bdnke4Vmzw" target="_blank" rel="noopener">一次架构设计心得体会</a></li>
<li>github<ul>
<li><a href="https://github.com/java-webbee/web-bee" target="_blank" rel="noopener">web垂直爬虫框架</a></li>
<li><a href="https://github.com/pkwenda/blog/issues/8" target="_blank" rel="noopener">如何写一个垂直爬虫并抓取知乎用户20万数据</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h1><ul>
<li><h3 id="会员、注册、登录"><a href="#会员、注册、登录" class="headerlink" title="会员、注册、登录"></a>会员、注册、登录</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/ZT1B6ziSSRW41FN33xA3ZA" target="_blank" rel="noopener">单点登录怎么实现？</a></li>
<li><a href="https://mp.weixin.qq.com/s/DkwfpZibKdllfm0lpxukWg" target="_blank" rel="noopener">深入了解Token认证的来龙去脉</a></li>
<li><a href="https://mp.weixin.qq.com/s/89YtsPX4cPLluWbM8JSNXQ" target="_blank" rel="noopener">单点登录原理与简单实现</a></li>
</ul>
</li>
<li><h3 id="短信"><a href="#短信" class="headerlink" title="短信"></a>短信</h3><ul>
<li><a href="https://blog.csdn.net/u011277123/article/details/77519910" target="_blank" rel="noopener">如何设计短信验证码防刷机制</a></li>
<li><a href="http://www.woshipm.com/pd/580976.html" target="_blank" rel="noopener">5种常见的短信验证码防刷策略</a></li>
</ul>
</li>
<li><h3 id="消息推送、push"><a href="#消息推送、push" class="headerlink" title="消息推送、push"></a>消息推送、push</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/tLFOFEWBUfjjO_YInDxpJw" target="_blank" rel="noopener">如何用Redis平衡海量信息推送的实效与体量</a></li>
</ul>
</li>
<li><h3 id="智能流量调度"><a href="#智能流量调度" class="headerlink" title="智能流量调度"></a>智能流量调度</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/tNMDImzKPJmkMBrssSl5yw" target="_blank" rel="noopener">京东到家订单派发的技术实战</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="技术点"><a href="#技术点" class="headerlink" title="技术点"></a>技术点</h1><ul>
<li><h3 id="异步非阻塞"><a href="#异步非阻塞" class="headerlink" title="异步非阻塞"></a>异步非阻塞</h3><ul>
<li><a href="https://www.jdon.com/idea/javaee7/servlet21.html" target="_blank" rel="noopener">Servlet的异步和非堵塞</a></li>
</ul>
</li>
<li><h3 id="分布式任务"><a href="#分布式任务" class="headerlink" title="分布式任务"></a>分布式任务</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/DfGligz50B_x6Y_S-DyU9w?from=groupmessage&isappinstalled=0" target="_blank" rel="noopener">点我达分布式任务调度系统-DaJob</a></li>
</ul>
</li>
</ul>
<hr>
<h1 id="其它-7"><a href="#其它-7" class="headerlink" title="其它"></a>其它</h1><ul>
<li><a href="http://mp.weixin.qq.com/s/4TmpzJEdiSzi5fLTLXAq2w" target="_blank" rel="noopener">网易美学平滑微服务化</a></li>
<li><a href="http://mp.weixin.qq.com/s/muoJas1nayP6gY8KBwVLSw" target="_blank" rel="noopener">微服务架构如何实现网站服务垂直化拆分</a></li>
<li><a href="http://mp.weixin.qq.com/s/_3BAn1-paC74qho3gFgnhw" target="_blank" rel="noopener">如何用消息系统避免分布式事务？</a></li>
<li><a href="https://mp.weixin.qq.com/s/5KQMrsK3hORFG4aHupdR1g" target="_blank" rel="noopener">Linux 主流架构运维工作简单剖析</a></li>
<li><a href="https://mp.weixin.qq.com/s/EYA65HML_QgsXnU-EYE6tQ" target="_blank" rel="noopener">Python 爬取百度网盘所有热门分享文件</a></li>
<li><a href="https://mp.weixin.qq.com/s/UPSIOaZAQmq0PDrJj-0t1A" target="_blank" rel="noopener">28款GitHub最流行的开源机器学习项目</a></li>
<li><a href="https://mp.weixin.qq.com/s/RAR1Gs0bf78vfaSau-8kLw" target="_blank" rel="noopener">58同城实施微服务架构的关键技术</a></li>
<li><a href="https://mp.weixin.qq.com/s/jy-tpDbbhC9EuUGN3mzWqg" target="_blank" rel="noopener">Java高效开发12个精品库</a></li>
<li><a href="https://mp.weixin.qq.com/s/1jvK89iRtX_aofCww34G1w" target="_blank" rel="noopener">Google最热门60款开源项目</a></li>
<li><a href="https://mp.weixin.qq.com/s/iEULJ6aGXezPjZTAq1-qCg" target="_blank" rel="noopener">今日头条Go语言构建日请求千亿级微服务的最佳实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/FuIlEl4VIsMfLvDGhgMDVQ" target="_blank" rel="noopener">亿级流量系统架构之如何设计承载百亿流量的高性能架构</a></li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>SOA与微服务</title>
    <url>/sa/SOA%E4%B8%8E%E5%BE%AE%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<h2 id="SOA与微服务"><a href="#SOA与微服务" class="headerlink" title="SOA与微服务"></a>SOA与微服务</h2><ul>
<li>微服务并非它的体积足够小，而是它的责任足够单一，很多人误解了「微」的真实含义，认为服务拆分得足够小就是微服务了，其实并非这样。此外，「微」还有“微不足道”的意思，也就是说，某个服务出现故障，它不会影响整个系统。</li>
</ul>
<a id="more"></a>
<ul>
<li><p>微服务并非细粒度服务的组合，也就是说，粒度要细到什么程度，这取决于对业务功能的把控能力。此外，微服务是一种架构思想，包括看得见的微服务，还包括看不见的基础设施和自动化技术作为支撑。</p>
</li>
<li><p>目前市面上常用的微服务架构dubbo+zk，spring cloud</p>
</li>
<li><p>微服务的核心：注册中心（Service Registry）、服务提供方（service provider）、服务消费方（service consumer）。不过现在为了方便，又提出了网关的（service gateway）的概念，配动自动完成服务的注册和发现。</p>
</li>
<li><p>从什么角度能区分出或者划分微服务和 RPC 分布式之间的区别或者关系？</p>
</li>
</ul>
<p>微服务是一种应用架构模式，而 RPC 是一种远程调用方式，它们是不一样的概念；而在微服务中会出现服务之间的调用，为了确保性能，我们一般采用 RPC 来调用。</p>
<ul>
<li>微服务实现系统的模块化，便于公共模块复用和水平扩展，但目前的系统规模其实都很小，这种情况是不是不适合使用微服务？</li>
</ul>
<p>我认为微服务架构用于业务较复杂或目前业务简单但将来有可能变得复杂的架构，建议视具体情况来确定合理的架构，不要为了微服务而去微服务。</p>
<ul>
<li>微服务与 SOA 到底有什么区别，各自的应用场景是什么？到底在什么样的情况才适合使用微服务架构？</li>
</ul>
<p>微服务是SOA的一种轻量级的解决方案，其本质还是SOA，只是更容易落地而以。</p>
<div class="note primary">
            <p>对于满足以下条件可以考虑使用微服务：</p><ol><li>应用变得越来越大</li><li>项目存在多种开发语言</li><li>经典架构模式太重</li><li>修改一个bug需要平滑升级</li><li>需要对系统细粒度监控</li><li>提升系统可用性，如果一个系统挂了，不会对整个业务产生致命影响</li></ol>
          </div>

<ul>
<li>服务与服务之间的事务怎么做？</li>
</ul>
<p>在微服务架构中，建议尽量避免服务之间的调用，因此服务粒度的切分是至关重要的；服务间的调用会产生分布式事务问题，建议采用“最终一致性”方法来确保分布式事务，业界有两种常用做法：CQRS 和 Event Sourcing。</p>
<ul>
<li>如何使用事务补偿模式解决分布式事务问题？</li>
</ul>
<p>事务补偿机制说简单点就是，在应用程序中通过代码的方式做到数据的还原。一般情况下，我们需借助消息队列与日志追踪等方式来实现。</p>
<ul>
<li>微服务在事务控制方面、容错方面有什么较好的实践方式？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、微服务的事务控制本质上是分布式事务控制，建议使用“最终一致性”来确保。</span><br><span class="line">2、在容错方面，需要有基础设施平台的支撑，比如服务网关的熔断机制</span><br></pre></td></tr></table></figure>
<ul>
<li>微服务拆分有没有什么原则要点？</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 微服务业务拆分可按整体业务组件来拆分，也可按单一业务功能来切分。建议切分步骤从粗到细，逐步细化，否则开始就过细，导致依赖性太高，增加复杂度。</span><br><span class="line">2. 拆分服务时需降低彼此之间的耦合性，尽可能一个服务只做一件事情，即“单一职责原则”。</span><br></pre></td></tr></table></figure>

<ul>
<li>怎样来控制微服务的粒度？就是有没有什么样的原则和最佳实践来判断一个功能（接口）是应该属于 A 服务还是应该属于 B 服务。</li>
</ul>
<p>微服务的粒度控制取决于我们对业务的理解与把控能力，一切所谓的原则都是不靠谱的。</p>
<p>微服务需要考虑服务多版本问题，尤其是服务升级时，需要做到平滑，对整体系统没有任何影响。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>Cache经验总结</title>
    <url>/sa/cache-summary/</url>
    <content><![CDATA[<h1 id="为什么要使用cache"><a href="#为什么要使用cache" class="headerlink" title="为什么要使用cache"></a>为什么要使用cache</h1><p>关系型数据库的数据量比较小，以mysql为例，单表的量尽量控制在千万级别。</p>
<a id="more"></a>
<p>关系型数据库在TPS上的瓶颈往往会比其他瓶颈更容易暴露出来，尤其对于大型web系统，由于每天大量的并发访问，对数据库的读写性能要求非常高;而传统的关系型数据库的处理能力确实捉襟见肘;以我们常用的MySQL数据库为例，常规情况下的TPS大概只有1500左右(各种极端场景下另当别论)。</p>
<p>下面是MySQL官方所给出的一份测试数据：</p>
<p>系统配置：</p>
<p>Sun V40z / 4x 2390MHZ / Solaris 10 / 8GB RAM</p>
<p>1m rows，Read Only，4 CPU</p>
<table>
<thead>
<tr>
<th>Connections</th>
<th>Trans/sec</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>382</td>
</tr>
<tr>
<td>2</td>
<td>677</td>
</tr>
<tr>
<td>4</td>
<td>1130</td>
</tr>
<tr>
<td>8</td>
<td>1479</td>
</tr>
<tr>
<td>32</td>
<td>1418</td>
</tr>
<tr>
<td>256</td>
<td>947</td>
</tr>
<tr>
<td>1024</td>
<td>224</td>
</tr>
</tbody></table>
<p><a href="img/UC2005-Advanced-Innodb-Optimization.pdf">详细压测报告：</a></p>
<p><a href="https://www.percona.com/blog/files/presentations/UC2005-Advanced-Innodb-Optimization.pdf" target="_blank" rel="noopener">https://www.percona.com/blog/files/presentations/UC2005-Advanced-Innodb-Optimization.pdf</a></p>
<p>对于一个PV上亿的网站，每一次请求涉及多次数据库交互，每天的读写请求量远远超过关系型数据库的处理能力，所以必须通过高效的缓存抵挡大部分的数据请求。</p>
<h1 id="缓存类型"><a href="#缓存类型" class="headerlink" title="缓存类型"></a>缓存类型</h1><ul>
<li><p>本地缓存</p>
<p> 本地缓存会减少网络层的交互，无论是本地内存还是磁盘，速度比较快。但对分布式系统来讲有一个缺点，当数据库更新时，没有一个简单有效的方法去更新本地缓存。</p>
<p> <strong>本地缓存适用两种场景：</strong></p>
<ul>
<li><p>一、对缓存内容时效性要求不高，能接受一定的延迟，可以设置较短过期时间，被动失效更新保持数据的新鲜度。</p>
</li>
<li><p>二、缓存的内容不会改变。比如订单号与uid的映射关系，一旦创建就不会发生改变。</p>
</li>
<li><p><em>注意问题：*</em></p>
</li>
<li><p>内存Cache数据条目上限控制，避免内存占用过多导致应用瘫痪。</p>
</li>
<li><p>内存中的数据移出策略</p>
</li>
<li><p>虽然实现简单，但潜在的坑比较多，最好选择一些成熟的开源框架</p>
</li>
</ul>
</li>
<li><p>分布式缓存</p>
<p> 本地缓存的使用很容易让你的应用服务器带上“状态”，而且容易受内存大小的限制。</p>
<p> 分布式缓存借助分布式的概念，集群化部署，独立运维，容量无上限，虽然会有网络传输的损耗，但这1~2ms的延迟相比其更多优势完成可以忽略。    </p>
<p> 优秀的分布式缓存系统有大家所熟知的Memcached、Redis。对比关系型数据库和缓存存储，其在读和写性能上的差距可谓天壤之别，redis单节点已经可以做到8W+ QPS。设计方案时尽量把读写压力从数据库转移到缓存上，有效保护脆弱的关系型数据库。</p>
</li>
</ul>
<ul>
<li><p>客户端缓存</p>
<p> 大部分的web应用、微服务应用都会尽量做到无状态，方便于线性扩容。有状态的后端存储：DB、NoSQL、分布式文件系统、CDN等。</p>
<p> 另一个很重要的就是客户端缓存了，对客户端存储的合理使用，原本每天几千万甚至上亿的接口调用，一下就可能降到了几百万甚至更少，而且即便是用户更换浏览器，或者缓存丢失需要重新访问服务器，由于随机性比较强，请求分散，给服务器的压力也很小。另外再加上合理的缓存过期时间，就可以在数据准确和性能上做一个很好的折衷。</p>
</li>
</ul>
<h1 id="常用技术框架"><a href="#常用技术框架" class="headerlink" title="常用技术框架"></a>常用技术框架</h1><ul>
<li>Guave</li>
<li>Memcached</li>
<li>Redis</li>
</ul>
<p>更多缓存框架：<a href="http://www.oschina.net/project/tag/109/cacheserver" target="_blank" rel="noopener">http://www.oschina.net/project/tag/109/cacheserver</a></p>
<h1 id="更新策略"><a href="#更新策略" class="headerlink" title="更新策略"></a>更新策略</h1><ul>
<li><p>被动失效</p>
<p>  缓存数据主要是服务读请求的，通常会设置一个过期时间，或者当数据库状态改变时，通过一个简单的delete操作，使数据失效掉；当下次再去读取时，如果发现数据过期了或者不存在了，那么就重新去数据库读取，然后更新到缓存中，这即是所谓的被动失效策略。</p>
<p>  被动策略有一个很大的风险，从缓存失效到数据再次被预热到cache这段时间，所有的读请求会直接打到DB上，对于一个高访问量的系统，很容易被击垮。</p>
</li>
</ul>
<ul>
<li><p>主动更新</p>
<p>  主动更新，很容易理解，就是数据库存储发生变化时，会直接同步更新到Cache，主要是为了解决cache空窗期引发的问题。比如电商的卖家修改商品详情，具有读多写少特点。</p>
<p>  但如果是读多写多，同样会带来另一个问题，就是并发更新。多台应用服务器同时访问一份数据是很正常的，这样就会存在一台服务器读取并修改了缓存数据，但是还没来得及写入的情况下，另一台服务器也读取并修改旧的数据，这时候，后写入的将会覆盖前面的，从而导致数据丢失。解决的方式主要有三种：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、锁控制。这种方式一般在客户端实现(在服务端加锁是另外一种情况)，其基本原理就是使用读写锁，即任何线程要调用写方法时，先要获取一个排他锁，阻塞住所有的其他访问，等自己完全修改完后才能释放。如果遇到其他线程也在修改或读取数据，那么则需要等待。锁控制虽然是一种方案，但是很少有真的这样去做的，其缺点显而易见，其并发性只存在于读操作之间，只要有写操作存在，就只能串行。</span><br><span class="line"></span><br><span class="line">2、单版本机制（乐观锁）。为每份数据保存一个版本号，当缓存数据写入时，需要回传这个版本号，然后服务端将传入的版本号和数据当前的版本号进行比对，如果等于当前版本号，则成功写入，否则失败。这样解决方式比较简单;但是增加了高并发下客户端的写失败概率;</span><br><span class="line"></span><br><span class="line">3、多版本机制。即存储系统为每个数据保存多份，每份都有自己的版本号，互不冲突，然后通过一定的策略来定期合并，再或者就是交由客户端自己去选择读取哪个版本的数据。</span><br></pre></td></tr></table></figure>

<h1 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h1><p>分布式缓存的本质就是将所有的业务数据对象序列化为字节数组，然后保存到自己的内存中。所使用的序列化方案也自然会成为影响系统性能的关键点之一</p>
<ul>
<li>序列化速度</li>
<li>对象压缩比例</li>
<li>支持的序列化数据类型范围</li>
<li>反序列化的速度</li>
<li>框架接入易用性</li>
</ul>
<p>常见的序列化框架：</p>
<ul>
<li>Java源生序列化</li>
<li>Hessian</li>
<li>Protobuf</li>
<li>Kryo</li>
</ul>
<h1 id="开发注意事项"><a href="#开发注意事项" class="headerlink" title="开发注意事项"></a>开发注意事项</h1><ul>
<li>评估当前业务使用的空间大小。避免空间不足，导致热数据被置换出去，影响缓存命中率</li>
<li>不要把缓存当DB使用，因为它会丢失</li>
<li>最好设置过期时间，可以自己回收</li>
<li>key定义遵循一定规则，相同业务采用同一前缀</li>
<li>缓存对象粒度。高内聚低耦合，考虑尽可能复用，不要一个小字段修改导整个大对象全部失效</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">方案一：</span><br><span class="line">uid---&gt; 发过的贴子内容列表</span><br><span class="line"></span><br><span class="line">方案二：</span><br><span class="line">uid---&gt;发过的贴子tid列表</span><br><span class="line">tid---&gt;贴子内容</span><br></pre></td></tr></table></figure>

<ul>
<li>另外缓存对象大小要控制，不要过大，占用过多带宽。之前遇到过一个业务团队，单key下挂了5M的大对象，每次用时，从缓存中取出，反序列化，然后取其中一小部分。后来随着业务并发量上升，把网卡打爆，进而影响其它正常业务访问。</li>
<li>根据业务需求，选择合适的缓存框架，比如memcache只支持kv对存储，redis则支持较丰富的数据结构</li>
<li>是否要引入多级缓存，本地内存–》非持久化缓存（如memcache）—》持久化缓存—》DB，要注意数据一致性问题</li>
<li>提前考虑扩容问题</li>
</ul>
<h1 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h1><h1 id="1、缓存穿透"><a href="#1、缓存穿透" class="headerlink" title="1、缓存穿透"></a>1、缓存穿透</h1><p>我们在项目中使用缓存通常都是先检查缓存中是否存在，如果存在直接返回缓存内容，如果不存在就直接查询数据库然后再缓存查询结果返回。这个时候如果我们查询的某一个数据在缓存中一直不存在，就会造成每一次请求都查询DB，这样缓存就失去了意义，在流量大时，可能DB就挂掉了。那这种问题有什么好办法解决呢？</p>
<p>有一个比较巧妙的做法是，可以将这个不存在的key预先设定一个值。比如，”NULL” ，在返回这个NULL值的时候，我们的应用就可以认为这是不存在的key。</p>
<p>缓存穿透如果被恶意攻击，造成的影响面很容易放大。比如文章详情页，查询一个不存在的tid，每次都会访问DB，如果有人恶意破坏，很可能直接对DB造成影响。</p>
<h1 id="2、缓存集体失效"><a href="#2、缓存集体失效" class="headerlink" title="2、缓存集体失效"></a>2、缓存集体失效</h1><p>对于一些活动期间的数据通常会提前预热到缓存中，并设置一个过期时间，如果系统的并发量很高，恰巧缓存又失效了，此时会将压力转嫁给后面的DB，很容易击垮系统。</p>
<p>那如何解决这些问题呢？</p>
<p>其中的一个简单方案就是将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。还有一种方式，就是计算好缓存的过期时间。</p>
<h1 id="3、DB和缓存不一致"><a href="#3、DB和缓存不一致" class="headerlink" title="3、DB和缓存不一致"></a>3、DB和缓存不一致</h1><p>当修改了数据库后，没有及时修改缓存，或者缓存服务器挂了。如果是因为网络问题引起的没有及时更新，可以通过重试机制来解决。而缓存服务器挂了，请求首先自然也就无法到达，从而直接访问到数据库。那么我们在修改数据库后，无法修改缓存，这时候可以将这条数据放到数据库中，同时启动一个异步任务定时去检测缓存服务器是否连接成功，一旦连接成功则从数据库中按顺序取出修改数据，依次进行缓存最新值的修改。</p>
<h1 id="4、命中率较低，影响性能"><a href="#4、命中率较低，影响性能" class="headerlink" title="4、命中率较低，影响性能"></a>4、命中率较低，影响性能</h1><ul>
<li>过期时间太短， 这种场景可以根据实际情况适当增大过期时间</li>
<li>存在不合理缓存删除逻辑， 导致有效的缓存频繁被删除</li>
<li>不合理的key规则设计， 每次缓存访问的key都在变化， 导致无法命中缓存和频繁的新缓存创建</li>
<li>key确实不存在，但是应用还是在频繁的访问， 这种应该从业务逻辑上杜绝</li>
</ul>
<h1 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h1><ul>
<li>缓存空间的使用率</li>
<li>topN 命令的执行次数</li>
<li>缓存的命中率</li>
<li>缓存的接口平均RT，最大RT，最小RT</li>
<li>缓存的QPS</li>
<li>网络出口流量</li>
<li>客户端连接数</li>
<li>key个数统计</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>Cache相关总结</title>
    <url>/sa/cache%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<p>缓存在带来性能提升和支持高并发的同时，也带来另一个问题，如果缓存宕机导致所有的缓存失效，所有的流量都压到后端的服务上，例如数据库层。这时，后端服务因为压力过大无法提供服务或快速响应，缓存因为等待后端请求的响应而“热”不起来，最终导致“雪崩”问题。</p>
<a id="more"></a>

<p><strong>在高并发系统中，解决缓存失效有以下三个思路：</strong></p>
<ol>
<li>Consistent Hashing一致性hash算法，缓存分片，增加虚拟节点来保证服务器能均匀地分布在圆环上，最大限度地减小服务器增减节点时产生的缓存重新分布问题。</li>
<li>备份。由中间件把缓存复制多份，一旦缓存宕机时能切换到另一份缓存上</li>
<li>实现缓存持久化或半持久化。所谓的持久化就是定期把缓存里面的数据刷到磁盘，保存起来，在缓存失效时能保证大部分数据仍然有效，例如使用Redis或MemcacheDB把一些数据存到磁盘。可能有人会说：“是否在刷磁盘那一刻会影响缓存的高效性？”这可以考虑通过高端硬件（例如Fushion IO或SSD作为存储设备），来减少刷Cache过程中减少对服务的影响</li>
</ol>
<p><strong>运维层面：</strong></p>
<ol>
<li>缓存空间大小的使用率</li>
<li>缓存的命中率</li>
<li>响应时间、以及qps</li>
<li>服务器的网络带宽、CPU、内存、硬盘I/O</li>
</ol>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>熔断器</title>
    <url>/sa/fusing/</url>
    <content><![CDATA[<p>熔断机制借鉴电闸上的“保险丝”。当电压有问题时，自动跳闸。</p>
<p>防止应用程序不断地尝试执行可能会失败的操作，如果已经恢复，应用程序会再次尝试调用。</p>
<a id="more"></a>
<h1 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h1><p>熔断器可以使用状态机来实现，内部模拟以下几种状态：</p>
<ul>
<li>闭合（Closed）状态：</li>
</ul>
<p>我们需要一个调用失败的计数器，如果调用失败，则使失败次数加 1。如果最近失败次数超过了在给定时间内允许失败的阈值，则切换到断开 (Open) 状态。此时开启了一个超时时钟，当该时钟超过了该时间，则切换到半断开（Half-Open）状态。该超时时间的设定是给了系统一次机会来修正导致调用失败的错误，以回到正常工作的状态。</p>
<p>在 Closed 状态下，错误计数器是基于时间的。在特定的时间间隔内会自动重置。这能够防止由于某次的偶然错误导致熔断器进入断开状态。也可以基于连续失败的次数。</p>
<ul>
<li>断开 (Open) 状态：</li>
</ul>
<p>在该状态下，对应用程序的请求会立即返回错误响应，而不调用后端的服务。这样也许比较粗暴，有些时候，我们可以 cache 住上次成功请求，直接返回缓存（当然，这个缓存放在本地内存就好了），如果没有缓存再返回错误（缓存的机制最好用在全站一样的数据，而不是用在不同的用户间不同的数据，因为后者需要缓存的数据有可能会很多）。</p>
<ul>
<li>半开（Half-Open）状态：</li>
</ul>
<p>允许应用程序一定数量的请求去调用服务。如果这些请求对服务的调用成功，那么可以认为之前导致调用失败的错误已经修正，此时熔断器切换到闭合状态 (并且将错误计数器重置)。</p>
<h1 id="开源框架"><a href="#开源框架" class="headerlink" title="开源框架"></a>开源框架</h1><ul>
<li>Hystrix</li>
</ul>
<p><a href="https://www.cnblogs.com/jinjiyese153/p/8669702.html" target="_blank" rel="noopener">https://www.cnblogs.com/jinjiyese153/p/8669702.html</a></p>
<h1 id="划重点"><a href="#划重点" class="headerlink" title="划重点"></a>划重点</h1><h2 id="错误的类型"><a href="#错误的类型" class="headerlink" title="* 错误的类型"></a>* 错误的类型</h2><p>请求失败的原因很多。要根据不同的错误情况来调整相应的策略。一些错误先走重试（如限流、超时），重试几次再打开熔断。一些错误是远程服务挂掉，恢复时间比较长，可以直接打开熔断</p>
<h2 id="日志监控"><a href="#日志监控" class="headerlink" title="* 日志监控"></a>* 日志监控</h2><p>熔断应该记录所有失败的请求，以及一些可能会尝试成功的请求</p>
<h2 id="测试服务是否可用"><a href="#测试服务是否可用" class="headerlink" title="* 测试服务是否可用"></a>* 测试服务是否可用</h2><p>断开状态下，熔断器定期ping下远程服务的健康状态，来判断服务是否恢复，而不是使用计时器来自动切换到半开状态</p>
<h2 id="手动重置"><a href="#手动重置" class="headerlink" title="* 手动重置"></a>* 手动重置</h2><p>管理员可以手动强制将熔断器切换到闭合状态。同样，如果服务暂时不可用，管理员也可以强制将熔断器设置为断开状态</p>
<h2 id="并发问题"><a href="#并发问题" class="headerlink" title="* 并发问题"></a>* 并发问题</h2><p>同一个熔断器可能存在大量并发请求访问，熔断器的实现不应该阻塞或者增加调用者的负担。计数器可以用atomic原子性</p>
<h2 id="资源分区"><a href="#资源分区" class="headerlink" title="* 资源分区"></a>* 资源分区</h2><p>分布式架构，资源可能分布在不同的分区上，如：数据库分库分表，某一个分区出现问题，其它分区可用。单一的熔断器会把所有的分区混为一谈。出现一会熔断一会又好了，来来回回的情况</p>
<h2 id="重试导致的错误"><a href="#重试导致的错误" class="headerlink" title="* 重试导致的错误"></a>* 重试导致的错误</h2><p>对于幂等的业务，重试也会报错，所以要准确区分服务是否真的恢复，还是重试报的错误</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>降级</title>
    <url>/sa/demotion/</url>
    <content><![CDATA[<p>资源和访问量出现矛盾时，将资源让给更核心的业务。</p>
<a id="more"></a>
<h1 id="牺牲的点"><a href="#牺牲的点" class="headerlink" title="牺牲的点"></a>牺牲的点</h1><ul>
<li>降低一致性</li>
</ul>
<p>从强一致性变成最终一致性</p>
<ul>
<li>停止次要功能</li>
</ul>
<p>不重要的功能临时下线。比如，电商中的商品成交记录，用户的评价功能等</p>
<ul>
<li>简化流程</li>
</ul>
<p>简化业务流程，或者是不再返回全量数据，而是只返回部分数据</p>
<p>或者异步化，借助MQ</p>
<p>这样可能会牺牲一部分用户体验，所以最好给出较好的用户提示。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>淘宝双11，银行会在支付环节成为瓶颈，业务解决方式，是预充值送红包，其实就是将用户的钱提前充入支付宝现金池中，当天交易无非就是内部的数据关联关系，降低对外部的依赖。</p>
<h1 id="降低数据的一致性"><a href="#降低数据的一致性" class="headerlink" title="降低数据的一致性"></a>降低数据的一致性</h1><ul>
<li>使用缓存，降低数据库的压力。降级后的系统，不再通过数据库获取数据，而是通过缓存获取数据。</li>
<li>直接去掉数据，比如，页面不显示库存，只显示有没有库存的状态</li>
</ul>
<h1 id="划重点"><a href="#划重点" class="headerlink" title="划重点"></a>划重点</h1><ul>
<li><p>要对业务做非常仔细的梳理。</p>
</li>
<li><p>分类处理，比如吞吐量大、响应时间过慢、失败次数较多，有网络或者服务故障等等，要分类做好预案。并写成代码，可以快速地自动化或半自动化执行</p>
</li>
<li><p>分好等级，哪些是“必须有的”，哪些是“可以有的”，事前评估好</p>
</li>
<li><p>降级的时候，需要牺牲掉一致性，或是一些业务流程：对于读操作来说，使用缓存来解决，对于写操作来说，需要异步调用来解决。并且，我们需要以流水账的方式记录下来，这样方便对账，以免漏掉或是和正常的流程混淆。</p>
</li>
<li><p>降级的功能的开关可以是一个系统的配置开关。做成配置时，你需要在要降级的时候推送相应的配置。另一种方式是，在对外服务的 API 上有所区分（方法签名或是开关参数），这样可以由上游调用者来驱动。</p>
</li>
<li><p>比如：一个网关在限流时，在协议头中加入了一个限流程度的参数，让后端服务能知道限流在发生中。当限流程度达到某个值时，或是限流时间超过某个值时，就自动开始降级，直到限流好转。</p>
</li>
<li><p>对于数据方面的降级，需要前端程序的配合。一般来说，前端的程序可以根据后端传来的数据来决定展示哪些界面模块。比如，当前端收不到商品评论时，就不展示。为了区分本来就没有数据，还是因为降级了没有数据的两种情况，在协议头中也应该加上降级的标签。</p>
</li>
</ul>
<p>因为降级的功能平时不会总是会发生，属于应急的情况，所以，降级的这些业务流程和功能有可能长期不用而出现 bug 或问题，对此我们平时要做些演练。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>Gateway详解</title>
    <url>/sa/gateway/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Gateway 是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的 Facade 模式很像。Gateway 封装内部系统的架构，并且提供 API 给各个客户端。</p>
<a id="more"></a>

<p>主要模块：授权、监控、负载均衡、缓存、熔断、降级、限流、请求分片和管理、静态响应处理，等等。</p>
<h1 id="网关模式设计"><a href="#网关模式设计" class="headerlink" title="网关模式设计"></a>网关模式设计</h1><h2 id="请求路由"><a href="#请求路由" class="headerlink" title="请求路由"></a>请求路由</h2><p>对于调用端来说，也是一件非常方便的事情。因为调用端不需要知道自己需要用到的其它服务的地址，全部统一地交给 Gateway 来处理。</p>
<h2 id="服务注册"><a href="#服务注册" class="headerlink" title="服务注册"></a>服务注册</h2><p>为了能够代理后面的服务，并把请求路由到正确的位置上，网关应该有服务注册功能，也就是后端的服务实例可以把其提供服务的地址注册、取消注册。一般来说，注册也就是注册一些 API 接口。比如，HTTP 的 Restful 请求，可以注册相应的 API 的 URI、方法、HTTP 头。 这样，Gateway 就可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上。</p>
<h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>一个网关可以接多个服务实例，所以网关还需要在各个对等的服务实例上做负载均衡策略。简单的就直接是 round robin 轮询，复杂点的可以设置上权重进行分发，再复杂一点还可以做到 session 粘连。</p>
<h2 id="弹力设计"><a href="#弹力设计" class="headerlink" title="弹力设计"></a>弹力设计</h2><p>网关还可以把弹力设计中的那些异步、重试、幂等、流控、降级、熔断、监视等都可以实现进去。这样，同样可以像 Service Mesh 那样，<strong>让应用服务只关心自己的业务逻辑（或是说数据面上的事）而不是控制逻辑（控制面）</strong>。</p>
<h2 id="安全方面"><a href="#安全方面" class="headerlink" title="安全方面"></a>安全方面</h2><p>SSL 加密及证书管理、Session 验证、授权、数据校验，以及对请求源进行恶意攻击的防范。<strong>错误处理越靠前的位置就是越好，所以，网关可以做到一个全站的接入组件来对后端的服务进行保护。</strong></p>
<h2 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h2><p>网关完全可以做到对相同服务不同版本的实例进行导流，并还可以收集相关的数据。这样对于软件质量的提升，甚至产品试错都有非常积极的意义。</p>
<h2 id="API聚合"><a href="#API聚合" class="headerlink" title="API聚合"></a>API聚合</h2><p>使用网关可将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小了，所以一个明显的问题是，客户端可能需要多次请求才能得到所有的数据。这样一来，客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。于是，我们可以让网关来帮客户端请求多个后端的服务（有些场景下完全可以并发请求），然后把后端服务的响应结果拼装起来，回传给客户端（当然，这个过程也可以做成异步的，但这需要客户端的配合）。</p>
<h2 id="API-编排"><a href="#API-编排" class="headerlink" title="API 编排"></a>API 编排</h2><p>同样在微服务的架构下，要走完一个完整的业务流程，我们需要调用一系列 API，就像一种工作流一样，这个事完全可以通过网页来编排这个业务流程。我们可能通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来串联不同的 API。</p>
<h1 id="设计重点"><a href="#设计重点" class="headerlink" title="设计重点"></a>设计重点</h1><h2 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h2><p>在技术设计上，网关不应该也不能成为性能的瓶颈。对于高性能，最好使用高性能的编程语言来实现，如 C、C++、Go 和 Java。网关对后端的请求，以及对前端的请求的服务<strong>一定要使用异步非阻塞的 I/O 来确保后端延迟不会导致应用程序中出现性能问题</strong>。C 和 C++ 可以参看 Linux 下的 epoll 和 Windows 的 I/O Completion Port 的异步 IO 模型，Java 下如 Netty、Vert.x、Spring Reactor 的 NIO 框架。当然，我还是更喜欢 Go 语言的 goroutine 加 channel 玩法。</p>
<h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><p>所有的流量或调用经过网关，所以网关必须成为一个高可用的技术组件，它的稳定直接关系到了所有服务的稳定。网关如果没有设计，就会成变一个单点故障。</p>
<h2 id="集群化"><a href="#集群化" class="headerlink" title="集群化"></a>集群化</h2><p>网关要成为一个集群，其最好可以自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。</p>
<h2 id="服务化"><a href="#服务化" class="headerlink" title="服务化"></a>服务化</h2><p>网关还需要做到在不间断的情况下修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，另一种是最好做到服务化。也就是说，得要有自己的 Admin API 来在运行时修改自己的配置。</p>
<h2 id="持续化"><a href="#持续化" class="headerlink" title="持续化"></a>持续化</h2><p>比如重启，就是像 Nginx 那样优雅地重启。有一个主管请求分发的主进程。当我们需要重启时，新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。</p>
<h2 id="高扩展性"><a href="#高扩展性" class="headerlink" title="高扩展性"></a>高扩展性</h2><p>网关需要承接所有的业务流量和请求，所以一定会有或多或少的业务逻辑。而我们都知道，<strong>业务逻辑是多变和不确定的。比如，需要在网关上加上一些和业务相关的东西。因此，一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。</strong>当然，像 Nginx 那样通过 Module 进行二次开发的固然可以。但我还是觉得应该做成像 AWS Lambda 那样的方式，也就是所谓的 Serverless 或 FaaS（Function as a Service）那样的方式。</p>
<h1 id="运维方面"><a href="#运维方面" class="headerlink" title="运维方面"></a>运维方面</h1><h2 id="业务松耦合，协议紧耦合"><a href="#业务松耦合，协议紧耦合" class="headerlink" title="业务松耦合，协议紧耦合"></a>业务松耦合，协议紧耦合</h2><p>在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。网关应该是在网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。另外，除了服务发现外，网关不应该有第三方服务的依赖。</p>
<h2 id="应用监视，提供分析数据"><a href="#应用监视，提供分析数据" class="headerlink" title="应用监视，提供分析数据"></a>应用监视，提供分析数据</h2><p>网关上需要考虑应用性能的监控，除了有相应后端服务的高可用的统计之外，还需要使用 Tracing ID 实施分布式链路跟踪，并统计好一定时间内每个 API 的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。</p>
<h2 id="用弹力设计保护后端服务"><a href="#用弹力设计保护后端服务" class="headerlink" title="用弹力设计保护后端服务"></a>用弹力设计保护后端服务</h2><p>网关上一定要实现熔断、限流、降级、重试和超时等弹力设计。如果一个或多个服务调用花费的时间过长，那么可接受超时并返回一部分数据，或是返回一个网关里的缓存的上一次成功请求的数据。你可以考虑一下这样的设计。</p>
<h2 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h2><p>因为网关这个组件太关键了，所以需要 DevOps 这样的东西，将其发生故障的概率降到最低。这个软件需要经过精良的测试，包括功能和性能的测试，还有浸泡测试。还需要有一系列自动化运维的管控工具。</p>
<h1 id="架构方面"><a href="#架构方面" class="headerlink" title="架构方面"></a>架构方面</h1><ul>
<li><p><strong>不要在网关中的代码里内置聚合后端服务的功能</strong>，而应考虑将聚合服务放在网关核心代码之外。可以使用 Plugin 的方式，也可以放在网关后面形成一个 Serverless 服务。</p>
</li>
<li><p>网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟，并可以减少很多网络上的问题。这里多说一句，网关处理的静态内容应该靠近用户（应该放到 CDN 上），而网关和此时的动态服务应该靠近后端服务。</p>
</li>
<li><p>网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量。这一点，要么通过 DNS 轮询的方式实现，要么通过 CDN 来做流量调度，或者通过更为底层的性能更高的负载均衡设备。</p>
</li>
<li><p>对于服务发现，可以做一个时间不长的缓存，这样不需要每次请求都去查一下相关的服务所在的地方。当然，如果你的系统不复杂，可以考虑把服务发现的功能直接集成进网关中。</p>
</li>
<li><p>为网关考虑 bulkhead 设计方式。用不同的网关服务不同的后端服务，或是用不同的网关服务前端不同的客户。</p>
</li>
<li><p>校验用户请求。一些基本的用户验证可以放在网关上来做，比如用户是否已登录，用户请求中的 token 是否合法等。但是，<strong>我们需要权衡一下，网关是否需要校验用户的输入。因为这样一来，网关就需要从只关心协议头，到需要关心协议体。而协议体中的东西一方面不像协议头是标准的，另一方面解析协议体还要耗费大量的运行时间，从而降低网关的性能</strong>。对此，我想说的是，看具体需求，一方面如果协议体是标准的，那么可以干；另一方面，对于解析协议所带来的性能问题，需要做相应的隔离。</p>
</li>
<li><p>检测异常访问。网关需要检测一些异常访问，比如，在一段比较短的时间内请求次数超过一定数值；还比如，同一客户端的 4xx 请求出错率太高……对于这样的一些请求访问，网关一方面要把这样的请求屏蔽掉，另一方面需要发出警告，有可能会是一些比较重大的安全问题，如被黑客攻击。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>Groovy</title>
    <url>/sa/groovy/</url>
    <content><![CDATA[<ul>
<li><a href="https://zhuanlan.zhihu.com/p/25303218" target="_blank" rel="noopener">Groovy与Java集成常见的坑</a></li>
<li><a href="http://groovy-lang.org/differences.html" target="_blank" rel="noopener">Differences with Java</a></li>
</ul>
<a id="more"></a>
<ul>
<li><p><a href="http://wiki.jikexueyuan.com/project/groovy-introduction/integrating-groovy-applications.html" target="_blank" rel="noopener">Groovy 与应用的集成</a></p>
</li>
<li><p><a href="https://blog.csdn.net/hxpjava1/article/details/71747497" target="_blank" rel="noopener">Groovy与Java的区别</a></p>
</li>
<li><p>编译</p>
<ul>
<li><a href="https://blog.csdn.net/xiajun07061225/article/details/26957563" target="_blank" rel="noopener">java执行预编译Groovy脚本</a></li>
</ul>
</li>
<li><p>动态编译</p>
<ul>
<li><a href="http://www.youzitool.com/blog/15.html" target="_blank" rel="noopener">Groovy&amp;Java动态编译执行</a></li>
<li><a href="http://shift-alt-ctrl.iteye.com/blog/1938238" target="_blank" rel="noopener">JAVA嵌入运行Groovy脚本</a></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>幂等性设计</title>
    <url>/sa/idempotent/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>服务间调用有三种状态：成功；失败；超时。前两个状态明确，但超时状态完全不知道是什么状态。</p>
<a id="more"></a>
<p>可能是请求没有到达，也可能是请求到达了，但返回结果没有到达。我们不知道下游系统是否收到了请求，而收到了请求是否处理了。</p>
<p>例如：</p>
<ul>
<li>创建订单接口，第一次调用超时，然后client重试了一次，是否会多创建一笔订单？</li>
<li>用户付款时，服务端发生扣款行为，接口响应超时，调用方重试了一次，是否会多扣一次钱？</li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li>下游系统提供查询接口，上游系统在timout后去查询一次，并根据结果执行不同的策略</li>
<li>幂等处理。上游只管重试，下游系统保证一次和多次的请求结果是一样的。（推荐方式）</li>
</ul>
<h1 id="全局id"><a href="#全局id" class="headerlink" title="全局id"></a>全局id</h1><p><a href="https://www.cnblogs.com/relucent/p/4955340.html" target="_blank" rel="noopener">Twitter的分布式自增ID算法snowflake </a></p>
<p>snowflake的结构如下(每部分用-分开):</p>
<p>0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000</p>
<ul>
<li>第一位为未使用</li>
<li>接下来的41位为毫秒级时间(41位的长度可以使用69年)</li>
<li>然后是5位datacenterId和5位workerId(10位的长度最多支持部署1024个节点） </li>
<li>最后12位是毫秒内的计数（12位的计数顺序号支持每个节点每毫秒产生4096个ID序号）</li>
</ul>
<p>一共加起来刚好64位，为一个Long型。(转换成字符串后长度最多19)</p>
<p>snowflake生成的ID整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和workerId作区分），并且效率较高。经测试snowflake每秒能够产生26万个ID。</p>
<p><strong>本机测试，每秒产生约4W个id</strong></p>
<h1 id="处理流程"><a href="#处理流程" class="headerlink" title="处理流程"></a>处理流程</h1><p>以交易为例，当收到交易请求时，先去查，有没有创建过？如果查到了就不做处理</p>
<p>一般可以采用乐观锁，基本CAS方式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update 订单表 set  status&#x3D;&quot;交易成功&quot;  where id&#x3D;#orderId# and status&#x3D;&quot;等待买家确认收货&quot;</span><br></pre></td></tr></table></figure>

<p>或者</p>
<p>以论坛发贴为例，在表单中隐藏一个token，防止用户多次点击表单提交按钮。防重复。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>InfluxDB</title>
    <url>/sa/influxdb/</url>
    <content><![CDATA[<ul>
<li><a href="https://www.cnblogs.com/waitig/p/6044177.html" target="_blank" rel="noopener">InfluxDB系列教程</a><a id="more"></a>

</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>流量调度</title>
    <url>/sa/flow-dispatch/</url>
    <content><![CDATA[<h1 id="主要功能："><a href="#主要功能：" class="headerlink" title="主要功能："></a>主要功能：</h1><p>1、根据系统运行的情况，自动地进行流量调度，无需人工干预的情况下，提升整个系统的稳定性。</p>
<p>如：对于一个机构有a、b、c三个口子，分别各用10%的流量探测各口子的成功率，依据结果将剩下的70%分流到成功率较高的口子上。</p>
<p>2、当系统遇到爆品时，弹性计算，动态扩容、缩容。</p>
<h1 id="其它相关"><a href="#其它相关" class="headerlink" title="其它相关"></a>其它相关</h1><ul>
<li>服务流控</li>
</ul>
<p>服务发现、路由、熔断、服务保护</p>
<ul>
<li>流量控制</li>
</ul>
<p>负载均衡、流量分配、流量控制、异地多活</p>
<ul>
<li>流量管理</li>
</ul>
<p>协议转换、请求校验、数据缓存、数据计算</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>隔离设计</title>
    <url>/sa/isolate/</url>
    <content><![CDATA[<h1 id="常见方式"><a href="#常见方式" class="headerlink" title="常见方式"></a>常见方式</h1><p>1、服务的种类来做分离</p>
<p>2、用户维度做分离</p>
<h1 id="服务种类分离"><a href="#服务种类分离" class="headerlink" title="服务种类分离"></a>服务种类分离</h1><img data-src="http://f.ngall-in.com/alan87/static/images/sa/13.jpeg/w600">

<p>以微服务形式，将业务拆分为用户中心，商品中心，评论中心，各自采用独立的服务器集群部署，独立的数据库。达到物理层面的隔离。</p>
<h1 id="用户维度分离"><a href="#用户维度分离" class="headerlink" title="用户维度分离"></a>用户维度分离</h1><img data-src="http://f.ngall-in.com/alan87/static/images/sa/14.jpeg/w600">

<p>将用户分成不同的组，并把后端的同一个服务根据这些不同的组分成不同的实例。同一个服务对于不同的用户进行冗余和隔离。这样一个服务实例挂掉，只会影响一部分用户。</p>
<p>“多租户”模式。针对一些大的客户，专用集群。</p>
<ul>
<li>特点：</li>
</ul>
<p>增加设计的复杂度，资源上存在浪费。</p>
<ul>
<li>多租户模式分为三种：</li>
</ul>
<p>1、完全独立。每个租户有自己完全独立的服务和数据。</p>
<p>2、独立的数据分区，服务共享。（较推荐方式）</p>
<p>3、共享服务，共享数据分区。</p>
<h1 id="设计要点"><a href="#设计要点" class="headerlink" title="设计要点"></a>设计要点</h1><ul>
<li><p>定义好隔离业务的大小和粒度。过大、过小都不好。需要结合具体业务来看。</p>
</li>
<li><p>考虑系统的复杂度、成本、性能、资源使用的问题。找到合适的均衡方案。</p>
</li>
<li><p>配置一些高可用、重试、异步、消息中间件、流控、熔断等框架</p>
</li>
<li><p>自动化运维工具，象容器或虚拟化技术帮助我们更方便的管理</p>
</li>
<li><p>非常完善的监控系统</p>
</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>jsoup</title>
    <url>/sa/jsoup/</url>
    <content><![CDATA[<ul>
<li>依赖jar包</li>
</ul>
<a id="more"></a>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.jsoup<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jsoup<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><a href="http://www.open-open.com/jsoup/selector-syntax.htm" target="_blank" rel="noopener">帮助文档</a></li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>负载均衡</title>
    <url>/sa/load-balance/</url>
    <content><![CDATA[<h1 id="1、随机算法"><a href="#1、随机算法" class="headerlink" title="1、随机算法"></a>1、随机算法</h1><p>从可用的节点中，随机挑选一个节点来访问</p>
<p>一般通过生成一个随机数来实现</p>
<a id="more"></a>
<p><a href="https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/RandomLoadBalance.java" target="_blank" rel="noopener">https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/RandomLoadBalance.java</a></p>
<p>适用场景：</p>
<p>实现比较简单，在请求量远超可用服务节点数量的情况下，各个服务节点被访问的概率基本相同，主要应用在各个服务节点的性能差异不大的情况下。</p>
<h1 id="2、轮询算法"><a href="#2、轮询算法" class="headerlink" title="2、轮询算法"></a>2、轮询算法</h1><p>按照固定的顺序，把可用的服务节点，挨个访问一次。</p>
<p>在实现时，轮询算法通常是把所有可用节点放到一个数组里，然后按照数组编号，挨个访问。比如服<br>务有 10 个节点，放到数组里就是一个大小为 10 的数组，这样的话就可以从序号为 0 的节点开始访<br>问，访问后序号自动加 1，下一次就会访问序号为 1 的节点，以此类推。</p>
<p>轮询算法能够保证所有节点被访问到的概率是相同的。</p>
<p><a href="https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/RoundRobinLoadBalance.java" target="_blank" rel="noopener">https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/RoundRobinLoadBalance.java</a></p>
<p>适用场景：</p>
<p>跟随机算法类似，各个服务节点被访问的概率也基本相同，也主要应用在各个服务节点性能差异不大的情况下。</p>
<h1 id="3、加权轮询算法"><a href="#3、加权轮询算法" class="headerlink" title="3、加权轮询算法"></a>3、加权轮询算法</h1><p>轮询算法能够保证所有节点被访问的概率相同，而加权轮询算法是在此基础上，给每个节点赋予一个<br>权重，从而使每个节点被访问到的概率不同，权重大的节点被访问的概率就高，权重小的节点被访问<br>的概率就小。</p>
<p>在实现时，加权轮询算法是生成一个节点序列，该序列里有 n 个节点，n 是所有节点的权重之和。<br>在这个序列中，每个节点出现的次数，就是它的权重值。比如有三个节点：a、b、c，权重分别是<br>3、2、1，那么生成的序列就是{a、a、b、c、b、a}，这样的话按照这个序列访问，前 6 次请求就<br>会分别访问节点 a 三次，节点 b 两次，节点 c 一次。从第 7 个请求开始，又重新按照这个序列的顺<br>序来访问节点。</p>
<p>在应用加权轮询算法的时候，根据我的经验，要尽可能保证生产的序列的均匀，如果生成的不均匀会<br>造成节点访问失衡，比如刚才的例子，如果生成的序列是{a、a、a、b、b、c}，就会导致前 3 次访<br>问的节点都是 a。</p>
<p><a href="https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ConfigurableWeightLoadBalance.java" target="_blank" rel="noopener">https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ConfigurableWeightLoadBalance.java</a></p>
<p>适用场景：</p>
<p>主要被用在服务节点性能差异比较大的情况。比如经常会出现一种情况，因为采购时间<br>的不同，新的服务节点的性能往往要高于旧的节点，这个时候可以给新的节点设置更高的权重，<br>让它承担更多的请求，充分发挥新节点的性能优势。</p>
<h1 id="4、最少活跃连接算法"><a href="#4、最少活跃连接算法" class="headerlink" title="4、最少活跃连接算法"></a>4、最少活跃连接算法</h1><p>顾名思义就是每一次访问都选择连接数最少的节点。因为不同节点处理请求的速<br>度不同，使得同一个服务消费者同每一个节点的连接数都不相同。连接数大的节点，可以认为是处理<br>请求慢，而连接数小的节点，可以认为是处理请求快。所以在挑选节点时，可以以连接数为依据，选<br>择连接数最少的节点访问。</p>
<p>在实现时，需要记录跟每一个节点的连接数，这样在选择节点时，才能比较出连接数最小的节点。</p>
<p><a href="https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ActiveWeightLoadBalance.java" target="_blank" rel="noopener">https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ActiveWeightLoadBalance.java</a></p>
<p>适用场景：</p>
<p>与加权轮询算法预先定义好每个节点的访问权重不同，采用最少活跃连接算<br>法，客户端同服务端节点的连接数是在时刻变化的，理论上连接数越少代表此时服务端节点越空<br>闲，选择最空闲的节点发起请求，能获取更快的响应速度。尤其在服务端节点性能差异较大，而<br>又不好做到预先定义权重时，采用最少活跃连接算法是比较好的选择。</p>
<h1 id="5、一致性hash-算法"><a href="#5、一致性hash-算法" class="headerlink" title="5、一致性hash 算法"></a>5、一致性hash 算法</h1><p>一致性 hash 算法，是通过某个 hash 函数，把同一个来源的请求都映射到同一个节点上。一致性<br>hash 算法最大的特点就是同一个来源的请求，只会映射到同一个节点上，可以说是具有记忆功能。<br>只有当这个节点不可用时，请求才会被分配到相邻的可用节点上。</p>
<p><a href="https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ConsistentHashLoadBalance.java" target="_blank" rel="noopener">https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ConsistentHashLoadBalance.java</a></p>
<p>适用场景：</p>
<p>因为它能够保证同一个客户端的请求始终访问同一个服务节点，所以适合服务端节点处理不同客户端请求差异较大的场景。比如服务端缓存里保存着客户端的请求结果，如果同一客户端一直访问一个服务节点，那么就可以一直从缓存中获取数据。</p>
<h1 id="6、自适应最优选择算法"><a href="#6、自适应最优选择算法" class="headerlink" title="6、自适应最优选择算法"></a>6、自适应最优选择算法</h1><p>这种算法的主要思路是在客户端本地维护一份同每一个服务节点的性能统计快照，并且每隔一段时间<br>去更新这个快照。在发起请求时，根据“二八原则”，把服务节点分成两部分，找出 20% 的那部分<br>响应最慢的节点，然后降低权重。这样的话，客户端就能够实时的根据自身访问每个节点性能的快<br>慢，动态调整访问最慢的那些节点的权重，来减少访问量，从而可以优化长尾请求。</p>
<p>由此可见，自适应最优选择算法是对加权轮询算法的改良，可以看作是一种<strong>动态加权轮询算法</strong>。它的<br>实现关键之处就在于两点：第一点是每隔一段时间获取客户端同每个服务节点之间调用的平均性能统<br>计；第二点是按照这个性能统计对服务节点进行排序，对排在性能倒数 20% 的那部分节点赋予一个<br>较低的权重，其余的节点赋予正常的权重。</p>
<p>在具体实现时，针对第一点，需要在内存中开辟一块空间记录客户端同每一个服务节点之间调用的平<br>均性能，并每隔一段固定时间去更新。这个更新的时间间隔不能太短，太短的话很容易受瞬时的性能<br>抖动影响，导致统计变化太快，没有参考性；同时也不能太长，太长的话时效性就会大打折扣，效果<br>不佳。根据我的经验，1 分钟的更新时间间隔是个比较合适的值。</p>
<p>针对第二点，关键点是权重值的设定，即使服务节点之间的性能差异较大，也不适合把权重设置得差<br>异太大，这样会导致性能较好的节点与性能较差的节点之间调用量相差太大，这样也不是一种合理的<br>状态。在实际设定时，可以设置 20% 性能较差的节点权重为 3，其余节点权重为 5。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>基于数据库实现分布式锁</title>
    <url>/sa/lock-db/</url>
    <content><![CDATA[<p>要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。</p>
<a id="more"></a>
<p>当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。</p>
<p>注意：</p>
<p>数据库表要建立唯一约束，保证只有一个请求可以成功。</p>
<p>缺点：</p>
<ul>
<li>吞吐能力完全依赖于数据库性能，数据库的负担比较重，不太适用线上环境。</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>技术大纲</title>
    <url>/sa/knowledge-outline/</url>
    <content><![CDATA[<h1 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h1><ul>
<li>前端浏览器地址的一个 http 请求到后端整个流程 <a href="outline/1.md">link</a></li>
<li>哪些设计模式可以增加系统的可扩展性</li>
<li>如果AB两个系统互相依赖，如何解除依赖？</li>
<li>什么场景应该拆分系统，什么场景应该合并系统？</li>
<li>常用的设计模式，23种  <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/basic-knowledge/%E5%B8%B8%E7%94%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.md" target="_blank" rel="noopener">link</a></li>
<li>如何构建高可用系统？ <a href="https://mp.weixin.qq.com/s/TuOMlzXRtDJSCgYGMPbpjw" target="_blank" rel="noopener">link</a></li>
<li>性能优化：使用单例、使用Future模式、使用线程池、选择就绪、减少上下文切换、减少锁粒度、数据压缩、结果缓存</li>
<li>Nginx负载均衡 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/web/load-balance.md" target="_blank" rel="noopener">link</a></li>
<li>一个系统如何优雅关闭。signal信号捕捉 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/basic-knowledge/java.md" target="_blank" rel="noopener">link</a></li>
</ul>
<h1 id="分布式系列"><a href="#分布式系列" class="headerlink" title="分布式系列"></a>分布式系列</h1><ul>
<li>如何设计一个高并发的分布式系统？你会引入哪些开源框架？</li>
<li>缓存<ul>
<li>搭建Redis缓存高可用集群</li>
<li>高并发下如何正确优雅的使用缓存</li>
<li>设计缓存要注意什么</li>
<li>本地缓存用过哪些框架？Guava</li>
<li>分布式缓存：缓存一致性、缓存命中率、缓存冗余</li>
<li>缓存和数据库，如何实现一致性？<a href="https://mp.weixin.qq.com/s/-Kvj8TPVvZE-rbtult_ozA?from=groupmessage&isappinstalled=0" target="_blank" rel="noopener">link</a></li>
</ul>
</li>
<li>分布式数据库<ul>
<li>怎样打造一个分布式数据库？什么时候需要分布式数据库、mycat、otter、HBase</li>
</ul>
</li>
<li>网关框架了解过哪些？能为后端服务带来哪些好处？</li>
<li>如何保证消息幂等  <a href="https://www.jianshu.com/p/8b77d4583bab?utm_campaign" target="_blank" rel="noopener">link</a></li>
<li>如何实现分布式Session</li>
<li>如何保证消息的一致性</li>
<li>CDN实现原理 </li>
</ul>
<h1 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h1><ul>
<li>zookeeper之服务注册与订阅</li>
<li>使用Docker部署微服务</li>
<li>微服务架构–分布式事务解决方案</li>
<li>微服务划分的粒度</li>
<li>微服务的高可用怎么保证的？</li>
<li>什么场景应该拆分系统，什么场景应该合并系统</li>
</ul>
<h1 id="锁相关"><a href="#锁相关" class="headerlink" title="锁相关"></a>锁相关</h1><ul>
<li>死锁定义；如何避免死锁 <a href="https://blog.csdn.net/ls5718/article/details/51896159" target="_blank" rel="noopener">link</a></li>
<li>乐观锁，悲观锁，使用场景？ <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/system-architecture/%E9%94%81%E6%9C%BA%E5%88%B6.md" target="_blank" rel="noopener">link</a></li>
<li>设计一个分布式锁 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/system-architecture/architecture-experience.md" target="_blank" rel="noopener">link</a></li>
<li>常见的锁有哪些？ <a href="https://github.com/aalansehaiyang/Lock-Learning" target="_blank" rel="noopener">link</a></li>
<li>java读写锁，读写锁设计主要解决什么问题？ <a href="http://ifeve.com/read-write-locks/" target="_blank" rel="noopener">link</a></li>
<li>synchronized和 ReentrantLock 的区别？ <a href="https://www.cnblogs.com/fanguangdexiaoyuer/p/5313653.html" target="_blank" rel="noopener">link</a> <a href="outline/2.md">link</a></li>
<li>不用synchronized和lock，实现线程安全的单例模式？<a href="https://blog.csdn.net/w372426096/article/details/80938895" target="_blank" rel="noopener">link</a> </li>
</ul>
<h1 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h1><ul>
<li>java<ul>
<li>基础<ul>
<li>String、StringBuffer与StringBuilder的区别</li>
<li>try catch finally，try里面有return，finally还执行吗？</li>
<li>泛型中K T V E   <a href="http://nannan408.iteye.com/blog/1825182" target="_blank" rel="noopener">link</a></li>
<li>Thread 和 Runnable区别？</li>
<li>关键字 volatile、transient、final <a href="https://www.cnblogs.com/ccfdod/p/6392343.html" target="_blank" rel="noopener">link</a></li>
<li>Object 的 equals方法重写了，hashCode 方法必须重写 <a href="https://blog.csdn.net/u013679744/article/details/57074669/" target="_blank" rel="noopener">link</a> <a href="https://github.com/Snailclimb/JavaGuide/blob/master/%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87/%E6%9C%80%E6%9C%80%E6%9C%80%E5%B8%B8%E8%A7%81%E7%9A%84Java%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/%E7%AC%AC%E4%B8%80%E5%91%A8%EF%BC%882018-8-7%EF%BC%89.md" target="_blank" rel="noopener">link</a></li>
</ul>
</li>
<li>集合<ul>
<li>ThreadLocal 内部原理？</li>
<li>HashMap，为什么线程不安全 <a href="https://mp.weixin.qq.com/s/RtfEPR2oclUAu0tXnYAn4Q" target="_blank" rel="noopener">link</a>    </li>
<li>HashMap 怎么解决碰撞问题？</li>
<li>Concurrenthashmap 是怎么做到线程安全的？</li>
</ul>
</li>
<li>线程<ul>
<li>线程有哪些状态？ blocked 和 wait 有什么区别? <a href="https://blog.csdn.net/longly_me/article/details/61414268" target="_blank" rel="noopener">link</a> <a href="https://www.cnblogs.com/lcplcpjava/p/6896904.html" target="_blank" rel="noopener">link</a></li>
<li>sleep() 和 wait() 的区别 <a href="https://blog.csdn.net/xyh269/article/details/52613507" target="_blank" rel="noopener">link</a></li>
<li>JDK 中有哪几个线程池？拒绝策略？ <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/basic-knowledge/concurrent-class.md" target="_blank" rel="noopener">link</a> <a href="https://mp.weixin.qq.com/s/5dexEENTqJWXN_17c6Lz6A" target="_blank" rel="noopener">link</a></li>
<li>如何保证线程安全问题？</li>
<li>JUC 常用的类 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/basic-knowledge/concurrent-class.md" target="_blank" rel="noopener">link</a> <a href="https://mp.weixin.qq.com/s/K8y6wMNDLwsmU7EFRx7Dsw" target="_blank" rel="noopener">link</a></li>
</ul>
</li>
<li>IO<ul>
<li>BIO、NIO和AIO的区别，三种IO的用法与原理</li>
</ul>
</li>
<li>JVM<ul>
<li>JVM 内存结构 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/basic-knowledge/java.md" target="_blank" rel="noopener">link</a></li>
<li>JVM如何加载字节码文件 </li>
<li>双亲委派，Bootstrap ClassLoader、Extension ClassLoader、ApplicationClassLoader</li>
<li>内存分配策略、垃圾收集器（G1）、GC算法、GC参数、对象存活的判定 </li>
<li>什么情况会出现young GC，什么情况会出现Full GC</li>
<li>怎样判断Full GC是否正常？ <a href="https://mp.weixin.qq.com/s/TuOMlzXRtDJSCgYGMPbpjw" target="_blank" rel="noopener">link</a></li>
<li>内存泄露原因？如何排查？ <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/ops/online-question.md" target="_blank" rel="noopener">link</a></li>
<li>OOM 出现的有哪些场景？ <a href="https://mp.weixin.qq.com/s/34GVlaYDOdY1OQ9eZs-iXg" target="_blank" rel="noopener">link</a> <a href="outline/3.md">link</a></li>
<li>熟悉哪些jvm 命令，jstack、jmap、jstat? <a href="https://blog.csdn.net/itomge/article/details/9904555" target="_blank" rel="noopener">link</a></li>
<li>jvm调优经验</li>
</ul>
</li>
<li>其它<ul>
<li>动态代理与Cglib实现的区别 <a href="https://www.cnblogs.com/leifei/p/8263448.html" target="_blank" rel="noopener">link</a></li>
<li>看过哪些JDK源码</li>
<li>JAVA并发编程艺术</li>
<li>java8的新特性 <a href="https://github.com/biezhi/30-seconds-of-java8" target="_blank" rel="noopener">link</a></li>
<li>lambda表达式、Stream API</li>
<li>HotSpot 即时编译器、编译优化 <a href="http://www.sohu.com/a/169704040_464084" target="_blank" rel="noopener">link</a></li>
<li>CPU缓存，L1，L2，L3和伪共享 <a href="https://blog.csdn.net/zero__007/article/details/54089730" target="_blank" rel="noopener">link</a></li>
<li>Java 9，Reactive Streams <a href="https://www.cnblogs.com/IcanFixIt/p/7245377.html" target="_blank" rel="noopener">link</a>        </li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>spring<ul>
<li>为什么要使用Spring，Spring的优缺点有哪些</li>
<li>Spring的IOC容器初始化流程</li>
<li>Spring Bean 的生命周期 <a href="https://blog.csdn.net/itomge/article/details/8656942" target="_blank" rel="noopener">link</a></li>
<li>Spring AOP实现原理</li>
<li>SpringMVC模式</li>
<li>Spring Boot 与 Spring 的区别 <a href="https://mp.weixin.qq.com/s/lsJU_XFmI3dPpkWndrsAuw" target="_blank" rel="noopener">link</a></li>
<li>Spring cloud了解过哪些</li>
<li>Spring 5 响应式编程 <a href="https://www.oschina.net/translate/reactive-programming-with-spring-5" target="_blank" rel="noopener">link</a></li>
</ul>
</li>
</ul>
<ul>
<li>mysql<ul>
<li>数据库主备搭建 <a href="https://www.cnblogs.com/fan-yuan/p/7249249.html" target="_blank" rel="noopener">link</a> <a href="https://blog.csdn.net/zimu002/article/details/72843260" target="_blank" rel="noopener">link</a></li>
<li>表级锁和行级锁对比 <a href="https://mp.weixin.qq.com/s/ENQZii1xgxlsIbR-oMseKw" target="_blank" rel="noopener">link</a></li>
<li>事务特性，有哪几种事务隔离级别 <a href="https://mp.weixin.qq.com/s/ENQZii1xgxlsIbR-oMseKw" target="_blank" rel="noopener">link</a></li>
<li>分布式事务，两阶段提交</li>
<li>当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施 <a href="https://mp.weixin.qq.com/s/ENQZii1xgxlsIbR-oMseKw" target="_blank" rel="noopener">link</a></li>
<li>SQL 优化的常见方法有哪些 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/data-base/sql-optimize.md" target="_blank" rel="noopener">link</a></li>
<li>如何查看执行计划，如何根据执行计划进行SQL优化 <a href="https://blog.csdn.net/taojin12/article/details/81489234" target="_blank" rel="noopener">link</a></li>
<li>MyISAM与InnoDB区别 <a href="https://www.cnblogs.com/lyl2016/p/5797519.html" target="_blank" rel="noopener">link</a></li>
</ul>
</li>
</ul>
<ul>
<li><p>redis</p>
<ul>
<li>为什么要用Redis，Redis有哪些优缺点？Redis如何实现扩容？ <a href="https://mp.weixin.qq.com/s/FqMScRBFwdwF2n3QJkNLRA" target="_blank" rel="noopener">link</a></li>
<li>10个redis常见问题 <a href="https://mp.weixin.qq.com/s/Z4a8wbWvPDGFTkKJH0X9VQ" target="_blank" rel="noopener">link</a><ul>
<li>Redis有哪些数据结构？</li>
<li>使用过Redis分布式锁么，代码怎么写？</li>
<li>假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？    </li>
<li>Redis如何做持久化的？</li>
<li>Pipeline有什么好处，为什么要用pipeline？</li>
<li>Redis的同步机制了解么？    </li>
</ul>
</li>
</ul>
</li>
<li><p>kafka</p>
<ul>
<li>Kafka的整体架构</li>
</ul>
</li>
<li><p>netty</p>
<ul>
<li>Netty的一次请求过程</li>
<li>Netty核心精讲之Reactor线程模型</li>
</ul>
</li>
<li><p>dubbo</p>
<ul>
<li>底层原理</li>
<li>支持哪些负载算法？默认哪种？</li>
<li>怎么设置超时时间？</li>
</ul>
</li>
<li><p>tomcat</p>
<ul>
<li>Tomcat 调优</li>
<li>Servlet线程安全问题 <a href="https://blog.csdn.net/i_will_try/article/details/62215633" target="_blank" rel="noopener">link</a></li>
</ul>
</li>
<li><p>其它</p>
<ul>
<li>HttpClient 内部实现？ <a href="https://www.jianshu.com/p/14c005e9287c" target="_blank" rel="noopener">link</a></li>
</ul>
</li>
</ul>
<h1 id="HTTP-协议"><a href="#HTTP-协议" class="headerlink" title="HTTP 协议"></a>HTTP 协议</h1><ul>
<li>OSI模型分为哪几层？</li>
<li>TCP<ul>
<li>TCP 和 UDP 的区别？TCP 数据传输过程中怎么做到可靠的？</li>
<li>TCP 三次握手、四次挥手过程 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/web/tcp.md" target="_blank" rel="noopener">link</a></li>
<li>TCP拥塞控制 <a href="https://www.cnblogs.com/hupp/p/4856134.html" target="_blank" rel="noopener">link</a></li>
</ul>
</li>
<li>http<ul>
<li>Cookie和Session的区别</li>
<li>Http的状态码</li>
<li>HTTP 301 、302有啥区别</li>
<li>HTTP连接池实现原理</li>
<li>Http怎么处理长连接</li>
</ul>
</li>
<li>谈谈对 Http 和 RPC 的理解？ <a href="outline/4.md">link</a></li>
</ul>
<h1 id="OS系统"><a href="#OS系统" class="headerlink" title="OS系统"></a>OS系统</h1><ul>
<li>centos7 的内存分配方式和6有啥不同 <a href="https://www.cnblogs.com/Csir/p/6746667.html" target="_blank" rel="noopener">link</a></li>
<li>linux<ul>
<li>常用的linux命令 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/ops/linux-commands.md" target="_blank" rel="noopener">link</a></li>
<li>缓冲区溢出</li>
<li>分段和分页</li>
<li>虚拟内存与主存</li>
<li>Linux 库函数与系统调用的关系与区别 <a href="https://www.cnblogs.com/liwei0526vip/p/8998751.html" target="_blank" rel="noopener">link</a></li>
<li>调度算法</li>
<li>select 、poll和epoll</li>
</ul>
</li>
<li>进程和线程的区别 <a href="https://mp.weixin.qq.com/s/xHOSVG5tGzj1RzpEutH_wg" target="_blank" rel="noopener">link</a></li>
</ul>
<h1 id="实战能力"><a href="#实战能力" class="headerlink" title="实战能力"></a>实战能力</h1><ul>
<li>有没有处理过线上问题？出现内存泄露，CPU利用率飙高，应用无响应时如何处理？</li>
<li>如果有几十亿的白名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能</li>
<li>双十一电商秒杀系统性能优化实战</li>
<li>电商网站，如何保证一件商品不被超卖</li>
<li>让您做一个电商平台，您如何设置一个在买家下订单后的”第60秒“发短信通知卖家发货，您需要考虑的是 像淘宝一样的大并发量的订单 <a href="https://mp.weixin.qq.com/s/u4Azg27wPtdbVtoi38EAiA" target="_blank" rel="noopener">link</a></li>
</ul>
<h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><ul>
<li>一致性Hash算法 <a href="https://github.com/aalansehaiyang/technology-talk/blob/master/other/%E4%B8%80%E8%87%B4%E6%80%A7hash.md" target="_blank" rel="noopener">link</a></li>
<li>看过哪些开源框架的源码</li>
<li>消息中间件是如何实现的，技术难点有哪些</li>
<li>工作案例。怎么提高研发效率。</li>
<li>HttpClient 讲下里面的具体实现，（涉及了哪些东西）</li>
<li>那要你设计一个高性能的 Http ，你会怎么设计？</li>
<li>说出一个空间换时间的场景</li>
<li>怎么防止订单重复提交?</li>
<li>ORM框架用过哪些？</li>
<li>hibernate 和 IBatis 的区别？</li>
<li>抽象能力，乐高模式，怎么提高研发效率</li>
<li>什么情况用接口，什么情况用消息</li>
<li>加密与解密：MD5，SHA1、DES、AES、RSA、DSA <a href="https://github.com/aalansehaiyang/sort-algorithm/blob/master/doc/encry.md" target="_blank" rel="noopener">link</a></li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>基于zookeeper实现的分布式锁</title>
    <url>/sa/lock-zk/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>用zk原生api实现的锁，大致思想：</p>
<a id="more"></a>
<p>每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序临时节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。可以避免服务宕机导致的锁无法释放，而产生的死锁问题。</p>
<p>示例：<a href="http://www.cnblogs.com/liuyang0/p/6800538.html" target="_blank" rel="noopener">http://www.cnblogs.com/liuyang0/p/6800538.html</a></p>
<p>来看下Zookeeper可能存在一些问题：</p>
<ul>
<li><p>锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。</p>
</li>
<li><p>非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。</p>
</li>
<li><p>不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。</p>
</li>
<li><p>单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。</p>
</li>
</ul>
<h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><ul>
<li>性能上不如使用缓存实现分布式锁。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同步到所有的Follower机器上。</li>
</ul>
<ul>
<li>另外Zookeeper也有可能存在并发问题，只是不常见而已。由于网络抖动，客户端与ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了，从而导致并发问题。解决方案，zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。）</li>
</ul>
<h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><p>有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。</p>
<h1 id="三者比较"><a href="#三者比较" class="headerlink" title="三者比较"></a>三者比较</h1><ul>
<li>从理解的难易程度角度（从低到高）</li>
</ul>
<p>数据库 &gt; 缓存 &gt; Zookeeper</p>
<ul>
<li>从实现的复杂性角度（从低到高）</li>
</ul>
<p>Zookeeper &gt;= 缓存 &gt; 数据库</p>
<ul>
<li>从性能角度（从高到低）</li>
</ul>
<p>缓存 &gt; Zookeeper &gt;= 数据库</p>
<ul>
<li>从可靠性角度（从高到低）</li>
</ul>
<p>Zookeeper &gt; 缓存 &gt; 数据库</p>
<h1 id="可以直接使用zookeeper第三方库Curator方便地实现分布式锁，代码示例"><a href="#可以直接使用zookeeper第三方库Curator方便地实现分布式锁，代码示例" class="headerlink" title="可以直接使用zookeeper第三方库Curator方便地实现分布式锁，代码示例"></a>可以直接使用zookeeper第三方库Curator方便地实现分布式锁，代码示例</h1><p><a href="https://github.com/xuyang0902/zklock/blob/master/src/main/java/com/tongbanjie/zk/lock/core/ZkDistributedLock.java" target="_blank" rel="noopener">https://github.com/xuyang0902/zklock/blob/master/src/main/java/com/tongbanjie/zk/lock/core/ZkDistributedLock.java</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Curator提供的InterProcessMutex是分布式锁的实现。</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取锁（阻塞，直到抢到锁）</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">acquire</span><span class="params">()</span> </span></span><br><span class="line"><span class="function">Acquire the mutex - blocking until it's available. Note: the same thread can call acquire re-entrantly. Each call to acquire must be balanced by a call to <span class="title">release</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">//提供带入参方法，支持超时释放</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">acquire</span><span class="params">(<span class="keyword">long</span> time,TimeUnit unit)</span> </span></span><br><span class="line"><span class="function">Acquire the mutex - blocks until it's available or the given time expires. Note: the same thread can call acquire re-entrantly. Each call to acquire that returns <span class="keyword">true</span> must be balanced by a call to <span class="title">release</span><span class="params">()</span> </span></span><br><span class="line"><span class="function">Parameters: </span></span><br><span class="line"><span class="function">time - time to wait </span></span><br><span class="line"><span class="function">unit - time unit </span></span><br><span class="line"><span class="function">Returns: </span></span><br><span class="line"><span class="function"><span class="keyword">true</span> <span class="keyword">if</span> the mutex was acquired, <span class="keyword">false</span> <span class="keyword">if</span> not</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">// 释放锁</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>

<p>官方提供的示例：</p>
<p><a href="https://github.com/apache/curator/blob/master/curator-examples/src/main/java/locking/ExampleClientThatLocks.java" target="_blank" rel="noopener">https://github.com/apache/curator/blob/master/curator-examples/src/main/java/locking/ExampleClientThatLocks.java</a></p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>锁相关</title>
    <url>/sa/lock/</url>
    <content><![CDATA[<hr>
<a id="more"></a>









]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务介绍</title>
    <url>/sa/microservice-introduce/</url>
    <content><![CDATA[<h1 id="什么是微服务架构？"><a href="#什么是微服务架构？" class="headerlink" title="什么是微服务架构？"></a>什么是微服务架构？</h1><p>形像一点来说，微服务架构就像搭积木，每个微服务都是一个零件，并使用这些零件组装出不同的形状。通俗来说，微服务架构就是把一个大系统按业务功能分解成多个职责单一的小系统，并利用简单的方法使多个小系统相互协作，组合成一个大系统。</p>
<a id="more"></a>
<p>如果学科派一点，微服务架构就是把因相同原因而变化的功能聚合到一起，而把因不同原因而变化的功能分离开，并利用轻量化机制（通常为 HTTP RESTful API）实现通信。</p>
<p>微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相协作（通常是基于 HTTP 协议的 RESTful API）。每个服务都围绕着具体业务进行构建，并且能够被独立的部署到生产环境、类生产环境等。另外，对具体的服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建  。（摘自王磊先生的《微服务架构与实践》）</p>
<p>对于我个人，我更喜欢一种延续性的解释，微服务架构 ≈ 模块化开发 + 分布式计算。不管微服务架构的定义怎么样，都是在描述一个核心思想：把大系统拆分成小型系统，把大事化小，以降低系统的复杂性，从而大幅降低系统建设、升级、运维的风险和成本。</p>
<blockquote>
<p>“微服务” 与 “微服务架构” 是有本质区别的。“微服务”强调的是服务的大小，它关注的是某一个点。而“微服务架构”则是一种架构思想，需要从整体上对软件系统进行通盘的考虑。</p>
</blockquote>
<h1 id="常见的微服务组件及概念"><a href="#常见的微服务组件及概念" class="headerlink" title="常见的微服务组件及概念"></a>常见的微服务组件及概念</h1><ul>
<li>服务注册，服务提供方将自己调用地址注册到服务注册中心，让服务调用方能够方便地找到自己。</li>
<li>服务发现，服务调用方从服务注册中心找到自己需要调用的服务的地址。</li>
<li>负载均衡，服务提供方一般以多实例的形式提供服务，负载均衡功能能够让服务调用方连接到合适的服务节点。并且，节点选择的工作对服务调用方来说是透明的。</li>
<li>服务网关，服务网关是服务调用的唯一入口，可以在这个组件是实现用户鉴权、动态路由、灰度发布、A/B 测试、负载限流等功能。</li>
<li>配置中心，将本地化的配置信息（properties, xml, yaml 等）注册到配置中心，实现程序包在开发、测试、生产环境的无差别性，方便程序包的迁移。</li>
<li>API 管理，以方便的形式编写及更新 API 文档，并以方便的形式供调用者查看和测试。</li>
<li>集成框架，微服务组件都以职责单一的程序包对外提供服务，集成框架以配置的形式将所有微服务组件（特别是管理端组件）集成到统一的界面框架下，让用户能够在统一的界面中使用系统。</li>
<li>分布式事务，对于重要的业务，需要通过分布式事务技术（TCC、高可用消息服务、最大努力通知）保证数据的一致性。</li>
<li>调用链，记录完成一个业务逻辑时调用到的微服务，并将这种串行或并行的调用关系展示出来。在系统出错时，可以方便地找到出错点。</li>
<li>支撑平台，系统微服务化后，系统变得更加碎片化，系统的部署、运维、监控等都比单体架构更加复杂，那么，就需要将大部分的工作自动化。现在，可以通过 Docker 等工具来中和这些微服务架构带来的弊端。 例如持续集成、蓝绿发布、健康检查、性能健康等等。严重点，以我们两年的实践经验，可以这么说，如果没有合适的支撑平台或工具，就不要使用微服务架构。</li>
</ul>
<h1 id="什么场景需要用微服务架构？"><a href="#什么场景需要用微服务架构？" class="headerlink" title="什么场景需要用微服务架构？"></a>什么场景需要用微服务架构？</h1><p>软件研发是一个系统工程，它没有银弹，不能够一招鲜吃遍天。正如当年的 CMMI 和敏捷方法一样，敏捷虽好，但它不一定能适用于所有的场景，它对组织环境、团队氛围、沟通方式、技术能力这些都是有一些要求的，如果用不好，反而会带来一些负面影响。</p>
<p>我们什么时候需要采用微服务呢？从我个人的经验来看，我认为有三种场景可以考虑使用微服务。</p>
<ul>
<li>规模大（团队超过 10 人）</li>
<li>业务复杂度高（系统超过 5 个子模块）</li>
<li>需要长期演进（项目开发和维护周期超过半年）</li>
</ul>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/10.png/w600">

<p>横轴是复杂度，纵轴是生产效率。从生产效率的角度来讲，在两条曲线的交叉点之前，单体架构是占优势的，过了交叉点之后，单体架构的生产效率将大幅度下降。</p>
<p>摘自<a href="https://mp.weixin.qq.com/s/mR73cZ7eoS1Bj-sMetccpQ" target="_blank" rel="noopener">《重识微服务架构》</a></p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>汉字转拼音</title>
    <url>/sa/pinyin/</url>
    <content><![CDATA[<ul>
<li><a href="https://github.com/belerweb/pinyin4j" target="_blank" rel="noopener">pinyin4j github源码</a></li>
<li><a href="http://blog.csdn.net/qq_19707521/article/details/76055480" target="_blank" rel="noopener">java 获取中文拼音首字母(缩写)</a></li>
</ul>
<a id="more"></a>

]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>重试</title>
    <url>/sa/re-try/</url>
    <content><![CDATA[<p><strong>重试： 这个故障是暂时的，不是永久的，我们才会去重试。</strong></p>
<p>设计重试时，一定要结合业务场景，定义出什么情况下需要重试。（比如：调用超时）</p>
<a id="more"></a>
<p><strong>一些错误最好不要重试，如：</strong></p>
<ul>
<li>没有权限</li>
<li>非法请求数据</li>
<li>数据格式不正确</li>
</ul>
<h1 id="设计要点"><a href="#设计要点" class="headerlink" title="设计要点"></a>设计要点</h1><ul>
<li>要确定什么样的错误才需要重试</li>
<li>重试的时间和重试的次数</li>
<li>超时重试次数，或是一段时间，那么重试就没有意义了。此后对于新来的请求，就没有必要再进行重试了。此时新来的请求直接返回错误即可。</li>
<li>重试要考虑被调用方是否支持幂等设计</li>
<li>可以借助框架，如 Spring Annotation，不用侵入业务代码</li>
<li>对于有事务相关的操作。我们可能会希望能重试成功，而不至于走业务补偿那样的复杂的回退流程。对此，我们可能需要一个比较长的时间来做重试，但是我们需要保存住请求的上下文，这可能对程序的运行有比较大的开销，因此，有一些设计会先把这样的上下文暂存在本机或是数据库中，然后腾出资源来去做别的事，过一会再回来把之前的请求从存储中捞出来重试。</li>
</ul>
<h1 id="重试的策略"><a href="#重试的策略" class="headerlink" title="重试的策略"></a>重试的策略</h1><p>要有最大值，经过一段时间的重试后，没有必要再重试了。重试可能加重网络负担。</p>
<p>Exponential Backoff （指数策略）</p>
<p>如：第一次等 200ms；第二次等400ms；第三次等800ms</p>
<h1 id="Spring-重试策略"><a href="#Spring-重试策略" class="headerlink" title="Spring 重试策略"></a>Spring 重试策略</h1><p><a href="https://github.com/spring-projects/spring-retry" target="_blank" rel="noopener">https://github.com/spring-projects/spring-retry</a></p>
<p>以AOP的方式通过Annotation的方式使用。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Service</span><br><span class="line">public interface MyService &#123;</span><br><span class="line">    @Retryable(</span><br><span class="line">      value &#x3D; &#123; SQLException.class &#125;, </span><br><span class="line">      maxAttempts &#x3D; 2,</span><br><span class="line">      backoff &#x3D; @Backoff(delay &#x3D; 5000))</span><br><span class="line">    void retryService(String sql) throws SQLException;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>配置 @Retryable 注解，只对 SQLException 的异常进行重试，重试两次，每次延时 5000ms。相关的细节可以看相应的文档。我在这里，只想让你看一下 Spring 有哪些重试的策略。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RetryTemplate template &#x3D; new RetryTemplate();</span><br><span class="line"></span><br><span class="line">TimeoutRetryPolicy policy &#x3D; new TimeoutRetryPolicy();</span><br><span class="line">policy.setTimeout(30000L);</span><br><span class="line"></span><br><span class="line">template.setRetryPolicy(policy);</span><br><span class="line"></span><br><span class="line">Foo result &#x3D; template.execute(new RetryCallback&lt;Foo&gt;() &#123;</span><br><span class="line"></span><br><span class="line">    public Foo doWithRetry(RetryContext context) &#123;</span><br><span class="line">        &#x2F;&#x2F; Do stuff that might fail, e.g. webservice operation</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<ul>
<li><p>NeverRetryPolicy：只允许调用 RetryCallback 一次，不允许重试。</p>
</li>
<li><p>AlwaysRetryPolicy：允许无限重试，直到成功，此方式逻辑不当会导致死循环。</p>
</li>
<li><p>SimpleRetryPolicy：固定次数重试策略，默认重试最大次数为 3 次，RetryTemplate 默认使用的策略。</p>
</li>
<li><p>TimeoutRetryPolicy：超时时间重试策略，默认超时时间为 1 秒，在指定的超时时间内允许重试。</p>
</li>
<li><p>CircuitBreakerRetryPolicy：有熔断功能的重试策略，需设置 3 个参数 openTimeout、resetTimeout 和 delegate；关于熔断，会在后面描述。</p>
</li>
<li><p>CompositeRetryPolicy：组合重试策略。有两种组合方式，乐观组合重试策略是指只要有一个策略允许重试即可以，悲观组合重试策略是指只要有一个策略不允许重试即不可以。但不管哪种组合方式，组合中的每一策略都会执行。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>软硬件性能</title>
    <url>/sa/software-performance/</url>
    <content><![CDATA[<h2 id="内存相关"><a href="#内存相关" class="headerlink" title="内存相关"></a>内存相关</h2><ul>
<li><a href="https://www.cnblogs.com/lyhero11/p/5120847.html" target="_blank" rel="noopener">cpu缓存java性能问题初探</a></li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>如何不停机完成单表拆分</title>
    <url>/sa/split-table/</url>
    <content><![CDATA[<p>在业务发展的早期，为了快速迭代及时响应市场需求，通常架构比较简单，比如数据库表，开始是单表，但随着业务的发展，数据量逐步膨胀，开始考虑分库分表。</p>
<a id="more"></a>

<h1 id="本文以交易系统的订单表为例："><a href="#本文以交易系统的订单表为例：" class="headerlink" title="本文以交易系统的订单表为例："></a>本文以交易系统的订单表为例：</h1><p>订单通常分为两张表：</p>
<ul>
<li>订单主表（order_main）</li>
</ul>
<table>
<thead>
<tr>
<th>描述</th>
<th>字段名</th>
</tr>
</thead>
<tbody><tr>
<td>订单id</td>
<td>order_id</td>
</tr>
<tr>
<td>买家id</td>
<td>buyer_id</td>
</tr>
<tr>
<td>卖家id</td>
<td>seller_id</td>
</tr>
<tr>
<td>下单时间</td>
<td>create_order_time</td>
</tr>
<tr>
<td>付款时间</td>
<td>pay_time</td>
</tr>
<tr>
<td>发货时间</td>
<td>deliver_time</td>
</tr>
<tr>
<td>买家确认收货时间</td>
<td>confirm_receive_goods_time</td>
</tr>
<tr>
<td>订单金额</td>
<td>order_sum</td>
</tr>
<tr>
<td>订单状态</td>
<td>order_status</td>
</tr>
<tr>
<td>其它业务字段</td>
<td>。。。</td>
</tr>
</tbody></table>
<ul>
<li>订单明细表（order_entry）</li>
</ul>
<table>
<thead>
<tr>
<th>描述</th>
<th>字段名</th>
</tr>
</thead>
<tbody><tr>
<td>明细id</td>
<td>order_entry_id</td>
</tr>
<tr>
<td>订单id</td>
<td>order_id</td>
</tr>
<tr>
<td>商品名称</td>
<td>product_name</td>
</tr>
<tr>
<td>商品id</td>
<td>product_id</td>
</tr>
<tr>
<td>商品金额</td>
<td>product_price</td>
</tr>
<tr>
<td>购买数量</td>
<td>quantity</td>
</tr>
<tr>
<td>物流单id</td>
<td>logistics_order_id</td>
</tr>
<tr>
<td>快照id</td>
<td>snapshot_id</td>
</tr>
<tr>
<td>明细状态</td>
<td>entry_status</td>
</tr>
<tr>
<td>其它业务字段</td>
<td>。。。</td>
</tr>
</tbody></table>
<p>注意点：</p>
<ul>
<li>订单主表与明细表一对多关系</li>
<li>每时每刻都有新的数据进来，可能是新增订单，也可能是订单修改，业务方不接受停机迁移方案</li>
</ul>
<p>问题：</p>
<ul>
<li>老order_main的订单id采用mysql自增方式，如果采用分表比如1024张，关于订单id肯定要提供单独的id生成器服务</li>
<li>迁移到新表，采用新的订单id，老的订单id与新的订单id需要建立映射关系</li>
</ul>
<h1 id="核心步骤"><a href="#核心步骤" class="headerlink" title="核心步骤"></a>核心步骤</h1><h2 id="一、双写"><a href="#一、双写" class="headerlink" title="一、双写"></a>一、双写</h2><p>原来的创建订单接口上，增加新库的写入逻辑</p>
<p>过程：</p>
<ul>
<li>老库创建订单</li>
<li>申请新的订单号（为了查库方便，新订单分表键采用订单号，订单号采用id序列号+buyer_userId后6位组成，理论上可最多分100W张表）<ul>
<li>这样分的好处，无论是按买家维度查订单列表，还是按订单号查询，都能快速定位到具体表</li>
</ul>
</li>
<li>在新库创建订单</li>
<li>并建立新老order_id之间的映射关系</li>
</ul>
<p>新订单，如果是修改操作，新、老表都同时修改，保证事务。</p>
<p>老订单，修改操作，只操作老表</p>
<h2 id="二、全量数据迁移"><a href="#二、全量数据迁移" class="headerlink" title="二、全量数据迁移"></a>二、全量数据迁移</h2><ul>
<li>启动任务，开始全量迁移老表的数据，到新的表中，返回新的order_id</li>
<li>并建立新老order_id之间的映射关系</li>
</ul>
<p>注：</p>
<ul>
<li>老的订单要在老库完结。此时对老库表记录修改时，需要发kakfa，异步任务监听，同步数据到新表</li>
</ul>
<h2 id="三、读切到新库"><a href="#三、读切到新库" class="headerlink" title="三、读切到新库"></a>三、读切到新库</h2><ul>
<li>所有依赖于老的订单表的接口，增加中间层逻辑</li>
<li>先根据老的订单号查新的订单号</li>
<li>将流量切到新的订单服务接口</li>
</ul>
<p>注意：</p>
<ul>
<li>上面的步聚2和3之间会有时间间隔，所以这段时间的订单修改记录要单独存储</li>
<li>在步骤3完成后，对这些增量数据再做一次同步</li>
</ul>
<h2 id="四、下双写"><a href="#四、下双写" class="headerlink" title="四、下双写"></a>四、下双写</h2><ul>
<li>对老订单表的写依赖下线</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>通用技术方案选型</title>
    <url>/sa/technology-selection/</url>
    <content><![CDATA[<h2 id="权限控制管理"><a href="#权限控制管理" class="headerlink" title="权限控制管理"></a>权限控制管理</h2><ul>
<li><a href="https://github.com/apache/shiro" target="_blank" rel="noopener">shiro源码</a></li>
<li><a href="http://jinnianshilongnian.iteye.com/blog/2018398" target="_blank" rel="noopener">跟我学Shiro目录贴</a></li>
<li><a href="https://github.com/zhangkaitao/shiro-example" target="_blank" rel="noopener">shiro-example</a></li>
</ul>
<h2 id="授权、鉴权"><a href="#授权、鉴权" class="headerlink" title="授权、鉴权"></a>授权、鉴权</h2><ul>
<li><a href="https://oauth.net/2/" target="_blank" rel="noopener">OAuth官网</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html" target="_blank" rel="noopener">理解OAuth 2.0</a></li>
<li><a href="http://ifeve.com/oauth2-tutorial-all/" target="_blank" rel="noopener">OAuth 2.0系列教程</a></li>
</ul>
<h2 id="流量分发"><a href="#流量分发" class="headerlink" title="流量分发"></a>流量分发</h2><ul>
<li><a href="http://www.iteye.com/blogs/subjects/nginx-lua" target="_blank" rel="noopener">跟我学Nginx+Lua开发</a></li>
<li><a href="http://openresty.org/cn/installation.html" target="_blank" rel="noopener">通过 Lua 扩展 NGINX 实现的可伸缩的 Web 平台 – openresty</a></li>
<li><a href="https://openresty.org/cn/" target="_blank" rel="noopener">OpenResty官网</a></li>
<li><a href="https://www.adroitlogic.com/" target="_blank" rel="noopener">企业服务总线 — UltraESB</a></li>
</ul>
<h2 id="GateWay网关"><a href="#GateWay网关" class="headerlink" title="GateWay网关"></a>GateWay网关</h2><ul>
<li><a href="http://blog.csdn.net/zeb_perfect/article/details/52008192" target="_blank" rel="noopener">spring cloud 实现服务发现、网关路由、负载均衡</a></li>
</ul>
<h2 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h2><ul>
<li>经纬度查询<ul>
<li><a href="http://blog.csdn.net/medea_yang/article/details/53436460" target="_blank" rel="noopener">mongoDB查询某个经纬度附近的用户</a></li>
<li><a href="http://blog.csdn.net/huangrunqing/article/details/9112227" target="_blank" rel="noopener">结合MongoDB开发LBS应用</a></li>
</ul>
</li>
</ul>
<h2 id="链路跟踪"><a href="#链路跟踪" class="headerlink" title="链路跟踪"></a>链路跟踪</h2><ul>
<li><a href="">阿里鹰眼</a></li>
<li><a href="https://github.com/openzipkin/zipkin" target="_blank" rel="noopener">Zipkin</a></li>
</ul>
<h2 id="数据库、缓存、文件存储"><a href="#数据库、缓存、文件存储" class="headerlink" title="数据库、缓存、文件存储"></a>数据库、缓存、文件存储</h2><ul>
<li><a href="http://www.memsql.com/" target="_blank" rel="noopener">内存数据库 — memsql</a></li>
<li><a href="http://www.cnblogs.com/mafly/p/fastdfs.html" target="_blank" rel="noopener">分布式文件存储系统 — FastDFS</a></li>
<li><a href="http://raychase.iteye.com/blog/1545906" target="_blank" rel="noopener">本地缓存、磁盘存储 — Ehcache</a></li>
<li><a href="https://github.com/google/leveldb" target="_blank" rel="noopener">kv存储 — levelDB</a></li>
<li><a href="http://www.open-open.com/13.htm" target="_blank" rel="noopener">若干缓存框架汇总</a></li>
<li>通用缓存 JetCache<ul>
<li><a href="https://mp.weixin.qq.com/s/qzS6fPUj70MW7LuMbefWZQ" target="_blank" rel="noopener">通用缓存访问JetCache介绍</a></li>
<li><a href="https://mp.weixin.qq.com/s/HvJwP5mWegDZYUO6TAeJ1g" target="_blank" rel="noopener">JetCache的异步API访问Redis缓存</a></li>
</ul>
</li>
<li><a href="InfluxDB.md">时间序列数据库 — InfluxDB</a></li>
<li><a href="http://www.kairosdb.com/" target="_blank" rel="noopener">基于Cassandra存储的快速时间序列数据库 — KairosDB</a></li>
<li><a href="https://www.yiibai.com/postgresql/" target="_blank" rel="noopener">关系数据库管理系统 — PostgreSQL</a></li>
</ul>
<h2 id="服务治理"><a href="#服务治理" class="headerlink" title="服务治理"></a>服务治理</h2><ul>
<li><a href="http://blog.csdn.net/xyang81/article/details/52556886" target="_blank" rel="noopener">主从心跳检测 — Keepalived</a></li>
</ul>
<h2 id="模块化、隔离"><a href="#模块化、隔离" class="headerlink" title="模块化、隔离"></a>模块化、隔离</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/AhNIvlKNba8ls9loM1CZ-w" target="_blank" rel="noopener">基于JAVA的模块化开发框架 — JarsLink</a></li>
</ul>
<h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><ul>
<li><a href="https://baike.baidu.com/item/Confluence" target="_blank" rel="noopener">文档管理 — Confluence</a></li>
<li><a href="">jira</a></li>
<li><a href="">禅道</a></li>
</ul>
<h2 id="测试、部署、打包"><a href="#测试、部署、打包" class="headerlink" title="测试、部署、打包"></a>测试、部署、打包</h2><ul>
<li><a href="https://www.liaoxuefeng.com/article/001463233913442cdb2d1bd1b1b42e3b0b29eb1ba736c5e000" target="_blank" rel="noopener">持续集成 — Jenkins</a></li>
<li><a href="http://blog.csdn.net/hunterno4/article/details/11687269" target="_blank" rel="noopener">代码质量管理 — Sonar</a></li>
<li><a href="">findbug</a></li>
<li><a href="http://jmeter.apache.org/" target="_blank" rel="noopener">性能压测 — jmeter</a></li>
<li><a href="">性能压测 — jprofiler</a></li>
<li>自动化<ul>
<li><a href="http://www.selenium.org.cn/" target="_blank" rel="noopener">自动化测试工具 — selenium</a></li>
</ul>
</li>
</ul>
<h2 id="图形、图表、图片"><a href="#图形、图表、图片" class="headerlink" title="图形、图表、图片"></a>图形、图表、图片</h2><ul>
<li><a href="http://echarts.baidu.com/index.html" target="_blank" rel="noopener">数据可视化图表 — ECharts</a></li>
<li><a href="https://www.hcharts.cn/" target="_blank" rel="noopener">数据可视化图表 — highcharts</a></li>
<li><a href="https://zhitu.isux.us/" target="_blank" rel="noopener">图片压缩、格式转换 — 智图</a></li>
</ul>
<h2 id="网站性能优化"><a href="#网站性能优化" class="headerlink" title="网站性能优化"></a>网站性能优化</h2><ul>
<li><a href="https://www.cnblogs.com/wajika/p/6278825.html" target="_blank" rel="noopener">网站优化工具 — Yslow</a></li>
</ul>
<h2 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h2><ul>
<li><a href="http://blog.csdn.net/eason_oracle/article/details/53535173" target="_blank" rel="noopener">ETL工具 — kettle</a></li>
</ul>
<h2 id="通用型"><a href="#通用型" class="headerlink" title="通用型"></a>通用型</h2><ul>
<li><a href="https://github.com/jobbole/awesome-java-cn" target="_blank" rel="noopener">Java生态圈框架汇总—可能会有满足你的</a></li>
</ul>
<h2 id="动态管理Class字节码"><a href="#动态管理Class字节码" class="headerlink" title="动态管理Class字节码"></a>动态管理Class字节码</h2><ul>
<li><a href="">Javassist</a></li>
<li><a href="groovy.md">groovy</a></li>
</ul>
<h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><ul>
<li><a href="https://yq.aliyun.com/articles/227006" target="_blank" rel="noopener">日志数据监控 —- Grafana</a></li>
</ul>
<h2 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h2><ul>
<li><a href="FreeMarker.md">商品详情页的静态化 — FreeMarker</a></li>
<li><a href="http://www.yiibai.com/apache_poi/" target="_blank" rel="noopener">Apache poi 操作 excel、word、pdf</a></li>
<li><a href="jsoup.md">java 解析HTML页面 — jsoup</a></li>
<li><a href="https://mp.weixin.qq.com/s/Zxxarev-HwAH2MUzB4QbBA" target="_blank" rel="noopener">Java 生成 PDF</a></li>
<li><a href="http://blog.csdn.net/yinwenjie/article/details/51692340" target="_blank" rel="noopener">基于规则路由和处理的引擎 — Apache Camel</a></li>
<li><a href="pinyin.md">汉字转拼音</a></li>
<li>字符串表达式动态求值<ul>
<li><a href="https://github.com/killme2008/aviator/wiki" target="_blank" rel="noopener">aviator</a></li>
<li><a href="http://blog.csdn.net/sunnyyoona/article/details/75244442" target="_blank" rel="noopener">MVEL</a></li>
</ul>
</li>
<li><a href="https://github.com/benjamine/jsondiffpatch" target="_blank" rel="noopener">json数据比对 — jsondiffpatch</a></li>
<li><a href="https://www.cnblogs.com/zerotomax/p/7255950.html" target="_blank" rel="noopener">无头浏览器 — HtmlUnit</a></li>
<li><a href="https://www.jianshu.com/p/054b50026f9a" target="_blank" rel="noopener">Java爬虫 — cdp4j</a></li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式锁</title>
    <url>/sa/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
    <content><![CDATA[<p>高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。</p>
<a id="more"></a>
<p>对多个资源、数据库表、对象同时加锁时,需要保持一致的加锁顺序,否则可能会造成死锁。<br>说明:线程一需要对表 A、B、C 依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是 A、B、C，否则可能出现死锁。</p>
<h2 id="分布式锁特点："><a href="#分布式锁特点：" class="headerlink" title="分布式锁特点："></a><strong>分布式锁特点：</strong></h2><ul>
<li>安全性。在任意时刻，只有一个客户端可以获得锁（排他性）</li>
<li>避免死锁。client最终一定可以获得锁，即使锁住资源的客户端在release锁之前崩溃或不可达</li>
<li>容错性。只要锁服务集群中的大部分节点存活，Client 就可以进行加锁解锁操作。</li>
</ul>
<h2 id="分布式锁服务，你需要考虑下面几个设计"><a href="#分布式锁服务，你需要考虑下面几个设计" class="headerlink" title="分布式锁服务，你需要考虑下面几个设计"></a><strong>分布式锁服务，你需要考虑下面几个设计</strong></h2><ul>
<li>需要给一个锁被释放的方式，以避免请求者不把锁还回来，导致死锁的问题。Redis 使用超时时间，ZooKeeper 可以依靠自身的 sessionTimeout 来删除节点。</li>
<li>分布式锁服务应该是高可用的，而且需要持久化。可以参考 <a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">Redis 的文档 RedLock</a>  </li>
<li>非阻塞方式的锁服务。</li>
<li>支持锁的可重入性。</li>
</ul>
<h3 id="1-使用redis的setnx-、expire-方法"><a href="#1-使用redis的setnx-、expire-方法" class="headerlink" title="1.使用redis的setnx()、expire()方法"></a>1.使用redis的setnx()、expire()方法</h3><p>这个方案相对于memcached()的add()方案，redis占优势的是，其支持的数据类型更多，而memcached只支持String一种数据类型。除此之外，无论是从性能上来说，还是操作方便性来说，其实都没有太多的差异，完全看你的选择，比如公司中用哪个比较多，你就可以用哪个。</p>
<p>首先说明一下setnx()命令，setnx的含义就是SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果key不存在，则设置当前key成功，返回1；如果当前key已经存在，则设置当前key失败，返回0。但是要注意的是setnx命令不能设置key的超时时间，只能通过expire()来对key设置。</p>
<p><strong>具体的使用步骤如下:</strong></p>
<ol>
<li><p>setnx(lockkey, 1)  如果返回0，则说明占位失败；如果返回1，则说明占位成功</p>
</li>
<li><p>expire()命令对lockkey设置超时时间，为的是避免死锁问题。</p>
</li>
<li><p>执行完业务代码后，可以通过delete命令删除key。</p>
</li>
</ol>
<p>这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。比如，如果在第一步setnx执行成功后，在expire()命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用redis的setnx()、get()和getset()方法来实现分布式锁。  </p>
<h3 id="2-使用redis的setnx-、get-、getset-方法"><a href="#2-使用redis的setnx-、get-、getset-方法" class="headerlink" title="2.使用redis的setnx()、get()、getset()方法"></a>2.使用redis的setnx()、get()、getset()方法</h3><p>这个方案的背景主要是在setnx()和expire()的方案上针对可能存在的死锁问题，做了一版优化。</p>
<p>那么先说明一下这三个命令，对于setnx()和get()这两个命令，相信不用再多说什么。那么getset()命令？这个命令主要有两个参数 getset(key，newValue)。该方法是原子的，对key设置newValue这个值，并且返回key原来的旧值。假设key原来是不存在的，那么多次执行这个命令，会出现下边的效果：</p>
<ol>
<li><p>getset(key, “value1″)  返回nil   此时key的值会被设置为value1</p>
</li>
<li><p>getset(key, “value2″)  返回value1   此时key的值会被设置为value2</p>
</li>
<li><p>依次类推！</p>
</li>
</ol>
<p>介绍完要使用的命令后，具体的使用步骤如下：</p>
<ol>
<li><p>setnx(lockkey, 当前时间+过期超时时间) ，如果返回1，则获取锁成功；如果返回0则没有获取到锁，转向2。</p>
</li>
<li><p>get(lockkey)获取值oldExpireTime ，并将这个value值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向3。</p>
</li>
<li><p>计算newExpireTime=当前时间+过期超时时间，然后getset(lockkey, newExpireTime) 会返回当前lockkey的值currentExpireTime。</p>
</li>
<li><p>判断currentExpireTime与oldExpireTime 是否相等，如果相等，说明当前getset设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</p>
</li>
<li><p>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行delete释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</p>
</li>
</ol>
<h3 id="3-SET-NX（推荐）"><a href="#3-SET-NX（推荐）" class="headerlink" title="3.SET NX（推荐）"></a>3.SET NX（推荐）</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET resource_name my_random_value NX PX 30000</span><br></pre></td></tr></table></figure>
<p><a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">Redis 的官方文档</a></p>
<ul>
<li><p>my_random_value是由客户端生成的一个随机字符串，相当于是客户端持有锁的标志</p>
</li>
<li><p>NX表示只有当resource_name对应的key值不存在的时候才能SET成功，相当于只有第一个请求的客户端才能获得锁</p>
</li>
<li><p>PX 30000表示这个锁有一个30秒的自动过期时间。</p>
</li>
</ul>
<p>至于解锁，为了防止客户端1获得的锁，被客户端2给释放,采用下面的Lua脚本来释放锁</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then </span><br><span class="line">    return redis.call(&quot;del&quot;,KEYS[1]) </span><br><span class="line">else </span><br><span class="line">    return 0 </span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>在执行这段LUA脚本的时候，KEYS[1]的值为resource_name，ARGV[1]的值为my_random_value。原理就是先获取锁对应的value值，保证和客户端传进去的my_random_value值相等，这样就能避免自己的锁被其他人释放。另外，采取Lua脚本操作保证了原子性。</p>
<p>例如，下面的例子演示了不区分 Client 会导致错误</p>
<ul>
<li>Client A 获得了一个锁。</li>
<li>当尝试释放锁的请求发送给 Redis 时被阻塞，没有及时到达Redis</li>
<li>锁定时间超时，Redis 认为锁的租约到期，释放了这个锁。</li>
<li>Client B 重新申请到了这个锁。</li>
<li>Client A 的解锁请求到达，将 Client B 锁定的key解锁</li>
<li>Client C 也获得了锁。</li>
<li>Client B 和 Client C 同时持有锁。</li>
</ul>
<p>通过执行上面脚本的方式释放锁，Client 的解锁操作只会解锁自己曾经加锁的资源，所以是安全的。</p>
<h3 id="常用的四种方案"><a href="#常用的四种方案" class="headerlink" title="常用的四种方案"></a>常用的四种方案</h3><ol>
<li><p>基于数据库表做乐观锁，用于分布式锁。</p>
</li>
<li><p>使用memcached的add()方法，用于分布式锁。</p>
</li>
<li><p>使用redis的setnx()、expire()方法，用于分布式锁。</p>
</li>
<li><p>使用redis的setnx()、get()、getset()方法，用于分布式锁。</p>
</li>
</ol>
<h3 id="其它资料"><a href="#其它资料" class="headerlink" title="其它资料"></a>其它资料</h3><p><a href="http://mp.weixin.qq.com/s/JTsJCDuasgIJ0j95K8Ay8w?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="noopener">http://mp.weixin.qq.com/s/JTsJCDuasgIJ0j95K8Ay8w?utm_source=tuicool&amp;utm_medium=referral</a></p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>大型网站技术架构</title>
    <url>/sa/%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<p>早期的网站为了节省成本一般会设计成集中式系统，应用程序、数据库等都部署在一台服务器上。<br>但随着业务的快速度发展，逐渐出现瓶颈，按一定原则<strong>（应用拆分、服务拆分、数据拆分、应用解耦）</strong>，向分布式系统转型，涉及到以下环节改造。</p>
<a id="more"></a>
<h1 id="主要环节"><a href="#主要环节" class="headerlink" title="主要环节"></a>主要环节</h1><ul>
<li>业务拆分：将整个网站业务拆分成不同的应用，每个应用独立部署维护，应用之间通过RPC或消息队列通信。</li>
<li>集群化（应用服务器；基于RPC的微服务应用等）</li>
<li>LVS负载均衡，负责将请求转发给不同业务集群</li>
<li>反向代理服务器，常用的如Nginx</li>
<li>应用服务器，servlet容器，如tomcat</li>
<li>应用和数据服务分离，分别部署在不同的服务器</li>
<li>后端应用合理分层，通常分为表现层或网关层、业务逻辑层、数据持久层</li>
<li>缓存。分为两种：本地缓存；分布式缓存</li>
<li>CDN化。静态内容部署到CDN，就近获取，加速网站响应。</li>
<li>数据库读写分离。数据库采用主从热备，应用服务器在写数据时访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库。</li>
<li>分库分表，引入分布式数据框架</li>
<li>引入NoSQL，支持海量数据存储</li>
<li>借助elastics search等开源搜索引擎</li>
<li>异步化，系统解耦。<ul>
<li>缩短业务流程，加快网站访问速度</li>
<li>消除并发访问高峰</li>
</ul>
</li>
</ul>
<h1 id="架构五要素："><a href="#架构五要素：" class="headerlink" title="架构五要素："></a>架构五要素：</h1><ul>
<li>高性能</li>
<li>可用性(Availability)</li>
<li>伸缩性(Scalability)</li>
<li>扩展性(Extensibility)</li>
<li>安全性</li>
</ul>
<h3 id="1、高性能"><a href="#1、高性能" class="headerlink" title="1、高性能"></a>1、高性能</h3><p>性能的测试指标主要有：</p>
<ul>
<li>响应时间：指应用执行一个操作需要的时间</li>
<li>并发数：指系统能够同时处理请求的数目</li>
<li>QPS：指单位时间内系统处理的请求量</li>
<li>系统性能计数器：描述服务器或者操作系统性能的一些数据指标</li>
</ul>
<p>性能优化，根据网站分层架构，可以分为三大类：</p>
<ul>
<li>Web 前端性能优化<ul>
<li>减少 http 请求</li>
<li>使用浏览器缓存</li>
<li>启用压缩</li>
<li>CSS 放在页面最上面，JavaScript 放在页面最下面</li>
<li>减少 Cookie 传输</li>
</ul>
</li>
</ul>
<ul>
<li><p>应用服务器性能优化：主要手段有 缓存、集群、异步</p>
<ul>
<li>多线程(设计为无状态，使用局部对象，并发访问资源使用锁)</li>
<li>资源复用(单例，对象池)</li>
<li>数据结构</li>
<li>异步操作(消息队列，削峰作用)</li>
<li>多台应用服务器组成一个集群共同对外服务，提高整体处理能力。</li>
<li>使用 CDN，将网站静态内容分发至离用户最近的网络服务商机房，使用户通过最短访问路径获取数据。可以在网站机房部署反向代理服务器，缓存热点文件，加快请求响应速度，减轻应用服务器负载压力</li>
<li>应用服务器端，可以使用服务器本地缓存和分布式缓存(网站性能优化第一定律：优化考虑使用缓存优化性能)</li>
<li>代码层面，也可以通过使用多线程、改善内存管理等手段优化性能。</li>
<li>数据库服务器端，索引、缓存、SQL 优化等性能优化手段</li>
<li>NoSQL 数据库通过优化数据模型、存储结构、伸缩特性等</li>
</ul>
<ul>
<li>存储服务器性能优化<ul>
<li>机械硬盘 vs. 固态硬盘</li>
<li>B+ 树 vs. LSM 树</li>
<li>RAID vs. HDFS</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2、高可用"><a href="#2、高可用" class="headerlink" title="2、高可用"></a>2、高可用</h3><p>高可用的网站架构：目的是保证服务器硬件故障时服务依然可用、数据依然保存并能够被访问，主要手段数据和服务的冗余备份及失效转移</p>
<ul>
<li>高可用的应用：显著特点是应用的无状态性<ul>
<li>通过负载均衡进行无状态服务的失效转移</li>
<li>应用服务器集群的 Session 管理</li>
</ul>
</li>
<li>高可用的服务：无状态的服务，可使用类似负载均衡的失效转移策略，此外还有如下策略<ul>
<li>超时设置</li>
<li>异步调用</li>
<li>服务降级</li>
<li>限流</li>
</ul>
</li>
<li>高可用的数据：主要手段是数据备份和失效转移机制<ul>
<li>失效确认</li>
<li>访问转移</li>
<li>数据恢复</li>
<li>冷备：缺点是不能保证数据最终一致和数据可用性</li>
<li>热备：分为异步热备和同步热备</li>
<li>数据一致性(Consisitency)</li>
<li>数据可用性(Availibility)</li>
<li>分区耐受性(Partition Tolerance)</li>
<li>CAP 原理</li>
<li>数据备份</li>
</ul>
</li>
<li>软件质量保证<ul>
<li>自动化测试</li>
<li>预发布验证</li>
<li>灰度发布</li>
</ul>
</li>
<li>网站实时监控<ul>
<li>警报系统</li>
<li>自动优雅降级</li>
<li>用户行为日志采集（服务器端和客户端）</li>
<li>服务器性能监控</li>
<li>监控数据采集</li>
<li>监控管理</li>
</ul>
</li>
</ul>
<h3 id="3、伸缩性"><a href="#3、伸缩性" class="headerlink" title="3、伸缩性"></a>3、伸缩性</h3><p>大型网站需要面对大量用户的高并发访问和存储海量数据，不可能只用一台服务器就处理全部用户请求，存储全部数据。网站通过集群的方式将多台服务器组成一个整体共同提供服务。所谓伸缩性是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。</p>
<p>衡量架构伸缩性的主要标准就是是否可以用多台服务器构建集群，是否容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来的服务器无差别的服务。集群中可容纳的总的服务器数量是否有限制。</p>
<p>对于应用服务器集群，只要服务器上不保存数据，所有服务器都是对等的，通过使用合适的负载均衡设备就可以向集群中不断加入服务器。</p>
<p>对于缓存服务器集群，加入新的服务器可能会导致缓存路由失效，进而导致集群中大部分缓存数据都无法访问。虽然缓存的数据可以通过数据库重新预热，但是如果应用已经严重依赖缓存，可能会导致整个网站崩溃。需要改进缓存路由算法保证缓存数据的可访问性。</p>
<p>关系数据库虽然支持数据复制，主从热备等机制，但是很难做到大规模集群的可伸缩性，因此关系数据库的集群伸缩性方案必须在数据库之外实现，通过路由分区等手段将部署有多个数据库的服务器组成一个集群。</p>
<p>至于大部分 NoSQL 数据库产品，由于其先天就是为海量数据而生，因此其对伸缩性的支持通常都非常好，可以做到在较少运维参与的情况下实现集群规模的线性伸缩。</p>
<p>概括起来伸缩性的分为如下几个方面：</p>
<ul>
<li>应用服务器集群的伸缩性设计<ul>
<li>轮询(Round Robin, RR)</li>
<li>加权轮询(Weighted Round Robin, WRR)</li>
<li>随机(Random)</li>
<li>最少链接(Least Connections)</li>
<li>源地址散列(Source Hashing)</li>
<li>DNS 域名解析负载均衡</li>
<li>反向代理负载均衡(在 HTTP 协议层面，应用层负载均衡)</li>
<li>IP 负载均衡(在内核进程完成数据分发)</li>
<li>数据链路层负载均衡(数据链路层修改 mac 地址，三角传输模式，LVS)</li>
</ul>
</li>
<li>分布式缓存集群的伸缩性设计<ul>
<li>Memcached 客户端（包括 API，路由算法，服务器列表，通信模块）</li>
<li>Memcached 服务器集群</li>
<li>分布式缓存的一致性 Hash 算法(一致性 Hash 环，虚拟层)</li>
</ul>
</li>
<li>数据存储服务集群的伸缩性设计<ul>
<li>关系数据库集群的伸缩性设计</li>
<li>NoSQL 数据库的伸缩性设计</li>
</ul>
</li>
</ul>
<h3 id="4、可扩展"><a href="#4、可扩展" class="headerlink" title="4、可扩展"></a>4、可扩展</h3><p>系统架构设计层面的“开闭原则”，构建可扩展的网站架构</p>
<ul>
<li>利用分布式消息队列降低耦合性<pre><code>* 分布式消息队列</code></pre><ul>
<li>事件驱动架构(Event Driven Architecture)</li>
</ul>
</li>
<li>利用分布式服务打造可复用的业务平台<ul>
<li>分布式服务框架设计(Thrift，Dubbo)</li>
</ul>
</li>
<li>可扩展的数据结构(如 HBase的 ColumnFamily 设计)</li>
<li>利用开放平台建设网站生态圈</li>
</ul>
<h3 id="5、网站的安全架构"><a href="#5、网站的安全架构" class="headerlink" title="5、网站的安全架构"></a>5、网站的安全架构</h3><p>XSS 攻击和 SQL 注入攻击是构成网站应用攻击最主要的两种手段，此外还包括 CSRF,Session 劫持等手段。</p>
<ul>
<li>攻击与防御<ul>
<li>Error Code</li>
<li>表单 Token</li>
<li>验证码</li>
<li>jsonp请求的，Referer 校验</li>
<li>SQL 注入</li>
<li>html 危险字符转义</li>
<li>XSS 攻击：跨站点脚本攻击（Cross Site Script）<blockquote>
<p>对js转义，使其失去执行功能，只作为纯字符串展示</p>
</blockquote>
</li>
<li>CSRF 攻击：跨站点请求伪造（Cross Site  Request Forgery）<blockquote>
<p>防范：httpOnly;增加token校验;通过Referer识别。 </p>
</blockquote>
</li>
<li>网站安全漏洞扫描</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>如何设计API的限流</title>
    <url>/sa/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1API%E7%9A%84%E9%99%90%E6%B5%81/</url>
    <content><![CDATA[<p>可用性和可靠性对于所有 Web 应用程序和 API 服务至关重要。如果您提供 API 服务，您可能体会过流量突增对服务质量的影响，甚至可能造成服务中断。</p>
<a id="more"></a>

<h1 id="限制流量可以使-API-服务在下面的场景中更可靠："><a href="#限制流量可以使-API-服务在下面的场景中更可靠：" class="headerlink" title="限制流量可以使 API 服务在下面的场景中更可靠："></a>限制流量可以使 API 服务在下面的场景中更可靠：</h1><ul>
<li><p>某个用户直接或间接造成了流量飙升，我们需要确保对其他用户服务可用。</p>
</li>
<li><p>某个用户向 API 服务发送大量请求。 或者更糟的是，某个用户试图恶意冲垮服务器。</p>
</li>
<li><p>用户发送了大量低优先级请求，但我们希望确保不会影响其他高优先级请求。 例如，发送大量分析数据请求的用户可能会影响其他用户的关键事务。</p>
</li>
<li><p>系统内部产生错误，导致无法处理所有请求，不得不丢弃低优先级的请求。</p>
</li>
</ul>
<h1 id="限流器和负载降级"><a href="#限流器和负载降级" class="headerlink" title="限流器和负载降级"></a>限流器和负载降级</h1><p>限流器用于控制在网络上发送或接收的流量速率。什么时候应该使用限流器？If your users can afford to change the pace at which they hit your API endpoints without affecting the outcome of their requests</p>
<p>用户可以产生很多请求：例如，批处理支付请求会导致 API 流量持续升高。用户总是可以扩展他们的请求，而不受限流器的影响。</p>
<p>限流器对于大部分使用场景是十分高效的，但有时我们需要完全丢弃低优先级的请求，以确保更多关键请求的处理，这称为负载降级（load shedder）。</p>
<p>负载降级可以根据系统的整体状态而不是正在请求的用户来进行决策。它可以帮助我们应对突发事件，确保核心部分正常工作。</p>
<h2 id="不同类型的限流器"><a href="#不同类型的限流器" class="headerlink" title="不同类型的限流器"></a>不同类型的限流器</h2><h2 id="1-请求限流器"><a href="#1-请求限流器" class="headerlink" title="1.请求限流器"></a>1.请求限流器</h2><p>该限流器限制每个用户每秒可发送 N 个请求。</p>
<p>我们的请求限流器在本月已经拒绝了数百万个请求，特别是对于用户无意运行脚本产生的测试请求。</p>
<p>我们的 API 在测试和生产模式下提供相同的速率/流量限制行为。 这样做有利于开发人员的体验：在从开发切换到生产模式时，程序或脚本不会遇到副作用。</p>
<p>在分析了我们的流量模式之后，我们为请求限流器增加了适应请求激增的能力，比如用于电商中的抢购。</p>
<h2 id="2-并发请求限流器"><a href="#2-并发请求限流器" class="headerlink" title="2.并发请求限流器"></a>2.并发请求限流器</h2><p>相对于第一种请求限流器，限制每秒最高请求数，这种限流器则是限制最高并发请求数。有些 API endpoint 对外部资源依赖多，用户经常处于请求－等待返回－重试。这些重试继续加剧了已经超载的服务。并发请求限流器有助于很好地解决这个问题。</p>
<p>我们的并发请求限流器很少被触发，本月只有12000次请求，它帮助我们有效地控制 CPU 密集型 API enpoint。在我们开始使用并发请求限流器之前，我们经常需要处理由于用户同一时间产生太多请求而造成的资源争用。并发请求限流器完全解决了这个问题。</p>
<h2 id="3-基于使用量的负载降级"><a href="#3-基于使用量的负载降级" class="headerlink" title="3.基于使用量的负载降级"></a>3.基于使用量的负载降级</h2><p>我们将流量分为两种类型：关键 API 请求（例如，创建订单）和非关键请求（例如，列出历史订单）。我们有一个 Redis 集群，用于计算当前每种类型的请求数量。</p>
<p>我们总是为关键请求预留一小部分冗余。例如，我们的预留比例是20％，那么超过 80％ 的非关键请求将被拒绝服务，并返回503的状态码。</p>
<h2 id="4-基于-Worker-利用率的负载降级"><a href="#4-基于-Worker-利用率的负载降级" class="headerlink" title="4.基于 Worker 利用率的负载降级"></a>4.基于 Worker 利用率的负载降级</h2><p>大多数 API 服务使用一组 worker 线程以并行方式独立地处理请求并响应。 这种负载降级是最后的防线。</p>
<p>我们将流量分为4类组成：</p>
<ul>
<li>关键 API 请求</li>
<li>HTTP POST 方法</li>
<li>HTTP GET 方法</li>
<li>测试请求</li>
</ul>
<p>我们追踪可用的 worker 数量。如果某个 worker 太忙，无法处理分配给它的请求，它会缓慢降级非关键请求，当然是先从测试请求开始。如果降低测试请求的过程中，worker 的处理能力恢复到好的状态，那我们就可以开始缓慢地恢复流量（取消降级）。</p>
<p>缓慢地进行降级和恢复是非常重要的！比如这个场景：“我完全丢弃了测试请求的流量，一切都很好！我把它恢复回来，噢一切又变糟了！”。我们用了大量的尝试和错误来调整降级和恢复的速率。</p>
<p>这种负载降级限制了已经发生事件的影响，控制了近一步的损害，比如你们知道的“雪崩效应”。</p>
<h2 id="构建限流器实践"><a href="#构建限流器实践" class="headerlink" title="构建限流器实践"></a>构建限流器实践</h2><p>上面已经概述了我们使用的四种类型的限流器，接下来我们来谈谈它们的实现。有什么限流算法？以及如何实现？</p>
<p>我们使用<a href="https://en.wikipedia.org/wiki/Token_bucket" target="_blank" rel="noopener">令牌桶算法</a>  来进行流量限制。该算法有一个集中的桶，为每一个请求分配一个令牌，并不断地缓慢地在桶中放入令牌。 如果桶为空，则拒绝该请求。在我们的例子中，每个用户都被分配一个桶，每当他们产生一个请求时，我们从这个桶中移除一个令牌。</p>
<p>我们通过 Redis 来实现我们的限速器。 既可以自己搭建和运维 Redis 实例，或者如果已经使用 AWS，则可以使用 ElastiCache 这样的托管服务。</p>
<p><strong>当你考虑要实现类似的限流器时，要注意下面几点：</strong></p>
<ul>
<li><p>将限流器安全地插入到您的中间件链（middleware chain）中。要确保如果限流器代码中出现错误（例如 Redis 发生故障），请求不会受到影响。需要捕获所有级别的异常，以确保 API 正常工作。</p>
</li>
<li><p>向用户显示清晰明白的异常。首先确定将什么样的异常显示给用户。比如是否将 HTTP 429 或 HTTP 503 展示给用户。同时任何返回给用户的信息应该是可操作的，以避免用户不知所措。</p>
</li>
<li><p>建立保障措施，以确保可以关闭限流器。确保有“终极大杀器”可以完全禁用限流器，设置报警和监控指标以了解触发频率。</p>
</li>
<li><p>低峰启动或发布，并注意观察流量变化。评估每个限流的策略并做出调整。找到不影响用户现有请求模式下的限流阈值。这可能涉及与用户的开发人员一起修改其代码，以便新的限流策略对他们有效。</p>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>流量限制是使 API 具备水平扩展最有效的方法之一。 这篇文章中描述的不同限流策略在一开始并不是必需的，一旦你意识到需要限流的话，你可以逐渐地引入它们。</p>
<p>我们的建议按照以下步骤为基础设施引入限流策略和机制：</p>
<ul>
<li><p>首先建立一个请求限流器。 它是防止“请求洪流”最重要，也是我们最常用的一种限流器。</p>
</li>
<li><p>逐渐地引入后面三种限流器，以应对不同类别的问题。</p>
</li>
<li><p>在基础架构中添加新的限流策略和限流器时，应遵循良好的启动发布方式。 应随时处理错误，随时可关闭，同时依靠监控指标来查看其触发频率。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>性能优化之Qps</title>
    <url>/sa/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BQps/</url>
    <content><![CDATA[<h2 id="性能优化之Qps"><a href="#性能优化之Qps" class="headerlink" title="性能优化之Qps"></a>性能优化之Qps</h2><ul>
<li>QPS受到编程语言影响</li>
<li>QPS主要是受到编程模型的影响，比如说是不是NIO啊，有没有阻塞啊。</li>
<li>QPS主要是你的业务逻辑决定的，业务逻辑越复杂，QPS越低 </li>
</ul>
<a id="more"></a>
<ul>
<li>QPS是受到数据结构和算法的影响</li>
<li>QPS是受到线程数的影响</li>
<li>QPS是受到系统瓶颈的影响（cpu核数）</li>
<li>QPS和RT关系非常紧密</li>
</ul>
<p>RT = Thread CPU Time + Thread Wait Time</p>
<p>最佳线程数=(RT/CPU Time) * CPU cores * CPU利用率</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/1.jpg/w600">

<img data-src="http://f.ngall-in.com/alan87/static/images/sa/2.jpg/w600">

<p>cpu核数由硬件决定，而cpu time和利用率则由我们的代码决定。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>数字签名</title>
    <url>/sa/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D/</url>
    <content><![CDATA[<p>签名方法对接口进行鉴权，所有接口每一次请求都需要包含签名信息（signature 参数），<strong>以验证用户身份，防止信息被恶意篡改。</strong></p>
<a id="more"></a>
<h1 id="申请安全凭证"><a href="#申请安全凭证" class="headerlink" title="申请安全凭证"></a>申请安全凭证</h1><p>在第一次使用 API 之前，需申请安全凭证，安全凭证包括 SecretId 和 SecretKey ，SecretId 是用于标识 API 调用者的身份，SecretKey 是用于加密签名字符串和服务器端验证签名字符串的密钥。SecretKey 必须严格保管，避免泄露。</p>
<h1 id="签名生成算法"><a href="#签名生成算法" class="headerlink" title="签名生成算法"></a>签名生成算法</h1><p>签名生成方法如下：</p>
<ul>
<li>对所有请求参数（包括公有参数和私有参数，但不包括 signature 参数），按照参数名ASCII码表升序顺序排序。如：foo=1， bar=2， foo_bar=3， baz=4 排序后的顺序是 bar=2， baz=4， foo=1， foobar=3。</li>
<li>将排序好的参数名和参数值构造成字符串，格式为：key1+value1+key2+value2… 。根据上面的示例得到的构造结果为：bar2baz4foo1foobar3 。</li>
<li>选择与 secretId 配对的 secretKey ，加到上一步构造好的参数字符串之后，如 secretKey=6308afb129ea00301bd7c79621d07591 ，则最后的参数字符串为 bar2baz4foo1foobar36308afb129ea00301bd7c79621d07591。</li>
<li>把拼装好的字符串采用 utf-8 编码，使用 MD5 算法对字符串进行摘要，计算得到 signature 参数值，将其加入到接口请求参数中即可。MD5 是128位长度的摘要算法，用16进制表示，一个十六进制的字符能表示4个位，所以签名后的字符串长度固定为32位十六进制字符。</li>
</ul>
<h1 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 生成签名信息</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> secretKey 产品私钥</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> params 接口请求参数名和参数值map，不包括signature参数名</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> UnsupportedEncodingException</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">genSignature</span><span class="params">(String secretKey, Map&lt;String, String&gt; params)</span> <span class="keyword">throws</span> UnsupportedEncodingException </span>&#123;</span><br><span class="line">    <span class="comment">// 1. 参数名按照ASCII码表升序排序</span></span><br><span class="line">    String[] keys = params.keySet().toArray(<span class="keyword">new</span> String[<span class="number">0</span>]);</span><br><span class="line">    Arrays.sort(keys);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 按照排序拼接参数名与参数值</span></span><br><span class="line">    StringBuffer paramBuffer = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    <span class="keyword">for</span> (String key : keys) &#123;</span><br><span class="line">        paramBuffer.append(key).append(params.get(key) == <span class="keyword">null</span> ? <span class="string">""</span> : params.get(key));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 3. 将secretKey拼接到最后</span></span><br><span class="line">    paramBuffer.append(secretKey);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. MD5是128位长度的摘要算法，用16进制表示，一个十六进制的字符能表示4个位，所以签名后的字符串长度固定为32个十六进制字符。</span></span><br><span class="line">    <span class="keyword">return</span> DigestUtils.md5Hex(paramBuffer.toString().getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库架构</title>
    <url>/sa/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<h2 id="主要会经历以下几个步骤："><a href="#主要会经历以下几个步骤：" class="headerlink" title="主要会经历以下几个步骤："></a>主要会经历以下几个步骤：</h2><ul>
<li>早期的单台MySQL服务器（Just Running）</li>
<li>主从复制</li>
<li>读写分离</li>
<li>SSD优化</li>
<li>按业务垂直分库</li>
<li>水平sharding分库（物理层面），逻辑上还是一张表</li>
</ul>
<a id="more"></a>

<h2 id="MySQL主从复制"><a href="#MySQL主从复制" class="headerlink" title="MySQL主从复制"></a>MySQL主从复制</h2><p>传统单库很容易出现单点问题，所以会增加备库，利用主从复制，将写数据实时同步到备库里，同时主备库间增加心跳检测，一旦检测到主库不可用时，自动切换到备库。大大提高了系统的可用性。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/5.jpg/w600">

<p>主从复制也带来其他一系列性能瓶颈问题：</p>
<ul>
<li><p>写入无法扩展</p>
</li>
<li><p>复制延时</p>
</li>
</ul>
<h2 id="MySQL读写分离"><a href="#MySQL读写分离" class="headerlink" title="MySQL读写分离"></a>MySQL读写分离</h2><p>原理是让master数据库处理写操作，slave数据库处理读操作。master将写操作的变更同步到各个slave节点。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/8.jpg/w600">

<p>提高系统性能的原因在于：</p>
<ul>
<li>物理服务器增加，机器处理能力提升。拿硬件换性能。</li>
<li>主从只负责各自的读和写，极大程度缓解X锁和S锁争用。</li>
<li>slave可以配置myiasm引擎，提升查询性能以及节约系统开销。</li>
<li>master直接写是并发的，slave通过主库发送来的binlog恢复数据是异步。</li>
<li>slave可以单独设置一些参数来提升其读的性能。</li>
<li>增加冗余，提高可用性。</li>
</ul>
<p>MySQL官方提供的数据库代理层产品MySQLProxy搭建读写分离。</p>
<p>MySQLProxy实际上是在客户端请求与MySQLServer之间建立了一个连接池。所有客户端请求都是发向MySQLProxy，然后经由MySQLProxy进行相应的分析，判断出是读操作还是写操作，分发至对应的MySQLServer上。对于多节点Slave集群，也可以起做到负载均衡的效果。</p>
<h2 id="MySQL垂直分区"><a href="#MySQL垂直分区" class="headerlink" title="MySQL垂直分区"></a>MySQL垂直分区</h2><p>如果把业务切割得足够独立，那把不同业务的数据放到不同的数据库服务器将是一个不错的方案，而且万一其中一个业务崩溃了也不会影响其他业务的正常进行，并且也起到了负载分流的作用，大大提升了数据库的吞吐能力。经过垂直分区后的数据库架构图如下：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/6.jpg/w600">

<p>尽管业务之间已经足够独立了，但是有些业务之间或多或少总会有点联系，如用户，基本上都会和每个业务相关联，况且这种分区方式，也不能解决单张表数据量暴涨的问题。</p>
<h2 id="MySQL水平分片（Sharding）"><a href="#MySQL水平分片（Sharding）" class="headerlink" title="MySQL水平分片（Sharding）"></a>MySQL水平分片（Sharding）</h2><p>这是一个非常好的思路，将用户按一定规则（按id哈希）分组，并把该组用户的数据存储到一个数据库分片中，即一个sharding，这样随着用户数量的增加，只要简单地配置一台服务器即可，原理图如下：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/7.jpg/w600">

]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>架构原则</title>
    <url>/sa/%E6%9E%B6%E6%9E%84%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<h2 id="架构原则"><a href="#架构原则" class="headerlink" title="架构原则"></a>架构原则</h2><ol>
<li>满足业务发展需求是最高准则</li>
<li>业务建模，抽象和枚举是两种方式，需要平衡，不能走极端</li>
</ol>
<a id="more"></a>
<ol start="3">
<li>模型要能更真实的反应事物的本质，不是名词概念的堆砌，不能过度设计</li>
<li>基础架构最关键的是分离不同业务领域、不同技术领域，让整个系统具有持续优化的能力。</li>
<li>分离基础服务、业务规则、业务流程，选择合适的工具外化业务规则和业务流程</li>
<li>分离业务组件和技术组件，高类聚，低耦合 - 业务信息的执行可以分散，但业务信息的管理要尽量集中</li>
<li>不要让软件的逻辑架构与最后物理部署绑死 - 选择合适的技术而不是高深的技术，随着业务的发展调整使用的技术</li>
<li>好的系统架构需要合适的组织架构去保障 - 团队成员思想的转变，漫长而艰难</li>
</ol>
<p><strong>CPU运算速度&gt;&gt;&gt;&gt;&gt;内存的读写速度&gt;&gt;磁盘读写速度</strong></p>
<hr>
<h2 id="精彩文章"><a href="#精彩文章" class="headerlink" title="精彩文章"></a>精彩文章</h2><ul>
<li><a href="https://app.yinxiang.com/Home.action#n=376d7f6d-22a8-4092-a340-4a7d62d8baa9&ses=4&sh=2&sds=5&" target="_blank" rel="noopener">技术不应成为业务的工具</a></li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>架构思想</title>
    <url>/sa/%E6%9E%B6%E6%9E%84%E6%80%9D%E6%83%B3/</url>
    <content><![CDATA[<p>关于什么是架构，一种比较通俗的说法是 “最高层次的规划，难以改变的决定”，这些规划和决定奠定了事物未来发展的方向和最终的蓝图。</p>
<a id="more"></a>
<p>从这个意义上说，人生规划也是一种架构。选什么学校、学什么专业、进什么公司、找什么对象，过什么样的生活，都是自己人生的架构。</p>
<p>具体到软件架构，维基百科是这样定义的：“有关软件整体结构与组件的抽象描述，用于指导大型软件系统各个方面的设计”。系统的各个重要组成部分及其关系构成了系统的架构，这些组成部分可以是具体的功能模块，也可以是非功能的设计与决策，他们相互关系组成一个整体，共同构成了软件系统的架构。</p>
<p>架构其实就是把复杂的问题抽象化、简单化，可能你会觉得“说起来容易但做起来难”，如何能快速上手。可以多观察，根据物质决定意识，借助生活真实场景（用户故事，要很多故事）来还原这一系列问题，抓住并提取核心特征。</p>
<h1 id="架构思想"><a href="#架构思想" class="headerlink" title="架构思想"></a>架构思想</h1><p>CPU运算速度&gt;&gt;&gt;&gt;&gt;内存的读写速度&gt;&gt;&gt;&gt;磁盘读写速度</p>
<ul>
<li>满足业务发展需求是最高准则</li>
<li>业务建模，抽象和枚举是两种方式，需要平衡，不能走极端</li>
<li>模型要能更真实的反应事物的本质，不是名词概念的堆砌，不能过度设计</li>
<li>基础架构最关键的是分离不同业务领域、不同技术领域，让整个系统具有持续优化的能力。</li>
<li>分离基础服务、业务规则、业务流程，选择合适的工具外化业务规则和业务流程</li>
<li>分离业务组件和技术组件，高类聚，低耦合 - 业务信息的执行可以分散，但业务信息的管理要尽量集中</li>
<li>不要让软件的逻辑架构与最后物理部署绑死 - 选择合适的技术而不是高深的技术，随着业务的发展调整使用的技术</li>
<li>好的系统架构需要合适的组织架构去保障 - 团队成员思想的转变，漫长而艰难</li>
<li>业务架构、系统架构、数据模型</li>
</ul>
<h1 id="面对一块新业务，如何系统架构？"><a href="#面对一块新业务，如何系统架构？" class="headerlink" title="面对一块新业务，如何系统架构？"></a>面对一块新业务，如何系统架构？</h1><ul>
<li>业务分析：输出业务架构图，这个系统里有多少个业务模块，从前台用户到底层一共有多少层。</li>
<li>系统划分：根据业务架构图输出系统架构图，需要思考的是这块业务划分成多少个系统，可能一个系统能支持多个业务。基于什么原则将一个系统拆分成多个系统？又基于什么原则将两个系统合并成一个系统？</li>
<li>系统分层：系统是几层架构，基于什么原则将一个系统进行分层，分成多少层？</li>
<li>模块化：系统里有多少个模块，哪些需要模块化？基于什么原则将一类代码变成一个模块。</li>
</ul>
<h1 id="如何模块化"><a href="#如何模块化" class="headerlink" title="如何模块化"></a>如何模块化</h1><ul>
<li>基于水平切分。把一个系统按照业务类型进行水平切分成多个模块，比如权限管理模块，用户管理模块，各种业务模块等。</li>
<li>基于垂直切分。把一个系统按照系统层次进行垂直切分成多个模块，如DAO层，SERVICE层，业务逻辑层。</li>
<li>基于单一职责。将代码按照职责抽象出来形成一个一个的模块。将系统中同一职责的代码放在一个模块里。比如我们开发的系统要对接多个渠道的数据，每个渠道的对接方式和数据解析方式不一样，为避免不同渠道代码的相互影响，我们把各个渠道的代码放在各自的模块里。</li>
<li>基于易变和不易变。将不易变的代码抽象到一个模块里，比如系统的比较通用的功能。将易变的代码放在另外一个或多个模块里，比如业务逻辑。因为易变的代码经常修改，会很不稳定，分开之后易变代码在修改时候，不会将BUG传染给不变的代码。</li>
</ul>
<h1 id="提升系统的稳定性"><a href="#提升系统的稳定性" class="headerlink" title="提升系统的稳定性"></a>提升系统的稳定性</h1><ul>
<li>流控</li>
</ul>
<p>双11期间，对于一些重要的接口（比如帐号的查询接口，店铺首页）做流量控制，超过阈值直接返回失败。<br>另外对于一些不重要的业务也可以考虑采用降级方案，大促—&gt;邮件系统。根据28原则，提前将大卖家约1W左右在缓存中预热，并设置起止时间，活动期间内这部分大卖家不发交易邮件提醒，以减轻SA邮件服务器的压力。</p>
<ul>
<li>容灾</li>
</ul>
<p>最大程度保证主链路的可用性，比如我负责交易的下单，而下单过程中有优惠的业务逻辑，此时需要考虑UMP系统挂掉，不会影响用户下单（后面可以通过修改价格弥补），采用的方式是，如果优惠挂掉，重新渲染页面，并增加ump屏蔽标记，下单时会自动屏蔽ump的代码逻辑。<br>另外还会记录ump系统不可用次数，一定时间内超过阈值，系统会自动报警。</p>
<ul>
<li>稳定性</li>
</ul>
<p>第三方系统可能会不稳定，存在接口超时或宕机，为了增加系统的健壮性，调用接口时设置超时时间以及异常捕获处理。</p>
<ul>
<li>容量规划</li>
</ul>
<p>做好容量规划、系统间强弱依赖关系梳理。<br>如：冷热数据不同处理，早期的订单采用oracle存储，随着订单的数量越来越多，查询缓慢，考虑数据迁移，引入历史表，将已归档的记录迁移到历史表中。当然最好的方法是分库分表。</p>
<h1 id="分布式架构"><a href="#分布式架构" class="headerlink" title="分布式架构"></a>分布式架构</h1><ul>
<li>分布式系统</li>
<li>分布式缓存</li>
<li>分布式数据</li>
</ul>
<h1 id="API-和乐高积木有什么相似之处？"><a href="#API-和乐高积木有什么相似之处？" class="headerlink" title="API 和乐高积木有什么相似之处？"></a>API 和乐高积木有什么相似之处？</h1><p>相信我们大多数人在儿童时期都喜欢玩乐高积木。乐高积木的真正乐趣和吸引力在于，尽管包装盒外面都带有示意图片，但你最终都可以随心所欲得搭出各种样子或造型。</p>
<p>对 API 的最佳解释就是它们像乐高积木一样。我们可以用创造性的方式来组合它们，而不用在意它们原本的设计和实现意图。</p>
<p>你可以发现很多 API 和乐高积木的相似之处：</p>
<ul>
<li><p>标准化：通用、标准化的组件，作为基本的构建块（building blocks）；</p>
</li>
<li><p>可用性：强调可用性，附有文档或使用说明；</p>
</li>
<li><p>可定制：为不同功能使用不同的API；</p>
</li>
<li><p>创造性：能够组合不同的 API 来创造混搭的结果；</p>
</li>
</ul>
<p>乐高和 API 都有超简单的界面/接口，并且借助这样简单的界面/接口，它可以非常直观、容易、快速得构建。</p>
<p>虽然乐高和 API 一样可能附带示意图片或使用文档，大概描述了推荐玩法或用途，但真正令人兴奋的结果或收获恰恰是通过创造力产生的。</p>
<p>让我们仔细地思考下上述的提法。在很多情况下，API 的使用者构建出了 API 的构建者超出预期的服务或产品，API 使用者想要的，和 API 构建者认为使用者想要的，这二者之间通常有个断层。事实也确实如此，在 IoT 领域，我们使用 API 创造出了一些非常有创造性的使用场景。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-公众号增量消息同步改造</title>
    <url>/sa/%E6%A1%88%E4%BE%8B-%E5%85%AC%E4%BC%97%E5%8F%B7%E5%A2%9E%E9%87%8F%E6%B6%88%E6%81%AF%E5%90%8C%E6%AD%A5%E6%94%B9%E9%80%A0/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>理财社区之前用的是开源的PHP discuz框架，私信也是沿用自带的那套，每次推送活动消息时，会为所有用户插入一条记录，一次就是几百万条记录到表中，db压力很大，而且运营反馈每次任务都要发送很长时间，毕竟是要insert这么多记录，慢也是情理之中。</p>
<a id="more"></a>

<h2 id="优化过程："><a href="#优化过程：" class="headerlink" title="优化过程："></a>优化过程：</h2><p> <strong>第一次优化：</strong></p>
<p>当时写代码的同学已线离职，大致过程如下：</p>
<p>采用<strong>异步拉取</strong>的方式，当用户打开消息列表页时，正常加载数据库数据，同时创建一个异步任务，扔到一个BlockQueue中（会控制长度），同时启动10个消费线程，对任务消费，为当前用户同步最新的公众号增量消息。<br>为了控制频率，15分钟同步一次</p>
<p>缺点：</p>
<p>1.不实时，用户主动打开消息通知页面，并不会马上获取最新消息，而只是触发同步任务，需要第二次打开页面才能看到最新的消息。体验不好</p>
<p> <strong>第二次优化：</strong></p>
<p>公众号消息采用<strong>同步拉取</strong>的方式，大致过程：</p>
<ol>
<li><p>运营发送全量活动消息，入db表，同时扔到最新的消息cache列表</p>
</li>
<li><p>当社区用户打开消息通知页时，会查询上一次的同步时间，并从cache列表中加载最新的公众号增量消息，并修改会话列表&amp;提醒数，异步线程将增量消息插入私信分表中。</p>
</li>
<li><p>按修改时间分页查询会话列表</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">补充：</span><br><span class="line">用户第一次打开消息通知页面，就能获取最新消息，基本上可以满足用户需求，体验也不错。</span><br><span class="line">但产品又提出新的要求，希望在首页可以看到消息数量提醒（如果有新的消息时），刺激用户点击。原来的逻辑是打开通知页时才会同步，现在触发条件又要升级，今天是推荐首页，明天可能是其它页面，有没有会什么通用的方式来收集所有的触发点。</span><br></pre></td></tr></table></figure>

<p> <strong>第三次优化：</strong></p>
<p>这次是对第二次优化的一个补充，扩展增量消息的触发来源！</p>
<p>1.定义并收集“活跃用户”。</p>
<p>改造后的系统（php-&gt;java），每多业务功能都要取当前用户信息，因此就涉及token验证。因此将这样的用户定义为“活跃用户”。token校验成功后，发kafka消息。</p>
<p>2.编写kafka消费任务，触发同步操作</p>
<p>3.由于运营并不会经常用公众号推送消息，所以设定一个间隔时间（距上一次同步15分钟后）才扫描一次。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">绝大部分的扫描都是空处理，设定这个时间间隔就显得很重要，如果太小，扫描频率比较高，系统压力大，实时性会好。反之，扫描频率低，系统压力小，实时性会差一些。</span><br><span class="line">经验先设定15分钟，后面根据情况再调整。</span><br></pre></td></tr></table></figure>

<p>4.考虑并发，看过kafka消息日志，确实挺多，为什么？因为一个页面，比如详情页，会同时请求多个api接口。</p>
<p>并发控制是借助于redis来实现的。</p>
<p>加锁—（成功）—处理业务—释放锁</p>
<p>加锁—（失败）—方法结束，不做任何事情。</p>
<p>其中：加锁和解锁是一对操作，如果因为系统的一些未知异常，导致解锁失败，那么后面可能再也无法拿到锁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isLock</span><span class="params">(Long uid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">long</span> value = bbsRedisClient.incr(KEY_BBS_PUBLIC_SYNC_LOCK + uid);</span><br><span class="line">            <span class="keyword">if</span> (value == <span class="number">1</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">if</span> (value &gt;= <span class="number">14</span>) &#123;</span><br><span class="line">                <span class="comment">// 补偿机制，防止解锁失败时，后面永远无法再拿到锁</span></span><br><span class="line">                releaseLock(uid);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            logger.error(<span class="string">"[MessageCacheManager.isLock] invoke error! uid=&#123;&#125;"</span>, uid);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"> 加锁逻辑，里面加了补偿机制，可能会比较猥琐   </span><br><span class="line"></span><br><span class="line">`</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">releaseLock</span><span class="params">(Long uid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            bbsRedisClient.del(KEY_BBS_PUBLIC_SYNC_LOCK + uid);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            logger.error(<span class="string">"[MessageCacheManager.releaseLock] invoke error! uid=&#123;&#125;"</span>, uid);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 释放锁</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">syncPublicMessage</span><span class="params">(Long uid, <span class="keyword">boolean</span> isAutoCheck)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (uid == <span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Long currentTime = System.currentTimeMillis() / <span class="number">1000</span>;<span class="comment">// 当前时间</span></span><br><span class="line">            Long lastSyncTime = messageCacheManager.getSyncTime(uid); <span class="comment">// 上一次同步时间</span></span><br><span class="line">            <span class="keyword">if</span> (lastSyncTime == <span class="keyword">null</span>) &#123;</span><br><span class="line">                lastSyncTime = <span class="number">0L</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 如果自动同步检测,15分钟同步一次</span></span><br><span class="line">            <span class="keyword">if</span> (isAutoCheck) &#123;</span><br><span class="line">                <span class="keyword">if</span> (lastSyncTime + <span class="number">900</span> &gt; currentTime) &#123;</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 加锁成功，处理业务</span></span><br><span class="line">            <span class="keyword">if</span> (messageCacheManager.isLock(uid)) &#123;</span><br><span class="line">                handleSyncPublicMessage(uid, lastSyncTime, currentTime);</span><br><span class="line">                messageCacheManager.releaseLock(uid);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            messageCacheManager.releaseLock(uid);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>小提醒：</p>
<div class="note warning">
            <ul><li>1.原来逻辑是先加锁–加锁成功–15分钟的频率检测–（根据需要，可能会执行业务逻辑）—再释放锁。这种写法其浪费很多，每次任务执行都要执行加锁、解锁，严重浪费系统开销。</li><li>2.早上上班时，在路上推敲这个过程时，觉的可以将顺序颠倒一下<br>先15分钟的频率检测—加锁—执行业务逻辑—释放锁<br>相信第一步的频率检测就会拦截掉很多请求，也将没有必要抢锁了</li></ul>
          </div>


























]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>架构师的职责与思考</title>
    <url>/sa/%E6%9E%B6%E6%9E%84%E5%B8%88%E7%9A%84%E8%81%8C%E8%B4%A3%E4%B8%8E%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<p>在当下的互联网时代，架构师是互联网行业的热点关键词，人云亦云者居多，那互联网架构师<br>到底是做什么的，如何来评价互联网架构师的优劣呢？</p>
<a id="more"></a>
<h1 id="架构师产生的历史渊源"><a href="#架构师产生的历史渊源" class="headerlink" title="架构师产生的历史渊源"></a>架构师产生的历史渊源</h1><p>互联网应用脱胎于传统软件应用，伴随着要求更为快捷与面向未知需求的互联网应用的兴起，对技术团队的要求也陡然升高，不再是按部就班的开发，而是需要快速迭代、快速响应来自市场和用户的需求和反馈，互联网应用的反应和迭代快慢决定了生死的微妙差别。</p>
<p>互联网时代的变更也带来了技术团队中组织结构和技术栈的快速升级与变化，所有的这些都来自于行业的快速演进和进化。于是乎之前的项目经理带领一帮高级程序员、中级/初级程序猿的组织结构显然已经不太适应时代的需求，产品经理、技术经理、<strong>系统架构师</strong>、数据架构师、运维架构师、前端开发与架构师等等诸多的细分职位与之伴生而为大家所接受和理解。</p>
<p>在这里，我们重点需要讨论的是互联网项目中的软件系统架构师的这个职位。</p>
<h1 id="众人眼中的”架构师”"><a href="#众人眼中的”架构师”" class="headerlink" title="众人眼中的”架构师”"></a>众人眼中的”架构师”</h1><p>在技术团队中，除了众多开发工程师、项目经理、技术经理和产品经理之外，还有一个架构师，通常大家都是把这个职位当作高级工程师中的资深工程师，经验和阅历都很丰富，有问题找他来解决就是了。</p>
<p>整个技术团队的主要管理内容包括： 人员管理、资源协调、进度管理、技术管理等等内容，分别分配到项目经理、技术经理和架构师等类似的职位上，一般架构师这个职位不承担技术之外的管理职能，主要专注于项目所使用的技术栈的评估与选取，关键的技术问题的分析与解决、核心代码和系统的设计与实现等任务；但是在实际的工作中，架构师和技术经理的角色在技术选型和关键部分的把控方面是由冲突和重叠的；另外，在技术团队中，人员和技术方面的工作实际上是无法分开的，重要的原因是人员大部分都是技术人员，其主要的工作是技术工作，很多时候都是需要听取来自专业技术方面的意见和反馈之后，才可以制定相应的排期以及计划，包括风险管理、工作量评估等内容。</p>
<p>在项目经理以及诸多的领导眼里，架构师就是做技术的，技术大牛，整个项目的技术架构以及技术问题都由其来承担和负责，出了问题就是架构师的问题。其实在实际情况中，一个项目出现了问题，固然有技术方面的因素，但是绝大多数情况下，技术都是次要的因素，技术之外的因素往往扮演了各种复杂的角色；产品的成败由业务线（比如产品经理）来负责，产品本身的质量由技术团队来负责，当然这个只是理想的状况下的自然推理。实际的情况，往往南辕北辙，彼此都是纠缠在一起的，业务方面深刻影响了技术架构的选择与设计，快速的业务变化带给技术架构以及技术团队的混乱与损耗都是非常巨大的。</p>
<h1 id="架构师的职责"><a href="#架构师的职责" class="headerlink" title="架构师的职责"></a>架构师的职责</h1><p><font color=red>架构师的职责应该是立足于技术和业务之间的中间角色或者平衡点</font>， 在针对业务深刻理解的基础上，针对业务中存在诸多变数，挑选适合的技术架构和技术方案；结合现有的技术团队的水平与特点，选择合适的技术栈进行落地和实现。</p>
<p>架构师在做每一个决定之时都会受到诸多的因素的限制，比如高效的技术栈需要很高的学习曲线，在工期与人员素质之间需要权衡。精妙的技术架构并不能解决业务的快速迭代和变化，技术架构都是后知后觉的，无法准确的预知业务层面的变更与方向，故只能是跟随的角色，这样就必然会面临技术架构迭代和升级的需求，技术架构从来都不是建立了之后，就无需修改，可以承载各方的多重期望；事实上恰恰相反，<font color=red>技术架构是需要与时俱进的，是不断迭代和升级出来，根据不断变化的业务需求和团队情况来动态调整的。</font></p>
<h1 id="架构师的应变与坚持"><a href="#架构师的应变与坚持" class="headerlink" title="架构师的应变与坚持"></a>架构师的应变与坚持</h1><p>架构师这个职位的优势所在是将技术方面重要的决定由专门的角色来进行负责和跟踪。当然这个职位的出现是基于现有团队功能的重新划分，将原来从属于技术经理的技术职能剥离出来独立成为架构师，必然带来了彼此之间的职能灰色地带；这也就带来一个巨大的隐患冲突： 技术经理和架构师之间的职责边界以及合作沟通。</p>
<p>技术架构的保持、重构与升级都与架构师的沟通技巧、坚持以及妥协技能息息相关，在技术团队之外，其余的角色和上层领导对于技术都是理解肤浅或者不甚了解的；除了自身的关注点之外，对于技术团队所为的技术架构以及业务的变更对于系统的冲击影响不甚关心；一般都是结果导向，在没有如期实现业务功能和目标之前，所谓的“技术架构”的稳定、重构与保持都是没有任何意义的。 所以，架构师需要与业务不停的沟通妥协，在面对对技术架构深远和错误的影响之时，需要有所坚持和信仰，对于对的方向和原则有所坚持；帮助技术团队规避一些人为或者外界带给系统和项目的各种冲击。</p>
<p>所有的这些都是建立在各个层面可以沟通和愿意承担的基础上，如果各个层面不满足这个基本原则，架构师所有的坚持与妥协都会让自身陷入不利的境地，过程中承担各种抱怨，来自技术团队、业务方和公司高层。建议此时，妥协第一，不必坚持，满足业务需求，尽力做好预防性设计，不做错误解决，已是万幸。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在其位，谋其政，站在架构师的职位上，架构师要本着对团队支持、对系统负责，对领导和业务相关方充分沟通与建议的基本准备，充分利用自身的经验与阅历，帮助团队规避各类或深或浅的系统之坑陷，保证业务线的正常运转，同时保持系统具备一定的灵活性、稳定性和可持续开发性。 尽人事，知天命，有所为，有所不为，架构师其实是技术、业务、管理和资源等各类因素之间进行妥协、沟通和协调的角色，混很容易，做好很难。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-新浪微博与理财社区cache对比分析</title>
    <url>/sa/%E6%A1%88%E4%BE%8B-%E5%BE%AE%E5%8D%9A%E4%B8%8E%E7%90%86%E8%B4%A2%E7%A4%BE%E5%8C%BAcache%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h1><p>社交平台由于内容成本较低，重度依赖用户关系，实时互动、动态浏览。对系统性要求较高。新浪微博由于较大的市场占用率，用户量大，在这一领域有很多经验，目前笔者在做的理财社区业务与其有很多相似的地方，可以借鉴。下面会做一些比较分析。</p>
<a id="more"></a>
<h1 id="1-缓存模型设计"><a href="#1-缓存模型设计" class="headerlink" title="1. 缓存模型设计"></a>1. 缓存模型设计</h1><ul>
<li>已发表微博</li>
</ul>
<p>可以使用 Redis 的 hash 来保存已发表微博。</p>
<p>一条微博通常包括多个字段，比如发表时间、发表用户、正文内容等，通常使用微博 id 作为 key 将多个键值对作为 hash 保存在 Redis 中。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/19.png/w600">
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/19.png/w600">


<p>理财社区不象微博有字数限制，所以message字段可能比较大，目前限制最大字符10W，而且该字段的使用场景是在贴子详情页。而推荐页或版块列表页只是展示一些摘要信息。所以内容正文拆成两个维度，根据业务场景各取所需，避免每次大字段传来传去，浪费网络带宽。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/21.png/w600">

<p>计数模型会采用Hash散列的形式，以tid为key，赞数、回复数、浏览数作为field，下图是消息提醒不同子类型业务的计数方式。贴子也是类似设计。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/29.png/w600">

<ul>
<li>信息流</li>
</ul>
<p>当一个用户访问它的首页信息流时候，他可以看到他所有关注用户最新的信息。key 是当前用户的 uid, 信息流的内容以 id –&gt; timestamp 的形式保存在 zset 中，timestamp 用于排序，以便返回的列表是按照时间顺序排列。微博的 id 用于业务下一步获取微博的相关信息。</p>
<p>理财社区由于业务的特殊性，动态流有两部分来源：人工推荐+订阅的版块热门。</p>
<p>但每一块的存储结构采用zset，通过时间戳来排序，有一点区别是里面的field，采用字符串，由“tid|uid”组成，方便后面可以并行取贴子和用户信息。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/25.png/w600">


<ul>
<li>关注与粉丝</li>
</ul>
<p>我们可以把关注及粉丝库也存在 zset 中，依旧使用 timestamp 来排序。key 是当前用户 uid。</p>
<p>了解上述结构之后，我们继续来看如何使用 Redis 来扩展整个系统，具备处理亿级用户的能力。</p>
<p>我们首先要做的，就是在 Redis 能够存储所有数据并且能够正常地处理写查询的情况下，让 Redis 的读查询处理能力超过单台 Redis 服务器所能提供的读查询处理能力。</p>
<h1 id="2-扩展读性能"><a href="#2-扩展读性能" class="headerlink" title="2. 扩展读性能"></a>2. 扩展读性能</h1><p>假定我们用 Redis 构建一个与微博或 Twitter 具有相同特性和功能的社交网站，网站的其中一个特性就是允许用户查看他们自己的 profile 页和个人首页信息流，每当用户访问时，程序就会从信息流里面获取大约 30 条内容。</p>
<p>因为一台专门负责获取信息流的 Redis 服务器每秒至少可以同时为 3,000 ～ 10,000 个用户获取信息流消息，所以这一操作对于规模较小的社交网站来说并不会造成什么问题。</p>
<p>但是对于规模更大的社交网站来说，程序每秒需要获取的信息流消息数量将远远超过单台 Redis 服务器所能处理的上限，因此我们必须想办法提升 Redis 每秒能够获取的信息流消息数量。</p>
<p>下面我们将会讨论如何使用只读的从服务器提升系统处理读查询的性能，使得系统的整体读性能能够超过单台 Redis 服务器所能提供的读查询性能上限。</p>
<p><strong>在对读查询的性能进行扩展，并将额外的服务器用作从服务器以提高系统处理读查询的性能之前，让我们先来回顾一下 Redis 提高性能的几个途径。</strong></p>
<ul>
<li><p>在使用短结构时，请确保压缩列表的最大长度不会太大以至于影响性能。</p>
</li>
<li><p>根据程序需要执行的查询的类型，选择能够为这种查询提供最好性能的结构。比如说，不要把 LIST 当作 SET 使用；也不要获取整个 HASH 然后在客户端里面对其进行排序，而是应该直接使用 ZSET；诸如此类。</p>
</li>
<li><p>在将大体积的对象缓存到 Redis 之前，考虑对它进行压缩以减少读取和写入对象时所需的网络带宽。对比压缩算法 lz4、gzip 和 bzip2，看看哪个算法能够对被存储的数据提供最好的压缩效果和最好的性能。</p>
</li>
<li><p>使用 pipeline（pipeline 是否启用事务性质由具体的程序决定）以及连接池。</p>
</li>
</ul>
<p>在做好了能确保读查询和写查询能够快速执行的一切准备之后，接下来要考虑的就是如何实际解决“怎样才能处理更多读请求”这个正题。</p>
<p><strong>提升 Redis 读取能力的最简单方法，就是添加提供读能力的从服务器。</strong></p>
<p>用户可以运行一些额外的服务器，让它们与主服务器进行连接，然后接受主服务器发送的数据副本并通过网络进行准实时的更新（具体的更新速度取决于网络带宽）。通过将读请求分散到不同的从服务器上面进行处理，用户可以从新添加的从服务器上获得额外的读查询处理能力。</p>
<p><strong>记住：只对主服务器进行写入</strong></p>
<p>在使用只读从服务器的时候，请务必记得只对 Redis 主服务器进行写入。在默认情况下，尝试对一个被配置为从服务器的 Redis 服务器进行写入将引发一个错误（就算这个从服务器是其他从服务器的主服务器，也是如此）。</p>
<p>简单来说，要将一个 Redis 服务器变为从服务器，我们只需要在 Redis 的配置文件里面，加上一条 slaveof host port 语句，并将 host 和 port 两个参数的值分别替换为主服务器的 IP 地址和端口号就可以了。除此之外，我们还可以通过对一个正在运行的 Redis 服务器发送 SLAVEOF host port 命令来把它配置为从服务器。需要注意的一点是，当一个从服务器连接至主服务器的时候，从服务器原本存储的所有数据将被清空。最后，通过向从服务器发送 SLAVEOF no one 命令，我们可以让这个从服务器断开与主服务器的连接。</p>
<p>使用多个 Redis 从服务器处理读查询时可能会遇到的最棘手的问题，就是主服务器临时下线或者永久下线。每当有从服务器尝试与主服务器建立连接的时候，主服务器就会为从服务器创建一个快照，如果在快照创建完毕之前，有多个从服务器都尝试与主服务器进行连接，那么这些从服务器将接收到同一个快照。从效率的角度来看，这种做法非常好，因为它可以避免创建多个快照。</p>
<p>但是，同时向多个从服务器发送快照的多个副本，可能会将主服务器可用的大部分带宽消耗殆尽。使主服务器的延迟变高，甚至导致主服务器已经建立了连接的从服务器断开。</p>
<p>解决从服务器重同步（resync）问题的其中一个方法，就是减少主服务器需要传送给从服务器的数据数量，这可以通过构建树状复制中间层来完成。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/sa/26.png/w600">

<p>从服务器树非常有用，在对不同数据中心（data center）进行复制的时候，这种从服务器树甚至是必需的：通过缓慢的广域网（WAN）连接进行重同步是一件相当耗费资源的工作，这种工作应该交给位于中间层的从服务器去做，而不必劳烦最顶层的主服务器。但是另一方面，构建从服务器树也会带来复杂的网络拓扑结构（topology），这增加了手动和自动处理故障转移的难度。</p>
<p>除了构建树状的从服务器群组之外，解决从服务器重同步问题的另一个方法就是对网络连接进行压缩，从而减少需要传送的数据量。一些 Redis 用户就发现使用带压缩的 SSH 隧道（tunnel）进行连接可以明显地降低带宽占用，比如某个公司就曾经使用这种方法，将复制单个从服务器所需的带宽从原来的 21Mbit 降低为 1.8Mbit（<a href="http://mng.bz/2ivv）。如果读者也打算使用这个方法的话，那么请记得使用" target="_blank" rel="noopener">http://mng.bz/2ivv）。如果读者也打算使用这个方法的话，那么请记得使用</a> SSH 提供的选项来让 SSH 连接在断线后自动重连。</p>
<p><strong>加密和压缩开销</strong></p>
<p>一般来说，使用 SSH 隧道带来的加密开销并不会给服务器造成大的负担，因为2.6 GHz 主频的英特尔酷睿 2 单核处理器在只使用单个处理核心的情况下，每秒能够使用 AES-128 算法加密 180MB 数据，而在使用 RC4 算法的情况下，每秒则可以加密大约 350MB 数据。在处理器足够强劲并且拥有千兆网络连接的情况下，程序即使在加密的情况下也能够充分地使用整个网络连接。</p>
<p>唯一可能会出问题的地方是压缩—因为 SSH 默认使用的是 gzip 压缩算法。SSH 提供了配置选项，可以让用户选择指定的压缩级别（具体信息可以参考SSH的文档），它的 1 级压缩在使用之前提到的 2.6GHz 处理器的情况下，可以在复制的初始时候，以每秒 24～52MB 的速度对 Redis 的 RDB 文件进行压缩；并在复制进入持续更新阶段之后，以每秒 60～80MB 的速度对 Redis 的 AOF 文件进行压缩。</p>
<h1 id="3-扩展复杂的业务场景"><a href="#3-扩展复杂的业务场景" class="headerlink" title="3.扩展复杂的业务场景"></a>3.扩展复杂的业务场景</h1><ul>
<li>对信息流列表进行分片</li>
</ul>
<p>标题所说的“对信息流进行分片”实际上有些词不达意，因为首页信息流和分组列表信息流通常都比较短（最大通常只有 1,000 条，实际的数量由 zset-max-ziplist-size 选项的值决定），因此实际上并不需要对信息流的内容进行分片；我们真正要做的是根据键名，把不同的信息流分别存储到不同的分片上面。</p>
<p>另一方面，社交网站每个用户 profile 信息流通常无限增长的。尽管绝大多数用户每天最多只会发布几条微博，但也有话痨用户以明显高于这一频率的速度发布大量信息。以 Twitter 为例，该网站上发布信息最多的 1,000 个用户，每人都发布了超过 150,000 条推文，而其中发布最多的 15 个用户，每人都发布了上百万条推文。</p>
<p>从实用性的角度来看，<strong>一个合乎情理的做法是限制每个用户的已发表微博最多只能存储大约 20,000 条信息，并将最旧的信息删除或者隐藏</strong>，这种做法足以处理 99.999% 的 Twitter 用户，而我们也会使用这一方案来对社交网站的个人信息流进行扩展。</p>
<ul>
<li>通过分片对关注及粉丝列表扩展</li>
</ul>
<p>虽然对信息流进行扩展的方法相当直观易懂，但是对关注和粉丝列表这些由有序集合构成的“列表”进行扩展却并不容易。这些有序集合绝大多数都很短（如 Twitter 上 99.99% 的用户的关注者都少于 1,000 人），但是也存在少量用户的列表非常大，他们关注了非常多的人或者拥有数量庞大的粉丝。</p>
<p>从实用性的角度来考虑，一个合理的做法是给用户以及分组可以关注的人数设置一个上限（比如新浪微博普通用户最大允许关注 2,000 用户）。不过这个方法虽然可以控制用户的关注人数，但是仍然解决不了单个用户的粉丝数人数过多的问题。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">目前理财社区也做了同样的限制，一个用户关注上限2000！</span><br></pre></td></tr></table></figure>

<p>为了处理关注和粉丝列表变得非常巨大的情况，我们需要将实现这些列表的有序集合划分到多个分片上面，说得更具体一样，也就是根据分片的数量把用户的粉丝划分为多个部分，存在多个 zset 中。为此，我们需要为 ZADD 命令、ZREM 命令和 ZRANGEBYSCORE 命令实现特定的分片版本。</p>
<p>和信息流分片的区别是，这次分片的对象是数据而不是键。此外，为了减少程序创建和调用连接的数量，把关注和粉丝的数据放置在同一个分片里面将是一种非常有意义的做法。因此这次我们将使用新的方法对数据进行分片。</p>
<p>为了能够在关注及粉丝数据进行分片的时候，把两者数据都存储到同一个分片里面，程序将会把关注者和被关注者双方的 ID 用作查找分片键的其中一个参数。</p>
<ul>
<li>按业务维度来拆分空间</li>
</ul>
<p>以理财社区为例，目前所有的业务都放在一个cache集群里，后面随着业务的发展、数据量的增大、以及调用的频率不同、各个业务功能重要程度不同，肯定要按更细的维度来拆分。</p>
<p>比如贴子相关的（基本信息、正文、计数）单独在一块；</p>
<p>用户信息（基本信息、uid关系、用户状态等）单独空间；</p>
<p>关注列表、粉丝列表等单独空间；</p>
<p>临时活动放在一块；</p>
<p>扩容或系统故障，也只是影响一小块业务，降低各个业务之间的影响。</p>
<p><strong>参考资料：</strong></p>
<p><a href="http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=2653547053&amp;idx=1&amp;sn=833fddbc83379d9cac8d7f757343412e&amp;scene=1&amp;srcid=0805WKvrSVA1WS4VKoGcR9rK#rd" target="_blank" rel="noopener">http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=2653547053&amp;idx=1&amp;sn=833fddbc83379d9cac8d7f757343412e&amp;scene=1&amp;srcid=0805WKvrSVA1WS4VKoGcR9rK#rd</a></p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-计数器</title>
    <url>/sa/%E6%A1%88%E4%BE%8B-%E8%AE%A1%E6%95%B0%E5%99%A8/</url>
    <content><![CDATA[<p><strong>业务场景：</strong></p>
<p>社区作为一个轻互动论坛，必不可少会涉及很多计数统计，比如个人主页要展示用户相关一些计数（他的粉丝数、发贴数），feed信息流会展示每个贴子查看数、点赞数和评论数。如果每个计数都作为一个独立的个体，独立管理，每次用的时候就要从不同地方去取，维护成本肯定很高。</p>
<a id="more"></a>

<p>为了更好的管理，从页面功能角度对这些计数做了分类，分为用户维度、贴子维度、小组维度，而每个维度下又有各自的子项计数。</p>
<ul>
<li>用户维度（关注数、粉丝数、发贴数、评论数、铜钱数、订阅小组数）</li>
<li>贴子维度（查看数、评论数、点赞数、收藏数）</li>
<li>小组相关（订阅数、贴子数、精华数）</li>
<li>消息相关（回复与&amp;、赞、新粉丝数、私信往来的用户）</li>
</ul>
<p><strong>以用户维度的计数为例：</strong></p>
<p>数据最终是持久到mysql存储，为了提升性能，中间会有一层redis，使用Hash数据结构</p>
<p><strong>1）写操作</strong></p>
<p>任何一个子项动作都会触发缓存的写操作，比如A关注了B，对于A用户来讲，A的关注数要增加1，其它子项计数不变；对于B用户来讲，B的粉丝数要增加1，其它子项计数不变。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateMemberCount</span><span class="params">(MemberEditCountParam memberEditCountParam)</span> </span>&#123;</span><br><span class="line">       MemberCountUpdateParam updateParam = <span class="keyword">new</span> MemberCountUpdateParam();</span><br><span class="line">       updateParam.setUid(memberEditCountParam.getUid());</span><br><span class="line">       updateParam.setCopperCount(memberEditCountParam.getCopperCount());</span><br><span class="line">       updateParam.setPostCount(memberEditCountParam.getPostCount());</span><br><span class="line">       updateParam.setFollowCount(memberEditCountParam.getFollowCount());</span><br><span class="line">       updateParam.setFansCount(memberEditCountParam.getFansCount());</span><br><span class="line">       updateParam.setReplyCount(memberEditCountParam.getReplyCount());</span><br><span class="line">       updateParam.setTags(memberEditCountParam.getTagCount());</span><br><span class="line">       memberCountDao.updateMemberCount(updateParam);</span><br><span class="line">       memberCacheManager.editMemberCount(updateParam);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p><code>先写DB，再写cache。对于DB，通过mysql自身的行锁机制解决数据并发问题，‘posts = posts + #{postCount}’。但对于cache的维护，比较麻烦一些</code></p>
<p><strong>常规思路：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">value &#x3D;  hincrBy(String key, String field, long value) ;</span><br><span class="line">   	|</span><br><span class="line">	|</span><br><span class="line">	|</span><br><span class="line">	|</span><br><span class="line">if value &#x3D;&#x3D;1 , del cache</span><br></pre></td></tr></table></figure>

<ul>
<li>当缓存为空时，hincrBy会返回1；</li>
<li>如果用户某一个子项的计数为0，即使预热到cache，hincrBy 也会返回1。</li>
<li>所以根据是否等于1决定del cache，在用户量很大的情况下，cache的效率会比较差（只有所有的子项都大于0，且已预热到cache里才能避开这种情况）。另外如果 del cache 操作完成之前有读操作，返回的可能是脏数据</li>
</ul>
<p><strong>解决思路：</strong></p>
<p>引入一个较大阈值，区分cache为空还是已经预热但值为0的情况</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">incrCount</span><span class="params">(String hashName, String member, <span class="keyword">long</span> by)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> newValue = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 线程安全</span></span><br><span class="line">            newValue = getRedisClient().hincrBy(hashName, member, by);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (RedisException e) &#123;</span><br><span class="line">            logger.error(<span class="string">"[AbstractCacheManager.incrCount.hincrBy] invoke error!"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//COUNT_OFFSET为一个并发数，可以设定一个较大值，为了解决初始时cache为空，预热cache时又有其它</span></span><br><span class="line">并发请求干扰带来的脏数据</span><br><span class="line">        <span class="keyword">if</span> (newValue &gt;= COUNT_OFFSET) &#123;</span><br><span class="line">            <span class="keyword">return</span> newValue - COUNT_OFFSET;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                getRedisClient().del(hashName);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (RedisException e) &#123;</span><br><span class="line">                logger.error(<span class="string">"[AbstractCacheManager.incrCount.del] invoke error!"</span>, e);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> Long.MIN_VALUE;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li>删除或者初始化cache，将key作为一个整体（非单个子项）来操作，减少复杂性</li>
<li>为了便于维护，cache的预热放在查询阶段，如果cache为空，预热到cache中。</li>
</ul>
<p><strong>2）读操作</strong></p>
<p>批量查多个用户的用户维度计数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">   <span class="function"><span class="keyword">public</span> List&lt;SimpleMemberCountModel&gt; <span class="title">batchGetSimpleMemberCountModel</span><span class="params">(List&lt;Long&gt; uidList)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (CollectionUtils.isEmpty(uidList)) &#123;</span><br><span class="line">           <span class="keyword">return</span> Collections.emptyList();</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       List&lt;String&gt; keyList = uidList.stream()</span><br><span class="line">               .map(<span class="keyword">this</span>::getKeyMemberCount).collect(Collectors.toList());</span><br><span class="line"></span><br><span class="line"><span class="comment">// key:用户，value:不同子项的计数</span></span><br><span class="line">       Map&lt;String, Map&lt;String, Long&gt;&gt; countMaps = <span class="keyword">super</span>.batchGetCountMap(keyList);</span><br><span class="line">       List&lt;SimpleMemberCountModel&gt; countModelList = Lists.newArrayListWithCapacity(countMaps.size());</span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; uidList.size(); ++i) &#123;</span><br><span class="line">           Map&lt;String, Long&gt; countMap = countMaps.get(keyList.get(i));</span><br><span class="line">           <span class="keyword">if</span> (countMap != <span class="keyword">null</span>) &#123;</span><br><span class="line">               <span class="keyword">final</span> Long fansCount = countMap.get(FIELD_FANS_COUNT);</span><br><span class="line">               <span class="keyword">final</span> Long postCount = countMap.get(FIELD_POST_COUNT);</span><br><span class="line">               <span class="keyword">final</span> Long followCount = countMap.get(FIELD_FOLLOW_COUNT);</span><br><span class="line">               <span class="keyword">final</span> Long replyCount = countMap.get(FIELD_REPLY_COUNT);</span><br><span class="line">               <span class="keyword">final</span> Long tags = countMap.get(FIELD_TAGS_COUNT);</span><br><span class="line">               <span class="keyword">if</span> (fansCount != <span class="keyword">null</span> &amp;&amp; postCount != <span class="keyword">null</span> &amp;&amp; followCount != <span class="keyword">null</span> &amp;&amp; replyCount != <span class="keyword">null</span> &amp;&amp; tags != <span class="keyword">null</span>) &#123;</span><br><span class="line">                   SimpleMemberCountModel countModel = <span class="keyword">new</span> SimpleMemberCountModel();</span><br><span class="line">                   Long uid = uidList.get(i);</span><br><span class="line">                   countModel.setUid(uid);</span><br><span class="line">                   countModel.setFansCount(fansCount);</span><br><span class="line">                   countModel.setPostcount(postCount);</span><br><span class="line">                   countModel.setFollowCount(followCount);</span><br><span class="line">                   countModel.setReplyCount(replyCount);</span><br><span class="line">                   countModel.setTagCount(tags);</span><br><span class="line">                   countModelList.add(countModel);</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> countModelList;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>如果缓存为空，从DB查询数据并预热到缓存中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">batchSaveSimpleMemberCountModel</span><span class="params">(List&lt;SimpleMemberCountModel&gt; countModelList)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Map&lt;String , Map&lt;String, Long&gt;&gt; batchCountMap = Maps.newHashMapWithExpectedSize(countModelList.size());</span><br><span class="line">        countModelList.forEach(countModel -&gt; &#123;</span><br><span class="line">            String hash = getKeyMemberCount(countModel.getUid());</span><br><span class="line">            Map&lt;String, Long&gt; countMap = Maps.newHashMapWithExpectedSize(<span class="number">6</span>);</span><br><span class="line">            countMap.put(FIELD_UID, countModel.getUid());</span><br><span class="line">            countMap.put(FIELD_FANS_COUNT, countModel.getFansCount());</span><br><span class="line">            countMap.put(FIELD_POST_COUNT, countModel.getPostcount());</span><br><span class="line">            countMap.put(FIELD_FOLLOW_COUNT, countModel.getFollowCount());</span><br><span class="line">            countMap.put(FIELD_REPLY_COUNT, countModel.getReplyCount());</span><br><span class="line">            countMap.put(FIELD_TAGS_COUNT, countModel.getTagCount());</span><br><span class="line">            batchCountMap.put(hash, countMap);</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 缓存有效期12个小时</span></span><br><span class="line">        <span class="keyword">super</span>.batchSaveCountHash(batchCountMap, HALF_DAY_EXPIRE);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//初始化计数器hash</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">batchSaveCountHash</span><span class="params">(Map&lt;String, Map&lt;String, Long&gt; &gt;batchCountMap, <span class="keyword">int</span> ttl)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (batchCountMap == <span class="keyword">null</span> || batchCountMap.size() == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Map&lt;Node, List&lt;String&gt;&gt; nodeMap = getNodeMap(batchCountMap.keySet());</span><br><span class="line"></span><br><span class="line">    Map&lt;String, Map&lt;String, String&gt;&gt; batchStrMap = Maps.newHashMapWithExpectedSize(batchCountMap.size());</span><br><span class="line">    batchCountMap.forEach((key, countMap) -&gt; &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//组装map</span></span><br><span class="line">        Map&lt;String, String&gt; strMap = Maps.newHashMap();</span><br><span class="line">        <span class="comment">//缓存里存的计数是实际计数+计数器基数</span></span><br><span class="line">        countMap.forEach((field, count) -&gt; strMap.put(field, String.valueOf(count + COUNT_OFFSET)));</span><br><span class="line">        batchStrMap.put(key, strMap);</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//对于同一个节点上的map, 批量执行</span></span><br><span class="line">    nodeMap.forEach((node, keyList) -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            getRedisClient().pipelined(<span class="keyword">new</span> PipelineBlock() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">                    keyList.forEach(key -&gt; &#123;</span><br><span class="line">                        Map&lt;String, String&gt; strMap = batchStrMap.get(key);</span><br><span class="line">                        <span class="comment">//先删除key, 再设置每一个field, 最后设置超时时间</span></span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            del(key);</span><br><span class="line">                            hmset(key, strMap);</span><br><span class="line">                            expire(key, ttl);</span><br><span class="line">                        &#125; <span class="keyword">catch</span> (RedisException e) &#123;</span><br><span class="line">                            logger.error(<span class="string">"[AbstractCacheManager.batchSaveCountHash.execute] invoke error!"</span>, e);</span><br><span class="line"></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> Node <span class="title">getTargetNode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> node;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (RedisException e) &#123;</span><br><span class="line">            logger.error(<span class="string">"[AbstractCacheManager.batchSaveCountHash] invoke error!"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>注意：时间久了，缓存中的数据可能会存在与DB不一致情况，目前设置的缓存有效期是12个小时，然后缓存会失效，需再次从数据库同步数据</code></p>
<p><strong>3）计数的准确性</strong></p>
<p>时间久了，数据库表里的计数值也未必准确，比如关注数，每天凌晨会有定时任务，借助关注表计算准确的数字更新到数据库和缓存中。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-秒杀小结</title>
    <url>/sa/%E6%A1%88%E4%BE%8B-%E7%A7%92%E6%9D%80%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<h2 id="秒杀特点："><a href="#秒杀特点：" class="headerlink" title="秒杀特点："></a><strong>秒杀特点：</strong></h2><p>短时间内，大量用户涌入，集中读和写有限的库存。</p>
<a id="more"></a>
<h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a><strong>解决方案：</strong></h2><p>层层拦截，将请求尽量拦截在系统上游，避免将锁冲落到数据库上。</p>
<h3 id="第一层：客户端优化"><a href="#第一层：客户端优化" class="headerlink" title="*     第一层：客户端优化"></a>*     第一层：客户端优化</h3><p>产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求；<br>JS层面，限制用户在x秒之内只能提交一次请求，比如微信摇一摇抢红包。<br>基本可以拦截80%的请求。</p>
<h3 id="第二层：站点层面的请求拦截（nginx层，写流控模块）"><a href="#第二层：站点层面的请求拦截（nginx层，写流控模块）" class="headerlink" title="*    第二层：站点层面的请求拦截（nginx层，写流控模块）"></a>*    第二层：站点层面的请求拦截（nginx层，写流控模块）</h3><p>怎么防止程序员写for循环调用，有去重依据么？IP？cookie-id？…想复杂了，这类业务都需要登录，用uid即可。在站点层面，对uid进行请求计数和去重，甚至不需要统一存储计数，直接站点层内存存储（这样计数会不准，但最简单，比如guava本地缓存）。一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。<br>对于5s内的无效请求，统一返回错误提示或错误页面。</p>
<p>这个方式拦住了写for循环发HTTP请求的程序员，有些高端程序员（黑客）控制了10w个肉鸡，手里有10w个uid，同时发请求（先不考虑实名制的问题，小米抢手机不需要实名制），这下怎么办，站点层按照uid限流拦不住了。</p>
<h3 id="第三层：服务层拦截"><a href="#第三层：服务层拦截" class="headerlink" title="*    第三层：服务层拦截"></a>*    第三层：服务层拦截</h3><p>方案一：写请求放到队列中，每次只透有限的写请求到数据层，如果成功了再放下一批，直到库存不够，队列里的写请求全部返回“已售完”。</p>
<p>方案二：或采用漏斗机制，只放一倍的流量进来，多余的返回“已售完”，把写压力转换成读压力。<br>读请求，用cache，redis单机可以抗10W QPS,用异步线程定时更新缓存里的库存值。</p>
<p>还有提示“模糊化”，比如火车余票查询，票剩了58张，还是26张，你真的关注么，其实我们只关心有票和无票。</p>
<h3 id="第四层：数据库层"><a href="#第四层：数据库层" class="headerlink" title="*    第四层：数据库层"></a>*    第四层：数据库层</h3><p>浏览器拦截了80%，站点层拦截了99.9%并做了页面缓存，服务层又做了写请求队列与数据缓存，每次透到数据库层的请求都是可控的。<br>db基本就没什么压力了，通过自身锁机制来控制，避免出现超卖。</p>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a><strong>总结：</strong></h2><ol>
<li>尽量将请求拦截在系统上游（越上游越好）；</li>
<li>读多写少的多使用缓存（缓存抗读压力）；</li>
</ol>
<p><strong>参考资料：</strong></p>
<p><a href="http://www.infoq.com/cn/articles/flash-deal-architecture-optimization" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/flash-deal-architecture-optimization</a></p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-贴子楼层号</title>
    <url>/sa/%E6%A1%88%E4%BE%8B-%E8%B4%B4%E5%AD%90%E6%A5%BC%E5%B1%82%E5%8F%B7/</url>
    <content><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ul>
<li>和分库分表的全局计数器区别的是，它要连续的且自增，所以不方便预分配区间的形式来削峰</li>
<li>要保证原子性。不能出现重复的楼层</li>
</ul>
<a id="more"></a>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>1.Manager层的调用入口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">getNextFloor</span><span class="params">(Long tid)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (replyCacheManager.getMaxFloor(tid) == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="keyword">long</span> maxFloor = replyDao.getMaxFloor(tid);</span><br><span class="line">          replyCacheManager.initFloor(tid, maxFloor);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> replyCacheManager.getNextFloor(tid);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>2.首先根据当前的key判断cache中是否有楼层值</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Long <span class="title">getMaxFloor</span><span class="params">(Long tid)</span> </span>&#123;</span><br><span class="line">       String key = getKeyBbsFloorTid(tid);</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           String value = bbsRedisClient.get(key);</span><br><span class="line">           <span class="keyword">return</span> StringUtils.isEmpty(value) ? <span class="keyword">null</span> : Long.parseLong(value);</span><br><span class="line">       &#125; <span class="keyword">catch</span> (RedisException e) &#123;</span><br><span class="line">           logger.error(<span class="string">"[ReplyCacheManager.getMaxFloor] invoke error!"</span>, e);</span><br><span class="line">           <span class="keyword">throw</span> ExceptionUtils.newServiceException(ResultCode.PARAM_SERVICE_ERROR, e);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>3.如果缓存没有值会进行初始化，从数据库表查询当前最大的楼层号，然后预热到缓存</p>
<p>StringCommands.setnx(String, String)： 将字符串值value关联到key，如果key已存在则不做任何改变。</p>
<p>借助redis这一特性可以避免多条评论并发创建，但都因为缓存无值经过初始化这一步带来的脏数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initFloor</span><span class="params">(Long tid, Long floor)</span> </span>&#123;</span><br><span class="line">       String key = getKeyBbsFloorTid(tid);</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">            bbsRedisClient.setnx(key, String.valueOf(floor));</span><br><span class="line">       &#125; <span class="keyword">catch</span> (RedisException e) &#123;</span><br><span class="line">           logger.error(<span class="string">"[ReplyCacheManager.initFloor] invoke error!"</span>, e);</span><br><span class="line">           <span class="keyword">throw</span> ExceptionUtils.newServiceException(ResultCode.PARAM_SERVICE_ERROR, e);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>4.获取楼层号</p>
<p>StringCommands.incr(String)：将key中储存的数字值加1，如果key不存在，以0为key的初始值，然后执行INCR操作。该方法线程安全。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getNextFloor</span><span class="params">(Long tid)</span> </span>&#123;</span><br><span class="line">       String key = getKeyBbsFloorTid(tid);</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="keyword">return</span> bbsRedisClient.incr(key);</span><br><span class="line">       &#125; <span class="keyword">catch</span> (RedisException e) &#123;</span><br><span class="line">           logger.error(<span class="string">"[ReplyCacheManager.getNextFloor] invoke error!"</span>, e);</span><br><span class="line">           <span class="keyword">throw</span> ExceptionUtils.newServiceException(ResultCode.PARAM_SERVICE_ERROR, e);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>编码前3000问</title>
    <url>/sa/%E7%BC%96%E7%A0%81%E5%89%8D3000%E9%97%AE/</url>
    <content><![CDATA[<blockquote>
<p>当我们接到产品的需求的时候，别着急马上投入开发，先要了解需求的来龙去脉，多思考，尽可能将里面潜在的坑挖出来，这样上线后才会更好的满足需求，代码的扩展性、代码生命周期才会更长。</p>
</blockquote>
<a id="more"></a>
<hr>
<h2 id="下面简单列了一些应该思考的问题："><a href="#下面简单列了一些应该思考的问题：" class="headerlink" title="下面简单列了一些应该思考的问题："></a>下面简单列了一些应该思考的问题：</h2><ul>
<li><p>多去了解业务功能背后的想法，也许产品只是口渴了而不是真的想喝牛奶，技术同学可以从技术角度给产品同学一些启发，最终大家达成新的业务共识。</p>
<blockquote>
<p>一名优秀的工程师至少可以抵半个产品经理！</p>
</blockquote>
</li>
<li><p>新功能会不会对历史业务产生影响？如果会的话，要把影响的范围尽可能全的罗列出来，产品和技术共同探讨老业务的兼容问题</p>
</li>
<li><p>如果涉及底层老的数据库表重构，要考虑新、老数据如何平稳迁移，不影响线上用户的正常访问</p>
</li>
<li><p>是否存在并发，如何保证数据质量？要采用什么锁机制？</p>
</li>
<li><p>做好概要设计方案、详情设计方案，并组织所有相关人员参加评审，如果涉及数据库变动，最好叫上DBA。做方案尽量多想一想，如果担心老业务吃不透，可以叫上一些老员工，先整体再细节再整体，做到有点有面，一定要以全局性视野对待项目，否则很容易陷入误区。</p>
</li>
<li><p>容量规划。新功能上线后，数据量有多大？后续每日预估新增多少数据？采用什么形式的存储？是关系型数据库（如mysql）? 要不要分库分表？还是采用Nosql存储？</p>
</li>
<li><p>数据是否存在冷数据、热数据之分（例如微博），是否要分开存储？</p>
</li>
<li><p>尽可能采用服务化形式，但是抽象到何种程度，要视具体的业务而定，尽量朝着高内聚、低耦合设计原则。</p>
<ul>
<li>集中式调用改为HSF分布式远程调用，走的网络调用。为了提高性能，封装client二方包，通过xml bean配置控制逻辑，先从tair中查询，然后再走远程调用。</li>
<li>如果有多处地方代码用到同样的模型数据，最好能过上下文的方式传递，避免每次用到都走接口查询</li>
</ul>
</li>
<li><p>模块化、组件化，具备乐高积木的特性</p>
</li>
<li><p>多使用一些设计模式，提升系统的可扩展性</p>
</li>
<li><p>尽量往平台方向思考，但要注意控制成本，即便一期做不到大而全，但一定要留好扩展，便于后续的不断迭代。</p>
</li>
<li><p>如果是新应用，另起炉灶，要做好技术选型，最好选一些主流技术框架，切勿凭个人喜好，最后搞成百花齐放，后面的维护成本极高</p>
<blockquote>
<p>统一、标准化是一个亘古不变的话题，这一点非常重要</p>
</blockquote>
</li>
<li><p>如果是跨部门跨团队合作，需要提前约定好交互方式，联调时间，并要想一想，如果一方挂了，另一方如何做才能将影响降到最小。</p>
</li>
<li><p>对于很多技术改造，可能会配置开关，做好开关两面的测试工作，必要时可以紧急切换开关降低影响</p>
</li>
<li><p>接口响应时间。是否需要引入缓存，缓存的数据如何维护？数据预热、数据有效期，空间不足、缓存的命中率怎么样？</p>
</li>
<li><p>接口的最大并发量，需要做性能压测，了解系统能支撑的上限，便于大促活动时机器扩容</p>
</li>
<li><p>接口的容错性，如果出现意外情况时，尽量保住核心业务，不受边缘业务或非核心接口的影响</p>
</li>
<li><p>有条件的话，做好接口的流量控制，配置阈值，超过预设值能自我保护，并有对应的业务提示。</p>
</li>
<li><p>做好单元测试、项目代码 code review</p>
</li>
<li><p>发布时，要提前准备发布计划，以及回滚计划</p>
</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>社区稳定性之降级</title>
    <url>/sa/%E7%A4%BE%E5%8C%BA%E7%A8%B3%E5%AE%9A%E6%80%A7%E4%B9%8B%E9%99%8D%E7%BA%A7/</url>
    <content><![CDATA[<h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>当遇到营销活动或者突发情况带来较大访问流量时，最大程度保证系统可用性，为用户输出稳定服务能力。</p>
<a id="more"></a>
<p><strong>思考方向：</strong></p>
<ul>
<li>根据监控，找到流量较大的业务、页面、功能</li>
<li>与业务方讨论，找出页面中哪些功能是重要的，哪些是不重要的 </li>
<li>每个功能模块会调用哪些接口，自上而下，梳理每个接口的全链路，看哪些接口可以降级</li>
</ul>
<p><strong>所有接口都要纳入监控体系，监控的指标：</strong></p>
<ul>
<li>接口的实时调用量</li>
<li>QPS</li>
<li>RT</li>
<li>服务器的load、cpu、IO、内存</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">注意：</span><br><span class="line">演练前要做性能压测，知道系统的容量瓶颈。配置报警阈值，如果触发，能及时通知相关工作人员。</span><br><span class="line">紧急启动应急机制</span><br></pre></td></tr></table></figure>

<h1 id="业务案例"><a href="#业务案例" class="headerlink" title="业务案例"></a>业务案例</h1><p>1、页面非核心功能屏蔽</p>
<p>banner位、话题位、猜你喜欢、达人推荐等非重要功能全部通过开关控制，必要时可全部关闭</p>
<p>2、接口流量控制</p>
<p>压测每个接口支持的调用上限，配置阀值，超过上限拒绝提供服务</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存架构之防雪崩设计</title>
    <url>/sa/%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%98%B2%E9%9B%AA%E5%B4%A9%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h1 id="使用缓存时有三个目标："><a href="#使用缓存时有三个目标：" class="headerlink" title="使用缓存时有三个目标："></a>使用缓存时有三个目标：</h1><ul>
<li>第一，加快用户访问速度，提高用户体验</li>
<li>第二，降低后端负载，减少潜在的风险，保证系统平稳</li>
<li>第三，保证数据“尽可能”及时更新</li>
</ul>
<a id="more"></a>
<h1 id="缓存穿透原因"><a href="#缓存穿透原因" class="headerlink" title="缓存穿透原因"></a>缓存穿透原因</h1><p>缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，但是出于容错的考虑，如果从存储层查不到数据则不写入缓存层</p>
<ul>
<li>缓存层不命中</li>
<li>存储层不命中，所以不将空结果写回缓存</li>
<li>返回空结果</li>
</ul>
<p><strong>缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。</strong></p>
<p>缓存穿透问题可能会使后端存储负载加大，由于很多后端存储不具备高并发性，甚至可能造成后端存储宕掉。通常可以在程序中分别统计总调用数、缓存层命中数、存储层命中数，如果发现大量存储层空命中，可能就是出现了缓存穿透问题。</p>
<p>造成缓存穿透的基本有两个：</p>
<ul>
<li>业务自身代码或者数据出现问题</li>
<li>一些恶意攻击、爬虫等造成大量空命中</li>
</ul>
<h1 id="缓存穿透的解决方法"><a href="#缓存穿透的解决方法" class="headerlink" title="缓存穿透的解决方法"></a>缓存穿透的解决方法</h1><h2 id="1）缓存空对象"><a href="#1）缓存空对象" class="headerlink" title="1）缓存空对象"></a>1）缓存空对象</h2><p>当存储层不命中后，仍然将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取，保护了后端数据源。</p>
<p>缓存空对象会有两个问题：</p>
<ul>
<li><p>空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间 ( 如果是攻击，问题更严重 )，比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。</p>
</li>
<li><p>缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为 5 分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。</p>
</li>
</ul>
<h2 id="2）布隆过滤器拦截"><a href="#2）布隆过滤器拦截" class="headerlink" title="2）布隆过滤器拦截"></a>2）布隆过滤器拦截</h2><p>在访问缓存层和存储层之前，将存在的 key 用布隆过滤器提前保存起来，做第一层拦截。例如： 一个个性化推荐系统有 4 亿个用户 ID，每个小时算法工程师会根据每个用户之前历史行为做出来的个性化放到存储层中，但是最新的用户由于没有历史行为，就会发生缓存穿透的行为，为此可以将所有有个性化推荐数据的用户做成布隆过滤器。如果布隆过滤器认为该用户 ID 不存在，那么就不会访问存储层，在一定程度保护了存储层。</p>
<p>有关布隆过滤器的相关知识，可以参考： <a href="https://en.wikipedia.org/wiki/Bloom_filter" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bloom_filter</a></p>
<p>可以利用 Redis 的 Bitmaps 实现布隆过滤器，GitHub 上已经开源了类似的方案，读者可以进行参考：<br><a href="https://github.com/erikdubbelboer/Redis-Lua-scaling-bloom-filter" target="_blank" rel="noopener">https://github.com/erikdubbelboer/Redis-Lua-scaling-bloom-filter</a></p>
<p>这种方法适用于数据命中不高，数据相对固定实时性低（通常是数据集较大）的应用场景，代码维护较为复杂，但是缓存空间占用少。</p>
<h1 id="缓存雪崩问题优化"><a href="#缓存雪崩问题优化" class="headerlink" title="缓存雪崩问题优化"></a>缓存雪崩问题优化</h1><p>预防和解决缓存雪崩问题，可以从以下三个方面进行着手。</p>
<ul>
<li>1）保证缓存层服务高可用性。</li>
</ul>
<p>和飞机都有多个引擎一样，如果缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务</p>
<ul>
<li>2）依赖隔离组件为后端限流并降级。</li>
</ul>
<p>无论是缓存层还是存储层都会有出错的概率，可以将它们视同为资源。作为并发量较大的系统，假如有一个资源不可用，可能会造成线程全部 hang 在这个资源上，造成整个系统不可用。降级在高并发系统中是非常正常的：比如推荐服务中，如果个性化推荐服务不可用，可以降级补充热点数据，不至于造成前端页面是开天窗。</p>
<p>在实际项目中，我们需要对重要的资源 ( 例如 Redis、 MySQL、 Hbase、外部接口 ) 都进行隔离，让每种资源都单独运行在自己的线程池中，即使个别资源出现了问题，对其他服务没有影响。但是线程池如何管理，比如如何关闭资源池，开启资源池，资源池阀值管理，这些做起来还是相当复杂的，这里推荐一个 Java 依赖隔离工具 Hystrix(<a href="https://github.com/Netflix/Hystrix" target="_blank" rel="noopener">https://github.com/Netflix/Hystrix</a>)</p>
<ul>
<li>3）提前演练。在项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定。</li>
</ul>
<h1 id="缓存热点-key-重建优化"><a href="#缓存热点-key-重建优化" class="headerlink" title="缓存热点 key 重建优化"></a>缓存热点 key 重建优化</h1><p>开发人员使用缓存 + 过期时间的策略既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求。但是有两个问题如果同时出现，可能就会对应用造成致命的危害：</p>
<ul>
<li>当前 key 是一个热点 key( 例如一个热门的娱乐新闻），并发量非常大。</li>
<li>重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的 SQL、多次 IO、多个依赖等。</li>
</ul>
<p>在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。</p>
<p>解决思路：</p>
<ul>
<li>1）互斥锁 (mutex key)</li>
</ul>
<p>只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可</p>
<ul>
<li><p>2）永远不过期，“永远不过期”包含两层意思：</p>
<ul>
<li>从缓存层面来看，确实没有设置过期时间，所以不会出现热点 key 过期后产生的问题，也就是“物理”不过期。</li>
<li>从功能层面来看，为每个 value 设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。</li>
</ul>
</li>
</ul>
<p>方案比较：</p>
<ul>
<li>互斥锁 (mutex key)：这种方案思路比较简单，但是存在一定的隐患，如果构建缓存过程出现问题或者时间较长，可能会存在死锁和线程池阻塞的风险，但是这种方法能够较好的降低后端存储负载并在一致性上做的比较好。</li>
<li>“ 永远不过期 “：这种方案由于没有设置真正的过期时间，实际上已经不存在热点 key 产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。</li>
</ul>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库并发锁机制</title>
    <url>/sa/%E9%94%81%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>在如今分布式、高并发、各种负载纵横天下的时代，支持高访问量成为检验一个系统合不合格的重要标准，然而我们除了在运算过程中要求系统更加效率外，在最终的数据存储过程中也希望其能够准确。</p>
<a id="more"></a>
<p>并发修改同一记录时为避免更新丢失，要么在应用层加锁，要么在缓存加锁，要么在数据库层使用乐观锁，使用 version 作为更新依据。</p>
<h1 id="悲观锁："><a href="#悲观锁：" class="headerlink" title="悲观锁："></a>悲观锁：</h1><p>正如其名，它指对数据被外界（可能是本机的其他事务，也可能是来自其它服务器的事务处理）的修改持保守态度。在整个数据处理过程中，将数据处于锁定状态。悲观锁大多数情况下<strong>依靠数据库的锁机制实现，以保证操作最大程度的独占性</strong>。如果加锁的时间过长，其他用户长时间无法访问，影响程序的并发访问性，同时这样对数据库性能开销影响也很大，特别是长事务而言，这样的开销往往无法承受。</p>
<h1 id="乐观锁："><a href="#乐观锁：" class="headerlink" title="乐观锁："></a>乐观锁：</h1><p>分为三个阶段：数据读取、写入校验、数据写入。</p>
<p>假设数据一般情况下不会造成冲突，只有在数据进行提交更新时，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回错误信息，让用户决定如何去做。fail-fast机制。</p>
<p><strong>小结：</strong></p>
<p>乐观锁和悲观锁之间选择的标准是冲突的频率、严重性。如果冲突较少或者冲突的后果不是很严重，通常情况下会选择乐观锁，容易实现且吞吐性高，能得到更好的并发性。如果冲突的结果对用户来说是非常严重的，可以使用悲观锁，适当牺牲一些性能。</p>
<p><strong>针对如何解决多线程并发产生的脏数据问题，本文简单列举一些常见案例及应对措施。</strong></p>
<h1 id="案例一："><a href="#案例一：" class="headerlink" title="案例一："></a>案例一：</h1><p>本地起10个线程，分别执行10次，对数据库的一条记录的sum字段（初始值为0）+1操作，中间的业务逻辑我们忽略掉，如何保证执行完毕后sum的值为100？</p>
<p>表结构：</p>
<table>
<thead>
<tr>
<th>字段名</th>
<th>字段类型</th>
<th>可空</th>
<th>字段描述</th>
<th>使用备注</th>
</tr>
</thead>
<tbody><tr>
<td>ID</td>
<td>BIGINT(20)</td>
<td>N</td>
<td>主键ID</td>
<td>无业务含义</td>
</tr>
<tr>
<td>SUM</td>
<td>NUMBER(20)</td>
<td>N</td>
<td>金额</td>
<td>初始值为0</td>
</tr>
</tbody></table>
<p><strong>解决措施：</strong></p>
<p>利用数据库自身的事务来解决问题，update 表 set sum=sum+#increment#   where id=#id#，适用于一些只更新数量、金额的场景。<br>尽量不要采用在后台计算一个最终的sum值，然后通过 update 表 set sum=#sum#  where id=#id#，因为此时在读与写的时间间隔里，很有可能其它的线程已经读过或操作过</p>
<h1 id="案例二："><a href="#案例二：" class="headerlink" title="案例二："></a>案例二：</h1><p>买家操作一笔订单，执行确认收货，假如同一笔订单打开了两个窗口，开始时在一个窗口确认成功，后来在另一个窗口又点了一次，此时应如何解决？</p>
<p><strong>解决措施：</strong></p>
<p>在执行“买家确认收货”操作时，我们通常会首先查出这笔订单，判断当前操作用户是否有执行权限，同时判断当前订单的状态是否是“等待买家确认收货”，。。。，如果满足这些前置条件，才允许后面的业务操作，更新数据库。<br>当然，存在另一种可能，如果是通过自动化脚本操作呢？两次操作几乎同时执行，也就是说，两次的前置校验都能顺利通过(因此那时，数据库记录还没来的及更新)，此时一个好的解决方案，操作时增加前置条件，比如确认收货的前置条件是“等待买家确认收货”，如果此时订单的状态变成了成功就无法操作。<br>update 订单表 set  status=”交易成功”  where id=#orderId# and status=”等待买家确认收货”<br>这样，第二次操作sq条件不满足，也就避免执行两次买家确认收货操作。</p>
<h1 id="案例三："><a href="#案例三：" class="headerlink" title="案例三："></a>案例三：</h1><p>增加前置条件是一个不错的解决方案，但是，不是每个业务都有前置条件，或者说前置条件不明确、无规则，此时应如何解决？</p>
<table>
<thead>
<tr>
<th>字段名</th>
<th>字段类型</th>
<th>可空</th>
<th>字段描述</th>
<th>使用备注</th>
</tr>
</thead>
<tbody><tr>
<td>ID</td>
<td>BIGINT(20)</td>
<td>N</td>
<td>主键ID</td>
<td>无业务含义</td>
</tr>
<tr>
<td>SUM</td>
<td>NUMBER(20)</td>
<td>N</td>
<td>金额</td>
<td>初始值为0</td>
</tr>
<tr>
<td>attribute_cc</td>
<td>INT(11)</td>
<td>N</td>
<td>用于为attribute加锁</td>
<td></td>
</tr>
</tbody></table>
<p><strong>解决措施：</strong></p>
<p>可以借助乐观锁，比较并交换（CAS），在数据库表增加一个冗余字段，每次操作都会自动+1。执行业务时，首先会从数据库读取该字段信息，更新业务数据时，会自动比较attribute_cc的值是否有变化，如果有变化，表示刚才读的信息已变化过，需要重新操作。</p>
<p><strong>特别注意：</strong></p>
<p>attribute_cc是针对整条记录设置的行锁，如果数据库表有很多类似于features这样的json复合字段，我们将锁的粒度范围进一步缩小，每一个features配一个features_cc，features_cc的作用就是features的乐观锁版本的控制，可以很好规避使用attribute_cc与整个字段冲突的尴尬。</p>
<h1 id="案例四："><a href="#案例四：" class="headerlink" title="案例四："></a>案例四：</h1><p>商品表items表中有一个字段status，status=1表示商品未被下单，status=2 表示该商品已经被下单，那么我们对每个商品下单前必须保证此商品的status=1。假设有一件商品，其id 为1000。</p>
<p>常规思路：</p>
<ul>
<li>先查询商品状态  select status from items where id=1000</li>
<li>生成订单 </li>
<li>修改商品状态 update items set status=2 wehre id=1000</li>
</ul>
<p>在高并发环境下，在操作第三步update时，很有可能其它人已经先一步把商品的status修改为2</p>
<p>悲观锁思路：从查询出items信息时就把当前的数据锁定，直到我们修改完毕后再解锁。使用悲观锁，需要关闭mysql数据库的自动提交属性，因为mysql默认使用autocommit模式，当你执行一个更新操作后，mysql会立刻将结果提交。</p>
<p>步骤：</p>
<ul>
<li><p>set autocommit=0</p>
</li>
<li><p>开始事务。begin、begin work、start transaction（三者选一就可以）</p>
</li>
<li><p>查询出商品信息</p>
<p>select status from items where id=1000 for update;</p>
</li>
<li><p>生成订单 insert into orders(id,item_id) values(null,1000)</p>
</li>
<li><p>修改商品状态 update items set status=2 wehre id=1000</p>
</li>
<li><p>提交事务  commit </p>
</li>
</ul>
<p>我们使用select … for update的方式，通过数据库实现了悲观锁。id=1000那条记录被我们锁定了，其它事务必须等本次事务提交后才能执行。这样我们就可以保证当前的数据不会被其它事务修改。</p>
<p>注：用select … for update 同一条记录时会等待其它事务结束后才执行，一般select…不受影响。比如当我们执行select status from items where id=1000 for update后，另外的事务也执行了select status from items where id=1000 for update 则第二个事务会一直等待第一个事务的提交，此时第二个查询处于阻塞的状态，但如果第二个事务中执行select status from items where id=1000,则能正常查询数据，不受第一个事务的影响。</p>
<p>mysql innoDB默认使用行锁，需要明确指定主键，否则mysql将会执行表锁（将整个表锁住）。除了主键外，使用索引也会影响数据库的锁定级别。</p>
<h1 id="案例五："><a href="#案例五：" class="headerlink" title="案例五："></a>案例五：</h1><p>商品减库存时，如果在秒杀等高并发的场景下，如果采用version作为乐观锁，虽然每次只有一个事务能更新成功，但业务感知上会有大量的操作失败。解决方案可以采用库存数做为乐观锁</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update item</span><br><span class="line">set quantity&#x3D;quantity - #sub_quantity#</span><br><span class="line">where item_id&#x3D;#id# </span><br><span class="line">	  and quantity - #sub_quantity# &gt; 0</span><br></pre></td></tr></table></figure>

<h1 id="注意：如果每次访问冲突概率小于-20-，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于-3-次。"><a href="#注意：如果每次访问冲突概率小于-20-，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于-3-次。" class="headerlink" title="注意：如果每次访问冲突概率小于 20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于 3 次。"></a>注意：如果每次访问冲突概率小于 20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于 3 次。</h1><hr>
<p><strong>参考资料：</strong></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;mid=2651477385&amp;idx=1&amp;sn=2db07fdbf148b47e88613cc648c9135a&amp;scene=0&amp;key=305bc10ec50ec19bec2be639b7fb5203e5461f172af5f913e52e8da9ab78acb42a407104893c37f972167b8d7b080be1&amp;ascene=0&amp;uin=Mzc2MDAyNDU%3D&amp;devicetype=iMac+MacBookPro11%2C1+OSX+OSX+10.10.1+build(14B25)&amp;version=11000003&amp;pass_ticket=wALAc3GK4Gz2wCm4YcYmcfVkSIKhak3fraNYqyqYFaU%3D" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;mid=2651477385&amp;idx=1&amp;sn=2db07fdbf148b47e88613cc648c9135a&amp;scene=0&amp;key=305bc10ec50ec19bec2be639b7fb5203e5461f172af5f913e52e8da9ab78acb42a407104893c37f972167b8d7b080be1&amp;ascene=0&amp;uin=Mzc2MDAyNDU%3D&amp;devicetype=iMac+MacBookPro11%2C1+OSX+OSX+10.10.1+build(14B25)&amp;version=11000003&amp;pass_ticket=wALAc3GK4Gz2wCm4YcYmcfVkSIKhak3fraNYqyqYFaU%3D</a></p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>CAS实现SSO单点登录原理</title>
    <url>/web/CAS%E5%AE%9E%E7%8E%B0SSO%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="1-CAS-简介"><a href="#1-CAS-简介" class="headerlink" title="1. CAS 简介"></a>1. CAS 简介</h1><h2 id="1-1-What-is-CAS-？"><a href="#1-1-What-is-CAS-？" class="headerlink" title="1.1. What is CAS ？"></a>1.1. What is CAS ？</h2><p>CAS （ Central Authentication Service ） 是 Yale 大学发起的一个企业级的、开源的项目，旨在为 Web 应用系统提供一种可靠的单点登录解决方法（属于 Web SSO ）。</p>
<a id="more"></a>

<p>CAS 开始于 2001 年， 并在 2004 年 12 月正式成为 JA-SIG 的一个项目。</p>
<h2 id="1-2-主要特性"><a href="#1-2-主要特性" class="headerlink" title="1.2.  主要特性"></a>1.2.  主要特性</h2><ol>
<li><p>开源的、多协议的 SSO 解决方案； Protocols ： Custom Protocol 、 CAS 、 OAuth 、 OpenID 、 RESTful API 、 SAML1.1 、 SAML2.0 等。</p>
</li>
<li><p>支持多种认证机制： Active Directory 、 JAAS 、 JDBC 、 LDAP 、 X.509 Certificates 等；</p>
</li>
<li><p>安全策略：使用票据（ Ticket ）来实现支持的认证协议；</p>
</li>
<li><p>支持授权：可以决定哪些服务可以请求和验证服务票据（ Service Ticket ）；</p>
</li>
<li><p>提供高可用性：通过把认证过的状态数据存储在 TicketRegistry 组件中，这些组件有很多支持分布式环境的实现，如： BerkleyDB 、 Default 、 EhcacheTicketRegistry 、 JDBCTicketRegistry 、 JBOSS TreeCache 、 JpaTicketRegistry 、 MemcacheTicketRegistry 等；</p>
</li>
<li><p>支持多种客户端： Java 、 .Net 、 PHP 、 Perl 、 Apache, uPortal 等。</p>
</li>
</ol>
<h1 id="2-SSO-单点登录原理"><a href="#2-SSO-单点登录原理" class="headerlink" title="2. SSO 单点登录原理"></a>2. SSO 单点登录原理</h1><p>本文内容主要针对 Web SSO 。</p>
<h2 id="2-1-什么是SSO"><a href="#2-1-什么是SSO" class="headerlink" title="2.1. 什么是SSO"></a>2.1. 什么是SSO</h2><p>单点登录（ Single Sign-On , 简称 SSO ）是目前比较流行的服务于企业业务整合的解决方案之一， SSO 使得在多个应用系统中，用户只需要 登录一次 就可以访问所有相互信任的应用系统。</p>
<h2 id="2-2-SSO-原理"><a href="#2-2-SSO-原理" class="headerlink" title="2.2. SSO 原理"></a>2.2. SSO 原理</h2><h3 id="2-2-1-SSO-体系中的角色"><a href="#2-2-1-SSO-体系中的角色" class="headerlink" title="2.2.1. SSO 体系中的角色"></a>2.2.1. SSO 体系中的角色</h3><p>一般 SSO 体系主要角色有三种：</p>
<ol>
<li><p>User （多个）</p>
</li>
<li><p>Web 应用（多个）</p>
</li>
<li><p>SSO 认证中心（ 1 个 ）</p>
</li>
</ol>
<h3 id="2-2-2-SSO-实现模式的原则"><a href="#2-2-2-SSO-实现模式的原则" class="headerlink" title="2.2.2. SSO 实现模式的原则"></a>2.2.2. SSO 实现模式的原则</h3><p>SSO 实现模式一般包括以下三个原则：</p>
<ol>
<li><p>所有的认证登录都在 SSO 认证中心进行；</p>
</li>
<li><p>SSO 认证中心通过一些方法来告诉 Web 应用当前访问用户究竟是不是已通过认证的用户；</p>
</li>
<li><p>SSO 认证中心和所有的 Web 应用建立一种信任关系，也就是说 web 应用必须信任认证中心。（单点信任）</p>
</li>
</ol>
<h3 id="2-2-3-SSO-主要实现方式"><a href="#2-2-3-SSO-主要实现方式" class="headerlink" title="2.2.3. SSO 主要实现方式"></a>2.2.3. SSO 主要实现方式</h3><p>SSO 的主要实现方式有：</p>
<ol>
<li>共享 cookies</li>
</ol>
<p>基于共享同域的 cookie 是 Web 刚开始阶段时使用的一种方式，它利用浏览同域名之间自动传递 cookies 机制，实现两个域名之间系统令牌传递问题；另外，关于跨域问题，虽然 cookies本身不跨域，但可以利用它实现跨域的 SSO 。如：代理、暴露 SSO 令牌值等。</p>
<p>缺点：不灵活而且有不少安全隐患，已经被抛弃。</p>
<ol start="2">
<li>Broker-based( 基于经纪人 )</li>
</ol>
<p>这种技术的特点就是，有一个集中的认证和用户帐号管理的服务器。经纪人给被用于进一步请求的电子身份存取。中央数据库的使用减少了管理的代价，并为认证提供一个公共和独立的 “第三方 “ 。例如 Kerberos 、 Sesame 、 IBM KryptoKnight （凭证库思想 ) 等。 Kerberos是由麻省理工大学发明的安全认证服务，已经被 UNIX 和 Windows 作为默认的安全认证服务集成进操作系统。</p>
<ol start="3">
<li>Agent-based （基于代理人）</li>
</ol>
<p>在这种解决方案中，有一个自动地为不同的应用程序认证用户身份的代理程序。这个代理程序需要设计有不同的功能。比如，它可以使用口令表或加密密钥来自动地将认证的负担从用户移开。代理人被放在服务器上面，在服务器的认证系统和客户端认证方法之间充当一个 “ 翻译 “。例如 SSH 等。</p>
<ol start="4">
<li>Token-based</li>
</ol>
<p>例如 SecureID,WebID ，现在被广泛使用的口令认证，比如 FTP 、邮件服务器的登录认证，这是一种简单易用的方式，实现一个口令在多种应用当中使用。</p>
<ol start="5">
<li><p>基于网关</p>
</li>
<li><p>基于 SAML</p>
</li>
</ol>
<p>SAML(Security Assertion Markup Language ，安全断言标记语言）的出现大大简化了 SSO ，并被 OASIS 批准为 SSO 的执行标准 。开源组织 OpenSAML 实现了 SAML 规范。</p>
<h1 id="3-CAS-的基本原理"><a href="#3-CAS-的基本原理" class="headerlink" title="3. CAS 的基本原理"></a>3. CAS 的基本原理</h1><h2 id="3-1-结构体系"><a href="#3-1-结构体系" class="headerlink" title="3.1. 结构体系"></a>3.1. 结构体系</h2><p>从结构体系看， CAS 包括两部分： CAS Server 和 CAS Client 。</p>
<h3 id="3-1-1-CAS-Server"><a href="#3-1-1-CAS-Server" class="headerlink" title="3.1.1. CAS Server"></a>3.1.1. CAS Server</h3><p>CAS Server 负责完成对用户的认证工作 , 需要独立部署 , CAS Server 会处理用户名 / 密码等凭证(Credentials) 。</p>
<h3 id="3-1-2-CAS-Client"><a href="#3-1-2-CAS-Client" class="headerlink" title="3.1.2. CAS Client"></a>3.1.2. CAS Client</h3><p>负责处理对客户端受保护资源的访问请求，需要对请求方进行身份认证时，重定向到 CAS Server 进行认证。（原则上，客户端应用不再接受任何的用户名密码等 Credentials ）。</p>
<p>CAS Client 与受保护的客户端应用部署在一起，以 Filter 方式保护受保护的资源。</p>
<h2 id="3-2-CAS-原理和协议"><a href="#3-2-CAS-原理和协议" class="headerlink" title="3.2. CAS 原理和协议"></a>3.2. CAS 原理和协议</h2><h3 id="3-2-1-基础模式"><a href="#3-2-1-基础模式" class="headerlink" title="3.2.1. 基础模式"></a>3.2.1. 基础模式</h3><p>基础模式 SSO 访问流程主要有以下步骤：</p>
<ol>
<li><p>访问服务： SSO 客户端发送请求访问应用系统提供的服务资源。</p>
</li>
<li><p>定向认证： SSO 客户端会重定向用户请求到 SSO 服务器。</p>
</li>
<li><p>用户认证：用户身份认证。</p>
</li>
<li><p>发放票据： SSO 服务器会产生一个随机的 Service Ticket 。</p>
</li>
<li><p>验证票据： SSO 服务器验证票据 Service Ticket 的合法性，验证通过后，允许客户端访问服务。</p>
</li>
<li><p>传输用户信息： SSO 服务器验证票据通过后，传输用户认证结果信息给客户端。</p>
</li>
</ol>
<p>下面是 CAS 最基本的协议过程：<br><img data-src="http://www.coin163.com/java/cas/images/cas_clip_image001.jpg" alt="cas基础协议图"></p>
<p>如上图： CAS Client 与受保护的客户端应用部署在一起，以 Filter 方式保护 Web 应用的受保护资源，过滤从客户端过来的每一个 Web 请求，同时， CAS Client 会分析 HTTP 请求中是否包含请求 Service Ticket( ST 上图中的 Ticket) ，如果没有，则说明该用户是没有经过认证的；于是 CAS Client 会重定向用户请求到 CAS Server （ Step 2 ），并传递 Service （要访问的目的资源地址）。 Step 3 是用户认证过程，如果用户提供了正确的 Credentials ， CAS Server 随机产生一个相当长度、唯一、不可伪造的 Service Ticket ，并缓存以待将来验证，并且重定向用户到 Service 所在地址（附带刚才产生的 Service Ticket ） , 并为客户端浏览器设置一个 Ticket Granted Cookie （ TGC ） ； CAS Client 在拿到 Service 和新产生的 Ticket 过后，在 Step 5 和 Step6 中与 CAS Server 进行身份核实，以确保 Service Ticket 的合法性。</p>
<p>在该协议中，所有与 CAS Server 的交互均采用 SSL 协议，以确保 ST 和 TGC 的安全性。协议工作过程中会有 2 次重定向 的过程。但是 CAS Client 与 CAS Server 之间进行 Ticket 验证的过程对于用户是透明的（使用 HttpsURLConnection ）。</p>
<p>CAS 请求认证时序图如下：</p>
<p><img data-src="http://www.coin163.com/java/cas/images/cas_clip_image003.gif" alt="cas认证时序图"></p>
<h3 id="3-2-1-CAS-如何实现-SSO"><a href="#3-2-1-CAS-如何实现-SSO" class="headerlink" title="3.2.1. CAS 如何实现 SSO"></a>3.2.1. CAS 如何实现 SSO</h3><p>当用户访问另一个应用的服务再次被重定向到 CAS Server 的时候， CAS Server 会主动获到这个 TGC cookie ，然后做下面的事情：</p>
<p>1) 如果 User 持有 TGC 且其还没失效，那么就走基础协议图的 Step4 ，达到了 SSO 的效果；</p>
<p>2) 如果 TGC 失效，那么用户还是要重新认证 ( 走基础协议图的 Step3) 。</p>
<h3 id="3-2-2-CAS-代理模式"><a href="#3-2-2-CAS-代理模式" class="headerlink" title="3.2.2. CAS 代理模式"></a>3.2.2. CAS 代理模式</h3><p>该模式形式为用户访问 App1 ， App1 又依赖于 App2 来获取一些信息，如： User –&gt;App1 –&gt;App2。</p>
<p>这种情况下，假设 App2 也是需要对 User 进行身份验证才能访问，那么，为了不影响用户体验（过多的重定向导致 User 的 IE 窗口不停地闪动 ) ， CAS 引入了一种 Proxy 认证机制，即 CAS Client 可以代理用户去访问其它 Web 应用。</p>
<p>代理的前提是需要 CAS Client 拥有用户的身份信息 ( 类似凭据 ) 。之前我们提到的 TGC 是用户持有对自己身份信息的一种凭据，这里的 PGT 就是 CAS Client 端持有的对用户身份信息的一种凭据。凭借TGC ， User 可以免去输入密码以获取访问其它服务的 Service Ticket ，所以，这里凭借 PGT ， Web应用可以代理用户去实现后端的认证，而 无需前端用户的参与 。</p>
<p>下面为代理应用（ helloService ）获取 PGT 的过程： （注： PGTURL 用于表示一个 Proxy 服务，是一个回调链接； PGT 相当于代理证； PGTIOU 为取代理证的钥匙，用来与 PGT 做关联关系；）</p>
<p><img data-src="http://www.coin163.com/java/cas/images/cas_clip_image004.jpg" alt="cas代理PGT获取"></p>
<p>如上面的 CAS Proxy 图所示， CAS Client 在基础协议之上，在验证 ST 时提供了一个额外的PGT URL( 而且是 SSL 的入口 ) 给 CAS Server ，使得 CAS Server 可以通过 PGT URL 提供一个 PGT 给 CAS Client 。</p>
<p>CAS Client 拿到了 PGT(PGTIOU-85 … ..ti2td) ，就可以通过 PGT 向后端 Web 应用进行认证。</p>
<p>下面是代理认证和提供服务的过程：<br><img data-src="http://www.coin163.com/java/cas/images/cas_clip_image005.jpg" alt=""></p>
<p>如上图所示， Proxy 认证与普通的认证其实差别不大， Step1 ， 2 与基础模式的 Step1,2 几乎一样，唯一不同的是， Proxy 模式用的是 PGT 而不是 TGC ，是 Proxy Ticket （ PT ）而不是 Service Ticket 。</p>
<h3 id="3-2-3-辅助说明"><a href="#3-2-3-辅助说明" class="headerlink" title="3.2.3. 辅助说明"></a>3.2.3. 辅助说明</h3><p>CAS 的 SSO 实现方式可简化理解为： 1 个 Cookie 和 N 个 Session 。 CAS Server 创建 cookie，在所有应用认证时使用，各应用通过创建各自的 Session 来标识用户是否已登录。</p>
<p>用户在一个应用验证通过后，以后用户在同一浏览器里访问此应用时，客户端应用中的过滤器会在 session 里读取到用户信息，所以就不会去 CAS Server 认证。如果在此浏览器里访问别的 web 应用时，客户端应用中的过滤器在 session 里读取不到用户信息，就会去 CAS Server 的 login 接口认证，但这时CAS Server 会读取到浏览器传来的 cookie （ TGC ），所以 CAS Server 不会要求用户去登录页面登录，只是会根据 service 参数生成一个 Ticket ，然后再和 web 应用做一个验证 ticket 的交互而已。</p>
<p>3.3.  术语解释<br>CAS 系统中设计了 5 中票据： TGC 、 ST 、 PGT 、 PGTIOU 、 PT 。</p>
<ul>
<li><p>Ticket-granting cookie(TGC) ：存放用户身份认证凭证的 cookie ，在浏览器和 CAS Server 间通讯时使用，并且只能基于安全通道传输（ Https ），是 CAS Server 用来明确用户身份的凭证；</p>
</li>
<li><p>Service ticket(ST) ：服务票据，服务的惟一标识码 , 由 CAS Server 发出（ Http 传送），通过客户端浏览器到达业务服务器端；一个特定的服务只能有一个惟一的 ST ；</p>
</li>
<li><p>Proxy-Granting ticket （ PGT ）：由 CAS Server 颁发给拥有 ST 凭证的服务， PGT 绑定一个用户的特定服务，使其拥有向 CAS Server 申请，获得 PT 的能力；</p>
</li>
<li><p>Proxy-Granting Ticket I Owe You （ PGTIOU ） : 作用是将通过凭证校验时的应答信息由 CAS Server 返回给 CAS Client ，同时，与该 PGTIOU 对应的 PGT 将通过回调链接传给 Web 应用。 Web 应用负责维护 PGTIOU 与 PGT 之间映射关系的内容表；</p>
</li>
<li><p>Proxy Ticket (PT) ：是应用程序代理用户身份对目标程序进行访问的凭证；</p>
</li>
</ul>
<p>其它说明如下：</p>
<ul>
<li><p>Ticket Granting ticket(TGT) ：票据授权票据，由 KDC 的 AS 发放。即获取这样一张票据后，以后申请各种其他服务票据 (ST) 便不必再向 KDC 提交身份认证信息 (Credentials) ；</p>
</li>
<li><p>Authentication service(AS) ——— 认证用服务，索取 Credentials ，发放 TGT ；</p>
</li>
<li><p>Ticket-granting service (TGS) ——— 票据授权服务，索取 TGT ，发放 ST ；</p>
</li>
<li><p>KDC( Key Distribution Center ) ———- 密钥发放中心；</p>
</li>
</ul>
<h1 id="4-CAS-安全性"><a href="#4-CAS-安全性" class="headerlink" title="4. CAS 安全性"></a>4. CAS 安全性</h1><p>CAS 的安全性仅仅依赖于 SSL 。使用的是 secure cookie 。</p>
<h2 id="4-1-TGC-PGT-安全性"><a href="#4-1-TGC-PGT-安全性" class="headerlink" title="4.1. TGC/PGT 安全性"></a>4.1. TGC/PGT 安全性</h2><p>对于一个 CAS 用户来说，最重要是要保护它的 TGC ，如果 TGC 不慎被 CAS Server 以外的实体获得， Hacker 能够找到该 TGC ，然后冒充 CAS 用户访问 所有 授权资源。 PGT 的角色跟 TGC 是一样的。</p>
<p>从基础模式可以看出， TGC 是 CAS Server 通过 SSL 方式发送给终端用户，因此，要截取 TGC 难度非常大，从而确保 CAS 的安全性。</p>
<p>TGT 的存活周期默认为 120 分钟。</p>
<h2 id="4-2-ST-PT-安全性"><a href="#4-2-ST-PT-安全性" class="headerlink" title="4.2. ST/PT 安全性"></a>4.2. ST/PT 安全性</h2><p>ST （ Service Ticket ）是通过 Http 传送的，因此网络中的其他人可以 Sniffer 到其他人的 Ticket 。 CAS 通过以下几方面来使 ST 变得更加安全（事实上都是可以配置的）：</p>
<ol>
<li>ST 只能使用一次</li>
</ol>
<p>CAS 协议规定，无论 Service Ticket 验证是否成功， CAS Server 都会清除服务端缓存中的该Ticket ，从而可以确保一个 Service Ticket 不被使用两次。</p>
<ol start="2">
<li>ST 在一段时间内失效</li>
</ol>
<p>CAS 规定 ST 只能存活一定的时间，然后 CAS Server 会让它失效。默认有效时间为 5 分钟。</p>
<ol start="3">
<li>ST 是基于随机数生成的</li>
</ol>
<p>ST 必须足够随机，如果 ST 生成规则被猜出， Hacker 就等于绕过 CAS 认证，直接访问 对应的服务。</p>
<h1 id="其他开源产品"><a href="#其他开源产品" class="headerlink" title="其他开源产品"></a>其他开源产品</h1><ol>
<li>MaxKey<br>MaxKey(马克思的钥匙)，寓意是最大钥匙， 是用户单点登录认证系统（Sigle Sign On System）,支持OAuth 2.0/OpenID Connect、SAML 2.0、JWT、CAS等标准化的开放协议，提供简单、标准、安全和开放的用户身份认证和单点登录，包含用户认证、单点登录、资源管理、权限管理等。</li>
</ol>
<p>项目地址：<a href="https://gitee.com/shimingxy/MaxKey" target="_blank" rel="noopener">https://gitee.com/shimingxy/MaxKey</a></p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>NGINX配置——nginx location proxy_pass 后面的url 加/与不加/的区别</title>
    <url>/web/NGINX%E9%85%8D%E7%BD%AE-nginx-location-proxy_pass/</url>
    <content><![CDATA[<p>这里分4种情况讨论</p>
<h1 id="整个配置文件是"><a href="#整个配置文件是" class="headerlink" title="整个配置文件是"></a><strong>整个配置文件是</strong></h1><figure class="highlight"><table><tr><td class="code"><pre><span class="line">server&#123;</span><br><span class="line">    port  80,</span><br><span class="line">    server name  192.168.1.123</span><br><span class="line"></span><br><span class="line">    location /static&#123;</span><br><span class="line">        proxy_pass  192.168.2.321:81</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /static&#123;</span><br><span class="line">        proxy_pass  192.168.2.321:81/</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /static/&#123;</span><br><span class="line">        proxy_pass  192.168.2.321:81</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /static/&#123;</span><br><span class="line">        proxy_pass  192.168.2.321:81/</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="1-第一种-location后没有-转发网站没有"><a href="#1-第一种-location后没有-转发网站没有" class="headerlink" title="1. 第一种: location后没有/ 转发网站没有/"></a>1. 第一种: location后没有/ 转发网站没有/</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#192.168.1.123-&gt;server name</span></span><br><span class="line"><span class="comment"># :80 ---------&gt; port</span></span><br><span class="line"><span class="comment">#/statc -------&gt;location</span></span><br><span class="line"><span class="comment">#/a.html ------&gt;proxy_pass </span></span><br><span class="line"></span><br><span class="line">location /static&#123;</span><br><span class="line">    proxy_pass  192.168.2.321:81</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后网址经过nginx转向到的网址是 192.168.2.321:81/static/a.html</p>
<h1 id="2-第二种-location后没有-转发网站有"><a href="#2-第二种-location后没有-转发网站有" class="headerlink" title="2. 第二种: location后没有/ 转发网站有/"></a>2. 第二种: location后没有/ 转发网站有/</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#192.168.1.123----&gt;server name</span></span><br><span class="line"><span class="comment"># :80 ------------&gt; port</span></span><br><span class="line"><span class="comment">#/statc ----------&gt;location</span></span><br><span class="line"><span class="comment">#/a.html ---------&gt;proxy_pass </span></span><br><span class="line"></span><br><span class="line">location /static&#123;</span><br><span class="line">    proxy_pass  192.168.2.321:81/</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后网址经过nginx转向到的网址是 192.168.2.321:81/a.html</p>
<h1 id="3-第三种-location后有-转发网站没有"><a href="#3-第三种-location后有-转发网站没有" class="headerlink" title="3. 第三种: location后有/ 转发网站没有/"></a>3. 第三种: location后有/ 转发网站没有/</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#192.168.1.123--&gt;server name</span></span><br><span class="line"><span class="comment"># :80 ------------&gt; port</span></span><br><span class="line"><span class="comment">#/statc/ ----------&gt;location</span></span><br><span class="line"><span class="comment">#a.html ---------&gt;proxy_pass </span></span><br><span class="line"></span><br><span class="line">location /static/&#123;</span><br><span class="line">    proxy_pass  192.168.2.321:81</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后网址经过nginx转向到的网址是 192.168.2.321:81/static/a.html</p>
<h1 id="4-第四种-location后有-转发网站有"><a href="#4-第四种-location后有-转发网站有" class="headerlink" title="4. 第四种: location后有/ 转发网站有/"></a>4. 第四种: location后有/ 转发网站有/</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#192.168.1.123--&gt;server name</span></span><br><span class="line"><span class="comment"># :80 ------------&gt; port</span></span><br><span class="line"><span class="comment">#/statc/ ----------&gt;location（path1）</span></span><br><span class="line"><span class="comment">#a.html ---------&gt;proxy_pass （path2）</span></span><br><span class="line"></span><br><span class="line">location /static/&#123;</span><br><span class="line">    proxy_pass  192.168.2.321:81/</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后网址经过nginx转向到的网址是 192.168.2.321:81/a.html</p>
<p>总结：</p>
<div class="note primary">
            <p>从这四种我们可以的看出，当nginx里面匹配时可以把端口后的参数分为path1+path2(其中我在上方标注的location属于path1，proxy_pass属于path2)</p><p>当 <strong>proxy_pass</strong></p><ul><li><p>里面是ip:port+/ 时nginx最后匹配的网址是 proxy_pass的内容加上path2</p></li><li><p>里面是ip:port 时nginx最后匹配的网址是 proxy_pass的内容加上path1+path2</p></li></ul>
          </div>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下部署NFS服务</title>
    <url>/web/Linux%E4%B8%8B%E9%83%A8%E7%BD%B2NFS%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<h1 id="一-、-NFS-简介和架构图"><a href="#一-、-NFS-简介和架构图" class="headerlink" title="一 、 NFS 简介和架构图"></a>一 、 NFS 简介和架构图</h1><p>NFS是Network File System的缩写，即网络文件系统。一种使用于分散式文件协定，功能是通过网络让不同的机器、不同的操作系统能够分享个人数据，让应用程序通过网络可以访问位于服务器磁盘中的数据。</p>
<a id="more"></a>
<p>NFS在文件传送或信息传送的过过程中，依赖于RPC协议。RPC，远程过程调用（Remote Procedure Call）,是使客户端能够执行其他系统中程序的一种机制。NFS本身是没有提供信息传输的协议和功能的，但NFS却能让我们通过网络进行资料的分享，就是因为NFS使用了RPC提供的传输协议，可以说NFS就是使用PRC的一个程序。</p>
<p>NFS 存储 服务器主要用于用户上传的数据 ，图片  音频 、等信息 </p>
<p>NFS服务端、RPC协议、客户端三者可以理解为房源、中介、租客之间的关系：<br><img data-src="https://img-blog.csdn.net/2018062513544128?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzQxMDc1MTQ2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<h1 id="二、NFS-适用场景-；"><a href="#二、NFS-适用场景-；" class="headerlink" title="二、NFS 适用场景 ；"></a>二、NFS 适用场景 ；</h1><ul>
<li>2.1 NFS  最好是部署在局域网 ，不要在公网上  ；</li>
<li>2.2 NFS  只能在 linux 上使用 （如果想让 windows 和 Linux 之间实现数据共享建议使用  FTP 或者  samba）；</li>
<li>2.3 NFS 适合在中小型企业使用  ；</li>
</ul>
<h1 id="三、"><a href="#三、" class="headerlink" title="三、"></a>三、</h1><ul>
<li>NFS  服务端干的三件事 <ol>
<li>启动RPC服务</li>
<li>启动NFS服务</li>
<li>向中介注册一次</li>
</ol>
</li>
<li>NFS 客户端干的三件事  <ol>
<li>启动RPC服务</li>
<li>mount命令挂载</li>
<li>向对端rpcbind请求NFS Server端口，NFS服务答复端口信息</li>
</ol>
</li>
</ul>
<p>==========================NFS 部署  环境准备=========================</p>
<h1 id="四、服务端配置"><a href="#四、服务端配置" class="headerlink" title="四、服务端配置"></a>四、服务端配置</h1><p> 环境准备2台  CentOS 7.5 ，IP可以自定义 ；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># cat /etc/redhat-release </span></span><br><span class="line"> CentOS release 7.5 (Final)</span><br></pre></td></tr></table></figure>

<h1 id="五、检查系统中是否安装-NFS-和-RPC-，并进行安装NFS-和RPC；"><a href="#五、检查系统中是否安装-NFS-和-RPC-，并进行安装NFS-和RPC；" class="headerlink" title="五、检查系统中是否安装 NFS 和 RPC ，并进行安装NFS 和RPC；"></a>五、检查系统中是否安装 NFS 和 RPC ，并进行安装NFS 和RPC；</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># rpm -qa nfs-utils rpcbind</span></span><br><span class="line">rpcbind-0.2.0-13.el6.x86_64</span><br><span class="line">nfs-utils-1.2.3-75.el6.x86_64</span><br><span class="line"></span><br><span class="line">[root@NFS ~]<span class="comment"># yum -y install nfs-utils rpcbind    #使用 yum 安装nfs 和 rpc </span></span><br><span class="line">已加载插件：fastestmirror</span><br><span class="line">设置安装进程</span><br><span class="line">Determining fastest mirrors</span><br><span class="line"> * base: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * extras: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">base                                                                                                                         | 3.7 kB     00:00     </span><br><span class="line">extras                                                                                                                       | 3.4 kB     00:00     </span><br><span class="line">extras/primary_db   </span><br><span class="line">```                          </span><br><span class="line"><span class="comment"># 六、在服务端 创建共享目录/data/nfs/，并且属主和属组都为：nfsnobody，其中nfsnobody是安装nfs服务时默认的用户；</span></span><br><span class="line">```bash</span><br><span class="line">[root@NFS ~]<span class="comment"># mkdir -p /data/nfs/</span></span><br><span class="line">[root@NFS ~]<span class="comment">#  chown -R nfsnobody.nfsnobody /data/nfs/</span></span><br><span class="line">[root@NFS ~]<span class="comment"># chmod 666 /data/nfs/</span></span><br><span class="line">[root@NFS ~]<span class="comment"># ll /data/</span></span><br><span class="line">总用量 4</span><br><span class="line">drw-rw-rw-. 2 nfsnobody nfsnobody 4096 6月  27 06:17 nfs</span><br></pre></td></tr></table></figure>

<h1 id="七、编辑配置-NFS-配置文件-；"><a href="#七、编辑配置-NFS-配置文件-；" class="headerlink" title="七、编辑配置 NFS 配置文件 ；"></a>七、编辑配置 NFS 配置文件 ；</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># cat &gt;&gt;/etc/exports&lt;&lt;EOF </span></span><br><span class="line">&gt; /data/nfs 172.16.1.0/24(rw,sync)</span><br><span class="line">&gt; EOF</span><br><span class="line">[root@NFS ~]<span class="comment"># cat /etc/exports </span></span><br><span class="line">/data/nfs 172.16.1.0/24(rw,sync)</span><br><span class="line">``` </span><br><span class="line">其中：/data/nfs 是服务器端共享的目录 </span><br><span class="line">      172.16.1.0/24共享目录的客户端ip地址 </span><br><span class="line">      (rw,sync) ，其中rw代表拥有读写的权限，sync代表数据同步写入NFS服务器端的硬盘中。</span><br><span class="line">      也可以用async，async是大数据时使用，是先写到缓存区，再写到磁盘里。</span><br><span class="line">```bash</span><br><span class="line">[root@NFS ~]<span class="comment"># exportfs -r                           #让配置文件生效</span></span><br></pre></td></tr></table></figure>

<h1 id="八、启动RPC-和-NFS-服务"><a href="#八、启动RPC-和-NFS-服务" class="headerlink" title="八、启动RPC 和 NFS 服务"></a>八、启动RPC 和 NFS 服务</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># /etc/init.d/rpcbind start          # 先启动rpc  </span></span><br><span class="line">[root@NFS ~]<span class="comment"># /etc/init.d/nfs start                  #启动NFS</span></span><br><span class="line">[root@NFS ~]<span class="comment"># /etc/init.d/rpcbind status        #查看一下 rpc 的运行状态 </span></span><br><span class="line">rpcbind (pid  27193) 正在运行...</span><br><span class="line">[root@NFS ~]<span class="comment"># /etc/init.d/nfs status               #查看一下 nfs 的运行状态 </span></span><br><span class="line">rpc.mountd (pid 27337) 正在运行...</span><br><span class="line">nfsd (pid 27353 27352 27351 27350 27349 27348 27347 27346) 正在运行...</span><br></pre></td></tr></table></figure>
<h1 id="九、查看NFS服务是否向rpc注册端口信息，主端口号是：111"><a href="#九、查看NFS服务是否向rpc注册端口信息，主端口号是：111" class="headerlink" title="九、查看NFS服务是否向rpc注册端口信息，主端口号是：111"></a>九、查看NFS服务是否向rpc注册端口信息，主端口号是：111</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># rpcinfo -p localhost</span></span><br><span class="line">    program vers proto   port  service</span><br><span class="line">    100000    4   tcp    111  portmapper</span><br><span class="line">    100000    3   tcp    111  portmapper</span><br><span class="line">    100000    2   tcp    111  portmapper</span><br><span class="line">    100000    4   udp    111  portmapper</span><br><span class="line">    100000    3   udp    111  portmapper</span><br><span class="line">    100000    2   udp    111  portmapper</span><br><span class="line">    100005    1   udp  46776  mountd</span><br><span class="line">    100005    1   tcp  58319  mountd</span><br><span class="line">    100005    2   udp  45857  mountd</span><br><span class="line">    100005    2   tcp  40719  mountd</span><br><span class="line">    100005    3   udp  48297  mountd</span><br><span class="line">    100005    3   tcp  56860  mountd</span><br></pre></td></tr></table></figure>
<p>选项与参数：<br>-p ：针对某 IP (未写则预设为本机) 显示出所有的 port 与 porgram 的信息；<br>-t ：针对某主机的某支程序检查其 TCP 封包所在的软件版本；<br>-u ：针对某主机的某支程序检查其 UDP 封包所在的软件版本；</p>
<h1 id="十-、在NFS设定妥当之后，可以先在服务端自我测试一下是否可以联机！利用-showmount-这个指令来查看！"><a href="#十-、在NFS设定妥当之后，可以先在服务端自我测试一下是否可以联机！利用-showmount-这个指令来查看！" class="headerlink" title="十 、在NFS设定妥当之后，可以先在服务端自我测试一下是否可以联机！利用 showmount 这个指令来查看！"></a>十 、在NFS设定妥当之后，可以先在服务端自我测试一下是否可以联机！利用 showmount 这个指令来查看！</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># showmount -e localhost</span></span><br><span class="line">Export list <span class="keyword">for</span> localhost:</span><br><span class="line">/data/nfs 172.16.1.0/24</span><br><span class="line">[root@NFS ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>
<p>选项与参数：<br>   -a ：显示目前主机与客户端的 NFS 联机分享的状态；<br>   -e ：显示某部主机的 /etc/exports 所分享的目录数据。<br>参数说明：<br>  #rpcinfo  -p     检查nfs服务是否有注册端口信息<br>  #showmount -e    检查共享目录信息 </p>
<h1 id="十一-、设置服务为开机自启-；"><a href="#十一-、设置服务为开机自启-；" class="headerlink" title="十一 、设置服务为开机自启 ；"></a>十一 、设置服务为开机自启 ；</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># chkconfig nfs on</span></span><br><span class="line">[root@NFS ~]<span class="comment"># chkconfig --list nfs</span></span><br><span class="line">nfs            	0:关闭	1:关闭	2:启用	3:启用	4:启用	5:启用	6:关闭</span><br><span class="line">[root@NFS ~]<span class="comment"># chkconfig --list rpcbind</span></span><br><span class="line">rpcbind        	0:关闭	1:关闭	2:启用	3:启用	4:启用	5:启用	6:关闭</span><br><span class="line">[root@NFS ~]<span class="comment"># </span></span><br><span class="line"></span><br><span class="line">[root@NFS ~]<span class="comment"># tail -2 /etc/rc.local           #加入到开机自启中 </span></span><br><span class="line">/etc/init.d/rpcbind start </span><br><span class="line">/etc/init.d/nfs  start</span><br><span class="line">[root@NFS ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p>==========================客户端配置=============================</p>
<h1 id="一-、查看系统中是否有-nfs-和rpc"><a href="#一-、查看系统中是否有-nfs-和rpc" class="headerlink" title="一 、查看系统中是否有 nfs 和rpc"></a>一 、查看系统中是否有 nfs 和rpc</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rsync ~]<span class="comment">#  rpm -qa nfs-utils rpcbind</span></span><br><span class="line"></span><br><span class="line">rpcbind-0.2.0-13.el6.x86_64</span><br><span class="line">nfs-utils-1.2.3-75.el6.x86_64</span><br></pre></td></tr></table></figure>
<h1 id="二-、进行安装服务，并启动服务-；"><a href="#二-、进行安装服务，并启动服务-；" class="headerlink" title="二 、进行安装服务，并启动服务  ；"></a>二 、进行安装服务，并启动服务  ；</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rsync ~]<span class="comment"># yum -y install nfs-utils rpcbind</span></span><br><span class="line">已加载插件：fastestmirror</span><br><span class="line">设置安装进程</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.huaweicloud.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">base                                                                                                                         | 3.7 kB     00:00     </span><br><span class="line">extras                                                                                                                       | 3.4 kB     00:00     </span><br><span class="line">updates                                                                                                                      | 3.4 kB     00:00     </span><br><span class="line">包 1:nfs-utils-1.2.3-75.el6_9.x86_64 已安装并且是最新版本</span><br></pre></td></tr></table></figure>
<p>解决依赖关系</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rsync ~]<span class="comment"># /etc/init.d/rpcbind start</span></span><br><span class="line">[root@rsync ~]<span class="comment"># /etc/init.d/nfs start</span></span><br><span class="line">启动 NFS 服务：                                            [确定]</span><br><span class="line">启动 NFS mountd：                                          [确定]</span><br><span class="line">启动 NFS 守护进程：                                        [确定]</span><br><span class="line">正在启动 RPC idmapd：                                      [确定]</span><br></pre></td></tr></table></figure>

<h1 id="三-、创建挂载目录-；"><a href="#三-、创建挂载目录-；" class="headerlink" title="三 、创建挂载目录  ；"></a>三 、创建挂载目录  ；</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rsync]<span class="comment"># mkdir -p /data/nfs</span></span><br></pre></td></tr></table></figure>
<h1 id="四-、查看客户端是否可以收到服务端的共享信息-；"><a href="#四-、查看客户端是否可以收到服务端的共享信息-；" class="headerlink" title="四 、查看客户端是否可以收到服务端的共享信息 ；"></a>四 、查看客户端是否可以收到服务端的共享信息 ；</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rsync nfs]<span class="comment"># showmount -e 172.16.1.9</span></span><br><span class="line">Export list <span class="keyword">for</span> 172.16.1.9:</span><br><span class="line">/data/nfs 172.16.1.0/24</span><br></pre></td></tr></table></figure>
<h1 id="五-、进行nfs-共享目录的挂载-；"><a href="#五-、进行nfs-共享目录的挂载-；" class="headerlink" title="五 、进行nfs 共享目录的挂载 ；"></a>五 、进行nfs 共享目录的挂载 ；</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rsync nfs]<span class="comment"># mount -t nfs 172.16.1.9:/data/nfs /mnt</span></span><br><span class="line"></span><br><span class="line">[root@rsync nfs]<span class="comment"># df -h</span></span><br><span class="line">Filesystem        Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda2          20G  2.7G   16G  15% /</span><br><span class="line">tmpfs             931M     0  931M   0% /dev/shm</span><br><span class="line">/dev/sda1         190M   39M  141M  22% /boot</span><br><span class="line">172.16.1.9:/data/nfs    20G  2.7G   16G  15% /mnt</span><br></pre></td></tr></table></figure>

<p>服务端 ；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@NFS nfs]<span class="comment"># echo "nfs" &gt; test.txt</span></span><br></pre></td></tr></table></figure>
<p>客户端创建一个文件 ；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@rsync data]<span class="comment"># cat /data/nfs/test.txt</span></span><br><span class="line">nfs</span><br></pre></td></tr></table></figure>
<p>########################### nfs常见问题排错思 ############################### </p>
<ul>
<li>nfs共享目录权限相关因素<br>①. 配置文件中的权限指定<br>②. 共享目录本身的权限，有w权限<br>③. 共享目录本身的所属用户与所属组的权限指定</li>
</ul>
<p>#########################  NFS客户端挂载排错思路  ###########################<br>客户端排查三部曲<br>①. 检查服务端房源信息是否还在<br>    rpcinfo -p 172.16.1.9<br>②. 检查服务端共享目录信息是否存在<br>    showmount -e 172.16.1.9<br>③. 直接进行目录挂载测试<br>    mount -t nfs 172.16.1.9:/data /mnt</p>
<p>#########################  服务端排查三部曲  #################################<br>①. 检查服务端房源信息是否还在<br>    rpcinfo -p localhost<br>    如果没有注册的房源信息了，会是什么情况？<br>    ①. nfs服务没有启动<br>    ②. nfs服务于rpc服务启动顺序不正确<br>②. 检查服务端共享目录信息是否存在<br>    showmount -e localhost<br>    ①. nfs配置文件编写格式错误<br>③. 直接进行目录挂载测试<br>    mount -t nfs 172.16.1.9:/data /mnt</p>
<h1 id="实现nfs客户端开机自动挂载方式"><a href="#实现nfs客户端开机自动挂载方式" class="headerlink" title="实现nfs客户端开机自动挂载方式"></a>实现nfs客户端开机自动挂载方式</h1><p>①. 将挂在命令追加到/etc/rc.local开机自启动文件中<br>②. 编写fstab文件，并且需要配合netfs服务使用，实现开机自动挂载</p>
<h3 id="nfs常见问题排错"><a href="#nfs常见问题排错" class="headerlink" title="nfs常见问题排错"></a>nfs常见问题排错</h3><p>示例1：客户端挂载报错“No such file or directory”<br>[root@nfs-client ~]# showmount -e 172.16.1.9<br>Export list for 172.16.1.9:<br>/data    172.16.1.0/24<br>[root@nfs-client ~]# mount -t nfs 172.16.1.9:/data /mnt<br>mount.nfs: mounting 172.16.1.9:/data failed, reason given by server: No such file or directory<br>解答：原因是NFS服务器端没有共享目录/data，创建即可。命令如下：<br>[root@nfs-server ~]# mkdir /data</p>
<p>示例2：NFS服务器端启动失败，如下：<br>[root@nfs-server ~]# /etc/init.d/nfs start<br>Starting NFS services:                                [  OK  ]<br>Starting NFS quotas: Cannot register service: RPC: Unable to receive; errno = Connection refused<br>rpc.rquotad: unable to register (RQUOTAPROG, RQUOTAVERS, udp).<br>                                                     [FAILED]<br>Starting NFS mountd:                                [FAILED]<br>Starting NFS daemon: rpc.nfsd: writing fd to kernel failed: errno 111 (Connection refused)<br>rpc.nfsd: unable to set any sockets for nfsd<br>                                                     [FAILED]<br>解答：这是因为RPC服务没有在NFS前面启动，需要先启动RPC服务再启动NFS，解决方法为，按顺序启动rpcbind及NFS，命令如下：<br>[root@nfs-server ~]# /etc/init.d/rpcbind restart<br>[root@nfs-server ~]# /etc/init.d/nfs restart</p>
<p>示例3：注册RPC服务失败，出现failed：RPC Error：Program not registered错误。<br>[root@nfs-client ~]# mount -t nfs 172.16.1.9:/data /mnt<br>mount.nfs: requested NFS version or transport protocol is not supported<br>[root@nfs-client ~]# showmount -e 172.16.1.9<br>clnt_create: RPC: Program not registered<br>解答：服务器端的NFS没有启动，客户端没有收到服务器端发来的随机端口信息。<br>解决方法如下：<br>[root@nfs-server ~]# /etc/init.d/rpcbind restart<br>[root@nfs-server ~]# /etc/init.d/nfs restart</p>
<p>示例4：卸载挂载设备时显示device is busy。<br>[root@nfs-client mnt]# umount /mnt<br>umount.nfs: /mnt: device is busy<br>umount.nfs: /mnt: device is busy<br>解答：有可能是当前目录就是挂载的NFS目录（/mnt），也有可能是NFS Server挂了。对于第一种情况，解决办法为退出挂载目录/mnt，再执行umount /mnt卸载。对于第二种情况，NFS Server挂了，NFS Client就会出现问题（df -h窗口会死掉），这时只能强制卸载，方法为：<br>umount -lf /mnt     其中的参数-f为强制卸载，参数-l为懒惰的卸载。</p>
<p>示例5：CentOS 6.6客户端NFS挂载时遇到问题。<br>[root@nfs-client ~]# mount -t nfs 172.16.1.9:/data /mnt<br>mount：wrong fs type，bad option，bad option，bad superblock on 10.0.0.7:/data,<br>   missing codepage or helper program，or other error<br>   (for several filesystems (e.g. nfs, cifs) you might<br>need a /sbin/mount.<type> helper program )<br>In some cases useful info is found in syslog - try<br>meg | tail or so<br>排查思路：同样的机器，NFS服务器本地可以挂载，但是客户端挂载时wrong fs type，因此尝试所有客户端安装nfs-utils。CentOS6.5及以前的NFS没有遇到这个问题。<br>解决方法：执行yum install nfs-utils -y，客户端安装NFS软件，但不启动服务。</p>
<p>示例六：共享目录挂载很卡<br>mount -t nfs 172.16.1.9:/data /mnt<br>cd /mnt<br>time touch test.txt<br>原因分析：<br>    NFS服务端重启之后。立刻进行挂载会出现此问题，因为NFS自身重启的时候，拥有无敌的时间，默认是90秒；在无敌时间内，是不能对共享目录进行更改的操作；<br>    在系统配置中/etc/sysconfig/nfs中指定了无敌时间的配置参数<br>NFSD_V4_GRACE=90<br>NFSD_V4_LEASE=90<br>NLM_GRACE_PERI0D=90<br>find /proc -name | grep -i ” NLM_GRACE_PERIOD”<br>find /proc -iname ” NLM_GRACE_PERIOD”<br>    重启NFS服务没有按照顺序进行重启，一旦NFS重启了，需要确认rpcbind服务有没有接收，即rpcinfo -p localhost；先启动rpcbind服务再启动nfs服务</p>
<p>示例七：ls: cannot open directory .: Stale file handle<br>Stale file handle<br>客户端报错<br>mount -t nfs 172.16.1.9:/data  /mnt<br>mount.nfs: Stale file handle<br>服务端挂载报错<br>[root@nfs01 data]# mount -t nfs 172.16.1.9:/data /mnt/<br>mount.nfs: access denied by server while mounting 172.16.1.9:/data<br>查看配置文件发现<br>[root@nfs01 data]# cat /etc/exports<br>#share /data  by lidao  at 20160913<br>/data 173.16.1.0/24(rw,sync)<br>原因分析：</p>
<ul>
<li>/proc/mounts客户端挂载文件中已经存在了相应的挂载记录，没有正确卸载掉，就再次进行挂载，就会出现以上错误。</li>
</ul>
<h1 id="挂载腾讯CFS"><a href="#挂载腾讯CFS" class="headerlink" title="挂载腾讯CFS"></a>挂载腾讯CFS</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install nfs-utils</span><br><span class="line">[root@node1 ~]<span class="comment"># mkdir /alan</span></span><br><span class="line">[root@node1 ~]<span class="comment"># mount -t nfs -o vers=4.0 挂载点IP:/ 待挂载目标目录</span></span><br></pre></td></tr></table></figure>
<ul>
<li>挂载点IP：指创建文件系统时，自动的生成的挂载点 IP。</li>
<li>目前默认挂载的是文件系统的根目录/。 在文件系统中创建子目录后，可以挂载该子目录。</li>
<li>待挂载目标目录： 在当前服务器上，需要挂载的目标目录，需要用户事先创建。<div class="note warning">
            <p>注意：<br>&lt;挂载点IP&gt;:/与&lt;待挂载目标目录&gt;之间有一个空格。</p>
          </div>


</li>
</ul>
<p>参考:<br><a href="https://blog.csdn.net/sinat_41075146/article/details/80800812" target="_blank" rel="noopener">https://blog.csdn.net/sinat_41075146/article/details/80800812</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>CDN</title>
    <url>/web/cdn/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>CDN的全称是Content Delivery Network，即内容分发网络。其基本思路是尽可能避开互联网上<strong>有可能影响数据传输速度和稳定性的瓶颈和环节</strong>，<a id="more"></a>使内容传输的更快、更稳定。通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。</p>
<p>CDN的好处不止是加速，还可以有效地降低源站负载，降低高额的带宽成本(不必按峰值带宽直接向ISP购买带宽)，防止DDOS攻击等。</p>
<p><strong>通常网络访问中会有”三公里”路程</strong></p>
<ul>
<li>第一公里为:源站到ISP接入点</li>
<li>第二公里为:源站ISP接入点到访问用户的ISP接入点</li>
<li>第三公里(最后一公里)为:用户ISP接入点到用户客户端</li>
</ul>
<div class="note primary">
            <ul><li>第一公里的耗时取决于源站自身响应能力和出口带宽</li><li>第二公里的耗时取决于从源站的接入点到最终用户的接入点之间的传输路径,主要为网络运营商之间的互连瓶颈问题，不同地区骨干网之间的数据交换、传输，会导致传输途中的路由阻塞和延迟</li><li>第三公里的耗时取决于最终用户接入Internet的方式,会越来越快,以后不会是瓶颈</li></ul>
          </div>


<p>而CDN网络层主要用来加速第二公里,怎么加速呢?原理并不难,下面简单介绍下</p>
<p>首先看下访问网站的一个普通流程:</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/web/cdn/cdn-1.png/w600">

<p>再看下有CDN层的访问流程</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/web/cdn/cdn-2.png/w600">

<p><strong>负载均衡集群</strong>：它是一个CDN网络的神经中枢，主要功能是负责对所有发起服务请求的用户进行访问调度，确定提供给用户的最终实际访问地址(即哪一台边缘Cache机)。</p>
<p>大多数CDN系统的负载均衡系统是分级实现的。一般而言，两级调度体系分为全局负载均衡(GSLB)和本地负载均衡(SLB)。</p>
<ul>
<li>全局负载均衡(GSLB)主要根据用户就近性原则，通过对每个服务节点进行”最优”判断，确定向用户提供服务的Cache的物理位置。最通用的GSLB实现方法是基于DNS解析的方式实现，也有一些系统采用了应用层重定向等方式来解决。</li>
<li>本地负载均衡(SLB)主要负责节点内部的设备负载均衡，当用户请求从GSLB调度到SLB时，SLB会根据节点内各Cache设备的实际能力或内容分布等因素对用户进行重定向，常用的本地负载均衡方法有基于4层调度(常用的LVS)、基于7层调度(常用的nginx)、链路负载调度(DNS)等。</li>
</ul>
<p><strong>源站WEB服务器内容到CDN边缘节点集群主要用两种内容分发技术</strong></p>
<ul>
<li>PUSH即主动分发，通常由CDN厂商的内容管理系统发起(主动刷新)，将内容从源或者中心资源库分发到各边缘的Cache节点。</li>
<li>PULL是被动分发，通常由用户请求驱动，当用户请求的内容在本地的边缘Cache上不存在(未命中)时，Cache启动PULL方法从源站或者其他CDN节点即时获取内容。</li>
</ul>
<p><strong>业界做的比较好的CDN厂商：</strong></p>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP协议详解</title>
    <url>/web/http/</url>
    <content><![CDATA[<h1 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/MNbjdnSeoeSlTwuXokaXMQ" target="_blank" rel="noopener">HTTP/2到底是什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s/qnBExJ0sjVmhk8UTxAPK1Q" target="_blank" rel="noopener">彻底弄懂 HTTP 缓存机制及原理</a><a id="more"></a></li>
<li><a href="https://blog.csdn.net/danielzhou888/article/details/72861097" target="_blank" rel="noopener">Http中Content-Type的详解</a></li>
</ul>
<hr>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>HTTP协议是指计算机通信网络中两台计算机之间进行通信所必须共同遵守的规定或规则，超文本传输协议(HTTP)是一种通信协议，它允许将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器。</p>
<p>原理：浏览器给Web服务器发送了一个Request, Web服务器接到Request后进行处理，生成相应的Response，然后发送给浏览器， 浏览器解析Response中的HTML,这样我们就看到了网页。有时中间可能会经过一个代理服务器。</p>
<p><strong>HTTP本身是无状态的，同一个客户端请求，这次和上次没有关联，服务器并不知道两次请求会来自同一个客户端，所以会引入cookie机制。</strong>（典型场景就是登录，如果没有这种机制，永远无法知道用户是否登录）<br>交互方法：GET,POST,PUT,DELETE。对应资源的查、改、增、删。</p>
<p>Get将数据放在url后面，安全性差，且对提交的数据长度有限制。而post提交没有限制。</p>
<hr>
<h1 id="Web组件化"><a href="#Web组件化" class="headerlink" title="Web组件化"></a>Web组件化</h1><p>浏览器分析Response中的 HTML，发现其中引用了很多其他文件，比如图片，CSS文件，JS文件。浏览器会自动发起请求下载相关文件，等所有文件下载结束，整个页面也就渲染完成。</p>
<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="Request消息的结构"><a href="#Request消息的结构" class="headerlink" title="Request消息的结构"></a>Request消息的结构</h2><p>Request 消息分为3部分，第一部分叫Request line, 第二部分叫Request header, 第三部分是body。header和body之间有个空行</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/web/http/http-req.png/w600">

<h2 id="Response消息的结构"><a href="#Response消息的结构" class="headerlink" title="Response消息的结构"></a>Response消息的结构</h2><p>Response和Request消息的结构基本一样。 同样也分为三部分,第一部分叫Response line, 第二部分叫Response header，第三部分是body。header和body之间也有个空行。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/web/http/http-resp.png/w600">


<h1 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h1><p>HTTP/1.1中定义了5类状态码， 状态码由三位数字组成，第一个数字定义了响应的类别</p>
<div class="note primary">
            <p>1XX  提示信息 - 表示请求已被成功接收，继续处理<br>2XX  成功 - 表示请求已被成功接收，理解，接受<br>3XX  重定向 - 要完成请求必须进行更进一步的处理<br>4XX  客户端错误 -  请求有语法错误或请求无法实现<br>5XX  服务器端错误 -   服务器未能实现合法的请求<br>302：外部重定向，新的URL会在response 中的Location中返回，浏览器将会自动使用新的URL发出新的Request。移除是临时的。<br>实现方式： response.sendRedirect(“<a href="http://www.brainysoftware.com&quot;)。client浏览器的url会有变化。" target="_blank" rel="noopener">http://www.brainysoftware.com&quot;)。client浏览器的url会有变化。</a><br>补充一点：内部重定向。重定向到一个新的页面并附加一些参数。服务器内部逻辑。Client浏览器的url不会变化。<br>实现方式：request. getRequestDispatcher().forward(request,response);通过request.setAttribute()可以补充信息。<br>301：Moved Permanently（永久移除）。请求的URL已移走。Response中应该包含一个Location URL, 说明资源现在所处的位置<br>304 ：Not Modified，采用本地缓存。<br>案例：之前B2B有次发布失败，后端java代码和js都回滚了，但客户那边依然是样式错乱，后来是因为访问过新页面，加载了新的js，但是回滚后的js的最后修改时间依然是旧的，这样客户那边实际是旧的页面、新的js。解决方案，旧js重新打包，最后修改时间变了。<br>400 Bad Request  客户端请求语法错误，不能被服务器所理解<br>403 Forbidden 服务器收到请求，但是拒绝提供服务<br>404 Not Found 文件资源不存在<br>500 Internal Server Error 服务器发生了不可预期的错误<br>503 Server Unavailable 服务器当前不能处理客户端的请求，一段时间后可能恢复正常</p>
          </div>

<h1 id="Request相关（协议参数）"><a href="#Request相关（协议参数）" class="headerlink" title="Request相关（协议参数）"></a>Request相关（协议参数）</h1><ul>
<li>URL：</li>
</ul>
<p>URL(Uniform Resource Locator) 地址用于描述一个网络上的资源,  基本格式如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">schema://host[:port<span class="comment">#]/path/.../[?query-string][#anchor]</span></span><br><span class="line">scheme               指定低层使用的协议(例如：http, https, ftp)</span><br><span class="line">host                   HTTP服务器的IP地址或者域名</span><br><span class="line">port<span class="comment">#                 HTTP服务器的默认端口是80，这种情况下端口号可以省略。如果使用了别的端口，必须指明，例如 http://www.cnblogs.com:8080/</span></span><br><span class="line">path                   访问资源的路径</span><br><span class="line">query-string       发送给http服务器的数据</span><br><span class="line">anchor-             锚</span><br><span class="line">URL 的一个例子</span><br><span class="line">http://www.mywebsite.com/sj/<span class="built_in">test</span>/test.aspx?name=sviergn&amp;x=<span class="literal">true</span><span class="comment">#stuff</span></span><br><span class="line">Schema:                 http</span><br><span class="line">host:                   www.mywebsite.com</span><br><span class="line">path:                   /sj/<span class="built_in">test</span>/test.aspx</span><br><span class="line">Query String:           name=sviergn&amp;x=<span class="literal">true</span></span><br><span class="line">Anchor:                 stuff</span><br></pre></td></tr></table></figure>


<ul>
<li>Accept</li>
</ul>
<p>作用： 浏览器端可以接受的媒体类型,</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">例如：  Accept: text/html  代表浏览器可以接受服务器回发的类型为 text/html  也就是我们常说的html文档,</span><br><span class="line"></span><br><span class="line">如果服务器无法返回text/html类型的数据,服务器应该返回一个406错误(non acceptable)</span><br><span class="line"></span><br><span class="line">通配符 * 代表任意类型</span><br><span class="line"></span><br><span class="line">例如  Accept: */*  代表浏览器可以处理所有类型,(一般浏览器发给服务器都是发这个)</span><br></pre></td></tr></table></figure>

<ul>
<li>Referer</li>
</ul>
<p>作用： 提供了Request的上下文信息的服务器，告诉服务器我是从哪个链接过来的，比如从我主页上链接到一个朋友那里，他的服务器就能够从HTTP Referer中统计出每天有多少用户点击我主页上的链接访问他的网站。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">例如: Referer: http://translate.google.cn/?hl=zh-cn&amp;tab=wT</span><br></pre></td></tr></table></figure>

<ul>
<li>Accept-Language</li>
</ul>
<p>作用： 浏览器申明自己接收的语言。</p>
<p>语言跟字符集的区别：中文是语言，中文有多种字符集，比如big5，gb2312，gbk等等；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如： Accept-Language: en-us</span><br></pre></td></tr></table></figure>

<ul>
<li>Content-Type</li>
</ul>
<p>作用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如：Content-Type: application&#x2F;x-www-form-urlencoded</span><br></pre></td></tr></table></figure>

<ul>
<li>Accept-Encoding：</li>
</ul>
<p>作用： 浏览器申明自己接收的编码方法，通常指定压缩方法，是否支持压缩，支持什么压缩方法（gzip，deflate），（注意：这不是只字符编码）;</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如： Accept-Encoding: gzip, deflate</span><br></pre></td></tr></table></figure>

<ul>
<li>User-Agent</li>
</ul>
<p>作用：告诉HTTP服务器， 客户端使用的操作系统和浏览器的名称和版本.<br>我们上网登陆论坛的时候，往往会看到一些欢迎信息，其中列出了你的操作系统的名称和版本，你所使用的浏览器的名称和版本，这往往让很多人感到很神奇，实际上，服务器应用程序就是从User-Agent这个请求报头域中获取到这些信息User-Agent请求报头域允许客户端将它的操作系统、浏览器和其它属性告诉服务器。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如： User-Agent: Mozilla&#x2F;4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident&#x2F;4.0; CIBA; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET4.0C; InfoPath.2; .NET4.0E)</span><br></pre></td></tr></table></figure>

<ul>
<li>Connection</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如：　Connection: keep-alive   当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接</span><br><span class="line"></span><br><span class="line">例如：  Connection: close  代表一个Request完成后，客户端和服务器之间用于传输HTTP数据的TCP连接会关闭， 当客户端再次发送Request，需要重新建立TCP连接。</span><br></pre></td></tr></table></figure>

<ul>
<li>Content-Length</li>
</ul>
<p>作用：发送给HTTP服务器数据的长度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如： Content-Length: 38</span><br></pre></td></tr></table></figure>

<ul>
<li>Pragma</li>
</ul>
<p>作用： 防止页面被缓存， 在HTTP/1.1版本中，它和Cache-Control:no-cache作用一模一样<br>Pargma只有一个用法， 例如： Pragma: no-cache<br>注意: 在HTTP/1.0版本中，只实现了Pragema:no-cache, 没有实现Cache-Control</p>
<ul>
<li>Cookie:</li>
</ul>
<p>作用： 最重要的header, 将cookie的值发送给HTTP 服务器</p>
<ul>
<li>Accept-Charset</li>
</ul>
<p>作用：浏览器申明自己接收的字符集，如gb2312，utf-8（通常我们说Charset包括了相应的字符编码方案）；</p>
<ul>
<li>If-Modified-Since</li>
</ul>
<p>作用： 把浏览器端缓存页面的最后修改时间发送到服务器去，服务器会把这个时间与服务器上实际文件的最后修改时间进行对比。如果时间一致，那么返回304，客户端就直接使用本地缓存文件。如果时间不一致，就会返回200和新的文件内容。客户端接到之后，会丢弃旧文件，把新文件缓存起来，并显示在浏览器中.<br>例如：If-Modified-Since: Thu, 09 Feb 2012 09:07:57 GMT</p>
<ul>
<li>If-None-Match</li>
</ul>
<p>作用: If-None-Match和ETag一起工作，工作原理是在HTTP Response中添加ETag信息。 当用户再次请求该资源时，将在HTTP Request 中加入If-None-Match信息(ETag的值)。如果服务器验证资源的ETag没有改变（该资源没有更新），将返回一个304状态告诉客户端使用本地缓存文件。否则将返回200状态和新的资源和Etag。使用这样的机制将提高网站的性能。<br>例如: If-None-Match: “03f2b33c0bfcc1:0”</p>
<hr>
<h1 id="Response相关（协议参数）"><a href="#Response相关（协议参数）" class="headerlink" title="Response相关（协议参数）"></a>Response相关（协议参数）</h1><ul>
<li>Cache-Control</li>
</ul>
<p>作用: 这个是非常重要的规则。 这个用来指定Response-Request遵循的缓存机制。各个指令含义如下</p>
<div class="note primary">
            <ul><li>Cache-Control:Public   响应被缓存，并且在多用户间共享</li><li>Cache-Control:Private     响应只能作为私有缓存，不能在用户之间共享</li><li>Cache-Control:no-cache  提醒浏览器要从服务器提取文档进行验证</li><li>Cache-Control:no-store     绝对禁止缓存（用于机密，敏感文件）</li><li>Cache-Control: max-age=60    60秒之后缓存过期（相对时间）</li></ul>
          </div>

<ul>
<li>Content-Type</li>
</ul>
<p>作用：WEB服务器告诉浏览器自己响应的对象的类型和字符集,</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Content-Type: text&#x2F;html; charset&#x3D;utf-8</span><br><span class="line">Content-Type:text&#x2F;html;charset&#x3D;GB2312</span><br><span class="line">Content-Type: image&#x2F;jpeg</span><br></pre></td></tr></table></figure>

<ul>
<li>Expires</li>
</ul>
<p>作用: 浏览器会在指定过期时间内使用本地缓存</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Expires: Tue, 08 Feb 2022 11:35:14 GMT</span><br></pre></td></tr></table></figure>


<ul>
<li>Last-Modified:</li>
</ul>
<p>作用： 表示资源最后修改时间</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如: Last-Modified: Wed, 21 Dec 2011 09:09:10 GMT</span><br></pre></td></tr></table></figure>

<ul>
<li>Etag</li>
</ul>
<p>主要为了解决Last-Modified无法解决的一些问题，它比Last_Modified更加精确的知道文件是否被修改过。如果一个文件修改非常频繁，比如1秒内修改了10次，If-Modified-Since只能检查到秒级别的修改。</p>
<ul>
<li>Server:</li>
</ul>
<p>作用：指明HTTP服务器的软件信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如:Server: Microsoft-IIS&#x2F;7.5</span><br></pre></td></tr></table></figure>

<ul>
<li>Connection</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如：　Connection: keep-alive   当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接</span><br><span class="line"></span><br><span class="line">例如：  Connection: close  代表一个Request完成后，客户端和服务器之间用于传输HTTP数据的TCP连接会关闭， 当客户端再次发送Request，需要重新建立TCP连接。</span><br></pre></td></tr></table></figure>

<ul>
<li>Content-Length</li>
</ul>
<p>指明实体正文的长度，以字节方式存储的十进制数字来表示。在数据下行的过程中，Content-Length的方式要预先在服务器中缓存所有数据，然后所有数据再一股脑儿地发给客户端。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如: Content-Length: 19847</span><br></pre></td></tr></table></figure>

<h1 id="压缩过程"><a href="#压缩过程" class="headerlink" title="压缩过程"></a>压缩过程</h1><ul>
<li>浏览器发送Http request 给Web服务器,  request 中有Accept-Encoding: gzip, deflate。 (告诉服务器， 浏览器支持gzip压缩)</li>
<li>Web服务器接到request后， 生成原始的Response, 其中有原始的Content-Type和Content-Length。 </li>
<li>Web服务器通过Gzip，来对Response进行编码， 编码后header中有Content-Type和Content-Length(压缩后的大小)， 并且增加了Content-Encoding:gzip.  然后把Response发送给浏览器。</li>
<li>浏览器接到Response后，根据Content-Encoding:gzip来对Response 进行解码。 获取到原始response后， 然后显示出网页。<br>压缩可以将大小缩小为原来的40%，减少60%的数据传输，节省网络流量。</li>
</ul>
<p><strong>Content-Encoding值：</strong></p>
<div class="note primary">
            <ul><li><p>gzip　　表明实体采用GNU zip编码</p></li><li><p>compress 表明实体采用Unix的文件压缩程序</p></li><li><p>deflate　　表明实体是用zlib的格式压缩的</p></li><li><p>identity　　表明没有对实体进行编码。当没有Content-Encoding header时， 就默认为这种情况</p></li><li><p>gzip, compress, 以及deflate编码都是无损压缩算法，用于减少传输报文的大小，不会导致信息损失。 其中gzip通常效率最高， 使用最为广泛。</p></li><li><p>Gzip压缩原理：Gzip压缩是在一个文本文件中找出类似的字符串，并临时替换他们，使整个文件变小。这种形式的压缩对Web来说非常适合，因为HTML和css文件通常包含大量的重复的字符串,例如空格，标签。</p></li></ul>
          </div>


<pre><code></code></pre>]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>负载均衡</title>
    <url>/web/load-balance/</url>
    <content><![CDATA[<h1 id="LVS"><a href="#LVS" class="headerlink" title="LVS"></a>LVS</h1><ul>
<li><a href="../lvs">LVS</a><a id="more"></a>

</li>
</ul>
<h1 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/oqlORS7dQvsIOEWRyhmfaw" target="_blank" rel="noopener">使用nginx作为HTTP负载均衡</a></li>
<li><a href="https://mp.weixin.qq.com/s/9aHs_eF0KPmF14bMLBQrvg" target="_blank" rel="noopener">高性能负载均衡：nginx搭建tomcat集群</a></li>
</ul>
<h1 id="HAProxy"><a href="#HAProxy" class="headerlink" title="HAProxy"></a>HAProxy</h1><h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/vg7XusGchg09nXmRh5DU7A" target="_blank" rel="noopener">分布式架构下的“负载均衡”</a></li>
</ul>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>LVS</title>
    <url>/web/lvs/</url>
    <content><![CDATA[<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/NONdqdYMgsXsfE3l0cYpTg" target="_blank" rel="noopener">LoadBalance软件对比分析和应用场景总结</a><a id="more"></a>

</li>
</ul>
<hr>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>面对互联网的高并发和大流量，为了平摊访问压力，通常会引入负载均衡，作为流量的入口，将请求转发给一台合适的无状态的服务器，处理用户请求，对用户是无感知的。</p>
<p><strong>软负载均衡有以下几种：</strong></p>
<ul>
<li>全局负载均衡（pharos）</li>
<li>4层负载均衡（lvs）</li>
<li>7层负载均衡（haproxy、nginx）</li>
</ul>
<p>常规的互联网架构：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/web/lvs/lvs-1.png/w600">

<h1 id="LVS的工作模式："><a href="#LVS的工作模式：" class="headerlink" title="LVS的工作模式："></a>LVS的工作模式：</h1><h2 id="1-DR"><a href="#1-DR" class="headerlink" title="1.DR"></a>1.DR</h2><p>性能最好的一种模式。</p>
<p>前提：要求LVS机器和Real Server绑定同一个VIP。</p>
<p>过程：</p>
<ul>
<li>用户发起一个请求</li>
<li>lvs接收到，将网络帧的MAC地址修改为某一台Real Server的MAC，数据包就会被转发给相应的RS处理（数据包的源ip和目标ip都没有变，只是服务器的mac变了）</li>
<li>RS接收到请求，验证ip、mac信息，都验证通过，处理业务</li>
<li>将响应的数据包返回给源ip</li>
</ul>
<p>缺点：</p>
<ul>
<li>LVS和RS必须在同一个VLAN；RS上绑vip，风险高</li>
</ul>
<h2 id="2-NAT（Netowrk-Address-Translation）"><a href="#2-NAT（Netowrk-Address-Translation）" class="headerlink" title="2.NAT（Netowrk Address Translation）"></a>2.NAT（Netowrk Address Translation）</h2><p>LVS充当网关的角色，所有的网络报文的进出都要经过LVS</p>
<p>过程：</p>
<ul>
<li>客户端发起请求，数据包到达lvs</li>
<li>lvs做目标地址转换（DNAT），将目标ip改为RS的ip</li>
<li>RS进行业务逻辑处理，返回响应数据，源ip是RS的ip，目标ip是客户端的ip</li>
<li>数据包经过LVS网关中转，源地址转换（SNAT），将源ip改为LVS的ip</li>
<li>客户端无法感知后端RS的存在</li>
</ul>
<h2 id="3-Full-NAT"><a href="#3-Full-NAT" class="headerlink" title="3.Full-NAT"></a>3.Full-NAT</h2><p>主要是为了解决LVS和RS的跨VLAN的问题，LVS和RS不再存在VLAN的从属关系，做到多个LVS对应多个RS，从而解决水平扩容问题；另外in/out流都经过LVS。</p>
<p>主要思想：<br>引入local address(内网ip地址)，cip-vip转换为lip-&gt;rip，而lip和rip均为IDC内网ip，可以跨vlan通讯;</p>
<p>过程：</p>
<ul>
<li>客户端发起请求，来源为client ip,目标是LVS的vip</li>
<li>数据到LVS网关，经过SNAT+ DNAT，客户端ip换成LVS的内网ip，目标是RS的ip</li>
<li>内网ip可以经过多个交换机跨VLAN通信</li>
<li>RS机器接收并处理完业务，响应数据包时，来源是RS的ip，目标是LVS的内网ip，</li>
<li>LVS接到响应包，经过SNAT+ DNAT，修改地址，来源为LVS的vip，目标是client ip</li>
</ul>
<p>示例：</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/web/lvs/lvs-2.png/w600">

<div class="note primary">
            <p>注：<br>LVS内部维护着一个session的Hash表，可以通过客户端的一些信息找到对应的RS，避免同一连接的TCP包被转发到不同的RS机器上。</p>
          </div>

]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx详解</title>
    <url>/web/nginx/</url>
    <content><![CDATA[<h1 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h1><ul>
<li><a href="http://jinnianshilongnian.iteye.com/blog/2186448" target="_blank" rel="noopener">nginx+lua</a></li>
<li><a href="https://mp.weixin.qq.com/s/YrC8aPZHtDlDL2Fqku2fbA" target="_blank" rel="noopener">Nginx配置文件及模块</a></li>
</ul>
<a id="more"></a>
<ul>
<li><p><a href="https://mp.weixin.qq.com/s/-tbku61HLKWXPoKypXGFHg" target="_blank" rel="noopener">全面了解 Nginx 到底能做什么</a></p>
</li>
<li><p><a href="../nginx映射本地文件">Nginx映射本地文件</a></p>
</li>
</ul>
<hr>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>￼Nginx做为一款高性能的HTTP反向代理服务器，有极高的执行效率、简单灵活的配置。</p>
<p>Nginx使用epoll和kqueue网络的I/O模型，而apache使用的是传统的select模型。</p>
<h1 id="与tomcat的区别："><a href="#与tomcat的区别：" class="headerlink" title="与tomcat的区别："></a><strong>与tomcat的区别：</strong></h1><ul>
<li>tomcat是根据Servlet和JSP规范执行的。</li>
<li>tomcat对静态文件、高并发文件的处理比较弱。</li>
</ul>
<h1 id="Nginx优势："><a href="#Nginx优势：" class="headerlink" title="Nginx优势："></a><strong>Nginx优势：</strong></h1><ul>
<li>配置文件简单</li>
<li>支持Rewrite重写规则。能根据域名、URL的不同将HTTP请求分发到不同的后端服务器集群</li>
<li>负载均衡（为集群提供服务分发能力）</li>
<li>反向代理</li>
<li>内置健康检查。如果后端的某台应用服务器挂了，不会影响前端访问</li>
<li>节省带宽。支持GZIP压缩。（具体应用服务器上层会挂一台web服务器，做一些压缩处理）</li>
<li>支持热部署</li>
</ul>
<h1 id="Nginx、Apache、Lighttpd的对比："><a href="#Nginx、Apache、Lighttpd的对比：" class="headerlink" title="Nginx、Apache、Lighttpd的对比："></a><strong>Nginx、Apache、Lighttpd的对比：</strong></h1><img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-1.png/w600">

<h1 id="Nginx的主配置文件为nginx-conf，下面是Web-Server的完整配置示例。"><a href="#Nginx的主配置文件为nginx-conf，下面是Web-Server的完整配置示例。" class="headerlink" title="Nginx的主配置文件为nginx.conf，下面是Web Server的完整配置示例。"></a>Nginx的主配置文件为nginx.conf，下面是Web Server的完整配置示例。</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#运行用户</span></span><br><span class="line">user www-data;    </span><br><span class="line"><span class="comment">#启动进程,通常设置成和cpu的数量相等</span></span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line"><span class="comment">#全局错误日志及PID文件</span></span><br><span class="line">error_log  /var/<span class="built_in">log</span>/nginx/error.log;</span><br><span class="line">pid        /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="comment">#工作模式及连接数上限</span></span><br><span class="line">events &#123;</span><br><span class="line">    use   epoll;             <span class="comment">#epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能</span></span><br><span class="line">    worker_connections  1024;<span class="comment">#单个后台worker process进程的最大并发链接数</span></span><br><span class="line">    <span class="comment"># multi_accept on; </span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#设定http服务器，利用它的反向代理功能提供负载均衡支持</span></span><br><span class="line">http &#123;</span><br><span class="line">     <span class="comment">#设定mime类型,类型由mime.type文件定义</span></span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    <span class="comment">#设定日志格式</span></span><br><span class="line">    access_log    /var/<span class="built_in">log</span>/nginx/access.log;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，</span></span><br><span class="line">    <span class="comment">#必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.</span></span><br><span class="line">    sendfile        on;</span><br><span class="line">    <span class="comment">#tcp_nopush     on;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#连接超时时间</span></span><br><span class="line">    <span class="comment">#keepalive_timeout  0;</span></span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line">    tcp_nodelay        on;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#开启gzip压缩</span></span><br><span class="line">    gzip  on;</span><br><span class="line">    gzip_disable <span class="string">"MSIE [1-6]\.(?!.*SV1)"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#设定请求缓冲</span></span><br><span class="line">    client_header_buffer_size    1k;</span><br><span class="line">    large_client_header_buffers  4 4k;</span><br><span class="line"></span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line">    include /etc/nginx/sites-enabled/*;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#设定负载均衡的服务器列表</span></span><br><span class="line">     upstream mysvr &#123;</span><br><span class="line">    <span class="comment">#weigth参数表示权值，权值越高被分配到的几率越大</span></span><br><span class="line">    <span class="comment">#本机上的Squid开启3128端口</span></span><br><span class="line">    server 192.168.8.1:3128 weight=5;</span><br><span class="line">    server 192.168.8.2:80  weight=1;</span><br><span class="line">    server 192.168.8.3:80  weight=6;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   server &#123;</span><br><span class="line">    <span class="comment">#侦听80端口</span></span><br><span class="line">        listen       80;</span><br><span class="line">        <span class="comment">#定义使用www.xx.com访问</span></span><br><span class="line">        server_name  www.xx.com;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#设定本虚拟主机的访问日志</span></span><br><span class="line">        access_log  logs/www.xx.com.access.log  main;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#默认请求</span></span><br><span class="line">    location / &#123;</span><br><span class="line">          root   /root;      <span class="comment">#定义服务器的默认网站根目录位置</span></span><br><span class="line">          index index.php index.html index.htm;   <span class="comment">#定义首页索引文件的名称</span></span><br><span class="line"></span><br><span class="line">          fastcgi_pass  www.xx.com;</span><br><span class="line">         fastcgi_param  SCRIPT_FILENAME  <span class="variable">$document_root</span>/<span class="variable">$fastcgi_script_name</span>; </span><br><span class="line">          include /etc/nginx/fastcgi_params;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义错误提示页面</span></span><br><span class="line">    error_page   500 502 503 504 /50x.html;  </span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">        root   /root;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#静态文件，nginx自己处理</span></span><br><span class="line">    location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123;</span><br><span class="line">        root /var/www/virtual/htdocs;</span><br><span class="line">        <span class="comment">#过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。</span></span><br><span class="line">        expires 30d;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.</span></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        root /root;</span><br><span class="line">        fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">        fastcgi_index index.php;</span><br><span class="line">        fastcgi_param SCRIPT_FILENAME /home/www/www<span class="variable">$fastcgi_script_name</span>;</span><br><span class="line">        include fastcgi_params;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#设定查看Nginx状态的地址</span></span><br><span class="line">    location /NginxStatus &#123;</span><br><span class="line">        stub_status            on;</span><br><span class="line">        access_log              on;</span><br><span class="line">        auth_basic              <span class="string">"NginxStatus"</span>;</span><br><span class="line">        auth_basic_user_file  conf/htpasswd;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#禁止访问 .htxxx 文件</span></span><br><span class="line">    location ~ /\.ht &#123;</span><br><span class="line">        deny all;</span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果要使用负载均衡的话,可以修改配置http节点如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#设定http服务器，利用它的反向代理功能提供负载均衡支持</span></span><br><span class="line">http &#123;</span><br><span class="line">     <span class="comment">#设定mime类型,类型由mime.type文件定义</span></span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    <span class="comment">#设定日志格式</span></span><br><span class="line">    access_log    /var/<span class="built_in">log</span>/nginx/access.log;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#省略上文有的一些配置节点</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#。。。。。。。。。。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#设定负载均衡的服务器列表</span></span><br><span class="line">     upstream mysvr &#123;</span><br><span class="line">    <span class="comment">#weigth参数表示权值，权值越高被分配到的几率越大</span></span><br><span class="line">    server 192.168.8.1x:3128 weight=5;<span class="comment">#本机上的Squid开启3128端口</span></span><br><span class="line">    server 192.168.8.2x:80  weight=1;</span><br><span class="line">    server 192.168.8.3x:80  weight=6;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   upstream mysvr2 &#123;</span><br><span class="line">    <span class="comment">#weigth参数表示权值，权值越高被分配到的几率越大</span></span><br><span class="line"></span><br><span class="line">    server 192.168.8.x:80  weight=1;</span><br><span class="line">    server 192.168.8.x:80  weight=6;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">#第一个虚拟服务器</span></span><br><span class="line">   server &#123;</span><br><span class="line">    <span class="comment">#侦听192.168.8.x的80端口</span></span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  192.168.8.x;</span><br><span class="line"></span><br><span class="line">      <span class="comment">#对aspx后缀的进行负载均衡请求</span></span><br><span class="line">    location ~ .*\.aspx$ &#123;</span><br><span class="line"></span><br><span class="line">         root   /root;      <span class="comment">#定义服务器的默认网站根目录位置</span></span><br><span class="line">          index index.php index.html index.htm;   <span class="comment">#定义首页索引文件的名称</span></span><br><span class="line"></span><br><span class="line">          proxy_pass  http://mysvr ;<span class="comment">#请求转向mysvr 定义的服务器列表</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">#以下是一些反向代理的配置可删除.</span></span><br><span class="line"></span><br><span class="line">          proxy_redirect off;</span><br><span class="line"></span><br><span class="line">          <span class="comment">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span></span><br><span class="line">          proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">          proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">          proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">          client_max_body_size 10m;    <span class="comment">#允许客户端请求的最大单文件字节数</span></span><br><span class="line">          client_body_buffer_size 128k;  <span class="comment">#缓冲区代理缓冲用户端请求的最大字节数，</span></span><br><span class="line">          proxy_connect_timeout 90;  <span class="comment">#nginx跟后端服务器连接超时时间(代理连接超时)</span></span><br><span class="line">          proxy_send_timeout 90;        <span class="comment">#后端服务器数据回传时间(代理发送超时)</span></span><br><span class="line">          proxy_read_timeout 90;         <span class="comment">#连接成功后，后端服务器响应时间(代理接收超时)</span></span><br><span class="line">          proxy_buffer_size 4k;             <span class="comment">#设置代理服务器（nginx）保存用户头信息的缓冲区大小</span></span><br><span class="line">          proxy_buffers 4 32k;               <span class="comment">#proxy_buffers缓冲区，网页平均在32k以下的话，这样设置</span></span><br><span class="line">          proxy_busy_buffers_size 64k;    <span class="comment">#高负荷下缓冲大小（proxy_buffers*2）</span></span><br><span class="line">          proxy_temp_file_write_size 64k;  <span class="comment">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</span></span><br><span class="line"></span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="虚拟主机"><a href="#虚拟主机" class="headerlink" title="虚拟主机"></a>虚拟主机</h1><p><strong>利用虚拟主机，不用为每个要运行的网站提供一台单独的Nginx服务器或单独运行一组Nginx进程。虚拟主机提供了在同一台服务器、同一组nginx进程上运行多个网站的功能。</strong></p>
<ul>
<li>基于IP的虚拟主机</li>
<li>基于域名的虚拟主机</li>
</ul>
<p>gzip（GNU—ZIP）是一种压缩技术，可以将页面大小压缩到原来的30%或更小。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-gzip.png/w600">


<p>Nginx的浏览器本地缓存设置。当用户再次请求这个页面时，浏览器可以从本地磁盘显示文件，节约了网络的资源，提高了网络的效率。</p>
<p>对图片文件缓存30天，对js、css文件缓存1小时。</p>
<img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-cache.png/w600">

<h1 id="FastCGI的工作原理是："><a href="#FastCGI的工作原理是：" class="headerlink" title="FastCGI的工作原理是："></a><strong>FastCGI的工作原理是：</strong></h1><ul>
<li>FastCGI进程管理器自身初始化，启动多个CGI解释器进程 (在任务管理器中可见多个php-cgi.exe)并等待来自Web Server的连接。启动php-cgi FastCGI进程时，可以配置以TCP和UNIX套接字(socket)两种方式启动。</li>
<li>当客户端请求到达Web Server（Nginx）时，Web Server（Nginx）将请求采用TCP协议或socket方式转发到FastCGI主进程，FastCGI主进程选择并连接到一个CGI解释器(子进程php-cgi.exe)。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi.exe。</li>
<li>FastCGI子进程php-cgi.ex完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在 WebServer中）的下一个连接。 而在CGI中，php-cgi子进程在此便被退出了。</li>
</ul>
<h1 id="Nginx与Tomcat的配置："><a href="#Nginx与Tomcat的配置：" class="headerlink" title="Nginx与Tomcat的配置："></a><strong>Nginx与Tomcat的配置：</strong></h1><img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-main.png/w600">

<img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-tomcat.png/w600">

<h1 id="反向代理："><a href="#反向代理：" class="headerlink" title="反向代理："></a><strong>反向代理：</strong></h1><p>代理服务器接受来自Internet的连接请求，然后将请求转发给内部网络上的服务器，并从服务器上得到的结果返回给Internet上请求连接的客户端。</p>
<p>反向代理服务器只是一层代理，所以受到攻击并不会使网页信息遭到破坏，增强了web服务器的安全性。</p>
<h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a><strong>参考资料：</strong></h1><p><a href="https://www.zybuluo.com/happyfans/note/161734" target="_blank" rel="noopener">https://www.zybuluo.com/happyfans/note/161734</a></p>
<p>《实战Nginx 取代Apache的高性能Web服务器》</p>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP协议</title>
    <url>/web/tcp/</url>
    <content><![CDATA[<ul>
<li><a href="">头结构</a></li>
<li><a href="http://www.jellythink.com/archives/705" target="_blank" rel="noopener">TCP 的三次握手与四次分手</a></li>
<li><a href="https://mp.weixin.qq.com/s/4xaMByF-FI74mLrCyWIhEg" target="_blank" rel="noopener">TCP协议疑难杂症全景解析</a><a id="more"></a></li>
</ul>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx映射本地文件</title>
    <url>/web/nginx%E6%98%A0%E5%B0%84%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<a id="more"></a>
<p>注意顺序，会与其他如后缀匹配 .*.(gif|jpg|jpeg|png|bmp|swf)$ 等冲突。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name api.yiqikj.cn;</span><br><span class="line">        location /resource/ &#123;</span><br><span class="line">                <span class="built_in">alias</span> /data/inkee/inkee-boot-os/;</span><br><span class="line">                autoindex on;</span><br><span class="line">                expires  30d;</span><br><span class="line">        &#125;</span><br><span class="line">        location / &#123;</span><br><span class="line">                <span class="comment">#proxy_redirect off;</span></span><br><span class="line">                proxy_pass http://127.0.0.1:9898;</span><br><span class="line">        &#125;       </span><br><span class="line">        <span class="comment"># location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ &#123;</span></span><br><span class="line">        <span class="comment">#         expires  30d;</span></span><br><span class="line">        <span class="comment"># &#125;</span></span><br><span class="line">        <span class="comment"># location ~ .*\.(js|css)?$ &#123;</span></span><br><span class="line">        <span class="comment">#         expires  12h;</span></span><br><span class="line">        <span class="comment"># &#125;       </span></span><br><span class="line">        access_log  logs/inkeebackstage.log main;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat</title>
    <url>/web/tomcat/</url>
    <content><![CDATA[<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><ul>
<li><a href="http://tomcat.apache.org/" target="_blank" rel="noopener">apache tomcat 官网</a></li>
<li><a href="https://mp.weixin.qq.com/s/Nk7gcwsgBhgMWTRkgAFpRA" target="_blank" rel="noopener">深度解读 Tomcat 中的 NIO 模型</a><a id="more"></a></li>
<li><a href="https://mp.weixin.qq.com/s/YoQJOhFBWzUqFkBtHevldA" target="_blank" rel="noopener">详解 Tomcat 的连接数与线程池</a></li>
<li><a href="https://www.cnblogs.com/jiaoyiping/p/5979242.html" target="_blank" rel="noopener">关于servlet3.0中的异步servlet</a></li>
</ul>
<hr>
<h1 id="tomcat服务器优化"><a href="#tomcat服务器优化" class="headerlink" title="tomcat服务器优化"></a>tomcat服务器优化</h1><h2 id="1、JDK内存优化"><a href="#1、JDK内存优化" class="headerlink" title="1、JDK内存优化"></a>1、JDK内存优化</h2><p>根据服务器物理内存情况配置相关参数优化tomcat性能。当应用程序需要的内存超出堆的最大值时虚拟机就会提示内存溢出，并且导致应用服务崩溃。因此一般建议堆的最大值设置为可用内存的最大值的80%。 Tomcat默认可以使用的内存为128MB，在较大型的应用项目中，这点内存是不够的，需要调大.</p>
<p>Tomcat默认可以使用的内存为128MB,Windows下,在文件/bin/catalina.bat，Unix下，在文件/bin/catalina.sh的前面，增加如下设置： JAVA_OPTS=’-Xms【初始化内存大小】 -Xmx【可以使用的最大内存】 -XX:PermSize=64M -XX:MaxPermSize=128m’ 需要把几个参数值调大。例如： JAVA_OPTS=’-Xms256m -Xmx512m’ 表示初始化内存为256MB，可以使用的最大内存为512MB。</p>
<p>参数详解</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-server  启用jdk 的 server 版；</span><br><span class="line">-Xms    java虚拟机初始化时的最小内存；</span><br><span class="line">-Xmx    java虚拟机可使用的最大内存；</span><br><span class="line">-XX:PermSize    内存永久保留区域</span><br><span class="line">-XX:MaxPermSize   内存最大永久保留区域</span><br><span class="line">-Xmn    jvm最小新生代大小</span><br></pre></td></tr></table></figure>

<p>32G 内存配置示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=<span class="string">"<span class="variable">$JAVA_OPTS</span>  -Xms10g -Xmx10g -XX:PermSize=1g -XX:MaxPermSize=2g -Xshare:off -Xmn1024m</span></span><br></pre></td></tr></table></figure>

<h2 id="2、tomcat线程优化"><a href="#2、tomcat线程优化" class="headerlink" title="2、tomcat线程优化"></a>2、tomcat线程优化</h2><p>在tomcat配置文件server.xml中的配置中，和连接数相关的参数有：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">maxThreads： Tomcat使用线程来处理接收的每个请求。这个值表示Tomcat可创建的最大的线程数。默认值150。</span><br><span class="line"></span><br><span class="line">acceptCount： 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理。默认值10。</span><br><span class="line"></span><br><span class="line">minSpareThreads： Tomcat初始化时创建的线程数。默认值25。</span><br><span class="line"></span><br><span class="line">maxSpareThreads： 一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。默认值75。</span><br><span class="line"></span><br><span class="line">enableLookups： 是否反查域名，默认值为<span class="literal">true</span>。为了提高处理能力，应设置为<span class="literal">false</span></span><br><span class="line"></span><br><span class="line">connnectionTimeout： 网络连接超时，默认值60000，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000毫秒。</span><br><span class="line"></span><br><span class="line">maxKeepAliveRequests： 保持请求数量，默认值100。 bufferSize： 输入流缓冲大小，默认值2048 bytes。</span><br><span class="line"></span><br><span class="line">compression： 压缩传输，取值on/off/force，默认值off。 其中和最大连接数相关的参数为maxThreads和acceptCount。如果要加大并发连接数，应同时加大这两个参数。</span><br></pre></td></tr></table></figure>

<p>32G 内存配置示例：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Connector</span> <span class="attr">port</span>=<span class="string">"8080"</span> <span class="attr">protocol</span>=<span class="string">"HTTP/1.1"</span></span></span><br><span class="line"><span class="tag">               <span class="attr">connectionTimeout</span>=<span class="string">"20000"</span> <span class="attr">maxThreads</span>=<span class="string">"1000"</span> <span class="attr">minSpareThreads</span>=<span class="string">"60"</span> <span class="attr">maxSpareThreads</span>=<span class="string">"600"</span>  <span class="attr">acceptCount</span>=<span class="string">"120"</span></span></span><br><span class="line"><span class="tag">               <span class="attr">redirectPort</span>=<span class="string">"8443"</span> <span class="attr">URIEncoding</span>=<span class="string">"utf-8"</span>/&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>常见的攻击手段——DDOS，CC攻击</title>
    <url>/web/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%94%BB%E5%87%BB%E6%89%8B%E6%AE%B5%E2%80%94%E2%80%94DDOS-CC%E6%94%BB%E5%87%BB/</url>
    <content><![CDATA[<h1 id="DDoS即分布式拒绝服务攻击"><a href="#DDoS即分布式拒绝服务攻击" class="headerlink" title="DDoS即分布式拒绝服务攻击"></a>DDoS即分布式拒绝服务攻击</h1><p>要理解DDos，得先从DoS说起。最基本的DoS攻击就是利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器的响应。</p>
<a id="more"></a>

<p>DDoS的原理就非常简单了，它指的是攻击者借助公共网络，将数量庞大的计算机设备联合起来作为攻击平台，对一个或多个目标发动攻击，从而达到瘫痪目标主机的目的。通常，在攻击开始前，攻击者会提前控制大量的用户计算机，称之为“肉鸡”，并通过指令使大量的肉鸡在同一时刻对某个主机进行访问，从而达到瘫痪目标主机的目的。</p>
<h2 id="常见的攻击手段—SYN-Flood（防御方式）"><a href="#常见的攻击手段—SYN-Flood（防御方式）" class="headerlink" title="常见的攻击手段—SYN Flood（防御方式）"></a>常见的攻击手段—SYN Flood（防御方式）</h2><h2 id="常见的攻击手段—DNS-Query-Flood"><a href="#常见的攻击手段—DNS-Query-Flood" class="headerlink" title="常见的攻击手段—DNS Query Flood"></a>常见的攻击手段—DNS Query Flood</h2><p>DNS Query Flood实际上是UDP Flood攻击的一种变形，由于DNS服务在互联网中不可替代的作用，一旦DNS服务器瘫痪，影响甚大。</p>
<p>DNS Query Flood攻击采用的方法是向被攻击的服务器发送海量的域名解析请求，通常，请求解析的域名是随机生成，大部分根本就不存在，并且通过伪造端口和客户端IP，防止查询请求被ACL过滤。被攻击的DNS 服务器在接收到域名解析请求后，首先会在服务器上查找是否有对应的缓存，由于域名是随机生成的，几乎不可能有相应的缓存信息，当没有缓存，并且该域名无法直接由该DNS服务器进行解析的时候，DNS服务器会向其上层DNS服务器递归查询域名信息，直到全球互联网的13台根DNS服务器。大量不存在的域名解析请求，给服务器带来了很大的负载，当解析请求超过一定量的时候，就会造成DNS服务器解析域名超时，这样攻击者便达成了攻击目的。</p>
<h1 id="常见的攻击手段—CC攻击（接口暴力请求）"><a href="#常见的攻击手段—CC攻击（接口暴力请求）" class="headerlink" title="常见的攻击手段—CC攻击（接口暴力请求）"></a>常见的攻击手段—CC攻击（接口暴力请求）</h1><p>CC(Challenge Collapsar)攻击属于DDos的一种，是基于应用层HTTP协议发起的DDos攻击，也被称为HTTP Flood。</p>
<p>CC攻击的原理是这样的，攻击者通过控制的大量“肉鸡”或者利用从互联网上搜寻的大量匿名的HTTP代理，模拟正常用户给网站发起请求直到该网站拒绝服务为止。大部分网站会通过CDN以及分布式缓存来加快服务端响应，提升网站的吞吐量，而这些精心构造的HTTP请求往往有意避开这些缓存，需要进行多次DB查询操作或者是一次请求返回大量的数据，加速系统资源消耗，从而拖垮后端的业务处理系统，甚至连相关存储以及日志收集系统也无法幸免。</p>
<h1 id="防御方式"><a href="#防御方式" class="headerlink" title="防御方式:"></a>防御方式:</h1><p>1,主要通过缓存来进行，由secret缓存直接返回结果来返回后端的业务，大型的互联网公司都会有CDN节点缓存。</p>
<p>2，网络清洗设备能够铺获到http请求来做一些处理，根据ip地址做统计，如果访问高于一定频率的ip，可以列入黑名单。</p>
<p>3，重发，强制使用TCP，根据头部报文来做效验。</p>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>认证协议-OAuth2</title>
    <url>/web/%E8%AE%A4%E8%AF%81%E5%8D%8F%E8%AE%AE-OAuth2/</url>
    <content><![CDATA[<h1 id="1-什么是OAuth2"><a href="#1-什么是OAuth2" class="headerlink" title="1 什么是OAuth2"></a>1 什么是OAuth2</h1><p>OAuth： OAuth（开放授权）是一个开放标准，允许用户授权第三方网站访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方网站或分享他们数据的所有内容。</p>
<a id="more"></a>

<p>OAuth2.0：对于用户相关的OpenAPI（例如获取用户信息，动态同步，照片，日志，分享等），为了保护用户数据的安全和隐私，第三方网站访问用户数据前都需要显式的向用户征求授权。</p>
<p>采用OAuth2.0标准协议来进行用户身份验证和获取用户授权，相对于之前的OAuth1.0协议，其认证流程更简单和安全。</p>
<h1 id="2-应用场景"><a href="#2-应用场景" class="headerlink" title="2 应用场景"></a>2 应用场景</h1><p>第三方应用授权登录：在APP或者网页接入一些第三方应用时，时长会需要用户登录另一个合作平台，比如QQ，微博，微信的授权登录。<br><img data-src="https://maxkey.top/images/oauth2/qq.jpg?202005100627" alt=""><br>原生app授权：app登录请求后台接口，为了安全认证，所有请求都带token信息，如果登录验证、请求后台数据。</p>
<p>前后端分离单页面应用（spa）：前后端分离框架，前端请求后台数据，需要进行oauth2安全认证，比如使用vue、react后者h5开发的app。</p>
<h1 id="3-名词定义"><a href="#3-名词定义" class="headerlink" title="3 名词定义"></a>3 名词定义</h1><p>（1） Third-party application：第三方应用程序，本文中又称”客户端”（client），比如打开知乎，使用第三方登录，选择qq登录，这时候知乎就是客户端。</p>
<p>（2）HTTP service：HTTP服务提供商，本文中简称”服务提供商”，即上例的qq。</p>
<p>（3）Resource Owner：资源所有者，本文中又称”用户”（user）,即登录用户。</p>
<p>（4）User Agent：用户代理，本文中就是指浏览器。</p>
<p>（5）Authorization server：认证服务器，即服务提供商专门用来处理认证的服务器。</p>
<p>（6）Resource server：资源服务器，即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。</p>
<h1 id="4-运行流程"><a href="#4-运行流程" class="headerlink" title="4 运行流程"></a>4 运行流程</h1><ul>
<li>（A）用户打开客户端以后，客户端要求用户给予授权。</li>
<li></li>
<li>（B）用户同意给予客户端授权。</li>
<li></li>
<li>（C）客户端使用上一步获得的授权，向认证服务器申请令牌。</li>
<li></li>
<li>（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。</li>
<li></li>
<li>（E）客户端使用令牌，向资源服务器申请获取资源。</li>
<li></li>
<li>（F）资源服务器确认令牌无误，同意向客户端开放资源。<br><img data-src="https://maxkey.top/images/oauth2/flow.jpg?202005100627" alt=""></li>
</ul>
<h1 id="5-四种授权模式"><a href="#5-四种授权模式" class="headerlink" title="5 四种授权模式"></a>5 四种授权模式</h1><p>授权码模式（authorization code）</p>
<p>简化模式（implicit）</p>
<p>密码模式（resource owner password credentials）</p>
<p>客户端模式（client credentials）</p>
<h2 id="5-1-授权码模式"><a href="#5-1-授权码模式" class="headerlink" title="5.1 授权码模式"></a>5.1 授权码模式</h2><p>授权码模式（authorization code）是功能最完整、流程最严密的授权模式。<br><img data-src="https://maxkey.top/images/oauth2/code.jpg?202005100627" alt=""></p>
<ul>
<li><p>（1）用户访问客户端，后者将前者导向认证服务器，假设用户给予授权，认证服务器将用户导向客户端事先指定的”重定向URI”（redirection URI），同时附上一个授权码。</p>
</li>
<li><p>（2）客户端收到授权码，附上早先的”重定向URI”，向认证服务器申请令牌：GET /oauth/token?response_type=code&amp;client_id=test&amp;redirect_uri=重定向页面链接。请求成功返回code授权码，一般有效时间是10分钟。</p>
</li>
<li><p>（3）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。POST /oauth/token?response_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA&amp;redirect_uri=重定向页面链接。请求成功返回access Token和refresh Token。</p>
</li>
</ul>
<h2 id="5-2-简化模式Implicit"><a href="#5-2-简化模式Implicit" class="headerlink" title="5.2 简化模式Implicit"></a>5.2 简化模式Implicit</h2><p>适用于公开的浏览器单页应用<br><img data-src="https://maxkey.top/images/oauth2/implicit.jpg?202005100627" alt=""><br>Access Token直接从授权服务器返回(只有前端渠道)</p>
<p>不支持refresh tokens</p>
<p>假定资源所有者和公开客户应用在同一个设备上</p>
<p>最容易受安全攻击</p>
<h2 id="5-3-用户名密码-Resource-Owner-Credentials"><a href="#5-3-用户名密码-Resource-Owner-Credentials" class="headerlink" title="5.3 用户名密码 Resource Owner Credentials"></a>5.3 用户名密码 Resource Owner Credentials</h2><p><img data-src="https://maxkey.top/images/oauth2/resource.jpg?202005100627" alt=""></p>
<p>使用用户名密码登录的应用，例如桌面App</p>
<p>使用用户名/密码作为授权方式从授权服务器上获取access token</p>
<p>一般不支持refresh token</p>
<p>假定资源拥有者和公开客户子啊相同设备上</p>
<h2 id="5-4-客户端凭证-Client-Credentials"><a href="#5-4-客户端凭证-Client-Credentials" class="headerlink" title="5.4 客户端凭证 Client Credentials"></a>5.4 客户端凭证 Client Credentials</h2><p><img data-src="https://maxkey.top/images/oauth2/client.jpg?202005100627" alt=""><br>适用于服务器见通信场景，机密客户代表它自己或者一个用户</p>
<p>只有后端渠道，使用客户凭证获取一个access token</p>
<p>因为客户凭证可以使用对称或者非对称加密，该方式支持共享密码或者证书</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>认证协议-JWT</title>
    <url>/web/%E8%AE%A4%E8%AF%81%E5%8D%8F%E8%AE%AE-jwt/</url>
    <content><![CDATA[<h1 id="1-JSON-Web-Token介绍"><a href="#1-JSON-Web-Token介绍" class="headerlink" title="1 JSON Web Token介绍"></a>1 JSON Web Token介绍</h1><p>JSON Web Token （JWT）是一个开放标准（RFC 7519），它定义了一种紧凑且自包含的方式，用于在各方之间安全地将信息作为JSON对象传输。由于此信息是经过数字签名的，因此可以被验证和信任。可以使用秘密（使用HMAC算法）或使用RSA或ECDSA的公用/专用密钥对对JWT进行签名。</p>
<a id="more"></a>

<p>尽管可以对JWT进行加密以在各方之间提供保密性，但我们将重点关注已签名的令牌。签名的令牌可以验证其中包含的声明的完整性，而加密的令牌则将这些声明隐藏在其他方的面前。当使用公钥/私钥对对令牌进行签名时，签名还证明只有持有私钥的一方才是对其进行签名的一方。</p>
<h1 id="2-什么时候使用JSON-Web-Token"><a href="#2-什么时候使用JSON-Web-Token" class="headerlink" title="2 什么时候使用JSON Web Token"></a>2 什么时候使用JSON Web Token</h1><p>以下是JSON Web令牌有用的一些情况：</p>
<p>授权：这是使用JWT的最常见方案。一旦用户登录，每个后续请求将包括JWT，从而允许用户访问该令牌允许的路由，服务和资源。单一登录是当今广泛使用JWT的一项功能，因为它的开销很小并且可以在不同的域中轻松使用。</p>
<p>信息交换：JSON Web令牌是在各方之间安全地传输信息的好方法。因为可以对JWT进行签名（例如，使用公钥/私钥对），所以您可以确定发件人是他们所说的人。此外，由于签名是使用标头和有效负载计算的，因此您还可以验证内容是否遭到篡改。</p>
<h1 id="3-JSON-Web-Token结构"><a href="#3-JSON-Web-Token结构" class="headerlink" title="3 JSON Web Token结构"></a>3 JSON Web Token结构</h1><p>JSON Web Token以紧凑的形式由三部分组成，这些部分由点（.）分隔，分别是：</p>
<ul>
<li><p>Header(标头)</p>
</li>
<li><p>Payload(有效载荷)</p>
</li>
<li><p>Signature(签名)</p>
</li>
</ul>
<p>因此，JWT通常如下所示。</p>
<p><code>xxxxx.yyyyy.zzzzz</code><br>让我们分解不同的部分。</p>
<h2 id="Header-标头"><a href="#Header-标头" class="headerlink" title="Header(标头)"></a>Header(标头)</h2><p>标头通常由两部分组成：令牌的类型（即JWT）和所使用的签名算法，例如HMAC SHA256或RSA。</p>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;alg&quot;: &quot;HS256&quot;,</span><br><span class="line">  &quot;typ&quot;: &quot;JWT&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后，此JSON被Base64Url编码以形成JWT的第一部分。</p>
<h2 id="Payload-有效载荷"><a href="#Payload-有效载荷" class="headerlink" title="Payload(有效载荷)"></a>Payload(有效载荷)</h2><p>令牌的第二部分是有效负载，其中包含声明。声明是有关实体（通常是用户）和其他数据的声明。索赔有以下三种类型：注册的，公共的和私人索赔。</p>
<p>已注册的权利要求：这些是一组非强制性的但建议使用的预定义权利要求，以提供一组有用的，可互操作的权利要求。其中一些是： iss（发布者）， exp（到期时间）， sub（主题）， aud（受众群体）等。</p>
<p>请注意，声明名称仅是三个字符，因为JWT是紧凑的。</p>
<p>公开声明：使用JWT的人员可以随意定义这些声明。但是为避免冲突，应在 IANA JSON Web令牌注册表中定义它们，或将其定义为包含抗冲突名称空间的URI。</p>
<p>私人权利：这些都是使用它们同意并既不是当事人之间建立共享信息的自定义声明注册或公众的权利要求。</p>
<p>有效负载示例可能是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;sub&quot;: &quot;1234567890&quot;,</span><br><span class="line">  &quot;name&quot;: &quot;John Doe&quot;,</span><br><span class="line">  &quot;admin&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后，对有效负载进行Base64Url编码，以形成JSON Web令牌的第二部分。</p>
<p>请注意，对于已签名的令牌，此信息尽管可以防止篡改，但任何人都可以读取。除非将其加密，否则请勿将机密信息放入JWT的有效负载或报头元素中。</p>
<p>Signature(签名)</p>
<p>要创建签名部分，您必须获取编码的标头，编码的有效载荷，机密，标头中指定的算法，并对其进行签名。</p>
<p>例如，如果要使用HMAC SHA256算法，则将通过以下方式创建签名：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HMACSHA256(</span><br><span class="line">  base64UrlEncode(header) + &quot;.&quot; +</span><br><span class="line">  base64UrlEncode(payload),</span><br><span class="line">  secret)</span><br></pre></td></tr></table></figure>
<p>签名用于验证消息在此过程中没有更改，并且对于使用私钥进行签名的令牌，它还可以验证JWT的发送者是它所说的真实身份。</p>
<p>结合一起</p>
<p>输出是三个由点分隔的Base64-URL字符串，可以在HTML和HTTP环境中轻松传递这些字符串，与基于XML的标准（例如SAML）相比，它更紧凑。</p>
<p>下面显示了一个JWT，它已对先前的标头和有效负载进行了编码，并用一个秘密进行了签名。 编码的JWT<br><img data-src="https://maxkey.top/images/jwt/encoded-jwt3.png?202005100627" alt=""></p>
<p>如果您想使用JWT并将这些概念付诸实践，则可以使用jwt.io Debugger解码，验证和生成JWT。JWT.io调试器<br><img data-src="https://maxkey.top/images/jwt/legacy-app-auth-5.png?202005100627" alt=""></p>
<h1 id="4-JSON-Web-Token工作机制"><a href="#4-JSON-Web-Token工作机制" class="headerlink" title="4 JSON Web Token工作机制"></a>4 JSON Web Token工作机制</h1><p>在身份验证中，当用户使用其凭据成功登录时，将返回JSON Web令牌。由于令牌是凭据，因此必须格外小心以防止安全问题。通常，令牌的保留时间不应超过要求的时间。</p>
<p>由于缺乏安全性，您也不应该将敏感的会话数据存储在浏览器中。</p>
<p>每当用户想要访问受保护的路由或资源时，用户代理通常应使用授权Authorization在Bearer承载模式标头中发送JWT 。标头的内容应如下所示：</p>
<p><code>Authorization: Bearer [token]</code><br>在某些情况下，这可以是无状态授权机制。服务器的受保护路由将在Authorization标头中检查有效的JWT ，如果存在，则将允许用户访问受保护的资源。如果JWT包含必要的数据，则可以减少查询数据库中某些操作的需求，尽管这种情况并非总是如此。</p>
<p>如果令牌是在Authorization标头中发送的，则跨域资源共享（CORS）不会成为问题，因为它不使用cookie。</p>
<p>下图显示了如何获取JWT并将其用于访问API或资源：  JSON Web令牌如何工作<br><img data-src="https://maxkey.top/images/jwt/client-credentials-grant.png?202005100627" alt=""><br>应用程序或客户端向授权服务器请求授权。这是通过不同的授权流程之一执行的。例如，典型的符合OpenID Connect的 Web应用程序将/oauth/authorize使用授权代码流通过端点。 授予授权后，授权服务器会将访问令牌返回给应用程序。 该应用程序使用访问令牌来访问受保护的资源（例如API）。 请注意，使用签名的令牌，令牌中包含的所有信息都会暴露给用户或其他方，即使他们无法更改它。这意味着您不应将机密信息放入令牌中。</p>
<h1 id="5-如何使用JSON-Web-Token"><a href="#5-如何使用JSON-Web-Token" class="headerlink" title="5 如何使用JSON Web Token"></a>5 如何使用JSON Web Token</h1><p>让我们谈谈与Simple Web Tokens（SWT）和Security Assertion Markup Language Tokens安全性声明标记语言令牌（SAML）相比，JSON Web Tokens（JWT）的优势。</p>
<p>由于JSON不如XML冗长，因此在编码时JSON的大小也较小，从而使JWT比SAML更为紧凑。这使得JWT是在HTML和HTTP环境中传递的不错的选择。</p>
<p>在安全方面，只能使用HMAC算法由共享机密对SWT进行对称签名。但是，JWT和SAML令牌可以使用X.509证书形式的公用/专用密钥对进行签名。与签名JSON的简单性相比，使用XML数字签名对XML进行签名而不引入模糊的安全漏洞是非常困难的。</p>
<p>JSON解析器在大多数编程语言中都很常见，因为它们直接映射到对象。相反，XML没有自然的文档到对象映射。与SAML断言相比，这使使用JWT更加容易。</p>
<p>关于用法，JWT是在Internet规模上使用的。这强调了在多个平台（尤其是移动平台）上对JSON Web令牌进行客户端处理的简便性。<br><img data-src="https://maxkey.top/images/jwt/comparing-jwt-vs-saml2.png?202005100627" alt=""><br><img data-src="https://maxkey.top/images/jwt/comparing-jwt-vs-saml2.png?202005100627" alt=""><br><img data-src="https://maxkey.top/images/jwt/comparing-jwt-vs-saml2.png?202005100627" alt=""></p>
<p>比较已编码的JWT和已编码的SAML的长度 编码的JWT和编码的SAML的长度比较</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>认证协议-SAML介绍</title>
    <url>/web/%E8%AE%A4%E8%AF%81%E5%8D%8F%E8%AE%AE-SAML%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1 id="1-SAML-介绍"><a href="#1-SAML-介绍" class="headerlink" title="1 SAML 介绍"></a>1 SAML 介绍</h1><p>SAML即安全断言标记语言，英文全称是Security Assertion Markup Language。它是一个基于XML的标准，用于在不同的安全域(security domain)之间用户身份验证和授权数据交换。<a id="more"></a>在SAML标准定义了身份提供者(identity provider)和服务提供者(service provider)，这两者构成了前面所说的不同的安全域。 SAML是OASIS组织安全服务技术委员会(Security Services Technical Committee)的产品。官方技术说明可参看OASIS Security Services (SAML) TC.</p>
<p>使用SAML，在线服务供应商可以联系一个独立的网络身份认证提供者，谁是试图访问受保护的内容的用户进行身份验证。</p>
<p>联邦是指两个或更多可信的业务合作伙伴组成的团体，其遵照的业务和技术协议允许来自联邦合作伙伴(成员公司)的用户以一种安全可靠的方式，无缝地访问另一家合作伙伴的资源。在联邦业务模型中(其中，服务是联邦化的，或可以与业务合作伙伴共享)，根据有关实体间达成的协议，一家公司的用户的身份将被转换，以合法访问另一家公司的Web站点，而另一家公司无需了解该用户的原始身份。</p>
<p>IDP认证中心提供了一个基于SAML的单点登录（SSO）服务，作为身份提供者(Identity provider)，控制用户名、密码和其他信息，用于识别，身份验证和授权用户的Web应用程序。</p>
<p>备注：SAML应用集成需完成应用集成申请，详见SAML相关内容。</p>
<p>通过SAML实现IDP 与其他合作伙伴的联邦身份认证。</p>
<p>流程说明图<br><img data-src="https://maxkey.top/images/saml/saml1.png?202005100627" alt=""></p>
<p>SAML实现联邦身份认证各方职责<br>IDP认证中心(Identity Provider/IDP)    合作伙伴(Service Provider/SP)<br>用户身份认证    安全断言判定<br>联邦身份安全断言    联邦身份维护<br>用户账号管理    服务提供和访问控制<br>IDP和SP预先完成证书的互信配置，SAML认证基于断言，断言基于证书的加密，传递过程是安全的，只有证书的持有者才能对断言进行解析</p>
<p>重要注意:SAML SSO解决方案仅适用于Web应用程序.</p>
<h1 id="2-SP-Init-SSO流程"><a href="#2-SP-Init-SSO流程" class="headerlink" title="2 SP-Init SSO流程"></a>2 SP-Init SSO流程</h1><p><img data-src="https://maxkey.top/images/saml/saml2.png?202005100627" alt=""><br>用户试图访问IDP的合作伙伴应用。</p>
<p>合作伙伴应用生成一个SAML身份验证请求。SAML请求编码并嵌入到URL IDP的SSO服务。RelayState参数包含编码的合作伙伴应用程序，用户尝试访问的URL也被嵌入在SSO URL。这的RelayState参数，就是要一个不透明的标识符，不作任何修改或检查传回的。</p>
<p>合作伙伴发送重定向到用户的浏览器。重定向URL编码SAML身份验证请求的，应提交到IDP的SSO服务。</p>
<p>IDP的SAML请求进行解码，并提取两个谷歌的断言消费服务（ACS）和用户的目标URL（RelayState参数）的URL。</p>
<p>IDP的用户进行身份验证。IDP可以通过要求有效的登录凭据，或通过检查有效的会话对用户进行身份验证。</p>
<p>IDP生成一个SAML响应，其中包含身份验证的用户的用户名。按照SAML 2.0规范，这种反应是公共和私人合作伙伴的DSA / RSA密钥数字签名的</p>
<p>IDP SAML响应和RelayState参数进行编码，并将该信息返回到用户的浏览器。IDP提供了一种机制，使浏览器可以转发信息到合作伙伴的ACS。</p>
<p>合作伙伴的ACS使用IDP的公钥验证SAML响应。如果成功验证的响应，ACS将用户重定向的目标URL。</p>
<p>用户被重定向的目标URL，并记录在合作伙伴应用程序。</p>
<h1 id="3-IDP-Init-SSO流程"><a href="#3-IDP-Init-SSO流程" class="headerlink" title="3 IDP-Init SSO流程"></a>3 IDP-Init SSO流程</h1><p><img data-src="https://maxkey.top/images/saml/saml3.png?202005100627" alt=""></p>
<p>IDP的用户进行身份验证。IDP可以通过要求有效的登录凭据，或通过检查有效的会话对用户进行身份验证。</p>
<p>IDP生成一个SAML响应，其中包含身份验证的用户的用户名。按照SAML 2.0规范，这种反应是公共和私人合作伙伴的DSA / RSA密钥数字签名的。</p>
<p>IDP SAML响应和RelayState参数进行编码，并将该信息返回到用户的浏览器。IDP提供了一种机制，使浏览器可以转发信息到合作伙伴的ACS。</p>
<p>合作伙伴的ACS使用IDP的公钥验证SAML响应。如果成功验证的响应，ACS将用户重定向的目标URL。</p>
<p>用户被重定向的目标URL，并记录在合作伙伴应用程序。</p>
]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL数据库面试题</title>
    <url>/db/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>Java面试总结汇总，整理了包括Java基础知识，集合容器，并发编程，JVM，常用开源框架Spring，MyBatis，数据库，中间件等，包含了作为一个Java工程师在面试中需要用到或者可能用到的绝大部分知识。</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>内容</th>
<th>链接地址</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Java基础知识面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104390612" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104390612</a></td>
</tr>
<tr>
<td>2</td>
<td>Java集合容器面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104588551" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104588551</a></td>
</tr>
<tr>
<td>3</td>
<td>Java异常面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104390689" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104390689</a></td>
</tr>
<tr>
<td>4</td>
<td>并发编程面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104863992" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104863992</a></td>
</tr>
<tr>
<td>5</td>
<td>JVM面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104390752" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104390752</a></td>
</tr>
<tr>
<td>6</td>
<td>Spring面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104397516" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104397516</a></td>
</tr>
<tr>
<td>7</td>
<td>Spring MVC面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104397427" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104397427</a></td>
</tr>
<tr>
<td>8</td>
<td>Spring Boot面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104397299" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104397299</a></td>
</tr>
<tr>
<td>9</td>
<td>Spring Cloud面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104397367" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104397367</a></td>
</tr>
<tr>
<td>10</td>
<td>MyBatis面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/101292950" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/101292950</a></td>
</tr>
<tr>
<td>11</td>
<td>Redis面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/103522351" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/103522351</a></td>
</tr>
<tr>
<td>12</td>
<td>MySQL数据库面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104778621" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104778621</a></td>
</tr>
<tr>
<td>13</td>
<td>消息中间件MQ与RabbitMQ面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104588612" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104588612</a></td>
</tr>
<tr>
<td>14</td>
<td>Dubbo面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104390006" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104390006</a></td>
</tr>
<tr>
<td>15</td>
<td>Linux面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104588679" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104588679</a></td>
</tr>
<tr>
<td>16</td>
<td>Tomcat面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104397665" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104397665</a></td>
</tr>
<tr>
<td>17</td>
<td>ZooKeeper面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104397719" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104397719</a></td>
</tr>
<tr>
<td>18</td>
<td>Netty面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/104391081" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/104391081</a></td>
</tr>
<tr>
<td>19</td>
<td>架构设计&amp;分布式&amp;数据结构与算法面试题（2020最新版）</td>
<td><a href="https://thinkwon.blog.csdn.net/article/details/105870730" target="_blank" rel="noopener">https://thinkwon.blog.csdn.net/article/details/105870730</a></td>
</tr>
</tbody></table>
<h2 id="数据库基础知识"><a href="#数据库基础知识" class="headerlink" title="数据库基础知识"></a>数据库基础知识</h2><h3 id="为什么要使用数据库"><a href="#为什么要使用数据库" class="headerlink" title="为什么要使用数据库"></a>为什么要使用数据库</h3><p><strong>数据保存在内存</strong></p>
<p>优点： 存取速度快</p>
<p>缺点： 数据不能永久保存</p>
<p><strong>数据保存在文件</strong></p>
<p>优点： 数据永久保存</p>
<p>缺点：1）速度比内存操作慢，频繁的IO操作。 2）查询数据不方便</p>
<p><strong>数据保存在数据库</strong></p>
<p>1）数据永久保存</p>
<p>2）使用SQL语句，查询方便效率高。</p>
<p>3）管理数据方便</p>
<h3 id="什么是SQL？"><a href="#什么是SQL？" class="headerlink" title="什么是SQL？"></a>什么是SQL？</h3><p>结构化查询语言(Structured Query Language)简称SQL，是一种数据库查询语言。</p>
<p>作用：用于存取数据、查询、更新和管理关系数据库系统。</p>
<h3 id="什么是MySQL"><a href="#什么是MySQL" class="headerlink" title="什么是MySQL?"></a>什么是MySQL?</h3><p>MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一。在Java企业级开发中非常常用，因为 MySQL 是开源免费的，并且方便扩展。</p>
<h3 id="数据库三大范式是什么"><a href="#数据库三大范式是什么" class="headerlink" title="数据库三大范式是什么"></a>数据库三大范式是什么</h3><p>第一范式：每个列都不可以再拆分。</p>
<p>第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分。</p>
<p>第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。</p>
<p>在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。事实上我们经常会为了性能而妥协数据库的设计。</p>
<h3 id="mysql有关权限的表都有哪几个"><a href="#mysql有关权限的表都有哪几个" class="headerlink" title="mysql有关权限的表都有哪几个"></a>mysql有关权限的表都有哪几个</h3><p>MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。下面分别介绍一下这些表的结构和内容：</p>
<ul>
<li>user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。</li>
<li>db权限表：记录各个帐号在各个数据库上的操作权限。</li>
<li>table_priv权限表：记录数据表级的操作权限。</li>
<li>columns_priv权限表：记录数据列级的操作权限。</li>
<li>host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。</li>
</ul>
<h3 id="MySQL的binlog有有几种录入格式？分别有什么区别？"><a href="#MySQL的binlog有有几种录入格式？分别有什么区别？" class="headerlink" title="MySQL的binlog有有几种录入格式？分别有什么区别？"></a>MySQL的binlog有有几种录入格式？分别有什么区别？</h3><p>有三种格式，statement，row和mixed。</p>
<ul>
<li>statement模式下，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。</li>
<li>row级别下，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。</li>
<li>mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。</li>
</ul>
<p>此外，新版的MySQL中对row级别也做了一些优化，当表结构发生变化的时候，会记录语句而不是逐行记录。</p>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="mysql有哪些数据类型"><a href="#mysql有哪些数据类型" class="headerlink" title="mysql有哪些数据类型"></a>mysql有哪些数据类型</h3><table>
<thead>
<tr>
<th><strong>分类</strong></th>
<th><strong>类型名称</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>整数类型</strong></td>
<td>tinyInt</td>
<td>很小的整数(8位二进制)</td>
</tr>
<tr>
<td></td>
<td>smallint</td>
<td>小的整数(16位二进制)</td>
</tr>
<tr>
<td></td>
<td>mediumint</td>
<td>中等大小的整数(24位二进制)</td>
</tr>
<tr>
<td></td>
<td>int(integer)</td>
<td>普通大小的整数(32位二进制)</td>
</tr>
<tr>
<td><strong>小数类型</strong></td>
<td>float</td>
<td>单精度浮点数</td>
</tr>
<tr>
<td></td>
<td>double</td>
<td>双精度浮点数</td>
</tr>
<tr>
<td></td>
<td>decimal(m,d)</td>
<td>压缩严格的定点数</td>
</tr>
<tr>
<td><strong>日期类型</strong></td>
<td>year</td>
<td>YYYY 1901~2155</td>
</tr>
<tr>
<td></td>
<td>time</td>
<td>HH:MM:SS -838:59:59~838:59:59</td>
</tr>
<tr>
<td></td>
<td>date</td>
<td>YYYY-MM-DD 1000-01-01~9999-12-3</td>
</tr>
<tr>
<td></td>
<td>datetime</td>
<td>YYYY-MM-DD  HH:MM:SS 1000-01-01 00:00:00~ 9999-12-31 23:59:59</td>
</tr>
<tr>
<td></td>
<td>timestamp</td>
<td>YYYY-MM-DD HH:MM:SS   1970<sub>01</sub>01 00:00:01 UTC~2038-01-19 03:14:07UTC</td>
</tr>
<tr>
<td><strong>文本、二进制类型</strong></td>
<td>CHAR(M)</td>
<td>M为0~255之间的整数</td>
</tr>
<tr>
<td></td>
<td>VARCHAR(M)</td>
<td>M为0~65535之间的整数</td>
</tr>
<tr>
<td></td>
<td>TINYBLOB</td>
<td>允许长度0~255字节</td>
</tr>
<tr>
<td></td>
<td>BLOB</td>
<td>允许长度0~65535字节</td>
</tr>
<tr>
<td></td>
<td>MEDIUMBLOB</td>
<td>允许长度0~167772150字节</td>
</tr>
<tr>
<td></td>
<td>LONGBLOB</td>
<td>允许长度0~4294967295字节</td>
</tr>
<tr>
<td></td>
<td>TINYTEXT</td>
<td>允许长度0~255字节</td>
</tr>
<tr>
<td></td>
<td>TEXT</td>
<td>允许长度0~65535字节</td>
</tr>
<tr>
<td></td>
<td>MEDIUMTEXT</td>
<td>允许长度0~167772150字节</td>
</tr>
<tr>
<td></td>
<td>LONGTEXT</td>
<td>允许长度0~4294967295字节</td>
</tr>
<tr>
<td></td>
<td>VARBINARY(M)</td>
<td>允许长度0~M个字节的变长字节字符串</td>
</tr>
<tr>
<td></td>
<td>BINARY(M)</td>
<td>允许长度0~M个字节的定长字节字符串</td>
</tr>
</tbody></table>
<ul>
<li><p><code>1、整数类型</code>，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。<br><code>长度</code>：整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。长度在大多数场景是没有意义的，它不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。<br><code>例子</code>，假定类型设定为INT(5)，属性为UNSIGNED ZEROFILL，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。</p>
</li>
<li><p><code>2、实数类型</code>，包括FLOAT、DOUBLE、DECIMAL。<br>DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。<br>而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。<br>计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。</p>
</li>
<li><p><code>3、字符串类型</code>，包括VARCHAR、CHAR、TEXT、BLOB<br>VARCHAR用于存储可变长字符串，它比定长类型更节省空间。<br>VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。<br>VARCHAR存储的内容超出设置的长度时，内容会被截断。<br>CHAR是定长的，根据定义的字符串长度分配足够的空间。<br>CHAR会根据需要使用空格进行填充方便比较。<br>CHAR适合存储很短的字符串，或者所有值都接近同一个长度。<br>CHAR存储的内容超出设置的长度时，内容同样会被截断。</p>
</li>
</ul>
<p><strong>使用策略：</strong><br>对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。<br>对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。<br>使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。<br>尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。</p>
<ul>
<li><p><code>4、枚举类型（ENUM）</code>，把不重复的数据存储为一个预定义的集合。<br>有时可以使用ENUM代替常用的字符串类型。<br>ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。<br>ENUM在内部存储时，其实存的是整数。<br>尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。<br>排序是按照内部存储的整数</p>
</li>
<li><p><code>5、日期和时间类型</code>，尽量使用timestamp，空间效率高于datetime，<br>用整数保存时间戳通常不方便处理。<br>如果需要存储微妙，可以使用bigint存储。<br>看到这里，这道真题是不是就比较容易回答了。</p>
</li>
</ul>
<h2 id="引擎"><a href="#引擎" class="headerlink" title="引擎"></a>引擎</h2><h3 id="MySQL存储引擎MyISAM与InnoDB区别"><a href="#MySQL存储引擎MyISAM与InnoDB区别" class="headerlink" title="MySQL存储引擎MyISAM与InnoDB区别"></a>MySQL存储引擎MyISAM与InnoDB区别</h3><p>存储引擎Storage engine：MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现。</p>
<p>常用的存储引擎有以下：</p>
<ul>
<li><strong>Innodb引擎</strong>：Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。</li>
<li><strong>MyIASM引擎</strong>(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。</li>
<li><strong>MEMORY引擎</strong>：所有的数据都在内存中，数据的处理速度快，但是安全性不高。</li>
</ul>
<p><strong>MyISAM与InnoDB区别</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>MyISAM</th>
<th>Innodb</th>
</tr>
</thead>
<tbody><tr>
<td>存储结构</td>
<td>每张表被存放在三个文件：frm-表格定义、MYD(MYData)-数据文件、MYI(MYIndex)-索引文件</td>
<td>所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB</td>
</tr>
<tr>
<td>存储空间</td>
<td>MyISAM可被压缩，存储空间较小</td>
<td>InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引</td>
</tr>
<tr>
<td>可移植性、备份及恢复</td>
<td>由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作</td>
<td>免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了</td>
</tr>
<tr>
<td>文件格式</td>
<td>数据和索引是分别存储的，数据<code>.MYD</code>，索引<code>.MYI</code></td>
<td>数据和索引是集中存储的，<code>.ibd</code></td>
</tr>
<tr>
<td>记录存储顺序</td>
<td>按记录插入顺序保存</td>
<td>按主键大小有序插入</td>
</tr>
<tr>
<td>外键</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>事务</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的）</td>
<td>表级锁定</td>
<td>行级锁定、表级锁定，锁定力度小并发能力高</td>
</tr>
<tr>
<td>SELECT</td>
<td>MyISAM更优</td>
<td></td>
</tr>
<tr>
<td>INSERT、UPDATE、DELETE</td>
<td></td>
<td>InnoDB更优</td>
</tr>
<tr>
<td>select count(*)</td>
<td>myisam更快，因为myisam内部维护了一个计数器，可以直接调取。</td>
<td></td>
</tr>
<tr>
<td>索引的实现方式</td>
<td>B+树索引，myisam 是堆表</td>
<td>B+树索引，Innodb 是索引组织表</td>
</tr>
<tr>
<td>哈希索引</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>全文索引</td>
<td>支持</td>
<td>不支持</td>
</tr>
</tbody></table>
<h3 id="MyISAM索引与InnoDB索引的区别？"><a href="#MyISAM索引与InnoDB索引的区别？" class="headerlink" title="MyISAM索引与InnoDB索引的区别？"></a>MyISAM索引与InnoDB索引的区别？</h3><ul>
<li>InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。</li>
<li>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。</li>
<li>MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</li>
<li>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。</li>
</ul>
<h3 id="聚簇索引和非聚簇索引的区别？"><a href="#聚簇索引和非聚簇索引的区别？" class="headerlink" title="聚簇索引和非聚簇索引的区别？"></a>聚簇索引和非聚簇索引的区别？</h3><ul>
<li>聚簇索引的叶子节点就是数据节点，</li>
<li>而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。</li>
</ul>
<h3 id="InnoDB引擎的4大特性"><a href="#InnoDB引擎的4大特性" class="headerlink" title="InnoDB引擎的4大特性"></a>InnoDB引擎的4大特性</h3><ul>
<li>插入缓冲（insert buffer)</li>
<li>二次写(double write)</li>
<li>自适应哈希索引(ahi)</li>
<li>预读(read ahead)</li>
</ul>
<h3 id="存储引擎选择"><a href="#存储引擎选择" class="headerlink" title="存储引擎选择"></a>存储引擎选择</h3><p>如果没有特别的需求，使用默认的<code>Innodb</code>即可。</p>
<p>MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。</p>
<p>Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。</p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="什么是索引？"><a href="#什么是索引？" class="headerlink" title="什么是索引？"></a>什么是索引？</h3><p>索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。</p>
<p>索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。</p>
<p>更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，它是要占据物理空间的。</p>
<h3 id="索引有哪些优缺点？"><a href="#索引有哪些优缺点？" class="headerlink" title="索引有哪些优缺点？"></a>索引有哪些优缺点？</h3><p>索引的优点</p>
<ul>
<li>可以大大加快数据的检索速度，这也是创建索引的最主要的原因。</li>
<li>通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。</li>
</ul>
<p>索引的缺点</p>
<ul>
<li>时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；</li>
<li>空间方面：索引需要占物理空间。</li>
</ul>
<h3 id="索引使用场景（重点）"><a href="#索引使用场景（重点）" class="headerlink" title="索引使用场景（重点）"></a>索引使用场景（重点）</h3><ul>
<li>where</li>
</ul>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8yLzE5LzE2OTA0NTk2ZTFiNTU4YjI?x-oss-process=image/format,png" alt="img">

<p>上图中，根据<code>id</code>查询记录，因为<code>id</code>字段仅建立了主键索引，因此此SQL执行可选的索引只有主键索引，如果有多个，最终会选一个较优的作为检索的依据。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 增加一个没有建立索引的字段</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> innodb1 <span class="keyword">add</span> sex <span class="built_in">char</span>(<span class="number">1</span>);</span><br><span class="line"><span class="comment">-- 按sex检索时可选的索引为null</span></span><br><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> * <span class="keyword">from</span> innodb1 <span class="keyword">where</span> sex=<span class="string">'男'</span>;</span><br></pre></td></tr></table></figure>

<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8yLzE5LzE2OTA0NTk2Zjk1YTdmOTk?x-oss-process=image/format,png" alt="img">

<blockquote>
<p>可以尝试在一个字段未建立索引时，根据该字段查询的效率，然后对该字段建立索引（<code>alter table 表名 add index(字段名)</code>），同样的SQL执行的效率，你会发现查询效率会有明显的提升（数据量越大越明显）。</p>
</blockquote>
<ul>
<li>order by</li>
</ul>
<p>当我们使用<code>order by</code>将查询结果按照某个字段排序时，如果该字段没有建立索引，那么执行计划会将查询出的所有数据使用外部排序（将数据从硬盘分批读取到内存使用内部排序，最后合并排序结果），这个操作是很影响性能的，因为需要将查询涉及到的所有数据从磁盘中读到内存（如果单条数据过大或者数据量过多都会降低效率），更无论读到内存之后的排序了。</p>
<p>但是如果我们对该字段建立索引<code>alter table 表名 add index(字段名)</code>，那么由于索引本身是有序的，因此直接按照索引的顺序和映射关系逐条取出数据即可。而且如果分页的，那么只用<strong>取出索引表某个范围内的索引对应的数据</strong>，而不用像上述那<strong>取出所有数据</strong>进行排序再返回某个范围内的数据。（从磁盘取数据是最影响性能的）</p>
<ul>
<li><p>join<br>对<code>join</code>语句匹配关系（<code>on</code>）涉及的字段建立索引能够提高效率</p>
</li>
<li><p>索引覆盖<br>如果要查询的字段都建立过索引，那么引擎会直接在索引表中查询而不会访问原始数据（否则只要有一个字段没有建立索引就会做全表扫描），这叫索引覆盖。因此我们需要尽可能的在<code>select</code>后<mark>只写必要的查询字段</mark>，以增加索引覆盖的几率。</p>
</li>
</ul>
<p>这里值得注意的是不要想着为每个字段建立索引，因为优先使用索引的优势就在于其体积小。</p>
<h3 id="索引有哪几种类型？"><a href="#索引有哪几种类型？" class="headerlink" title="索引有哪几种类型？"></a>索引有哪几种类型？</h3><ul>
<li><p><strong>主键索引:</strong> 数据列不允许重复，不允许为NULL，一个表只能有一个主键。</p>
</li>
<li><p><strong>唯一索引:</strong> 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。</p>
</li>
</ul>
<p>可以通过 <code>ALTER TABLE table_name ADD UNIQUE (column);</code> 创建唯一索引</p>
<p>可以通过 <code>ALTER TABLE table_name ADD UNIQUE (column1,column2);</code> 创建唯一组合索引</p>
<p>可以通过 <code>ALTER TABLE table_name ADD UNIQUE (column1,column2);</code> 创建唯一组合索引</p>
<ul>
<li><strong>普通索引:</strong> 基本的索引类型，没有唯一性的限制，允许为NULL值。</li>
</ul>
<p>可以通过<code>ALTER TABLE table_name ADD INDEX index_name (column);</code>创建普通索引</p>
<p>可以通过<code>ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);</code>创建组合索引</p>
<p>可以通过<code>ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);</code>创建组合索引</p>
<p><strong>全文索引：</strong> 是目前搜索引擎使用的一种关键技术。</p>
<ul>
<li>可以通过<code>ALTER TABLE table_name ADD FULLTEXT (column);</code>创建全文索引</li>
</ul>
<h3 id="索引的数据结构（b树，hash）"><a href="#索引的数据结构（b树，hash）" class="headerlink" title="索引的数据结构（b树，hash）"></a>索引的数据结构（b树，hash）</h3><p>索引的数据结构和具体存储引擎的实现有关，在MySQL中使用较多的索引有<strong>Hash索引</strong>，<strong>B+树索引</strong>等，而我们经常使用的InnoDB存储引擎的默认索引实现为：B+树索引。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。</p>
<p>1）B树索引</p>
<p>mysql通过存储引擎取数据，基本上90%的人用的就是InnoDB了，按照实现方式分，InnoDB的索引类型目前只有两种：BTREE（B树）索引和HASH索引。B树索引是Mysql数据库中使用最频繁的索引类型，基本所有存储引擎都支持BTree索引。通常我们说的索引不出意外指的就是（B树）索引（实际是用B+树实现的，因为在查看表索引时，mysql一律打印BTREE，所以简称为B树索引）</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzI0LzE2NjBjMGYxNGRhY2Y2ZjU?x-oss-process=image/format,png" alt="img">

<p>查询方式：</p>
<p>主键索引区:PI(关联保存的时数据的地址)按主键查询,</p>
<p>普通索引区:si(关联的id的地址,然后再到达上面的地址)。所以按主键查询,速度最快</p>
<p>B+tree性质：</p>
<p>1.）n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。</p>
<p>2.）所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。</p>
<p>3.）所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。</p>
<p>4.）B+ 树中，数据对象的插入和删除仅在叶节点上进行。</p>
<p>5.）B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。</p>
<p>2）哈希索引</p>
<p>简要说下，类似于数据结构中简单实现的HASH表（散列表）一样，当我们在mysql中用哈希索引时，主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。当然这只是简略模拟图。</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzI0LzE2NjBjMGYxNThhNzZmOTQ?x-oss-process=image/format,png" alt="img">

<h3 id="索引的基本原理"><a href="#索引的基本原理" class="headerlink" title="索引的基本原理"></a>索引的基本原理</h3><p>索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。</p>
<p>索引的原理很简单，就是把无序的数据变成有序的查询</p>
<p>把创建了索引的列的内容进行排序</p>
<p>对排序结果生成倒排表</p>
<p>在倒排表内容上拼上数据地址链</p>
<p>在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据</p>
<p>对排序结果生成倒排表</p>
<p>在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据</p>
<h3 id="索引算法有哪些？"><a href="#索引算法有哪些？" class="headerlink" title="索引算法有哪些？"></a>索引算法有哪些？</h3><p>索引算法有 BTree算法和Hash算法</p>
<p><strong>BTree算法</strong></p>
<p>BTree是最常用的mysql数据库索引算法，也是mysql默认的算法。因为它不仅可以被用在=,&gt;,&gt;=,&lt;,&lt;=和between这些比较操作符上，而且还可以用于like操作符，只要它的查询条件是一个不以通配符开头的常量， 例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 只要它的查询条件是一个不以通配符开头的常量</span><br><span class="line">select * from user where name like &#39;jack%&#39;; </span><br><span class="line">-- 如果一通配符开头，或者没有使用常量，则不会使用索引，例如： </span><br><span class="line">select * from user where name like &#39;%jack&#39;;</span><br></pre></td></tr></table></figure>

<p><strong>Hash算法</strong></p>
<p>Hash Hash索引只能用于对等比较，例如=,&lt;=&gt;（相当于=）操作符。由于是一次定位数据，不像BTree索引需要从根节点到枝节点，最后才能访问到页节点这样多次IO访问，所以检索效率远高于BTree索引。</p>
<h3 id="索引设计的原则？"><a href="#索引设计的原则？" class="headerlink" title="索引设计的原则？"></a>索引设计的原则？</h3><ol>
<li>适合索引的列是出现在where子句中的列，或者连接子句中指定的列</li>
<li>基数较小的类，索引效果较差，没有必要在此列建立索引</li>
<li>使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间</li>
<li>不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可。</li>
</ol>
<h3 id="创建索引的原则（重中之重）"><a href="#创建索引的原则（重中之重）" class="headerlink" title="创建索引的原则（重中之重）"></a>创建索引的原则（重中之重）</h3><p>索引虽好，但也不是无限制的使用，最好符合一下几个原则</p>
<p>1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p>
<p>2）较频繁作为查询条件的字段才去创建索引</p>
<p>3）更新频繁字段不适合创建索引</p>
<p>4）若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低)</p>
<p>5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。</p>
<p>6）定义有外键的数据列一定要建立索引。</p>
<p>7）对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。</p>
<p>8）对于定义为text、image和bit的数据类型的列不要建立索引。</p>
<h3 id="创建索引的三种方式，删除索引"><a href="#创建索引的三种方式，删除索引" class="headerlink" title="创建索引的三种方式，删除索引"></a>创建索引的三种方式，删除索引</h3><p>第一种方式：在执行CREATE TABLE时创建索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> user_index2 (</span><br><span class="line">	<span class="keyword">id</span> <span class="built_in">INT</span> auto_increment PRIMARY <span class="keyword">KEY</span>,</span><br><span class="line">	first_name <span class="built_in">VARCHAR</span> (<span class="number">16</span>),</span><br><span class="line">	last_name <span class="built_in">VARCHAR</span> (<span class="number">16</span>),</span><br><span class="line">	id_card <span class="built_in">VARCHAR</span> (<span class="number">18</span>),</span><br><span class="line">	information <span class="built_in">text</span>,</span><br><span class="line">	<span class="keyword">KEY</span> <span class="keyword">name</span> (first_name, last_name),</span><br><span class="line">	FULLTEXT <span class="keyword">KEY</span> (information),</span><br><span class="line">	<span class="keyword">UNIQUE</span> <span class="keyword">KEY</span> (id_card)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>第二种方式：使用ALTER TABLE命令去增加索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> <span class="keyword">INDEX</span> index_name (column_list);</span><br></pre></td></tr></table></figure>

<p>ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。</p>
<p>其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。</p>
<p>索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。</p>
<p>第三种方式：使用CREATE INDEX命令创建</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> index_name <span class="keyword">ON</span> table_name (column_list);</span><br></pre></td></tr></table></figure>

<p>CREATE INDEX可对表增加普通索引或UNIQUE索引。（但是，不能创建PRIMARY KEY索引）</p>
<p>删除索引</p>
<p>根据索引名删除普通索引、唯一索引、全文索引：<code>alter table 表名 drop KEY 索引名</code></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> user_index <span class="keyword">drop</span> <span class="keyword">KEY</span> <span class="keyword">name</span>;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> user_index <span class="keyword">drop</span> <span class="keyword">KEY</span> id_card;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> user_index <span class="keyword">drop</span> <span class="keyword">KEY</span> information;</span><br></pre></td></tr></table></figure>

<p>删除主键索引：<code>alter table 表名 drop primary key</code>（因为主键只有一个）。这里值得注意的是，如果主键自增长，那么不能直接执行此操作（自增长依赖于主键索引）：</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8yLzE5LzE2OTA0NTk2YjIxZTIwOWM?x-oss-process=image/format,png" alt="img">

<p>需要取消自增长再行删除：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table user_index</span><br><span class="line">-- 重新定义字段</span><br><span class="line">MODIFY id int,</span><br><span class="line">drop PRIMARY KEY</span><br></pre></td></tr></table></figure>

<p>但通常不会删除主键，因为设计主键一定与业务逻辑无关。</p>
<h3 id="创建索引时需要注意什么？"><a href="#创建索引时需要注意什么？" class="headerlink" title="创建索引时需要注意什么？"></a>创建索引时需要注意什么？</h3><ul>
<li>非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；</li>
<li>取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；</li>
<li>索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。</li>
</ul>
<h3 id="使用索引查询一定能提高查询的性能吗？为什么"><a href="#使用索引查询一定能提高查询的性能吗？为什么" class="headerlink" title="使用索引查询一定能提高查询的性能吗？为什么"></a>使用索引查询一定能提高查询的性能吗？为什么</h3><p>通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。</p>
<ul>
<li>索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:</li>
<li>基于一个范围的检索，一般查询返回结果集小于表中记录数的30%</li>
<li>基于非唯一性索引的检索</li>
</ul>
<h3 id="百万级别或以上的数据如何删除"><a href="#百万级别或以上的数据如何删除" class="headerlink" title="百万级别或以上的数据如何删除"></a>百万级别或以上的数据如何删除</h3><p>关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。</p>
<ol>
<li>所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）</li>
<li>然后删除其中无用数据（此过程需要不到两分钟）</li>
<li>删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。</li>
<li>与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。</li>
</ol>
<h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>语法：<code>index(field(10))</code>，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。</p>
<p>前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。</p>
<p><mark>实操的难度</mark>：在于前缀截取的长度。</p>
<p>我们可以利用<code>select count(*)/count(distinct left(password,prefixLen));</code>，通过从调整<code>prefixLen</code>的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前<code>prefixLen</code>个字符几乎能确定唯一一条记录）</p>
<h3 id="什么是最左前缀原则？什么是最左匹配原则"><a href="#什么是最左前缀原则？什么是最左匹配原则" class="headerlink" title="什么是最左前缀原则？什么是最左匹配原则"></a>什么是最左前缀原则？什么是最左匹配原则</h3><ul>
<li>顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。</li>
<li>最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</li>
<li>=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式</li>
</ul>
<h3 id="B树和B-树的区别"><a href="#B树和B-树的区别" class="headerlink" title="B树和B+树的区别"></a>B树和B+树的区别</h3><p>在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。</p>
<p>B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。<br><img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzIxLzE2NWZiNjgyZTc1OWNmMTI?x-oss-process=image/format,png" alt="img"></p>
<p>B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。</p>
<h3 id="使用B树的好处"><a href="#使用B树的好处" class="headerlink" title="使用B树的好处"></a>使用B树的好处</h3><p>B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。这种特性使得B树在特定数据重复多次查询的场景中更加高效。</p>
<h3 id="使用B-树的好处"><a href="#使用B-树的好处" class="headerlink" title="使用B+树的好处"></a>使用B+树的好处</h3><p>由于B+树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间</p>
<h3 id="Hash索引和B-树所有有什么区别或者说优劣呢"><a href="#Hash索引和B-树所有有什么区别或者说优劣呢" class="headerlink" title="Hash索引和B+树所有有什么区别或者说优劣呢?"></a>Hash索引和B+树所有有什么区别或者说优劣呢?</h3><p>首先要知道Hash索引和B+树索引的底层实现原理：</p>
<p>hash索引底层就是hash表，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。B+树底层实现是多路平衡查找树。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。</p>
<p>那么可以看出他们有以下的不同：</p>
<ul>
<li>hash索引进行等值查询更快(一般情况下)，但是却无法进行范围查询。</li>
</ul>
<p>因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。</p>
<ul>
<li>hash索引不支持使用索引进行排序，原理同上。</li>
<li>hash索引不支持模糊查询以及多列索引的最左前缀匹配。原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。</li>
<li>hash索引任何时候都避免不了回表查询数据，而B+树在符合某些条件(聚簇索引，覆盖索引等)的时候可以只通过索引完成查询。</li>
<li>hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。</li>
</ul>
<p>因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。</p>
<h3 id="数据库为什么使用B-树而不是B树"><a href="#数据库为什么使用B-树而不是B树" class="headerlink" title="数据库为什么使用B+树而不是B树"></a>数据库为什么使用B+树而不是B树</h3><ul>
<li>B树只适合随机检索，而B+树同时支持随机检索和顺序检索；</li>
<li>B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素；</li>
<li>B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。</li>
<li>B-树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。</li>
<li>增删文件（节点）时，效率更高。因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。</li>
</ul>
<h3 id="B-树在满足聚簇索引和覆盖索引的时候不需要回表查询数据，"><a href="#B-树在满足聚簇索引和覆盖索引的时候不需要回表查询数据，" class="headerlink" title="B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据，"></a>B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据，</h3><p>在B+树的索引中，叶子节点可能存储了当前的key值，也可能存储了当前的key值以及整行的数据，这就是聚簇索引和非聚簇索引。 在InnoDB中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。</p>
<p>当查询使用聚簇索引时，在对应的叶子节点，可以获取到整行数据，因此不用再次进行回表查询。</p>
<h3 id="什么是聚簇索引？何时使用聚簇索引与非聚簇索引"><a href="#什么是聚簇索引？何时使用聚簇索引与非聚簇索引" class="headerlink" title="什么是聚簇索引？何时使用聚簇索引与非聚簇索引"></a>什么是聚簇索引？何时使用聚簇索引与非聚簇索引</h3><ul>
<li>聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据</li>
<li>非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因</li>
</ul>
<p>澄清一个概念：innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值</p>
<p>何时使用聚簇索引与非聚簇索引</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xMDE1NDQ5OS1kNTNhNWNlOWNlY2YyMmYzLnBuZw?x-oss-process=image/format,png" alt="img">

<h3 id="非聚簇索引一定会回表查询吗？"><a href="#非聚簇索引一定会回表查询吗？" class="headerlink" title="非聚簇索引一定会回表查询吗？"></a>非聚簇索引一定会回表查询吗？</h3><p>不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。</p>
<p>举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行<code>select age from employee where age &amp;lt; 20</code>的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。</p>
<h3 id="联合索引是什么？为什么需要注意联合索引中的顺序？"><a href="#联合索引是什么？为什么需要注意联合索引中的顺序？" class="headerlink" title="联合索引是什么？为什么需要注意联合索引中的顺序？"></a>联合索引是什么？为什么需要注意联合索引中的顺序？</h3><p>MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。</p>
<p>具体原因为:</p>
<p>MySQL使用索引时需要索引有序，假设现在建立了”name，age，school”的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。</p>
<p>当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。</p>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="什么是数据库事务？"><a href="#什么是数据库事务？" class="headerlink" title="什么是数据库事务？"></a>什么是数据库事务？</h3><p>事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>
<p>事务最经典也经常被拿出来说例子就是转账了。</p>
<p>假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。</p>
<h3 id="事物的四大特性-ACID-介绍一下"><a href="#事物的四大特性-ACID-介绍一下" class="headerlink" title="事物的四大特性(ACID)介绍一下?"></a>事物的四大特性(ACID)介绍一下?</h3><p>关系性数据库需要遵循ACID规则，具体内容如下：</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC81LzIwLzE2MzdiMDhiOTg2MTk0NTU?x-oss-process=image/format,png" alt="事务的特性">

<ol>
<li><strong>原子性：</strong> 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li>
<li><strong>一致性：</strong> 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；</li>
<li><strong>隔离性：</strong> 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li>
<li><strong>持久性：</strong> 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li>
</ol>
<h3 id="什么是脏读？幻读？不可重复读？"><a href="#什么是脏读？幻读？不可重复读？" class="headerlink" title="什么是脏读？幻读？不可重复读？"></a>什么是脏读？幻读？不可重复读？</h3><ul>
<li>脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。</li>
<li>不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。</li>
<li>幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。</li>
</ul>
<h3 id="什么是事务的隔离级别？MySQL的默认隔离级别是什么？"><a href="#什么是事务的隔离级别？MySQL的默认隔离级别是什么？" class="headerlink" title="什么是事务的隔离级别？MySQL的默认隔离级别是什么？"></a>什么是事务的隔离级别？MySQL的默认隔离级别是什么？</h3><p>为了达到事务的四大特性，数据库定义了4种不同的事务隔离级别，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻影读</th>
</tr>
</thead>
<tbody><tr>
<td>READ-UNCOMMITTED</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>READ-COMMITTED</td>
<td>×</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>REPEATABLE-READ</td>
<td>×</td>
<td>×</td>
<td>√</td>
</tr>
<tr>
<td>SERIALIZABLE</td>
<td>×</td>
<td>×</td>
<td>×</td>
</tr>
</tbody></table>
<p><strong>SQL 标准定义了四个隔离级别：</strong></p>
<ul>
<li><strong>READ-UNCOMMITTED(读取未提交)：</strong> 最低的隔离级别，允许读取尚未提交的数据变更，<strong>可能会导致脏读、幻读或不可重复读</strong>。</li>
<li><strong>READ-COMMITTED(读取已提交)：</strong> 允许读取并发事务已经提交的数据，<strong>可以阻止脏读，但是幻读或不可重复读仍有可能发生</strong>。</li>
<li><strong>REPEATABLE-READ(可重复读)：</strong> 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，<strong>可以阻止脏读和不可重复读，但幻读仍有可能发生</strong>。</li>
<li><strong>SERIALIZABLE(可串行化)：</strong> 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，<strong>该级别可以防止脏读、不可重复读以及幻读</strong>。</li>
</ul>
<p>这里需要注意的是：Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别</p>
<p>事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。</p>
<p>因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是<strong>READ-COMMITTED(读取提交内容):</strong>，但是你要知道的是InnoDB 存储引擎默认使用 <strong>REPEATABLE-READ（可重读）</strong>并不会有任何性能损失。</p>
<p>InnoDB 存储引擎在 <strong>分布式事务</strong> 的情况下一般会用到<strong>SERIALIZABLE(可串行化)</strong>隔离级别。</p>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="对MySQL的锁了解吗"><a href="#对MySQL的锁了解吗" class="headerlink" title="对MySQL的锁了解吗"></a>对MySQL的锁了解吗</h3><p>当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。</p>
<p>就像酒店的房间，如果大家随意进出，就会出现多人抢夺同一个房间的情况，而在房间上装上锁，申请到钥匙的人才可以入住并且将房间锁起来，其他人只有等他使用完毕才可以再次使用。</p>
<h3 id="隔离级别与锁的关系"><a href="#隔离级别与锁的关系" class="headerlink" title="隔离级别与锁的关系"></a>隔离级别与锁的关系</h3><p>在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突</p>
<p>在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；</p>
<p>在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。</p>
<p>SERIALIZABLE 是限制性最强的隔离级别，因为该级别<strong>锁定整个范围的键</strong>，并一直持有锁，直到事务完成。</p>
<h3 id="按照锁的粒度分数据库锁有哪些？锁机制与InnoDB锁算法"><a href="#按照锁的粒度分数据库锁有哪些？锁机制与InnoDB锁算法" class="headerlink" title="按照锁的粒度分数据库锁有哪些？锁机制与InnoDB锁算法"></a>按照锁的粒度分数据库锁有哪些？锁机制与InnoDB锁算法</h3><p>在关系型数据库中，可以<strong>按照锁的粒度把数据库锁分</strong>为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。</p>
<p><strong>MyISAM和InnoDB存储引擎使用的锁：</strong></p>
<ul>
<li>MyISAM采用表级锁(table-level locking)。</li>
<li>InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁</li>
</ul>
<p>行级锁，表级锁和页级锁对比</p>
<p><strong>行级锁</strong> 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。</p>
<p>特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p>
<p><strong>表级锁</strong> 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。</p>
<p>特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。</p>
<p><strong>页级锁</strong> 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。</p>
<p>特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</p>
<h3 id="从锁的类别上分MySQL都有哪些锁呢？像上面那样子进行锁定岂不是有点阻碍并发效率了"><a href="#从锁的类别上分MySQL都有哪些锁呢？像上面那样子进行锁定岂不是有点阻碍并发效率了" class="headerlink" title="从锁的类别上分MySQL都有哪些锁呢？像上面那样子进行锁定岂不是有点阻碍并发效率了"></a>从锁的类别上分MySQL都有哪些锁呢？像上面那样子进行锁定岂不是有点阻碍并发效率了</h3><p><strong>从锁的类别上来讲</strong>，有共享锁和排他锁。</p>
<p>共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p>
<p>排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。</p>
<p>用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。</p>
<p>锁的粒度取决于具体的存储引擎，InnoDB实现了行级锁，页级锁，表级锁。</p>
<p>他们的加锁开销从大到小，并发能力也是从大到小。</p>
<h3 id="MySQL中InnoDB引擎的行锁是怎么实现的？"><a href="#MySQL中InnoDB引擎的行锁是怎么实现的？" class="headerlink" title="MySQL中InnoDB引擎的行锁是怎么实现的？"></a>MySQL中InnoDB引擎的行锁是怎么实现的？</h3><p>答：InnoDB是基于索引来完成行锁</p>
<p>例: select * from tab_with_index where id = 1 for update;</p>
<p>for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将完成表锁，并发将无从谈起</p>
<h3 id="InnoDB存储引擎的锁的算法有三种"><a href="#InnoDB存储引擎的锁的算法有三种" class="headerlink" title="InnoDB存储引擎的锁的算法有三种"></a>InnoDB存储引擎的锁的算法有三种</h3><ul>
<li>Record lock：单个行记录上的锁</li>
<li>Gap lock：间隙锁，锁定一个范围，不包括记录本身</li>
<li>Next-key lock：record+gap 锁定一个范围，包含记录本身</li>
</ul>
<p><strong>相关知识点：</strong></p>
<ol>
<li>innodb对于行的查询使用next-key lock</li>
<li>Next-locking keying为了解决Phantom Problem幻读问题</li>
<li>当查询的索引含有唯一属性时，将next-key lock降级为record key</li>
<li>Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生</li>
<li>有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1</li>
</ol>
<h3 id="什么是死锁？怎么解决？"><a href="#什么是死锁？怎么解决？" class="headerlink" title="什么是死锁？怎么解决？"></a>什么是死锁？怎么解决？</h3><p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。</p>
<p>常见的解决死锁的方法</p>
<p>1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。</p>
<p>2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</p>
<p>3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</p>
<p>如果业务处理不好可以用分布式事务锁或者使用乐观锁</p>
<h3 id="数据库的乐观锁和悲观锁是什么？怎么实现的？"><a href="#数据库的乐观锁和悲观锁是什么？怎么实现的？" class="headerlink" title="数据库的乐观锁和悲观锁是什么？怎么实现的？"></a>数据库的乐观锁和悲观锁是什么？怎么实现的？</h3><p>数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。</p>
<p><strong>悲观锁</strong>：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制</p>
<p><strong>乐观锁</strong>：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。</p>
<p><strong>两种锁的使用场景</strong></p>
<p>从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像<strong>乐观锁适用于写比较少的情况下（多读场景）</strong>，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。</p>
<p>但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以<strong>一般多写的场景下用悲观锁就比较合适。</strong></p>
<h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><h3 id="为什么要使用视图？什么是视图？"><a href="#为什么要使用视图？什么是视图？" class="headerlink" title="为什么要使用视图？什么是视图？"></a>为什么要使用视图？什么是视图？</h3><p>为了提高复杂SQL语句的复用性和表操作的安全性，MySQL数据库管理系统提供了视图特性。所谓视图，本质上是一种虚拟表，在物理上是不存在的，其内容与真实的表相似，包含一系列带有名称的列和行数据。但是，视图并不在数据库中以储存的数据值形式存在。行和列数据来自定义视图的查询所引用基本表，并且在具体引用视图时动态生成。</p>
<p>视图使开发者只关心感兴趣的某些特定数据和所负责的特定任务，只能看到视图中所定义的数据，而不是视图所引用表中的数据，从而提高了数据库中数据的安全性。</p>
<h3 id="视图有哪些特点？"><a href="#视图有哪些特点？" class="headerlink" title="视图有哪些特点？"></a>视图有哪些特点？</h3><p>视图的特点如下:</p>
<p>视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。</p>
<p>视图是由基本表(实表)产生的表(虚表)。</p>
<p>视图的建立和删除不影响基本表。</p>
<p>对视图内容的更新(添加，删除和修改)直接影响基本表。</p>
<p>当视图来自多个基本表时，不允许添加和删除数据。</p>
<p>视图是由基本表(实表)产生的表(虚表)。</p>
<p>对视图内容的更新(添加，删除和修改)直接影响基本表。</p>
<p>视图的操作包括创建视图，查看视图，删除视图和修改视图。</p>
<h3 id="视图的使用场景有哪些？"><a href="#视图的使用场景有哪些？" class="headerlink" title="视图的使用场景有哪些？"></a>视图的使用场景有哪些？</h3><p>视图根本用途：简化sql查询，提高开发效率。如果说还有另外一个用途那就是兼容老的表结构。</p>
<p>下面是视图的常见使用场景：</p>
<p>重用SQL语句；</p>
<p>简化复杂的SQL操作。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；</p>
<p>使用表的组成部分而不是整个表；</p>
<p>保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；</p>
<p>更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。</p>
<p>简化复杂的SQL操作。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；</p>
<p>保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；</p>
<h3 id="视图的优点"><a href="#视图的优点" class="headerlink" title="视图的优点"></a>视图的优点</h3><ol>
<li>查询简单化。视图能简化用户的操作</li>
<li>数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护</li>
<li>逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性</li>
</ol>
<h3 id="视图的缺点"><a href="#视图的缺点" class="headerlink" title="视图的缺点"></a>视图的缺点</h3><p>性能。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，即使是视图的一个简单查询，数据库也把它变成一个复杂的结合体，需要花费一定的时间。</p>
<p>修改限制。当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的<br>这些视图有如下特征：1.有UNIQUE等集合操作符的视图。2.有GROUP BY子句的视图。3.有诸如AVG\SUM\MAX等聚合函数的视图。 4.使用DISTINCT关键字的视图。5.连接表的视图（其中有些例外）</p>
<p>修改限制。当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的</p>
<h3 id="什么是游标？"><a href="#什么是游标？" class="headerlink" title="什么是游标？"></a>什么是游标？</h3><p>游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果，每个游标区都有一个名字。用户可以通过游标逐一获取记录并赋给主变量，交由主语言进一步处理。</p>
<h2 id="存储过程与函数"><a href="#存储过程与函数" class="headerlink" title="存储过程与函数"></a>存储过程与函数</h2><h3 id="什么是存储过程？有哪些优缺点？"><a href="#什么是存储过程？有哪些优缺点？" class="headerlink" title="什么是存储过程？有哪些优缺点？"></a>什么是存储过程？有哪些优缺点？</h3><p>存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需要创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。</p>
<p><strong>优点</strong></p>
<p>1）存储过程是预编译过的，执行效率高。</p>
<p>2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。</p>
<p>3）安全性高，执行存储过程需要有一定权限的用户。</p>
<p>4）存储过程可以重复使用，减少数据库开发人员的工作量。</p>
<p><strong>缺点</strong></p>
<p>1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。</p>
<p>2）移植问题，数据库端代码当然是与数据库相关的。但是如果是做工程型项目，基本不存在移植问题。</p>
<p>3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。</p>
<p>4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。</p>
<h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><h3 id="什么是触发器？触发器的使用场景有哪些？"><a href="#什么是触发器？触发器的使用场景有哪些？" class="headerlink" title="什么是触发器？触发器的使用场景有哪些？"></a>什么是触发器？触发器的使用场景有哪些？</h3><p>触发器是用户定义在关系表上的一类由事件驱动的特殊的存储过程。触发器是指一段代码，当触发某个事件时，自动执行这些代码。</p>
<p>使用场景</p>
<ul>
<li>可以通过数据库中的相关表实现级联更改。</li>
<li>实时监控某张表中的某个字段的更改而需要做出相应的处理。</li>
<li>例如可以生成某些业务的编号。</li>
<li>注意不要滥用，否则会造成数据库及应用程序的维护困难。</li>
<li>大家需要牢记以上基础知识点，重点是理解数据类型CHAR和VARCHAR的差异，表存储引擎InnoDB和MyISAM的区别。</li>
</ul>
<h3 id="MySQL中都有哪些触发器？"><a href="#MySQL中都有哪些触发器？" class="headerlink" title="MySQL中都有哪些触发器？"></a>MySQL中都有哪些触发器？</h3><p>在MySQL数据库中有如下六种触发器：</p>
<ul>
<li>Before Insert</li>
<li>After Insert</li>
<li>Before Update</li>
<li>After Update</li>
<li>Before Delete</li>
<li>After Delete</li>
</ul>
<h2 id="常用SQL语句"><a href="#常用SQL语句" class="headerlink" title="常用SQL语句"></a>常用SQL语句</h2><h3 id="SQL语句主要分为哪几类"><a href="#SQL语句主要分为哪几类" class="headerlink" title="SQL语句主要分为哪几类"></a>SQL语句主要分为哪几类</h3><p>数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER</p>
<p>主要为以上操作 即对逻辑结构等有操作的，其中包括表结构，视图和索引。</p>
<p>数据查询语言DQL（Data Query Language）SELECT</p>
<p>这个较为好理解 即查询操作，以select关键字。各种简单查询，连接查询等 都属于DQL。</p>
<p>数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE</p>
<p>主要为以上操作 即对数据进行操作的，对应上面所说的查询操作 DQL与DML共同构建了多数初级程序员常用的增删改查操作。而查询是较为特殊的一种 被划分到DQL中。</p>
<p>数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK</p>
<p>主要为以上操作 即对数据库安全性完整性等有操作的，可以简单的理解为权限控制等。</p>
<h3 id="超键、候选键、主键、外键分别是什么？"><a href="#超键、候选键、主键、外键分别是什么？" class="headerlink" title="超键、候选键、主键、外键分别是什么？"></a>超键、候选键、主键、外键分别是什么？</h3><ul>
<li>超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。</li>
<li>候选键：是最小超键，即没有冗余元素的超键。</li>
<li>主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。</li>
<li>外键：在一个表中存在的另一个表的主键称此表的外键。</li>
</ul>
<h3 id="SQL-约束有哪几种？"><a href="#SQL-约束有哪几种？" class="headerlink" title="SQL 约束有哪几种？"></a>SQL 约束有哪几种？</h3><p>SQL 约束有哪几种？</p>
<ul>
<li>NOT NULL: 用于控制字段的内容一定不能为空（NULL）。</li>
<li>UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。</li>
<li>PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。</li>
<li>FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。</li>
<li>CHECK: 用于控制字段的值范围。</li>
</ul>
<h3 id="六种关联查询"><a href="#六种关联查询" class="headerlink" title="六种关联查询"></a>六种关联查询</h3><ul>
<li>交叉连接（CROSS JOIN）</li>
<li>内连接（INNER JOIN）</li>
<li>外连接（LEFT JOIN/RIGHT JOIN）</li>
<li>联合查询（UNION与UNION ALL）</li>
<li>全连接（FULL JOIN）</li>
<li>交叉连接（CROSS JOIN）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM A,B(,C)或者SELECT * FROM A CROSS JOIN B (CROSS JOIN C)#没有任何关联条件，结果是笛卡尔积，结果集会很大，没有意义，很少使用内连接（INNER JOIN）SELECT * FROM A,B WHERE A.id&#x3D;B.id或者SELECT * FROM A INNER JOIN B ON A.id&#x3D;B.id多表中同时符合某种条件的数据记录的集合，INNER JOIN可以缩写为JOIN</span><br></pre></td></tr></table></figure>

<p>内连接分为三类</p>
<ul>
<li>等值连接：ON A.id=B.id</li>
<li>不等值连接：ON A.id &gt; B.id</li>
<li>自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid</li>
</ul>
<p>外连接（LEFT JOIN/RIGHT JOIN）</p>
<ul>
<li>左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN</li>
<li>右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN</li>
</ul>
<p>联合查询（UNION与UNION ALL）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM A UNION SELECT * FROM B UNION ...</span><br></pre></td></tr></table></figure>

<ul>
<li>就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并</li>
<li>如果使用UNION ALL，不会合并重复的记录行</li>
<li>效率 UNION 高于 UNION ALL</li>
</ul>
<p>全连接（FULL JOIN）</p>
<ul>
<li>MySQL不支持全连接</li>
<li>可以使用LEFT JOIN 和UNION和RIGHT JOIN联合使用</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM A LEFT JOIN B ON A.id&#x3D;B.id UNIONSELECT * FROM A RIGHT JOIN B ON A.id&#x3D;B.id</span><br></pre></td></tr></table></figure>

<p>表连接面试题</p>
<p>有2张表，1张R、1张S，R表有ABC三列，S表有CD两列，表中各有三条记录。</p>
<p>R表</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
</tr>
</thead>
<tbody><tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
</tr>
</tbody></table>
<p>S表</p>
<table>
<thead>
<tr>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody><tr>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>c4</td>
<td>d3</td>
</tr>
</tbody></table>
<ol>
<li>交叉连接(笛卡尔积):</li>
</ol>
<p>select r.<code>*</code>,s.<code>*</code> from r,s</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody><tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c4</td>
<td>d3</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c4</td>
<td>d3</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td>c4</td>
<td>d3</td>
</tr>
</tbody></table>
<p>内连接结果：<br>select r.<code>*</code>,s.<code>*</code> from r inner join s on r.c=s.c</p>
<p>select r.<code>*</code>,s.<code>*</code> from r inner join s on r.c=s.c</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody><tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
</tbody></table>
<p>左连接结果：<br>select r.<code>*</code>,s.<code>*</code> from r left join s on r.c=s.c</p>
<p>select r.<code>*</code>,s.<code>*</code> from r left join s on r.c=s.c</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody><tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>右连接结果：<br>select r.<code>*</code>,s.<code>*</code> from r right join s on r.c=s.c</p>
<p>select r.<code>*</code>,s.<code>*</code> from r right join s on r.c=s.c</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody><tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>c4</td>
<td>d3</td>
</tr>
</tbody></table>
<p>全表连接的结果（MySql不支持，Oracle支持）：<br>select r.<code>*</code>,s.<code>*</code> from r full join  s on r.c=s.c</p>
<p>select r.<code>*</code>,s.<code>*</code> from r full join  s on r.c=s.c</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody><tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>c4</td>
<td>d3</td>
</tr>
</tbody></table>
<h3 id="什么是子查询"><a href="#什么是子查询" class="headerlink" title="什么是子查询"></a>什么是子查询</h3><p>条件：一条SQL语句的查询结果做为另一条查询语句的条件或查询结果<br>嵌套：多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。<br>嵌套：多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。</p>
<h3 id="子查询的三种情况"><a href="#子查询的三种情况" class="headerlink" title="子查询的三种情况"></a>子查询的三种情况</h3><ol>
<li>子查询是单行单列的情况：结果集是一个值，父查询使用：=、 &lt;、 &gt; 等运算符</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 查询工资最高的员工是谁？ </span><br><span class="line">select  * from employee where salary&#x3D;(select max(salary) from employee);</span><br></pre></td></tr></table></figure>

<ol>
<li>子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 查询工资最高的员工是谁？ </span><br><span class="line">select  * from employee where salary&#x3D;(select max(salary) from employee);</span><br></pre></td></tr></table></figure>

<ol>
<li>子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 1) 查询出2011年以后入职的员工信息</span><br><span class="line">-- 2) 查询所有的部门信息，与上面的虚拟表中的信息比对，找出所有部门ID相等的员工。</span><br><span class="line">select * from dept d,  (select * from employee where join_date &gt; &#39;2011-1-1&#39;) e where e.dept_id &#x3D;  d.id;    </span><br><span class="line"></span><br><span class="line">-- 使用表连接：</span><br><span class="line">select d.*, e.* from  dept d inner join employee e on d.id &#x3D; e.dept_id where e.join_date &gt;  &#39;2011-1-1&#39;</span><br></pre></td></tr></table></figure>

<h3 id="mysql中-in-和-exists-区别"><a href="#mysql中-in-和-exists-区别" class="headerlink" title="mysql中 in 和 exists 区别"></a>mysql中 in 和 exists 区别</h3><p>mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。</p>
<ol>
<li>如果查询的两个表大小相当，那么用in和exists差别不大。</li>
<li>如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。</li>
<li>not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</li>
</ol>
<h3 id="varchar与char的区别"><a href="#varchar与char的区别" class="headerlink" title="varchar与char的区别"></a>varchar与char的区别</h3><p><strong>char的特点</strong></p>
<p>char表示定长字符串，长度是固定的；</p>
<p>如果插入数据的长度小于char的固定长度时，则用空格填充；</p>
<p>因为长度固定，所以存取速度要比varchar快很多，甚至能快50%，但正因为其长度固定，所以会占据多余的空间，是空间换时间的做法；</p>
<p>对于char来说，最多能存放的字符个数为255，和编码无关</p>
<p>如果插入数据的长度小于char的固定长度时，则用空格填充；</p>
<p>对于char来说，最多能存放的字符个数为255，和编码无关</p>
<p><strong>varchar的特点</strong></p>
<p>varchar表示可变长字符串，长度是可变的；</p>
<p>插入的数据是多长，就按照多长来存储；</p>
<p>varchar在存取方面与char相反，它存取慢，因为长度不固定，但正因如此，不占据多余的空间，是时间换空间的做法；</p>
<p>对于varchar来说，最多能存放的字符个数为65532</p>
<p>插入的数据是多长，就按照多长来存储；</p>
<p>对于varchar来说，最多能存放的字符个数为65532</p>
<p>总之，结合性能角度（char更快）和节省磁盘空间角度（varchar更小），具体情况还需具体来设计数据库才是妥当的做法。</p>
<h3 id="varchar-50-中50的涵义"><a href="#varchar-50-中50的涵义" class="headerlink" title="varchar(50)中50的涵义"></a>varchar(50)中50的涵义</h3><p>最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度(memory引擎也一样)。在早期 MySQL 版本中， 50 代表字节数，现在代表字符数。</p>
<h3 id="int-20-中20的涵义"><a href="#int-20-中20的涵义" class="headerlink" title="int(20)中20的涵义"></a>int(20)中20的涵义</h3><p>是指显示字符的长度。20表示最大显示宽度为20，但仍占4字节存储，存储范围不变；</p>
<p>不影响内部存储，只是影响带 zerofill 定义的 int 时，前面补多少个 0，易于报表展示</p>
<h3 id="mysql为什么这么设计"><a href="#mysql为什么这么设计" class="headerlink" title="mysql为什么这么设计"></a>mysql为什么这么设计</h3><p>对大多数应用没有意义，只是规定一些工具用来显示字符的个数；int(1)和int(20)存储和计算均一样；</p>
<h3 id="mysql中int-10-和char-10-以及varchar-10-的区别"><a href="#mysql中int-10-和char-10-以及varchar-10-的区别" class="headerlink" title="mysql中int(10)和char(10)以及varchar(10)的区别"></a>mysql中int(10)和char(10)以及varchar(10)的区别</h3><p>int(10)的10表示显示的数据的长度，不是存储数据的大小；chart(10)和varchar(10)的10表示存储数据的大小，即表示存储多少个字符。<br>int(10) 10位的数据长度 9999999999，占32个字节，int型4位<br>char(10) 10位固定字符串，不足补空格 最多10个字符<br>varchar(10) 10位可变字符串，不足补空格 最多10个字符</p>
<p>char(10)表示存储定长的10个字符，不足10个就用空格补齐，占用更多的存储空间</p>
<p>varchar(10)表示存储10个变长的字符，存储多少个就是多少个，空格也按一个字符存储，这一点是和char(10)的空格不同的，char(10)的空格表示占位不算一个字符</p>
<p>int(10) 10位的数据长度 9999999999，占32个字节，int型4位<br>char(10) 10位固定字符串，不足补空格 最多10个字符<br>varchar(10) 10位可变字符串，不足补空格 最多10个字符</p>
<p>varchar(10)表示存储10个变长的字符，存储多少个就是多少个，空格也按一个字符存储，这一点是和char(10)的空格不同的，char(10)的空格表示占位不算一个字符</p>
<h3 id="FLOAT和DOUBLE的区别是什么？"><a href="#FLOAT和DOUBLE的区别是什么？" class="headerlink" title="FLOAT和DOUBLE的区别是什么？"></a>FLOAT和DOUBLE的区别是什么？</h3><ul>
<li>FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。</li>
<li>DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节。</li>
</ul>
<h3 id="drop、delete与truncate的区别"><a href="#drop、delete与truncate的区别" class="headerlink" title="drop、delete与truncate的区别"></a>drop、delete与truncate的区别</h3><p>三者都表示删除，但是三者有一些差别：</p>
<table>
<thead>
<tr>
<th></th>
<th>Delete</th>
<th>Truncate</th>
<th>Drop</th>
</tr>
</thead>
<tbody><tr>
<td>类型</td>
<td>属于DML</td>
<td>属于DDL</td>
<td>属于DDL</td>
</tr>
<tr>
<td>回滚</td>
<td>可回滚</td>
<td>不可回滚</td>
<td>不可回滚</td>
</tr>
<tr>
<td>删除内容</td>
<td>表结构还在，删除表的全部或者一部分数据行</td>
<td>表结构还在，删除表中的所有数据</td>
<td>从数据库中删除表，所有的数据行，索引和权限也会被删除</td>
</tr>
<tr>
<td>删除速度</td>
<td>删除速度慢，需要逐行删除</td>
<td>删除速度快</td>
<td>删除速度最快</td>
</tr>
</tbody></table>
<p>因此，在不再需要一张表的时候，用drop；在想删除部分数据行时候，用delete；在保留表而删除所有数据的时候用truncate。</p>
<h3 id="UNION与UNION-ALL的区别？"><a href="#UNION与UNION-ALL的区别？" class="headerlink" title="UNION与UNION ALL的区别？"></a>UNION与UNION ALL的区别？</h3><ul>
<li>如果使用UNION ALL，不会合并重复的记录行</li>
<li>效率 UNION 高于 UNION ALL</li>
</ul>
<h2 id="SQL优化"><a href="#SQL优化" class="headerlink" title="SQL优化"></a>SQL优化</h2><h3 id="如何定位及优化SQL语句的性能问题？创建的索引有没有被使用到-或者说怎么才可以知道这条语句运行很慢的原因？"><a href="#如何定位及优化SQL语句的性能问题？创建的索引有没有被使用到-或者说怎么才可以知道这条语句运行很慢的原因？" class="headerlink" title="如何定位及优化SQL语句的性能问题？创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因？"></a>如何定位及优化SQL语句的性能问题？创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因？</h3><p>对于低性能的SQL语句的定位，最重要也是最有效的方法就是使用执行计划，MySQL提供了explain命令来查看语句的执行计划。 我们知道，不管是哪种数据库，或者是哪种数据库引擎，在对一条SQL语句进行执行的过程中都会做很多相关的优化，<strong>对于查询语句，最重要的优化方式就是使用索引</strong>。 而<strong>执行计划，就是显示数据库引擎对于SQL语句的执行的详细情况，其中包含了是否使用索引，使用什么索引，使用的索引的相关信息等</strong>。</p>
<img data-src="https://img-blog.csdnimg.cn/20200310171131582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RoaW5rV29u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">

<p>概要描述：</p>
<ul>
<li><p>id:选择标识符</p>
</li>
<li><p>select_type:表示查询的类型。</p>
</li>
<li><p>table:输出结果集的表</p>
</li>
<li><p>partitions:匹配的分区</p>
</li>
<li><p>type:表示表的连接类型</p>
</li>
<li><p>possible_keys:表示查询时，可能使用的索引</p>
</li>
<li><p>key:表示实际使用的索引</p>
</li>
<li><p>key_len:索引字段的长度</p>
</li>
<li><p>ref:列与索引的比较</p>
</li>
<li><p>rows:扫描出的行数(估算的行数)</p>
</li>
<li><p>filtered:按表条件过滤的行百分比</p>
</li>
<li><p>Extra:执行情况的描述和说明</p>
</li>
<li><p>id: 执行计划包含的信息 <strong>id</strong> 有一组数字组成。表示一个查询中各个子查询的执行顺序;</p>
</li>
<li><p>id相同执行顺序由上至下。</p>
</li>
<li><p>id不同，id值越大优先级越高，越先被执行。</p>
</li>
<li><p>id为null时表示一个结果集，不需要使用它查询，常出现在包含union等查询语句中。</p>
</li>
<li><p><strong>select_type</strong> 每个子查询的查询类型，一些常见的查询类型。</p>
<table>
<thead>
<tr>
<th>id</th>
<th>select_type</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>SIMPLE</td>
<td>简单SELECT，不包含任何子查询或union等查询</td>
</tr>
<tr>
<td>2</td>
<td>PRIMARY</td>
<td>包含子查询最外层查询就显示为 PRIMARY</td>
</tr>
<tr>
<td>3</td>
<td>SUBQUERY</td>
<td>子查询中的第一个SELECT，结果不依赖于外部查询,在select或 where字句中包含的查询</td>
</tr>
<tr>
<td>4</td>
<td>DERIVED</td>
<td>派生表的SELECT, FROM子句的子查询</td>
</tr>
<tr>
<td>5</td>
<td>UNION</td>
<td>出现在union后的查询语句中</td>
</tr>
<tr>
<td>6</td>
<td>UNION RESULT</td>
<td>从UNION中获取结果集，例如上文的第三个例子</td>
</tr>
<tr>
<td>7</td>
<td>DEPENDENT UNION</td>
<td>UNION中的第二个或后面的SELECT语句，取决于外面的查询</td>
</tr>
<tr>
<td>8</td>
<td>DEPENDENT SUBQUERY</td>
<td>子查询中的第一个SELECT，依赖于外部查询</td>
</tr>
<tr>
<td>9</td>
<td>UNCACHEABLE SUBQUERY</td>
<td>一个子查询的结果不能被缓存，必须重新评估外链接的第一行</td>
</tr>
</tbody></table>
</li>
<li><p><strong>table</strong> 查询的数据表，当从衍生表中查数据时会显示 x 表示对应的执行计划id <strong>partitions</strong> 表分区、表创建的时候可以指定通过那个列进行表分区。 举个例子：</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tmp (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">int</span> <span class="keyword">unsigned</span> <span class="keyword">not</span> <span class="literal">null</span> AUTO_INCREMENT,</span><br><span class="line">    <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">255</span>),</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (<span class="keyword">id</span>)</span><br><span class="line">) <span class="keyword">engine</span> = <span class="keyword">innodb</span></span><br><span class="line"><span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">key</span> (<span class="keyword">id</span>) <span class="keyword">partitions</span> <span class="number">5</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>type</strong>(非常重要，可以看到有没有走索引) 对表访问方式，表示MySQL在表中找到所需行的方式，又称“访问类型”。<br>常用的类型有： ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好）</p>
<ul>
<li>ALL   扫描全表数据 Full Table Scan， MySQL将遍历全表以找到匹配的行</li>
<li>index 遍历索引  Full Index Scan，index与ALL区别为index类型只遍历索引树</li>
<li>range 索引范围查找 只检索给定范围的行，使用一个索引来选择行</li>
<li>ref   使用非唯一索引查找数据,表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</li>
<li>eq_ref 在join查询中使用PRIMARY KEY or UNIQUE NOT NULL索引关联。类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件</li>
<li>const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const类型的特例，当查询的表只有一行的情况下，使用system</li>
<li>NULL: MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。</li>
<li>index_subquery 在子查询中使用 ref</li>
<li>unique_subquery 在子查询中使用 eq_ref</li>
<li>ref_or_null 对Null进行索引的优化的 ref</li>
<li>fulltext 使用全文索引</li>
</ul>
</li>
<li><p><strong>possible_keys</strong> 可能使用的索引，注意不一定会使用。查询涉及到的字段上若存在索引，则该索引将被列出来。当该列为 NULL时就要考虑当前的SQL是否需要优化了。</p>
</li>
</ul>
<p>该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。<br>如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询</p>
<ul>
<li><strong>key</strong> 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。<br>如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。</li>
</ul>
<p>查询中若使用了覆盖索引(覆盖索引：索引的数据覆盖了需要查询的所有数据)，则该索引仅出现在key列表中</p>
<ul>
<li><strong>key_length</strong> 索引长度<br>表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的）</li>
</ul>
<p>不损失精确性的情况下，长度越短越好 </p>
<ul>
<li><p><strong>ref</strong> 列与索引的比较,表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</p>
</li>
<li><p><strong>rows</strong> 估算出结果集行数，表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数</p>
</li>
<li><p><strong>extra</strong> 的信息非常丰富，常见的有：</p>
<ol>
<li>Using index 使用覆盖索引</li>
<li>Using where 使用了用where子句来过滤结果集 </li>
<li>Using filesort 当Query中包含 order by 操作，而且无法利用索引完成的排序操作称为“文件排序”，使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。</li>
<li>Using temporary 使用了临时表 表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by 、order bysql,优化的目标可以参考阿里开发手册</li>
<li>Using join buffer：强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。</li>
<li>Impossible where：这个值强调了where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。</li>
<li>Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行</li>
<li>No tables used：Query语句中使用from dual 或不含任何from子句</li>
</ol>
</li>
</ul>
<p>【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是const最好。<br>说明： </p>
<ul>
<li>1） const 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。 </li>
<li>2） ref 指的是使用普通的索引（normal index）。 </li>
<li>3） range 对索引进行范围检索。<br>反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range还低，与全表扫描是小巫见大巫。</li>
</ul>
<p><a href="https://www.cnblogs.com/tufujie/p/9413852.html" target="_blank" rel="noopener">https://www.cnblogs.com/tufujie/p/9413852.html</a></p>
<h3 id="SQL的生命周期？"><a href="#SQL的生命周期？" class="headerlink" title="SQL的生命周期？"></a>SQL的生命周期？</h3><ol>
<li><p>应用服务器与数据库服务器建立一个连接</p>
</li>
<li><p>数据库进程拿到请求sql</p>
</li>
<li><p>解析并生成执行计划，执行</p>
</li>
<li><p>读取数据到内存并进行逻辑处理</p>
</li>
<li><p>通过步骤一的连接，发送结果到客户端</p>
</li>
<li><p>关掉连接，释放资源</p>
<img data-src="https://img-blog.csdnimg.cn/20200310170936478.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RoaW5rV29u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">

</li>
</ol>
<h3 id="大表数据查询，怎么优化"><a href="#大表数据查询，怎么优化" class="headerlink" title="大表数据查询，怎么优化"></a>大表数据查询，怎么优化</h3><ol>
<li>优化shema、sql语句+索引；</li>
<li>第二加缓存，memcached, redis；</li>
<li>主从复制，读写分离；</li>
<li>垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；</li>
<li>水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；</li>
</ol>
<h3 id="超大分页怎么处理？"><a href="#超大分页怎么处理？" class="headerlink" title="超大分页怎么处理？"></a>超大分页怎么处理？</h3><p>超大的分页一般从两个方向上来解决.</p>
<ul>
<li>数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于<code>select * from table where age &gt; 20 limit 1000000,10</code>这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为<code>select * from table where id in (select id from table where age &gt; 20 limit 1000000,10)</code>.这样虽然也load了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以<code>select * from table where id &gt; 1000000 limit 10</code>,效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据.</li>
<li>从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击.</li>
</ul>
<p>解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可.</p>
<p>在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种.</p>
<div class="note primary">
            <p>【推荐】利用延迟关联或者子查询优化超多分页场景。 </p><p>说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 </p><p>正例：先快速定位需要获取的id段，然后再关联： </p><p>SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id</p>
          </div>


<h3 id="mysql-分页"><a href="#mysql-分页" class="headerlink" title="mysql 分页"></a>mysql 分页</h3><p>LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0(而不是 1)</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15</span><br></pre></td></tr></table></figure>

<p>为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last.</span><br></pre></td></tr></table></figure>

<p>如果只给定一个参数，它表示返回最大的记录行数目：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM table LIMIT 5; //检索前 5 个记录行</span><br></pre></td></tr></table></figure>

<p>换句话说，LIMIT n 等价于 LIMIT 0,n。</p>
<h3 id="慢查询日志"><a href="#慢查询日志" class="headerlink" title="慢查询日志"></a>慢查询日志</h3><p>用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。</p>
<p>开启慢查询日志</p>
<p>配置项：<code>slow_query_log</code></p>
<p>可以使用<code>show variables like ‘slov_query_log’</code>查看是否开启，如果状态值为<code>OFF</code>，可以使用<code>set GLOBAL slow_query_log = on</code>来开启，它会在<code>datadir</code>下产生一个<code>xxx-slow.log</code>的文件。</p>
<p>设置临界时间</p>
<p>配置项：<code>long_query_time</code></p>
<p>查看：<code>show VARIABLES like &#39;long_query_time&#39;</code>，单位秒</p>
<p>设置：<code>set long_query_time=0.5</code></p>
<p>实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉</p>
<p>查看日志，一旦SQL超过了我们设置的临界时间就会被记录到<code>xxx-slow.log</code>中</p>
<h3 id="关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？"><a href="#关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？" class="headerlink" title="关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？"></a>关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？</h3><p>在业务系统中，除了使用主键进行的查询，其他的我都会在测试库上测试其耗时，慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。</p>
<p>慢查询的优化首先要搞明白慢的原因是什么？ 是查询条件没有命中索引？是load了不需要的数据列？还是数据量太大？</p>
<p>所以优化也是针对这三个方向来的，</p>
<ul>
<li>首先分析语句，看看是否load了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。</li>
<li>分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。</li>
<li>如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。</li>
</ul>
<h3 id="为什么要尽量设定一个主键？"><a href="#为什么要尽量设定一个主键？" class="headerlink" title="为什么要尽量设定一个主键？"></a>为什么要尽量设定一个主键？</h3><p>主键是数据库确保数据行在整张表唯一性的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。</p>
<h3 id="主键使用自增ID还是UUID？"><a href="#主键使用自增ID还是UUID？" class="headerlink" title="主键使用自增ID还是UUID？"></a>主键使用自增ID还是UUID？</h3><p>推荐使用自增ID，不要使用UUID。</p>
<p>因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。</p>
<p>总之，在数据量大一些的情况下，用自增主键性能会好一些。</p>
<p>关于主键是聚簇索引，如果没有主键，InnoDB会选择一个唯一键来作为聚簇索引，如果没有唯一键，会生成一个隐式的主键。</p>
<h3 id="段为什么要求定义为not-null？"><a href="#段为什么要求定义为not-null？" class="headerlink" title="段为什么要求定义为not null？"></a>段为什么要求定义为not null？</h3><p>null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。</p>
<h3 id="如果要存储用户的密码散列，应该使用什么字段进行存储？"><a href="#如果要存储用户的密码散列，应该使用什么字段进行存储？" class="headerlink" title="如果要存储用户的密码散列，应该使用什么字段进行存储？"></a>如果要存储用户的密码散列，应该使用什么字段进行存储？</h3><p>密码散列，盐，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。</p>
<h3 id="优化查询过程中的数据访问"><a href="#优化查询过程中的数据访问" class="headerlink" title="优化查询过程中的数据访问"></a>优化查询过程中的数据访问</h3><ul>
<li>访问数据太多导致查询性能下降</li>
<li>确定应用程序是否在检索大量超过需要的数据，可能是太多行或列</li>
<li>确认MySQL服务器是否在分析大量不必要的数据行</li>
<li>避免犯如下SQL语句错误</li>
<li>查询不需要的数据。解决办法：使用limit解决</li>
<li>多表关联返回全部列。解决办法：指定列名</li>
<li>总是返回全部列。解决办法：避免使用SELECT *</li>
<li>重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存</li>
<li>是否在扫描额外的记录。解决办法：</li>
<li>使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化：</li>
<li>使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。</li>
<li>改变数据库和表的结构，修改数据表范式</li>
<li>重写SQL语句，让优化器可以以更优的方式执行查询。</li>
</ul>
<h3 id="优化长难的查询语句"><a href="#优化长难的查询语句" class="headerlink" title="优化长难的查询语句"></a>优化长难的查询语句</h3><ul>
<li>一个复杂查询还是多个简单查询</li>
<li>MySQL内部每秒能扫描内存中上百万行数据，相比之下，响应数据给客户端就要慢得多</li>
<li>使用尽可能小的查询是好的，但是有时将一个大的查询分解为多个小的查询是很有必要的。</li>
<li>切分查询</li>
<li>将一个大的查询分为多个小的相同的查询</li>
<li>一次性删除1000万的数据要比一次删除1万，暂停一会的方案更加损耗服务器开销。</li>
<li>分解关联查询，让缓存的效率更高。</li>
<li>执行单个查询可以减少锁的竞争。</li>
<li>在应用层做关联更容易对数据库进行拆分。</li>
<li>查询效率会有大幅提升。</li>
<li>较少冗余记录的查询。</li>
</ul>
<h3 id="优化特定类型的查询语句"><a href="#优化特定类型的查询语句" class="headerlink" title="优化特定类型的查询语句"></a>优化特定类型的查询语句</h3><ul>
<li>count(*)会忽略所有的列，直接统计所有列数，不要使用count(列名)</li>
<li>MyISAM中，没有任何where条件的count(*)非常快。</li>
<li>当有where条件时，MyISAM的count统计不一定比其它引擎快。</li>
<li>可以使用explain查询近似值，用近似值替代count(*)</li>
<li>增加汇总表</li>
<li>使用缓存</li>
</ul>
<h3 id="优化关联查询"><a href="#优化关联查询" class="headerlink" title="优化关联查询"></a>优化关联查询</h3><ul>
<li>确定ON或者USING子句中是否有索引。</li>
<li>确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。</li>
</ul>
<h3 id="优化子查询"><a href="#优化子查询" class="headerlink" title="优化子查询"></a>优化子查询</h3><ul>
<li>用关联查询替代</li>
<li>优化GROUP BY和DISTINCT</li>
<li>这两种查询据可以使用索引来优化，是最有效的优化方法</li>
<li>关联查询中，使用标识列分组的效率更高</li>
<li>如果不需要ORDER BY，进行GROUP BY时加ORDER BY NULL，MySQL不会再进行文件排序。</li>
<li>WITH ROLLUP超级聚合，可以挪到应用程序处理</li>
</ul>
<h3 id="优化LIMIT分页"><a href="#优化LIMIT分页" class="headerlink" title="优化LIMIT分页"></a>优化LIMIT分页</h3><ul>
<li>LIMIT偏移量大的时候，查询效率较低</li>
<li>可以记录上次查询的最大ID，下次查询时直接根据该ID来查询</li>
</ul>
<h3 id="优化UNION查询"><a href="#优化UNION查询" class="headerlink" title="优化UNION查询"></a>优化UNION查询</h3><ul>
<li>UNION ALL的效率高于UNION</li>
</ul>
<h3 id="优化WHERE子句"><a href="#优化WHERE子句" class="headerlink" title="优化WHERE子句"></a>优化WHERE子句</h3><p>解题方法</p>
<p>对于此类考题，先说明如何定位低效SQL语句，然后根据SQL语句可能低效的原因做排查，先从索引着手，如果索引没有问题，考虑以上几个方面，数据访问的问题，长难查询句的问题还是一些特定类型优化的问题，逐一回答。</p>
<p>SQL语句优化的一些方法？</p>
<ul>
<li>1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。</li>
<li>2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">num</span> <span class="keyword">is</span> <span class="literal">null</span></span><br><span class="line"><span class="comment">-- 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">num</span>=</span><br></pre></td></tr></table></figure>

<ul>
<li>3.应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则引擎将放弃使用索引而进行全表扫描。</li>
<li>4.应尽量避免在 where 子句中使用or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">num</span>=<span class="number">10</span> <span class="keyword">or</span> <span class="keyword">num</span>=<span class="number">20</span></span><br><span class="line"><span class="comment">-- 可以这样查询：</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">num</span>=<span class="number">10</span> <span class="keyword">union</span> <span class="keyword">all</span> <span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">num</span>=<span class="number">20</span></span><br></pre></td></tr></table></figure>

<ul>
<li>5.in 和 not in 也要慎用，否则会导致全表扫描，如：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">num</span> <span class="keyword">in</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>) </span><br><span class="line"><span class="comment">-- 对于连续的数值，能用 between 就不要用 in 了：</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">num</span> <span class="keyword">between</span> <span class="number">1</span> <span class="keyword">and</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<ul>
<li>6.下面的查询也将导致全表扫描：select id from t where name like ‘%李%’若要提高效率，可以考虑全文检索。</li>
<li>7.如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">num</span>=@<span class="keyword">num</span></span><br><span class="line"><span class="comment">-- 可以改为强制查询使用索引：</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> t <span class="keyword">with</span>(<span class="keyword">index</span>(索引名)) <span class="keyword">where</span> <span class="keyword">num</span>=@<span class="keyword">num</span></span><br></pre></td></tr></table></figure>

<ul>
<li>8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select id from t where num&#x2F;2&#x3D;100</span><br><span class="line">-- 应改为:</span><br><span class="line">select id from t where num&#x3D;100*2</span><br></pre></td></tr></table></figure>

<ul>
<li>9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select id from t where substring(name,1,3)&#x3D;’abc’</span><br><span class="line">-- name以abc开头的id应改为:</span><br><span class="line">select id from t where name like ‘abc%’</span><br></pre></td></tr></table></figure>

<ul>
<li>10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。</li>
</ul>
<h2 id="数据库优化"><a href="#数据库优化" class="headerlink" title="数据库优化"></a>数据库优化</h2><h3 id="为什么要优化"><a href="#为什么要优化" class="headerlink" title="为什么要优化"></a>为什么要优化</h3><ul>
<li>系统的吞吐量瓶颈往往出现在数据库的访问速度上</li>
<li>随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢</li>
<li>数据是存放在磁盘上的，读写速度无法和内存相比</li>
</ul>
<p>优化原则：减少系统瓶颈，减少资源占用，增加系统的反应速度。</p>
<h3 id="数据库结构优化"><a href="#数据库结构优化" class="headerlink" title="数据库结构优化"></a>数据库结构优化</h3><p>一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。</p>
<p>需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。</p>
<p><strong>将字段很多的表分解成多个表</strong></p>
<p>对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。</p>
<p>因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。</p>
<p><strong>增加中间表</strong></p>
<p>对于需要经常联合查询的表，可以建立中间表以提高查询效率。</p>
<p>通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。</p>
<p><strong>增加冗余字段</strong></p>
<p>设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。</p>
<p>表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。</p>
<p><strong>注意：</strong></p>
<p><strong>冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数据不一致的问题。</strong></p>
<h3 id="MySQL数据库cpu飙升到500-的话他怎么处理？"><a href="#MySQL数据库cpu飙升到500-的话他怎么处理？" class="headerlink" title="MySQL数据库cpu飙升到500%的话他怎么处理？"></a>MySQL数据库cpu飙升到500%的话他怎么处理？</h3><p>当 cpu 飙升到 500%时，先用操作系统命令 top 命令观察是不是 mysqld 占用导致的，如果不是，找出占用高的进程，并进行相关处理。</p>
<p>如果是 mysqld 造成的， show processlist，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。</p>
<p>一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。</p>
<p>也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等</p>
<h3 id="大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？"><a href="#大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？" class="headerlink" title="大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？"></a>大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？</h3><p>当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：</p>
<ol>
<li><strong>限定数据的范围：</strong> 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。；</li>
<li><strong>读/写分离：</strong> 经典的数据库拆分方案，主库负责写，从库负责读；</li>
<li><strong>缓存：</strong> 使用MySQL的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存；</li>
</ol>
<p>还有就是通过分库分表的方式进行优化，主要有垂直分表和水平分表</p>
<p><strong>垂直分区：</strong></p>
<ul>
<li><p><strong>根据数据库里面数据表的相关性进行拆分。</strong> 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。</p>
</li>
<li><p><strong>简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。</strong> 如下图所示，这样来说大家应该就更容易理解了。</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC82LzE2LzE2NDA4NDM1NGJhMmUwZmQ?x-oss-process=image/format,png" alt="img">
</li>
<li><p><strong>垂直拆分的优点：</strong> 可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。</p>
</li>
<li><p><strong>垂直拆分的缺点：</strong> 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；</p>
</li>
</ul>
<p>垂直分表</p>
<ul>
<li><p>把主键和一些列放在一个表，然后把主键和另外的列放在另一个表中</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy90dVNhS2M2U2ZQcjh0NFBaVVFJVUszVHl0aWF3T0VRa2dFZnBCTm4xZkNtdEVhMkRaNTlISFNSaWN2SEIzeU43Yk5LY1hkc3NWZGFNb25TOEFKanY5cFdBLzY0MA?x-oss-process=image/format,png" alt="img">
</li>
<li><p>适用场景</p>
</li>
</ul>
<ol>
<li>如果一个表中某些列常用，另外一些列不常用</li>
<li>可以使数据行变小，一个数据页能存储更多数据，查询时减少I/O次数<br>缺点:</li>
<li>有些分表的策略基于应用层的逻辑算法，一旦逻辑算法改变，整个分表逻辑都会改变，扩展性较差</li>
<li>对于应用层来说，逻辑算法增加开发成本</li>
<li>管理冗余列，查询所有数据需要join操作</li>
</ol>
<p><strong>水平分区：</strong></p>
<ul>
<li><strong>保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。</strong><br>水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC82LzE2LzE2NDA4NGI3ZTllNDIzZTM?x-oss-process=image/format,png" alt="数据库水平拆分">

</li>
</ul>
<p>水品拆分可以支持非常大的数据量。需要注意的一点是:分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 <strong>水平拆分最好分库</strong> 。<br>水平拆分能够 <strong>支持非常大的数据量存储，应用端改造也少</strong>，但 <strong>分片事务难以解决</strong> ，跨界点Join性能较差，逻辑复杂。<br>《Java工程师修炼之道》的作者推荐 <strong>尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度</strong> ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。</p>
<p>水平分表：<br>表很大，分割后可以降低在查询时需要读的数据和索引的页数，同时也降低了索引的层数，提高查询次数<br><img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy90dVNhS2M2U2ZQcjh0NFBaVVFJVUszVHl0aWF3T0VRa2dkQVpyU1Y3M2liMWZkRENYS2M3QUd6Wmhid3FjS0ZVWkpGWThwMFZkVXRPM3JNYzZ2eDFBdzVBLzY0MA?x-oss-process=image/format,png" alt="img"></p>
<p>适用场景</p>
<ol>
<li>表中的数据本身就有独立性，例如表中分表记录各个地区的数据或者不同时期的数据，特别是有些数据常用，有些不常用。</li>
<li>需要把数据存放在多个介质上。</li>
</ol>
<p>水平切分的缺点</p>
<ol>
<li>给应用增加复杂度，通常查询时需要多个表名，查询所有数据都需UNION操作</li>
<li>在许多数据库应用中，这种复杂度会超过它带来的优点，查询时会增加读一个索引层的磁盘次数</li>
</ol>
<p><strong>下面补充一下数据库分片的两种常见方案：</strong></p>
<ol>
<li><strong>客户端代理：</strong> <strong>分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。</strong> 当当网的 <strong>Sharding-JDBC</strong> 、阿里的TDDL是两种比较常用的实现。</li>
<li><strong>中间件代理：</strong> <strong>在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。</strong> 我们现在谈的 <strong>Mycat</strong> 、360的Atlas、网易的DDB等等都是这种架构的实现。</li>
</ol>
<p><strong>根据数据库里面数据表的相关性进行拆分。</strong> 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC82LzE2LzE2NDA4NDM1NGJhMmUwZmQ?x-oss-process=image/format,png" alt="img">

<p><strong>垂直拆分的缺点：</strong> 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；</p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy90dVNhS2M2U2ZQcjh0NFBaVVFJVUszVHl0aWF3T0VRa2dFZnBCTm4xZkNtdEVhMkRaNTlISFNSaWN2SEIzeU43Yk5LY1hkc3NWZGFNb25TOEFKanY5cFdBLzY0MA?x-oss-process=image/format,png" alt="img">

<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><p><strong>保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。</strong></p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC82LzE2LzE2NDA4NGI3ZTllNDIzZTM?x-oss-process=image/format,png" alt="数据库水平拆分">

<p>水平拆分能够 <strong>支持非常大的数据量存储，应用端改造也少</strong>，但 <strong>分片事务难以解决</strong> ，跨界点Join性能较差，逻辑复杂。</p>
<h4 id="水平分表："><a href="#水平分表：" class="headerlink" title="水平分表："></a>水平分表：</h4><p>表很大，分割后可以降低在查询时需要读的数据和索引的页数，同时也降低了索引的层数，提高查询次数</p>
<h5 id="水平切分的缺点"><a href="#水平切分的缺点" class="headerlink" title="水平切分的缺点"></a>水平切分的缺点</h5><p><strong>下面补充一下数据库分片的两种常见方案：</strong></p>
<p><strong>分库分表后面临的问题</strong></p>
<p><strong>事务支持</strong> 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。</p>
<p><strong>跨库join</strong><br>只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 分库分表方案产品</p>
<p><strong>跨节点的count,order by,group by以及聚合函数问题</strong> 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。</p>
<p><strong>数据迁移，容量规划，扩容等问题</strong> 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。</p>
<p><strong>ID问题</strong></p>
<p>一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略</p>
<p><strong>跨库join</strong></p>
<p><strong>跨节点的count,order by,group by以及聚合函数问题</strong> 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。</p>
<p><strong>ID问题</strong></p>
<p><strong>UUID</strong> 使用UUID作主键是最简单的方案，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 <strong>Twitter的分布式自增ID算法Snowflake</strong> 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。</p>
<p>跨分片的排序分页<br>般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：<br><img data-src="https://img-blog.csdnimg.cn/20200310170753848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RoaW5rV29u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：</p>
<h3 id="MySQL的复制原理以及流程"><a href="#MySQL的复制原理以及流程" class="headerlink" title="MySQL的复制原理以及流程"></a>MySQL的复制原理以及流程</h3><p>主从复制：将主数据库中的DDL和DML操作通过二进制日志（BINLOG）传输到从数据库上，然后将这些日志重新执行（重做）；从而使得从数据库的数据与主数据库保持一致。</p>
<p><strong>主从复制的作用</strong></p>
<ol>
<li>主数据库出现问题，可以切换到从数据库。</li>
<li>可以进行数据库层面的读写分离。</li>
<li>可以在从数据库上进行日常备份。</li>
</ol>
<p><strong>MySQL主从复制解决的问题</strong></p>
<ul>
<li>数据分布：随意开始或停止复制，并在不同地理位置分布数据备份</li>
<li>负载均衡：降低单个服务器的压力</li>
<li>高可用和故障切换：帮助应用程序避免单点失败</li>
<li>升级测试：可以用更高版本的MySQL作为从库</li>
</ul>
<p><strong>MySQL主从复制工作原理</strong></p>
<ul>
<li>在主库上把数据更高记录到二进制日志</li>
<li>从库将主库的日志复制到自己的中继日志</li>
<li>从库读取中继日志的事件，将其重放到从库数据中</li>
</ul>
<p><strong>基本原理流程，3个线程以及之间的关联</strong></p>
<p><strong>主</strong>：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；</p>
<p><strong>从</strong>：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中；</p>
<p><strong>从</strong>：sql执行线程——执行relay log中的语句；</p>
<p><strong>复制过程</strong></p>
<img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzIxLzE2NWZiNjgzMjIyMDViMmU?x-oss-process=image/format,png" alt="img">

<p>Binary log：主数据库的二进制日志</p>
<p>Relay log：从服务器的中继日志</p>
<p>第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。</p>
<p>第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。</p>
<p>第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。</p>
<h3 id="读写分离有哪些解决方案？"><a href="#读写分离有哪些解决方案？" class="headerlink" title="读写分离有哪些解决方案？"></a>读写分离有哪些解决方案？</h3><p>读写分离是依赖于主从复制，而主从复制又是为读写分离服务的。因为主从复制要求<code>slave</code>不能写只能读（如果对<code>slave</code>执行写操作，那么<code>show slave status</code>将会呈现<code>Slave_SQL_Running=NO</code>，此时你需要按照前面提到的手动同步一下<code>slave</code>）。</p>
<p><strong>方案一</strong></p>
<p>使用mysql-proxy代理</p>
<p>优点：直接实现读写分离和负载均衡，不用修改代码，master和slave用一样的帐号，mysql官方不建议实际生产中使用</p>
<p>缺点：降低性能， 不支持事务</p>
<p><strong>方案二</strong></p>
<p>使用AbstractRoutingDataSource+aop+annotation在dao层决定数据源。<br>如果采用了mybatis， 可以将读写分离放在ORM层，比如mybatis可以通过mybatis plugin拦截sql语句，所有的insert/update/delete都访问master库，所有的select 都访问salve库，这样对于dao层都是透明。  plugin实现时可以通过注解或者分析语句是读写方法来选定主从库。不过这样依然有一个问题， 也就是不支持事务， 所以我们还需要重写一下DataSourceTransactionManager， 将read-only的事务扔进读库， 其余的有读有写的扔进写库。</p>
<p><strong>方案三</strong></p>
<p>使用AbstractRoutingDataSource+aop+annotation在service层决定数据源，可以支持事务.</p>
<p>缺点：类内部方法通过this.xx()方式相互调用时，aop不会进行拦截，需进行特殊处理。</p>
<h3 id="备份计划，mysqldump以及xtranbackup的实现原理"><a href="#备份计划，mysqldump以及xtranbackup的实现原理" class="headerlink" title="备份计划，mysqldump以及xtranbackup的实现原理"></a>备份计划，mysqldump以及xtranbackup的实现原理</h3><p><strong>(1)备份计划</strong></p>
<p>视库的大小来定，一般来说 100G 内的库，可以考虑使用 mysqldump 来做，因为 mysqldump更加轻巧灵活，备份时间选在业务低峰期，可以每天进行都进行全量备份(mysqldump 备份出来的文件比较小，压缩之后更小)。</p>
<p>100G 以上的库，可以考虑用 xtranbackup 来做，备份速度明显要比 mysqldump 要快。一般是选择一周一个全备，其余每天进行增量备份，备份时间为业务低峰期。</p>
<p><strong>(2)备份恢复时间</strong></p>
<p>物理备份恢复快，逻辑备份恢复慢</p>
<p>这里跟机器，尤其是硬盘的速率有关系，以下列举几个仅供参考</p>
<p>20G的2分钟（mysqldump）</p>
<p>80G的30分钟(mysqldump)</p>
<p>111G的30分钟（mysqldump)</p>
<p>288G的3小时（xtra)</p>
<p>3T的4小时（xtra)</p>
<p>逻辑导入时间一般是备份时间的5倍以上</p>
<p><strong>(3)备份恢复失败如何处理</strong></p>
<p>首先在恢复之前就应该做足准备工作，避免恢复的时候出错。比如说备份之后的有效性检查、权限检查、空间检查等。如果万一报错，再根据报错的提示来进行相应的调整。</p>
<p><strong>(4)mysqldump和xtrabackup实现原理</strong></p>
<p>mysqldump</p>
<p>mysqldump 属于逻辑备份。加入–single-transaction 选项可以进行一致性备份。后台进程会先设置 session 的事务隔离级别为 RR(SET SESSION TRANSACTION ISOLATION LEVELREPEATABLE READ)，之后显式开启一个事务(START TRANSACTION /*!40100 WITH CONSISTENTSNAPSHOT */)，这样就保证了该事务里读到的数据都是事务事务时候的快照。之后再把表的数据读取出来。如果加上–master-data=1 的话，在刚开始的时候还会加一个数据库的读锁(FLUSH TABLES WITH READ LOCK),等开启事务后，再记录下数据库此时 binlog 的位置(showmaster status)，马上解锁，再读取表的数据。等所有的数据都已经导完，就可以结束事务</p>
<p>Xtrabackup:</p>
<p>xtrabackup 属于物理备份，直接拷贝表空间文件，同时不断扫描产生的 redo 日志并保存下来。最后完成 innodb 的备份后，会做一个 flush engine logs 的操作(老版本在有 bug，在5.6 上不做此操作会丢数据)，确保所有的 redo log 都已经落盘(涉及到事务的两阶段提交</p>
<p>概念，因为 xtrabackup 并不拷贝 binlog，所以必须保证所有的 redo log 都落盘，否则可能会丢最后一组提交事务的数据)。这个时间点就是 innodb 完成备份的时间点，数据文件虽然不是一致性的，但是有这段时间的 redo 就可以让数据文件达到一致性(恢复的时候做的事</p>
<p>情)。然后还需要 flush tables with read lock，把 myisam 等其他引擎的表给备份出来，备份完后解锁。这样就做到了完美的热备。</p>
<h3 id="数据表损坏的修复方式有哪些？"><a href="#数据表损坏的修复方式有哪些？" class="headerlink" title="数据表损坏的修复方式有哪些？"></a>数据表损坏的修复方式有哪些？</h3><p>使用 myisamchk 来修复，具体步骤：</p>
<ul>
<li>1）修复前将mysql服务停止。</li>
<li>2）打开命令行方式，然后进入到mysql的/bin目录。</li>
<li>3）执行myisamchk –recover 数据库所在路径/*.MYI</li>
</ul>
<p>使用repair table 或者 OPTIMIZE table命令来修复，REPAIR TABLE table_name 修复表 OPTIMIZE TABLE table_name 优化表 REPAIR TABLE 用于修复被破坏的表。 OPTIMIZE TABLE 用于回收闲置的数据库空间，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用了OPTIMIZE TABLE命令后这些空间将被回收，并且对磁盘上的数据行进行重排（注意：是磁盘上，而非数据库）</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
