<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>千寻</title>
  
  <subtitle>道路很长, 开始了就别停下!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.alan87.top/"/>
  <updated>2020-10-10T07:03:43.951Z</updated>
  <id>https://www.alan87.top/</id>
  
  <author>
    <name>千寻</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>常见的攻击手段——DDOS，CC攻击</title>
    <link href="https://www.alan87.top/web/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%94%BB%E5%87%BB%E6%89%8B%E6%AE%B5%E2%80%94%E2%80%94DDOS-CC%E6%94%BB%E5%87%BB/"/>
    <id>https://www.alan87.top/web/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%94%BB%E5%87%BB%E6%89%8B%E6%AE%B5%E2%80%94%E2%80%94DDOS-CC%E6%94%BB%E5%87%BB/</id>
    <published>2020-05-25T13:28:35.000Z</published>
    <updated>2020-10-10T07:03:43.951Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DDoS即分布式拒绝服务攻击"><a href="#DDoS即分布式拒绝服务攻击" class="headerlink" title="DDoS即分布式拒绝服务攻击"></a>DDoS即分布式拒绝服务攻击</h1><p>要理解DDos，得先从DoS说起。最基本的DoS攻击就是利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器的响应。</p><a id="more"></a><p>DDoS的原理就非常简单了，它指的是攻击者借助公共网络，将数量庞大的计算机设备联合起来作为攻击平台，对一个或多个目标发动攻击，从而达到瘫痪目标主机的目的。通常，在攻击开始前，攻击者会提前控制大量的用户计算机，称之为“肉鸡”，并通过指令使大量的肉鸡在同一时刻对某个主机进行访问，从而达到瘫痪目标主机的目的。</p><h2 id="常见的攻击手段—SYN-Flood（防御方式）"><a href="#常见的攻击手段—SYN-Flood（防御方式）" class="headerlink" title="常见的攻击手段—SYN Flood（防御方式）"></a>常见的攻击手段—SYN Flood（防御方式）</h2><h2 id="常见的攻击手段—DNS-Query-Flood"><a href="#常见的攻击手段—DNS-Query-Flood" class="headerlink" title="常见的攻击手段—DNS Query Flood"></a>常见的攻击手段—DNS Query Flood</h2><p>DNS Query Flood实际上是UDP Flood攻击的一种变形，由于DNS服务在互联网中不可替代的作用，一旦DNS服务器瘫痪，影响甚大。</p><p>DNS Query Flood攻击采用的方法是向被攻击的服务器发送海量的域名解析请求，通常，请求解析的域名是随机生成，大部分根本就不存在，并且通过伪造端口和客户端IP，防止查询请求被ACL过滤。被攻击的DNS 服务器在接收到域名解析请求后，首先会在服务器上查找是否有对应的缓存，由于域名是随机生成的，几乎不可能有相应的缓存信息，当没有缓存，并且该域名无法直接由该DNS服务器进行解析的时候，DNS服务器会向其上层DNS服务器递归查询域名信息，直到全球互联网的13台根DNS服务器。大量不存在的域名解析请求，给服务器带来了很大的负载，当解析请求超过一定量的时候，就会造成DNS服务器解析域名超时，这样攻击者便达成了攻击目的。</p><h1 id="常见的攻击手段—CC攻击（接口暴力请求）"><a href="#常见的攻击手段—CC攻击（接口暴力请求）" class="headerlink" title="常见的攻击手段—CC攻击（接口暴力请求）"></a>常见的攻击手段—CC攻击（接口暴力请求）</h1><p>CC(Challenge Collapsar)攻击属于DDos的一种，是基于应用层HTTP协议发起的DDos攻击，也被称为HTTP Flood。</p><p>CC攻击的原理是这样的，攻击者通过控制的大量“肉鸡”或者利用从互联网上搜寻的大量匿名的HTTP代理，模拟正常用户给网站发起请求直到该网站拒绝服务为止。大部分网站会通过CDN以及分布式缓存来加快服务端响应，提升网站的吞吐量，而这些精心构造的HTTP请求往往有意避开这些缓存，需要进行多次DB查询操作或者是一次请求返回大量的数据，加速系统资源消耗，从而拖垮后端的业务处理系统，甚至连相关存储以及日志收集系统也无法幸免。</p><h1 id="防御方式"><a href="#防御方式" class="headerlink" title="防御方式:"></a>防御方式:</h1><p>1,主要通过缓存来进行，由secret缓存直接返回结果来返回后端的业务，大型的互联网公司都会有CDN节点缓存。</p><p>2，网络清洗设备能够铺获到http请求来做一些处理，根据ip地址做统计，如果访问高于一定频率的ip，可以列入黑名单。</p><p>3，重发，强制使用TCP，根据头部报文来做效验。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;DDoS即分布式拒绝服务攻击&quot;&gt;&lt;a href=&quot;#DDoS即分布式拒绝服务攻击&quot; class=&quot;headerlink&quot; title=&quot;DDoS即分布式拒绝服务攻击&quot;&gt;&lt;/a&gt;DDoS即分布式拒绝服务攻击&lt;/h1&gt;&lt;p&gt;要理解DDos，得先从DoS说起。最基本的DoS攻击就是利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器的响应。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Web" scheme="https://www.alan87.top/categories/web/"/>
    
    
      <category term="Web" scheme="https://www.alan87.top/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>大厂面试题</title>
    <link href="https://www.alan87.top/java/%E5%A4%A7%E5%8E%82%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <id>https://www.alan87.top/java/%E5%A4%A7%E5%8E%82%E9%9D%A2%E8%AF%95%E9%A2%98/</id>
    <published>2020-05-25T07:36:20.000Z</published>
    <updated>2020-10-10T07:03:43.835Z</updated>
    
    <content type="html"><![CDATA[<h1 id="JAVA"><a href="#JAVA" class="headerlink" title="JAVA"></a>JAVA</h1><h2 id="Java常用的数据结构有哪些-哪些是线程安全的-是怎么保证线程安全的？"><a href="#Java常用的数据结构有哪些-哪些是线程安全的-是怎么保证线程安全的？" class="headerlink" title="Java常用的数据结构有哪些?哪些是线程安全的?是怎么保证线程安全的？"></a>Java常用的数据结构有哪些?哪些是线程安全的?是怎么保证线程安全的？</h2><a id="more"></a><p><a href="../Java开发中常用的数据结构">Java开发中常用的数据结构</a><br><a href="../Java中满足线程安全的数据结构">简述Java中满足线程安全的数据结构</a></p><h2 id="多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？"><a href="#多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？" class="headerlink" title="多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？"></a>多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？</h2><p>ReadWriteLock读写锁</p><h2 id="JAVA的AQS是否了解，它是干嘛的？"><a href="#JAVA的AQS是否了解，它是干嘛的？" class="headerlink" title="JAVA的AQS是否了解，它是干嘛的？"></a>JAVA的AQS是否了解，它是干嘛的？</h2><p>AbstractQueuedSynchronizer（AQS）为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁定和相关同步器（信号量、事件，等等）提供一个框架。<br>要明白AQS在功能上有独占锁和共享锁两种功能。</p><h2 id="除了synchronized关键字之外，你是怎么来保障线程安全的？"><a href="#除了synchronized关键字之外，你是怎么来保障线程安全的？" class="headerlink" title="除了synchronized关键字之外，你是怎么来保障线程安全的？"></a>除了synchronized关键字之外，你是怎么来保障线程安全的？</h2><pre><code>- 1、互斥同步(阻塞同步)，悲观并发策略  synchronized关键字 、ReentrantLock- 2、非阻塞同步，基于冲突检测的乐观并发策略    非阻塞的实现CAS（compareandswap）：CAS指令需要有3个操作数，分别是内存地址（在java中理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，CAS指令指令时，当且仅当V处的值符合旧预期值A时，处理器用B更新V处的值，否则它就不执行更新，但是无论是否更新了V处的值，都会返回V的旧值，上述的处理过程是一个原子操作。    CAS缺点：        - ABA问题：因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。        - ABA问题的解决思路就是使用版本号。在变量前面追加版本号，每次变量更新的时候把版本号加一，那么A-B-A就变成了1A-2B-3C。JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。- 3、无需同步方案    要保证线程安全，并不是一定就要进行同步，两者没有因果关系。同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无需任何同步操作去保证正确性，因此会有一些代码天生就是线程安全的。    - 1）可重入代码       可重入代码（ReentrantCode）也称为纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码，而在控制权返回后，原来的程序不会出现任何错误。所有的可重入代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。       可重入代码的特点是不依赖存储在堆上的数据和公用的系统资源、用到的状态量都是由参数中传入、不调用 非可重入的方法等。       （类比：synchronized拥有锁重入的功能，也就是在使用synchronized时，当一个线程得到一个对象锁后，再次请求此对象锁时时可以再次得到该对象的锁）    - 2）线程本地存储       如果一段代码中所需的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内。这样无需同步也能保证线程之间不出现数据的争用问题。       符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典的Web交互模型中的“一个请求对应一个服务器线程（Thread-per-Request）”的处理方式，这种处理方式的广泛应用使得很多Web服务器应用都可以使用线程本地存储来解决线程安全问题。</code></pre><h2 id="Tomcat本身的参数你一般会怎么调整？"><a href="#Tomcat本身的参数你一般会怎么调整？" class="headerlink" title="Tomcat本身的参数你一般会怎么调整？"></a>Tomcat本身的参数你一般会怎么调整？</h2><h2 id="HashMap和Hashtable的区别。"><a href="#HashMap和Hashtable的区别。" class="headerlink" title="HashMap和Hashtable的区别。"></a>HashMap和Hashtable的区别。</h2><h2 id="实现一个保证迭代顺序的HashMap。"><a href="#实现一个保证迭代顺序的HashMap。" class="headerlink" title="实现一个保证迭代顺序的HashMap。"></a>实现一个保证迭代顺序的HashMap。</h2><h2 id="说说HashMap的原理-以及HashMap如何扩充bucket的大小。"><a href="#说说HashMap的原理-以及HashMap如何扩充bucket的大小。" class="headerlink" title="说说HashMap的原理, 以及HashMap如何扩充bucket的大小。"></a>说说HashMap的原理, 以及HashMap如何扩充bucket的大小。</h2><h2 id="说一说排序算法，稳定性，复杂度。"><a href="#说一说排序算法，稳定性，复杂度。" class="headerlink" title="说一说排序算法，稳定性，复杂度。"></a>说一说排序算法，稳定性，复杂度。</h2><h2 id="TCP如何保证可靠传输？三次握手过程？"><a href="#TCP如何保证可靠传输？三次握手过程？" class="headerlink" title="TCP如何保证可靠传输？三次握手过程？"></a>TCP如何保证可靠传输？三次握手过程？</h2><h2 id="如何控制某个方法允许并发访问线程的个数"><a href="#如何控制某个方法允许并发访问线程的个数" class="headerlink" title="如何控制某个方法允许并发访问线程的个数"></a>如何控制某个方法允许并发访问线程的个数</h2><p>Semaphore（信号量）</p><h2 id="死锁是什么意思，形成条件是什么？出现死锁是可以通过什么方式去排查。"><a href="#死锁是什么意思，形成条件是什么？出现死锁是可以通过什么方式去排查。" class="headerlink" title="死锁是什么意思，形成条件是什么？出现死锁是可以通过什么方式去排查。"></a>死锁是什么意思，形成条件是什么？出现死锁是可以通过什么方式去排查。</h2><p>监测死锁可以使用jdk自带的工具。<br>执行jps命令，得到运行的线程的id，<br><code>jps -l</code><br>再执行jstack命令，查看结果。<br><code>jstack -l pid</code></p><p>jvisualVM, jconsole</p><h2 id="Java中活锁和死锁有什么区别？"><a href="#Java中活锁和死锁有什么区别？" class="headerlink" title="Java中活锁和死锁有什么区别？"></a>Java中活锁和死锁有什么区别？</h2><p>活锁：互相释放资源给对方，结果谁都没有用到这资源。<br>死锁：互相抢着资源，谁都没有抢到。</p><h2 id="产生死锁的四个必要条件："><a href="#产生死锁的四个必要条件：" class="headerlink" title="产生死锁的四个必要条件："></a>产生死锁的四个必要条件：</h2><ul><li>（1）互斥条件：一个资源每次只能被一个进程使用。</li><li>（2）占有且等待：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li><li>（3）不可强行占有:进程已获得的资源，在末使用完之前，不能强行剥夺。</li><li>（4）循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。</li></ul><h2 id="如何避免死锁？"><a href="#如何避免死锁？" class="headerlink" title="如何避免死锁？"></a>如何避免死锁？</h2><p>　　加锁顺序（线程按照一定的顺序加锁）；<br>　　加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁）；<br>　　死锁检测。</p><h2 id="对于volatile关键字，当且仅当满足以下所有条件时可使用："><a href="#对于volatile关键字，当且仅当满足以下所有条件时可使用：" class="headerlink" title="对于volatile关键字，当且仅当满足以下所有条件时可使用："></a>对于volatile关键字，当且仅当满足以下所有条件时可使用：</h2><ol><li>对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。</li><li>该变量没有包含在具有其他变量的不变式中。</li><li>static是类的属性，存储在类的那块内存，每个线程操作的时候会读取这个内存块，甚至会加载到寄存器或高速缓存中，这样自然不会保证其他线程对该值的可见性；而volatile表示每次读操作直接到内存，如果多个线程都遵循这样的约定，就会读取到最新的状态.<br> PS：synchronized代码块会对变量进行写入操作</li></ol><h2 id="什么时候需要加volatile关键字？它能保证线程安全吗？"><a href="#什么时候需要加volatile关键字？它能保证线程安全吗？" class="headerlink" title="什么时候需要加volatile关键字？它能保证线程安全吗？"></a>什么时候需要加volatile关键字？它能保证线程安全吗？</h2><p>volatile是不能保证线程安全的，它只是保证了数据的可见性，不会再缓存，</p><p>每个线程都是从主存中读到的数据，而不是从缓存中读取的数据，</p><p>当synchronized去掉的时候，每个线程的结果是乱的，加上的时候结果才是正确的。</p><p>并发编程的3个概念：原子性、可见性、有序性</p><ul><li>原子性：一个操作或多个操作要么全部执行完成且执行过程不被中断，要么就不执行。</li><li>可见性：当多个线程同时访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。</li><li>有序性：程序执行的顺序按照代码的先后顺序执行。</li></ul><h2 id="线程池内的线程如果全部忙，提交一个新的任务，会发生什么？队列全部塞满了之后，还是忙，再提交会发生什么？"><a href="#线程池内的线程如果全部忙，提交一个新的任务，会发生什么？队列全部塞满了之后，还是忙，再提交会发生什么？" class="headerlink" title="线程池内的线程如果全部忙，提交一个新的任务，会发生什么？队列全部塞满了之后，还是忙，再提交会发生什么？"></a>线程池内的线程如果全部忙，提交一个新的任务，会发生什么？队列全部塞满了之后，还是忙，再提交会发生什么？</h2><p>一个任务通过execute(Runnable)方法被添加到线程池，任务就是一个Runnable类型的对象，任务的执行方法就是Runnable类型对象的run()方法。当一个任务通过execute(Runnable)方法想添加到线程池时：</p><ul><li>如果此时线程池中数量小于corePoolSize,即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。</li><li>如果此时线程池中的数量等于corePoolSize,但是缓冲队列workQueue未满，那么任务放入缓冲队列</li><li>如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。</li><li>如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue 满，并且线程池中的数量等于maximumPoolSize，那么通过handler所指定的策略来处理此任务。也就是：处理任务的优先级为：核心线程 corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务</li><li>当线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。<ul><li>corePoolSize： 线程池维护线程的最少数量</li><li>maxnumPoolSize： 线程池维护线程的最大数量</li><li>keepAliveTime： 线程池维护线程所允许的空闲时间</li><li>unit： 线程池维护线程所允许的空闲时间的单位</li><li>workQueue： 线程池所使用的缓冲队列</li><li>handler： 线程池对拒绝任务的处理策略</li></ul></li></ul><h2 id="synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？"><a href="#synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？" class="headerlink" title="synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？"></a>synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？</h2><ol><li>synchronized锁住的是括号里的对象，不是代码。对于非static的synchronized方法，锁的就是对象本身也就是this。</li><li>在java语言中存在两种内建的synchronized语法：<ul><li>1、synchronized语句；对于synchronized语句当Java源代码被javac编译成bytecode的时候，会在同步块的入口位置和退出位置分别插入monitorenter和monitorexit字节码指令。</li><li>2、synchronized方法。synchronized方法则会被翻译成普通的方法调用和返回指令如:invokevirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象</li></ul></li></ol><h2 id="synchronized-的原理是什么？synchronized-和-ReentrantLock-有什么不同？"><a href="#synchronized-的原理是什么？synchronized-和-ReentrantLock-有什么不同？" class="headerlink" title="synchronized 的原理是什么？synchronized 和 ReentrantLock 有什么不同？"></a>synchronized 的原理是什么？synchronized 和 ReentrantLock 有什么不同？</h2><p>这两种方式最大区别就是对于Synchronized来说，它是java语言的关键字，是原生语法层面的互斥，需要jvm实现。而ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。</p><p>Synchronized进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。 </p><h2 id="wait-notify-notifyAll方法需不需要被包含在synchronized块中？这是为什么？"><a href="#wait-notify-notifyAll方法需不需要被包含在synchronized块中？这是为什么？" class="headerlink" title="wait/notify/notifyAll方法需不需要被包含在synchronized块中？这是为什么？"></a>wait/notify/notifyAll方法需不需要被包含在synchronized块中？这是为什么？</h2><pre><code>Obj.wait()，与Obj.notify()必须要与synchronized(Obj)一起使用，也就是wait,与notify是针对已经获取了Obj锁进行操作。</code></pre><p>　　从语法角度来说就是Obj.wait(),Obj.notify必须synchronized(Obj){…}语句块内。<br>　　从功能上来说wait就是说线程在获取对象锁后，主动释放对象锁，同时本线程休眠。直到有其它线程调用对象的notify()唤醒该线程，才能继续获取对象锁，并继续执行<br>　　如果实例方法含有如下的语句时：wait();则其意义同：this.wait();</p><h2 id="Executors类是什么？-Executor和Executors的区别？"><a href="#Executors类是什么？-Executor和Executors的区别？" class="headerlink" title="Executors类是什么？ Executor和Executors的区别？"></a>Executors类是什么？ Executor和Executors的区别？</h2><ol><li><p>Executor<br>它是”执行者来”接口，它是来执行任务的。准确的说，Executor提供了execute()接口来执行已提交的 Runnable 任务的对象。Executor存在的目的是提供一源种将”任务提交”与”任务如何运行”分离开来的知机制。它只包含一个函数接口。</p></li><li><p>Executors<br>Executors是个静态工厂类。它通过静态工厂方法返回到ExecutorService、ScheduledExecutorService、ThreadFactory 和 Callable 等类的对象。</p></li></ol><h2 id="ExecutorService你一般是怎么用的？是每个service放一个还是一个项目里面放一个？有什么好处？"><a href="#ExecutorService你一般是怎么用的？是每个service放一个还是一个项目里面放一个？有什么好处？" class="headerlink" title="ExecutorService你一般是怎么用的？是每个service放一个还是一个项目里面放一个？有什么好处？"></a>ExecutorService你一般是怎么用的？是每个service放一个还是一个项目里面放一个？有什么好处？</h2><p>Java线程池ExecutorService<br>如果有一套相同逻辑的多个任务的情况下,应用一个线程池是个好选择。<br>如果项目中有多套不同的这种任务,那每套任务应该一个线程池。</p><h2 id="线程池是什么？为什么要使用它？如何创建一个Java线程池？"><a href="#线程池是什么？为什么要使用它？如何创建一个Java线程池？" class="headerlink" title="线程池是什么？为什么要使用它？如何创建一个Java线程池？"></a>线程池是什么？为什么要使用它？如何创建一个Java线程池？</h2><p>线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。<br>线程池线程都是后台线程。每个线程都使用默认的堆栈大小，以默认的优先级运行，并处于多线程单元中。<br>如果某个线程在托管代码中空闲（如正在等待某个事件），则线程池将插入另一个辅助线程来使所有处理器保持繁忙。<br>如果所有线程池线程都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。<br>超过最大值的线程可以排队，但他们要等到其他线程完成后才启动。</p><p>使用线程池的好处:</p><ol><li>重用存在的线程，减少对象创建、消亡的开销，性能佳。</li><li>可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。</li><li>提供定时执行、定期执行、单线程、并发数控制等功能。</li></ol><h2 id="线程池内部工作原理可以说一下么？"><a href="#线程池内部工作原理可以说一下么？" class="headerlink" title="线程池内部工作原理可以说一下么？"></a>线程池内部工作原理可以说一下么？</h2><p>其实java线程池的实现原理很简单，说白了就是一个线程集合workerSet和一个阻塞队列workQueue。当用户向线程池提交一个任务(也就是线程)时，线程池会先将任务放入workQueue中。workerSet中的线程会不断的从workQueue中获取线程然后执行。当workQueue中没有任务的时候，worker就会阻塞，直到队列中有任务了就取出来继续执行。</p><h2 id="线程池创建有几种，为什么创建定长的线程池个数最好是5，10，15这样的数字。"><a href="#线程池创建有几种，为什么创建定长的线程池个数最好是5，10，15这样的数字。" class="headerlink" title="线程池创建有几种，为什么创建定长的线程池个数最好是5，10，15这样的数字。"></a>线程池创建有几种，为什么创建定长的线程池个数最好是5，10，15这样的数字。</h2><ol><li><p>newCachedThreadPool<br> 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。这种类型的线程池特点是：<br> 工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。<br> 如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。<br> 在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同时运行，很有会造成系统瘫痪。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService cachedThreadPool = Executors.newCachedThreadPool();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Thread.sleep(index * <span class="number">1000</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cachedThreadPool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>newFixedThreadPool<br> 创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。</p><p> FixedThreadPool是一个典型且优秀的线程池，它具有线程池提高程序效率和节省创建线程时所耗的开销的优点。但是，在线程池空闲时，即线程池中没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService fixedThreadPool = Executors.newFixedThreadPool(<span class="number">3</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    fixedThreadPool.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(index);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>newSingleThreadExecutor<br>创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。如果这个线程异常结束，会有另一个取代它，保证顺序执行。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">    singleThreadExecutor.execute(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(index);</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>newScheduleThreadPool<br>创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(<span class="number">5</span>);</span><br><span class="line">scheduledThreadPool.schedule(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"delay 3 seconds"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;, <span class="number">3</span>, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure></li><li><p>newWorkStealingPool：<strong>jdk1.8新增</strong>,创建持有足够线程的线程池来支持给定的并行级别，并通过使用多个队列，减少竞争，它需要穿一个并行级别的参数，如果不传，则被设定为默认的CPU数量。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newWorkStealingPool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ForkJoinPool (Runtime.getRuntime().availableProcessors(),</span><br><span class="line">            ForkJoinPool.defaultForkJoinWorkerThreadFactory,</span><br><span class="line">            <span class="keyword">null</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ForkJoinPool</span><span class="params">(<span class="keyword">int</span> parallelism,</span></span></span><br><span class="line"><span class="function"><span class="params">                    ForkJoinWorkerThreadFactory factory,</span></span></span><br><span class="line"><span class="function"><span class="params">                    UncaughtExceptionHandler handler,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">boolean</span> asyncMode)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(checkParallelism(parallelism),</span><br><span class="line">            checkFactory(factory),</span><br><span class="line">            handler,</span><br><span class="line">            asyncMode ? FIFO_QUEUE : LIFO_QUEUE,</span><br><span class="line">            <span class="string">"ForkJoinPool-"</span> + nextPoolId() + <span class="string">"-worker-"</span>);</span><br><span class="line">    checkPermission();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>可以看出前四种线程池最终都是返回了ThreadPoolExecutor对象，最后一个返回的ForkJoinPool是jdk1.7才新增的。</p><p><strong>线程池个数:</strong></p><ol><li>先看下机器的CPU核数，然后在设定具体参数：</li></ol><p>即CPU核数 = Runtime.getRuntime().availableProcessors()</p><ol start="2"><li>分析下线程池处理的程序是CPU密集型，还是IO密集型</li></ol><ul><li><p>CPU密集型：核心线程数 = CPU核数 + 1</p></li><li><p>IO密集型：核心线程数 = CPU核数 * 2</p></li></ul><p>注：IO密集型（某大厂实践经验）</p><ul><li>核心线程数 = CPU核数 / （1-阻塞系数）<br>例如阻塞系数 0.8，CPU核数为4,则核心线程数为20</li></ul><h2 id="在交易过程中如何放在用户在支付时的重复支付（交叉支付），请写出你了解的方案或使用的过的方案。"><a href="#在交易过程中如何放在用户在支付时的重复支付（交叉支付），请写出你了解的方案或使用的过的方案。" class="headerlink" title="在交易过程中如何放在用户在支付时的重复支付（交叉支付），请写出你了解的方案或使用的过的方案。"></a>在交易过程中如何放在用户在支付时的重复支付（交叉支付），请写出你了解的方案或使用的过的方案。</h2><h2 id="程序开发时通过开发工具DeBug调试时，控制台显示的内容都包含什么？哪些内容可以帮助你发现问题和解决问题。"><a href="#程序开发时通过开发工具DeBug调试时，控制台显示的内容都包含什么？哪些内容可以帮助你发现问题和解决问题。" class="headerlink" title="程序开发时通过开发工具DeBug调试时，控制台显示的内容都包含什么？哪些内容可以帮助你发现问题和解决问题。"></a>程序开发时通过开发工具DeBug调试时，控制台显示的内容都包含什么？哪些内容可以帮助你发现问题和解决问题。</h2><h2 id="RPC通信过程中，假设A系统提供了一个方法入参是一个JavaBean，出参也是一个JavaBean。另外两个系统B系统、C系统调用接口，调用方B想让提供方A增加一个返回参数，假设服务提供方A增加了返回参数，请问C系统调用方需要做什么处理？"><a href="#RPC通信过程中，假设A系统提供了一个方法入参是一个JavaBean，出参也是一个JavaBean。另外两个系统B系统、C系统调用接口，调用方B想让提供方A增加一个返回参数，假设服务提供方A增加了返回参数，请问C系统调用方需要做什么处理？" class="headerlink" title="RPC通信过程中，假设A系统提供了一个方法入参是一个JavaBean，出参也是一个JavaBean。另外两个系统B系统、C系统调用接口，调用方B想让提供方A增加一个返回参数，假设服务提供方A增加了返回参数，请问C系统调用方需要做什么处理？"></a>RPC通信过程中，假设A系统提供了一个方法入参是一个JavaBean，出参也是一个JavaBean。另外两个系统B系统、C系统调用接口，调用方B想让提供方A增加一个返回参数，假设服务提供方A增加了返回参数，请问C系统调用方需要做什么处理？</h2><h2 id="了解哪些设计模式，用伪代码实现一个你熟悉的设计模式。"><a href="#了解哪些设计模式，用伪代码实现一个你熟悉的设计模式。" class="headerlink" title="了解哪些设计模式，用伪代码实现一个你熟悉的设计模式。"></a>了解哪些设计模式，用伪代码实现一个你熟悉的设计模式。</h2><h2 id="知道哪些负载均衡算法。"><a href="#知道哪些负载均衡算法。" class="headerlink" title="知道哪些负载均衡算法。"></a>知道哪些负载均衡算法。</h2><h2 id="说一下Btree的查找原理。"><a href="#说一下Btree的查找原理。" class="headerlink" title="说一下Btree的查找原理。"></a>说一下Btree的查找原理。</h2><h2 id="简述三次握手，如果c端发起握手请求，s端无法立刻建立连接应该回应什么？"><a href="#简述三次握手，如果c端发起握手请求，s端无法立刻建立连接应该回应什么？" class="headerlink" title="简述三次握手，如果c端发起握手请求，s端无法立刻建立连接应该回应什么？"></a>简述三次握手，如果c端发起握手请求，s端无法立刻建立连接应该回应什么？</h2><h2 id="Java对象四种引用。"><a href="#Java对象四种引用。" class="headerlink" title="Java对象四种引用。"></a>Java对象四种引用。</h2><h2 id="Java字节流、字符流使用场景、为什么有了字符流还要字节流？"><a href="#Java字节流、字符流使用场景、为什么有了字符流还要字节流？" class="headerlink" title="Java字节流、字符流使用场景、为什么有了字符流还要字节流？"></a>Java字节流、字符流使用场景、为什么有了字符流还要字节流？</h2><h2 id="Java序列化Id的作用"><a href="#Java序列化Id的作用" class="headerlink" title="Java序列化Id的作用"></a>Java序列化Id的作用</h2><ul><li><p>序列化ID的作用：<br>其实，这个序列化ID起着关键的作用，它决定着是否能够成功反序列化！简单来说，java的序列化机制是通过在运行时判断类的serialVersionUID来验证版本一致性的。在进行反序列化时，JVM会把传来的字节流中的serialVersionUID与本地实体类中的serialVersionUID进行比较，如果相同则认为是一致的，便可以进行反序列化，否则就会报序列化版本不一致的异常。</p></li><li><p>序列化ID如何产生：<br>当我们一个实体类中没有显示的定义一个名为“serialVersionUID”、类型为long的变量时，Java序列化机制会根据编译时的class自动生成一个serialVersionUID作为序列化版本比较，这种情况下，只有同一次编译生成的class才会生成相同的serialVersionUID。譬如，当我们编写一个类时，随着时间的推移，我们因为需求改动，需要在本地类中添加其他的字段，这个时候再反序列化时便会出现serialVersionUID不一致，导致反序列化失败。那么如何解决呢？便是在本地类中添加一个“serialVersionUID”变量，值保持不变，便可以进行序列化和反序列化。</p></li></ul><h2 id="Java为什么要有基本类型的包装类-为什么要有基本类型。"><a href="#Java为什么要有基本类型的包装类-为什么要有基本类型。" class="headerlink" title="Java为什么要有基本类型的包装类,为什么要有基本类型。"></a>Java为什么要有基本类型的包装类,为什么要有基本类型。</h2><h2 id="什么是泛型-参数化类型"><a href="#什么是泛型-参数化类型" class="headerlink" title="什么是泛型? 参数化类型"></a>什么是泛型? 参数化类型</h2><h2 id="什么是反射"><a href="#什么是反射" class="headerlink" title="什么是反射"></a>什么是反射</h2><h2 id="Java类型擦除（泛型擦除）"><a href="#Java类型擦除（泛型擦除）" class="headerlink" title="Java类型擦除（泛型擦除）"></a>Java类型擦除（泛型擦除）</h2><h2 id="Java有哪几种IO模型"><a href="#Java有哪几种IO模型" class="headerlink" title="Java有哪几种IO模型"></a>Java有哪几种IO模型</h2><h2 id="Jdk代理、cglib代理的区别"><a href="#Jdk代理、cglib代理的区别" class="headerlink" title="Jdk代理、cglib代理的区别"></a>Jdk代理、cglib代理的区别</h2><h2 id="讲一下怎么使用分布式锁"><a href="#讲一下怎么使用分布式锁" class="headerlink" title="讲一下怎么使用分布式锁"></a>讲一下怎么使用分布式锁</h2><h2 id="java-util-concurrent包下CountDownLatch、CyclicBarrier和-Semaphore使用场景"><a href="#java-util-concurrent包下CountDownLatch、CyclicBarrier和-Semaphore使用场景" class="headerlink" title="java.util.concurrent包下CountDownLatch、CyclicBarrier和 Semaphore使用场景"></a>java.util.concurrent包下CountDownLatch、CyclicBarrier和 Semaphore使用场景</h2><ol><li><p>CountDownLatch<br> CountDownLatch类利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。</p></li><li><p>CyclicBarrier<br> 字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。</p></li><li><p>Semaphore<br> Semaphore翻译成字面意思为 信号量，Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。</p></li></ol><p>区别:<br>CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同：</p><ul><li>1、CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；</li><li>2、CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；</li><li>3、另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。<br>Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。</li></ul><h2 id="什么是线程局部变量ThreadLocal"><a href="#什么是线程局部变量ThreadLocal" class="headerlink" title="什么是线程局部变量ThreadLocal"></a>什么是线程局部变量ThreadLocal</h2><p>线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。</p><h2 id="ThreadLoal的作用是什么"><a href="#ThreadLoal的作用是什么" class="headerlink" title="ThreadLoal的作用是什么?"></a>ThreadLoal的作用是什么?</h2><p>简单说ThreadLocal就是一种以空间换时间的做法在每个Thread里面维护了一个ThreadLocal.ThreadLocalMap把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了。</p><h1 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h1><h2 id="你知道哪些或者你们线上使用什么GC策略-它有什么优势，适用于什么场景？"><a href="#你知道哪些或者你们线上使用什么GC策略-它有什么优势，适用于什么场景？" class="headerlink" title="你知道哪些或者你们线上使用什么GC策略? 它有什么优势，适用于什么场景？"></a>你知道哪些或者你们线上使用什么GC策略? 它有什么优势，适用于什么场景？</h2><h2 id="JAVA类加载器包括几种？它们之间的父子关系是怎么样的？双亲委派机制是什么意思？有什么好处？"><a href="#JAVA类加载器包括几种？它们之间的父子关系是怎么样的？双亲委派机制是什么意思？有什么好处？" class="headerlink" title="JAVA类加载器包括几种？它们之间的父子关系是怎么样的？双亲委派机制是什么意思？有什么好处？"></a>JAVA类加载器包括几种？它们之间的父子关系是怎么样的？双亲委派机制是什么意思？有什么好处？</h2><h2 id="JVM如何加载一个类的过程，双亲委派模型中有哪些方法？"><a href="#JVM如何加载一个类的过程，双亲委派模型中有哪些方法？" class="headerlink" title="JVM如何加载一个类的过程，双亲委派模型中有哪些方法？"></a>JVM如何加载一个类的过程，双亲委派模型中有哪些方法？</h2><h2 id="如何自定义一个类加载器？你使用过哪些或者你在什么场景下需要一个自定义的类加载器吗？"><a href="#如何自定义一个类加载器？你使用过哪些或者你在什么场景下需要一个自定义的类加载器吗？" class="headerlink" title="如何自定义一个类加载器？你使用过哪些或者你在什么场景下需要一个自定义的类加载器吗？"></a>如何自定义一个类加载器？你使用过哪些或者你在什么场景下需要一个自定义的类加载器吗？</h2><h2 id="堆内存设置的参数是什么？"><a href="#堆内存设置的参数是什么？" class="headerlink" title="堆内存设置的参数是什么？"></a>堆内存设置的参数是什么？</h2><h2 id="Perm-Space中保存什么数据-会引起OutOfMemory吗？"><a href="#Perm-Space中保存什么数据-会引起OutOfMemory吗？" class="headerlink" title="Perm Space中保存什么数据? 会引起OutOfMemory吗？"></a>Perm Space中保存什么数据? 会引起OutOfMemory吗？</h2><h2 id="做gc时，一个对象在内存各个Space中被移动的顺序是什么？"><a href="#做gc时，一个对象在内存各个Space中被移动的顺序是什么？" class="headerlink" title="做gc时，一个对象在内存各个Space中被移动的顺序是什么？"></a>做gc时，一个对象在内存各个Space中被移动的顺序是什么？</h2><h2 id="你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理过程中有哪些收获？"><a href="#你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理过程中有哪些收获？" class="headerlink" title="你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理过程中有哪些收获？"></a>你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理过程中有哪些收获？</h2><h2 id="1-8之后Perm-Space有哪些变动-MetaSpace大小默认是无限的么-还是你们会通过什么方式来指定大小"><a href="#1-8之后Perm-Space有哪些变动-MetaSpace大小默认是无限的么-还是你们会通过什么方式来指定大小" class="headerlink" title="1.8之后Perm Space有哪些变动? MetaSpace大小默认是无限的么? 还是你们会通过什么方式来指定大小?"></a>1.8之后Perm Space有哪些变动? MetaSpace大小默认是无限的么? 还是你们会通过什么方式来指定大小?</h2><h2 id="Jstack是干什么的-Jstat呢-如果线上程序周期性地出现卡顿，你怀疑可能是gc导致的，你会怎么来排查这个问题？线程日志一般你会看其中的什么部分？"><a href="#Jstack是干什么的-Jstat呢-如果线上程序周期性地出现卡顿，你怀疑可能是gc导致的，你会怎么来排查这个问题？线程日志一般你会看其中的什么部分？" class="headerlink" title="Jstack是干什么的? Jstat呢? 如果线上程序周期性地出现卡顿，你怀疑可能是gc导致的，你会怎么来排查这个问题？线程日志一般你会看其中的什么部分？"></a>Jstack是干什么的? Jstat呢? 如果线上程序周期性地出现卡顿，你怀疑可能是gc导致的，你会怎么来排查这个问题？线程日志一般你会看其中的什么部分？</h2><h2 id="StackOverFlow异常有没有遇到过？一般你猜测会在什么情况下被触发？如何指定一个线程的堆栈大小？一般你们写多少？"><a href="#StackOverFlow异常有没有遇到过？一般你猜测会在什么情况下被触发？如何指定一个线程的堆栈大小？一般你们写多少？" class="headerlink" title="StackOverFlow异常有没有遇到过？一般你猜测会在什么情况下被触发？如何指定一个线程的堆栈大小？一般你们写多少？"></a>StackOverFlow异常有没有遇到过？一般你猜测会在什么情况下被触发？如何指定一个线程的堆栈大小？一般你们写多少？</h2><h2 id="Jvm的内存屏障"><a href="#Jvm的内存屏障" class="headerlink" title="Jvm的内存屏障"></a>Jvm的内存屏障</h2><h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><h2 id="你有没有用过Spring的AOP-是用来干嘛的-大概会怎么使用？"><a href="#你有没有用过Spring的AOP-是用来干嘛的-大概会怎么使用？" class="headerlink" title="你有没有用过Spring的AOP? 是用来干嘛的? 大概会怎么使用？"></a>你有没有用过Spring的AOP? 是用来干嘛的? 大概会怎么使用？</h2><h2 id="如果一个接口有2个不同的实现-那么怎么来Autowire一个指定的实现？"><a href="#如果一个接口有2个不同的实现-那么怎么来Autowire一个指定的实现？" class="headerlink" title="如果一个接口有2个不同的实现, 那么怎么来Autowire一个指定的实现？"></a>如果一个接口有2个不同的实现, 那么怎么来Autowire一个指定的实现？</h2><h2 id="Spring的声明式事务-Transaction注解一般写在什么位置-抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚"><a href="#Spring的声明式事务-Transaction注解一般写在什么位置-抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚" class="headerlink" title="Spring的声明式事务 @Transaction注解一般写在什么位置? 抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚?"></a>Spring的声明式事务 @Transaction注解一般写在什么位置? 抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚?</h2><h2 id="如果想在某个Bean生成并装配完毕后执行自己的逻辑，可以什么方式实现？"><a href="#如果想在某个Bean生成并装配完毕后执行自己的逻辑，可以什么方式实现？" class="headerlink" title="如果想在某个Bean生成并装配完毕后执行自己的逻辑，可以什么方式实现？"></a>如果想在某个Bean生成并装配完毕后执行自己的逻辑，可以什么方式实现？</h2><h2 id="SpringBoot没有放到web容器里为什么能跑HTTP服务？"><a href="#SpringBoot没有放到web容器里为什么能跑HTTP服务？" class="headerlink" title="SpringBoot没有放到web容器里为什么能跑HTTP服务？"></a>SpringBoot没有放到web容器里为什么能跑HTTP服务？</h2><h2 id="SpringBoot中如果你想使用自定义的配置文件而不仅仅是application-properties，应该怎么弄？"><a href="#SpringBoot中如果你想使用自定义的配置文件而不仅仅是application-properties，应该怎么弄？" class="headerlink" title="SpringBoot中如果你想使用自定义的配置文件而不仅仅是application.properties，应该怎么弄？"></a>SpringBoot中如果你想使用自定义的配置文件而不仅仅是application.properties，应该怎么弄？</h2><h2 id="SpringMVC中RequestMapping可以指定GET-POST方法么？怎么指定？"><a href="#SpringMVC中RequestMapping可以指定GET-POST方法么？怎么指定？" class="headerlink" title="SpringMVC中RequestMapping可以指定GET, POST方法么？怎么指定？"></a>SpringMVC中RequestMapping可以指定GET, POST方法么？怎么指定？</h2><h2 id="SpringMVC如果希望把输出的Object-例如XXResult或者XXResponse-这种包装为JSON输出-应该怎么处理"><a href="#SpringMVC如果希望把输出的Object-例如XXResult或者XXResponse-这种包装为JSON输出-应该怎么处理" class="headerlink" title="SpringMVC如果希望把输出的Object(例如XXResult或者XXResponse)这种包装为JSON输出, 应该怎么处理?"></a>SpringMVC如果希望把输出的Object(例如XXResult或者XXResponse)这种包装为JSON输出, 应该怎么处理?</h2><h2 id="怎样拦截SpringMVC的异常，然后做自定义的处理，比如打日志或者包装成JSON"><a href="#怎样拦截SpringMVC的异常，然后做自定义的处理，比如打日志或者包装成JSON" class="headerlink" title="怎样拦截SpringMVC的异常，然后做自定义的处理，比如打日志或者包装成JSON"></a>怎样拦截SpringMVC的异常，然后做自定义的处理，比如打日志或者包装成JSON</h2><h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><h2 id="如果有很多数据插入MYSQL-你会选择什么方式"><a href="#如果有很多数据插入MYSQL-你会选择什么方式" class="headerlink" title="如果有很多数据插入MYSQL 你会选择什么方式?"></a>如果有很多数据插入MYSQL 你会选择什么方式?</h2><h2 id="如果查询很慢，你会想到的第一个方式是什么？索引是干嘛的"><a href="#如果查询很慢，你会想到的第一个方式是什么？索引是干嘛的" class="headerlink" title="如果查询很慢，你会想到的第一个方式是什么？索引是干嘛的?"></a>如果查询很慢，你会想到的第一个方式是什么？索引是干嘛的?</h2><h2 id="如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？"><a href="#如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？" class="headerlink" title="如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？"></a>如果建了一个单列索引，查询的时候查出2列，会用到这个单列索引吗？</h2><h2 id="如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？"><a href="#如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？" class="headerlink" title="如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？"></a>如果建了一个包含多个列的索引，查询的时候只用了第一列，能不能用上这个索引？查三列呢？</h2><h2 id="接上题，如果where条件后面带有一个-i-5-lt-100-会使用到这个索引吗？"><a href="#接上题，如果where条件后面带有一个-i-5-lt-100-会使用到这个索引吗？" class="headerlink" title="接上题，如果where条件后面带有一个 i + 5 &lt; 100 会使用到这个索引吗？"></a>接上题，如果where条件后面带有一个 i + 5 &lt; 100 会使用到这个索引吗？</h2><h2 id="怎么看是否用到了某个索引？"><a href="#怎么看是否用到了某个索引？" class="headerlink" title="怎么看是否用到了某个索引？"></a>怎么看是否用到了某个索引？</h2><h2 id="数据库索引有哪几种，他们之间的区别。"><a href="#数据库索引有哪几种，他们之间的区别。" class="headerlink" title="数据库索引有哪几种，他们之间的区别。"></a>数据库索引有哪几种，他们之间的区别。</h2><h2 id="like-aaa-会使用索引吗-like-aaa-呢"><a href="#like-aaa-会使用索引吗-like-aaa-呢" class="headerlink" title="like %aaa%会使用索引吗? like aaa%呢?"></a>like %aaa%会使用索引吗? like aaa%呢?</h2><h2 id="drop、truncate、delete的区别？"><a href="#drop、truncate、delete的区别？" class="headerlink" title="drop、truncate、delete的区别？"></a>drop、truncate、delete的区别？</h2><h2 id="平时你们是怎么监控数据库的-慢SQL是怎么排查的？"><a href="#平时你们是怎么监控数据库的-慢SQL是怎么排查的？" class="headerlink" title="平时你们是怎么监控数据库的? 慢SQL是怎么排查的？"></a>平时你们是怎么监控数据库的? 慢SQL是怎么排查的？</h2><h2 id="你们数据库是否支持emoji表情，如果不支持，如何操作"><a href="#你们数据库是否支持emoji表情，如果不支持，如何操作" class="headerlink" title="你们数据库是否支持emoji表情，如果不支持，如何操作?"></a>你们数据库是否支持emoji表情，如果不支持，如何操作?</h2><h2 id="你们的数据库单表数据量是多少？一般多大的时候开始出现查询性能急剧下降？"><a href="#你们的数据库单表数据量是多少？一般多大的时候开始出现查询性能急剧下降？" class="headerlink" title="你们的数据库单表数据量是多少？一般多大的时候开始出现查询性能急剧下降？"></a>你们的数据库单表数据量是多少？一般多大的时候开始出现查询性能急剧下降？</h2><h2 id="查询死掉了，想要找出执行的查询进程用什么命令？找出来之后一般你会干嘛？"><a href="#查询死掉了，想要找出执行的查询进程用什么命令？找出来之后一般你会干嘛？" class="headerlink" title="查询死掉了，想要找出执行的查询进程用什么命令？找出来之后一般你会干嘛？"></a>查询死掉了，想要找出执行的查询进程用什么命令？找出来之后一般你会干嘛？</h2><h2 id="读写分离是怎么做的？你认为中间件会怎么来操作？这样操作跟事务有什么关系？"><a href="#读写分离是怎么做的？你认为中间件会怎么来操作？这样操作跟事务有什么关系？" class="headerlink" title="读写分离是怎么做的？你认为中间件会怎么来操作？这样操作跟事务有什么关系？"></a>读写分离是怎么做的？你认为中间件会怎么来操作？这样操作跟事务有什么关系？</h2><h2 id="分库分表有没有做过？线上的迁移过程是怎么样的？如何确定数据是正确的？"><a href="#分库分表有没有做过？线上的迁移过程是怎么样的？如何确定数据是正确的？" class="headerlink" title="分库分表有没有做过？线上的迁移过程是怎么样的？如何确定数据是正确的？"></a>分库分表有没有做过？线上的迁移过程是怎么样的？如何确定数据是正确的？</h2><h2 id="Mysql索引的分类-Btree-hash-，各自使用什么情况-。"><a href="#Mysql索引的分类-Btree-hash-，各自使用什么情况-。" class="headerlink" title="Mysql索引的分类(Btree, hash)，各自使用什么情况 。"></a>Mysql索引的分类(Btree, hash)，各自使用什么情况 。</h2><h2 id="说说Myisam-Innodb区别。"><a href="#说说Myisam-Innodb区别。" class="headerlink" title="说说Myisam, Innodb区别。"></a>说说Myisam, Innodb区别。</h2><h1 id="Linux命令"><a href="#Linux命令" class="headerlink" title="Linux命令"></a>Linux命令</h1><h2 id="日志特别大只想看最后100行怎么弄-如果想一直看日志的持续输出，用什么命令"><a href="#日志特别大只想看最后100行怎么弄-如果想一直看日志的持续输出，用什么命令" class="headerlink" title="日志特别大只想看最后100行怎么弄? 如果想一直看日志的持续输出，用什么命令?"></a>日志特别大只想看最后100行怎么弄? 如果想一直看日志的持续输出，用什么命令?</h2><h2 id="如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？"><a href="#如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？" class="headerlink" title="如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？"></a>如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？</h2><h2 id="grep如果忽略大小写应该怎么弄-正则表达式呢？"><a href="#grep如果忽略大小写应该怎么弄-正则表达式呢？" class="headerlink" title="grep如果忽略大小写应该怎么弄? 正则表达式呢？"></a>grep如果忽略大小写应该怎么弄? 正则表达式呢？</h2><h2 id="vim往下一行是什么键？往下30行呢-跳到文件末尾一行是什么-跳回来是什么-向后搜索是什么"><a href="#vim往下一行是什么键？往下30行呢-跳到文件末尾一行是什么-跳回来是什么-向后搜索是什么" class="headerlink" title="vim往下一行是什么键？往下30行呢? 跳到文件末尾一行是什么? 跳回来是什么? 向后搜索是什么?"></a>vim往下一行是什么键？往下30行呢? 跳到文件末尾一行是什么? 跳回来是什么? 向后搜索是什么?</h2><h2 id="如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？"><a href="#如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？" class="headerlink" title="如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？"></a>如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？</h2><h2 id="如果把上面的出现次数排个序应该怎么弄-想按照数字本身的顺序而不是字符串的顺序排列怎么弄？"><a href="#如果把上面的出现次数排个序应该怎么弄-想按照数字本身的顺序而不是字符串的顺序排列怎么弄？" class="headerlink" title="如果把上面的出现次数排个序应该怎么弄? 想按照数字本身的顺序而不是字符串的顺序排列怎么弄？"></a>如果把上面的出现次数排个序应该怎么弄? 想按照数字本身的顺序而不是字符串的顺序排列怎么弄？</h2><h2 id="Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？"><a href="#Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？" class="headerlink" title="Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？"></a>Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？</h2><h2 id="给某个文件权设置限比如设置为644-是用什么命令？这个6是什么意思？"><a href="#给某个文件权设置限比如设置为644-是用什么命令？这个6是什么意思？" class="headerlink" title="给某个文件权设置限比如设置为644 是用什么命令？这个6是什么意思？"></a>给某个文件权设置限比如设置为644 是用什么命令？这个6是什么意思？</h2><h2 id="Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么"><a href="#Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么" class="headerlink" title="Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么?"></a>Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么?</h2><h2 id="top命令里面，有时候所有进程的CPU使用率加起来超过100-是怎么回事？"><a href="#top命令里面，有时候所有进程的CPU使用率加起来超过100-是怎么回事？" class="headerlink" title="top命令里面，有时候所有进程的CPU使用率加起来超过100%是怎么回事？"></a>top命令里面，有时候所有进程的CPU使用率加起来超过100%是怎么回事？</h2><h2 id="还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？"><a href="#还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？" class="headerlink" title="还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？"></a>还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？</h2><h2 id="想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？"><a href="#想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？" class="headerlink" title="想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？"></a>想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？</h2><p>Linux常问题</p><h2 id="有没有做过Linux系统参数方面的优化，大概优化过什么？"><a href="#有没有做过Linux系统参数方面的优化，大概优化过什么？" class="headerlink" title="有没有做过Linux系统参数方面的优化，大概优化过什么？"></a>有没有做过Linux系统参数方面的优化，大概优化过什么？</h2><h2 id="系统参数里面有个叫做backlog的可以用来干什么？"><a href="#系统参数里面有个叫做backlog的可以用来干什么？" class="headerlink" title="系统参数里面有个叫做backlog的可以用来干什么？"></a>系统参数里面有个叫做backlog的可以用来干什么？</h2><h2 id="查看网络连接发现好多TIME-WAIT-可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIME-WAIT"><a href="#查看网络连接发现好多TIME-WAIT-可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIME-WAIT" class="headerlink" title="查看网络连接发现好多TIME_WAIT 可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIME_WAIT"></a>查看网络连接发现好多TIME_WAIT 可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIME_WAIT</h2><h2 id="可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？"><a href="#可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？" class="headerlink" title="可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？"></a>可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？</h2><h2 id="KeepAlive是用来干什么的？这样的好处是什么？"><a href="#KeepAlive是用来干什么的？这样的好处是什么？" class="headerlink" title="KeepAlive是用来干什么的？这样的好处是什么？"></a>KeepAlive是用来干什么的？这样的好处是什么？</h2><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><ol><li>缓存穿透可以介绍一下么？你认为应该如何解决这个问题</li><li>你是怎么触发缓存更新的？(比如设置超时时间(被动方式), 比如更新的时候主动update)？如果是被动的方式如何控制多个入口同时触发某个缓存更新？</li><li>你们用Redis来做什么？为什么不用其他的KV存储例如Memcached,Cassandra等?</li><li>你们用什么Redis客户端? Redis高性能的原因大概可以讲一些?</li><li>你熟悉哪些Redis的数据结构? zset是干什么的? 和set有什么区别?</li><li>Redis的hash, 存储和获取的具体命令叫什么名字?</li><li>LPOP和BLPOP的区别?</li><li>Redis的有一些包含SCAN关键字的命令是干嘛的? SCAN返回的数据量是固定的吗?</li><li>Redis中的Lua有没有使用过? 可以用来做什么? 为什么可以这么用?</li><li>Redis的Pipeline是用来干什么的?</li></ol><h1 id="去哪儿网面试题"><a href="#去哪儿网面试题" class="headerlink" title="去哪儿网面试题"></a>去哪儿网面试题</h1><ol><li>mysql数据库调优。</li><li>sql优化。</li><li>like能用索引吗？</li><li></li><li>GC原理。</li><li>jvm内存结构。</li><li>说一下你学过jvm 在书写代码上对你有什么帮助和提高。</li><li>千万数据量的查询你会怎么做？</li><li>HashMap在jdk1.7和1.8的区别，为什么引入这个概念？hash碰撞怎么解决，为什么1.8要比1.7更好，好在哪？</li><li>关于你的项目，如果并发很大，你会怎么改造。</li><li>方法区里什么样的对象有可能被回收。</li><li>线上cpu飙升100%你怎么处理。</li><li>频繁FullGC怎么处理。</li><li>linux命令。(快速文件处理命令)</li><li>伊甸区和幸存区可动态变化吗？</li><li>redis和memcached区别。</li><li>说几个jdk命令，jmap是什么意思。</li><li>如果并发很大，你对数据的正确性怎么保证。</li></ol><h1 id="饿了么面试题"><a href="#饿了么面试题" class="headerlink" title="饿了么面试题"></a>饿了么面试题</h1><ol><li>http和https的区别，https原理，http2.0与1.0的区别。</li><li>Java的垃圾回收机制，Java文件加载机制，tomcat类加载机制，锁机制，jvm原理及线上调优，jvm内存模型。</li><li>多线程，有哪些可以保持进程同步的方法，创建线程的几种方法，对i++多线程访问你会怎么做。</li><li>Java的设计模式，单例有什么模式，懒汉为什么加volotile，volotile的内存屏障，如何避免死锁。</li><li>考虑单例模式的编写，要线程安全且内存消耗小（剑指offer原题）。</li><li>String、StringBuilder、StringBuffer区别；String类能被继承吗？为什么？</li><li>在白纸上手写二分法排序算法（lintcode上原题）；二分查找的思想。</li><li>查找单链表中倒数第k个节点的算法，手写（lintcode上原题）；最常见的排序算法你见过哪些，快排的基本思想及时间复杂度。</li><li>常见的数据结构有哪些。</li><li>hashmap、hashcode一样，不equals怎么处理 ；hashcode实现原理，currentHashMap原理，实现细节，怎么实现同步的；类为什么要有hascode方法，是不是主要在集合类中都要实现hashcode方法；equals方法怎么实现；两个不同的对象可能有相同的hashcode值吗；常用集合有哪些。</li><li>tcp三次握手，四次挥手协议。</li><li>架构设计一个开发性问题，设计一个Nginx管理的中间件，怎么设计。</li><li>所有的类都继承与object，你用过object类的直接子类有哪些，object类常用的方法有哪些。</li><li>Java会出现内存泄漏吗，如果回，在哪种情况下？</li><li>抽象类和接口的区别。</li><li>平时怎么扩展自己的专业知识水平。</li></ol><h1 id="百度面试题"><a href="#百度面试题" class="headerlink" title="百度面试题"></a>百度面试题</h1><ol><li><p>什么是 Java 的反射机制。</p></li><li><p>Cookie 和 Session的区别。</p></li><li><p>get 和 post请求的区别。</p></li><li><p>IOC的优点是什么。</p></li><li><p>IO 和 NIO的区别，NIO优点。</p></li><li><p>JRE、JDK、JVM 及 JIT 之间有什么不同。</p></li><li><p>Hashcode 的作用。</p></li><li><p>简述一致性 Hash 算法。</p></li><li><p>为什么在重写 equals 方法的时候需要重写 hashCode 方法？equals与 hashCode 的异同点在哪里。</p></li><li><p>为什么 Map 接口不继承 Collection 接口。</p></li><li><p>说出几点 Java 中使用 Collections 的最佳实践？</p></li><li><p>GC是什么？为什么要有GC。</p></li><li><p>什么时候会导致垃圾回收。</p></li><li><p>GC 有几种方式？怎么配置。</p></li><li><p>什么时候一个对象会被GC？ 如何判断一个对象是否存活。</p></li><li><p>垃圾回收器的基本原理是什么？</p></li><li><p>Serial 与 Parallel GC之间的不同之处。</p></li><li><p>JVM 中一次完整的 GC 流程是怎样的？ 对象如何晋升到老年代。</p></li><li><p>吞吐量优先和响应优先的垃圾收集器选择。</p></li><li><p>说说你知道的几种主要的jvm 参数。</p></li><li><p>Java中存在内存泄漏问题吗？请举例说明。</p></li><li><p>什么是线程，多线程的优点是什么？以及简单说一下多线程的几种实现方式。</p></li><li><p>ThreadLocal 用途是什么，原理是什么，用的时候要注意什么?</p></li><li><p>有T1，T2，T3三个线程，怎么确保它们按顺序执行？怎样保证T2在T1执行完后执行，T3在T2执行完后执行同步块内的线程抛出异常会发生什么？</p></li><li><p>什么是乐观锁（Optimistic Locking）？如何实现乐观锁？如何避免ABA问题。</p></li><li><p>什么是设计模式（Design Patterns）？你用过哪种设计模式？用在什么场合？</p></li><li><p>你能写出三种单例模式实现么？</p></li><li><p>你知道Google是如何在一秒内把搜索结果返回给用户？</p></li><li><p>高并发下，如何做到安全的修改同一行数据？</p></li><li><p>如何避免浏览器缓存。</p></li><li><p>大型网站在架构上应当考虑哪些问题？</p></li><li><p>最近有在看什么书么，印象最深刻的是什么？</p></li><li><p>你们线上应用的 JVM 参数有哪些？</p></li><li><p>能简单说下你对算法的理解么？</p></li></ol><h1 id="经验分享"><a href="#经验分享" class="headerlink" title="经验分享"></a>经验分享</h1><p>如果你的技术扎实没问题，接下来的面试也决定你是否能得到认可拿到offer，列出以下几点经验，面试前提前准备好答案。</p><ul><li>最好准备好1-2两个问题来应对“你有什么想问的吗？”之类的问题。</li><li>离职原因，不要抱怨现在和以前的雇主。</li><li>保持谈话的时间安排节奏顺利进行, 但不要就某个问题说过多，通过一个问题引入到下一个问题。</li><li>面谈的过程中面试官的问题可能会比较细，比较犀利，那是正常环节，不必紧张。</li><li>如果遇到不太了解问题，最好不要说模棱两可的答案。</li><li>沟通过程中最好保持高度的愿意性。</li><li>准备要充分，知识面要尽量的广，同时深度也要够。</li><li>面试安排上，如果不着急，尽量给自己留多时间，两天一家，及时做总结和补充。</li><li>简历投递方面，拉勾上投了很多经常不匹配，有一些打击自信心，如果有同样感受的，不妨换BOSS或者其他平台。避免打击自信心。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;JAVA&quot;&gt;&lt;a href=&quot;#JAVA&quot; class=&quot;headerlink&quot; title=&quot;JAVA&quot;&gt;&lt;/a&gt;JAVA&lt;/h1&gt;&lt;h2 id=&quot;Java常用的数据结构有哪些-哪些是线程安全的-是怎么保证线程安全的？&quot;&gt;&lt;a href=&quot;#Java常用的数据结构有哪些-哪些是线程安全的-是怎么保证线程安全的？&quot; class=&quot;headerlink&quot; title=&quot;Java常用的数据结构有哪些?哪些是线程安全的?是怎么保证线程安全的？&quot;&gt;&lt;/a&gt;Java常用的数据结构有哪些?哪些是线程安全的?是怎么保证线程安全的？&lt;/h2&gt;
    
    </summary>
    
    
      <category term="Java" scheme="https://www.alan87.top/categories/java/"/>
    
    
      <category term="Java" scheme="https://www.alan87.top/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>K8S有状态服务-StatefulSet使用</title>
    <link href="https://www.alan87.top/k8s/K8S%E6%9C%89%E7%8A%B6%E6%80%81%E6%9C%8D%E5%8A%A1-StatefulSet%E4%BD%BF%E7%94%A8%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>https://www.alan87.top/k8s/K8S%E6%9C%89%E7%8A%B6%E6%80%81%E6%9C%8D%E5%8A%A1-StatefulSet%E4%BD%BF%E7%94%A8%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2020-05-15T03:52:30.000Z</published>
    <updated>2020-10-10T07:03:43.838Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>StatefulSet是一种给Pod提供唯一标志的控制器，它可以保证部署和扩展的顺序。</p><a id="more"></a><div class="note primary">            <ul><li><p>Pod一致性：包含次序（启动、停止次序）、网络一致性。此一致性与Pod相关，与被调度到哪个node节点无关。</p></li><li><p>稳定的次序：对于N个副本的StatefulSet，每个Pod都在[0，N)的范围内分配一个数字序号，且是唯一的。</p></li><li><p>稳定的网络：Pod的hostname模式为$(statefulset名称)-$(序号)。</p></li><li><p>稳定的存储：通过VolumeClaimTemplate为每个Pod创建一个PV。删除、减少副本，不会删除相关的卷。</p></li></ul>          </div><h1 id="部署Statefulset服务"><a href="#部署Statefulset服务" class="headerlink" title="部署Statefulset服务"></a>部署Statefulset服务</h1><p>volumeClaimTemplates：表示一类PVC的模板，系统会根据Statefulset配置的replicas数量，创建相应数量的PVC。这些PVC除了名字不一样之外其他配置都是一样的。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1beta2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">"nginx"</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">disk-data</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">disk-data</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line">      <span class="attr">storageClassName:</span> <span class="string">"data-db"</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">storage:</span> <span class="string">20Gi</span></span><br></pre></td></tr></table></figure><h1 id="验证服务伸缩性"><a href="#验证服务伸缩性" class="headerlink" title="验证服务伸缩性"></a>验证服务伸缩性</h1><h2 id="创建Statefulset服务："><a href="#创建Statefulset服务：" class="headerlink" title="创建Statefulset服务："></a>创建Statefulset服务：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f statefulset.yaml</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          21m</span><br><span class="line">web-1     1/1       Running   0          20m</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME             STATUS    VOLUME                   CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">disk-ssd-web-0   Bound     d-2ze9k2rrtcy92e97d3ie   20Gi       RWO            alicloud-disk-ssd   21m</span><br><span class="line">disk-ssd-web-1   Bound     d-2ze5dwq6gyjnvdcrmtwg   20Gi       RWO            alicloud-disk-ssd   21m</span><br></pre></td></tr></table></figure><h2 id="扩容服务到3个Pod，显示会创建新的云盘卷："><a href="#扩容服务到3个Pod，显示会创建新的云盘卷：" class="headerlink" title="扩容服务到3个Pod，显示会创建新的云盘卷："></a>扩容服务到3个Pod，显示会创建新的云盘卷：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl scale sts web --replicas=3</span><br><span class="line">statefulset.apps <span class="string">"web"</span> scaled</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          24m</span><br><span class="line">web-1     1/1       Running   0          23m</span><br><span class="line">web-2     1/1       Running   0          2m</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME             STATUS    VOLUME                   CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">disk-ssd-web-0   Bound     d-2ze9k2rrtcy92e97d3ie   20Gi       RWO            alicloud-disk-ssd   24m</span><br><span class="line">disk-ssd-web-1   Bound     d-2ze5dwq6gyjnvdcrmtwg   20Gi       RWO            alicloud-disk-ssd   24m</span><br><span class="line">disk-ssd-web-2   Bound     d-2zea5iul9f4vgt82hxjj   20Gi       RWO            alicloud-disk-ssd   2m</span><br></pre></td></tr></table></figure><h2 id="缩容服务到2个Pod，显示pvc-pv并不会一同删除："><a href="#缩容服务到2个Pod，显示pvc-pv并不会一同删除：" class="headerlink" title="缩容服务到2个Pod，显示pvc/pv并不会一同删除："></a>缩容服务到2个Pod，显示pvc/pv并不会一同删除：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl scale sts web --replicas=2</span><br><span class="line">statefulset.apps <span class="string">"web"</span> scaled</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          25m</span><br><span class="line">web-1     1/1       Running   0          25m</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME             STATUS    VOLUME                   CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">disk-ssd-web-0   Bound     d-2ze9k2rrtcy92e97d3ie   20Gi       RWO            alicloud-disk-ssd   25m</span><br><span class="line">disk-ssd-web-1   Bound     d-2ze5dwq6gyjnvdcrmtwg   20Gi       RWO            alicloud-disk-ssd   25m</span><br><span class="line">disk-ssd-web-2   Bound     d-2zea5iul9f4vgt82hxjj   20Gi       RWO            alicloud-disk-ssd   3m</span><br></pre></td></tr></table></figure><h3 id="再次扩容到3个Pod，新的pod会复用原来的PVC-PV："><a href="#再次扩容到3个Pod，新的pod会复用原来的PVC-PV：" class="headerlink" title="再次扩容到3个Pod，新的pod会复用原来的PVC/PV："></a>再次扩容到3个Pod，新的pod会复用原来的PVC/PV：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl scale sts web --replicas=3</span><br><span class="line">statefulset.apps <span class="string">"web"</span> scaled</span><br><span class="line"></span><br><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          27m</span><br><span class="line">web-1     1/1       Running   0          27m</span><br><span class="line">web-2     1/1       Running   0          2m</span><br><span class="line"></span><br><span class="line">$ kubectl get pvc</span><br><span class="line">NAME             STATUS    VOLUME                   CAPACITY   ACCESS MODES   STORAGECLASS        AGE</span><br><span class="line">disk-ssd-web-0   Bound     d-2ze9k2rrtcy92e97d3ie   20Gi       RWO            alicloud-disk-ssd   27m</span><br><span class="line">disk-ssd-web-1   Bound     d-2ze5dwq6gyjnvdcrmtwg   20Gi       RWO            alicloud-disk-ssd   27m</span><br><span class="line">disk-ssd-web-2   Bound     d-2zea5iul9f4vgt82hxjj   20Gi       RWO            alicloud-disk-ssd   5m</span><br></pre></td></tr></table></figure><p>删除StatefulSet服务，PVC、PV并不会随着删除；</p><h2 id="验证服务稳定性"><a href="#验证服务稳定性" class="headerlink" title="验证服务稳定性"></a>验证服务稳定性</h2><p>删除一个Pod前，Pod引用PVC：disk-ssd-web-1</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod web-1 | grep ClaimName</span><br><span class="line">ClaimName:  disk-ssd-web-1</span><br><span class="line"></span><br><span class="line">$ kubectl delete pod web-1</span><br><span class="line">pod <span class="string">"web-1"</span> deleted</span><br></pre></td></tr></table></figure><p>删除Pod后，重新创建的Pod名字与删除的一致，且使用同一个PVC：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE</span><br><span class="line">web-0     1/1       Running   0          29m</span><br><span class="line">web-1     1/1       Running   0          6s</span><br><span class="line">web-2     1/1       Running   0          4m</span><br><span class="line"></span><br><span class="line">$ kubectl describe pod web-1 | grep ClaimName</span><br><span class="line">ClaimName:  disk-ssd-web-1</span><br></pre></td></tr></table></figure><h2 id="验证服务高可用性"><a href="#验证服务高可用性" class="headerlink" title="验证服务高可用性"></a>验证服务高可用性</h2><h3 id="云盘中创建临时文件："><a href="#云盘中创建临时文件：" class="headerlink" title="云盘中创建临时文件："></a>云盘中创建临时文件：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">exec</span> web-1 ls /data</span><br><span class="line">lost+found</span><br><span class="line"></span><br><span class="line">$ kubectl <span class="built_in">exec</span> web-1 touch /data/statefulset</span><br><span class="line">$ kubectl <span class="built_in">exec</span> web-1 ls /data</span><br><span class="line">statefulset</span><br></pre></td></tr></table></figure><h3 id="删除Pod，验证数据持久性："><a href="#删除Pod，验证数据持久性：" class="headerlink" title="删除Pod，验证数据持久性："></a>删除Pod，验证数据持久性：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete pod web-1</span><br><span class="line">pod <span class="string">"web-1"</span> deleted</span><br><span class="line"></span><br><span class="line">$ kubectl <span class="built_in">exec</span> web-1 ls /data</span><br><span class="line">statefulset</span><br></pre></td></tr></table></figure><h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ol><li>服务都可以启动，但是运行一段时间后kafka的pod全部CrashLoopBackOff</li></ol><p>解决: 查看kafka日志连接zookeeper超时。查看zookeeper日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2020-05-18 02:39:07,095]WARN Error accepting new connection: Too many connections from &#x2F;172.18.80.0 - max is 2</span><br></pre></td></tr></table></figure><p>问题找到了,修改zookeeper配置 maxClientCnxns=200</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;StatefulSet是一种给Pod提供唯一标志的控制器，它可以保证部署和扩展的顺序。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/categories/kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Pod has unbound immediate PersistentVolumeClaims,statefulset挂载不上pv的另一种情况</title>
    <link href="https://www.alan87.top/k8s/pod-has-unbound-PersistentVolumeClaims/"/>
    <id>https://www.alan87.top/k8s/pod-has-unbound-PersistentVolumeClaims/</id>
    <published>2020-05-15T03:48:31.000Z</published>
    <updated>2020-10-10T07:03:43.841Z</updated>
    
    <content type="html"><![CDATA[<p>大家都知道当<code>volumeClaimTemplates</code>匹配不上pv时,会出现statefulset挂载不到pv的问题。错误提示如下:</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error while running &quot;VolumeBinding&quot; filter plugin for pod &quot;web-2&quot;: pod has unbound immediate PersistentVolumeClaims</span><br></pre></td></tr></table></figure><p>如果你反复确认了volumeClaimTemplates是正确的，但是始终挂载不上，可以尝试检查以下pvc，看是不是statefulset之前自动创建的错误的pvc没有删除，导致后面statefulset的yaml文件怎么更改也没生效(刷新pvc)。</p><p>这种错误产生步骤如下：</p><ol><li><p>创建一个1G的pv</p></li><li><p>创建了一个statefulset,但是要求的pv容量为2G</p></li><li><p>发现statefulset的yaml文件写错了,改成1G,kubectl delete statefulset xx,然后使用新的yaml</p></li><li><p>然后就发现statefulset的pod无论如何都成为了pending状态</p></li><li><p>原因就在于第三步删除statefulset的时候,自动创建的pvc没有删除,后面使用新的statefulset,pvc并不会自动刷新</p></li><li><p>可以使用命令kubectl get pvc 错误的pvc -o yaml查看这个pvc的创建yaml文档</p></li><li><p>可以使用命令kubectl describe pvc xxx –namespace xxx 查看具体错误信息</p></li><li><p><strong>kubectl delete -f xxx.yml 时不会自动删除volumeClaimTemplates 创建的错误pvc.<br>需要手动删除kubectls delete pvc pvcname –namespace=kafka</strong></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大家都知道当&lt;code&gt;volumeClaimTemplates&lt;/code&gt;匹配不上pv时,会出现statefulset挂载不到pv的问题。错误提示如下:&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/categories/kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes系列——持久化存储StorageClass</title>
    <link href="https://www.alan87.top/k8s/Kubernetes%E7%B3%BB%E5%88%97-%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8StorageClass/"/>
    <id>https://www.alan87.top/k8s/Kubernetes%E7%B3%BB%E5%88%97-%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8StorageClass/</id>
    <published>2020-05-14T09:20:17.000Z</published>
    <updated>2020-10-10T07:03:43.839Z</updated>
    
    <content type="html"><![CDATA[<div class="note primary">            <p>学习本节内容前，希望你已经对Kubernetes中PV和PVC的概念有了初步的了解，具体请参考这篇文章：</p><ul><li>[Kubernetes对象之PersistentVolume和PersistentVolumeClaim]</li></ul>          </div><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>前面的课程中我们学习了 PV 和 PVC 的使用方法，但是前面的 PV 都是静态的，什么意思？<a id="more"></a>就是我要使用的一个 PVC 的话就必须手动去创建一个 PV，我们也说过这种方式在很大程度上并不能满足我们的需求，比如我们有一个应用需要对存储的并发度要求比较高，而另外一个应用对读写速度又要求比较高，特别是对于 StatefulSet 类型的应用简单的来使用静态的 PV 就很不合适了，这种情况下我们就需要用到动态 PV，也就是我们今天要讲解的 StorageClass。</p><h1 id="创建-Provisioner"><a href="#创建-Provisioner" class="headerlink" title="创建 Provisioner"></a>创建 Provisioner</h1><p>要使用 StorageClass，我们就得安装对应的自动配置程序，比如我们这里存储后端使用的是 nfs，那么我们就需要使用到一个 nfs-client 的自动配置程序，我们也叫它 Provisioner，这个程序使用我们已经配置好的 nfs 服务器，来自动创建持久卷，也就是自动帮我们创建 PV。</p><ul><li>自动创建的 PV 以${namespace}-${pvcName}-${pvName}这样的命名格式创建在 NFS 服务器上的共享数据目录中</li><li>而当这个 PV 被回收后会以archieved-${namespace}-${pvcName}-${pvName}这样的命名格式存在 NFS 服务器上。</li></ul><p>当然在部署nfs-client之前，我们需要先成功安装上 nfs 服务器，前面的课程中我们已经过了，服务地址是1192.168.3.131，共享数据目录是/data/k8s/，然后接下来我们部署 nfs-client 即可，我们也可以直接参考nfs-client 的文档，进行安装即可。</p><h2 id="第一步：配置-Deployment"><a href="#第一步：配置-Deployment" class="headerlink" title="第一步：配置 Deployment"></a>第一步：配置 Deployment</h2><p>将里面的对应的参数替换成我们自己的 nfs 配置（nfs-client.yaml）</p><p>将环境变量 NFS_SERVER 和 NFS_PATH 替换<br>当然也包括下面的 nfs 配置，我们可以看到我们这里使用了一个名为 nfs-client-provisioner 的serviceAccount，所以我们也需要创建一个 sa，然后绑定上对应的权限：（nfs-client-sa.yaml）</p><h2 id="第二步：创建account并绑定角色"><a href="#第二步：创建account并绑定角色" class="headerlink" title="第二步：创建account并绑定角色"></a>第二步：创建account并绑定角色</h2><p>我们这里新建的一个名为 nfs-client-provisioner 的ServiceAccount，然后绑定了一个名为 nfs-client-provisioner-runner 的ClusterRole，而该ClusterRole声明了一些权限，其中就包括对persistentvolumes的增、删、改、查等权限，所以我们可以利用该ServiceAccount来自动创建 PV。</p><h3 id="第三步-创建storageclass"><a href="#第三步-创建storageclass" class="headerlink" title="第三步 创建storageclass"></a>第三步 创建storageclass</h3><p>nfs-client 的 Deployment 声明完成后，我们就可以来创建一个StorageClass对象了：（nfs-client-class.yaml）</p><p>我们声明了一个名为 data-nfs 的StorageClass对象，注意下面的provisioner对应的值一定要和上面的Deployment下面的 PROVISIONER_NAME 这个环境变量的值一样。</p><p>现在我们来创建这些资源对象吧：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f nfs-client.yaml</span><br><span class="line">kubectl apply -f nfs-client-sa.yaml</span><br><span class="line">kubectl apply -f nfs-client-class.yaml</span><br></pre></td></tr></table></figure><p>创建完成后查看下资源状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost nfs]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                                      READY   STATUS              RESTARTS   AGE</span><br><span class="line">nfs-client-provisioner-5db79cb75f-nk952   0/1     ContainerCreating   0          12s</span><br><span class="line"></span><br><span class="line">[root@localhost nfs]<span class="comment"># kubectl get storageclass</span></span><br><span class="line">NAME                 PROVISIONER      AGE</span><br><span class="line">data-nfs             fuseim.pri/ifs   31s</span><br><span class="line">harbor-data          fuseim.pri/ifs   90d</span><br></pre></td></tr></table></figure><h1 id="新建-StorageClass"><a href="#新建-StorageClass" class="headerlink" title="新建 StorageClass"></a>新建 StorageClass</h1><p>上面把StorageClass资源对象创建成功了，接下来我们来通过一个示例测试下动态 PV，首先创建一个 PVC 对象：(test-pvc.yaml)</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Mi</span></span><br></pre></td></tr></table></figure><p>我们这里声明了一个PVC对象，采用 ReadWriteMany 的访问模式，请求 1Mi 的空间，但是我们可以看到上面的 PVC 文件我们没有标识出任何和 StorageClass 相关联的信息，那么如果我们现在直接创建这个 PVC 对象能够自动绑定上合适的 PV 对象吗？显然是不能的(前提是没有合适的 PV)，我们这里有两种方法可以来利用上面我们创建的 StorageClass 对象来自动帮我们创建一个合适的 PV:</p><ul><li>第一种方法：在这个PVC对象中添加一个声明StorageClass对象的标识，这里我们可以利用一个annotations属性来标识，如下<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pvc</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">volume.beta.kubernetes.io/storage-class:</span> <span class="string">"data-nfs"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Mi</span></span><br></pre></td></tr></table></figure></li><li>第二种方法：我们可以设置这个 data-nfs 的 StorageClass 为 Kubernetes 的默认存储后端，我们可以用kubectl patch命令来更新： yaml $ kubectl patch storageclass data-nfs -p ‘{“metadata”: {“annotations”:{“storageclass.kubernetes.io/is-default-class”:”true”}}}’<br>上面这两种方法都是可以的，当然为了不影响系统的默认行为，我们这里还是采用第一种方法，直接创建即可：</li></ul><p>上面这两种方法都是可以的，当然为了不影响系统的默认行为，我们这里还是采用第一种方法，直接创建即可：</p><p>（注意网络问题 这里需要拉取外网镜像）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f <span class="built_in">test</span>-pvc.yaml</span><br><span class="line">persistentvolumeclaim <span class="string">"test-pvc"</span> created</span><br><span class="line">[root@localhost nfs]<span class="comment"># kubectl get pvc</span></span><br><span class="line">NAME       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS         AGE</span><br><span class="line">pvc-nfs    Bound    pv1                                        1Gi        RWO                                 12h</span><br><span class="line"><span class="built_in">test</span>-pvc   Bound    pvc-a7293619-bb8c-11e9-93e7-000c29ecf8a8   1Mi        RWX            data-nfs   11h</span><br></pre></td></tr></table></figure><p>我们可以看到一个名为 test-pvc 的 PVC 对象创建成功了，状态已经是Bound了，是不是也产生了一个对应的VOLUME 对象，最重要的一栏是STORAGECLASS，现在是不是也有值了，就是我们刚刚创建的StorageClass对象 data-nfs。</p><p>然后查看下 PV 对象呢：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost nfs]<span class="comment"># kubectl get pv</span></span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM              STORAGECLASS         REASON   AGE</span><br><span class="line">pvc-a7293619-bb8c-11e9-93e7-000c29ecf8a8   1Mi        RWX            Delete           Bound    default/<span class="built_in">test</span>-pvc   data-nfs            3m48s</span><br></pre></td></tr></table></figure><p>可以看到是不是自动生成了一个关联的 PV 对象，访问模式是RWX，回收策略是 Delete，这个 PV 对象并不是我们手动创建的吧，这是通过我们上面的 StorageClass 对象自动创建的。这就是 StorageClass 的创建方法。</p><h1 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h1><h2 id="创建StorageClass持久化存储"><a href="#创建StorageClass持久化存储" class="headerlink" title="创建StorageClass持久化存储"></a>创建StorageClass持久化存储</h2><p>以NFS 作为后端存储资源，在主节点安装NFS，共享/data/k8s/目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop firewalld.service</span><br><span class="line">$ yum -y install nfs-utils rpcbind</span><br><span class="line">$ mkdir -p /data/k8s</span><br><span class="line">$ chmod 755 /data/k8s</span><br><span class="line">$ vim /etc/exports</span><br><span class="line">/data/k8s  *(rw,sync,no_root_squash)</span><br><span class="line"></span><br><span class="line">$ exportfs -r <span class="comment">#修改生效</span></span><br><span class="line">$ systemctl start rpcbind.service</span><br><span class="line">$ systemctl start nfs-server.service</span><br></pre></td></tr></table></figure><ol><li>创建 Provisioner，使用nfs-client 的自动配置程序， nfs-client.yaml<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Recreate</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">quay.io/external_storage/nfs-client-provisioner:latest</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/persistentvolumes</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">fuseim.pri/ifs</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_SERVER</span></span><br><span class="line">              <span class="attr">value:</span> <span class="number">172.16</span><span class="number">.0</span><span class="number">.12</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NFS_PATH</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">/data/k8s</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span></span><br><span class="line">          <span class="attr">nfs:</span></span><br><span class="line">            <span class="attr">server:</span> <span class="number">172.16</span><span class="number">.0</span><span class="number">.12</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/data/k8s</span></span><br></pre></td></tr></table></figure></li><li>创建 sa，然后绑定上对应的权限：（nfs-client-sa.yaml）<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["persistentvolumes"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"create"</span><span class="string">,</span> <span class="string">"delete"</span><span class="string">]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["persistentvolumeclaims"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">["storage.k8s.io"]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["storageclasses"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["events"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["list",</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"create"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">,</span> <span class="string">"patch"</span><span class="string">]</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["endpoints"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["create",</span> <span class="string">"delete"</span><span class="string">,</span> <span class="string">"get"</span><span class="string">,</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"patch"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">run-nfs-client-provisioner</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nfs-client-provisioner</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfs-client-provisioner-runner</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></li><li>创建StorageClass，elasticsearch-storageclass.yaml<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">data-db</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">fuseim.pri/ifs</span></span><br></pre></td></tr></table></figure></li><li>部署<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f nfs-client.yaml</span><br><span class="line">$ kubectl create -f nfs-client-sa.yaml</span><br><span class="line">$ kubectl create -f elasticsearch-storageclass.yaml </span><br><span class="line">$ kubectl  get pods </span><br><span class="line">NAME                                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">nfs-client-provisioner-5b486d9c65-9fzjz   1/1     Running   9          13d</span><br><span class="line">$ kubectl get storageclass</span><br><span class="line">NAME                PROVISIONER      AGE</span><br><span class="line">data-db          fuseim.pri/ifs   13d</span><br></pre></td></tr></table></figure></li></ol><h1 id="问题处理"><a href="#问题处理" class="headerlink" title="问题处理"></a>问题处理</h1><ol><li><p>排查问题命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get events </span><br><span class="line">mount failed: <span class="built_in">exit</span> status 32</span><br><span class="line"></span><br><span class="line">$ kubectl kubectls describe nfs-client-provisioner-5f4c97f67c-jcprd</span><br><span class="line"><span class="comment"># kubectl logs nfs-client-provisioner-5f4c97f67c-jcprd</span></span><br><span class="line"></span><br><span class="line">Warning  Failed     11s (x2 over 16s)  kubelet, 172.16.0.17  Error: Error response from daemon: invalid volume specification: <span class="string">'/var/lib/kubelet/pods/1dadc905-1ebc-408b-ba97-5558c7ed4181/volumes/kubernetes.io~nfs/nfs-client-root:/'</span>: invalid mount config <span class="keyword">for</span> <span class="built_in">type</span> <span class="string">"bind"</span>: invalid specification: destination can<span class="string">'t be '</span>/<span class="string">'</span></span><br></pre></td></tr></table></figure><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">containers:</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span></span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">/</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nfs-client-root</span></span><br><span class="line">      <span class="attr">nfs:</span></span><br><span class="line">        <span class="attr">server:</span> <span class="number">172.16</span><span class="number">.0</span><span class="number">.12</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/data/k8s</span></span><br></pre></td></tr></table></figure><p>containers.volumeMounts.mountPath 挂载点不对,不能为 / 根目录</p></li><li><p>mount failed: exit status 32</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mount: wrong fs <span class="built_in">type</span>, bad option, bad superblock on 172.16.0.12:/data/k8s,</span><br><span class="line">       missing codepage or helper program, or other error</span><br><span class="line">       (<span class="keyword">for</span> several filesystems (e.g. nfs, cifs) you might</span><br><span class="line">       need a /sbin/mount.&lt;<span class="built_in">type</span>&gt; helper program)</span><br><span class="line"></span><br><span class="line">       In some cases useful info is found <span class="keyword">in</span> syslog - try</span><br><span class="line">       dmesg | tail or so.</span><br><span class="line">5s          Warning   FailedMount   pod/nfs-client-provisioner-5f4c97f67c-wgbjc   MountVolume.SetUp failed <span class="keyword">for</span> volume <span class="string">"nfs-client-root"</span> : mount failed: <span class="built_in">exit</span> status 32</span><br></pre></td></tr></table></figure></li></ol><ul><li><p>解决方法</p><ul><li><p>mount 命令查看是否有错误挂载。umount -l /alan</p></li><li><p>要想成功挂载nfs，必须在kubernetes集群的每个node上安装nfs-utils 或nfs-common。</p></li><li><p>在创建persistentvolume和persistentvolumeclaim时他们的name必须相同，而且和pod中的spec.containers.volumeMounts.name以及spec.volumes.name，spec.volumes.persistentVolumeClaim.claimName全都相同，此时才能成功挂载，启动Pod。</p></li></ul></li></ul><p>经过以上，应该就能顺利解决问题了。这不知道算不算是k8s的一个bug，碰到问题在网上找了各种方案都不行，差点想放弃，最后自己经过多次尝试，终于解决了。希望分享出来能够帮助到其他人。</p><p>OK，到这里我们大体明白了StorageClass的作用，下一篇我们会实际把它利用起来。</p>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note primary&quot;&gt;
            &lt;p&gt;学习本节内容前，希望你已经对Kubernetes中PV和PVC的概念有了初步的了解，具体请参考这篇文章：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;[Kubernetes对象之PersistentVolume和PersistentVolumeClaim]&lt;/li&gt;&lt;/ul&gt;
          &lt;/div&gt;
&lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;前面的课程中我们学习了 PV 和 PVC 的使用方法，但是前面的 PV 都是静态的，什么意思？
    
    </summary>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/categories/system-architecture/"/>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/tags/system-architecture/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes对象之PersistentVolume和PersistentVolumeClaim</title>
    <link href="https://www.alan87.top/k8s/Kubernetes%E5%AF%B9%E8%B1%A1%E4%B9%8BPersistentVolume/"/>
    <id>https://www.alan87.top/k8s/Kubernetes%E5%AF%B9%E8%B1%A1%E4%B9%8BPersistentVolume/</id>
    <published>2020-05-14T09:14:11.000Z</published>
    <updated>2020-10-10T07:03:43.839Z</updated>
    
    <content type="html"><![CDATA[<div class="note primary">            <p>学习本节内容前，希望你已经对Kubernetes中Volume的概念有了初步的了解，具体请参考这篇文章：</p><ul><li>[Kubernetes基本概念之Volume]</li></ul>          </div><a id="more"></a><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Kubernetes的pod本身是无状态的（stateless）,生命周期通常比较短，只要出现了异常，Kubernetes就会自动创建一个新的Pod来代替它。</p><p>而容器产生的数据，会随着Pod消亡而自动消失。</p><p>为了实现Pod内数据的存储管理，Kubernetes引入了两个API资源：Persistent Volume（持久卷，以下简称PV）和Persistent Volume Claim（持久卷申请，以下简称PVC）。</p><h2 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h2><ul><li><p>PV是Kubernetes集群中的一种网络存储实现，跟Node一样，也是属于集群的资源。</p></li><li><p>PV跟Docker里的Volume(卷)类似，不过会有独立于Pod的生命周期。</p></li><li><p>PersistentVolume和Volume一样，代表了集群中的一块存储区域，然而Kubernetes将PersistentVolume抽象成了一种集群资源，类似于集群中的Node对象，这意味着我们可以使用Kubernetes API来创建PersistentVolume对象。</p></li><li><p>PV与Volume最大的不同是PV拥有着独立于Pod的生命周期。</p><h3 id="PVC"><a href="#PVC" class="headerlink" title="PVC"></a>PVC</h3><p>PersistentVolumeClaim（PVC）代表了用户对PV资源的请求。用户需要使用PV资源时，只需要创建一个PVC对象（包括指定使用何种存储资源，使用多少GB，以何种模式使用PV等信息），Kubernetes会自动为我们分配我们所需的PV。</p></li></ul><p>如果把PersistentVolume类比成集群中的Node，那么PersistentVolumeClaim就相当于集群中的Pod，Kubernetes为Pod分配可用的Node，为PersistentVolumeClaim分配可用的PersistentVolume。</p><h1 id="1-PV的静态创建"><a href="#1-PV的静态创建" class="headerlink" title="1. PV的静态创建"></a>1. PV的静态创建</h1><p>首先是一个创建PV的简单例子：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv0003</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">slow</span></span><br><span class="line">  <span class="attr">mountOptions:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hard</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">nfsvers=4.1</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/tmp</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.2</span></span><br></pre></td></tr></table></figure><p>PV 的访问模式（accessModes）有三种：</p><ol><li>ReadWriteOnce（RWO）：是最基本的方式，可读可写，但只支持被单个 Pod 挂载。</li><li>ReadOnlyMany（ROX）：可以以只读的方式被多个 Pod 挂载。</li><li>ReadWriteMany（RWX）：这种存储可以以读写的方式被多个 Pod 共享。<br>不是每一种PV都支持这三种方式，例如ReadWriteMany，目前支持的还比较少。在 PVC 绑定 PV 时通常根据两个条件来绑定，一个是存储的大小，另一个就是访问模式。</li></ol><p>PV 的回收策略（persistentVolumeReclaimPolicy，即 PVC 释放卷的时候 PV 该如何操作）也有三种：</p><ul><li>Retain，不清理, 保留 Volume（需要手动清理）</li><li>Recycle，删除数据，即 rm -rf /thevolume/*（只有 NFS 和 HostPath 支持）</li><li>Delete，删除存储资源，比如删除 AWS EBS 卷（只有 AWS EBS, GCE PD, Azure Disk 和 Cinder 支持）</li></ul><p>PVC释放卷是指用户删除一个PVC对象时，那么与该PVC对象绑定的PV就会被释放。</p><p>1.1 PV支持的类型<br>定义PV时，我们需要指定其底层存储的类型，例如上文中创建的PV，底层使用nfs存储。目前Kuberntes支持以下类型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">GCEPersistentDisk</span><br><span class="line">AWSElasticBlockStore</span><br><span class="line">AzureFile</span><br><span class="line">AzureDisk</span><br><span class="line">FC (Fibre Channel)**</span><br><span class="line">FlexVolume</span><br><span class="line">Flocker</span><br><span class="line">NFS</span><br><span class="line">iSCSI</span><br><span class="line">RBD (Ceph Block Device)</span><br><span class="line">CephFS</span><br><span class="line">Cinder (OpenStack block storage)</span><br><span class="line">Glusterfs</span><br><span class="line">VsphereVolume</span><br><span class="line">Quobyte Volumes</span><br><span class="line">HostPath (Single node testing only – local storage is not supported in any way and WILL NOT WORK in a multi-node cluster)</span><br><span class="line">VMware Photon</span><br><span class="line">Portworx Volumes</span><br><span class="line">ScaleIO Volumes</span><br><span class="line">StorageOS</span><br></pre></td></tr></table></figure><h1 id="2-PVC的创建"><a href="#2-PVC的创建" class="headerlink" title="2. PVC的创建"></a>2. PVC的创建</h1><p>当我们定义好一个PV后，我们希望像使用Volume那样使用这个PV，那么我们需要做的就是创建一个PVC对象，并在Pod定义中使用这个PVC。<br>定义一个PVC：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myclaim</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">8Gi</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">slow</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">release:</span> <span class="string">"stable"</span></span><br></pre></td></tr></table></figure><p>Pod通过挂在Volume的方式应用PVC：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mypod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myfrontend</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">dockerfile/nginx</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">"/var/www/html"</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">mypd</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mypd</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">myclaim</span></span><br></pre></td></tr></table></figure><p>下面简要分析一下定义的PVC文件的关键：</p><ul><li>首先关注这个配置：storageClassName: slow。此配置用于绑定PVC和PV。这表明这个PVC希望使用storageClassName=slow的PV。返回到上文中PV的定义，我们可以看到PV定义中也包含storageClassName=slow的配置。</li><li>接下来是accessModes = ReadWriteOnce。这表明这个PV希望使用storageClassName=slow，并且accessModes = ReadWriteOnce的PV。</li><li>在上述条件都满足后，PVC还可以指定PV必须满足的Label，如matchLabels: release: “stable”。这表明此PVC希望使用storageClassName=slow，accessModes = ReadWriteOnce并且拥有Label：release: “stable”的PV。</li><li>最后是storage: 8Gi。这表明此PVC希望使用8G的Volume资源。</li></ul><p>通过上面的分析，我们可以看到PVC和PV的绑定，不是简单的通过Label来进行。而是要综合storageClassName，accessModes，matchLabels以及storage来进行绑定。</p><h1 id="3-PV的动态创建"><a href="#3-PV的动态创建" class="headerlink" title="3. PV的动态创建"></a>3. PV的动态创建</h1><p>上文中我们通过PersistentVolume描述文件创建了一个PV。这样的创建方式我们成为静态创建。这样的创建方式有一个弊端，那就是假如我们创建PV时指定大小为50G，而PVC请求80G的PV，那么此PVC就无法找到合适的PV来绑定。因此产生了了PV的动态创建。</p><p>PV的动态创建依赖于StorageClass对象。我们不需要手动创建任何PV，所有的工作都由StorageClass为我们完成。一个例子如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">slow</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/aws-ebs</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">io1</span></span><br><span class="line">  <span class="attr">zones:</span> <span class="string">us-east-1d,</span> <span class="string">us-east-1c</span></span><br><span class="line">  <span class="attr">iopsPerGB:</span> <span class="string">"10"</span></span><br></pre></td></tr></table></figure><p>这个例子使用AWS提供的插件（ kubernetes.io/aws-ebs）创建了一个基于AWS底层存储的StorageClass。这意味着使用这个StorageClass，那么所有的PV都是AWSElasticBlockStore类型的。</p><p>StorageClass的定义包含四个部分：</p><ul><li>provisioner：指定 Volume 插件的类型，包括内置插件（如 kubernetes.io/aws-ebs）和外部插件（如 external-storage 提供的 ceph.com/cephfs）。</li><li>mountOptions：指定挂载选项，当 PV 不支持指定的选项时会直接失败。比如 NFS 支持 hard 和 nfsvers=4.1 等选项。</li><li>parameters：指定 provisioner 的选项，比如 kubernetes.io/aws-ebs 支持 type、zone、iopsPerGB 等参数。</li><li>reclaimPolicy：指定回收策略，同 PV 的回收策略。</li></ul><p>手动创建的PV时，我们指定了storageClassName=slow的配置项，然后Pod定义中也通过指定storageClassName=slow，从而完成绑定。而通过StorageClass实现动态PV时，我们只需要指定StorageClass的metadata.name。</p><p>回到上文中创建PVC的例子，此时PVC指定了storageClassName=slow。那么Kubernetes会在集群中寻找是否存在metadata.name=slow的StorageClass，如果存在，此StorageClass会自动为此PVC创建一个accessModes = ReadWriteOnce，并且大小为8GB的PV。</p><p>通过StorageClass的使用，使我们从提前构建静态PV池的工作中解放出来。</p><h1 id="4-PV的生命周期"><a href="#4-PV的生命周期" class="headerlink" title="4. PV的生命周期"></a>4. PV的生命周期</h1><p>PV的生命周期包括 6 个阶段：</p><ol><li>Provisioning，即 PV 的创建，可以直接创建 PV（静态方式），也可以使用 StorageClass 动态创建</li><li>Binding，将 PV 分配给 PVC</li><li>Using，Pod 通过 PVC 使用该 Volume，并可以通过准入控制 StorageProtection（1.9及以前版本为PVCProtection）阻止删除正在使用的 PVC</li><li>Releasing，Pod 释放 Volume 并删除 PVC</li><li>Reclaiming，回收 PV，可以保留 PV 以便下次使用，也可以直接从云存储中删除</li><li>Deleting，删除 PV 并从云存储中删除后段存储<br>根据这 6 个阶段，PV 的状态有以下 4 种</li></ol><ul><li>Available：可用</li><li>Bound：已经分配给 PVC</li><li>Released：PVC 解绑但还未执行回收策略</li><li>Failed：发生错误</li></ul><p>一个PV从创建到销毁的具体流程如下：</p><ol><li>一个PV创建完后状态会变成Available，等待被PVC绑定。</li><li>一旦被PVC邦定，PV的状态会变成Bound，就可以被定义了相应PVC的Pod使用。</li><li>Pod使用完后会释放PV，PV的状态变成Released。</li><li>变成Released的PV会根据定义的回收策略做相应的回收工作。有三种回收策略，Retain、Delete 和 Recycle。<ul><li>Retain就是保留现场，K8S什么也不做，等待用户手动去处理PV里的数据，处理完后，再手动删除PV。</li><li>Delete 策略，K8S会自动删除该PV及里面的数据。</li><li>Recycle方式，K8S会将PV里的数据删除，然后把PV的状态变成Available，又可以被新的PVC绑定使用。</li></ul></li></ol><h1 id="5-DefaultStorageClass"><a href="#5-DefaultStorageClass" class="headerlink" title="5. DefaultStorageClass"></a>5. DefaultStorageClass</h1><p>前面我们说到，PVC和PV的绑定是通过StorageClassName进行的。然而如果定义PVC时没有指定StorageClassName呢？这取决与admission插件是否开启了DefaultDefaultStorageClass功能：</p><p>如果DefaultStorageClass功能开启，那么此PVC的StorageClassName就会被指定为DefaultStorageClass。DefaultStorageClass从何处而来呢？原来在定义StorageClass时，可以在Annotation中添加一个键值对：storageclass.kubernetes.io/is-default-class: true，那么此StorageClass就变成默认的StorageClass了。</p><p>如果DefaultStorageClass功能没有开启，那么没有指定StorageClassName的PVC只能被绑定到同样没有指定StorageClassName的PV。</p><h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ol><li><a href="../pod-has-unbound-PersistentVolumeClaims">pod has unbound immediate PersistentVolumeClaims</a></li></ol><p>参考文章<br><a href="http://blog.csdn.net/liukuan73/article/details/60089305" target="_blank" rel="noopener">http://blog.csdn.net/liukuan73/article/details/60089305</a><br><a href="https://www.jianshu.com/p/99e610067bc8" target="_blank" rel="noopener">https://www.jianshu.com/p/99e610067bc8</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;note primary&quot;&gt;
            &lt;p&gt;学习本节内容前，希望你已经对Kubernetes中Volume的概念有了初步的了解，具体请参考这篇文章：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;[Kubernetes基本概念之Volume]&lt;/li&gt;&lt;/ul&gt;
          &lt;/div&gt;
    
    </summary>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/categories/system-architecture/"/>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/tags/system-architecture/"/>
    
  </entry>
  
  <entry>
    <title>Linux下部署NFS服务</title>
    <link href="https://www.alan87.top/web/Linux%E4%B8%8B%E9%83%A8%E7%BD%B2NFS%E6%9C%8D%E5%8A%A1/"/>
    <id>https://www.alan87.top/web/Linux%E4%B8%8B%E9%83%A8%E7%BD%B2NFS%E6%9C%8D%E5%8A%A1/</id>
    <published>2020-05-14T08:07:21.000Z</published>
    <updated>2020-10-10T07:03:43.945Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一-、-NFS-简介和架构图"><a href="#一-、-NFS-简介和架构图" class="headerlink" title="一 、 NFS 简介和架构图"></a>一 、 NFS 简介和架构图</h1><p>NFS是Network File System的缩写，即网络文件系统。一种使用于分散式文件协定，功能是通过网络让不同的机器、不同的操作系统能够分享个人数据，让应用程序通过网络可以访问位于服务器磁盘中的数据。</p><a id="more"></a><p>NFS在文件传送或信息传送的过过程中，依赖于RPC协议。RPC，远程过程调用（Remote Procedure Call）,是使客户端能够执行其他系统中程序的一种机制。NFS本身是没有提供信息传输的协议和功能的，但NFS却能让我们通过网络进行资料的分享，就是因为NFS使用了RPC提供的传输协议，可以说NFS就是使用PRC的一个程序。</p><p>NFS 存储 服务器主要用于用户上传的数据 ，图片  音频 、等信息 </p><p>NFS服务端、RPC协议、客户端三者可以理解为房源、中介、租客之间的关系：<br><img data-src="https://img-blog.csdn.net/2018062513544128?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzQxMDc1MTQ2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><h1 id="二、NFS-适用场景-；"><a href="#二、NFS-适用场景-；" class="headerlink" title="二、NFS 适用场景 ；"></a>二、NFS 适用场景 ；</h1><ul><li>2.1 NFS  最好是部署在局域网 ，不要在公网上  ；</li><li>2.2 NFS  只能在 linux 上使用 （如果想让 windows 和 Linux 之间实现数据共享建议使用  FTP 或者  samba）；</li><li>2.3 NFS 适合在中小型企业使用  ；</li></ul><h1 id="三、"><a href="#三、" class="headerlink" title="三、"></a>三、</h1><ul><li>NFS  服务端干的三件事 <ol><li>启动RPC服务</li><li>启动NFS服务</li><li>向中介注册一次</li></ol></li><li>NFS 客户端干的三件事  <ol><li>启动RPC服务</li><li>mount命令挂载</li><li>向对端rpcbind请求NFS Server端口，NFS服务答复端口信息</li></ol></li></ul><p>==========================NFS 部署  环境准备=========================</p><h1 id="四、服务端配置"><a href="#四、服务端配置" class="headerlink" title="四、服务端配置"></a>四、服务端配置</h1><p> 环境准备2台  CentOS 7.5 ，IP可以自定义 ；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># cat /etc/redhat-release </span></span><br><span class="line"> CentOS release 7.5 (Final)</span><br></pre></td></tr></table></figure><h1 id="五、检查系统中是否安装-NFS-和-RPC-，并进行安装NFS-和RPC；"><a href="#五、检查系统中是否安装-NFS-和-RPC-，并进行安装NFS-和RPC；" class="headerlink" title="五、检查系统中是否安装 NFS 和 RPC ，并进行安装NFS 和RPC；"></a>五、检查系统中是否安装 NFS 和 RPC ，并进行安装NFS 和RPC；</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># rpm -qa nfs-utils rpcbind</span></span><br><span class="line">rpcbind-0.2.0-13.el6.x86_64</span><br><span class="line">nfs-utils-1.2.3-75.el6.x86_64</span><br><span class="line"></span><br><span class="line">[root@NFS ~]<span class="comment"># yum -y install nfs-utils rpcbind    #使用 yum 安装nfs 和 rpc </span></span><br><span class="line">已加载插件：fastestmirror</span><br><span class="line">设置安装进程</span><br><span class="line">Determining fastest mirrors</span><br><span class="line"> * base: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * extras: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">base                                                                                                                         | 3.7 kB     00:00     </span><br><span class="line">extras                                                                                                                       | 3.4 kB     00:00     </span><br><span class="line">extras/primary_db   </span><br><span class="line">```                          </span><br><span class="line"><span class="comment"># 六、在服务端 创建共享目录/data/nfs/，并且属主和属组都为：nfsnobody，其中nfsnobody是安装nfs服务时默认的用户；</span></span><br><span class="line">```bash</span><br><span class="line">[root@NFS ~]<span class="comment"># mkdir -p /data/nfs/</span></span><br><span class="line">[root@NFS ~]<span class="comment">#  chown -R nfsnobody.nfsnobody /data/nfs/</span></span><br><span class="line">[root@NFS ~]<span class="comment"># chmod 666 /data/nfs/</span></span><br><span class="line">[root@NFS ~]<span class="comment"># ll /data/</span></span><br><span class="line">总用量 4</span><br><span class="line">drw-rw-rw-. 2 nfsnobody nfsnobody 4096 6月  27 06:17 nfs</span><br></pre></td></tr></table></figure><h1 id="七、编辑配置-NFS-配置文件-；"><a href="#七、编辑配置-NFS-配置文件-；" class="headerlink" title="七、编辑配置 NFS 配置文件 ；"></a>七、编辑配置 NFS 配置文件 ；</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># cat &gt;&gt;/etc/exports&lt;&lt;EOF </span></span><br><span class="line">&gt; /data/nfs 172.16.1.0/24(rw,sync)</span><br><span class="line">&gt; EOF</span><br><span class="line">[root@NFS ~]<span class="comment"># cat /etc/exports </span></span><br><span class="line">/data/nfs 172.16.1.0/24(rw,sync)</span><br><span class="line">``` </span><br><span class="line">其中：/data/nfs 是服务器端共享的目录 </span><br><span class="line">      172.16.1.0/24共享目录的客户端ip地址 </span><br><span class="line">      (rw,sync) ，其中rw代表拥有读写的权限，sync代表数据同步写入NFS服务器端的硬盘中。</span><br><span class="line">      也可以用async，async是大数据时使用，是先写到缓存区，再写到磁盘里。</span><br><span class="line">```bash</span><br><span class="line">[root@NFS ~]<span class="comment"># exportfs -r                           #让配置文件生效</span></span><br></pre></td></tr></table></figure><h1 id="八、启动RPC-和-NFS-服务"><a href="#八、启动RPC-和-NFS-服务" class="headerlink" title="八、启动RPC 和 NFS 服务"></a>八、启动RPC 和 NFS 服务</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># /etc/init.d/rpcbind start          # 先启动rpc  </span></span><br><span class="line">[root@NFS ~]<span class="comment"># /etc/init.d/nfs start                  #启动NFS</span></span><br><span class="line">[root@NFS ~]<span class="comment"># /etc/init.d/rpcbind status        #查看一下 rpc 的运行状态 </span></span><br><span class="line">rpcbind (pid  27193) 正在运行...</span><br><span class="line">[root@NFS ~]<span class="comment"># /etc/init.d/nfs status               #查看一下 nfs 的运行状态 </span></span><br><span class="line">rpc.mountd (pid 27337) 正在运行...</span><br><span class="line">nfsd (pid 27353 27352 27351 27350 27349 27348 27347 27346) 正在运行...</span><br></pre></td></tr></table></figure><h1 id="九、查看NFS服务是否向rpc注册端口信息，主端口号是：111"><a href="#九、查看NFS服务是否向rpc注册端口信息，主端口号是：111" class="headerlink" title="九、查看NFS服务是否向rpc注册端口信息，主端口号是：111"></a>九、查看NFS服务是否向rpc注册端口信息，主端口号是：111</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># rpcinfo -p localhost</span></span><br><span class="line">    program vers proto   port  service</span><br><span class="line">    100000    4   tcp    111  portmapper</span><br><span class="line">    100000    3   tcp    111  portmapper</span><br><span class="line">    100000    2   tcp    111  portmapper</span><br><span class="line">    100000    4   udp    111  portmapper</span><br><span class="line">    100000    3   udp    111  portmapper</span><br><span class="line">    100000    2   udp    111  portmapper</span><br><span class="line">    100005    1   udp  46776  mountd</span><br><span class="line">    100005    1   tcp  58319  mountd</span><br><span class="line">    100005    2   udp  45857  mountd</span><br><span class="line">    100005    2   tcp  40719  mountd</span><br><span class="line">    100005    3   udp  48297  mountd</span><br><span class="line">    100005    3   tcp  56860  mountd</span><br></pre></td></tr></table></figure><p>选项与参数：<br>-p ：针对某 IP (未写则预设为本机) 显示出所有的 port 与 porgram 的信息；<br>-t ：针对某主机的某支程序检查其 TCP 封包所在的软件版本；<br>-u ：针对某主机的某支程序检查其 UDP 封包所在的软件版本；</p><h1 id="十-、在NFS设定妥当之后，可以先在服务端自我测试一下是否可以联机！利用-showmount-这个指令来查看！"><a href="#十-、在NFS设定妥当之后，可以先在服务端自我测试一下是否可以联机！利用-showmount-这个指令来查看！" class="headerlink" title="十 、在NFS设定妥当之后，可以先在服务端自我测试一下是否可以联机！利用 showmount 这个指令来查看！"></a>十 、在NFS设定妥当之后，可以先在服务端自我测试一下是否可以联机！利用 showmount 这个指令来查看！</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># showmount -e localhost</span></span><br><span class="line">Export list <span class="keyword">for</span> localhost:</span><br><span class="line">/data/nfs 172.16.1.0/24</span><br><span class="line">[root@NFS ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>选项与参数：<br>   -a ：显示目前主机与客户端的 NFS 联机分享的状态；<br>   -e ：显示某部主机的 /etc/exports 所分享的目录数据。<br>参数说明：<br>  #rpcinfo  -p     检查nfs服务是否有注册端口信息<br>  #showmount -e    检查共享目录信息 </p><h1 id="十一-、设置服务为开机自启-；"><a href="#十一-、设置服务为开机自启-；" class="headerlink" title="十一 、设置服务为开机自启 ；"></a>十一 、设置服务为开机自启 ；</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@NFS ~]<span class="comment"># chkconfig nfs on</span></span><br><span class="line">[root@NFS ~]<span class="comment"># chkconfig --list nfs</span></span><br><span class="line">nfs            0:关闭1:关闭2:启用3:启用4:启用5:启用6:关闭</span><br><span class="line">[root@NFS ~]<span class="comment"># chkconfig --list rpcbind</span></span><br><span class="line">rpcbind        0:关闭1:关闭2:启用3:启用4:启用5:启用6:关闭</span><br><span class="line">[root@NFS ~]<span class="comment"># </span></span><br><span class="line"></span><br><span class="line">[root@NFS ~]<span class="comment"># tail -2 /etc/rc.local           #加入到开机自启中 </span></span><br><span class="line">/etc/init.d/rpcbind start </span><br><span class="line">/etc/init.d/nfs  start</span><br><span class="line">[root@NFS ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>==========================客户端配置=============================</p><h1 id="一-、查看系统中是否有-nfs-和rpc"><a href="#一-、查看系统中是否有-nfs-和rpc" class="headerlink" title="一 、查看系统中是否有 nfs 和rpc"></a>一 、查看系统中是否有 nfs 和rpc</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@rsync ~]<span class="comment">#  rpm -qa nfs-utils rpcbind</span></span><br><span class="line"></span><br><span class="line">rpcbind-0.2.0-13.el6.x86_64</span><br><span class="line">nfs-utils-1.2.3-75.el6.x86_64</span><br></pre></td></tr></table></figure><h1 id="二-、进行安装服务，并启动服务-；"><a href="#二-、进行安装服务，并启动服务-；" class="headerlink" title="二 、进行安装服务，并启动服务  ；"></a>二 、进行安装服务，并启动服务  ；</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@rsync ~]<span class="comment"># yum -y install nfs-utils rpcbind</span></span><br><span class="line">已加载插件：fastestmirror</span><br><span class="line">设置安装进程</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.huaweicloud.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">base                                                                                                                         | 3.7 kB     00:00     </span><br><span class="line">extras                                                                                                                       | 3.4 kB     00:00     </span><br><span class="line">updates                                                                                                                      | 3.4 kB     00:00     </span><br><span class="line">包 1:nfs-utils-1.2.3-75.el6_9.x86_64 已安装并且是最新版本</span><br></pre></td></tr></table></figure><p>解决依赖关系</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@rsync ~]<span class="comment"># /etc/init.d/rpcbind start</span></span><br><span class="line">[root@rsync ~]<span class="comment"># /etc/init.d/nfs start</span></span><br><span class="line">启动 NFS 服务：                                            [确定]</span><br><span class="line">启动 NFS mountd：                                          [确定]</span><br><span class="line">启动 NFS 守护进程：                                        [确定]</span><br><span class="line">正在启动 RPC idmapd：                                      [确定]</span><br></pre></td></tr></table></figure><h1 id="三-、创建挂载目录-；"><a href="#三-、创建挂载目录-；" class="headerlink" title="三 、创建挂载目录  ；"></a>三 、创建挂载目录  ；</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@rsync]<span class="comment"># mkdir -p /data/nfs</span></span><br></pre></td></tr></table></figure><h1 id="四-、查看客户端是否可以收到服务端的共享信息-；"><a href="#四-、查看客户端是否可以收到服务端的共享信息-；" class="headerlink" title="四 、查看客户端是否可以收到服务端的共享信息 ；"></a>四 、查看客户端是否可以收到服务端的共享信息 ；</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@rsync nfs]<span class="comment"># showmount -e 172.16.1.9</span></span><br><span class="line">Export list <span class="keyword">for</span> 172.16.1.9:</span><br><span class="line">/data/nfs 172.16.1.0/24</span><br></pre></td></tr></table></figure><h1 id="五-、进行nfs-共享目录的挂载-；"><a href="#五-、进行nfs-共享目录的挂载-；" class="headerlink" title="五 、进行nfs 共享目录的挂载 ；"></a>五 、进行nfs 共享目录的挂载 ；</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@rsync nfs]<span class="comment"># mount -t nfs 172.16.1.9:/data/nfs /mnt</span></span><br><span class="line"></span><br><span class="line">[root@rsync nfs]<span class="comment"># df -h</span></span><br><span class="line">Filesystem        Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda2          20G  2.7G   16G  15% /</span><br><span class="line">tmpfs             931M     0  931M   0% /dev/shm</span><br><span class="line">/dev/sda1         190M   39M  141M  22% /boot</span><br><span class="line">172.16.1.9:/data/nfs    20G  2.7G   16G  15% /mnt</span><br></pre></td></tr></table></figure><p>服务端 ；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@NFS nfs]<span class="comment"># echo "nfs" &gt; test.txt</span></span><br></pre></td></tr></table></figure><p>客户端创建一个文件 ；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@rsync data]<span class="comment"># cat /data/nfs/test.txt</span></span><br><span class="line">nfs</span><br></pre></td></tr></table></figure><p>########################### nfs常见问题排错思 ############################### </p><ul><li>nfs共享目录权限相关因素<br>①. 配置文件中的权限指定<br>②. 共享目录本身的权限，有w权限<br>③. 共享目录本身的所属用户与所属组的权限指定</li></ul><p>#########################  NFS客户端挂载排错思路  ###########################<br>客户端排查三部曲<br>①. 检查服务端房源信息是否还在<br>    rpcinfo -p 172.16.1.9<br>②. 检查服务端共享目录信息是否存在<br>    showmount -e 172.16.1.9<br>③. 直接进行目录挂载测试<br>    mount -t nfs 172.16.1.9:/data /mnt</p><p>#########################  服务端排查三部曲  #################################<br>①. 检查服务端房源信息是否还在<br>    rpcinfo -p localhost<br>    如果没有注册的房源信息了，会是什么情况？<br>    ①. nfs服务没有启动<br>    ②. nfs服务于rpc服务启动顺序不正确<br>②. 检查服务端共享目录信息是否存在<br>    showmount -e localhost<br>    ①. nfs配置文件编写格式错误<br>③. 直接进行目录挂载测试<br>    mount -t nfs 172.16.1.9:/data /mnt</p><h1 id="实现nfs客户端开机自动挂载方式"><a href="#实现nfs客户端开机自动挂载方式" class="headerlink" title="实现nfs客户端开机自动挂载方式"></a>实现nfs客户端开机自动挂载方式</h1><p>①. 将挂在命令追加到/etc/rc.local开机自启动文件中<br>②. 编写fstab文件，并且需要配合netfs服务使用，实现开机自动挂载</p><h3 id="nfs常见问题排错"><a href="#nfs常见问题排错" class="headerlink" title="nfs常见问题排错"></a>nfs常见问题排错</h3><p>示例1：客户端挂载报错“No such file or directory”<br>[root@nfs-client ~]# showmount -e 172.16.1.9<br>Export list for 172.16.1.9:<br>/data    172.16.1.0/24<br>[root@nfs-client ~]# mount -t nfs 172.16.1.9:/data /mnt<br>mount.nfs: mounting 172.16.1.9:/data failed, reason given by server: No such file or directory<br>解答：原因是NFS服务器端没有共享目录/data，创建即可。命令如下：<br>[root@nfs-server ~]# mkdir /data</p><p>示例2：NFS服务器端启动失败，如下：<br>[root@nfs-server ~]# /etc/init.d/nfs start<br>Starting NFS services:                                [  OK  ]<br>Starting NFS quotas: Cannot register service: RPC: Unable to receive; errno = Connection refused<br>rpc.rquotad: unable to register (RQUOTAPROG, RQUOTAVERS, udp).<br>                                                     [FAILED]<br>Starting NFS mountd:                                [FAILED]<br>Starting NFS daemon: rpc.nfsd: writing fd to kernel failed: errno 111 (Connection refused)<br>rpc.nfsd: unable to set any sockets for nfsd<br>                                                     [FAILED]<br>解答：这是因为RPC服务没有在NFS前面启动，需要先启动RPC服务再启动NFS，解决方法为，按顺序启动rpcbind及NFS，命令如下：<br>[root@nfs-server ~]# /etc/init.d/rpcbind restart<br>[root@nfs-server ~]# /etc/init.d/nfs restart</p><p>示例3：注册RPC服务失败，出现failed：RPC Error：Program not registered错误。<br>[root@nfs-client ~]# mount -t nfs 172.16.1.9:/data /mnt<br>mount.nfs: requested NFS version or transport protocol is not supported<br>[root@nfs-client ~]# showmount -e 172.16.1.9<br>clnt_create: RPC: Program not registered<br>解答：服务器端的NFS没有启动，客户端没有收到服务器端发来的随机端口信息。<br>解决方法如下：<br>[root@nfs-server ~]# /etc/init.d/rpcbind restart<br>[root@nfs-server ~]# /etc/init.d/nfs restart</p><p>示例4：卸载挂载设备时显示device is busy。<br>[root@nfs-client mnt]# umount /mnt<br>umount.nfs: /mnt: device is busy<br>umount.nfs: /mnt: device is busy<br>解答：有可能是当前目录就是挂载的NFS目录（/mnt），也有可能是NFS Server挂了。对于第一种情况，解决办法为退出挂载目录/mnt，再执行umount /mnt卸载。对于第二种情况，NFS Server挂了，NFS Client就会出现问题（df -h窗口会死掉），这时只能强制卸载，方法为：<br>umount -lf /mnt     其中的参数-f为强制卸载，参数-l为懒惰的卸载。</p><p>示例5：CentOS 6.6客户端NFS挂载时遇到问题。<br>[root@nfs-client ~]# mount -t nfs 172.16.1.9:/data /mnt<br>mount：wrong fs type，bad option，bad option，bad superblock on 10.0.0.7:/data,<br>   missing codepage or helper program，or other error<br>   (for several filesystems (e.g. nfs, cifs) you might<br>need a /sbin/mount.<type> helper program )<br>In some cases useful info is found in syslog - try<br>meg | tail or so<br>排查思路：同样的机器，NFS服务器本地可以挂载，但是客户端挂载时wrong fs type，因此尝试所有客户端安装nfs-utils。CentOS6.5及以前的NFS没有遇到这个问题。<br>解决方法：执行yum install nfs-utils -y，客户端安装NFS软件，但不启动服务。</p><p>示例六：共享目录挂载很卡<br>mount -t nfs 172.16.1.9:/data /mnt<br>cd /mnt<br>time touch test.txt<br>原因分析：<br>    NFS服务端重启之后。立刻进行挂载会出现此问题，因为NFS自身重启的时候，拥有无敌的时间，默认是90秒；在无敌时间内，是不能对共享目录进行更改的操作；<br>    在系统配置中/etc/sysconfig/nfs中指定了无敌时间的配置参数<br>NFSD_V4_GRACE=90<br>NFSD_V4_LEASE=90<br>NLM_GRACE_PERI0D=90<br>find /proc -name | grep -i ” NLM_GRACE_PERIOD”<br>find /proc -iname ” NLM_GRACE_PERIOD”<br>    重启NFS服务没有按照顺序进行重启，一旦NFS重启了，需要确认rpcbind服务有没有接收，即rpcinfo -p localhost；先启动rpcbind服务再启动nfs服务</p><p>示例七：ls: cannot open directory .: Stale file handle<br>Stale file handle<br>客户端报错<br>mount -t nfs 172.16.1.9:/data  /mnt<br>mount.nfs: Stale file handle<br>服务端挂载报错<br>[root@nfs01 data]# mount -t nfs 172.16.1.9:/data /mnt/<br>mount.nfs: access denied by server while mounting 172.16.1.9:/data<br>查看配置文件发现<br>[root@nfs01 data]# cat /etc/exports<br>#share /data  by lidao  at 20160913<br>/data 173.16.1.0/24(rw,sync)<br>原因分析：</p><ul><li>/proc/mounts客户端挂载文件中已经存在了相应的挂载记录，没有正确卸载掉，就再次进行挂载，就会出现以上错误。</li></ul><h1 id="挂载腾讯CFS"><a href="#挂载腾讯CFS" class="headerlink" title="挂载腾讯CFS"></a>挂载腾讯CFS</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install nfs-utils</span><br><span class="line">[root@node1 ~]<span class="comment"># mkdir /alan</span></span><br><span class="line">[root@node1 ~]<span class="comment"># mount -t nfs -o vers=4.0 挂载点IP:/ 待挂载目标目录</span></span><br></pre></td></tr></table></figure><ul><li>挂载点IP：指创建文件系统时，自动的生成的挂载点 IP。</li><li>目前默认挂载的是文件系统的根目录/。 在文件系统中创建子目录后，可以挂载该子目录。</li><li>待挂载目标目录： 在当前服务器上，需要挂载的目标目录，需要用户事先创建。<div class="note warning">            <p>注意：<br>&lt;挂载点IP&gt;:/与&lt;待挂载目标目录&gt;之间有一个空格。</p>          </div></li></ul><p>参考:<br><a href="https://blog.csdn.net/sinat_41075146/article/details/80800812" target="_blank" rel="noopener">https://blog.csdn.net/sinat_41075146/article/details/80800812</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一-、-NFS-简介和架构图&quot;&gt;&lt;a href=&quot;#一-、-NFS-简介和架构图&quot; class=&quot;headerlink&quot; title=&quot;一 、 NFS 简介和架构图&quot;&gt;&lt;/a&gt;一 、 NFS 简介和架构图&lt;/h1&gt;&lt;p&gt;NFS是Network File System的缩写，即网络文件系统。一种使用于分散式文件协定，功能是通过网络让不同的机器、不同的操作系统能够分享个人数据，让应用程序通过网络可以访问位于服务器磁盘中的数据。&lt;/p&gt;
    
    </summary>
    
    
      <category term="其他" scheme="https://www.alan87.top/categories/other/"/>
    
    
      <category term="其他" scheme="https://www.alan87.top/tags/other/"/>
    
  </entry>
  
  <entry>
    <title>Ingress对外暴露端口</title>
    <link href="https://www.alan87.top/k8s/Ingress%E5%AF%B9%E5%A4%96%E6%9A%B4%E9%9C%B2%E7%AB%AF%E5%8F%A3/"/>
    <id>https://www.alan87.top/k8s/Ingress%E5%AF%B9%E5%A4%96%E6%9A%B4%E9%9C%B2%E7%AB%AF%E5%8F%A3/</id>
    <published>2020-05-14T06:46:38.000Z</published>
    <updated>2020-10-10T07:03:43.837Z</updated>
    
    <content type="html"><![CDATA[<h1 id="http-https端口"><a href="#http-https端口" class="headerlink" title="http,https端口"></a>http,https端口</h1><a id="more"></a><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">"nginx"</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">"HTTPS"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks.hongda.com</span></span><br><span class="line">    <span class="attr">secretName:</span> <span class="string">hongda-com-tls-secret</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">ks.hongda.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">443</span></span><br></pre></td></tr></table></figure><p>执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f ingress-kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><h1 id="具体说明"><a href="#具体说明" class="headerlink" title="具体说明"></a>具体说明</h1><ul><li>kubernetes.io/ingress.class: “nginx”：Inginx Ingress Controller 根据该注解自动发现 Ingress；</li><li>nginx.ingress.kubernetes.io/backend-protocol: Controller 向后端 Service 转发时使用 HTTPS 协议</li><li>secretName: kube-dasboard-ssl：https 证书 Secret；</li><li>host: ks.hongda.com：对外访问的域名；</li><li>serviceName: kubernetes-dashboard：集群对外暴露的 Service 名称；</li><li>servicePort: 443：service 监听的端口；<br>注意：创建的 Ingress 必须要和对外暴露的 Service 在同一命名空间下！</li></ul><h1 id="ConfigMap暴露TCP端口"><a href="#ConfigMap暴露TCP端口" class="headerlink" title="ConfigMap暴露TCP端口"></a>ConfigMap暴露TCP端口</h1><p>Ingress 不支持TCP 和 UDP 服务，可以通过 Ingress controller 来实现</p><p>默认的yaml中已经设置：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">   <span class="attr">hostNetwork:</span> <span class="literal">true</span> <span class="comment"># &lt;--</span></span><br><span class="line">   <span class="attr">containers:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">/nginx-ingress-controller</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--configmap=$(POD_NAMESPACE)/nginx-configuration</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--tcp-services-configmap=$(POD_NAMESPACE)/tcp-services</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--udp-services-configmap=$(POD_NAMESPACE)/udp-services</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--publish-service=$(POD_NAMESPACE)/ingress-nginx</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">--annotations-prefix=nginx.ingress.kubernetes.io</span></span><br><span class="line">     <span class="attr">env:</span></span><br></pre></td></tr></table></figure><p>通过 tcp-services-configmap.yaml 设置映射tcp， 通过 udp-services-configmap.yaml 映射udp</p><ul><li>tcp-services-configmap.yaml<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tcp-services</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">2181:</span> <span class="string">"kafka/kafka-zookeeper:2181"</span></span><br><span class="line">  <span class="attr">9092:</span> <span class="string">"kafka/kafka:9092"</span></span><br></pre></td></tr></table></figure></li><li>udp-services-configmap.yaml<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">udp-services</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">53:</span> <span class="string">"kube-system/kube-dns:53"</span></span><br></pre></td></tr></table></figure><h1 id="Ingress服务公开端口"><a href="#Ingress服务公开端口" class="headerlink" title="Ingress服务公开端口"></a>Ingress服务公开端口</h1>更新Ingress安装文件<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ingress-nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">ingress-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">proxied-tcp-9000</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">9000</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9000</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/name:</span> <span class="string">ingress-nginx</span></span><br><span class="line">    <span class="attr">app.kubernetes.io/part-of:</span> <span class="string">ingress-nginx</span></span><br></pre></td></tr></table></figure></li></ul><p>更新：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade nginx-ingress stable&#x2F;nginx-ingress \</span><br><span class="line">-f ingress-nginx.yaml</span><br></pre></td></tr></table></figure><p>查看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master home]<span class="comment"># netstat -ano |grep 2181</span></span><br><span class="line">tcp        0      0 0.0.0.0:2181            0.0.0.0:*               LISTEN      off (0.00/0/0)</span><br><span class="line">tcp6       0      0 :::2181                 :::*                    LISTEN      off (0.00/0/0)</span><br></pre></td></tr></table></figure><p>这样暴露以后就可以直接调用zk,连接地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zk.hongda.com:2181</span><br><span class="line">18.16.202.163:2181</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;http-https端口&quot;&gt;&lt;a href=&quot;#http-https端口&quot; class=&quot;headerlink&quot; title=&quot;http,https端口&quot;&gt;&lt;/a&gt;http,https端口&lt;/h1&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/categories/kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s排查问题命令</title>
    <link href="https://www.alan87.top/k8s/k8s%E6%8E%92%E6%9F%A5%E9%97%AE%E9%A2%98/"/>
    <id>https://www.alan87.top/k8s/k8s%E6%8E%92%E6%9F%A5%E9%97%AE%E9%A2%98/</id>
    <published>2020-05-14T06:46:38.000Z</published>
    <updated>2020-10-10T07:03:43.840Z</updated>
    
    <content type="html"><![CDATA[<h1 id="排查问题命令"><a href="#排查问题命令" class="headerlink" title="排查问题命令"></a>排查问题命令</h1><h2 id="1-kubectl-get-events"><a href="#1-kubectl-get-events" class="headerlink" title="1. kubectl get events"></a>1. kubectl get events</h2><h2 id="2-kubectl-kubectls-describe"><a href="#2-kubectl-kubectls-describe" class="headerlink" title="2. kubectl kubectls describe"></a>2. kubectl kubectls describe</h2><h2 id="3-kubectl-logs"><a href="#3-kubectl-logs" class="headerlink" title="3. kubectl logs"></a>3. kubectl logs</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get events </span><br><span class="line">mount failed: <span class="built_in">exit</span> status 32</span><br><span class="line"></span><br><span class="line">$ kubectl kubectls describe nfs-client-provisioner-5f4c97f67c-jcprd</span><br><span class="line"><span class="comment"># kubectl logs nfs-client-provisioner-5f4c97f67c-jcprd</span></span><br><span class="line"></span><br><span class="line">Warning  Failed     11s (x2 over 16s)  kubelet, 172.16.0.17  Error: Error response from daemon: invalid volume specification: <span class="string">'/var/lib/kubelet/pods/1dadc905-1ebc-408b-ba97-5558c7ed4181/volumes/kubernetes.io~nfs/nfs-client-root:/'</span>: invalid mount config <span class="keyword">for</span> <span class="built_in">type</span> <span class="string">"bind"</span>: invalid specification: destination can<span class="string">'t be '</span>/<span class="string">'</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;排查问题命令&quot;&gt;&lt;a href=&quot;#排查问题命令&quot; class=&quot;headerlink&quot; title=&quot;排查问题命令&quot;&gt;&lt;/a&gt;排查问题命令&lt;/h1&gt;&lt;h2 id=&quot;1-kubectl-get-events&quot;&gt;&lt;a href=&quot;#1-kubectl-get-eve
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/categories/kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes部署Ingress-nginx</title>
    <link href="https://www.alan87.top/k8s/kubernetes%E9%83%A8%E7%BD%B2Ingress-nginx/"/>
    <id>https://www.alan87.top/k8s/kubernetes%E9%83%A8%E7%BD%B2Ingress-nginx/</id>
    <published>2020-05-14T05:59:55.000Z</published>
    <updated>2020-10-10T07:03:43.840Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、Ingress-简介"><a href="#一、Ingress-简介" class="headerlink" title="一、Ingress 简介"></a>一、Ingress 简介</h1><p>在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。<br>为了使外部的应用能够访问集群内的服务，<br>在Kubernetes 目前 提供了以下几种方案：</p><a id="more"></a><ul><li><p>odePort</p></li><li><p>oadBalancer</p></li><li><p>ngress</p><h2 id="1-1-Ingress-组成"><a href="#1-1-Ingress-组成" class="headerlink" title="1.1.Ingress 组成"></a>1.1.Ingress 组成</h2></li><li><p>ingress controller<br>将新加入的Ingress转化成Nginx的配置文件并使之生效</p></li><li><p>ingress service<br>将Nginx的配置抽象成一个Ingress对象，每添加一个新的服务只需写一个新的Ingress的yaml文件即可</p></li></ul><h2 id="1-2-Ingress-工作原理"><a href="#1-2-Ingress-工作原理" class="headerlink" title="1.2.Ingress 工作原理"></a>1.2.Ingress 工作原理</h2><ul><li><p>ingress controller通过和kubernetes api交互，动态的去感知集群中ingress规则变化，</p></li><li><p>然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段nginx配置，</p></li><li><p>再写到nginx-ingress-control的pod里，这个Ingress controller的pod里运行着一个Nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中，</p></li><li><p>然后reload一下使配置生效。<br>以此达到域名分配置和动态更新的问题。</p></li></ul><h2 id="1-3-Ingress-可以解决什么问题？"><a href="#1-3-Ingress-可以解决什么问题？" class="headerlink" title="1.3.Ingress 可以解决什么问题？"></a>1.3.Ingress 可以解决什么问题？</h2><ul><li>动态配置服务<br>如果按照传统方式, 当新增加一个服务时, 我们可能需要在流量入口加一个反向代理指向我们新的k8s服务. 而如果用了Ingress, 只需要配置好这个服务, 当服务启动时, 会自动注册到Ingress的中, 不需要而外的操作.</li><li>减少不必要的端口暴露<br>配置过k8s的都清楚, 第一步是要关闭防火墙的, 主要原因是k8s的很多服务会以NodePort方式映射出去, 这样就相当于给宿主机打了很多孔, 既不安全也不优雅. 而Ingress可以避免这个问题, 除了Ingress自身服务可能需要映射出去, 其他服务都不要用NodePort方式</li></ul><h2 id="1-4-Ingress当前的实现方式？"><a href="#1-4-Ingress当前的实现方式？" class="headerlink" title="1.4. Ingress当前的实现方式？"></a>1.4. Ingress当前的实现方式？</h2><p>本文使用的是基于nginx的ingress<br><img data-src="https://upload-images.jianshu.io/upload_images/13868689-6a3d9f6c3eab8d88?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt=""></p><h1 id="二、部署配置Ingress"><a href="#二、部署配置Ingress" class="headerlink" title="二、部署配置Ingress"></a>二、部署配置Ingress</h1><h2 id="2-1-部署文件介绍、准备"><a href="#2-1-部署文件介绍、准备" class="headerlink" title="2.1 部署文件介绍、准备"></a>2.1 部署文件介绍、准备</h2><h3 id="第一步：-获取配置文件位置"><a href="#第一步：-获取配置文件位置" class="headerlink" title="第一步： 获取配置文件位置"></a>第一步： 获取配置文件位置</h3><p><a href="https://github.com/kubernetes/ingress-nginx/tree/nginx-0.20.0/deploy" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx/tree/nginx-0.20.0/deploy</a></p><h3 id="第二步：-下载部署文件"><a href="#第二步：-下载部署文件" class="headerlink" title="第二步： 下载部署文件"></a>第二步： 下载部署文件</h3><p>提供了两种方式 ：</p><ul><li>默认下载最新的yaml</li><li>指定版本号下载对应的yaml</li></ul><ol><li><p>默认下载最新的yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget  https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml</span><br></pre></td></tr></table></figure></li><li><p>指定版本号下载对应的yaml<br>如下载ingress-nginx 0.17.0对应的yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget  https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.17.0/deploy/mandatory.yaml</span><br></pre></td></tr></table></figure><p><img data-src="https://upload-images.jianshu.io/upload_images/13868689-a0219fe75b7092e0?imageMogr2/auto-orient/strip%7CimageView2/2/w/587/format/webp" alt=""></p></li></ol><h3 id="部署文件介绍"><a href="#部署文件介绍" class="headerlink" title="部署文件介绍"></a>部署文件介绍</h3><ol><li>namespace.yaml<br>创建一个独立的命名空间 ingress-nginx</li><li>configmap.yaml<br>ConfigMap是存储通用的配置变量的，类似于配置文件，使用户可以将分布式系统中用于不同模块的环境变量统一到一个对象中管理；而它与配置文件的区别在于它是存在集群的“环境”中的，并且支持K8S集群中所有通用的操作调用方式。</li></ol><p>从数据角度来看，ConfigMap的类型只是键值组，用于存储被Pod或者其他资源对象（如RC）访问的信息。这与secret的设计理念有异曲同工之妙，主要区别在于ConfigMap通常不用于存储敏感信息，而只存储简单的文本信息。</p><p>ConfigMap可以保存环境变量的属性，也可以保存配置文件。</p><p>创建pod时，对configmap进行绑定，pod内的应用可以直接引用ConfigMap的配置。相当于configmap为应用/运行环境封装配置。</p><p>pod使用ConfigMap，通常用于：设置环境变量的值、设置命令行参数、创建配置文件。</p><ol start="3"><li><p>default-backend.yaml<br>如果外界访问的域名不存在的话，则默认转发到default-http-backend这个Service，其会直接返回404：</p></li><li><p>rbac.yaml<br>负责Ingress的RBAC授权的控制，其创建了Ingress用到的ServiceAccount、ClusterRole、Role、RoleBinding、ClusterRoleBinding</p></li><li><p>with-rbac.yaml<br>是Ingress的核心，用于创建ingress-controller。前面提到过，ingress-controller的作用是将新加入的Ingress进行转化为Nginx的配置</p></li></ol><h2 id="2-2-部署ingress"><a href="#2-2-部署ingress" class="headerlink" title="2.2 部署ingress"></a>2.2 部署ingress</h2><h3 id="第一步：-准备镜像，从这里mandatory-yaml查看需要哪些镜像"><a href="#第一步：-准备镜像，从这里mandatory-yaml查看需要哪些镜像" class="headerlink" title="第一步： 准备镜像，从这里mandatory.yaml查看需要哪些镜像"></a>第一步： 准备镜像，从这里mandatory.yaml查看需要哪些镜像</h3><p>已经准备好， 可以直接点击下载</p><table><thead><tr><th align="left">镜像名称</th><th align="center">版本</th><th align="left">下载地址</th></tr></thead><tbody><tr><td align="left">k8s.gcr.io/defaultbackend-amd64</td><td align="center">1.5</td><td align="left">registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/defaultbackend-amd64</td></tr><tr><td align="left">quay.io/kubernetes-ingress-controller/nginx-ingress-controller</td><td align="center">0.20.0</td><td align="left">registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/nginx-ingress-controller</td></tr></tbody></table><p>如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/nginx-ingress-controller:0.20.0</span><br></pre></td></tr></table></figure><p>将镜像上传到自己的私有仓库，以供下面的步骤使用。</p><h3 id="第二步：-更新mandatory-yaml中的镜像地址"><a href="#第二步：-更新mandatory-yaml中的镜像地址" class="headerlink" title="第二步： 更新mandatory.yaml中的镜像地址"></a>第二步： 更新mandatory.yaml中的镜像地址</h3><p>替换成自己的镜像地址：</p><p>替换defaultbackend-amd64镜像地址</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">'s#k8s.gcr.io/defaultbackend-amd64#registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/defaultbackend-amd64#g'</span> mandatory.yaml</span><br></pre></td></tr></table></figure><p>替换nginx-ingress-controller镜像地址</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">'s#quay.io/kubernetes-ingress-controller/nginx-ingress-controller#registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/nginx-ingress-controller#g'</span> mandatory.yaml</span><br></pre></td></tr></table></figure><p>第三步： 部署nginx-ingress-controller</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f mandatory.yaml</span><br></pre></td></tr></table></figure><p>第四步： 查看ingress-nginx组件状态？<br>查看相关pod状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master ingress-nginx]<span class="comment"># kubectl get pods -n ingress-nginx -owide</span></span><br><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE     IP              NODE     NOMINATED NODE</span><br><span class="line">default-http-backend-7f594549df-nzthj      1/1     Running   0          3m59s   192.168.1.90    slave1   &lt;none&gt;</span><br><span class="line">nginx-ingress-controller-9fc7f4c5f-dr722   1/1     Running   0          3m59s   192.168.2.110   slave2   &lt;none&gt;</span><br></pre></td></tr></table></figure><p>查看service状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master ingress-nginx]<span class="comment"># kubectl get service -n ingress-nginx</span></span><br><span class="line">NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">default-http-backend   ClusterIP   10.104.146.218   &lt;none&gt;        80/TCP    5m37s</span><br></pre></td></tr></table></figure><h1 id="三、测试"><a href="#三、测试" class="headerlink" title="三、测试"></a>三、测试</h1><h2 id="3-1-测试default-http-backend-是否起作用？"><a href="#3-1-测试default-http-backend-是否起作用？" class="headerlink" title="3.1 测试default-http-backend 是否起作用？"></a>3.1 测试default-http-backend 是否起作用？</h2><p>系统自动安装了一个default-http-backend pod， 这是一个缺省的http后端服务， 用于返回404结果.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># curl -i 172.16.0.18:80</span><br><span class="line">default backend - 404</span><br></pre></td></tr></table></figure><p>参考文献：<br><a href="https://github.com/kubernetes/ingress-nginx/blob/nginx-0.20.0/docs/deploy/index.md" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx/blob/nginx-0.20.0/docs/deploy/index.md</a><br><a href="https://www.jianshu.com/p/e30b06906b77" target="_blank" rel="noopener">https://www.jianshu.com/p/e30b06906b77</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一、Ingress-简介&quot;&gt;&lt;a href=&quot;#一、Ingress-简介&quot; class=&quot;headerlink&quot; title=&quot;一、Ingress 简介&quot;&gt;&lt;/a&gt;一、Ingress 简介&lt;/h1&gt;&lt;p&gt;在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。&lt;br&gt;为了使外部的应用能够访问集群内的服务，&lt;br&gt;在Kubernetes 目前 提供了以下几种方案：&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/categories/kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="https://www.alan87.top/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Springcloud微服务——基于security和jwt实现认证及鉴权服务</title>
    <link href="https://www.alan87.top/springcloud/%E5%9F%BA%E4%BA%8Esecurity%E5%92%8Cjwt%E5%AE%9E%E7%8E%B0%E8%AE%A4%E8%AF%81%E5%8F%8A%E9%89%B4%E6%9D%83%E6%9C%8D%E5%8A%A1/"/>
    <id>https://www.alan87.top/springcloud/%E5%9F%BA%E4%BA%8Esecurity%E5%92%8Cjwt%E5%AE%9E%E7%8E%B0%E8%AE%A4%E8%AF%81%E5%8F%8A%E9%89%B4%E6%9D%83%E6%9C%8D%E5%8A%A1/</id>
    <published>2020-05-13T04:13:44.000Z</published>
    <updated>2020-10-10T07:03:43.929Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、需求"><a href="#一、需求" class="headerlink" title="一、需求"></a>一、需求</h1><ul><li>1、RESTfull风格的鉴权服务（路线相同的情况下根据请求方式鉴别访问权限）</li><li>2、包含用户、角色、权限</li><li>3、使用JWT最为token认证方式</li></ul><a id="more"></a><h1 id="二、知识点讲解"><a href="#二、知识点讲解" class="headerlink" title="二、知识点讲解"></a>二、知识点讲解</h1><h2 id="2-1-方案"><a href="#2-1-方案" class="headerlink" title="2.1 方案"></a>2.1 方案</h2><p>传统的单体应用体系下，应用是一个整体，一般针对所有的请求都会进行权限校验。请求一般会通过一个权限的拦截器进行权限的校验，在登录时将用户信息缓存到 session 中，后续访问则从缓存中获取用户信息</p><p>但在微服务架构下，一个应用会被拆分成若干个微应用，每个微应用都需要对访问进行鉴权，每个微应用都需要明确当前访问用户以及其权限。尤其当访问来源不只是浏览器，还包括其他服务的调用时，单体应用架构下的鉴权方式就不是特别合适了。因此在设计架构中，要考虑外部应用接入的场景、用户与服务的鉴权、服务与服务的鉴权等多种鉴权场景。</p><p>目前主流的方案由四种</p><h3 id="2-1-1-单点登录（SSO）"><a href="#2-1-1-单点登录（SSO）" class="headerlink" title="2.1.1 单点登录（SSO）"></a>2.1.1 单点登录（SSO）</h3><p>一次登入，多地使用。这种方案意味着每个面向用户的服务都必须与认证服务交互，进而产生大量琐碎的网络流量和重复的工作，当动辄数十个微应用时，这种方案的弊端会更加明显。</p><h3 id="2-1-2-分布式-Session-方案"><a href="#2-1-2-分布式-Session-方案" class="headerlink" title="2.1.2 分布式 Session 方案"></a>2.1.2 分布式 Session 方案</h3><p>借助reids或其他共享存储中，将用户认证的信息存储在其中，通常使用用户会话作为 key 来实现的简单分布式哈希映射。当用户访问微服务时，用户数据可以从共享存储中获取。在某些场景下，这种方案很不错，用户登录状态是不透明的。同时也是一个高可用且可扩展的解决方案。这种方案的缺点在于共享存储需要一定保护机制，因此需要通过安全链接来访问，这时解决方案的实现就通常具有相当高的复杂性了。</p><h3 id="2-1-3-客户端-Token-方案"><a href="#2-1-3-客户端-Token-方案" class="headerlink" title="2.1.3 客户端 Token 方案"></a>2.1.3 客户端 Token 方案</h3><p>令牌在客户端生成，由身份验证服务进行签名，并且必须包含足够的信息，以便可以在所有微服务中建立用户身份。令牌会附加到每个请求上，为微服务提供用户身份验证，这种解决方案的安全性相对较好，但身份验证注销是一个大问题，缓解这种情况的方法可以使用短期令牌和频繁检查认证服务等。对于客户端令牌的编码方案，Borsos 更喜欢使用 JSON Web Tokens（JWT），它足够简单且库支持程度也比较好。</p><h3 id="2-1-4-客户端-Token-与-API-网关结合"><a href="#2-1-4-客户端-Token-与-API-网关结合" class="headerlink" title="2.1.4 客户端 Token 与 API 网关结合"></a>2.1.4 客户端 Token 与 API 网关结合</h3><p>这个方案意味着所有请求都通过网关，从而有效地隐藏了微服务。 在请求时，网关将原始用户令牌转换为内部会话 ID 令牌。在这种情况下，注销就不是问题，因为网关可以在注销时撤销用户的令牌。</p><p>本文就采用方案4，实现微服务体系中用户鉴权及认证服务。</p><p>Token的实现方案业界有多套成熟的方案，这其中最主流的是JWT 和 Oauth2.0 两种方式。<br>下面就基于JWT的方式具体实现。</p><h1 id="SpringSecurity"><a href="#SpringSecurity" class="headerlink" title="SpringSecurity"></a>SpringSecurity</h1><ul><li><p>AuthenticationManager, 用户认证的管理类，所有的认证请求（比如login）都会通过提交一个token给AuthenticationManager的authenticate()方法来实现。当然事情肯定不是它来做，具体校验动作会由AuthenticationManager将请求转发给具体的实现类来做。根据实现反馈的结果再调用具体的Handler来给用户以反馈。</p></li><li><p>AuthenticationProvider, 认证的具体实现类，一个provider是一种认证方式的实现，比如提交的用户名密码我是通过和DB中查出的user记录做比对实现的，那就有一个DaoProvider；如果我是通过CAS请求单点登录系统实现，那就有一个CASProvider。按照Spring一贯的作风，主流的认证方式它都已经提供了默认实现，比如DAO、LDAP、CAS、OAuth2等。<br>前面讲了AuthenticationManager只是一个代理接口，真正的认证就是由AuthenticationProvider来做的。一个AuthenticationManager可以包含多个Provider，每个provider通过实现一个support方法来表示自己支持那种Token的认证。AuthenticationManager默认的实现类是ProviderManager。</p></li><li><p>UserDetailService, 用户认证通过Provider来做，所以Provider需要拿到系统已经保存的认证信息，获取用户信息的接口spring-security抽象成UserDetailService。虽然叫Service,但是我更愿意把它认为是我们系统里经常有的UserDao。</p></li><li><p>AuthenticationToken, 所有提交给AuthenticationManager的认证请求都会被封装成一个Token的实现，比如最容易理解的UsernamePasswordAuthenticationToken。</p></li><li><p>SecurityContext，当用户通过认证之后，就会为这个用户生成一个唯一的SecurityContext，里面包含用户的认证信息Authentication。通过SecurityContext我们可以获取到用户的标识Principle和授权信息GrantedAuthrity。在系统的任何地方只要通过SecurityHolder.getSecruityContext()就可以获取到SecurityContext。在Shiro中通过SecurityUtils.getSubject()到达同样的目的。</p></li></ul><h1 id="三、具体实现"><a href="#三、具体实现" class="headerlink" title="三、具体实现"></a>三、具体实现</h1><h2 id="3-1-业务流程"><a href="#3-1-业务流程" class="headerlink" title="3.1 业务流程"></a>3.1 业务流程</h2><ul><li>客户端调用登录接口，传入用户名密码。</li><li>服务端请求身份认证中心，确认用户名密码正确。</li><li>服务端创建JWT，返回给客户端。</li><li>客户端拿到 JWT，进行存储（可以存储在缓存中，也可以存储在数据库中，如果是浏览器，可以存储在 Cookie中）在后续请求中，在 HTTP 请求头中加上 JWT。</li><li>服务端校验 JWT，校验通过后，返回相关资源和数据。<h2 id="3-2-代码"><a href="#3-2-代码" class="headerlink" title="3.2 代码"></a>3.2 代码</h2>完整pom文件（项目结构为多模块）<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springcloud<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lhm<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>security<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--web 服务--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--security--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-security<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.jsonwebtoken<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jjwt<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--mybatis-plus--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--mybatis-plus日志--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>p6spy<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>p6spy<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- druid的starter --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- redis --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-pool2<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-redis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--JSON--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.38<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- StringUtils相关工具类jar包 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-lang3<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--  lombok  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="3-3-认证服务"><a href="#3-3-认证服务" class="headerlink" title="3.3 认证服务"></a>3.3 认证服务</h2><p><img data-src="https://img-blog.csdnimg.cn/20190522113953804.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JlY2F1c2VTeQ==,size_16,color_FFFFFF,t_70" alt=""><br>在登入方面，本次使用了security默认提供的表单登陆方式，因此直接从实现<br>UserDetailsService开始</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.exception.CommonException;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.AuthUserDetails;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.AuthUserPoJo;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.service.IUsersService;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.StringRedisTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UserDetails;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UserDetailsService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UsernameNotFoundException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> UserDetailsServiceImpl</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>  实现security提供的 用户信息获取接口  并按照业务增加redis 登陆限制</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2018/5/6 10:26</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDetailsServiceImpl</span> <span class="keyword">implements</span> <span class="title">UserDetailsService</span> </span>&#123;</span><br><span class="line">    <span class="comment">//登入重试时间</span></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;security.loginAfterTime&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> Integer loginAfterTime;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> StringRedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IUsersService iUsersService;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 实现用户信息查询方法 让DaoAuthenticationProvider 获取到数据库获中用户数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Date</span> 11:21 2019/5/6</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Param</span> [username]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> org.springframework.security.core.userdetails.UserDetails</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> UserDetails <span class="title">loadUserByUsername</span><span class="params">(String username)</span> <span class="keyword">throws</span> UsernameNotFoundException </span>&#123;</span><br><span class="line">        String flagKey = <span class="string">"loginFailFlag:"</span>+username;</span><br><span class="line">        String value = redisTemplate.opsForValue().get(flagKey);</span><br><span class="line">        <span class="keyword">if</span>(StringUtils.isNotBlank(value))&#123;</span><br><span class="line">            <span class="comment">//超过限制次数</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UsernameNotFoundException(<span class="string">"登录错误次数超过限制，请"</span>+loginAfterTime+<span class="string">"分钟后再试"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//查询用户信息</span></span><br><span class="line">        AuthUserPoJo authUserPoJo=iUsersService.findAuthUserByUsername(username);</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">null</span>==authUserPoJo)&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UsernameNotFoundException(<span class="string">"当前用户不存在"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(authUserPoJo.getRoleInfos()==<span class="keyword">null</span> || authUserPoJo.getRoleInfos().isEmpty())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UsernameNotFoundException(<span class="string">"当前用户无角色"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> AuthUserDetails(authUserPoJo);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>UserDetailsServiceImpl 最后返回一个拼装好的security用户对象，但为了实现自定义角色与权限管理需要对UserDetails进行重写。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.pojo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.UserConstant;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.entity.PermissionInfo;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.GrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.authority.SimpleGrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UserDetails;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Collection;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Exrickx</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AuthUserDetails</span> <span class="keyword">extends</span> <span class="title">AuthUserPoJo</span> <span class="keyword">implements</span> <span class="title">UserDetails</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">AuthUserDetails</span><span class="params">(AuthUserPoJo user)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (user != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.setUserName(user.getUserName());</span><br><span class="line">            <span class="keyword">this</span>.setPassWord(user.getPassWord());</span><br><span class="line">            <span class="keyword">this</span>.setStatus(user.getStatus());</span><br><span class="line">            <span class="keyword">this</span>.setRoleInfos(user.getRoleInfos());</span><br><span class="line">            <span class="keyword">this</span>.setPermissionInfos(user.getPermissionInfos());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将角色权限 放入GrantedAuthorit的自定义实现类MyGrantedAuthority中  为权限判定提供数据</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123;</span><br><span class="line"></span><br><span class="line">        List&lt;GrantedAuthority&gt; authorityList = <span class="keyword">new</span> ArrayList&lt;GrantedAuthority&gt;();</span><br><span class="line">        List&lt;PermissionInfo&gt; permissions = <span class="keyword">this</span>.getPermissionInfos();</span><br><span class="line">        <span class="keyword">if</span> (permissions != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (PermissionInfo permission : permissions) &#123;</span><br><span class="line">                GrantedAuthority grantedAuthority = <span class="keyword">new</span> MyGrantedAuthority(permission.getPath(), permission.getMethod());</span><br><span class="line">                authorityList.add(grantedAuthority);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> authorityList;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPassword</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getPassWord();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getUsername</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getUserName();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 账户是否过期</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isAccountNonExpired</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否禁用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isAccountNonLocked</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 密码是否过期</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isCredentialsNonExpired</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 是否启用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEnabled</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> UserConstant.USER_STATUS_NORMAL.equals(<span class="keyword">this</span>.getStatus()) ? <span class="keyword">true</span> : <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后DaoProvider会对比校验并执行相应的结果处理器</p><p>登入成功处理器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.handler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.AuthUserDetails;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResponseUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.TokenUtil;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.Authentication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.AuthenticationSuccessHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> LoginSuccessHandlerFilter</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 登陆认证成功处理过滤器</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2019/5/6 16:27</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginSuccessHandler</span> <span class="keyword">implements</span> <span class="title">AuthenticationSuccessHandler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> TokenUtil tokenUtil;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 用户认证成功后 生成token并返回</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Date</span> 8:50 2019/5/7</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Param</span> [request, response, authentication]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> void</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAuthenticationSuccess</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Authentication authentication)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">       AuthUserDetails authUserDetails=(AuthUserDetails)authentication.getPrincipal();<span class="comment">//从内存中获取当前认证用户信息</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建token</span></span><br><span class="line">        String accessToken = tokenUtil.createAccessJwtToken(authUserDetails);</span><br><span class="line">        String refreshToken = tokenUtil.createRefreshToken(authUserDetails);</span><br><span class="line"></span><br><span class="line">        HashMap&lt;String,String&gt; map=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(<span class="string">"accessToken"</span>,accessToken);</span><br><span class="line">        map.put(<span class="string">"refreshToken"</span>,refreshToken);</span><br><span class="line"></span><br><span class="line">        ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.OK,<span class="string">"登录成功"</span>,map));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>登入失败处理器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.handler;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResponseUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.StringRedisTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.BadCredentialsException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.DisabledException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.AuthenticationException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.UsernameNotFoundException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.AuthenticationFailureHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> LoginFailureHandler</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 登陆失败处理过滤器</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2019/5/7 9:05</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginFailureHandler</span> <span class="keyword">implements</span> <span class="title">AuthenticationFailureHandler</span> </span>&#123;</span><br><span class="line">    <span class="comment">//#限制用户登陆错误次数（次）</span></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;security.loginTimeLimit&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> Integer loginTimeLimit;</span><br><span class="line">    <span class="comment">//#错误超过次数后多少分钟后才能继续登录（分钟）</span></span><br><span class="line">    <span class="meta">@Value</span>(<span class="string">"$&#123;security.loginAfterTime&#125;"</span>)</span><br><span class="line">    <span class="keyword">private</span> Integer loginAfterTime;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> StringRedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 用户登陆失败处理类  记录用户登陆错误次数</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Date</span> 9:12 2019/5/7</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Param</span> [request, response, e]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> void</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAuthenticationFailure</span><span class="params">(HttpServletRequest request, HttpServletResponse response, AuthenticationException e)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (e <span class="keyword">instanceof</span> UsernameNotFoundException || e <span class="keyword">instanceof</span> BadCredentialsException) &#123;</span><br><span class="line">            String username = request.getParameter(<span class="string">"username"</span>);</span><br><span class="line">            recordLoginTime(username);</span><br><span class="line">            String key = <span class="string">"loginTimeLimit:"</span> + username;</span><br><span class="line">            String value = redisTemplate.opsForValue().get(key);</span><br><span class="line">            <span class="keyword">if</span> (StringUtils.isBlank(value)) &#123;</span><br><span class="line">                value = <span class="string">"0"</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//获取已登录错误次数</span></span><br><span class="line">            <span class="keyword">int</span> loginFailTime = Integer.parseInt(value);</span><br><span class="line">            <span class="keyword">int</span> restLoginTime = loginTimeLimit - loginFailTime;</span><br><span class="line">            ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.BAD_REQUEST, <span class="string">"用户名或密码错误"</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> DisabledException) &#123;</span><br><span class="line">            ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.BAD_REQUEST, <span class="string">"账户被禁用，请联系管理员"</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.BAD_REQUEST, <span class="string">"登录失败"</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断用户登陆错误次数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">recordLoginTime</span><span class="params">(String username)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        String key = <span class="string">"loginTimeLimit:"</span> + username;</span><br><span class="line">        String flagKey = <span class="string">"loginFailFlag:"</span> + username;</span><br><span class="line">        String value = redisTemplate.opsForValue().get(key);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(value)) &#123;</span><br><span class="line">            value = <span class="string">"0"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//获取已登录错误次数</span></span><br><span class="line">        <span class="keyword">int</span> loginFailTime = Integer.parseInt(value) + <span class="number">1</span>;</span><br><span class="line">        redisTemplate.opsForValue().set(key, String.valueOf(loginFailTime), loginAfterTime, TimeUnit.MINUTES);</span><br><span class="line">        <span class="keyword">if</span> (loginFailTime &gt;= loginTimeLimit) &#123;</span><br><span class="line"></span><br><span class="line">            redisTemplate.opsForValue().set(flagKey, <span class="string">"fail"</span>, loginAfterTime, TimeUnit.MINUTES);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在登入的过程中会对用户的请求间隔时间及失败次数做记录。</p><h2 id="3-4-鉴权服务"><a href="#3-4-鉴权服务" class="headerlink" title="3.4 鉴权服务"></a>3.4 鉴权服务</h2><p>鉴权的过程分成了两个大的步骤</p><ul><li>第一对请求的路径、方法、头部信息进行判断，确认该请求是否需要鉴权<br>JWTAuthenticationFilter</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.filter;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONArray;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.IgnoredUrlsProperties;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.ResultCode;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.SecurityConstant;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.exception.CommonException;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.MyGrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.ResponseUtil;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.utils.SpringUtil;</span><br><span class="line"><span class="keyword">import</span> io.jsonwebtoken.Claims;</span><br><span class="line"><span class="keyword">import</span> io.jsonwebtoken.ExpiredJwtException;</span><br><span class="line"><span class="keyword">import</span> io.jsonwebtoken.Jwts;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.AuthenticationManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.UsernamePasswordAuthenticationToken;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.context.SecurityContextHolder;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.userdetails.User;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.AuthenticationEntryPoint;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.www.BasicAuthenticationFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.AntPathMatcher;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.PathMatcher;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.FilterChain;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * JWT过滤器1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JWTAuthenticationFilter</span> <span class="keyword">extends</span> <span class="title">BasicAuthenticationFilter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JWTAuthenticationFilter</span><span class="params">(AuthenticationManager authenticationManager)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(authenticationManager);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JWTAuthenticationFilter</span><span class="params">(AuthenticationManager authenticationManager, AuthenticationEntryPoint authenticationEntryPoint)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(authenticationManager, authenticationEntryPoint);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doFilterInternal</span><span class="params">(HttpServletRequest request, HttpServletResponse response, FilterChain chain)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">        IgnoredUrlsProperties ignoredUrlsProperties= SpringUtil.getBean(<span class="string">"ignoredUrlsProperties"</span>, IgnoredUrlsProperties<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        String Requesturl=request.getRequestURI();</span><br><span class="line">        PathMatcher pathMatcher = <span class="keyword">new</span> AntPathMatcher();</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">null</span> != ignoredUrlsProperties)&#123;</span><br><span class="line">            <span class="keyword">for</span>(String url:ignoredUrlsProperties.getUrls())&#123;</span><br><span class="line">                <span class="keyword">if</span>(pathMatcher.match(url,Requesturl))&#123;</span><br><span class="line">                    chain.doFilter(request, response);</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取请求头</span></span><br><span class="line">        String header = request.getHeader(SecurityConstant.HEADER);</span><br><span class="line">        <span class="comment">//如果请求头中不存在 或  格式不对  则进入下个过滤器</span></span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(header) || !header.startsWith(SecurityConstant.TOKEN_SPLIT)) &#123;</span><br><span class="line">            chain.doFilter(request, response);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            UsernamePasswordAuthenticationToken authentication = getAuthentication(request, response);</span><br><span class="line">            SecurityContextHolder.getContext().setAuthentication(authentication);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            ResponseUtil.out(response, ResUtil.getJsonStr(ResultCode.BAD_REQUEST, e.getMessage()));</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        chain.doFilter(request, response);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Description</span> 对token进行解析认证</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Date</span> 11:11 2019/5/7</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@Param</span> [request, response]</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> org.springframework.security.authentication.UsernamePasswordAuthenticationToken</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> UsernamePasswordAuthenticationToken <span class="title">getAuthentication</span><span class="params">(HttpServletRequest request, HttpServletResponse response)</span> <span class="keyword">throws</span> CommonException </span>&#123;</span><br><span class="line"></span><br><span class="line">        String token = request.getHeader(SecurityConstant.HEADER);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isNotBlank(token)) &#123;</span><br><span class="line">            <span class="comment">// 解析token</span></span><br><span class="line">            Claims claims = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                claims = Jwts.parser()</span><br><span class="line">                        .setSigningKey(SecurityConstant.tokenSigningKey)</span><br><span class="line">                        .parseClaimsJws(token.replace(SecurityConstant.TOKEN_SPLIT, <span class="string">""</span>))</span><br><span class="line">                        .getBody();</span><br><span class="line"></span><br><span class="line">                <span class="comment">//获取用户名</span></span><br><span class="line">                String username = claims.getSubject();</span><br><span class="line"></span><br><span class="line">                <span class="comment">//获取权限</span></span><br><span class="line">                List&lt;MyGrantedAuthority&gt; authorities = <span class="keyword">new</span> ArrayList&lt;MyGrantedAuthority&gt;();</span><br><span class="line">                String authority = claims.get(SecurityConstant.AUTHORITIES).toString();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (StringUtils.isNotBlank(authority)) &#123;</span><br><span class="line">                    JSONArray list=JSONArray.parseArray(authority);</span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;list.size();i++)&#123;</span><br><span class="line">                        JSONObject jsonObject=list.getJSONObject(i);</span><br><span class="line">                        authorities.add(<span class="keyword">new</span> MyGrantedAuthority(jsonObject.getString(<span class="string">"path"</span>),jsonObject.getString(<span class="string">"method"</span>)));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (StringUtils.isNotBlank(username)) &#123;</span><br><span class="line">                    <span class="comment">//此处password不能为null</span></span><br><span class="line">                    User principal = <span class="keyword">new</span> User(username, <span class="string">""</span>, authorities);</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> UsernamePasswordAuthenticationToken(principal, <span class="keyword">null</span>, authorities);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ExpiredJwtException e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> CommonException(ResultCode.BAD_REQUEST, <span class="string">"登录已失效，请重新登录"</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> CommonException(ResultCode.BAD_REQUEST, <span class="string">"解析token错误"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>第二判断当前请求token是否有权访问当前请求地址<br>MyFilterSecurityInterceptor</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.filter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.manager.MyAccessDecisionManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.SecurityMetadataSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.intercept.AbstractSecurityInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.intercept.InterceptorStatusToken;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.FilterInvocation;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.access.intercept.FilterInvocationSecurityMetadataSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.*;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 权限管理过滤器2</span></span><br><span class="line"><span class="comment"> * 监控用户行为</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Exrickx</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFilterSecurityInterceptor</span> <span class="keyword">extends</span> <span class="title">AbstractSecurityInterceptor</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> FilterInvocationSecurityMetadataSource securityMetadataSource;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMyAccessDecisionManager</span><span class="params">(MyAccessDecisionManager myAccessDecisionManager)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.setAccessDecisionManager(myAccessDecisionManager);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig filterConfig)</span> <span class="keyword">throws</span> ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest request, ServletResponse response, FilterChain chain)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">        FilterInvocation fi = <span class="keyword">new</span> FilterInvocation(request, response, chain);</span><br><span class="line">        invoke(fi);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//fi里面有一个被拦截的url</span></span><br><span class="line">    <span class="comment">//里面调用MyInvocationSecurityMetadataSource的getAttributes(Object object)这个方法获取fi对应的所有权限</span></span><br><span class="line">    <span class="comment">//再调用MyAccessDecisionManager的decide方法来校验用户的权限是否足够</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(FilterInvocation fi)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">        InterceptorStatusToken token = <span class="keyword">super</span>.beforeInvocation(fi);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fi.getChain().doFilter(fi.getRequest(), fi.getResponse());</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">super</span>.afterInvocation(token, <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Class&lt;?&gt; getSecureObjectClass() &#123;</span><br><span class="line">        <span class="keyword">return</span> FilterInvocation<span class="class">.<span class="keyword">class</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SecurityMetadataSource <span class="title">obtainSecurityMetadataSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.securityMetadataSource;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体的处理会放到MySecurityMetadataSource中去判断，不过我这里做了个小优化，将处理权限的业务统一放到了MyAccessDecisionManager下，减少点性能开销</p><p>MySecurityMetadataSource</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.manager;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.ConfigAttribute;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.SecurityConfig;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.access.intercept.FilterInvocationSecurityMetadataSource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Collection;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 权限资源管理器</span></span><br><span class="line"><span class="comment"> * 为权限决断器提供支持</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Exrickx</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySecurityMetadataSource</span> <span class="keyword">implements</span> <span class="title">FilterInvocationSecurityMetadataSource</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 此方法是为了判定用户请求的url 是否在权限表中，如果在权限表中，则返回给 decide 方法，用来判定用户是否有此权限。如果不在权限表中则放行。</span></span><br><span class="line"><span class="comment">     * 因为每一次来了请求，都先要匹配一下权限表中的信息是不是包含此url，</span></span><br><span class="line"><span class="comment">     * 因此优化一下，对url直接拦截，不管请求的url 是什么都直接拦截，然后在MyAccessDecisionManager的decide 方法中做拦截还是放行的决策。</span></span><br><span class="line"><span class="comment">     * 所以此方法的返回值不能返回 null 此处随便返回一下。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> o</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IllegalArgumentException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Collection&lt;ConfigAttribute&gt; <span class="title">getAttributes</span><span class="params">(Object o)</span> <span class="keyword">throws</span> IllegalArgumentException </span>&#123;</span><br><span class="line"></span><br><span class="line">        Collection&lt;ConfigAttribute&gt; co = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        co.add(<span class="keyword">new</span> SecurityConfig(<span class="string">"null"</span>));</span><br><span class="line">        <span class="keyword">return</span> co;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Collection&lt;ConfigAttribute&gt; <span class="title">getAllConfigAttributes</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">supports</span><span class="params">(Class&lt;?&gt; aClass)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MyAccessDecisionManager</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.manager;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.pojo.MyGrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.AccessDecisionManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.AccessDeniedException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.access.ConfigAttribute;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.authentication.InsufficientAuthenticationException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.Authentication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.GrantedAuthority;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.FilterInvocation;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.util.matcher.AntPathRequestMatcher;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> java.util.Collection;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> MyAccessDecisionManager</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 权限最终判断器</span></span><br><span class="line"><span class="comment"> *  * 判断用户拥有的角色是否有资源访问权限</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2019/5/7 10:44</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyAccessDecisionManager</span> <span class="keyword">implements</span> <span class="title">AccessDecisionManager</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//decide 方法是判定是否拥有权限的决策方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">decide</span><span class="params">(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; configAttributes)</span> <span class="keyword">throws</span> AccessDeniedException, InsufficientAuthenticationException </span>&#123;</span><br><span class="line">        HttpServletRequest request = ((FilterInvocation) object).getHttpRequest();</span><br><span class="line">        String url, method;</span><br><span class="line">        AntPathRequestMatcher matcher;</span><br><span class="line">        <span class="keyword">for</span> (GrantedAuthority ga : authentication.getAuthorities()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (ga <span class="keyword">instanceof</span> MyGrantedAuthority) &#123;</span><br><span class="line">                MyGrantedAuthority urlGrantedAuthority = (MyGrantedAuthority) ga;</span><br><span class="line">                url = urlGrantedAuthority.getPermissionUrl();</span><br><span class="line">                method = urlGrantedAuthority.getMethod();</span><br><span class="line">                matcher = <span class="keyword">new</span> AntPathRequestMatcher(url);</span><br><span class="line">                <span class="keyword">if</span> (matcher.matches(request)) &#123;</span><br><span class="line">                    <span class="comment">//当权限表权限的method为ALL时表示拥有此路径的所有请求方式权利。</span></span><br><span class="line">                    <span class="keyword">if</span> (method.equals(request.getMethod()) || <span class="string">"ALL"</span>.equals(method)) &#123;</span><br><span class="line">                        <span class="keyword">return</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> AccessDeniedException(<span class="string">"您没有访问权限"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> AccessDeniedException(<span class="string">"鉴权出错"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">supports</span><span class="params">(ConfigAttribute attribute)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">supports</span><span class="params">(Class&lt;?&gt; clazz)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>decide（）方法中的MyGrantedAuthority是我自定义的权限对象 因为原有的SimpleGrantedAuthority类只有一个属性，无法完成RESTfull风格的请求。<br>MyGrantedAuthority</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.pojo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.security.core.GrantedAuthority;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> MyGrantedAuthority</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Alan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 2018/5/7 10:39</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyGrantedAuthority</span> <span class="keyword">implements</span> <span class="title">GrantedAuthority</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String url;</span><br><span class="line">    <span class="keyword">private</span> String method;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getPermissionUrl</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> url;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPermissionUrl</span><span class="params">(String permissionUrl)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.url = permissionUrl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> method;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMethod</span><span class="params">(String method)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.method = method;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyGrantedAuthority</span><span class="params">(String url, String method)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.url = url;</span><br><span class="line">        <span class="keyword">this</span>.method = method;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getAuthority</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.url + <span class="string">";"</span> + <span class="keyword">this</span>.method;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>最后将我们自定义的类全部注入到security提供的配置文件类中，具体的配置我都用注解表明了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lhm.springcloud.security.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.constant.IgnoredUrlsProperties;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.filter.JWTAuthenticationFilter;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.filter.MyFilterSecurityInterceptor;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.filter.WebSecurityCorsFilter;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.handler.RestAccessDeniedHandler;</span><br><span class="line"><span class="keyword">import</span> com.lhm.springcloud.security.service.impl.UserDetailsServiceImpl;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.HttpMethod;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.annotation.web.builders.HttpSecurity;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.annotation.web.configurers.ExpressionUrlAuthorizationConfigurer;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.config.http.SessionCreationPolicy;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.access.channel.ChannelProcessingFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.access.intercept.FilterSecurityInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.AuthenticationFailureHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.security.web.authentication.AuthenticationSuccessHandler;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Security 核心配置类</span></span><br><span class="line"><span class="comment"> * 开启控制权限至Controller</span></span><br><span class="line"><span class="comment"> * @author Exrickx</span></span><br><span class="line"><span class="comment"> * */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WebSecurityConfig</span> <span class="keyword">extends</span> <span class="title">WebSecurityConfigurerAdapter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IgnoredUrlsProperties ignoredUrlsProperties;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserDetailsServiceImpl userDetailsService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> AuthenticationSuccessHandler successHandler;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> AuthenticationFailureHandler failHandler;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RestAccessDeniedHandler accessDeniedHandler;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> MyFilterSecurityInterceptor myFilterSecurityInterceptor;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(AuthenticationManagerBuilder auth)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        auth.userDetailsService(userDetailsService).passwordEncoder(<span class="keyword">new</span> BCryptPasswordEncoder());</span><br><span class="line">        <span class="comment">//密码加密使用 Spring Security 提供的BCryptPasswordEncoder.encode(user.getRawPassword().trim())</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(HttpSecurity http)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ExpressionUrlAuthorizationConfigurer&lt;HttpSecurity&gt;.ExpressionInterceptUrlRegistry registry = http</span><br><span class="line">                .authorizeRequests();</span><br><span class="line">        <span class="comment">//除配置文件忽略路径其它所有请求都需经过认证和授权</span></span><br><span class="line">        <span class="keyword">for</span>(String url:ignoredUrlsProperties.getUrls())&#123;</span><br><span class="line">            registry.antMatchers(url).permitAll();</span><br><span class="line">        &#125;</span><br><span class="line">        registry.antMatchers(HttpMethod.OPTIONS).permitAll()</span><br><span class="line">                .and()</span><br><span class="line">                <span class="comment">//表单登录方式</span></span><br><span class="line">                .formLogin()</span><br><span class="line">                .loginPage(<span class="string">"/login/needLogin"</span>)</span><br><span class="line">                <span class="comment">//登录需要经过的url请求</span></span><br><span class="line">                .loginProcessingUrl(<span class="string">"/api/v1/auth/login"</span>)</span><br><span class="line">                .usernameParameter(<span class="string">"username"</span>)</span><br><span class="line">                .passwordParameter(<span class="string">"password"</span>)</span><br><span class="line">                .permitAll()</span><br><span class="line">                <span class="comment">//成功处理类</span></span><br><span class="line">                .successHandler(successHandler)</span><br><span class="line">                <span class="comment">//失败</span></span><br><span class="line">                .failureHandler(failHandler)</span><br><span class="line">                .and()</span><br><span class="line">                .logout()</span><br><span class="line">                .permitAll()</span><br><span class="line">                .and()</span><br><span class="line">                .authorizeRequests()</span><br><span class="line">                <span class="comment">//任何请求</span></span><br><span class="line">                .anyRequest()</span><br><span class="line">                <span class="comment">//需要身份认证</span></span><br><span class="line">                .authenticated()</span><br><span class="line">                .and()</span><br><span class="line">                <span class="comment">//关闭跨站请求防护</span></span><br><span class="line">                .csrf().disable()</span><br><span class="line">                <span class="comment">//前后端分离采用JWT 不需要session</span></span><br><span class="line">                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)</span><br><span class="line">                .and()</span><br><span class="line">                <span class="comment">//自定义权限拒绝处理类</span></span><br><span class="line">                .exceptionHandling().accessDeniedHandler(accessDeniedHandler)</span><br><span class="line">                .and()</span><br><span class="line">                <span class="comment">//添加自定义权限过滤器</span></span><br><span class="line">                .addFilterBefore(<span class="keyword">new</span> WebSecurityCorsFilter(), ChannelProcessingFilter<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">                .<span class="title">addFilterBefore</span>(<span class="title">myFilterSecurityInterceptor</span>, <span class="title">FilterSecurityInterceptor</span>.<span class="title">class</span>)</span></span><br><span class="line"><span class="class">                //添加<span class="title">JWT</span>过滤器 除/<span class="title">login</span>其它请求都需经过此过滤器</span></span><br><span class="line"><span class="class">                .<span class="title">addFilter</span>(<span class="title">new</span> <span class="title">JWTAuthenticationFilter</span>(<span class="title">authenticationManager</span>()))</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一、需求&quot;&gt;&lt;a href=&quot;#一、需求&quot; class=&quot;headerlink&quot; title=&quot;一、需求&quot;&gt;&lt;/a&gt;一、需求&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;1、RESTfull风格的鉴权服务（路线相同的情况下根据请求方式鉴别访问权限）&lt;/li&gt;
&lt;li&gt;2、包含用户、角色、权限&lt;/li&gt;
&lt;li&gt;3、使用JWT最为token认证方式&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="SpringCloud" scheme="https://www.alan87.top/categories/springcloud/"/>
    
    
      <category term="SpringCloud" scheme="https://www.alan87.top/tags/springcloud/"/>
    
  </entry>
  
  <entry>
    <title>认证协议-SAML介绍</title>
    <link href="https://www.alan87.top/web/%E8%AE%A4%E8%AF%81%E5%8D%8F%E8%AE%AE-SAML%E4%BB%8B%E7%BB%8D/"/>
    <id>https://www.alan87.top/web/%E8%AE%A4%E8%AF%81%E5%8D%8F%E8%AE%AE-SAML%E4%BB%8B%E7%BB%8D/</id>
    <published>2020-05-13T03:36:54.000Z</published>
    <updated>2020-10-10T07:03:43.952Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-SAML-介绍"><a href="#1-SAML-介绍" class="headerlink" title="1 SAML 介绍"></a>1 SAML 介绍</h1><p>SAML即安全断言标记语言，英文全称是Security Assertion Markup Language。它是一个基于XML的标准，用于在不同的安全域(security domain)之间用户身份验证和授权数据交换。<a id="more"></a>在SAML标准定义了身份提供者(identity provider)和服务提供者(service provider)，这两者构成了前面所说的不同的安全域。 SAML是OASIS组织安全服务技术委员会(Security Services Technical Committee)的产品。官方技术说明可参看OASIS Security Services (SAML) TC.</p><p>使用SAML，在线服务供应商可以联系一个独立的网络身份认证提供者，谁是试图访问受保护的内容的用户进行身份验证。</p><p>联邦是指两个或更多可信的业务合作伙伴组成的团体，其遵照的业务和技术协议允许来自联邦合作伙伴(成员公司)的用户以一种安全可靠的方式，无缝地访问另一家合作伙伴的资源。在联邦业务模型中(其中，服务是联邦化的，或可以与业务合作伙伴共享)，根据有关实体间达成的协议，一家公司的用户的身份将被转换，以合法访问另一家公司的Web站点，而另一家公司无需了解该用户的原始身份。</p><p>IDP认证中心提供了一个基于SAML的单点登录（SSO）服务，作为身份提供者(Identity provider)，控制用户名、密码和其他信息，用于识别，身份验证和授权用户的Web应用程序。</p><p>备注：SAML应用集成需完成应用集成申请，详见SAML相关内容。</p><p>通过SAML实现IDP 与其他合作伙伴的联邦身份认证。</p><p>流程说明图<br><img data-src="https://maxkey.top/images/saml/saml1.png?202005100627" alt=""></p><p>SAML实现联邦身份认证各方职责<br>IDP认证中心(Identity Provider/IDP)    合作伙伴(Service Provider/SP)<br>用户身份认证    安全断言判定<br>联邦身份安全断言    联邦身份维护<br>用户账号管理    服务提供和访问控制<br>IDP和SP预先完成证书的互信配置，SAML认证基于断言，断言基于证书的加密，传递过程是安全的，只有证书的持有者才能对断言进行解析</p><p>重要注意:SAML SSO解决方案仅适用于Web应用程序.</p><h1 id="2-SP-Init-SSO流程"><a href="#2-SP-Init-SSO流程" class="headerlink" title="2 SP-Init SSO流程"></a>2 SP-Init SSO流程</h1><p><img data-src="https://maxkey.top/images/saml/saml2.png?202005100627" alt=""><br>用户试图访问IDP的合作伙伴应用。</p><p>合作伙伴应用生成一个SAML身份验证请求。SAML请求编码并嵌入到URL IDP的SSO服务。RelayState参数包含编码的合作伙伴应用程序，用户尝试访问的URL也被嵌入在SSO URL。这的RelayState参数，就是要一个不透明的标识符，不作任何修改或检查传回的。</p><p>合作伙伴发送重定向到用户的浏览器。重定向URL编码SAML身份验证请求的，应提交到IDP的SSO服务。</p><p>IDP的SAML请求进行解码，并提取两个谷歌的断言消费服务（ACS）和用户的目标URL（RelayState参数）的URL。</p><p>IDP的用户进行身份验证。IDP可以通过要求有效的登录凭据，或通过检查有效的会话对用户进行身份验证。</p><p>IDP生成一个SAML响应，其中包含身份验证的用户的用户名。按照SAML 2.0规范，这种反应是公共和私人合作伙伴的DSA / RSA密钥数字签名的</p><p>IDP SAML响应和RelayState参数进行编码，并将该信息返回到用户的浏览器。IDP提供了一种机制，使浏览器可以转发信息到合作伙伴的ACS。</p><p>合作伙伴的ACS使用IDP的公钥验证SAML响应。如果成功验证的响应，ACS将用户重定向的目标URL。</p><p>用户被重定向的目标URL，并记录在合作伙伴应用程序。</p><h1 id="3-IDP-Init-SSO流程"><a href="#3-IDP-Init-SSO流程" class="headerlink" title="3 IDP-Init SSO流程"></a>3 IDP-Init SSO流程</h1><p><img data-src="https://maxkey.top/images/saml/saml3.png?202005100627" alt=""></p><p>IDP的用户进行身份验证。IDP可以通过要求有效的登录凭据，或通过检查有效的会话对用户进行身份验证。</p><p>IDP生成一个SAML响应，其中包含身份验证的用户的用户名。按照SAML 2.0规范，这种反应是公共和私人合作伙伴的DSA / RSA密钥数字签名的。</p><p>IDP SAML响应和RelayState参数进行编码，并将该信息返回到用户的浏览器。IDP提供了一种机制，使浏览器可以转发信息到合作伙伴的ACS。</p><p>合作伙伴的ACS使用IDP的公钥验证SAML响应。如果成功验证的响应，ACS将用户重定向的目标URL。</p><p>用户被重定向的目标URL，并记录在合作伙伴应用程序。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-SAML-介绍&quot;&gt;&lt;a href=&quot;#1-SAML-介绍&quot; class=&quot;headerlink&quot; title=&quot;1 SAML 介绍&quot;&gt;&lt;/a&gt;1 SAML 介绍&lt;/h1&gt;&lt;p&gt;SAML即安全断言标记语言，英文全称是Security Assertion Markup Language。它是一个基于XML的标准，用于在不同的安全域(security domain)之间用户身份验证和授权数据交换。
    
    </summary>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/categories/system-architecture/"/>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/tags/system-architecture/"/>
    
  </entry>
  
  <entry>
    <title>技术心得</title>
    <link href="https://www.alan87.top/readme/"/>
    <id>https://www.alan87.top/readme/</id>
    <published>2020-05-12T01:22:15.000Z</published>
    <updated>2020-10-10T07:03:43.883Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>有人认为编程是一门技术活，要有一定的天赋，非天资聪慧者不能及也。</p><p>其实不然，笔者计算机专业出身，对于技术这碗饭有一些心得体会，大多数人成为某领域顶级专家可能会有些难度，但应对日常工作，<strong>成长为资深研发工程师、技术专家、甚至成为小团队的Team Leader，并不难。</strong></p><a id="more"></a><p><strong>多读书、多看报，多研究开源框架源码，比如：github.com，这里汇集了全球工程师的智慧！</strong></p><p>言归正传，本文会列举工作中常用的一些技术，以及如何锻炼提升自己的架构能力。</p><p>由于每块技术市场上基本都有对应的网络资料或书籍，所以本文只是少篇幅列举工作中用到的核心知识点，抛砖引玉，属于进阶型，不适用初学者。</p><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><ul><li><a href="/java/summary">java</a></li><li><a href="/spring/sprint-summary">spring</a></li><li><a href="/springboot/summary">spring boot</a></li><li><a href="/springcloud/springcloud-netflix">spring cloud</a></li><li><a href="/java/mybatis">ibatis</a></li><li><a href="/java/common-design-patterns">设计模式</a></li><li><a href="/java/log">Log日志</a></li></ul><p>HashMap的原理<br><a href="https://www.jianshu.com/p/d2c14a10266e" target="_blank" rel="noopener">https://www.jianshu.com/p/d2c14a10266e</a></p><p>kafka之partition消费者并行度测试心得<br><a href="https://blog.csdn.net/willwill101/article/details/50393416" target="_blank" rel="noopener">https://blog.csdn.net/willwill101/article/details/50393416</a></p><p>k8s与各网络插件集成<br><a href="https://www.jianshu.com/p/9e02e755bf54" target="_blank" rel="noopener">https://www.jianshu.com/p/9e02e755bf54</a></p><p>软件架构设计-五视图方法论<br><a href="https://blog.csdn.net/nnsword/article/details/78109126" target="_blank" rel="noopener">https://blog.csdn.net/nnsword/article/details/78109126</a></p><p>Flink面试题<br><a href="https://blog.csdn.net/huzechen/article/details/102827576" target="_blank" rel="noopener">https://blog.csdn.net/huzechen/article/details/102827576</a></p><h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><p>目前使用最多还是mysql，虽然单机性能比不上oracle，但免费开源，单机成本低且借助于分布式集群，可以有强大的输出能力。</p><ul><li><a href="/java/database-connection-pool">连接池</a></li><li><a href="/db/transaction">事务</a></li><li><a href="/db/sub-db-sub-table">分库分表</a></li><li><a href="/java/id-generate">全局表 ID生成器</a></li><li><a href="http://blog.csdn.net/itomge/article/details/6909240" target="_blank" rel="noopener">读写分离</a></li><li><a href="/db/sql-optimize1">SQL调优1</a></li><li><a href="/db/sql-optimize2">SQL调优1</a></li></ul><h2 id="web容器-协议-网络"><a href="#web容器-协议-网络" class="headerlink" title="web容器/协议/网络"></a>web容器/协议/网络</h2><ul><li><a href="/web/load-balance">负载均衡</a></li><li>服务器<ul><li><a href="/web/nginx">Nginx</a></li><li><a href="/web/tomcat">Tomcat</a></li></ul></li><li>协议<ul><li><a href="/web/http">HTTP 协议</a></li><li><a href="/web/tcp">TCP 协议</a></li></ul></li><li><a href="/web/cdn">CDN</a></li></ul><h2 id="常用三方工具包"><a href="#常用三方工具包" class="headerlink" title="常用三方工具包"></a>常用三方工具包</h2><ul><li><a href="/third-tools/Goole-Guava">Google Guava</a></li><li><a href="/third-tools/fastJson">fastJson</a></li><li><a href="http://blog.csdn.net/itomge/article/details/17913607" target="_blank" rel="noopener">log4J</a></li><li><a href="/third-tools/commons-codec">commons-codec</a></li><li><a href="/third-tools/commons-lang3">commons-lang3</a></li><li><a href="/third-tools/commons-io">commons-io</a></li><li><a href="/third-tools/Quartz">Quartz</a></li><li><a href="/third-tools/HttpClient">HttpClient</a></li><li><a href="/third-tools/okhttp">okhttp</a></li><li><a href="/third-tools/Javassist">Javassist</a></li><li><a href="/third-tools/lombok">lombok</a></li></ul><h2 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h2><ul><li><p>RPC框架</p><ul><li><a href="/middle-software/dubbo">dubbo</a></li><li><a href="https://www.oschina.net/p/dubbox" target="_blank" rel="noopener">dubbox</a></li><li><a href="https://github.com/weibocom/motan" target="_blank" rel="noopener">motan</a></li><li><a href="https://github.com/apache/thrift" target="_blank" rel="noopener">Thrift</a></li><li><a href="/middle-software/rpc-compare">RPC框架性能比较</a></li></ul></li><li><p>MQ消息</p><ul><li><a href="https://github.com/apache/activemq" target="_blank" rel="noopener">ActiveMQ</a></li><li><a href="/middle-software/RabbitMQ">RabbitMQ</a></li><li><a href="/middle-software/kafka">Kafka</a></li><li><a href="/middle-software/RocketMQ">RocketMQ</a>    </li><li><a href="/middle-software/mq-compare">MQ框架性能比较</a></li></ul></li><li><p>分布式缓存</p><ul><li><a href="/third-tools/redis">redis</a></li><li><a href="http://blog.csdn.net/itomge/article/details/8035197" target="_blank" rel="noopener">memcache</a></li></ul></li><li><p>本地缓存</p><ul><li><a href="/middle-software/guava">Guava</a></li><li><a href="/middle-software/ehcache">Ehcache</a></li></ul></li><li><p>搜索</p><ul><li><a href="/middle-software/elasticsearch">Elasticsearch</a></li></ul></li><li><p>分布式数据框架</p><ul><li><a href="/middle-software/cobar">cobar</a></li><li><a href="/middle-software/mycat">Mycat</a></li><li><a href="/middle-software/tsharding">tsharding</a></li><li><a href="https://github.com/alibaba/tb_tddl" target="_blank" rel="noopener">tddl</a></li><li><a href="/middle-software/sharding-jdbc">sharding-jdbc</a></li><li><a href="https://gitee.com/robertleepeak/dbsplit" target="_blank" rel="noopener">dbsplit</a></li></ul></li><li><p>分布式协调服务</p><ul><li><a href="/middle-software/zookeeper">zookeeper</a></li></ul></li><li><p>配置管理</p><ul><li><a href="/java-other/super-diamond源码分析">super-diamond</a></li><li><a href="https://www.oschina.net/p/disconf" target="_blank" rel="noopener">disconf</a></li><li><a href="/middle-software/apollo">apollo</a></li></ul></li><li><p>分布式文件系统</p><ul><li><a href="/middle-software/FastDFS">FastDFS</a></li></ul></li><li><p>分布式任务调度框架</p><ul><li><a href="https://github.com/elasticjob/elastic-job" target="_blank" rel="noopener">Elastic-Job</a></li><li><a href="http://www.infoq.com/cn/articles/dangdang-distributed-work-framework-elastic-job" target="_blank" rel="noopener">详解当当网的分布式作业框架elastic-job</a></li><li><a href="http://blog.csdn.net/taosir_zhang/article/details/50728362" target="_blank" rel="noopener">TBSchedule</a></li><li><a href="https://github.com/xuxueli/xxl-job" target="_blank" rel="noopener">xxl-job</a></li></ul></li><li><p>大数据</p><ul><li><a href="/middle-software/Hbase">Hbase</a></li><li><a href="/middle-software/Spark">Spark</a></li><li><a href="/middle-software/Hadoop">Hadoop</a></li><li><a href="/middle-software/Hive">Hive</a></li><li><a href="/middle-software/big-data">other框架</a>    </li></ul></li><li><p>其它</p><ul><li><a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">数据库binlog的增量订阅&amp;消费组件</a></li><li><a href="https://github.com/alibaba/otter" target="_blank" rel="noopener">数据库同步系统</a></li><li><a href="/middle-software/TCC-Transaction">TCC-Transaction</a></li><li><a href="/middle-software/Netty">Netty</a></li><li><a href="/middle-software/openresty">OpenResty</a></li></ul></li></ul><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><ul><li><a href="/system-architecture/architecture-experience">架构经验</a></li><li><a href="/system-architecture/architecture-good-case">经典案例</a></li><li><a href="/system-architecture/technology-selection">通用技术方案选型</a></li><li><a href="/system-architecture/编码前3000问">编码前3000问</a></li><li><a href="/system-architecture/software-performance">软硬件性能</a></li><li><a href="/system-architecture/knowledge-outline">技术大纲</a></li></ul><h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><ul><li><a href="/project-management/论需求调研的重要性">论需求调研的重要性</a></li><li><a href="/project-management/project-management">项目管理</a></li><li><a href="/project-management/code">代码管理</a></li><li><a href="/project-management/test">测试相关</a></li></ul><h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><ul><li><a href="/java/online-question">快速排查线上问题</a></li><li><a href="/linux/linux-commands">linux常用命令</a></li><li><a href="/docker/docker-summary">Docker</a></li></ul><h2 id="个人成长"><a href="#个人成长" class="headerlink" title="个人成长"></a>个人成长</h2><ul><li><a href="/java-other/study">学习网站</a></li><li><a href="/java-other/book">Tom哥的读书单</a></li><li><a href="/java-other/person">个人成长与职业规划</a></li><li><a href="/java-other/programer">程序员素养</a></li></ul><h2 id="优秀开源项目"><a href="#优秀开源项目" class="headerlink" title="优秀开源项目"></a>优秀开源项目</h2><h3 id="1-SpringBlade"><a href="#1-SpringBlade" class="headerlink" title="1. SpringBlade"></a>1. SpringBlade</h3><p>SpringBlade 是一个由商业级项目升级优化而来的SpringCloud分布式微服务架构、SpringBoot单体式微服务架构并存的综合型项目，采用Java8 API重构了业务代码，完全遵循阿里巴巴编码规范。采用Spring Boot 2 、Spring Cloud Hoxton 、Mybatis 等核心技术，同时提供基于React和Vue的两个前端框架用于快速搭建企业级的SaaS多租户微服务平台。 官网：<a href="https://bladex.vip" target="_blank" rel="noopener">https://bladex.vip</a></p><p>项目地址: <a href="https://gitee.com/kisee/SpringBlade" target="_blank" rel="noopener">https://gitee.com/kisee/SpringBlade</a></p><h3 id="1-wisdom-education"><a href="#1-wisdom-education" class="headerlink" title="1. wisdom-education"></a>1. wisdom-education</h3><p>基于 SpringBoot + Mybatis + Shiro + mysql + redis构建的智慧云智能教育平台。</p><p>项目地址：<a href="https://gitee.com/zhuimengshaonian/wisdom-education" target="_blank" rel="noopener">https://gitee.com/zhuimengshaonian/wisdom-education</a></p><p>项目演示地址<br>管理后台 <a href="http://180.76.146.67:8002" target="_blank" rel="noopener">http://180.76.146.67:8002</a> （admin 123456）<br>学生端 <a href="http://180.76.146.67" target="_blank" rel="noopener">http://180.76.146.67</a> （student 123456）</p><p>智慧云智能教育系统管理平台<br>项目源码地址： <a href="https://gitee.com/zhuimengshaonian/wisdom-education-admin-front" target="_blank" rel="noopener">https://gitee.com/zhuimengshaonian/wisdom-education-admin-front</a></p><ul><li>功能模块：系统首页、教育教学模块、考试管理模块、统计分析模块、系统设置模块</li><li>试题管理：支持excel模板导入试题、支持使用富文本编辑试题及插入数学公式，同时还支持上传试题教学视频</li><li>试卷管理：支持将试卷导出成word文档、html页面进行打印、支持富文本图片导出到word</li><li>试卷批改功能：支持教师后台批改试卷，主观题系统自动评分、非主观题由教师评分、错题可设置添加到学员错题本</li><li>RBCA权限管理：主要包括用户、角色、权限<br>智慧云智能教育平台学生端<br>项目源码地址： <a href="https://gitee.com/zhuimengshaonian/wisdom-education-front" target="_blank" rel="noopener">https://gitee.com/zhuimengshaonian/wisdom-education-front</a></li><li>功能模块：学员在线做课程试题、在线考试、错题本功能记录、考试记录、个人中心</li></ul><h3 id="2-dts-shop"><a href="#2-dts-shop" class="headerlink" title="2. dts-shop"></a>2. dts-shop</h3><p>聚惠星商城 DTS-SHOP，基于 微信小程序 + springboot + vue 技术构建 ，支持单店铺，多店铺入驻的商城平台。项目包含 微信小程序，管理后台。基于java后台语言，已功能闭环，且达到商用标准的一套项目体系。</p><p>项目地址：<a href="https://gitee.com/qiguliuxing/dts-shop" target="_blank" rel="noopener">https://gitee.com/qiguliuxing/dts-shop</a></p><h3 id="3-x-RdbmsSyncTool"><a href="#3-x-RdbmsSyncTool" class="headerlink" title="3.x-RdbmsSyncTool"></a>3.x-RdbmsSyncTool</h3><p>RdbmsSyncTool是使用javaFx开发的关系型数据库同步工具xJavaFxTool的插件集合，可实现打包后让框架自动加载，可在线下载和更新工具，后续小工具将在这个项目中添加，实现动态jar包加载。</p><p>项目地址：<a href="https://gitee.com/xwintop/x-RdbmsSyncTool" target="_blank" rel="noopener">https://gitee.com/xwintop/x-RdbmsSyncTool</a></p><h3 id="4-QuickD"><a href="#4-QuickD" class="headerlink" title="4. QuickD"></a>4. QuickD</h3><p>QuickD是一个前后端分离快速开发平台，是基于 Spring Boot 和 Vue 开发，整合Flowable工作流、Shiro、Redis等，来帮助中小型企业及个人实现敏捷化的应用交付和运营管理，并提供代码生成器、通用前端等业务组件，来帮助开发者聚焦于业务，加速中小型企业数字化转型。<a href="http://website.jhyj56.com/" target="_blank" rel="noopener">http://website.jhyj56.com/</a></p><p>项目地址：<a href="https://gitee.com/quickd/quickd" target="_blank" rel="noopener">https://gitee.com/quickd/quickd</a></p><h3 id="5-JeecgBoot"><a href="#5-JeecgBoot" class="headerlink" title="5. JeecgBoot"></a>5. JeecgBoot</h3><p>基于代码生成器的低代码开发平台，开源界“小普元”超越传统商业开发平台！前后端分离架构：SpringBoot 2.x，Ant Design&amp;Vue，Mybatis-plus，Shiro，JWT。强大的代码生成器让前后端代码一键生成，无需写任何代码! 引领新开发模式(OnlineCoding-&gt; 代码生成-&gt; 手工MERGE)，帮助Java项目解决70%重复工作，让开发更关注业务逻辑，既能快速提高开发效率，帮助公司节省成本，同时又不失灵活性。 <a href="http://www.jeecg.com" target="_blank" rel="noopener">http://www.jeecg.com</a></p><p>项目地址：<a href="https://github.com/zhangdaiscott/jeecg-boot" target="_blank" rel="noopener">https://github.com/zhangdaiscott/jeecg-boot</a></p><h3 id="6-ExeBuilder"><a href="#6-ExeBuilder" class="headerlink" title="6. ExeBuilder"></a>6. ExeBuilder</h3><p>ExeBuilder 是一款利用 JDK 模块化的特性把jar打包成独立exe的工具，它支持GUI和控制台应用程序的创建。</p><p>项目地址：<a href="https://gitee.com/qsyan/ExeBuilder" target="_blank" rel="noopener">https://gitee.com/qsyan/ExeBuilder</a></p><h3 id="7-keycloak"><a href="#7-keycloak" class="headerlink" title="7. keycloak"></a>7. keycloak</h3><p>Open Source Identity and Access Management For Modern Applications and Services <a href="https://www.keycloak.org" target="_blank" rel="noopener">https://www.keycloak.org</a></p><p>项目地址：<a href="https://github.com/keycloak/keycloak" target="_blank" rel="noopener">https://github.com/keycloak/keycloak</a></p><h3 id="8-MaxKey"><a href="#8-MaxKey" class="headerlink" title="8. MaxKey"></a>8. MaxKey</h3><p>MaxKey(马克思的钥匙)，寓意是最大钥匙， 是用户单点登录认证系统（Sigle Sign On System）,支持OAuth 2.0/OpenID Connect、SAML 2.0、JWT、CAS等标准化的开放协议，提供简单、标准、安全和开放的用户身份认证和单点登录，包含用户认证、单点登录、资源管理、权限管理等。</p><p>项目地址：<a href="https://gitee.com/shimingxy/MaxKey" target="_blank" rel="noopener">https://gitee.com/shimingxy/MaxKey</a></p><h3 id="9-microservices-platform"><a href="#9-microservices-platform" class="headerlink" title="9. microservices-platform"></a>9. microservices-platform</h3><p>SpringCloud, 基于SpringBoot2.x、SpringCloud和SpringCloudAlibaba并采用前后端分离的企业级微服务多租户系统架构。并引入组件化的思想实现高内聚低耦合并且高度可配置化，适合学习和企业中使用。真正实现了基于RBAC、jwt和oauth2的无状态统一权限认证的解决方案，面向互联网设计同时适合B端和C端用户，支持CI/CD多环境部署，并提供应用管理方便第三方系统接入；同时还集合各种微服务治理功能和监控功能。模块包括:企业级的认证系统、开发平台、应用监控、慢sql监控、统一日志、单点登录、Redis分布式高速缓存、配置中心、分布式任务调度、接口文档、代码生成等等。</p><p>项目地址： <a href="https://gitee.com/zlt2000/microservices-platform.git" target="_blank" rel="noopener">https://gitee.com/zlt2000/microservices-platform.git</a></p><h3 id="10-middle-ware-parent"><a href="#10-middle-ware-parent" class="headerlink" title="10. middle-ware-parent"></a>10. middle-ware-parent</h3><p>SpringBoot集成各类常用开发中间件，分库分表，缓存，消息队列，定时器，权限管理等组件</p><p>项目地址：<a href="https://gitee.com/cicadasmile/middle-ware-parent" target="_blank" rel="noopener">https://gitee.com/cicadasmile/middle-ware-parent</a></p><h3 id="11-chjm872-mall"><a href="#11-chjm872-mall" class="headerlink" title="11. chjm872/mall"></a>11. chjm872/mall</h3><p>mall项目是一套电商系统，包括前台商城系统及后台管理系统，基于SpringBoot+MyBatis实现，采用Docker容器化部署。 前台商城系统包含首页门户、商品推荐、商品搜索、商品展示、购物车、订单流程、会员中心、客户服务、帮助中心等模块。 后台管理系统包含商品管理、订单管理、会员管理、促销管理、运营管理、内容管理、统计报表、财务管理、权限管理、设置等模块。</p><p>项目地址：<a href="https://github.com/chjm872/mall" target="_blank" rel="noopener">https://github.com/chjm872/mall</a></p><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><ul><li><a href="/java-other/tool">常用软件工具</a></li><li><a href="/java-other/一致性hash">一致性hash算法</a></li><li>面试<ul><li><a href="/java-other/java-interview">java面试题</a></li><li><a href="/java-other/bigdata-interview">大数据面试题</a></li></ul></li><li><a href="/java-other/回车与换行的区别">回车与换行的区别</a></li><li><a href="http://blog.csdn.net/qq1332479771/article/details/56087333" target="_blank" rel="noopener">github上fork项目后，如何同步更新后面提交</a></li><li><a href="/java-other/other">其它</a></li></ul><h2 id="今日头条"><a href="#今日头条" class="headerlink" title="今日头条"></a>今日头条</h2><p><strong>新开了个今日头条号：微观技术，分享各个行业优秀的架构设计方案、技术心得、心路历程等，欢迎各位技术达人关注、经验交流</strong></p><img data-src="http://f.ngall-in.com/alan87/static/images/toutiao.jpeg/200"><h2 id="商务合作，请发邮件到-547708024-QQ邮箱"><a href="#商务合作，请发邮件到-547708024-QQ邮箱" class="headerlink" title="商务合作，请发邮件到 547708024 QQ邮箱"></a>商务合作，请发邮件到 547708024 QQ邮箱</h2>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;有人认为编程是一门技术活，要有一定的天赋，非天资聪慧者不能及也。&lt;/p&gt;
&lt;p&gt;其实不然，笔者计算机专业出身，对于技术这碗饭有一些心得体会，大多数人成为某领域顶级专家可能会有些难度，但应对日常工作，&lt;strong&gt;成长为资深研发工程师、技术专家、甚至成为小团队的Team Leader，并不难。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="其他" scheme="https://www.alan87.top/categories/other/"/>
    
    
      <category term="其他" scheme="https://www.alan87.top/tags/other/"/>
    
  </entry>
  
  <entry>
    <title>mysql5.7性能提升一百倍调优</title>
    <link href="https://www.alan87.top/db/mysql5.7%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E4%B8%80%E7%99%BE%E5%80%8D%E8%B0%83%E4%BC%98/"/>
    <id>https://www.alan87.top/db/mysql5.7%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E4%B8%80%E7%99%BE%E5%80%8D%E8%B0%83%E4%BC%98/</id>
    <published>2020-05-09T05:09:30.000Z</published>
    <updated>2020-10-10T07:03:43.775Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h1><p>全文中一共有常用的（事实上你如果花1-2周阅读、理解、自己动手设一下后是需要这么多参数的）76个参数，笔者把近10年里3个亿万级项目的数据库调优用此篇浓缩到了可能读者只需要2周时间就可以掌握，同时我是按照：</p><a id="more"></a><p>每一个参数干吗？<br>在某些典型硬件配置下的db上参数该设多少？<br>设会怎么样？<br>不设会怎么样？<br>有什么坑如何填坑？<br>有些参数怎么算、算法又如何<br>mysql5.7性能提升一百倍调优宝典（赠给有缘人）<br>这种style来写的，相信此篇会对一些使用mysql的尤其是正在或者将要面临万级并发的项目、网站有所帮助。具体请看文档！</p><p>一千个DBA就有一千种配置方式!</p><p>大家一定记得不要轻易去看网上，要看只看官网！网上很多博客都是错的，连参数都列错了，5.7很多参数和5.6是完全不一样的。</p><p>可能你从未看到过这样的一篇集中火力式的把mysql参数列了这么全的文章，很有兴曾参与过超3万并发的18～19年的数轮520、618、双11、双12保卫战。因此这一篇是汇集了最精华和实战的内容把mysql所有的参数列在这边供大家参考。并且以（64c cpu，128gb内存）的mysql cpu和内存来进行了一轮配置。而此文的内存相关参数部分可以延展至256gb～512gb。</p><p>另外有一点，建议在mysql的服务器上使用ssd。除非并发数永远控制在500-1000内那就没必要使用ssd，普通高速磁盘就可以了。</p><p>你会发觉这篇文章是一篇宝藏，这些参数都能够自己动手试验一篇基本在外面是可以吊打mysql面试官了。</p><h1 id="client域："><a href="#client域：" class="headerlink" title="client域："></a>client域：</h1><h2 id="character-set-client"><a href="#character-set-client" class="headerlink" title="character_set_client"></a>character_set_client</h2><ul><li><p>推荐设置：utf8mb4</p></li><li><p>作用：字符集设定，如果前台有连social mobile application一类包括wechat，并且允许有使用emoji表情的，请开启成utf8mb4</p></li><li><p>如果不配的后果：mysql不支持前端app存表情等字符</p></li><li><p>配置实例：character_set_client=utf8mb4</p></li></ul><h1 id="mysqld域："><a href="#mysqld域：" class="headerlink" title="mysqld域："></a>mysqld域：</h1><h2 id="1-server-id"><a href="#1-server-id" class="headerlink" title="1)server-id"></a>1)server-id</h2><ul><li><p>推荐设置：如果没有做任何主从复制，此值可以不设。</p></li><li><p>作用：遇有主从复制，必设该值，每个参与主从复制的mysql实例的server-id不能重复，必须为阿拉伯数字。</p></li><li><p>如果不配的后果：如果你用的是主从复制，这个id不设那么整个mysql的主从复制会失几。</p></li><li><p>配置实例：server-id=1</p></li></ul><h2 id="2-port"><a href="#2-port" class="headerlink" title="2)port"></a>2)port</h2><ul><li><p>推荐设置：3306</p></li><li><p>作用：mysql实例端口</p></li><li><p>如果不配的后果：默认为3306</p></li><li><p>配置实例：port=3306</p></li></ul><h2 id="3-bind-address"><a href="#3-bind-address" class="headerlink" title="3)bind_address"></a>3)bind_address</h2><ul><li><p>推荐设置：0.0.0.0</p></li><li><p>作用：除非有特殊需要，我们会限制只允许mysql实例被某一个ip方问，不支持多个，生产上都为：0.0.0.0然后使用防火墙策略来控制。</p></li><li><p>如果不配的后果：默认不允许远程登录</p></li><li><p>配置实例：bind_address=0.0.0.0</p></li></ul><h2 id="4-autocommit"><a href="#4-autocommit" class="headerlink" title="4)autocommit"></a>4)autocommit</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：生产上开启成1，如果你开启的是0会有一个这样的情况：</p></li></ul><p>a运行一条insert语句，并未作commit;b去做查询此时b是查询不到的。这种操作一般用于在写store procedure时用到。</p><ul><li><p>如果不配的后果：如果在系统的my.cnf层面把它设成了0，如果在使用时（99%情况是用的1）时，你想要用root在生产运行时把它设成set autocommit = 1都开启不了。而如果你在一开始就没它设置成1，那么当碰到某些特殊场景特别是写store procedure时需要把它设成0时，你是可以手动临时把某一个session给开在0的。</p></li><li><p>配置实例：autocommit = 1</p></li></ul><h2 id="5-character-set-server"><a href="#5-character-set-server" class="headerlink" title="5)character_set_server"></a>5)character_set_server</h2><ul><li><p>推荐设置：utf8mb4</p></li><li><p>作用：字符集设定，如果前台有连social mobile application一类包括wechat，并且允许有使用emoji表情的，请开启成utf8mb4</p></li><li><p>如果不配的后果：mysql不支持前端app存表情等字符</p></li></ul><p>配置实例：character_set_server=utf8mb4</p><h2 id="6-skip-name-resolve"><a href="#6-skip-name-resolve" class="headerlink" title="6)skip_name_resolve"></a>6)skip_name_resolve</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：生产上建议开启成1，这样mysql server不会对客户端连接使用反向dns解析，否则客户端连上后有时在遇有生产高速运行时直接timeout，如果设成了1带来的问题就是你不能在mysql中使用主机名来对客户端权限进行划分，而是需要使用ip。</p></li></ul><p>如果要做成即允许mysql里允许使用主机名来分配客户端连接权限，又要做到不要让mysql去做dns解析，可以在mysql所在主机端的/etc/hosts文件中写上客户端的主机名，因为当客户端连接连上来时，mysql反向查找客户端连接时的域名解析的步骤是：首先查找 /etc/hosts 文件，搜索域名和IP的对应关系。但是这样做也有一个问题，那就是如果你有多个客户端多个mysql主从关系，哪到你要把mysql做成一个dns解析器吗？因此推荐设成1</p><ul><li><p>如果不配的后果：mysql server每一次会对客户端连接使用反向dns解析，经常会出现客户端连上后有timeout现象。</p></li><li><p>配置实例：skip_name_resolve=1</p></li></ul><h2 id="7-max-connections"><a href="#7-max-connections" class="headerlink" title="7)max_connections"></a>7)max_connections</h2><ul><li><p>推荐设置：20,000</p></li><li><p>作用：最大连接数，以前端3万的tps并发，假设redis命中失效50%（这是灾难），那么后端mysql单个主或从开启连接数为：20,000，我们公司在前端并发曾达到过6万，80%被waf、vanish、缓存挡掉，落在db上的qps最高一次为20,000连接，再按照mysql官方，max_connections值受系统os最大打开连接数限制，因此我们需要做以下2步操作：</p><ul><li>1）在 /etc/security/limits.conf 底部增加2行<br>mysql hard nofile 65535<br>mysql soft nofile 65535</li><li>2）在/usr/lib/systemd/system/mysqld.service（视如何安装mysql所决定，用编译安装和yum安装会产生path路径不同。）文件最后添加：<br>LimitNOFILE=65535<br>LimitNPROC=65535<br>$ systemctl daemon-reload<br>$ systemctl restart mysqld.service<br>如不生效重启服务器。</li></ul></li><li><p>如果不配的后果：默认只有150</p></li><li><p>配置实例：max_connections = 20,000</p></li></ul><h2 id="8-max-connect-errors"><a href="#8-max-connect-errors" class="headerlink" title="8)max_connect_errors"></a>8)max_connect_errors</h2><ul><li><p>推荐设置：生产上设10, 开发测试上使用默认100</p></li><li><p>作用：生产上开启成10次，开发测试上使用默认即不设。</p><p>max_connect_errors是一个MySQL中与安全有关的计数器值，它负责阻止过多尝试失败的客户端以防止暴力破解密码的情况。如果需要设置此数值，手动添加。当此值设置为10时，意味着如果某一客户端尝试连接此MySQL服务器，但是失败（如密码错误等等）10次，则MySQL会无条件强制阻止此客户端连接。相关的登录错误信息会记录到performance_schema.host_cache表中。如果希望重置此计数器的值，则必须重启MySQL服务器或者执行</p><p>Mysql&gt; FLUSH HOSTS;</p><p>当这一客户端成功连接一次MySQL服务器后，针对此客户端的max_connect_errors会清零。可以在防火墙上做策略限制某些ip的远程连接。</p></li><li><p>如果不配的后果：默认为100</p></li><li><p>配置实例：max_connect_errors =10</p></li></ul><h2 id="9-innodb-flush-log-at-trx-commit"><a href="#9-innodb-flush-log-at-trx-commit" class="headerlink" title="9)innodb_flush_log_at_trx_commit"></a>9)innodb_flush_log_at_trx_commit</h2><ul><li><p>推荐设置：2</p></li><li><p>作用：(核心交易系统设置为1，默认为1，其他2或者0)，</p><ul><li><p>0代表：log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下在事务提交的时候，不会主动触发写入磁盘的操作。</p></li><li><p>1代表：每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去，该模式为系统默认（因此会保留每一份redo日志）</p></li><li><p>2代表：每次事务提交时MySQL都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下，MySQL会每秒执行一次 flush(刷到磁盘)操作。该模式速度较快，也比0安全，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失。</p></li></ul><p>除非你用的是小型机或者是超大规模mysql集群一类如：游戏行业，那么需要保留每一秒的事务，否则请设成2，要不然会严重影响系统性能。这个参数是5.6所没有的。</p></li><li><p>如果不配的后果：默认为1，影响系统写性能。</p></li><li><p>配置实例：innodb_flush_log_at_trx_commit=2</p></li></ul><h2 id="10-transaction-isolation"><a href="#10-transaction-isolation" class="headerlink" title="10)transaction_isolation"></a>10)transaction_isolation</h2><ul><li><p>推荐设置：READ-COMMITTED</p></li><li><p>作用：此参数直接决定了mysql的性能，oracle中的事务默认级别就是read-commited，而mysql的默认级别是:repeatable-read，它利用自身独有的Gap Lock解决了”幻读”。但也因为Gap Lock的缘故，相比于READ-COMMITTED级别的Record Lock，REPEATABLE-READ的事务并发插入性能受到很大的限制。离级别的选择取决于实际的业务需求（安全与性能的权衡），如果不是金融、电信等事务级别要求很高的业务，完全可以设置成transaction_isolation=READ-COMMITTED。</p><ul><li><p>读未提交（READ-UNCOMMITTED）-它是最低的隔离级别，虽然性能最高，但也不推荐<br>它会读取到其他事务修改尚未提交的数据，使用此隔离级别就需要非常小心，认识到这种级别下的查询结果可能不一致或不可复制，这取决于其他事务同时在做什么。通常，具有此隔离级别的事务只执行查询，而不执行插入、更新或删除操作。<br>在实际环境中，应当根据是否允许出现脏读（dirty reads），不可重复读（non-repeatable reads）和幻读（phantom reads ）现象而选择相应的隔离级别。例如在大数据中，少量的数据不一致不会影响到最后的决策，这种情况下可以使用较低的隔离级别以提交性能和并发性。</p></li><li><p>Read-Committed-推荐: 事务无法看到来自其他事务的未提交数据，但可以看到当前事务启动后另一个事务提交的数据。当拥有这种级别的事务执行 UPDATE … WHERE or DELETE … WHERE操作时，其他事务可能需要等待。但是该事务可以执行 SELECT … FOR UPDATE, and LOCK IN SHARE MODE操作，其他事务不需要等待。</p></li><li><p>Repeatable-read: 这是MySQL的InnoDB引擎默认的隔离级别，它阻止查询的任何行被其他事务更改。因此，阻塞不可重复读，而不是幻读。也就是说在可重复读中，可能会出现幻读。重复读使用一种中等严格的锁定策略，以便事务中的所有查询都能看到来自相同快照(即事务启动时的数据)的数据。当拥有该级别的事务执行 UPDATE … WHERE, DELETE … WHERE, SELECT … FOR UPDATE和LOCK IN SHARE MODE操作时，其他事务可能需要等待。</p></li><li><p>串行化（SERIALIZABLE）-极力不推荐，串行化隔离级别是最高的隔离级别，它使用了最保守的锁策略。它阻止任何其他事务插入或更改此事务读取的数据，直到该事务完成。简单的来说，就是一个事务一个事务的来执行，显然性能会很低。在这种隔离级别下，一个事务中的相同查询可以反复执行，每次查询结果是一样的。从当前事务开始执行，任何更改另一个事务提交的数据的尝试都会导致当前事务等待（阻塞）。这是SQL标准指定的默认隔离级别（注意不是MySQL）。在实践中，这种严格程度是很少需要的。</p></li></ul></li><li><p>如果不配的后果：默认就是repeatable-read</p></li><li><p>配置实例：transaction_isolation = READ-COMMITTED</p></li></ul><h2 id="11-explicit-defaults-for-timestamp"><a href="#11-explicit-defaults-for-timestamp" class="headerlink" title="11)explicit_defaults_for_timestamp"></a>11)explicit_defaults_for_timestamp</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：mysql5.7默认对于timestamp字段会显示“系统当前日期”，就算你在插表时这个timestamp字段留空，它在select出来时也会显示系统日期。因此，这个值的影响范围是你在建表时导致的。</p><p>系统默认这个值是0，在0的情况下，你要让该表的timestamp字段在为null时不显示系统默认时间，你的建表必须为：create table order(o_id int ,updateed_time timestamp null default null) ;</p><p>explicit_defaults_for_timestamp 变量会直接影响表结构，也就是说explicit_defaults_for_timestamp的作用时间是在表定义的时候；你的update | insert 想通过它去改变行为已经太晚了！</p><p>因此，我推荐把这个值设为1.</p></li><li><p>如果不配的后果：默认为0</p></li><li><p>配置实例：explicit_defaults_for_timestamp = 1</p></li></ul><h2 id="12-join-buffer-size"><a href="#12-join-buffer-size" class="headerlink" title="12)join_buffer_size"></a>12)join_buffer_size</h2><ul><li><p>推荐设置：16M</p></li><li><p>作用：系统默认大小为：512k，mac下默认大小为：256k，针对128GB，1万并发的mysql我推荐给到的值为：8~16M<br>对于JOIN KEY 有索引和二级索引，JOIN KEY 无索引mysql会使用到join_buffer_size，一般建议设置一个很小的 GLOBAL 值，完了在 SESSION 或者 QUERY 的基础上来做一个合适的调整。</p><p>如果你拍脑袋给也个4g，我们有1000个并发，就是用掉了4T的内存。。。4T啊。。。你以为你是小型机。适当的去改变它确实可以带来一定的提速，但并不是说很多值越大越好.</p><p>为什么我们设置成4m呢？我们假设我们的mysql所在的vm是128gb，一根这样的join（如果被用到）是4M，1万个也不过用掉40G,而根据官方说法，total加在一起产生的join_buffer_size不要超过你所在系统的50%.默认512k肯定是小了点，我们可以适当放宽，比如说：2M.</p><p>在实际使用场景时我们发觉有这样的高频操作（要看高频出现的有意义的sql的执行计划，并确认该计划的：执行cost如： “<strong>query_cost</strong>“: “1003179606.87”，它产生的cost为：0.93个G,如果它真的很高频出现在调优sql到无法调优的程度，我们会去做set session join_buffer_size = 1024 * 1024 * 1024;这样的操作。</p><p>而不是在一开始的my.cnf中去分配一个暴大的值，我们这边基于128gb，1万connection的并发来说，你给个16M不算小也不算多，我推荐给到8~16M间（这是指在一开始）。</p></li><li><p>如果不配的后果：默认的为256k</p></li><li><p>配置实例：join_buffer_size = 16M</p></li></ul><h2 id="13-tmp-table-size"><a href="#13-tmp-table-size" class="headerlink" title="13)tmp_table_size"></a>13)tmp_table_size</h2><ul><li><p>推荐设置：67108864</p></li><li><p>作用：如果是128gb内存的服务器，我建议是在my.cnf中设成64M<br>通过设置tmp_table_size选项来增加一张临时表的大小，例如做高级GROUP BY操作生成的临时表。默认系统为32M，如果当你的临时表越来越多加在一起超过了这个值，那么mysql会在系统磁盘上创建，这个值不是越多越好，也没有一个合适的值。一开始的建议为&gt;64M，然后在运行时我们通过以下公式来做临时调优</p><p><code>show global status like &#39;created_tmp%&#39;;</code></p><p>把得到的结果中的：(Created_tmp_disk_tables / Created_tmp_tables) * 100% 如果&lt;=25%为最佳值。注意了，在生产时热设定时一定要用类似以下语法：<br><code>set global tmp_table_size=64*1024*1024</code>而不是<code>set global tmp_table_size=64M</code>。</p></li><li><p>如果不配的后果：默认为32M</p></li><li><p>配置实例：tmp_table_size = 67108864</p></li></ul><h2 id="14-tmpdir"><a href="#14-tmpdir" class="headerlink" title="14)tmpdir"></a>14)tmpdir</h2><p>这块参数可以让运维给到，放到大空间里就行了，没什么太敏感的。</p><h2 id="15-max-allowed-packet"><a href="#15-max-allowed-packet" class="headerlink" title="15)max_allowed_packet"></a>15)max_allowed_packet</h2><ul><li><p>推荐设置：134217728</p></li><li><p>作用：如果你经常在应用层碰到了：Got a packet bigger than’max_allowed_packet’ bytes，这时你可以使用<br>show variables like ‘%max_allowed_packet%’;来查看这个值，这个值没有合适，一般如：用客户端导入数据的时候，遇到 错误代码: 1153 - Got a packet bigger than ‘max_allowed_packet’ bytes 终止了数据导入。这样的场景下，当MySQL客户端或mysqld服务器收到大于max_allowed_packet字节的信息包时，将发出“信息包过大”错误，并关闭连接。对于某些客户端，如果通信信息包过大，在执行查询期间，可能会遇到“丢失与MySQL服务器的连接”错误。</p><p>客户端和服务器均有自己的max_allowed_packet变量，因此，如你打算处理大的信息包，必须增加客户端和服务器上的该变量。一般情况下，服务器默认max-allowed-packet为1MB,可以通过在交换机上抓包或者是图形化分析来抓返回结果判断。<br>一般推荐在128gb内存下设置的置为128M.也可以在运行时动态调整：set global max_allowed_packet = 128<em>1024</em>1024</p></li><li><p>如果不配的后果：1M</p></li><li><p>配置实例：max_allowed_packet = 134217728</p></li></ul><h2 id="16-sql-mode"><a href="#16-sql-mode" class="headerlink" title="16)sql_mode"></a>16)sql_mode</h2><p>不需要去设置，使用默认的，这块和性能无关。我们的中台中的sql如果碰到有sql报错，因该是在测试环境上就已经报了，它的作用是用来约束你sql的写法的，如果是一个从头开始开发的应用，我们比如说约束好都是ansi sql写法，对于一个产品，不要去做这种画蛇添足的做法。</p><h2 id="17-interactive-timeout"><a href="#17-interactive-timeout" class="headerlink" title="17)interactive_timeout"></a>17)interactive_timeout</h2><ul><li><p>推荐设置：600</p></li><li><p>作用：单位为s，系统默认为：28800s即8小时。如果这个值太大，你会发觉在mysql中有大量sleep的连接，这些连接又被称为：僵尸连接，僵尸连接一多你真正要用的时候就会抛：too many connection这样的错，因此对于长久不用的连接，我们一般要使用“踢出机制”，多久对于一个活动累的sql进行踢呢？</p><p>我们说如果有一个长事务，它要执行1小时，我不知道这是不是属于正常？当然如果你设了太短，说1分钟就把它踢了，还真不一定踢的对，按照我们在oracle中设置的best practice我们都会把它放到10分钟。你有一条sql连着，10分钟不用，我就把它踢了，这也算正常。</p><p>但是在高并发的场景下这个timeout会缩短至3-5分钟，这就是为什么我提倡我们的非报表即时类查询需要优化到sql的运行时间不超过300ms的原因，因为在高并发场景下，超过500ms的sql都已经很夸张了。保守点我觉得可以设成10分钏，在应用端由其通过jdbc连接数据库的，做的好的应用都会在jdbc里有一个autoconnect参数，这个autoconnect参数就要和mysql中的wait_timeout来做匹配了。</p><p>同时在应用端要有相应的validate sql一类的操作来keep alived。不过我更推荐使用”连接池内连接的生存周期（idleConnectionTestPeriod）”来做设置，把这个值设成 &lt; mysql内的这两个值将会是最好，同时，idleConnectionTestPeriod会使用到异步的方式去做超时check。<br>如c3p0中的：idleConnectionTestPeriod和testConnectionOnCheckin相当可靠</p><ul><li>interactive_timeout：交互式连接超时时间(mysql工具、mysqldump等)</li><li>wait_timeout：非交互式连接超时时间，默认的连接mysql api程序,jdbc连接数据库等<br>interactive_timeout针对交互式连接，wait_timeout针对非交互式连接。所谓的交互式连接，即在mysql_real_connect()函数中使用了CLIENT_INTERACTIVE选项。</li></ul><p><code>show global variables like &#39;wait_timeout&#39;;</code></p><ol><li><p>wait_timeout 只是针对空闲会话有影响。</p></li><li><p>session级别的wait_timeout继承global级别的interactive_timeout的值。而global级别的session则不受interactive_timeout的影响。</p></li><li><p>交互式会话的timeout时间受global级别的interactive_timeout影响。因此要修改非交互模式下的timeout，必须同时修改interactive_timeout的值。</p></li><li><p>非交互模式下，wait_timeout参数继承global级别的wait_timeout。</p></li></ol></li><li><p>如果不配的后果：系统默认为28800</p></li><li><p>配置实例：interactive_timeout = 600</p></li></ul><h2 id="18-wait-timeout"><a href="#18-wait-timeout" class="headerlink" title="18)wait_timeout"></a>18)wait_timeout</h2><p>同interactive_timeout，两个值都设成一样。</p><h2 id="19-read-buffer-size"><a href="#19-read-buffer-size" class="headerlink" title="19)read_buffer_size"></a>19)read_buffer_size</h2><ul><li><p>推荐设置：4194304</p></li><li><p>作用：这个值其实轻易是用不到的，因为，它只对2种场景的full table scan产生影响而不是所有的full table scan，同时从mysql5.6以后开始没有数据块多块读的功能,与是否设置 read_buffer_size参数无关。应用场景：</p><ul><li><p>1）SELECT INTO … OUTFILE ‘fileName‘</p></li><li><p>2）When filesort is used, during merge buffers and when merged results are written to a temporary file, then writes are buffered</p></li></ul><p>一般保留默认:64k，保守作法是设置在1～4M，不过它的应用场景很有限，对于互联网场景真的不太用，我推荐设成4M</p></li><li><p>如果不配的后果：默认为64k</p></li><li><p>配置实例：read_buffer_size = 4194304</p></li></ul><h2 id="20-read-rnd-buffer-size"><a href="#20-read-rnd-buffer-size" class="headerlink" title="20)read_rnd_buffer_size"></a>20)read_rnd_buffer_size</h2><ul><li><p>推荐设置：8388608</p></li><li><p>作用：就是当数据块的读取需要满足一定的顺序的情况下，MySQL 就需要产生随机读取，进而使用到 read_rnd_buffer_size 参数所设置的内存缓冲区。</p><p>它的默认为256k，最大可以设到2G，它会对order by关键字起作用，当order by的计划成本超出了sort_buffer_size后，mysql会产用随机读取并消耗额外的内容，很多外面的博客说它是只对myisam引擎起作用，</p><p>但其实不是，该参数还真的覆盖到所有引擎，一般它的推荐设置在8-16M，我推荐8M，根据sql分析计划如果碰到高频的查询且order by的返回包体都很大，那么再在session级别去放。</p></li><li><p>如果不配的后果：默认为256k</p></li><li><p>配置实例：read_rnd_buffer_size = 8388608</p></li></ul><h2 id="21-sort-buffer-size"><a href="#21-sort-buffer-size" class="headerlink" title="21)sort_buffer_size"></a>21)sort_buffer_size</h2><ul><li><p>推荐设置：4194304</p></li><li><p>作用：每个会话执行排序操作所分配的内存大小。想要增大max_sort_length参数，需要增大sort_buffer_size参数。</p><p>如果在SHOW GLOBAL STATUS输出结果中看到每秒输出的Sort_merge_passes状态参数很大，可以考虑增大sort_buffer_size这个值来提高ORDER BY 和 GROUP BY的处理速度。建议设置为1~4MB。</p><p>当个别会话需要执行大的排序操作时，在会话级别增大这个参数。所谓会话级别，我举个例子，你拍脑袋一下，说我设个32M,你所它乘10,000请求，这得多大内存。</p><p>另外，千万要注意，在mysql内存，当你的sort_buffer_size在超过2K时在底层使用的是mmap()的c函数去做内存分配的，而不是malloc()，做过c的都知道mmap()是一个矢量单位，因此它会付出性能的影响，能影响多少呢？单条sql影响值在30%。</p></li><li><p>如果不配的后果：默认值为1M</p></li><li><p>配置实例：sort_buffer_size =4194304</p></li></ul><h2 id="22-innodb-page-size"><a href="#22-innodb-page-size" class="headerlink" title="22)innodb_page_size"></a>22)innodb_page_size</h2><ul><li><p>推荐设置：8192</p></li><li><p>作用：这个值可要小心，一般它在设置后就不能轻易改了，一般来说我们都认为，值越大越好，不是的， 这个值它的原理是这样的：size越小，内存划分粒度越大，使用率越高，但是会有其他问题，就是限制了索引字段还有整行的大小。</p><p>innodb引擎读取内存还有更新都是一页一页更新的，这个innodb_page_size决定了，一个基本页的大小。常用B+Tree索引，B+树是为磁盘及其他存储辅助设备而设计一种平衡查找树（不是二叉树）。</p><p>B+树中，所有记录的节点按大小顺序存放在同一层的叶子节点中，各叶子节点用指针进行连接。MySQL将每个叶子节点的大小设置为一个页的整数倍，利用磁盘的预读机制，能有效减少磁盘I/O次数，提高查询效率。 </p><p>如果一个行数据，超过了一页的一半，那么一个页只能容纳一条记录，这样B+Tree在不理想的情况下就变成了双向链表。我们拿白话来说就是：你越大，空间利用率更高，但是越小呢越有助于性能但是这边一定一定有一个“但是”，但是小到一定的量反而性能不好，为什么呢？太大上面我已经举例了，太小。。。mysql的页间的check point太频繁。怎么样做才能达到一个合理值呢？</p><p>这个我们是在全真生产环境、全数据量下用测试工具去对4k,8k,16k三种场景压测得到的吞吐量即tps来做观察的，我这边可以给出一个推荐值，以单表超1000w条数据基于中台1.1的数据库结果（每个表都超1000w），我们在设置该值为：8K时，它的吞吐达到最优。</p></li><li><p>如果不配的后果：32位下默认为8192 , 64位下默认为16384</p></li><li><p>配置实例：innodb_page_size = 8192</p></li></ul><h2 id="23-innodb-buffer-pool-size"><a href="#23-innodb-buffer-pool-size" class="headerlink" title="23)innodb_buffer_pool_size"></a>23)innodb_buffer_pool_size</h2><ul><li><p>推荐设置：72G</p></li><li><p>作用：这个值和innodb_buffer_pool_instances相辅相成。在32位机器下，innodb_buffer_pool_instances一般为1，在64位机器上，这个值为8-64.</p><p>pool_instances其实为cpu核数，它的作用是：</p><ul><li><p>1）对于缓冲池在数千兆字节范围内的系统，通过减少争用不同线程对缓存页面进行读写的争用，将缓冲池划分为多个单独的实例可以提高并发性。</p></li><li><p>2）使用散列函数将存储在缓冲池中或从缓冲池读取的每个页面随机分配给其中一个缓冲池实例。每个缓冲池管理自己的空闲列表， 刷新列表， LRU和连接到缓冲池的所有其他数据结构，并受其自己的缓冲池互斥量保护。</p></li></ul><p>innodb_buffer_pool_size的设置需要为pool_instance的整数倍。</p><p>网上很多说innodb_buffer_pool_size为系统的70%，这是错的！因为你真的设了70%你的swap空间会被挤压，你不要忘了你还有os，上面还可能有监控agent端。一旦swap空间被挤压后你的mysql反面严重拖慢读写。</p><p>此处强烈建议设成内存的20%-65%间（独立的mysql服务器），为什么有一个20%呢？对于&lt;4gb的mysql用服务器来说按照20%系统内存来设置。由于我们是128gb的内存，此处我建议使用72G,如果内存超过128gb，一般我们会把pool instance设成16个，每个开启10g左右的buffer_pool_size，对于256gb内存的服务器来说我们可以这样设。</p></li><li><p>如果不配的后果：默认为64</p></li><li><p>配置实例：innodb_buffer_pool_size = 72G</p></li></ul><h2 id="24-innodb-buffer-pool-instances-8"><a href="#24-innodb-buffer-pool-instances-8" class="headerlink" title="24)innodb_buffer_pool_instances = 8"></a>24)innodb_buffer_pool_instances = 8</h2><p>这个参数同innodb_buffer_pool_size一起讲解了。</p><h2 id="25-innodb-buffer-pool-load-at-startup"><a href="#25-innodb-buffer-pool-load-at-startup" class="headerlink" title="25)innodb_buffer_pool_load_at_startup"></a>25)innodb_buffer_pool_load_at_startup</h2><ul><li><p>推荐设置：0</p></li><li><p>作用：这两个参数几乎没人用一般dba也不曾听说过，它是什么意思呢？<br>Mysql在第一次（重启）时，它的buffer_pool_size中是空的，随着mysql运行时间1-2小时后，它的buffer_pool_size里开始被塞入东西，它分为old block与new block，而此时mysql性能开始一点点读写效率上去了，那是因为在buffer_pool_size没有放入东西时，mysql很多读写发生在硬盘上，从硬盘到内存的加载过程是一个比较漫长和耗时的过程，因此我们往往会设一个startup=1以加快这个“预热”过程。</p><p>它与参数shutdown配合使用，即相当于把上次使用的innot_db_buffer_pool里的东西在启动时先做一次加载，以加快mysql的性能。它会在innodb的数据目录中生成一个文件：ib_buffer_pool。</p><p>高度注意：加入了startup和shutdown=1时，mysql的启动过程会比较慢，如果你上次的dump出的buffer_pool里的东西有50多g那么mysql启动时的加载过程会变得比较慢。这个值很多人使用默认的0（不开启），它的影响就是你在mysql重启后，一开始你的系统读写性能不如在你系统运行了2-4小时（视db读写而定）反而它的读写性能变好了。不设使用默认值0。</p></li><li><p>如果不配的后果：不配的话系统默认为0</p></li><li><p>配置实例：innodb_buffer_pool_load_at_startup = 0</p></li></ul><h2 id="26-innodb-buffer-pool-dump-at-shutdown"><a href="#26-innodb-buffer-pool-dump-at-shutdown" class="headerlink" title="26)innodb_buffer_pool_dump_at_shutdown"></a>26)innodb_buffer_pool_dump_at_shutdown</h2><p>同上面的startup参数以及解说</p><h2 id="27-innodb-lru-scan-depth"><a href="#27-innodb-lru-scan-depth" class="headerlink" title="27)innodb_lru_scan_depth"></a>27)innodb_lru_scan_depth</h2><ul><li><p>推荐设置：2000</p></li><li><p>作用：innodb_io_capactiy 在sas 15000转的下配置800就可以了，在ssd下面配置2000以上。<br>可使用默认配置。即不设。</p></li><li><p>如果不配的后果：默认为200，db吞吐量上不去。</p></li><li><p>配置实例：innodb_lru_scan_depth = 2000</p></li></ul><p>28)innodb_lock_wait_timeout</p><ul><li><p>推荐设置：60</p></li><li><p>作用：我们一般会碰到，mysql innodb_lock_wait_timeout这个错，这个错是慢sql导致，<br>它代表的是慢sql的事务锁超过了mysql锁超时的设置了。默认这个值为：50s，这个值是可以动态改变的，我不建议去改这个值，因为一个sql能达50s这得多夸张？</p><p>动态改变命令如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> <span class="keyword">VARIABLES</span> <span class="keyword">LIKE</span> <span class="string">'innodb_lock_wait_timeout'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> innodb_lock_wait_timeout=<span class="number">500</span>;</span><br></pre></td></tr></table></figure><p>把它设成60s足够了。</p></li><li><p>如果不配的后果：默认为50s</p></li><li><p>配置实例：innodb_lock_wait_timeout = 60</p></li></ul><h2 id="29-innodb-io-capacity-max"><a href="#29-innodb-io-capacity-max" class="headerlink" title="29)innodb_io_capacity_max"></a>29)innodb_io_capacity_max</h2><ul><li><p>推荐设置：8000</p></li><li><p>作用：这个值很重要，它对读无效，对写很有决定意义。</p><p>它会直接决定mysql的tps（吞吐性能），这边给出参考：sata/sas硬盘这个值在200. sas raid10: 2000，ssd硬盘：8000， fusion-io（闪存卡）：25,000-50,000</p><p>本调优基于的是ssd，此值设置为8000，笔者上一家公司互联网金融是把一整个mysql扔到了闪存卡里的，因此设置的值为：50,000. 需要根据paas或者是ias的vm的硬盘性号来定</p></li><li><p>如果不配的后果：默认为200，系统吞吐上不去。</p></li><li><p>配置实例：innodb_io_capacity_max = 8000</p></li></ul><h2 id="30-innodb-io-capacity"><a href="#30-innodb-io-capacity" class="headerlink" title="30)innodb_io_capacity"></a>30)innodb_io_capacity</h2><p>它是io_capacity_max的一半，同样，它对读无效对写有决定意义。</p><ul><li>配置实例：innodb_io_capacity_max = 4000</li></ul><h2 id="31-innodb-flush-method"><a href="#31-innodb-flush-method" class="headerlink" title="31)innodb_flush_method"></a>31)innodb_flush_method</h2><ul><li><p>推荐设置：O_DIRECT</p></li><li><p>作用：推荐使用O_DIRECT。让我们一起来理解一下，它有3种模式去刷数据文件与redo log的buffer：</p><ul><li><p>1）fdatasync 写数据时，write这一步并不需要真正写到磁盘才算完成（可能写入到操作系统buffer中就会返回完成），真正完成是flush操作，buffer交给操作系统去flush,并且文件的元数据信息也都需要更新到磁盘。</p><p>fsync(int fd)函数，该函数作用是flush时将与fd文件描述符所指文件有关的buffer刷写到磁盘，并且flush完元数据信息(比如修改日期、创建日期等)才算flush成功。它对磁盘的io读写会很频繁.</p></li><li><p>2) O_DSYNC 写日志操作是在write这步完成，而数据文件的写入是在flush这步通过fsync完成</p></li><li><p>3）O_DIRECT则表示我们的write操作是从mysql innodb buffer里直接向磁盘上写，它会充分利用缓存<br>O_DIRECT模式的free内存下降比较慢，因为它是据文件的写入操作是直接从mysql innodb buffer到磁盘的，并不用通过操作系统的缓冲，而真正的完成也是在flush这步,日志还是要经过OS缓冲，O_DIRECT在SQL吞吐能力上较好。<br><img data-src="https://img-blog.csdn.net/20170525170219701?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc21vb3RoMDA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p></li></ul></li><li><p>如果不配的后果：它的默认值为fdatasync。</p></li><li><p>配置实例：innodb_flush_method = O_DIRECT</p></li></ul><h2 id="32-innodb-file-format"><a href="#32-innodb-file-format" class="headerlink" title="32)innodb_file_format"></a>32)innodb_file_format</h2><ul><li><p>推荐设置：Barracuda</p></li><li><p>作用：推荐使用Barracuda模式,它是启用表压缩用的，如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`test_1`</span> (</span><br><span class="line"></span><br><span class="line"><span class="string">`x`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span></span><br><span class="line"></span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=<span class="number">8</span>;</span><br></pre></td></tr></table></figure><p>建完后可以通过：<code>show table status like &#39;test_1&#39;;</code>来查看是否已经启用了表压缩了。</p><p>innodb_file_format有这么几种模式：</p><p>Antelope-羚羊模式，支持Redundant（冗余）、Compact（紧凑）模式</p><p>Barracuda-梭子鱼,是InnoDB Plugin支持的文件格式，在原来的基础上新增了两种数据表格式的支持：Dynamic 和 Compressed</p><p>因此我推荐使用：Barracude模式，因为它可以兼容其它数据模式。</p><p>它也可以在运行时动态改变：<code>SET GLOBAL innodb_file_format_max = barracuda;</code></p></li><li><p>如果不配的后果：它默认使用的是叫“联合模式”，即不是棱子鱼也不是羚羊。</p></li><li><p>配置实例：innodb_file_format = Barracuda</p></li></ul><h2 id="33-innodb-file-format-max"><a href="#33-innodb-file-format-max" class="headerlink" title="33)innodb_file_format_max"></a>33)innodb_file_format_max</h2><p>这个参数必须和innodb_file_format参数一致，一定记住，要不然不生效。</p><h2 id="34-innodb-log-group-home-dir-redolog"><a href="#34-innodb-log-group-home-dir-redolog" class="headerlink" title="34)innodb_log_group_home_dir = /redolog/"></a>34)innodb_log_group_home_dir = /redolog/</h2><p>这个就不用解释了，太傻瓜了。这种路径的都可由运维决定，记得挂在大磁盘下。</p><h2 id="35-innodb-undo-directory-undolog"><a href="#35-innodb-undo-directory-undolog" class="headerlink" title="35)innodb_undo_directory = /undolog/"></a>35)innodb_undo_directory = /undolog/</h2><p>这个就不用解释了，太傻瓜了。这种路径的都可由运维决定，记得挂在大磁盘下。</p><h2 id="36-innodb-undo-logs-128"><a href="#36-innodb-undo-logs-128" class="headerlink" title="36)innodb_undo_logs = 128"></a>36)innodb_undo_logs = 128</h2><ul><li><p>推荐设置：128</p></li><li><p>作用：指定回滚段的个数（早期版本该参数名字是innodb_rollback_segments），默认128个。每个回滚段可同时支持1024个在线事务。这些回滚段会平均分布到各个undo表空间中。该变量可以动态调整，但是物理上的回滚段不会减少，只是会控制用到的回滚段的个数。现在SSD非常普及。innodb_undo_logs可以默认为128不变。</p></li><li><p>如果不配的后果：默认就是128</p></li><li><p>配置实例：innodb_undo_logs = 128</p></li></ul><h2 id="37-innodb-undo-tablespaces"><a href="#37-innodb-undo-tablespaces" class="headerlink" title="37)innodb_undo_tablespaces"></a>37)innodb_undo_tablespaces</h2><ul><li><p>推荐设置：3</p></li><li><p>作用：推荐：3，默认为3<br>定单独存放的undo表空间个数，例如如果设置为3，则undo表空间为undo001、undo002、undo003，每个文件初始大小默认为10M。该参数我们推荐设置为大于等于3，更多的碎片文件会影响磁盘的io性能，而不够碎片同样影响mysql的吞吐率，在ssd上一般最佳的配置在3.</p><p>如果只有1个undo表空间，那么整个系统在此过程中将处于不可用状态。为了尽可能降低truncate对系统的影响，建议将该参数最少设置为3；</p></li><li><p>如果不配的后果：默认为：3</p></li><li><p>配置实例：innodb_undo_tablespaces = 3</p></li></ul><h2 id="38-innodb-flush-neighbors"><a href="#38-innodb-flush-neighbors" class="headerlink" title="38)innodb_flush_neighbors"></a>38)innodb_flush_neighbors</h2><ul><li><p>推荐设置：推荐为：0</p></li><li><p>作用：这个参数很要紧，目前在ssd盛行的情况下我们都把它设为0（不开启），如果你设置成了1即开启（默认状态）InnoDB就会刷新一个extent中的所有页面，因为SSD在随机IO上没有额外负载，所以不需要启用该特性，开启了反而多此一句。下面给出一段mysql5.7源码编译前程序员看的readme里的一句话：</p><p>This new default changes MySQL to cater for SSDs and fast storage devices by default. We expect that for the majority of users, this will result in a small performance gain. Users who are using slower hard drives may see a performance loss, and are encouraged to revert to the previous defaults by setting innodb_flush_neighbors=1.</p></li><li><p>如果不配的后果：它的默认是1，不是0.这个参数对机械硬盘来说很有效，可以减少随机io，增加性能。如果是ssd类磁盘，建议设置为0，可以更快的刷新脏页。如果你把它设为1同时又是ssd那就显得没必要了。这边普及一下小知识，如果你装过8.0，你可以去看一下，8.0已经把这个默认值设为0了。</p></li><li><p>配置实例：innodb_flush_neighbors = 0</p></li></ul><h2 id="39-innodb-log-file-size"><a href="#39-innodb-log-file-size" class="headerlink" title="39)innodb_log_file_size"></a>39)innodb_log_file_size</h2><ul><li><p>推荐设置：</p><ul><li><p>第1步：<code>show engine innodb status;</code></p><p>得到：</p><p>Log sequence number 2944118284</p><p>Log flushed up to 2944118283</p><p>Last checkpoint at 2724318261</p></li><li><p>第2步：设innodb_log_file_size=Log sequence number-last checkpoint at=select (2944118284-2724318261)/1024/1024; =209M</p></li><li><p>第3步：设真正的innodb_log_file_size&lt;=(innodb_log_files_in_group<em>innodb_log_file_size)</em>0.75,innodb_log_files_in_group为2（默认），得：</p></li><li><p>第4步：select 209/(2*0.75); =139.33即：139m，此时可把这个值设为140M</p></li></ul></li><li><p>作用：这个值的默认为5M，是远远不够的，在安装完mysql时需要尽快的修改这个值。</p><p>如果对 Innodb 数据表有大量的写入操作，那么选择合适的 innodb_log_file_size 值对提升MySQL性能很重要。然而设置太大了，就会增加恢复的时间，因此在MySQL崩溃或者突然断电等情况会令MySQL服务器花很长时间来恢复。</p><p>而这个值是没有一个绝对的概念的，MySQL的InnoDB 存储引擎使用一个指定大小的Redo log空间（一个环形的数据结构）。Redo log的空间通过innodb_log_file_size和innodb_log_files_in_group（默认2）参数来调节。</p><p>将这俩参数相乘即可得到总的可用Redo log 空间。尽管技术上并不关心你是通过innodb_log_file_size还是innodb_log_files_in_group来调整Redo log空间，不过多数情况下还是通过innodb_log_file_size 来调节。</p><p>为InnoDB引擎设置合适的Redo log空间对于写敏感的工作负载来说是非常重要的。然而，这项工作是要做出权衡的。你配置的Redo空间越大，InnoDB就能更好的优化写操作；然而，增大Redo空间也意味着更长的恢复时间当出现崩溃或掉电等意外时。</p><p>我们是通过“测试”得到，怎么测试下面给出方法论：一般情况下我们可以按照每1GB的Redo log的恢复时间大约在5分钟左右来估算。如果恢复时间对于你的使用环境来说很重要，我建议你做一些模拟测试，在正常工作负载下（预热完毕后）模拟系统崩溃，来评估更准确的恢复时间。你可以安装 Percona Monitoring and Management，在该pmm的percona monitoring and management图表中，主要看：</p><ul><li><p>1）Uncheckpointed Bytes ，如果它已经非常接近 Max Checkpoint Age，那么你几乎可以确定当前的 innodb_log_file_size 值因为太小已经某种程度上限制了系统性能。增加该值可以较为显著的提升系统性能。</p></li><li><p>2）Uncheckpointed Bytes 远小于 Max Checkpoint Age，这种情况下再增加 innodb_log_file_size 就不会有明显性能提升。</p></li></ul><p>在调整完log_file_size后我们再到pmm中去看：Redo Log空间指标，比如说我们看到了1小时内有60g数据被写入日志文件，差不多就是每10分钟会有10g数据在进行“写日志“，我们需要牢牢记得，这个”写日日土已“的时间拖得越久、出现的频次越少就越有助于mysql的innodb的性能。因此这个值没有绝对推荐。如果你没有pmm，那么我们来人肉算，在上面我已经给出了人肉算的详细例子！</p></li><li><p>如果不配的后果：默认是5M，这是肯定不够的。</p></li><li><p>配置实例：innodb_log_file_size = 140M</p></li></ul><h2 id="40-innodb-log-buffer-size"><a href="#40-innodb-log-buffer-size" class="headerlink" title="40)innodb_log_buffer_size"></a>40)innodb_log_buffer_size</h2><ul><li><p>推荐设置：16777216</p></li><li><p>作用：对于较小的innodb_buffer_pool_size，我们会把它设成和innodb_buffer_pool_size一样。<br>而当超过4gb的innodb_buffer_pool_size时，我们的建议是把它切的够碎，这是mysql5.7里新带的特性，它的默认在8m，但是对于大量有事务操作的mysql我们推荐在写操作库上设置：16m</p><p>此参数确定写日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，但意外的故障将会丢失数据.官方的方档建议设置为1－8M之间！</p></li><li><p>如果不配的后果：默认是8M</p></li><li><p>配置实例：innodb_log_buffer_size = 16777216</p></li></ul><h2 id="41-innodb-purge-threads"><a href="#41-innodb-purge-threads" class="headerlink" title="41)innodb_purge_threads"></a>41)innodb_purge_threads</h2><ul><li><p>推荐设置：0</p></li><li><p>作用：这个参数轻易不用的，我推荐它设为：0，为什么呢？这个参数是和innodb_force_recovery关联起来的，只有当数据库崩溃后重启时才会临时去设的。它的使用场景如下：</p><p>mysql断电，重启后无效，起不来。所以我们根据innodb_force_recovery的参数：</p><ol><li><p>(SRV_FORCE_IGNORE_CORRUPT):忽略检查到的corrupt页。</p></li><li><p>(SRV_FORCE_NO_BACKGROUND):阻止主线程的运行，如主线程需要执行full purge操作，会导致crash。</p></li><li><p>(SRV_FORCE_NO_TRX_UNDO):不执行事务回滚操作。</p></li><li><p>(SRV_FORCE_NO_IBUF_MERGE):不执行插入缓冲的合并操作。</p></li><li><p>(SRV_FORCE_NO_UNDO_LOG_SCAN):不查看重做日志，InnoDB存储引擎会将未提交的事务视为已提交。</p></li><li><p>(SRV_FORCE_NO_LOG_REDO):不执行前滚的操作。</p></li></ol><p>我们在my.cnf中如下设置：</p><p>innodb_force_recovery = 6</p><p>innodb_purge_threads = 0</p><p>记住，一旦当innodb_force_recovery&gt;2时，要把innodb_purge_threads设成0.</p></li><li><p>如果不配的后果：默认不要去设，可以不配，出现了问题在recover需要时再去改。</p></li><li><p>配置实例：innodb_purge_threads = 0</p></li></ul><h2 id="42-innodb-large-prefix"><a href="#42-innodb-large-prefix" class="headerlink" title="42)innodb_large_prefix"></a>42)innodb_large_prefix</h2><p>推荐设置：1</p><p>作用：如果你的客户端和服务端的字符集设成了utf8mb4，那么我们需要把这个开关开启，为什么呢？mysql在5.6之前一直都是单列索引限制767，起因是256×3-1。这个3是字符最大占用空间（utf8）。但是在5.6以后，开始支持4个字节的uutf8。255×4&gt;767, 于是增加了这个参数。这个参数默认值是OFF。当改为ON时，允许列索引最大达到3072.<br>  在mysql5.6中这个开关叫on, off。而在5.7中叫0和1，由于我们前面设置了utf8mb4，因此这边我们必须把这个参数开启。</p><ul><li><p>如果不配的后果：不配会有问题，特别是索引会无效、或者不是走最优计划，如果你的字符集是utf8mb4，那么这个值必开启。</p></li><li><p>配置实例：innodb_large_prefix = 1</p></li></ul><h2 id="43-innodb-thread-concurrency"><a href="#43-innodb-thread-concurrency" class="headerlink" title="43)innodb_thread_concurrency"></a>43)innodb_thread_concurrency</h2><ul><li><p>推荐设置：装mysql的服务器的cpu的核数</p></li><li><p>作用：如：64核cpu，那么推荐：64（&lt;=cpu核数）<br>如果一个工作负载中，并发用户线程的数量小于等于64，建议设置innodb_thread_concurrency=0;而事实上我们的系统是处于大并发大事务的情况下的，怎么来算这个值？建议是先设置为128，然后我们不断的降这个值，直到发现能够提供最佳性能的线程数。为了安全起间我们会把它设成和cpu一样大小。</p></li><li><p>如果不配的后果：默认在64位下会是8</p></li><li><p>配置实例：innodb_thread_concurrency = 64</p></li></ul><h2 id="44-innodb-print-all-deadlocks"><a href="#44-innodb-print-all-deadlocks" class="headerlink" title="44)innodb_print_all_deadlocks"></a>44)innodb_print_all_deadlocks</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：推荐：1 ，当mysql 数据库发生死锁时， innodb status 里面会记录最后一次死锁的相关信息，但mysql 错误日志里面不会记录死锁相关信息，要想记录，启动 innodb_print_all_deadlocks 参数 。</p></li><li><p>如果不配的后果：不会记录该信息。</p></li><li><p>配置实例：innodb_print_all_deadlocks = 1</p></li></ul><h2 id="45-innodb-strict-mode"><a href="#45-innodb-strict-mode" class="headerlink" title="45)innodb_strict_mode"></a>45)innodb_strict_mode</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：必须开启，没得选择，1，为什么？<br>从MySQL5.5.X版本开始，你可以开启InnoDB严格检查模式，尤其采用了页数据压缩功能后，最好是开启该功能。开启此功能后，当创建表（CREATE TABLE）、更改表（ALTER TABLE）和创建索引（CREATE INDEX）语句时，如果写法有错误，不会有警告信息，而是直接抛出错误，这样就可直接将问题扼杀在摇篮里。</p></li><li><p>如果不配的后果：如果不配碰到开发或者非专业的dba会把旧ddl语句生效在5.7内，另外一个问题就是ddl语句出错时报错不明显，这会影响到“主从复制”，至于dll为什么会影响到主从复制，我们后面会在“slave_skip_errors = ddl_exist_errors”中详细解说。</p></li><li><p>配置实例：innodb_strict_mode = 1</p></li></ul><h2 id="46-log-error"><a href="#46-log-error" class="headerlink" title="46)log_error"></a>46)log_error</h2><p>error log所在位置，这个不用多讲，可以和mysql log放在同一路径下，文件名能够和其它log区分开来。</p><h2 id="47-slow-query-log"><a href="#47-slow-query-log" class="headerlink" title="47)slow_query_log"></a>47)slow_query_log</h2><p>建议开启</p><h2 id="48-slow-query-log-file"><a href="#48-slow-query-log-file" class="headerlink" title="48)slow_query_log_file"></a>48)slow_query_log_file</h2><p>慢sql所在位置，这个不用多讲，可以和mysql log放在同一路径下，文件名能够和其它log区分开来。</p><h2 id="49-log-queries-not-using-indexes-1"><a href="#49-log-queries-not-using-indexes-1" class="headerlink" title="49)log_queries_not_using_indexes=1"></a>49)log_queries_not_using_indexes=1</h2><p>强烈建议开启成1.</p><h2 id="50-log-slow-admin-statements-1"><a href="#50-log-slow-admin-statements-1" class="headerlink" title="50)log_slow_admin_statements = 1"></a>50)log_slow_admin_statements = 1</h2><p>强烈建议开启成1.</p><h2 id="51-log-slow-slave-statements-1"><a href="#51-log-slow-slave-statements-1" class="headerlink" title="51)log_slow_slave_statements = 1"></a>51)log_slow_slave_statements = 1</h2><p>强烈建议开启成1.</p><h2 id="52-log-throttle-queries-not-using-indexes"><a href="#52-log-throttle-queries-not-using-indexes" class="headerlink" title="52)log_throttle_queries_not_using_indexes"></a>52)log_throttle_queries_not_using_indexes</h2><ul><li><p>推荐设置：在一开始上线后的初期我们会开成30～50条。随着性能逐渐优化我们会把这个数量开成10.</p></li><li><p>作用：上线前一段时间会不太稳定，我们发生过近几十条sql没有走index</p></li><li><p>如果不配的后果：不配不开启，建议开启。</p></li><li><p>配置实例：log_throttle_queries_not_using_indexes = 50</p></li></ul><h2 id="53-expire-logs-days"><a href="#53-expire-logs-days" class="headerlink" title="53)expire_logs_days"></a>53)expire_logs_days</h2><ul><li><p>推荐设置：30</p></li><li><p>作用：这个值不能太大，因为你不是土豪，不能让binlog无限占用你的磁盘空间，记得这个值一旦设小，你需要做好binlog备份策略，30这个值就是30天，前提是你的binlog的备份做的有效且不占用mysql的磁盘空间。</p></li><li><p>如果不配的后果：默认是0，即永不过期。</p></li><li><p>配置实例：expire_logs_days = 30</p></li></ul><h2 id="54-long-query-time"><a href="#54-long-query-time" class="headerlink" title="54)long_query_time"></a>54)long_query_time</h2><ul><li><p>推荐设置：10</p></li><li><p>作用：默认为10秒种，即一切&gt;=10s的sql都会被记录。我建议在开始刚上线期设成10（用默认值），越着慢sql调优越来越好，可以把这个值设成1.因为秒数越低，记录的sql越多，记录越多，也会造成mysql过慢。<br>另外不能完全依赖于mysql的慢sql log，而是应该布署druid sql实时查看器或者是apm或者是专业的慢sql实时查询器。</p></li><li><p>如果不配的后果：默认为10</p></li><li><p>配置实例：long_query_time = 10</p></li></ul><h2 id="55-min-examined-row-limit"><a href="#55-min-examined-row-limit" class="headerlink" title="55)min_examined_row_limit"></a>55)min_examined_row_limit</h2><ul><li><p>推荐设置：100</p></li><li><p>作用：这个值配合着慢查询sql记录用，指定为少于该值的行的查询就算慢sql不被记录成”慢sql日志“。</p></li><li><p>如果不配的后果：不开启的话以慢sql的long_query_time为优先规则。</p></li><li><p>配置实例：min_examined_row_limit = 100</p></li></ul><h2 id="56-master-info-repository"><a href="#56-master-info-repository" class="headerlink" title="56)master_info_repository"></a>56)master_info_repository</h2><ul><li><p>推荐设置：TABLE</p></li><li><p>作用：主从复制时用，推荐TABLE.<br>从机保存主节点信息方式，设成file时 会生成master.info 和 relay-log.info 2个文件，设成table，信息就会存在mysql.master_slave_info表中。不管是设置的哪种值，都不要移动或者编辑相关的文件和表。</p></li><li><p>如果不配的后果：不配的话默认存成file格式。</p></li><li><p>配置实例：master_info_repository = TABLE</p></li></ul><h2 id="57-relay-log-info-repository"><a href="#57-relay-log-info-repository" class="headerlink" title="57)relay_log_info_repository"></a>57)relay_log_info_repository</h2><ul><li><p>推荐设置：TABLE</p></li><li><p>作用：主从复制时用，推荐TABLE.</p><p>这个参数和上面的master_info_repository必须保持一致，要不然mysql实例启不起来。</p><p>不过需要注意的是，这几个table默认用的是myIsAM引擎，要开启成TABLE模式的话一定记得把这两个表的引擎改成innodb</p><p>alter table slave_master_info engine=innodb;<br>alter table slave_relay_log_info engine=innodb;<br>alter table slave_worker_info engine=innodb;</p></li><li><p>如果不配的后果：</p><p>这个参数和上面的master_info_repository必须保持一致，要不然mysql实例启不起来</p></li><li><p>配置实例：relay_log_info_repository = TABLE</p></li></ul><h2 id="58-log-bin-bin-log"><a href="#58-log-bin-bin-log" class="headerlink" title="58)log_bin = bin.log"></a>58)log_bin = bin.log</h2><p>主从复制时用，主从复制下的bin.log日志所在文件夹。</p><h2 id="59-sync-binlog"><a href="#59-sync-binlog" class="headerlink" title="59)sync_binlog"></a>59)sync_binlog</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：主从复制时用，这个值是要看业务的，它可以有0，1，非零共3种设置方式。</p><ul><li><p>1）0-代表mysql不控制写binlog的时间，由file system自由去控制，此时的mysql的并发性达到最好，但是一旦系统崩溃你会丢失很多还会写入binlog的数据（比如说你正在删数据和更新数据）</p></li><li><p>2）1-最安全，你最多丢掉一个事务或者是一条语句，但是此时它的性能很差，此参数设为0或者是1之间的性能能差4～5倍。</p></li><li><p>3）如果你用的是万兆光纤高速磁盘像或者是ssd同时data和binlog都放在一个目录下的同时你要为了安全可以开启成1.</p></li></ul></li><li><p>如果不配的后果：默认为0</p></li><li><p>配置实例：sync_binlog = 1</p></li></ul><h2 id="60-gtid-mode"><a href="#60-gtid-mode" class="headerlink" title="60)gtid_mode"></a>60)gtid_mode</h2><ul><li><p>推荐设置：on</p></li><li><p>作用：主从复制时用，推荐开启成on，它的用处就是允许你在从库上进行”备份“，从库上在进行备份时它能够获取主库的binlog位点。<br>该参数也可以动态在线设定。如果你要在线运行时设定，在my.cnf文件中必须把它设成on。在开启该参数时，log-bin和log-slave-updates也必须开启，否则MySQL Server拒绝启动，当开启GTID模式时，集群中的全部MySQL Server必须同时配置gtid_mod = ON，否则无法同步。</p></li><li><p>如果不配的后果：默认为off</p></li><li><p>配置实例：gtid_mode = on</p></li></ul><h2 id="61-enforce-gtid-consistency"><a href="#61-enforce-gtid-consistency" class="headerlink" title="61)enforce_gtid_consistency"></a>61)enforce_gtid_consistency</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：主从复制时用，见gtid_mode，这是牵连参数，随着gtid_mode的开启一起开启。</p></li><li><p>如果不配的后果：必须跟着gtid_mode一起开启，要不然mysql实例起不来。</p></li><li><p>配置实例：enforce_gtid_consistency = 1</p></li></ul><h2 id="62-log-slave-updates"><a href="#62-log-slave-updates" class="headerlink" title="62)log_slave_updates"></a>62)log_slave_updates</h2><ul><li><p>推荐设置：它只要标注在my.cnf里就代表起作用了。</p></li><li><p>作用：主从复制时用，见gtid_mode，这是牵连参数，随着gtid_mode的开启一起开启。它只要标注在这就可以了，代表开启，否则也就不要有这一行了。</p></li><li><p>如果不配的后果：它是牵连参数，随着gtid_mode的开启一起开启。</p></li><li><p>配置实例：log_slave_updates</p></li></ul><h2 id="63-binlog-format"><a href="#63-binlog-format" class="headerlink" title="63)binlog_format"></a>63)binlog_format</h2><ul><li><p>推荐设置：row</p></li><li><p>作用：主从复制时用，mysql5.7有3种bin log模式：</p><ol><li><p>STATEMENT：历史悠久，技术成熟,binlog文件较小,binlog中包含了所有数据库更改信息，可以据此来审核数据库的安全等情况。binlog可以用于实时的还原，而不仅仅用于复制主从版本可以不一样，从服务器版本可以比主服务器版本高。缺点是：不是所有的UPDATE语句都能被复制，尤其是包含不确定操作的时候。调用具有不确定因素的 UDF 时复制也可能出问题，使用以下函数的语句也无法被复制：</p><ul><li><p>LOAD_FILE()</p></li><li><p>UUID()</p></li><li><p>USER()</p></li><li><p>FOUND_ROWS()</p></li><li><p>SYSDATE() (除非启动时启用了 –sysdate-is-now 选项)</p></li></ul><p>同时，INSERT … SELECT 会产生比 ROW 更多的行级锁，复制需要进行全表扫描(WHERE 语句中没有使用到索引)的 UPDATE 时，需要比 RBR 请求更多的行级锁</p><p>对于有 AUTO_INCREMENT 字段的 InnoDB表而言，INSERT 语句会阻塞其他 INSERT 语句，对于一些复杂的语句，在从服务器上的耗资源情况会更严重，而 RBR 模式下，只会对那个发生变化的记录产生影响，存储函数(不是存储过程)在被调用的同时也会执行一次 NOW() 函数，这个可以说是坏事也可能是好事，确定了的 UDF 也需要在从服务器上执行，数据表必须几乎和主服务器保持一致才行，否则可能会导致复制出错，执行复杂语句如果出错的话，会消耗更多资源。</p></li><li><p>ROW：任何情况都可以被复制，这对复制来说是最安全可靠的，和其他大多数数据库系统的复制技术一样。多数情况下，从服务器上的表如果有主键的话，复制就会快了很多。复制以下几种语句时的行锁更少：</p><ul><li><p>INSERT … SELECT</p></li><li><p>包含 AUTO_INCREMENT 字段的 INSERT</p></li><li><p>没有附带条件或者并没有修改很多记录的 UPDATE 或 DELETE 语句</p></li></ul></li></ol><p>执行 INSERT，UPDATE，DELETE 语句时锁更少，从服务器上采用多线程来执行复制成为可能，它的缺点是：inlog 大了很多，复杂的回滚时 binlog 中会包含大量的数据，主服务器上执行 UPDATE 语句时，所有发生变化的记录都会写到 binlog 中，而 SBR 只会写一次，这会导致频繁发生 binlog 的并发写问题，UDF 产生的大 BLOB 值会导致复制变慢，无法从 binlog 中看到都复制了写什么语句。</p><p>从安全和稳定性的缩合考虑上来说我们选择ROW模式。</p><ol start="3"><li>混合式-不推荐</li></ol></li><li><p>如果不配的后果：5.7.6之前默认为STATEMENT模式。MySQL 5.7.7之后默认为ROW模式</p></li><li><p>配置实例：binlog_format = row</p></li></ul><h2 id="64-relay-log"><a href="#64-relay-log" class="headerlink" title="64)relay_log"></a>64)relay_log</h2><p>主从复制用，定义relay_log的位置和名称，如果值为空，则默认位置在数据文件的目录（datadir），文件名为host_name-relay-bin.nnnnnn（By default, relay log file names have the form host_name-relay-bin.nnnnnn in the data directory）</p><h2 id="65-relay-log-recovery"><a href="#65-relay-log-recovery" class="headerlink" title="65)relay_log_recovery"></a>65)relay_log_recovery</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：主从复制用，推荐值为1，建议打开。<br>当slave从库宕机后，假如relay-log损坏了，导致一部分中继日志没有处理，则自动放弃所有未执行的relay-log，并且重新从master上获取日志，这样就保证了relay-log的完整性。默认情况下该功能是关闭的，将relay_log_recovery的值设置为 1时，可在slave从库上开启该功能，建议开启。</p></li><li><p>如果不配的后果：默认情况下是关闭的。</p></li><li><p>配置实例：relay_log_recovery = 1</p></li></ul><h2 id="66-slave-skip-errors"><a href="#66-slave-skip-errors" class="headerlink" title="66)slave_skip_errors"></a>66)slave_skip_errors</h2><ul><li><p>推荐设置：ddl_exist_errors</p></li><li><p>作用：主从复制用，推荐值：ddl_exist_errors。理论上我们不应该设置这个值的。即它在my.cnf文件中应该是消失的或者是这样的表示的：</p><p>#slave_skip_errors = ddl_exist_errors</p><p>但是有时我们的一些表（特别是不熟悉mysql的一些开发）真的是用的是mysql5.6旧版的建表语句，这个问题在平时单机模式下很难发现，一旦主从结构一上后，在5.7上真的是有一定机率（有10%-20%的机率）碰到ddl语句是旧版mysql而运行在mysql5.7上，这时在主从复制时会抛一个无法主从复制的错，那么这时我们需要抓数据，表已经建好了，这个影响不大、微乎其微，因此我们可以把它设成”忽略“。这个是本人的吐血经验，为什么要提这个梗。。。你们懂的。</p></li><li><p>如果不配的后果：如果因为建表语句和mysql5.7有冲突时在单实例模式下mysql运行时不会发现，在主从复制时如果没有设跳过值，一旦发生，会影响主从复制，表现就是：主从复制失败。</p></li><li><p>配置实例：slave_skip_errors = ddl_exist_errors</p></li></ul><h2 id="67-innodb-buffer-pool-dump-pct"><a href="#67-innodb-buffer-pool-dump-pct" class="headerlink" title="67)innodb_buffer_pool_dump_pct"></a>67)innodb_buffer_pool_dump_pct</h2><ul><li><p>推荐设置：25~40</p></li><li><p>作用：锦上添花的值，非必要，这边给出一些best practice:<br>通常来说我们会设成25%。对于大并发前提下我们会使用40这个值，这个值越大，mysql启动时间越长。它是你的innodb_buffer_pool_size的百分比！</p><p>MySQL默认在InnoDB缓冲池（而不是整个缓冲池）中仅保留最频繁访问页的25%。请注意，这个变量是基于内存中的实际数据量，而不是缓冲池的大小。例如，如果有100GB的缓冲池，但只有10GB的数据，默认只有10GB的25%（即2.5GB）数据保存在内存中。</p><p>在多数使用场景下，合理的选择是：保留最有用的数据页，比加载所有的页(很多页可能在后续的工作中并没有访问到)在缓冲池中要更快。你可以更改innodb_buffer_pool_dump_pct变量的值。</p></li><li><p>如果不配的后果：不配的话不生效。</p></li><li><p>配置实例：innodb_buffer_pool_dump_pct=25</p></li></ul><h2 id="68-innodb-page-cleaners-8"><a href="#68-innodb-page-cleaners-8" class="headerlink" title="68)innodb_page_cleaners=8"></a>68)innodb_page_cleaners=8</h2><p>这值一般会在主从延迟的情况下会去设，它的值最好是=innodb_buffer_pool_instance的值，它就是cpu的核数。</p><h2 id="69-innodb-undo-log-truncate"><a href="#69-innodb-undo-log-truncate" class="headerlink" title="69)innodb_undo_log_truncate"></a>69)innodb_undo_log_truncate</h2><ul><li><p>推荐设置：1</p></li><li><p>作用：建议开启，设为1<br>innodb_undo_log_truncate参数设置为1，即开启在线回收（收缩）undo log日志文件，支持动态设置。</p></li><li><p>如果不配的后果：不配的话是不生效的。</p></li><li><p>配置实例：innodb_undo_log_truncate=1</p></li></ul><h2 id="70-innodb-max-undo-log-size"><a href="#70-innodb-max-undo-log-size" class="headerlink" title="70)innodb_max_undo_log_size"></a>70)innodb_max_undo_log_size</h2><ul><li><p>推荐设置：推荐在默认值的2倍（默认为1GB）</p></li><li><p>作用：推荐在默认值的2倍（默认为1GB），一般我们不会轻易去设它。</p><p>这个值和innodb_undo_tablespaces、innodb_undo_logs以及innodb_purge_rseg_truncate_frequency有关，这4个值是互相有牵连的。</p><ul><li><p>1）innodb_undo_tablespaces必须为&gt;=3</p></li><li><p>2）innodb_undo_logs必须开启</p></li><li><p>3）innodb_purge_rseg_truncate_frequence必须开启</p></li></ul></li><li><p>如果不配的后果：系统按照1GB来计算。</p></li><li><p>配置实例：innodb_max_undo_log_size=2G</p></li></ul><h2 id="71-innodb-purge-rseg-truncate-frequency"><a href="#71-innodb-purge-rseg-truncate-frequency" class="headerlink" title="71)innodb_purge_rseg_truncate_frequency"></a>71)innodb_purge_rseg_truncate_frequency</h2><ul><li><p>推荐设置：128</p></li><li><p>作用：默认值在128，这个值不太会去碰。控制回收undo log的频率。 指定purge操作被唤起多少次之后才释放rollback segments。当undo表空间里面的rollback segments被释放时，undo表空间才会被truncate。由此可见，该参数越小，undo表空间被尝试truncate的频率越高。</p></li><li><p>如果不配的后果：系统默认按照：128去设定。</p></li><li><p>配置实例：innodb_purge_rseg_truncate_frequency=128</p></li></ul><h2 id="72-binlog-gtid-simple-recovery"><a href="#72-binlog-gtid-simple-recovery" class="headerlink" title="72)binlog_gtid_simple_recovery"></a>72)binlog_gtid_simple_recovery</h2><ul><li><p>推荐设置：建议开启</p></li><li><p>作用：前提是你的mysql必须&gt;5.7.6，否则要设为关闭。<br>这个参数控制了当mysql启动或重启时，mysql在搜寻GTIDs时是如何迭代使用binlog文件的。</p><p>这个选项设置为真，会提升mysql执行恢复的性能。因为这样mysql-server启动和binlog日志清理更快。该参数为真时，mysql-server只需打开最老的和最新的这2个binlog文件。</p></li><li><p>如果不配的后果：默认为0</p></li><li><p>配置实例：binlog_gtid_simple_recovery=1</p></li></ul><h2 id="73-log-timestamps"><a href="#73-log-timestamps" class="headerlink" title="73)log_timestamps"></a>73)log_timestamps</h2><ul><li><p>推荐设置：system</p></li><li><p>作用：推荐使用:system<br>这个参数主要是控制错误日志、慢查询日志等日志中的显示时间。但它不会影响查询日志和慢日志写到表 (mysql.general_log, mysql.slow_log) 中的显示时间，此参数是全局的，可以动态修改。</p></li><li><p>如果不配的后果：默认值为:UTC</p></li><li><p>配置实例：log_timestamps=system</p></li></ul><h2 id="74-transaction-write-set-extraction"><a href="#74-transaction-write-set-extraction" class="headerlink" title="74)transaction_write_set_extraction"></a>74)transaction_write_set_extraction</h2><ul><li><p>推荐设置：这个值不需要去设，因为你用的不是mysql8.0，在5.7.6版以后这个制不是很成熟，如果要开启一般会使用：XXHASH64.</p></li><li><p>作用：这个值是基于group(并行）复制用的，推荐值为：XXHASH64，如果没有开启基于group（并行）的复制千万不要去设这个参数，设都不用去设，保持默认就可以了。</p></li><li><p>如果不配的后果：默认为off状态，即不生效。</p></li><li><p>配置实例：<br>transaction_write_set_extraction = OFF<br>transaction_write_set_extraction = XXHASH64<br>transaction_write_set_extraction = MURMUR32</p></li></ul><h2 id="75-show-compatibility-56"><a href="#75-show-compatibility-56" class="headerlink" title="75)show_compatibility_56"></a>75)show_compatibility_56</h2><ul><li><p>推荐设置：on</p></li><li><p>作用：推荐打开。这个参数是兼容mysql5.6版的INFORMATION_SCHEMA.GLOBAL_STATUS相关功能的，它有利于从5.6到5.7的过渡时非mysql专职dba但是懂mysql的运维用的。</p></li><li><p>如果不配的后果：默认是off。相当于严格模式。</p></li><li><p>配置实例：show_compatibility_56=on</p></li></ul><h1 id="查看数据库-运维SQL"><a href="#查看数据库-运维SQL" class="headerlink" title="查看数据库 运维SQL"></a>查看数据库 运维SQL</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">PROCESSLIST</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> <span class="keyword">status</span> <span class="keyword">like</span> <span class="string">'created_tmp%'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">variables</span> <span class="keyword">like</span> <span class="string">'%max_allowed_packet%'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> <span class="keyword">VARIABLES</span> <span class="keyword">LIKE</span> <span class="string">'innodb_lock_wait_timeout'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> innodb_lock_wait_timeout=<span class="number">500</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">engine</span> <span class="keyword">innodb</span> <span class="keyword">status</span>;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言：&quot;&gt;&lt;a href=&quot;#前言：&quot; class=&quot;headerlink&quot; title=&quot;前言：&quot;&gt;&lt;/a&gt;前言：&lt;/h1&gt;&lt;p&gt;全文中一共有常用的（事实上你如果花1-2周阅读、理解、自己动手设一下后是需要这么多参数的）76个参数，笔者把近10年里3个亿万级项目的数据库调优用此篇浓缩到了可能读者只需要2周时间就可以掌握，同时我是按照：&lt;/p&gt;
    
    </summary>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/categories/system-architecture/"/>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/tags/system-architecture/"/>
    
  </entry>
  
  <entry>
    <title>Gateway详解</title>
    <link href="https://www.alan87.top/sa/gateway/"/>
    <id>https://www.alan87.top/sa/gateway/</id>
    <published>2020-05-09T02:35:50.000Z</published>
    <updated>2020-10-10T07:03:43.889Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Gateway 是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的 Facade 模式很像。Gateway 封装内部系统的架构，并且提供 API 给各个客户端。</p><a id="more"></a><p>主要模块：授权、监控、负载均衡、缓存、熔断、降级、限流、请求分片和管理、静态响应处理，等等。</p><h1 id="网关模式设计"><a href="#网关模式设计" class="headerlink" title="网关模式设计"></a>网关模式设计</h1><h2 id="请求路由"><a href="#请求路由" class="headerlink" title="请求路由"></a>请求路由</h2><p>对于调用端来说，也是一件非常方便的事情。因为调用端不需要知道自己需要用到的其它服务的地址，全部统一地交给 Gateway 来处理。</p><h2 id="服务注册"><a href="#服务注册" class="headerlink" title="服务注册"></a>服务注册</h2><p>为了能够代理后面的服务，并把请求路由到正确的位置上，网关应该有服务注册功能，也就是后端的服务实例可以把其提供服务的地址注册、取消注册。一般来说，注册也就是注册一些 API 接口。比如，HTTP 的 Restful 请求，可以注册相应的 API 的 URI、方法、HTTP 头。 这样，Gateway 就可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上。</p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>一个网关可以接多个服务实例，所以网关还需要在各个对等的服务实例上做负载均衡策略。简单的就直接是 round robin 轮询，复杂点的可以设置上权重进行分发，再复杂一点还可以做到 session 粘连。</p><h2 id="弹力设计"><a href="#弹力设计" class="headerlink" title="弹力设计"></a>弹力设计</h2><p>网关还可以把弹力设计中的那些异步、重试、幂等、流控、降级、熔断、监视等都可以实现进去。这样，同样可以像 Service Mesh 那样，<strong>让应用服务只关心自己的业务逻辑（或是说数据面上的事）而不是控制逻辑（控制面）</strong>。</p><h2 id="安全方面"><a href="#安全方面" class="headerlink" title="安全方面"></a>安全方面</h2><p>SSL 加密及证书管理、Session 验证、授权、数据校验，以及对请求源进行恶意攻击的防范。<strong>错误处理越靠前的位置就是越好，所以，网关可以做到一个全站的接入组件来对后端的服务进行保护。</strong></p><h2 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h2><p>网关完全可以做到对相同服务不同版本的实例进行导流，并还可以收集相关的数据。这样对于软件质量的提升，甚至产品试错都有非常积极的意义。</p><h2 id="API聚合"><a href="#API聚合" class="headerlink" title="API聚合"></a>API聚合</h2><p>使用网关可将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小了，所以一个明显的问题是，客户端可能需要多次请求才能得到所有的数据。这样一来，客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。于是，我们可以让网关来帮客户端请求多个后端的服务（有些场景下完全可以并发请求），然后把后端服务的响应结果拼装起来，回传给客户端（当然，这个过程也可以做成异步的，但这需要客户端的配合）。</p><h2 id="API-编排"><a href="#API-编排" class="headerlink" title="API 编排"></a>API 编排</h2><p>同样在微服务的架构下，要走完一个完整的业务流程，我们需要调用一系列 API，就像一种工作流一样，这个事完全可以通过网页来编排这个业务流程。我们可能通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来串联不同的 API。</p><h1 id="设计重点"><a href="#设计重点" class="headerlink" title="设计重点"></a>设计重点</h1><h2 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h2><p>在技术设计上，网关不应该也不能成为性能的瓶颈。对于高性能，最好使用高性能的编程语言来实现，如 C、C++、Go 和 Java。网关对后端的请求，以及对前端的请求的服务<strong>一定要使用异步非阻塞的 I/O 来确保后端延迟不会导致应用程序中出现性能问题</strong>。C 和 C++ 可以参看 Linux 下的 epoll 和 Windows 的 I/O Completion Port 的异步 IO 模型，Java 下如 Netty、Vert.x、Spring Reactor 的 NIO 框架。当然，我还是更喜欢 Go 语言的 goroutine 加 channel 玩法。</p><h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><p>所有的流量或调用经过网关，所以网关必须成为一个高可用的技术组件，它的稳定直接关系到了所有服务的稳定。网关如果没有设计，就会成变一个单点故障。</p><h2 id="集群化"><a href="#集群化" class="headerlink" title="集群化"></a>集群化</h2><p>网关要成为一个集群，其最好可以自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。</p><h2 id="服务化"><a href="#服务化" class="headerlink" title="服务化"></a>服务化</h2><p>网关还需要做到在不间断的情况下修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，另一种是最好做到服务化。也就是说，得要有自己的 Admin API 来在运行时修改自己的配置。</p><h2 id="持续化"><a href="#持续化" class="headerlink" title="持续化"></a>持续化</h2><p>比如重启，就是像 Nginx 那样优雅地重启。有一个主管请求分发的主进程。当我们需要重启时，新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。</p><h2 id="高扩展性"><a href="#高扩展性" class="headerlink" title="高扩展性"></a>高扩展性</h2><p>网关需要承接所有的业务流量和请求，所以一定会有或多或少的业务逻辑。而我们都知道，<strong>业务逻辑是多变和不确定的。比如，需要在网关上加上一些和业务相关的东西。因此，一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。</strong>当然，像 Nginx 那样通过 Module 进行二次开发的固然可以。但我还是觉得应该做成像 AWS Lambda 那样的方式，也就是所谓的 Serverless 或 FaaS（Function as a Service）那样的方式。</p><h1 id="运维方面"><a href="#运维方面" class="headerlink" title="运维方面"></a>运维方面</h1><h2 id="业务松耦合，协议紧耦合"><a href="#业务松耦合，协议紧耦合" class="headerlink" title="业务松耦合，协议紧耦合"></a>业务松耦合，协议紧耦合</h2><p>在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。网关应该是在网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。另外，除了服务发现外，网关不应该有第三方服务的依赖。</p><h2 id="应用监视，提供分析数据"><a href="#应用监视，提供分析数据" class="headerlink" title="应用监视，提供分析数据"></a>应用监视，提供分析数据</h2><p>网关上需要考虑应用性能的监控，除了有相应后端服务的高可用的统计之外，还需要使用 Tracing ID 实施分布式链路跟踪，并统计好一定时间内每个 API 的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。</p><h2 id="用弹力设计保护后端服务"><a href="#用弹力设计保护后端服务" class="headerlink" title="用弹力设计保护后端服务"></a>用弹力设计保护后端服务</h2><p>网关上一定要实现熔断、限流、降级、重试和超时等弹力设计。如果一个或多个服务调用花费的时间过长，那么可接受超时并返回一部分数据，或是返回一个网关里的缓存的上一次成功请求的数据。你可以考虑一下这样的设计。</p><h2 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h2><p>因为网关这个组件太关键了，所以需要 DevOps 这样的东西，将其发生故障的概率降到最低。这个软件需要经过精良的测试，包括功能和性能的测试，还有浸泡测试。还需要有一系列自动化运维的管控工具。</p><h1 id="架构方面"><a href="#架构方面" class="headerlink" title="架构方面"></a>架构方面</h1><ul><li><p><strong>不要在网关中的代码里内置聚合后端服务的功能</strong>，而应考虑将聚合服务放在网关核心代码之外。可以使用 Plugin 的方式，也可以放在网关后面形成一个 Serverless 服务。</p></li><li><p>网关应该靠近后端服务，并和后端服务使用同一个内网，这样可以保证网关和后端服务调用的低延迟，并可以减少很多网络上的问题。这里多说一句，网关处理的静态内容应该靠近用户（应该放到 CDN 上），而网关和此时的动态服务应该靠近后端服务。</p></li><li><p>网关也需要做容量扩展，所以需要成为一个集群来分担前端带来的流量。这一点，要么通过 DNS 轮询的方式实现，要么通过 CDN 来做流量调度，或者通过更为底层的性能更高的负载均衡设备。</p></li><li><p>对于服务发现，可以做一个时间不长的缓存，这样不需要每次请求都去查一下相关的服务所在的地方。当然，如果你的系统不复杂，可以考虑把服务发现的功能直接集成进网关中。</p></li><li><p>为网关考虑 bulkhead 设计方式。用不同的网关服务不同的后端服务，或是用不同的网关服务前端不同的客户。</p></li><li><p>校验用户请求。一些基本的用户验证可以放在网关上来做，比如用户是否已登录，用户请求中的 token 是否合法等。但是，<strong>我们需要权衡一下，网关是否需要校验用户的输入。因为这样一来，网关就需要从只关心协议头，到需要关心协议体。而协议体中的东西一方面不像协议头是标准的，另一方面解析协议体还要耗费大量的运行时间，从而降低网关的性能</strong>。对此，我想说的是，看具体需求，一方面如果协议体是标准的，那么可以干；另一方面，对于解析协议所带来的性能问题，需要做相应的隔离。</p></li><li><p>检测异常访问。网关需要检测一些异常访问，比如，在一段比较短的时间内请求次数超过一定数值；还比如，同一客户端的 4xx 请求出错率太高……对于这样的一些请求访问，网关一方面要把这样的请求屏蔽掉，另一方面需要发出警告，有可能会是一些比较重大的安全问题，如被黑客攻击。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;Gateway 是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的 Facade 模式很像。Gateway 封装内部系统的架构，并且提供 API 给各个客户端。&lt;/p&gt;
    
    </summary>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/categories/system-architecture/"/>
    
    
      <category term="系统架构" scheme="https://www.alan87.top/tags/system-architecture/"/>
    
  </entry>
  
  <entry>
    <title>Nginx详解</title>
    <link href="https://www.alan87.top/web/nginx/"/>
    <id>https://www.alan87.top/web/nginx/</id>
    <published>2020-05-09T01:48:36.000Z</published>
    <updated>2020-10-10T07:03:43.949Z</updated>
    
    <content type="html"><![CDATA[<h1 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h1><ul><li><a href="http://jinnianshilongnian.iteye.com/blog/2186448" target="_blank" rel="noopener">nginx+lua</a></li><li><a href="https://mp.weixin.qq.com/s/YrC8aPZHtDlDL2Fqku2fbA" target="_blank" rel="noopener">Nginx配置文件及模块</a></li></ul><a id="more"></a><ul><li><p><a href="https://mp.weixin.qq.com/s/-tbku61HLKWXPoKypXGFHg" target="_blank" rel="noopener">全面了解 Nginx 到底能做什么</a></p></li><li><p><a href="../nginx映射本地文件">Nginx映射本地文件</a></p></li></ul><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>￼Nginx做为一款高性能的HTTP反向代理服务器，有极高的执行效率、简单灵活的配置。</p><p>Nginx使用epoll和kqueue网络的I/O模型，而apache使用的是传统的select模型。</p><h1 id="与tomcat的区别："><a href="#与tomcat的区别：" class="headerlink" title="与tomcat的区别："></a><strong>与tomcat的区别：</strong></h1><ul><li>tomcat是根据Servlet和JSP规范执行的。</li><li>tomcat对静态文件、高并发文件的处理比较弱。</li></ul><h1 id="Nginx优势："><a href="#Nginx优势：" class="headerlink" title="Nginx优势："></a><strong>Nginx优势：</strong></h1><ul><li>配置文件简单</li><li>支持Rewrite重写规则。能根据域名、URL的不同将HTTP请求分发到不同的后端服务器集群</li><li>负载均衡（为集群提供服务分发能力）</li><li>反向代理</li><li>内置健康检查。如果后端的某台应用服务器挂了，不会影响前端访问</li><li>节省带宽。支持GZIP压缩。（具体应用服务器上层会挂一台web服务器，做一些压缩处理）</li><li>支持热部署</li></ul><h1 id="Nginx、Apache、Lighttpd的对比："><a href="#Nginx、Apache、Lighttpd的对比：" class="headerlink" title="Nginx、Apache、Lighttpd的对比："></a><strong>Nginx、Apache、Lighttpd的对比：</strong></h1><img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-1.png/w600"><h1 id="Nginx的主配置文件为nginx-conf，下面是Web-Server的完整配置示例。"><a href="#Nginx的主配置文件为nginx-conf，下面是Web-Server的完整配置示例。" class="headerlink" title="Nginx的主配置文件为nginx.conf，下面是Web Server的完整配置示例。"></a>Nginx的主配置文件为nginx.conf，下面是Web Server的完整配置示例。</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#运行用户</span></span><br><span class="line">user www-data;    </span><br><span class="line"><span class="comment">#启动进程,通常设置成和cpu的数量相等</span></span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line"><span class="comment">#全局错误日志及PID文件</span></span><br><span class="line">error_log  /var/<span class="built_in">log</span>/nginx/error.log;</span><br><span class="line">pid        /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="comment">#工作模式及连接数上限</span></span><br><span class="line">events &#123;</span><br><span class="line">    use   epoll;             <span class="comment">#epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能</span></span><br><span class="line">    worker_connections  1024;<span class="comment">#单个后台worker process进程的最大并发链接数</span></span><br><span class="line">    <span class="comment"># multi_accept on; </span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#设定http服务器，利用它的反向代理功能提供负载均衡支持</span></span><br><span class="line">http &#123;</span><br><span class="line">     <span class="comment">#设定mime类型,类型由mime.type文件定义</span></span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    <span class="comment">#设定日志格式</span></span><br><span class="line">    access_log    /var/<span class="built_in">log</span>/nginx/access.log;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，</span></span><br><span class="line">    <span class="comment">#必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.</span></span><br><span class="line">    sendfile        on;</span><br><span class="line">    <span class="comment">#tcp_nopush     on;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#连接超时时间</span></span><br><span class="line">    <span class="comment">#keepalive_timeout  0;</span></span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line">    tcp_nodelay        on;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#开启gzip压缩</span></span><br><span class="line">    gzip  on;</span><br><span class="line">    gzip_disable <span class="string">"MSIE [1-6]\.(?!.*SV1)"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#设定请求缓冲</span></span><br><span class="line">    client_header_buffer_size    1k;</span><br><span class="line">    large_client_header_buffers  4 4k;</span><br><span class="line"></span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line">    include /etc/nginx/sites-enabled/*;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#设定负载均衡的服务器列表</span></span><br><span class="line">     upstream mysvr &#123;</span><br><span class="line">    <span class="comment">#weigth参数表示权值，权值越高被分配到的几率越大</span></span><br><span class="line">    <span class="comment">#本机上的Squid开启3128端口</span></span><br><span class="line">    server 192.168.8.1:3128 weight=5;</span><br><span class="line">    server 192.168.8.2:80  weight=1;</span><br><span class="line">    server 192.168.8.3:80  weight=6;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   server &#123;</span><br><span class="line">    <span class="comment">#侦听80端口</span></span><br><span class="line">        listen       80;</span><br><span class="line">        <span class="comment">#定义使用www.xx.com访问</span></span><br><span class="line">        server_name  www.xx.com;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#设定本虚拟主机的访问日志</span></span><br><span class="line">        access_log  logs/www.xx.com.access.log  main;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#默认请求</span></span><br><span class="line">    location / &#123;</span><br><span class="line">          root   /root;      <span class="comment">#定义服务器的默认网站根目录位置</span></span><br><span class="line">          index index.php index.html index.htm;   <span class="comment">#定义首页索引文件的名称</span></span><br><span class="line"></span><br><span class="line">          fastcgi_pass  www.xx.com;</span><br><span class="line">         fastcgi_param  SCRIPT_FILENAME  <span class="variable">$document_root</span>/<span class="variable">$fastcgi_script_name</span>; </span><br><span class="line">          include /etc/nginx/fastcgi_params;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义错误提示页面</span></span><br><span class="line">    error_page   500 502 503 504 /50x.html;  </span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">        root   /root;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#静态文件，nginx自己处理</span></span><br><span class="line">    location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123;</span><br><span class="line">        root /var/www/virtual/htdocs;</span><br><span class="line">        <span class="comment">#过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。</span></span><br><span class="line">        expires 30d;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.</span></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        root /root;</span><br><span class="line">        fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">        fastcgi_index index.php;</span><br><span class="line">        fastcgi_param SCRIPT_FILENAME /home/www/www<span class="variable">$fastcgi_script_name</span>;</span><br><span class="line">        include fastcgi_params;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#设定查看Nginx状态的地址</span></span><br><span class="line">    location /NginxStatus &#123;</span><br><span class="line">        stub_status            on;</span><br><span class="line">        access_log              on;</span><br><span class="line">        auth_basic              <span class="string">"NginxStatus"</span>;</span><br><span class="line">        auth_basic_user_file  conf/htpasswd;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#禁止访问 .htxxx 文件</span></span><br><span class="line">    location ~ /\.ht &#123;</span><br><span class="line">        deny all;</span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要使用负载均衡的话,可以修改配置http节点如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设定http服务器，利用它的反向代理功能提供负载均衡支持</span></span><br><span class="line">http &#123;</span><br><span class="line">     <span class="comment">#设定mime类型,类型由mime.type文件定义</span></span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    <span class="comment">#设定日志格式</span></span><br><span class="line">    access_log    /var/<span class="built_in">log</span>/nginx/access.log;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#省略上文有的一些配置节点</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#。。。。。。。。。。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#设定负载均衡的服务器列表</span></span><br><span class="line">     upstream mysvr &#123;</span><br><span class="line">    <span class="comment">#weigth参数表示权值，权值越高被分配到的几率越大</span></span><br><span class="line">    server 192.168.8.1x:3128 weight=5;<span class="comment">#本机上的Squid开启3128端口</span></span><br><span class="line">    server 192.168.8.2x:80  weight=1;</span><br><span class="line">    server 192.168.8.3x:80  weight=6;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   upstream mysvr2 &#123;</span><br><span class="line">    <span class="comment">#weigth参数表示权值，权值越高被分配到的几率越大</span></span><br><span class="line"></span><br><span class="line">    server 192.168.8.x:80  weight=1;</span><br><span class="line">    server 192.168.8.x:80  weight=6;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">#第一个虚拟服务器</span></span><br><span class="line">   server &#123;</span><br><span class="line">    <span class="comment">#侦听192.168.8.x的80端口</span></span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  192.168.8.x;</span><br><span class="line"></span><br><span class="line">      <span class="comment">#对aspx后缀的进行负载均衡请求</span></span><br><span class="line">    location ~ .*\.aspx$ &#123;</span><br><span class="line"></span><br><span class="line">         root   /root;      <span class="comment">#定义服务器的默认网站根目录位置</span></span><br><span class="line">          index index.php index.html index.htm;   <span class="comment">#定义首页索引文件的名称</span></span><br><span class="line"></span><br><span class="line">          proxy_pass  http://mysvr ;<span class="comment">#请求转向mysvr 定义的服务器列表</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">#以下是一些反向代理的配置可删除.</span></span><br><span class="line"></span><br><span class="line">          proxy_redirect off;</span><br><span class="line"></span><br><span class="line">          <span class="comment">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span></span><br><span class="line">          proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">          proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">          proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">          client_max_body_size 10m;    <span class="comment">#允许客户端请求的最大单文件字节数</span></span><br><span class="line">          client_body_buffer_size 128k;  <span class="comment">#缓冲区代理缓冲用户端请求的最大字节数，</span></span><br><span class="line">          proxy_connect_timeout 90;  <span class="comment">#nginx跟后端服务器连接超时时间(代理连接超时)</span></span><br><span class="line">          proxy_send_timeout 90;        <span class="comment">#后端服务器数据回传时间(代理发送超时)</span></span><br><span class="line">          proxy_read_timeout 90;         <span class="comment">#连接成功后，后端服务器响应时间(代理接收超时)</span></span><br><span class="line">          proxy_buffer_size 4k;             <span class="comment">#设置代理服务器（nginx）保存用户头信息的缓冲区大小</span></span><br><span class="line">          proxy_buffers 4 32k;               <span class="comment">#proxy_buffers缓冲区，网页平均在32k以下的话，这样设置</span></span><br><span class="line">          proxy_busy_buffers_size 64k;    <span class="comment">#高负荷下缓冲大小（proxy_buffers*2）</span></span><br><span class="line">          proxy_temp_file_write_size 64k;  <span class="comment">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</span></span><br><span class="line"></span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="虚拟主机"><a href="#虚拟主机" class="headerlink" title="虚拟主机"></a>虚拟主机</h1><p><strong>利用虚拟主机，不用为每个要运行的网站提供一台单独的Nginx服务器或单独运行一组Nginx进程。虚拟主机提供了在同一台服务器、同一组nginx进程上运行多个网站的功能。</strong></p><ul><li>基于IP的虚拟主机</li><li>基于域名的虚拟主机</li></ul><p>gzip（GNU—ZIP）是一种压缩技术，可以将页面大小压缩到原来的30%或更小。</p><img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-gzip.png/w600"><p>Nginx的浏览器本地缓存设置。当用户再次请求这个页面时，浏览器可以从本地磁盘显示文件，节约了网络的资源，提高了网络的效率。</p><p>对图片文件缓存30天，对js、css文件缓存1小时。</p><img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-cache.png/w600"><h1 id="FastCGI的工作原理是："><a href="#FastCGI的工作原理是：" class="headerlink" title="FastCGI的工作原理是："></a><strong>FastCGI的工作原理是：</strong></h1><ul><li>FastCGI进程管理器自身初始化，启动多个CGI解释器进程 (在任务管理器中可见多个php-cgi.exe)并等待来自Web Server的连接。启动php-cgi FastCGI进程时，可以配置以TCP和UNIX套接字(socket)两种方式启动。</li><li>当客户端请求到达Web Server（Nginx）时，Web Server（Nginx）将请求采用TCP协议或socket方式转发到FastCGI主进程，FastCGI主进程选择并连接到一个CGI解释器(子进程php-cgi.exe)。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi.exe。</li><li>FastCGI子进程php-cgi.ex完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在 WebServer中）的下一个连接。 而在CGI中，php-cgi子进程在此便被退出了。</li></ul><h1 id="Nginx与Tomcat的配置："><a href="#Nginx与Tomcat的配置：" class="headerlink" title="Nginx与Tomcat的配置："></a><strong>Nginx与Tomcat的配置：</strong></h1><img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-main.png/w600"><img data-src="http://f.ngall-in.com/alan87/static/images/web/nginx/nginx-tomcat.png/w600"><h1 id="反向代理："><a href="#反向代理：" class="headerlink" title="反向代理："></a><strong>反向代理：</strong></h1><p>代理服务器接受来自Internet的连接请求，然后将请求转发给内部网络上的服务器，并从服务器上得到的结果返回给Internet上请求连接的客户端。</p><p>反向代理服务器只是一层代理，所以受到攻击并不会使网页信息遭到破坏，增强了web服务器的安全性。</p><h1 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a><strong>参考资料：</strong></h1><p><a href="https://www.zybuluo.com/happyfans/note/161734" target="_blank" rel="noopener">https://www.zybuluo.com/happyfans/note/161734</a></p><p>《实战Nginx 取代Apache的高性能Web服务器》</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;附录：&quot;&gt;&lt;a href=&quot;#附录：&quot; class=&quot;headerlink&quot; title=&quot;附录：&quot;&gt;&lt;/a&gt;附录：&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://jinnianshilongnian.iteye.com/blog/2186448&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;nginx+lua&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/YrC8aPZHtDlDL2Fqku2fbA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Nginx配置文件及模块&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Web" scheme="https://www.alan87.top/categories/web/"/>
    
    
      <category term="Web" scheme="https://www.alan87.top/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>Docker汇总</title>
    <link href="https://www.alan87.top/docker/docker-summary/"/>
    <id>https://www.alan87.top/docker/docker-summary/</id>
    <published>2020-05-08T07:15:01.000Z</published>
    <updated>2020-10-10T07:03:43.782Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="https://mp.weixin.qq.com/s/bNmpqDsX1RTaiBHi0FIk0Q" target="_blank" rel="noopener">简述 Docker</a></li><li><a href="https://mp.weixin.qq.com/s/mNge9HfAjeiP12Z8IikP2g" target="_blank" rel="noopener">Docker入门教程</a></li></ul><a id="more"></a><p>/etc/docker/daemon.json</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="attr">"log-driver"</span>:<span class="string">"json-file"</span>,</span><br><span class="line">  <span class="attr">"log-opts"</span>: &#123;<span class="attr">"max-size"</span>:<span class="string">"100m"</span>, <span class="attr">"max-file"</span>:<span class="string">"3"</span>&#125;,</span><br><span class="line">  <span class="attr">"registry-mirrors"</span>: [</span><br><span class="line">        <span class="string">"https://zckzdbvq.mirror.aliyuncs.com"</span>, </span><br><span class="line">        <span class="string">"https://116.62.81.173"</span>, </span><br><span class="line">        <span class="string">"http://hub-mirror.c.163.com"</span>,</span><br><span class="line">        <span class="string">"https://docker.mirrors.ustc.edu.cn"</span>,</span><br><span class="line">        <span class="string">"http://192.168.1.200:2000"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"insecure-registries"</span>: [<span class="string">"139.159.220.178:8088"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="添加静态路由联通不同主机docker"><a href="#添加静态路由联通不同主机docker" class="headerlink" title="添加静态路由联通不同主机docker"></a>添加静态路由联通不同主机docker</h1><p>在/etc/rc.local 加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">route add -net 172.18.1.0/24 dev eth0</span><br><span class="line"></span><br><span class="line">route -n <span class="comment"># 查看路由</span></span><br><span class="line"><span class="comment"># 开启内核ipv4转发功能</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"net.ipv4.ip_forward = 1"</span> &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure><h1 id="清理docker空间"><a href="#清理docker空间" class="headerlink" title="清理docker空间"></a>清理docker空间</h1><p>docker system prune -a</p><h1 id="删除所有没有用的镜像，而不仅仅是临时文件；"><a href="#删除所有没有用的镜像，而不仅仅是临时文件；" class="headerlink" title="删除所有没有用的镜像，而不仅仅是临时文件；"></a>删除所有没有用的镜像，而不仅仅是临时文件；</h1><p>docker image prune -a </p><h1 id="限制docker-日志大小"><a href="#限制docker-日志大小" class="headerlink" title="限制docker 日志大小"></a>限制docker 日志大小</h1><p>{<br>  “log-driver”:”json-file”,<br>  “log-opts”: {“max-size”:”100m”, “max-file”:”1”}<br>}</p><h1 id="无法用docker-rmi-删除的镜像，可以直接删除文件"><a href="#无法用docker-rmi-删除的镜像，可以直接删除文件" class="headerlink" title="无法用docker rmi 删除的镜像，可以直接删除文件"></a>无法用docker rmi 删除的镜像，可以直接删除文件</h1><p>cd /var/lib/docker/image/overlay2/imagedb/content/sha256<br>for i in <code>docker images|grep /test/|awk &#39;{print $3}&#39;</code>;do rm -rf $i* ;done</p><h1 id="docker-build-报错"><a href="#docker-build-报错" class="headerlink" title="docker build 报错"></a>docker build 报错</h1><p>unable to find image “sha256:823e1ed7982d5426dcc257ef43ba7e10b7758d6275d85ce645899f4f55b073b7”<br>加 –no-cache 参数<br>docker build -t docker.io/share/test/insurance-center:latest . –no-cache</p><h1 id="Docker-Swarm"><a href="#Docker-Swarm" class="headerlink" title="Docker Swarm"></a>Docker Swarm</h1><h2 id="创建Swarm集群"><a href="#创建Swarm集群" class="headerlink" title="创建Swarm集群"></a>创建Swarm集群</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 在manager1机器上创建docker swarm集群</span></span><br><span class="line">docker swarm init ‐‐advertise‐addr 192.168.1.200</span><br><span class="line"><span class="comment"># docker swarm join-token manager 查看token</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 向docker swarm中添加工作节点：在两个工作节点中分别执行如下命令，ip地址是manager节点的</span></span><br><span class="line">docker swarm join ‐‐token xxx 192.168.1.200:2377  （worker1）</span><br><span class="line">docker swarm join ‐‐token xxx 192.168.1.200:2377  （worker2）</span><br><span class="line"><span class="comment"># 3. 查看管理节点集群信息：</span></span><br><span class="line">docker node ls</span><br><span class="line"><span class="comment"># 4. 删除node,退出集群 </span></span><br><span class="line">docker swarm leave --force(节点上)</span><br><span class="line">docker node rm id --force（manager上）</span><br><span class="line"><span class="comment"># 5. 节点加标签</span></span><br><span class="line"><span class="comment"># docker node update --label-add role=标签名称  主机名</span></span><br><span class="line">docker node update --label-add role=db  docker1</span><br><span class="line"><span class="comment">#删除标签</span></span><br><span class="line">docker node update --label-rm role manager-node </span><br><span class="line"><span class="comment"># 6. 查看节点详情</span></span><br><span class="line">docker node inspect hostname</span><br></pre></td></tr></table></figure><h2 id="在docker-swarm中部署服务（管理节点运行）"><a href="#在docker-swarm中部署服务（管理节点运行）" class="headerlink" title="在docker swarm中部署服务（管理节点运行）"></a>在docker swarm中部署服务（管理节点运行）</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. service命令创建服务</span></span><br><span class="line">$ docker service create --replicas 1 --name nginx1 nginx(imagename) --network=goldeye</span><br><span class="line"></span><br><span class="line"><span class="comment"># docker service create指令：用于在Swarm集群中创建一个基于alpine镜像的服务</span></span><br><span class="line"><span class="comment"># ‐‐replicas参数：指定了该服务只有一个副本实例</span></span><br><span class="line"><span class="comment"># ‐‐name参数：指定创建成功后的服务名称为helloworld</span></span><br><span class="line"><span class="comment"># ping docker.com指令：表示服务启动后执行的命令</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 查看docker swarm集群中的服务</span></span><br><span class="line">查看服务列表：docker service ls</span><br><span class="line">查看部署具体服务的详细信息：docker service inspect 服务名称</span><br><span class="line">查看服务在集群节点上的分配以及运行情况：docker service ps --no-trunc 服务名称</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 修改副本数量</span></span><br><span class="line">在manager1上，更改服务副本的数量（创建的副本会随机分配到不同的节点）</span><br><span class="line">docker service scale helloworld=5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 删除服务（在管理节点）</span></span><br><span class="line">docker service rm 服务名称</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 在集群管理节点manager1上部署一个nginx服务</span></span><br><span class="line">docker service create \</span><br><span class="line">  ‐‐network my‐multi‐host‐network \</span><br><span class="line">  ‐‐name my‐web \</span><br><span class="line">  ‐p 8080:80 \</span><br><span class="line">  ‐‐replicas 2 \</span><br><span class="line">  nginx</span><br></pre></td></tr></table></figure><h2 id="使用compose部署docker-swarm-服务"><a href="#使用compose部署docker-swarm-服务" class="headerlink" title="使用compose部署docker swarm 服务"></a>使用compose部署docker swarm 服务</h2><ol><li><p>部署服务<br><code># docker stack deploy -c docker-compose.yml stackname</code></p></li><li><p>查看服务<br><code># docker stack ls</code></p></li><li><p>移除服务<br><code># docker stack down stackname</code></p></li><li><p>docker-compose.yml 文件示例</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3.3"</span></span><br><span class="line"> </span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">visualizer:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">dockersamples/visualizer:stable</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"8080:8080"</span></span><br><span class="line">    <span class="attr">stop_grace_period:</span> <span class="string">1m30s</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"/var/run/docker.sock:/var/run/docker.sock"</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">alan</span></span><br><span class="line">    <span class="attr">deploy:</span> <span class="comment"># deploy参数是Docker Compose针对Swarm集群部署提供的，子参数专门用于指定与服务部署和运行相关的配置</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">replicated</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">restart_policy:</span></span><br><span class="line">        <span class="attr">condition:</span> <span class="string">on-failure</span></span><br><span class="line">        <span class="attr">max_attempts:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">placement:</span></span><br><span class="line">        <span class="attr">constraints:</span>  </span><br><span class="line">          <span class="bullet">-</span> <span class="string">node.role</span> <span class="string">==</span> <span class="string">manager</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">node.hostname</span> <span class="string">==</span> <span class="string">docker1</span> </span><br><span class="line">          <span class="bullet">-</span> <span class="string">node.labels.role</span> <span class="string">==</span> <span class="string">db</span></span><br><span class="line">      <span class="attr">update_config:</span></span><br><span class="line">        <span class="attr">delay:</span> <span class="string">5s</span></span><br><span class="line">        <span class="attr">order:</span> <span class="string">start-first</span> <span class="comment"># 默认为 stop-first，推荐设置先启动新服务再终止旧的</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">limits:</span></span><br><span class="line">          <span class="attr">cpus:</span> <span class="string">"0.50"</span></span><br><span class="line">          <span class="attr">memory:</span> <span class="string">1g</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">alan:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/bNmpqDsX1RTaiBHi0FIk0Q&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;简述 Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/mNge9HfAjeiP12Z8IikP2g&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Docker入门教程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="云原生" scheme="https://www.alan87.top/categories/cloud-native/"/>
    
      <category term="Docker" scheme="https://www.alan87.top/categories/cloud-native/docker/"/>
    
    
      <category term="云原生" scheme="https://www.alan87.top/tags/cn/"/>
    
      <category term="Docker" scheme="https://www.alan87.top/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker三剑客之Docker Swarm</title>
    <link href="https://www.alan87.top/docker/docker%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bswarm/"/>
    <id>https://www.alan87.top/docker/docker%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bswarm/</id>
    <published>2020-05-08T07:15:01.000Z</published>
    <updated>2020-10-10T07:03:43.783Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、什么是Docker-Swarm"><a href="#一、什么是Docker-Swarm" class="headerlink" title="一、什么是Docker Swarm"></a>一、什么是Docker Swarm</h1><p>　　Swarm是Docker公司推出的用来管理docker集群的平台，几乎全部用GO语言来完成的开发的，代码开源在<a href="https://github.com/docker/swarm，" target="_blank" rel="noopener">https://github.com/docker/swarm，</a> 它是将一群Docker宿主机变成一个单一的虚拟主机，Swarm使用标准的Docker API接口作为其前端的访问入口，换言之，各种形式的Docker</p><p>  Client(compose,docker-py等)均可以直接与Swarm通信，甚至Docker本身都可以很容易的与Swarm集成，这大大方便了用户将原本基于单节点的系统移植到Swarm上，同时Swarm内置了对Docker网络插件的支持，用户也很容易的部署跨主机的容器集群服务。</p><p>　　Docker Swarm 和 Docker Compose 一样，都是 Docker 官方容器编排项目，但不同的是，Docker Compose 是一个在单个服务器或主机上创建多个容器的工具，而 Docker Swarm 则可以在多个服务器或主机上创建容器集群服务，对于微服务的部署，显然 Docker Swarm 会更加适合。</p><p>从 Docker 1.12.0 版本开始，Docker Swarm 已经包含在 Docker 引擎中（docker swarm），并且已经内置了服务发现工具，我们就不需要像之前一样，再配置 Etcd 或者 Consul 来进行服务发现配置了。</p><p>　　Swarm deamon只是一个调度器(Scheduler)加路由器(router),Swarm自己不运行容器，它只是接受Docker客户端发来的请求，调度适合的节点来运行容器，这就意味着，即使Swarm由于某些原因挂掉了，集群中的节点也会照常运行，放Swarm重新恢复运行之后，他会收集重建集群信息。</p><h1 id="二、Docker-Swarm-基本结构图"><a href="#二、Docker-Swarm-基本结构图" class="headerlink" title="二、Docker Swarm 基本结构图"></a>二、Docker Swarm 基本结构图</h1><p>在结构图可以看出 Docker Client使用Swarm对 集群(Cluster)进行调度使用。</p><p>上图可以看出，Swarm是典型的master-slave结构，通过发现服务来选举manager。manager是中心管理节点，各个node上运行agent接受manager的统一管理，集群会自动通过Raft协议分布式选举出manager节点，无需额外的发现服务支持，避免了单点的瓶颈问题，同时也内置了DNS的负载均衡和对外部负载均衡机制的集成支持</p><h1 id="三-Swarm的几个关键概念"><a href="#三-Swarm的几个关键概念" class="headerlink" title="三.Swarm的几个关键概念"></a>三.Swarm的几个关键概念</h1><ol><li><p>Swarm<br>集群的管理和编排是使用嵌入docker引擎的SwarmKit，可以在docker初始化时启动swarm模式或者加入已存在的swarm</p></li><li><p>Node<br>一个节点是docker引擎集群的一个实例。您还可以将其视为Docker节点。您可以在单个物理计算机或云服务器上运行一个或多个节点，但生产群集部署通常包括分布在多个物理和云计算机上的Docker节点。</p></li></ol><p>要将应用程序部署到swarm，请将服务定义提交给 管理器节点。管理器节点将称为任务的工作单元分派 给工作节点。</p><p>Manager节点还执行维护所需群集状态所需的编排和集群管理功能。Manager节点选择单个领导者来执行编排任务。</p><p>工作节点接收并执行从管理器节点分派的任务。默认情况下，管理器节点还将服务作为工作节点运行，但您可以将它们配置为仅运行管理器任务并且是仅管理器节点。代理程序在每个工作程序节点上运行，并报告分配给它的任务。工作节点向管理器节点通知其分配的任务的当前状态，以便管理器可以维持每个工作者的期望状态。</p><ol start="3"><li><p>Service<br>一个服务是任务的定义，管理机或工作节点上执行。它是群体系统的中心结构，是用户与群体交互的主要根源。创建服务时，你需要指定要使用的容器镜像。</p></li><li><p>Task<br>任务是在docekr容器中执行的命令，Manager节点根据指定数量的任务副本分配任务给worker节点</p></li></ol><p>——————————————使用方法————————————-<br>docker swarm：集群管理，子命令有init, join, leave, update。（docker swarm –help查看帮助）<br>docker service：服务创建，子命令有create, inspect, update, remove, tasks。（docker service–help查看帮助）<br>docker node：节点管理，子命令有accept, promote, demote, inspect, update, tasks, ls, rm。（docker node –help查看帮助）</p><p>node是加入到swarm集群中的一个docker引擎实体，可以在一台物理机上运行多个node，node分为：<br>manager nodes，也就是管理节点<br>worker nodes，也就是工作节点</p><ul><li>1）manager node管理节点：执行集群的管理功能，维护集群的状态，选举一个leader节点去执行调度任务。</li><li>2）worker node工作节点：接收和执行任务。参与容器集群负载调度，仅用于承载task。</li><li>3）service服务：一个服务是工作节点上执行任务的定义。创建一个服务，指定了容器所使用的镜像和容器运行的命令。<br> service是运行在worker nodes上的task的描述，service的描述包括使用哪个docker 镜像，以及在使用该镜像的容器中执行什么命令。</li><li>4）task任务：一个任务包含了一个容器及其运行的命令。task是service的执行实体，task启动docker容器并在容器中执行任务。</li></ul><h1 id="四、Swarm的工作模式"><a href="#四、Swarm的工作模式" class="headerlink" title="四、Swarm的工作模式"></a>四、Swarm的工作模式</h1><ol><li>Node</li><li>Service</li><li>任务与调度</li><li>服务副本与全局服务</li></ol><h1 id="五、Swarm的调度策略"><a href="#五、Swarm的调度策略" class="headerlink" title="五、Swarm的调度策略"></a>五、Swarm的调度策略</h1><p>Swarm在调度(scheduler)节点（leader节点）运行容器的时候，会根据指定的策略来计算最适合运行容器的节点，目前支持的策略有：spread, binpack, random.</p><ul><li><p>1）Random<br>顾名思义，就是随机选择一个Node来运行容器，一般用作调试用，spread和binpack策略会根据各个节点的可用的CPU, RAM以及正在运<br>行的容器的数量来计算应该运行容器的节点。</p></li><li><p>2）Spread<br>在同等条件下，Spread策略会选择运行容器最少的那台节点来运行新的容器，binpack策略会选择运行容器最集中的那台机器来运行新的节点。<br>使用Spread策略会使得容器会均衡的分布在集群中的各个节点上运行，一旦一个节点挂掉了只会损失少部分的容器。</p></li><li><p>3）Binpack<br>Binpack策略最大化的避免容器碎片化，就是说binpack策略尽可能的把还未使用的节点留给需要更大空间的容器运行，尽可能的把容器运行在<br>一个节点上面。</p></li></ul><h1 id="六、Swarm-Cluster模式特性"><a href="#六、Swarm-Cluster模式特性" class="headerlink" title="六、Swarm Cluster模式特性"></a>六、Swarm Cluster模式特性</h1><ul><li><p>1）批量创建服务<br>建立容器之前先创建一个overlay的网络，用来保证在不同主机上的容器网络互通的网络模式</p></li><li><p>2）强大的集群的容错性<br>当容器副本中的其中某一个或某几个节点宕机后，cluster会根据自己的服务注册发现机制，以及之前设定的值–replicas n，<br>在集群中剩余的空闲节点上，重新拉起容器副本。整个副本迁移的过程无需人工干预，迁移后原本的集群的load balance依旧好使！<br>不难看出，docker service其实不仅仅是批量启动服务这么简单，而是在集群中定义了一种状态。Cluster会持续检测服务的健康状态<br>并维护集群的高可用性。</p></li><li><p>3）服务节点的可扩展性<br>Swarm Cluster不光只是提供了优秀的高可用性，同时也提供了节点弹性扩展或缩减的功能。当容器组想动态扩展时，只需通过scale<br>参数即可复制出新的副本出来。</p></li></ul><p>仔细观察的话，可以发现所有扩展出来的容器副本都run在原先的节点下面，如果有需求想在每台节点上都run一个相同的副本，方法<br>其实很简单，只需要在命令中将”–replicas n”更换成”–mode=global”即可！</p><p>复制服务（–replicas n）<br>将一系列复制任务分发至各节点当中，具体取决于您所需要的设置状态，例如“–replicas 3”。</p><p>全局服务（–mode=global）<br>适用于集群内全部可用节点上的服务任务，例如“–mode global”。如果大家在 Swarm 集群中设有 7 台 Docker 节点，则全部节点之上都将存在对应容器。</p><ol start="4"><li>调度机制<br>所谓的调度其主要功能是cluster的server端去选择在哪个服务器节点上创建并启动一个容器实例的动作。它是由一个装箱算法和过滤器<br>组合而成。每次通过过滤器（constraint）启动容器的时候，swarm cluster 都会调用调度机制筛选出匹配约束条件的服务器，并在这上面运行容器。</li></ol><p>——————Swarm cluster的创建过程包含以下三个步骤———————-</p><ul><li>1）发现Docker集群中的各个节点，收集节点状态、角色信息，并监视节点状态的变化</li><li>2）初始化内部调度（scheduler）模块</li><li>3）创建并启动API监听服务模块</li></ul><p>一旦创建好这个cluster，就可以用命令docker service批量对集群内的容器进行操作，非常方便！</p><p>在启动容器后，docker 会根据当前每个swarm节点的负载判断，在负载最优的节点运行这个task任务，用”docker service ls” 和”docker service ps + taskID”<br>可以看到任务运行在哪个节点上。容器启动后，有时需要等待一段时间才能完成容器创建。</p><h1 id="七、Dcoker-Swarm-集群部署"><a href="#七、Dcoker-Swarm-集群部署" class="headerlink" title="七、Dcoker Swarm 集群部署"></a>七、Dcoker Swarm 集群部署</h1><p>温馨提示：</p><p>机器环境(三台机器，centos系统)</p><p>IP：192.168.31.43 主机名：manager43 担任角色：swarm manager</p><p>IP：192.168.31.188 主机名：node188 担任角色：swarm node</p><p>IP：192.168.31.139 主机名：node139 担任角色：swarm node</p><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>1) 修改主机名<h1 id="192-168-31-43-主机上执行"><a href="#192-168-31-43-主机上执行" class="headerlink" title="192.168.31.43  主机上执行"></a>192.168.31.43  主机上执行</h1>[root@manager43 ~]# hostnamectl set-hostname manager43</li></ul><h1 id="192-168-31-188-主机上执行"><a href="#192-168-31-188-主机上执行" class="headerlink" title="192.168.31.188 主机上执行"></a>192.168.31.188 主机上执行</h1><p>[root@node188 ~]# hostnamectl set-hostname node188</p><h1 id="192-168-31-139-主机上执行"><a href="#192-168-31-139-主机上执行" class="headerlink" title="192.168.31.139 主机上执行"></a>192.168.31.139 主机上执行</h1><p>[root@node139 ~]# hostnamectl set-hostname node139</p><ul><li>2)配置hosts文件(可配置可不配置)<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># cat /etc/hosts</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"> </span><br><span class="line">192.168.31.43 manager43</span><br><span class="line">192.168.31.188 node188</span><br><span class="line">192.168.31.139 node139</span><br></pre></td></tr></table></figure><h1 id="使用scp复制到node主机"><a href="#使用scp复制到node主机" class="headerlink" title="使用scp复制到node主机"></a>使用scp复制到node主机</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># scp /etc/hosts root@192.168.31.188:/etc/hosts</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># scp /etc/hosts root@192.168.31.139:/etc/hosts</span></span><br></pre></td></tr></table></figure></li></ul><p>3) 设置防火墙<br>关闭三台机器上的防火墙。如果开启防火墙，则需要在所有节点的防火墙上依次放行2377/tcp（管理端口）、7946/udp（节点间通信端口）、4789/udp（overlay 网络端口）端口。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># systemctl disable firewalld.service</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># systemctl stop firewalld.service</span></span><br></pre></td></tr></table></figure><p>4) 安装docker并配置加速器(在三台主机都要安装哟…)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># yum -y install docker</span></span><br><span class="line">[root@node188 ~]<span class="comment"># yum -y install docker</span></span><br><span class="line">[root@node139 ~]<span class="comment"># yum -y install docker</span></span><br></pre></td></tr></table></figure><p>也可以安装最新版docker，可查考：docker安装教程</p><p>加速器配置，可查考:docker加速器配置教程</p><h2 id="2、创建Swarm并添加节点"><a href="#2、创建Swarm并添加节点" class="headerlink" title="2、创建Swarm并添加节点"></a>2、创建Swarm并添加节点</h2><p>1) 创建Swarm集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker swarm init --advertise-addr 192.168.31.43</span></span><br><span class="line">Swarm initialized: current node (z2n633mty5py7u9wyl423qnq0) is now a manager.</span><br><span class="line"> </span><br><span class="line">To add a worker to this swarm, run the following <span class="built_in">command</span>:</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 这就是添加节点的方式(要保存初始化后token，因为在节点加入时要使用token作为通讯的密钥)</span></span><br><span class="line">    docker swarm join --token SWMTKN-1-2lefzq18zohy9yr1vskutf1sfb2a590xz9d0mjj2m15zu9eprw-2938j5f50t35ycut0vbj2sx0s 192.168.31.43:2377  </span><br><span class="line"> </span><br><span class="line">To add a manager to this swarm, run <span class="string">'docker swarm join-token manager'</span> and follow the instructions.</span><br></pre></td></tr></table></figure><p>上面命令执行后，该机器自动加入到swarm集群。这个会创建一个集群token，获取全球唯一的 token，作为集群唯一标识。后续将其他节点加入集群都会用到这个token值。<br>其中，–advertise-addr参数表示其它swarm中的worker节点使用此ip地址与manager联系。命令的输出包含了其它节点如何加入集群的命令。</p><p>这里无意中遇到了一个小小的问题：</p><h1 id="在次执行上面的命令，回报下面的错误"><a href="#在次执行上面的命令，回报下面的错误" class="headerlink" title="在次执行上面的命令，回报下面的错误"></a>在次执行上面的命令，回报下面的错误</h1><p>[root@manager43 ~]# docker swarm init –advertise-addr 192.168.31.43<br>Error response from daemon: This node is already part of a swarm. Use “docker swarm leave” to leave this swarm and join another one.</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p><code>[root@manager43 ~]# docker swarm leave -f</code><br>这里的leave就是在集群中删除节点，-f参数强制删除，执行完在重新执行OK</p><p>2) 查看集群的相关信息<br><code>[root@manager43 ~]# docker info</code><br>上面的命令执行后 找到Swarm的关键字，就可以看到相关信息了</p><p>[root@manager43 ~]# docker node ls<br>ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION<br>3jcmnzjh0e99ipgshk1ykuovd *   manager43           Ready               Active              Leader              18.06.0-ce<br>上面的命令是查看集群中的机器(注意上面node ID旁边那个*号表示现在连接到这个节点上)</p><p>3) 添加节点主机到Swarm集群<br>上面我们在创建Swarm集群的时候就已经给出了添加节点的方法</p><h1 id="192-168-31-188-主机上执行-1"><a href="#192-168-31-188-主机上执行-1" class="headerlink" title="192.168.31.188 主机上执行"></a>192.168.31.188 主机上执行</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node188 ~]<span class="comment"># docker swarm join --token SWMTKN-1-2lefzq18zohy9yr1vskutf1sfb2a590xz9d0mjj2m15zu9eprw-2938j5f50t35ycut0vbj2sx0s 192.168.31.43:2377</span></span><br><span class="line">This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure><h1 id="192-168-31-139-主机上执行-1"><a href="#192-168-31-139-主机上执行-1" class="headerlink" title="192.168.31.139 主机上执行"></a>192.168.31.139 主机上执行</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node139 ~]<span class="comment"># docker swarm join --token SWMTKN-1-2lefzq18zohy9yr1vskutf1sfb2a590xz9d0mjj2m15zu9eprw-2938j5f50t35ycut0vbj2sx0s 192.168.31.43:2377</span></span><br><span class="line">This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure><p>如果想要将其他更多的节点添加到这个swarm集群中，添加方法如上一致</p><p>在manager43主机上我们可以看一下集群中的机器及状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker node ls</span></span><br><span class="line">ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class="line">3jcmnzjh0e99ipgshk1ykuovd *   manager43           Ready               Active              Leader              18.06.0-ce</span><br><span class="line">vww7ue2xprzg46bjx7afo4h04     node139             Ready               Active                                  18.06.1-ce</span><br><span class="line">c5klw5ns4adcvumzgiv66xpyj     node188             Ready               Active                                  18.06.1-ce</span><br></pre></td></tr></table></figure><hr><p>温馨提示：更改节点的availablity状态</p><ul><li>swarm集群中node的availability状态可以为 active或者drain，其中：</li><li>active状态下，node可以接受来自manager节点的任务分派；</li><li>drain状态下，node节点会结束task，且不再接受来自manager节点的任务分派（也就是下线节点）<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker node update --availability drain node139               # 将node139节点下线。如果要删除node139节点，命令是"docker node rm --force node139"</span></span><br><span class="line">node139</span><br><span class="line">[root@manager43 ~]<span class="comment"># docker node ls</span></span><br><span class="line">ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class="line">3jcmnzjh0e99ipgshk1ykuovd *   manager43           Ready               Active              Leader              18.06.0-ce</span><br><span class="line">vww7ue2xprzg46bjx7afo4h04     node139             Ready               Drain                                   18.06.1-ce</span><br><span class="line">c5klw5ns4adcvumzgiv66xpyj     node188             Ready               Active                                  18.06.1-ce</span><br></pre></td></tr></table></figure>如上，当node1的状态改为drain后，那么该节点就不会接受task任务分发，就算之前已经接受的任务也会转移到别的节点上。<br>再次修改为active状态（及将下线的节点再次上线）<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker node update --availability active node139</span></span><br><span class="line">node139</span><br><span class="line">[root@manager43 ~]<span class="comment"># docker node ls</span></span><br><span class="line">ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class="line">3jcmnzjh0e99ipgshk1ykuovd *   manager43           Ready               Active              Leader              18.06.0-ce</span><br><span class="line">vww7ue2xprzg46bjx7afo4h04     node139             Ready               Active                                  18.06.1-ce</span><br><span class="line">c5klw5ns4adcvumzgiv66xpyj     node188             Ready               Active                                  18.06.1-ce</span><br></pre></td></tr></table></figure><h2 id="3、在Swarm中部署服务-nginx为例"><a href="#3、在Swarm中部署服务-nginx为例" class="headerlink" title="3、在Swarm中部署服务(nginx为例)"></a>3、在Swarm中部署服务(nginx为例)</h2></li></ul><p>Docker 1.12版本提供服务的Scaling、health check、滚动升级等功能，并提供了内置的dns、vip机制，实现service的服务发现和负载均衡能力</p><p>1) 创建网络在部署服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建网络</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># docker network create -d overlay nginx_net</span></span><br><span class="line">a52jy33asc5o0ts0rq823bf0m</span><br><span class="line">[root@manager43 ~]<span class="comment"># docker network ls | grep nginx_net</span></span><br><span class="line">a52jy33asc5o        nginx_net           overlay             swarm</span><br><span class="line"><span class="comment"># 部署服务</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># docker service create --replicas 1 --network nginx_net --name my_nginx -p 80:80 nginx    # 就创建了一个具有一个副本（--replicas 1 ）的nginx服务，使用镜像nginx</span></span><br><span class="line">olexfmtdf94sxyeetkchwhehg</span><br><span class="line">overall progress: 1 out of 1 tasks</span><br><span class="line">1/1: running   [==================================================&gt;]</span><br><span class="line">verify: Service converged</span><br></pre></td></tr></table></figure><p>在manager-node节点上使用上面这个覆盖网络创建nginx服务：<br>其中，–replicas 参数指定服务由几个实例组成。<br>注意：不需要提前在节点上下载nginx镜像，这个命令执行后会自动下载这个容器镜像（比如此处创建tomcat容器，就将下面命令中的镜像改为tomcat镜像）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 docker service ls 查看正在运行服务的列表</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># docker service ls</span></span><br><span class="line">ID                  NAME                MODE                REPLICAS            IMAGE               PORTS</span><br><span class="line">olexfmtdf94s        my_nginx            replicated          1/1                 nginx:latest        *:80-&gt;80/tcp</span><br></pre></td></tr></table></figure><p>2) 查询Swarm中服务的信息<br>-pretty 使命令输出格式化为可读的格式，不加 –pretty 可以输出更详细的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker service inspect --pretty my_nginx</span></span><br><span class="line">ID:             zs7fw4ereo5w7ohd4n9ii06nt</span><br><span class="line">Name:           my_nginx</span><br><span class="line">Service Mode:   Replicated</span><br><span class="line"> Replicas:      1</span><br><span class="line">Placement:</span><br><span class="line">UpdateConfig:</span><br><span class="line"> Parallelism:   1</span><br><span class="line"> On failure:    pause</span><br><span class="line"> Monitoring Period: 5s</span><br><span class="line"> Max failure ratio: 0</span><br><span class="line"> Update order:      stop-first</span><br><span class="line">RollbackConfig:</span><br><span class="line"> Parallelism:   1</span><br><span class="line"> On failure:    pause</span><br><span class="line"> Monitoring Period: 5s</span><br><span class="line"> Max failure ratio: 0</span><br><span class="line"> Rollback order:    stop-first</span><br><span class="line">ContainerSpec:</span><br><span class="line"> Image:         nginx:latest@sha256:b73f527d86e3461fd652f62cf47e7b375196063bbbd503e853af5be16597cb2e</span><br><span class="line"> Init:          <span class="literal">false</span></span><br><span class="line">Resources:</span><br><span class="line">Networks: nginx_net</span><br><span class="line">Endpoint Mode:  vip</span><br><span class="line">Ports:</span><br><span class="line"> PublishedPort = 80</span><br><span class="line">  Protocol = tcp</span><br><span class="line">  TargetPort = 80</span><br><span class="line">  PublishMode = ingress</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询到哪个节点正在运行该服务。如下该容器被调度到manager-node节点上启动了，然后访问http://192.168.31.43即可访问这个容器应用（如果调度到其他节点，访问也是如此）</span></span><br><span class="line">[root@manager43 ~]<span class="comment"># docker service ps my_nginx</span></span><br><span class="line">ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE               ERROR               PORTS</span><br><span class="line">yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running about an hour ago</span><br><span class="line">```                       </span><br><span class="line">温馨提示：如果上面命令执行后，上面的 STATE 字段中刚开始的服务状态为 Preparing，需要等一会才能变为 Running 状态，其中最费时间的应该是下载镜像的过程</span><br><span class="line"> </span><br><span class="line">有上面命令可知，该服务在manager-node节点上运行。登陆该节点，可以查看到nginx容器在运行中</span><br><span class="line">```bash</span><br><span class="line">[root@manager43 ~]<span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">0dc7103f8030        nginx:latest        <span class="string">"nginx -g 'daemon of…"</span>   About an hour ago   Up About an hour    80/tcp              my_nginx.1.yzonph0zu7km0211uj0ro5brj</span><br></pre></td></tr></table></figure><p>3) 在Swarm中动态扩展服务(scale)<br>当然，如果只是通过service启动容器，swarm也算不上什么新鲜东西了。Service还提供了复制（类似kubernetes里的副本）功能。可以通过 docker service scale 命令来设置服务中容器的副本数<br>比如将上面的my_nginx容器动态扩展到4个</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker service scale my_nginx=4</span></span><br><span class="line">my_nginx scaled to 4</span><br><span class="line">overall progress: 4 out of 4 tasks</span><br><span class="line">1/4: running   [==================================================&gt;]</span><br><span class="line">2/4: running   [==================================================&gt;]</span><br><span class="line">3/4: running   [==================================================&gt;]</span><br><span class="line">4/4: running   [==================================================&gt;]</span><br><span class="line">verify: Service converged</span><br></pre></td></tr></table></figure><p>和创建服务一样，增加scale数之后，将会创建新的容器，这些新启动的容器也会经历从准备到运行的过程，过一分钟左右，服务应该就会启动完成，这时候可以再来看一下 nginx 服务中的容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@manager43 ~]<span class="comment"># docker service ps my_nginx</span></span><br><span class="line">ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE               ERROR               PORTS</span><br><span class="line">yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running about an hour ago                      </span><br><span class="line">mlprstt9ds5x        my_nginx.2          nginx:latest        node139             Running             Running 52 seconds ago                         </span><br><span class="line">y09lk90tdzdp        my_nginx.3          nginx:latest        node139             Running             Running 52 seconds ago                         </span><br><span class="line">clolfl3zlvj0        my_nginx.4          nginx:latest        node188             Running             Running 2 minutes ago</span><br></pre></td></tr></table></figure><p>可以看到，之前my_nginx容器只在manager-node节点上有一个实例，而现在又增加了3个实例。<br>这4个副本的my_nginx容器分别运行在这三个节点上，登陆这三个节点，就会发现已经存在运行着的my_nginx容器</p><p>4) 模拟宕机node节点<br>特别需要清楚的一点：<br>如果一个节点宕机了（即该节点就会从swarm集群中被踢出），则Docker应该会将在该节点运行的容器，调度到其他节点，以满足指定数量的副本保持运行状态。</p><p>比如：<br>将node139宕机后或将node139的docker服务关闭，那么它上面的task实例就会转移到别的节点上。当node139节点恢复后，它转移出去的task实例不会主动转移回来，<br>只能等别的节点出现故障后转移task实例到它的上面。使用命令”docker node ls”，发现node139节点已不在swarm集群中了(状态为：Down)。<br>[root@node139 ~]# systemctl stop docker<br>[root@manager43 ~]# docker node ls<br>ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION<br>ppk7q0bjond8a58xja7in1qid *   manager43           Ready               Active              Leader              18.06.0-ce<br>mums8azgbrffnecp3q8fz70pl     node139             Down                Active                                  18.06.1-ce<br>z3n36maf03yjg7odghikuv574     node188             Ready               Active                                  18.06.1-ce</p><p>然后过一会查询服务的状态列表<br>[root@manager43 ~]# docker service ps my_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTS<br>yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running about an hour ago<br>wb1cpk9k22rl        my_nginx.2          nginx:latest        node188             Running             Running about a minute ago<br>mlprstt9ds5x         _ my_nginx.2      nginx:latest        node139             Shutdown            Running 4 minutes ago<br>rhbj4bcr4t2c        my_nginx.3          nginx:latest        manager43           Running             Running about a minute ago<br>y09lk90tdzdp         _ my_nginx.3      nginx:latest        node139             Shutdown            Running 4 minutes ago<br>clolfl3zlvj0        my_nginx.4          nginx:latest        node188             Running             Running 6 minutes ago</p><p>上面我们可以发现node139故障后，它上面之前的两个task任务已经转移到node188和manager43节点上了</p><p>登陆到node188和manager43节点上，可以看到这两个运行的task任务。当访问192.168.31.188和192.168.31.43节点的80端口，swarm的负载均衡会把请求路由到一个任意节点的可用的容器上<br>[root@manager43 ~]# docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES<br>ae4c5c2e6f3f        nginx:latest        “nginx -g ‘daemon of…”   4 minutes ago       Up 4 minutes        80/tcp              my_nginx.3.rhbj4bcr4t2c3y2f8vyfmbi21<br>0dc7103f8030        nginx:latest        “nginx -g ‘daemon of…”   About an hour ago   Up About an hour    80/tcp              my_nginx.1.yzonph0zu7km0211uj0ro5brj</p><p>[root@node188 ~]# docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES<br>a63ef253f7dd        nginx:latest        “nginx -g ‘daemon of…”   3 minutes ago       Up 3 minutes        80/tcp              my_nginx.2.wb1cpk9k22rl1ydab7aozl2b5<br>74a1a1db81d4        nginx:latest        “nginx -g ‘daemon of…”   8 minutes ago       Up 8 minutes        80/tcp              my_nginx.4.clolfl3zlvj0ewmh85c2ljnza</p><p>再次在node188和manager43节点上将从node139上转移过来的两个task关闭<br>[root@manager43 ~]# docker stop my_nginx.3.rhbj4bcr4t2c3y2f8vyfmbi21<br>my_nginx.3.rhbj4bcr4t2c3y2f8vyfmbi21</p><p>[root@node188 ~]# docker stop my_nginx.2.wb1cpk9k22rl1ydab7aozl2b5<br>my_nginx.2.wb1cpk9k22rl1ydab7aozl2b5</p><p>再次查询服务的状态列表，发现这两个task又转移到node139上了<br>[root@manager43 ~]# docker service ps my_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR               PORTS<br>yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running 2 hours ago<br>j2q61f8jtzba        my_nginx.2          nginx:latest        node188             Running             Running 24 seconds ago<br>wb1cpk9k22rl         _ my_nginx.2      nginx:latest        node188             Shutdown            Complete 29 seconds ago<br>mlprstt9ds5x         _ my_nginx.2      nginx:latest        node139             Shutdown            Running 11 minutes ago<br>oz9wyjuldw1t        my_nginx.3          nginx:latest        manager43           Running             Running 40 seconds ago<br>rhbj4bcr4t2c         _ my_nginx.3      nginx:latest        manager43           Shutdown            Complete 45 seconds ago<br>y09lk90tdzdp         _ my_nginx.3      nginx:latest        node139             Shutdown            Running 11 minutes ago<br>clolfl3zlvj0        my_nginx.4          nginx:latest        node188             Running             Running 12 minutes ago<br>结论：即在swarm cluster集群中启动的容器，在worker node节点上删除或停用后，该容器会自动转移到其他的worker node节点上</p><p>5) Swarm 动态缩容服务(scale)<br>同理，swarm还可以缩容，同样是使用scale命令<br>如下，将my_nginx容器变为1个<br>[root@manager43 ~]# docker service scale my_nginx=1<br>my_nginx scaled to 1<br>overall progress: 1 out of 1 tasks<br>1/1:<br>verify: Service converged</p><p>[root@manager43 ~]# docker service ls<br>ID                  NAME                MODE                REPLICAS            IMAGE               PORTS<br>zs7fw4ereo5w        my_nginx            replicated          1/1                 nginx:latest        *:80-&gt;80/tcp</p><p>[root@manager43 ~]# docker service ps my_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR               PORTS<br>yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running 11 hours ago<br>wb1cpk9k22rl        my_nginx.2          nginx:latest        node188             Shutdown            Complete 9 hours ago<br>mlprstt9ds5x         _ my_nginx.2      nginx:latest        node139             Shutdown            Shutdown 29 seconds ago<br>rhbj4bcr4t2c        my_nginx.3          nginx:latest        manager43           Shutdown            Complete 9 hours ago<br>y09lk90tdzdp         _ my_nginx.3      nginx:latest        node139             Shutdown            Shutdown 29 seconds ago      </p><p>通过docker service ps my_nginx 可以看到node节点上已经为Shutdown状态了</p><p>在登录到node节点主机上查看<br>[root@node188 ~]# docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS               NAMES<br>f93c0a27374a        nginx:latest        “nginx -g ‘daemon of…”   9 hours ago         Exited (0) 44 seconds ago                       my_nginx.2.j2q61f8jtzba9kb3unupkhl25<br>a63ef253f7dd        nginx:latest        “nginx -g ‘daemon of…”   9 hours ago         Exited (0) 9 hours ago                          my_nginx.2.wb1cpk9k22rl1ydab7aozl2b5<br>[root@node139 ~]# docker ps -a<br>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                   PORTS               NAMES<br>e8ac2e44f5c4        nginx:latest        “nginx -g ‘daemon of…”   9 hours ago         Exited (0) 9 hours ago                       my_nginx.2.mlprstt9ds5xi48u1rzscgfdk<br>5b031aa5a2cc        nginx:latest        “nginx -g ‘daemon of…”   9 hours ago         Exited (0) 9 hours ago                       my_nginx.3.y09lk90tdzdp8cwj6mm5oyr3f<br>登录node节点，使用docker ps -a 查看，会发现容器被stop而非rm</p><p>6) 除了上面使用scale进行容器的扩容或缩容之外，还可以使用docker service update 命令。 可对 服务的启动 参数 进行 更新/修改。<br>[root@manager43 ~]# docker service update –replicas 3 my_nginx<br>my_nginx<br>overall progress: 3 out of 3 tasks<br>1/3: running   [==================================================&gt;]<br>2/3: running   [==================================================&gt;]<br>3/3: running   [==================================================&gt;]<br>verify: Service converged</p><p>[root@manager43 ~]# docker service ls<br>ID                  NAME                MODE                REPLICAS            IMAGE               PORTS<br>zs7fw4ereo5w        my_nginx            replicated          3/3                 nginx:latest        *:80-&gt;80/tcp</p><p>[root@manager43 ~]# docker service ps my_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS<br>yzonph0zu7km        my_nginx.1          nginx:latest        manager43           Running             Running 11 hours ago<br>j3hduzd9pret        my_nginx.2          nginx:latest        node188             Running             Running 18 seconds ago<br>wb1cpk9k22rl         _ my_nginx.2      nginx:latest        node188             Shutdown            Complete 9 hours ago<br>mlprstt9ds5x         _ my_nginx.2      nginx:latest        node139             Shutdown            Shutdown 4 minutes ago<br>gng96vc5vqpv        my_nginx.3          nginx:latest        node139             Running             Running 18 seconds ago<br>rhbj4bcr4t2c         _ my_nginx.3      nginx:latest        manager43           Shutdown            Complete 9 hours ago<br>y09lk90tdzdp         _ my_nginx.3      nginx:latest        node139             Shutdown            Shutdown 4 minutes ago    </p><p>docker service update 命令，也可用于直接 升级 镜像等<br>[root@manager43 ~]# docker service update –image nginx:new my_nginx</p><p>[root@manager43 ~]# docker service ls<br>ID                  NAME                MODE                REPLICAS            IMAGE               PORTS<br>zs7fw4ereo5w        my_nginx            replicated          3/3                 nginx:new           *:80-&gt;80/tcp<br>注意IMAGE列 变成了nginx:new</p><p>7) 为了下面的直观显示，我这里把my_nginx服务直接删除了<br>[root@manager43 ~]# docker service rm my_nginx</p><p>这样就会把所有节点上的所有容器（task任务实例）全部删除了<br>4、Swarm中使用Volume(挂在目录，mount命令)</p><p>1) 查看volume的帮助信息<br>[root@manager43 ~]# docker volume –help</p><p>Usage:  docker volume COMMAND</p><p>Manage volumes</p><p>Commands:<br>  create      Create a volume<br>  inspect     Display detailed information on one or more volumes<br>  ls          List volumes<br>  prune       Remove all unused local volumes<br>  rm          Remove one or more volumes</p><p>Run ‘docker volume COMMAND –help’ for more information on a command.</p><p>2) 创建一个volume<br>[root@manager43 ~]# docker volume create –name testvolume<br>testvolume</p><h1 id="查看创建的volume"><a href="#查看创建的volume" class="headerlink" title="查看创建的volume"></a>查看创建的volume</h1><p>[root@manager43 ~]# docker volume ls<br>DRIVER              VOLUME NAME<br>local               testvolume</p><h1 id="查看volume详情"><a href="#查看volume详情" class="headerlink" title="查看volume详情"></a>查看volume详情</h1><p>[root@manager43 ~]# docker volume inspect testvolume<br>[<br>    {<br>        “CreatedAt”: “2018-10-21T10:50:02+08:00”,<br>        “Driver”: “local”,<br>        “Labels”: {},<br>        “Mountpoint”: “/var/lib/docker/volumes/testvolume/_data”,<br>        “Name”: “testvolume”,<br>        “Options”: {},<br>        “Scope”: “local”<br>    }<br>]</p><p>3) 创建新的服务并挂载testvolume(nginx为例)<br>[root@manager43 ~]# docker service create –replicas 3 –mount type=volume,src=testvolume,dst=/zjz –name test_nginx nginx<br>sh7wc8yzcvr0xaedo4tnraj7l<br>overall progress: 3 out of 3 tasks<br>1/3: running   [==================================================&gt;]<br>2/3: running   [==================================================&gt;]<br>3/3: running   [==================================================&gt;]<br>verify: Service converged</p><p>温馨提示：<br>参数src写成source也可以；dst表示容器内的路径，也可以写成target</p><h1 id="查看创建服务"><a href="#查看创建服务" class="headerlink" title="查看创建服务"></a>查看创建服务</h1><p>[root@manager43 ~]# docker service ls<br>ID                  NAME                MODE                REPLICAS            IMAGE               PORTS<br>sh7wc8yzcvr0        test_nginx          replicated          3/3                 nginx:latest<br>[root@manager43 ~]# docker service ps test_nginx<br>ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS<br>m7m41kwt4q6w        test_nginx.1        nginx:latest        node188             Running             Running 56 seconds ago<br>kayh81q1o1kx        test_nginx.2        nginx:latest        node139             Running             Running 56 seconds ago<br>eq11v0rcwy38        test_nginx.3        nginx:latest        manager43           Running             Running 56 seconds ago           </p><h1 id="查看有没有挂载成功-登录各个节点的容器看看有没有指定的目录并创建文件测试"><a href="#查看有没有挂载成功-登录各个节点的容器看看有没有指定的目录并创建文件测试" class="headerlink" title="查看有没有挂载成功(登录各个节点的容器看看有没有指定的目录并创建文件测试)"></a>查看有没有挂载成功(登录各个节点的容器看看有没有指定的目录并创建文件测试)</h1><h1 id="容器中操作"><a href="#容器中操作" class="headerlink" title="容器中操作"></a>容器中操作</h1><p>[root@manager43 ~]# docker exec -it 63451219cb4e /bin/bash<br>root@63451219cb4e:/# cd /zjz/<br>root@63451219cb4e:/zjz# ls<br>root@63451219cb4e:/zjz# echo “gen wo xue docker” &gt; docker.txt<br>root@63451219cb4e:/zjz# ls<br>docker.txt</p><p>执行docker volume inspect testvolume 可以看到本地的路径(上面已经执行过了)<br>本地路径：/var/lib/docker/volumes/testvolume/_data<br>[root@manager43 ~]# cd /var/lib/docker/volumes/testvolume/_data<br>[root@manager43 _data]# ls<br>docker.txt<br>[root@manager43 _data]# cat docker.txt<br>gen wo xue docker</p><p>还可以将node节点机上的volume数据目录做成软链接<br>[root@manager43 _data]# ln -s /var/lib/docker/volumes/testvolume/_data /zjz<br>[root@manager43 _data]# cd /zjz/<br>[root@manager43 zjz]# ls<br>docker.txt<br>[root@manager43 zjz]# echo “123” &gt; 1.txt<br>[root@manager43 zjz]# ll<br>总用量 8<br>-rw-r–r– 1 root root  4 10月 21 11:04 1.txt<br>-rw-r–r– 1 root root 18 10月 21 11:00 docker.txt</p><h1 id="容器中查看"><a href="#容器中查看" class="headerlink" title="容器中查看"></a>容器中查看</h1><p>[root@manager43 zjz]# docker exec -it 63451219cb4e /bin/bash<br>root@63451219cb4e:/# cd /zjz/<br>root@63451219cb4e:/zjz# ls<br>1.txt  docker.txt<br>root@63451219cb4e:/zjz# cat 1.txt<br>123<br>root@63451219cb4e:/zjz# cat docker.txt<br>gen wo xue docker</p><h1 id="还有一种挂载方式简单说一下吧，上面的会了下面的肯定简单"><a href="#还有一种挂载方式简单说一下吧，上面的会了下面的肯定简单" class="headerlink" title="还有一种挂载方式简单说一下吧，上面的会了下面的肯定简单"></a>还有一种挂载方式简单说一下吧，上面的会了下面的肯定简单</h1><p>命令格式：<br>docker service create –mount type=bind,target=/container_data/,source=/host_data/<br>其中，参数target表示容器里面的路径，source表示本地硬盘路径</p><h1 id="示例创建并挂载并使用网络"><a href="#示例创建并挂载并使用网络" class="headerlink" title="示例创建并挂载并使用网络"></a>示例创建并挂载并使用网络</h1><p>[root@manager43 ~]# docker service create –replicas 1 –mount type=bind,target=/usr/share/nginx/html/,source=/opt/web/ –network nginx_net –name zjz_nginx -p 8880:80 nginx<br>5、多服务Swarm集群部署</p><p>问：上面我们只是对单独的一个nginx服务进行的集群部署，那如果要统一编排多个服务呢？<br>答：docker 三剑客中有个compose 这个就是对单机进行统一编排的，它的实现是通过docker-compose.yml的文件，这里我们就可以结合compose和swarm进行多服务的编排(docker compose教程)</p><p>温馨提示：<br>我们这里要部署的服务有三个(nginx服务，visualizer服务，portainer服务) 都是集群 GUI 管理服务<br>docker service部署的是单个服务，我们可以使用docker stack进行多服务编排部署</p><p>1) 编写docker-compose.yml文件<br>[root@manager43 ~]# mkdir testswarm<br>[root@manager43 ~]# cd testswarm/<br>[root@manager43 testswarm]# cat docker-compose.yml<br>version: “3”<br>services:<br>  nginx:<br>    image: nginx<br>    ports:<br>      - 8888:80<br>    deploy:<br>      mode: replicated<br>      replocas: 3</p><p>  visualizer:<br>    image: dockersamples/visualizer<br>    ports:<br>      - “8080:8080”<br>    volumes:<br>      - “/var/run/docker.sock:/var/run/docker.sock”<br>    deploy:<br>      replicas: 1<br>      placement:<br>        constraints: [node.role == manager]</p><p>  portainer:<br>    image: portainer/portainer<br>    ports:<br>      - “9000:9000”<br>    volumes:<br>      - “/var/run/docker.sock:/var/run/docker.sock”<br>    deploy:<br>      replicas: 1<br>      placement:<br>        constraints: [node.role == manager]</p><p>2) 通过这个yml文件部署服务<br>[root@manager43 testswarm]# docker stack deploy -c docker-compose.yml deploy_deamon<br>Creating network deploy_deamon_default<br>Creating service deploy_deamon_portainer<br>Creating service deploy_deamon_nginx<br>Creating service deploy_deamon_visualizer</p><p>通过上面的执行过程可以看出这样创建会默认创建一个网络并使用它，名字都是我们给的名字的前缀加上服务名</p><h1 id="查看创建服务-1"><a href="#查看创建服务-1" class="headerlink" title="查看创建服务"></a>查看创建服务</h1><p>[root@manager43 testswarm]# docker service ls<br>ID                  NAME                       MODE                REPLICAS            IMAGE                             PORTS<br>xj2f1t5ax3nm        deploy_deamon_nginx        replicated          3/3                 nginx:latest                      *:8888-&gt;80/tcp<br>ky9qpldr5abb        deploy_deamon_portainer    replicated          1/1                 portainer/portainer:latest        *:9000-&gt;9000/tcp<br>r47ff177x1ir        deploy_deamon_visualizer   replicated          1/1                 dockersamples/visualizer:latest   *:8080-&gt;8080/tcp</p><p>[root@manager43 testswarm]# docker service ps deploy_deamon_nginx<br>ID                  NAME                    IMAGE               NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTS<br>z3v4uc1ujsnq        deploy_deamon_nginx.1   nginx:latest        node139             Running             Running about a minute ago<br>jhg3ups0cko5        deploy_deamon_nginx.2   nginx:latest        manager43           Running             Running about a minute ago<br>3e6guv791x21        deploy_deamon_nginx.3   nginx:latest        node188             Running             Running about a minute ago        </p><p>[root@manager43 testswarm]# docker service ps deploy_deamon_portainer<br>ID                  NAME                        IMAGE                        NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTS<br>whyuvy82cvvw        deploy_deamon_portainer.1   portainer/portainer:latest   manager43           Running             Running about a minute ago                      </p><p>[root@manager43 testswarm]# docker service ps deploy_deamon_visualizer<br>ID                  NAME                         IMAGE                             NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS<br>wge5w1eqykg3        deploy_deamon_visualizer.1   dockersamples/visualizer:latest   manager43           Running             Starting 7 seconds ago<br>测试</p><h1 id="八、Docker-Swarm-容器网络"><a href="#八、Docker-Swarm-容器网络" class="headerlink" title="八、Docker Swarm 容器网络"></a>八、Docker Swarm 容器网络</h1><p>在Docker版本1.12之后swarm模式原生支持覆盖网络(overlay networks)，可以先创建一个覆盖网络，然后启动容器的时候启用这个覆盖网络，<br>这样只要是这个覆盖网络内的容器，不管在不在同一个宿主机上都能相互通信，即跨主机通信！不同覆盖网络内的容器组之间是相互隔离的（相互ping不通）。</p><p>swarm模式的覆盖网络包括以下功能：<br>1）可以附加多个服务到同一个网络。<br>2）默认情况下，service discovery为每个swarm服务分配一个虚拟IP地址(vip)和DNS名称，使得在同一个网络中容器之间可以使用服务名称为互相连接。<br>3）可以配置使用DNS轮循而不使用VIP<br>4）为了可以使用swarm的覆盖网络，在启用swarm模式之间你需要在swarm节点之间开放以下端口：<br>5）TCP/UDP端口7946 – 用于容器网络发现<br>6）UDP端口4789 – 用于容器覆盖网络</p><p>实例如下：<br>———–在Swarm集群中创建overlay网络————<br>[root@manager-node ~]# docker network create –driver overlay –opt encrypted –subnet 10.10.19.0/24 ngx_net</p><p>参数解释：<br>–opt encrypted  默认情况下swarm中的节点通信是加密的。在不同节点的容器之间，可选的–opt encrypted参数能在它们的vxlan流量启用附加的加密层。<br>–subnet 命令行参数指定overlay网络使用的子网网段。当不指定一个子网时，swarm管理器自动选择一个子网并分配给网络。</p><p>[root@manager-node ~]# docker network ls<br>NETWORK ID          NAME                DRIVER              SCOPE<br>d7aa48d3e485        bridge              bridge              local<br>9e637a97a3b9        docker_gwbridge     bridge              local<br>b5a41c8c71e7        host                host                local<br>7f4fx3jf4dbr        ingress             overlay             swarm<br>3x2wgugr6zmn        ngx_net             overlay             swarm<br>0808a5c72a0a        none                null                local</p><p>由上可知，Swarm当中拥有2套覆盖网络。其中”ngx_net”网络正是我们在部署容器时所创建的成果。而”ingress”覆盖网络则为默认提供。<br>Swarm 管理节点会利用 ingress 负载均衡以将服务公布至集群之外。<br>在将服务连接到这个创建的网络之前，网络覆盖到manager节点。上面输出的SCOPE为 swarm 表示将服务部署到Swarm时可以使用此网络。<br>在将服务连接到这个网络后，Swarm只将该网络扩展到特定的worker节点，这个worker节点被swarm调度器分配了运行服务的任务。<br>在那些没有运行该服务任务的worker节点上，网络并不扩展到该节点。</p><p>——————将服务连接到overlay网络——————-<br>[root@manager-node ~]# docker service create –replicas 5 –network ngx_net –name my-test -p 80:80 nginx</p><p>上面名为”my-test”的服务启动了3个task，用于运行每个任务的容器都可以彼此通过overlay网络进行通信。Swarm集群将网络扩展到所有任务处于Running状态的节点上。<br>[root@manager-node ~]# docker service ls<br>ID            NAME     REPLICAS  IMAGE  COMMAND<br>dsaxs6v463g9  my-test  5/5       nginx</p><p>在manager-node节点上，通过下面的命令查看哪些节点有处于running状态的任务：<br>[root@manager-node ~]# docker service ps my-test<br>ID                         NAME       IMAGE  NODE          DESIRED STATE  CURRENT STATE          ERROR<br>8433fuiy7vpu0p80arl7vggfe  my-test.1  nginx  node2         Running        Running 2 minutes ago<br>f1h7a0vtojv18zrsiw8j0rzaw  my-test.2  nginx  node1         Running        Running 2 minutes ago<br>ex73ifk3jvzw8ukurl8yu7fyq  my-test.3  nginx  node1         Running        Running 2 minutes ago<br>cyu73jd8psupfhken23vvmpud  my-test.4  nginx  manager-node  Running        Running 2 minutes ago<br>btorxekfix4hcqh4v83dr0tzw  my-test.5  nginx  manager-node  Running        Running 2 minutes ago</p><p>可见三个节点都有处于running状态的任务，所以my-network网络扩展到三个节点上。</p><p>可以查询某个节点上关于my-network的详细信息：<br>[root@manager-node ~]# docker network inspect ngx_net<br>[<br>    {<br>        “Name”: “ngx_net”,<br>        “Id”: “3x2wgugr6zmn1mcyf9k1du27p”,<br>        “Scope”: “swarm”,<br>        “Driver”: “overlay”,<br>        “EnableIPv6”: false,<br>        “IPAM”: {<br>            “Driver”: “default”,<br>            “Options”: null,<br>            “Config”: [<br>                {<br>                    “Subnet”: “10.10.19.0/24”,<br>                    “Gateway”: “10.10.19.1”<br>                }<br>            ]<br>        },<br>        “Internal”: false,<br>        “Containers”: {<br>            “00f47e38deea76269eb03ba13695ec0b0c740601c85019546d6a9a17fd434663”: {<br>                “Name”: “my-test.5.btorxekfix4hcqh4v83dr0tzw”,<br>                “EndpointID”: “ea962d07eee150b263ae631b8a7f8c1950337c11ef2c3d488a7c3717defd8601”,<br>                “MacAddress”: “02:42:0a:0a:13:03”,<br>                “IPv4Address”: “10.10.19.3/24”,<br>                “IPv6Address”: “”<br>            },<br>            “957620c6f7abb44ad8dd2d842d333f5e5c1655034dc43e49abbbd680de3a5341”: {<br>                “Name”: “my-test.4.cyu73jd8psupfhken23vvmpud”,<br>                “EndpointID”: “f33a6e9ddf1dd01bcfc43ffefd19e19514658f001cdf9b2fbe23bc3fdf56a42a”,<br>                “MacAddress”: “02:42:0a:0a:13:07”,<br>                “IPv4Address”: “10.10.19.7/24”,<br>                “IPv6Address”: “”<br>            }<br>        },<br>        “Options”: {<br>            “com.docker.network.driver.overlay.vxlanid_list”: “257”<br>        },<br>        “Labels”: {}<br>    }<br>]</p><p>从上面的信息可以看出在manager-node节点上，名为my-test的服务有一个名为my-test.5.btorxekfix4hcqh4v83dr0tzw和<br>my-test.4.cyu73jd8psupfhken23vvmpud的task连接到名为ngx_net的网络上（另外两个节点node1和node2同样可以用上面命令查看）<br>[root@node1 ~]# docker network inspect ngx_net<br>…….<br>        “Containers”: {<br>            “7d9986fad5a7d834676ba76ae75aff2258f840953f1dc633c3ef3c0efd2b2501”: {<br>                “Name”: “my-test.3.ex73ifk3jvzw8ukurl8yu7fyq”,<br>                “EndpointID”: “957ca19f3d5480762dbd14fd9a6a1cd01a8deac3e8e35b23d1350f480a7b2f37”,<br>                “MacAddress”: “02:42:0a:0a:13:06”,<br>                “IPv4Address”: “10.10.19.6/24”,<br>                “IPv6Address”: “”<br>            },<br>            “9e50fceada1d7c653a886ca29d2bf2606debafe8c8a97f2d79104faf3ecf8a46”: {<br>                “Name”: “my-test.2.f1h7a0vtojv18zrsiw8j0rzaw”,<br>                “EndpointID”: “b1c209c7b68634e88e0bf5e100fe03435b3096054da6555c61e6c207ac651ac2”,<br>                “MacAddress”: “02:42:0a:0a:13:05”,<br>                “IPv4Address”: “10.10.19.5/24”,<br>                “IPv6Address”: “”<br>            }<br>        },<br>………</p><p>[root@node2 web]# docker network inspect ngx_net<br>……..<br>        “Containers”: {<br>            “4bdcce0ee63edc08d943cf4a049eac027719ff2dc14b7c3aa85fdddc5d1da968”: {<br>                “Name”: “my-test.1.8433fuiy7vpu0p80arl7vggfe”,<br>                “EndpointID”: “df58de85b0a0e4d128bf332fc783f6528d1f179b0f9f3b7aa70ebc832640d3bc”,<br>                “MacAddress”: “02:42:0a:0a:13:04”,<br>                “IPv4Address”: “10.10.19.4/24”,<br>                “IPv6Address”: “”<br>            }<br>        },</p><p>可以通过查询服务来获得服务的虚拟IP地址，如下：<br>[root@manager-node ~]# docker service inspect –format=’‘ my-test<br>[{“NetworkID”:”7f4fx3jf4dbrp97aioc05pul4”,”Addr”:”10.255.0.6/16”},{“NetworkID”:”3x2wgugr6zmn1mcyf9k1du27p”,”Addr”:”10.10.19.2/24”}]</p><p>由上结果可知，10.10.19.2其实就是swarm集群内部的vip，整个网络结构如下图所示：　</p><p>加入ngx_net网络的容器彼此之间可以通过IP地址通信，也可以通过名称通信。</p><p>[root@node2 ~]# docker ps<br>CONTAINER ID    IMAGE           COMMAND                  CREATED         STATUS             PORTS    NAMES<br>4bdcce0ee63e    nginx:latest    “nginx -g ‘daemon off”   22 minutes ago  Up 22 minutes      80/tcp   my-test.1.8433fuiy7vpu0p80arl7vggfe</p><p>[root@node2 ~]# docker exec -ti 4bdcce0ee63e /bin/bash<br>root@4bdcce0ee63e:/# ip addr<br>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default<br>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00<br>    inet 127.0.0.1/8 scope host lo<br>       valid_lft forever preferred_lft forever<br>    inet6 ::1/128 scope host<br>       valid_lft forever preferred_lft forever<br>1786: eth0@if1787: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default<br>    link/ether 02:42:0a:ff:00:08 brd ff:ff:ff:ff:ff:ff link-netnsid 0<br>    inet 10.255.0.8/16 scope global eth0<br>       valid_lft forever preferred_lft forever<br>    inet 10.255.0.6/32 scope global eth0<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::42:aff:feff:8/64 scope link<br>       valid_lft forever preferred_lft forever<br>1788: eth1@if1789: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default<br>    link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 1<br>    inet 172.18.0.3/16 scope global eth1<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::42:acff:fe12:3/64 scope link<br>       valid_lft forever preferred_lft forever<br>1791: eth2@if1792: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP group default<br>    link/ether 02:42:0a:0a:13:04 brd ff:ff:ff:ff:ff:ff link-netnsid 2<br>    inet 10.10.19.4/24 scope global eth2<br>       valid_lft forever preferred_lft forever<br>    inet 10.10.19.2/32 scope global eth2<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::42:aff:fe0a:1304/64 scope link<br>       valid_lft forever preferred_lft forever</p><p>root@4bdcce0ee63e:/# ping 10.10.19.3<br>PING 10.10.19.3 (10.10.19.3): 56 data bytes<br>64 bytes from 10.10.19.3: icmp_seq=0 ttl=64 time=0.890 ms<br>64 bytes from 10.10.19.3: icmp_seq=1 ttl=64 time=0.622 ms<br>…..-<br>2 packets transmitted, 2 packets received, 0% packet loss<br>round-trip min/avg/max/stddev = 0.622/0.756/0.890/0.134 ms</p><p>root@4bdcce0ee63e:/# ping 10.10.19.6<br>PING 10.10.19.6 (10.10.19.6): 56 data bytes<br>64 bytes from 10.10.19.6: icmp_seq=0 ttl=64 time=0.939 ms<br>64 bytes from 10.10.19.6: icmp_seq=1 ttl=64 time=0.590 ms</p><p>—————————-使用swarm模式的服务发现————————–<br>默认情况下，当创建了一个服务并连接到某个网络后，swarm会为该服务分配一个VIP。此VIP根据服务名映射到DNS。在网络上的容器共享该服务的DNS映射，<br>所以网络上的任意容器可以通过服务名访问服务。</p><p>在同一overlay网络中，不用通过端口映射来使某个服务可以被其它服务访问。Swarm内部的负载均衡器自动将请求发送到服务的VIP上，然后分发到所有的<br>active的task上。</p><p>如下示例：<br>在同一个网络中添加了一个centos服务，此服务可以通过名称my-test访问前面创建的nginx服务：<br>[root@manager-node ~]# docker service create –name my-centos –network ngx_net centos       </p><p>查询centos运行在哪个节点上（上面创建命令执行后，需要一段时间才能完成这个centos服务的创建）<br>[root@manager-node ~]# docker service ps my-centos<br>ID                         NAME             IMAGE   NODE   DESIRED STATE  CURRENT STATE            ERROR<br>e03pqgkjs3l1qizc6v4aqaune  my-centos.1      centos  node2  Running        Preparing 4 seconds ago</p><p>登录centos运行的节点（由上可知是node2节点），打开centos的交互shell：<br>[root@node2 ~]# docker ps<br>CONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS            NAMES<br>e4554490d891        centos:latest            “/bin/bash”             About an hour ago   Up About an hour   my-centos.1.9yk5ie28gwk9mw1h1jovb68ki</p><p>[root@node2 ~]# docker exec -ti my-centos.1.9yk5ie28gwk9mw1h1jovb68ki /bin/bash<br>root@4bdcce0ee63e:/# nslookup my-test<br>Server: 127.0.0.11<br>Address 1: 127.0.0.11</p><p>Name: my-test<br>Address 1: 10.10.19.2 10.10.19.2</p><p>从centos容器内部，使用特殊查询 查询DNS，来找到my-test服务的所有容器的IP地址：<br>root@4bdcce0ee63e:/# nslookup tasks.my-test<br>Server: 127.0.0.11<br>Address 1: 127.0.0.11</p><p>Name: tasks.my-test<br>Address 1: 10.10.19.4 my-test.1.8433fuiy7vpu0p80arl7vggfe<br>Address 2: 10.10.19.5 my-test.2.f1h7a0vtojv18zrsiw8j0rzaw<br>Address 3: 10.10.19.6 my-test.3.ex73ifk3jvzw8ukurl8yu7fyq<br>Address 2: 10.10.19.7 my-test.4.cyu73jd8psupfhken23vvmpud<br>Address 3: 10.10.19.3 my-test.5.btorxekfix4hcqh4v83dr0tzw</p><p>从centos容器内部，通过wget来访问my-test服务中运行的nginx网页服务器<br>root@4bdcce0ee63e:/# wget -O- my-test<br>Connecting to my-test (10.10.19.2:80)<br><!DOCTYPE html></p><html><head><title>Welcome to nginx!</title>...<p>Swarm的负载均衡器自动将HTTP请求路由到VIP上，然后到一个active的task容器上。它根据round-robin选择算法将后续的请求分发到另一个active的task上。</p><p>———————————–为服务使用DNS round-robin—————————–<br>在创建服务时，可以配置服务直接使用DNS round-robin而无需使用VIP。这是通过在创建服务时指定 –endpoint-mode dnsrr 命令行参数实现的。<br>当你想要使用自己的负载均衡器时可以使用这种方式。</p><p>如下示例（注意：使用DNS round-robin方式创建服务，不能直接在命令里使用-p指定端口）<br>[root@manager-node ~]# docker service create –replicas 3 –name my-dnsrr-nginx –network ngx_net –endpoint-mode dnsrr nginx</p><p>[root@manager-node ~]# docker service ps my-dnsrr-nginx<br>ID                         NAME              IMAGE  NODE          DESIRED STATE  CURRENT STATE          ERROR<br>65li2zbhxvvoaesndmwjokouj  my-dnsrr-nginx.1  nginx  node1         Running        Running 2 minutes ago<br>5hjw7wm4xr877879m0ewjciuj  my-dnsrr-nginx.2  nginx  manager-node  Running        Running 2 minutes ago<br>afo7acduge2qfy60e87liz557  my-dnsrr-nginx.3  nginx  manager-node  Running        Running 2 minutes ago</p><p>当通过服务名称查询DNS时，DNS服务返回所有任务容器的IP地址：<br>root@4bdcce0ee63e:/# nslookup my-dnsrr-nginx<br>Server:    127.0.0.11<br>Address 1: 127.0.0.11</p><p>Name:      my-dnsrr-nginx<br>Address 1: 10.10.19.10 my-dnsrr-nginx.3.0sm1n9o8hygzarv5t5eq46okn.my-network<br>Address 2: 10.10.19.9  my-dnsrr-nginx.2.b3o1uoa8m003b2kk0ytl9lawh.my-network<br>Address 3: 10.10.19.8  my-dnsrr-nginx.1.55za4c83jq9846rle6eigiq15.my-network</p><p>需要注意的是：一定要确认VIP的连通性<br>通常Docker官方推荐使用dig，nslookup或其它DNS查询工具来查询通过DNS对服务名的访问。因为VIP是逻辑IP，ping并不是确认VIP连通性的正确的工具。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、什么是Docker-Swarm&quot;&gt;&lt;a href=&quot;#一、什么是Docker-Swarm&quot; class=&quot;headerlink&quot; title=&quot;一、什么是Docker Swarm&quot;&gt;&lt;/a&gt;一、什么是Docker Swarm&lt;/h1&gt;&lt;p&gt;　　Swarm是Do
      
    
    </summary>
    
    
      <category term="云原生" scheme="https://www.alan87.top/categories/cloud-native/"/>
    
      <category term="Docker" scheme="https://www.alan87.top/categories/cloud-native/docker/"/>
    
    
      <category term="云原生" scheme="https://www.alan87.top/tags/cn/"/>
    
      <category term="Docker" scheme="https://www.alan87.top/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>elasticsearch实战--java实现修改数据立即可见</title>
    <link href="https://www.alan87.top/es/elasticsearch%E5%AE%9E%E6%88%98-java%E5%AE%9E%E7%8E%B0%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E7%AB%8B%E5%8D%B3%E5%8F%AF%E8%A7%81/"/>
    <id>https://www.alan87.top/es/elasticsearch%E5%AE%9E%E6%88%98-java%E5%AE%9E%E7%8E%B0%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E7%AB%8B%E5%8D%B3%E5%8F%AF%E8%A7%81/</id>
    <published>2020-04-19T00:31:47.000Z</published>
    <updated>2020-10-10T07:03:43.784Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-背景"><a href="#0-背景" class="headerlink" title="0.背景"></a>0.背景</h1><p>后台管理系统中，当进行部分修改操作后，会立即跳转列表页面，此时列表展示的仍为es的旧数据。修改的es的数据没有立即展示，但是当再次刷新页面后，数据才为最新的数据。</p><p>众所周知，es不是一个实时的搜索引擎，<strong>当数据从写入到可见之间有1秒的间隔时间</strong>。因此，在此时间间隔内的查询操作，都是不是最新的数据。</p><h1 id="1-解决"><a href="#1-解决" class="headerlink" title="1.解决"></a>1.解决</h1><p>在<strong>java high level client</strong>中，为<code>index</code>、<code>insert</code>、<code>update</code>、<code>bulk</code> 提供了<code>setRefreshPolicy</code>方法，用于设置数据更改后的刷新策略。</p><p>主要是三个参数<code>IMMEDIATE</code>、<code>NONE</code>、<code>WAIT_UNTIL</code>：</p><h2 id="NONE"><a href="#NONE" class="headerlink" title="NONE:"></a><strong>NONE</strong>:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Don’t refresh after this request. The default.</span><br><span class="line">这是默认的一种方式，调用request修改以后，并不进行强制刷新，刷新的时间间隔为refresh_interval设置的参数。</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.</span></span><br><span class="line">request.setRefreshPolicy(WriteRequest.RefreshPolicy.NONE);</span><br><span class="line"><span class="comment">// 2.</span></span><br><span class="line">request.setRefreshPolicy(<span class="string">"false"</span>);</span><br></pre></td></tr></table></figure><h2 id="IMMEDIATE："><a href="#IMMEDIATE：" class="headerlink" title="IMMEDIATE："></a><strong>IMMEDIATE</strong>：</h2><ul><li>强制刷新相关的主分片和副分片（而不是整个索引），使更新的分片状态变为可搜索。</li><li>在使用之前，一定要仔细考虑使用该参数会不会导致性能不佳。</li><li>强制刷新作为请求的一部分,这种方式并不适用于索引和查询高吞吐量的场景，</li><li>但是作为流量小时提供一致性的视图的确是很使用的。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.</span></span><br><span class="line">request.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE);</span><br><span class="line"><span class="comment">// 2.</span></span><br><span class="line">request.setRefreshPolicy(<span class="string">"true"</span>);</span><br></pre></td></tr></table></figure><h2 id="WAIT-UNTIL"><a href="#WAIT-UNTIL" class="headerlink" title="WAIT_UNTIL:"></a><strong>WAIT_UNTIL</strong>:</h2><ul><li>在返回请求结果之前，会等待刷新请求所做的更改。并不是强制立即刷新，而是等待刷新发生。Elasticsearch会自动刷新已更改每个index.refresh_interval的分片，默认为一秒。该设置是动态的。</li><li>请求持续为打开状态，直到修改的内容变为可搜索为止。此刷新策略与高索引和搜索吞吐量兼容，但它会导致请求等待回复，直到刷新发生</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.</span></span><br><span class="line">request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL);</span><br><span class="line"><span class="comment">// 2.</span></span><br><span class="line">request.setRefreshPolicy(<span class="string">"wait_for"</span>);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0-背景&quot;&gt;&lt;a href=&quot;#0-背景&quot; class=&quot;headerlink&quot; title=&quot;0.背景&quot;&gt;&lt;/a&gt;0.背景&lt;/h1&gt;&lt;p&gt;后台管理系统中，当进行部分修改操作后，会立即跳转列表页面，此时列表展示的仍为es的旧数据。修改的es的数据没有立即展示，但是
      
    
    </summary>
    
    
      <category term="Java" scheme="https://www.alan87.top/categories/java/"/>
    
    
      <category term="Java" scheme="https://www.alan87.top/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Java的JIT知识整理</title>
    <link href="https://www.alan87.top/java/Java%E7%9A%84JIT%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"/>
    <id>https://www.alan87.top/java/Java%E7%9A%84JIT%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</id>
    <published>2020-03-06T01:00:51.000Z</published>
    <updated>2020-10-10T07:03:43.810Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-什么是JIT："><a href="#1-什么是JIT：" class="headerlink" title="1. 什么是JIT："></a>1. 什么是JIT：</h2><p>JIT编译器（just in time 即时编译器），当虚拟机发现某个方法或代码块运行特别频繁时，就会把这些代码认定为(Hot Spot Code 热点代码，为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各层次的优化，完成这项任务的正是JIT编译器。</p><a id="more"></a><h2 id="2-JIT的工作原理"><a href="#2-JIT的工作原理" class="headerlink" title="2. JIT的工作原理"></a>2. JIT的工作原理</h2><p><img data-src="https://upload-images.jianshu.io/upload_images/1917623-2624a58354221aed.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/330/format/webp" alt="JIT的工作原理图"></p><h2 id="3-JIT编译"><a href="#3-JIT编译" class="headerlink" title="3. JIT编译"></a>3. JIT编译</h2><p>对于 Java 代码，刚开始都是被编译器编译成字节码文件，然后字节码文件会被交由 JVM 解释执行，所以可以说 Java 本身是一种半编译半解释执行的语言。</p><p>当JIT编译启用时（默认是启用的），JVM读入.class文件解释后，将其发给JIT编译器。JIT编译器将字节码编译成本机机器代码。</p><p>通常Javac将程序源码编译，转换成java字节码，JVM通过解释字节码将其翻译成相应的机器指令，逐条读入，逐条解释翻译。<br>经过解释运行，其运行速度必定会比可运行的二进制字节码程序慢。为了提高运行速度，引入了JIT技术。</p><p>在执行时JIT会把翻译过的机器码保存起来，已备下次使用，因此从理论上来说，采用该JIT技术能够，能够接近曾经纯编译技术。</p><p>现在主流的商用虚拟机（如Sun HotSpot、IBM J9 如 # 各大主流的虚拟机比较<br>）中几乎都同时包含``解释器和编译器（三大商用虚拟机之一的JRockit是个例外，它内部没有解释器，因此会有启动相应时间长之类的缺点，但它主要是面向服务端的应用，这类应用一般不会重点关注启动时间）。<br>二者各有优势：当程序需要迅速启动和执行时，解释器可以首先发挥作用，省去编译的时间，立即执行；当程序运行后，随着时间的推移，编译器逐渐会返回作用，把越来越多的代码编译成本地代码后，可以获取更高的执行效率。解释执行可以节约内存，而编译执行可以提升效率。</p><p>HotSpot虚拟机中内置了两个JIT编译器：Client Complier和Server Complier，分别用在客户端和服务端，目前主流的HotSpot虚拟机中默认是采用解释器与其中一个编译器直接配合的方式工作。</p><p>运行过程中会被即时编译器编译的热点代码有两类：被多次调用的方法。``被多次调用的循环体。<br>这两种情况，编译器都是以整个方法作为编译对象，这种编译也是虚拟机中标准的编译方式。要知道一段代码或方法是不是热点代码，是不是需要触发即时编译，需要进行Hot Spot Detection（热点探测）。</p><p>目前主要的热点 判定方式有以下两种：</p><ol><li>基于采样的热点探测：<br>采用这种方法的虚拟机会周期性地检查各个线程的栈顶，如果发现某些方法经常出现在栈顶，那这段方法代码就是“热点代码”。这种探测方法的好处是实现简单高效，还可以很容易地获取方法调用关系，缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。</li><li>基于计数器的热点探测：<br>采用这种方法的虚拟机会为每个方法，甚至是代码块建立计数器，统计方法的执行次数，如果执行次数超过一定的阀值，就认为它是“热点方法”。这种统计方法实现复杂一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是它的统计结果相对更加精确严谨。</li></ol><p>HotSpot虚拟机中使用的是第二种:基于计数器的热点探测方法，因此它为每个方法准备了两个计数器：方法调用计数器和回边计数器。</p><ol><li><p>方法调用计数器<br>方法调用计数器用来统计方法调用的次数，在默认设置下，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间内方法被调用的次数。</p></li><li><p>回边计数器<br>用于统计一个方法中循环体代码执行的次数（准确地说，应该是回边的次数，因为并非所有的循环都是回边），在字节码中遇到控制流向后跳转的指令就称为“回边”。</p></li></ol><p>JIT编译。触发了JIT编译后，在默认设置下，执行引擎并不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成为止（编译工作在后台线程中进行）。当编译工作完成后，下一次调用该方法或代码时，就会使用已编译的版本。</p><p><img data-src="https://upload-images.jianshu.io/upload_images/1917623-1068b27cb819b4db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/545/format/webp" alt="方法调用计数器触发即时编译的流程(回边计数器触发即时编译的过程类似)"></p><p>注: Javac字节码编译器与虚拟机内的JIT编译器的执行过程合起来其实就等同于一个传统的编译器所执行的编译过程。</p><h2 id="Java和C-C-的编译器对比"><a href="#Java和C-C-的编译器对比" class="headerlink" title="Java和C/C++的编译器对比"></a>Java和C/C++的编译器对比</h2><p>这里不是比Java和C/C++谁快这种大坑问题，只是比较编译器（我个人认为开发效率上Java快，执行效率上C/C++快）</p><p>这种对比代表了经典的即时编译器与静态编译期的对比，其实总体来说Java编译器有优有劣。主要就是动态编译时间压力大能做的优化少，还要做一些动态校验。而静态编译器无法实现一些开发上很有用的动态特性。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-什么是JIT：&quot;&gt;&lt;a href=&quot;#1-什么是JIT：&quot; class=&quot;headerlink&quot; title=&quot;1. 什么是JIT：&quot;&gt;&lt;/a&gt;1. 什么是JIT：&lt;/h2&gt;&lt;p&gt;JIT编译器（just in time 即时编译器），当虚拟机发现某个方法或代码块运行特别频繁时，就会把这些代码认定为(Hot Spot Code 热点代码，为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各层次的优化，完成这项任务的正是JIT编译器。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="https://www.alan87.top/categories/java/"/>
    
    
      <category term="Java" scheme="https://www.alan87.top/tags/java/"/>
    
  </entry>
  
</feed>
